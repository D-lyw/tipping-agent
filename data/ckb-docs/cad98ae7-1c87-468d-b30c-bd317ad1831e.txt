Directory structure:
└── nervosnetwork-fiber/
    ├── README.md
    ├── Cargo.toml
    ├── Makefile
    ├── rust-toolchain.toml
    ├── config/
    │   └── testnet/
    │       └── config.yml
    ├── docs/
    │   ├── light-paper-cn.md
    │   ├── light-paper.md
    │   ├── dev/
    │   │   └── README.md
    │   ├── notes/
    │   │   ├── README.md
    │   │   └── state-updates-across-multiple-actors.md
    │   └── specs/
    │       ├── cross-chain-htlc.md
    │       ├── p2p-message.md
    │       └── payment-invoice.md
    ├── migrate/
    │   ├── Cargo.lock
    │   ├── Cargo.toml
    │   ├── build.rs
    │   └── src/
    │       ├── lib.rs
    │       ├── main.rs
    │       ├── util.rs
    │       └── migrations/
    │           ├── mig_20250114.rs
    │           ├── mig_20250115.rs
    │           ├── mig_20250123.rs
    │           ├── mod.rs
    │           └── sample.rs
    ├── src/
    │   ├── actors.rs
    │   ├── build.rs
    │   ├── config.rs
    │   ├── errors.rs
    │   ├── lib.rs
    │   ├── main.rs
    │   ├── tasks.rs
    │   ├── cch/
    │   │   ├── actor.rs
    │   │   ├── config.rs
    │   │   ├── error.rs
    │   │   ├── mod.rs
    │   │   ├── order.rs
    │   │   └── orders_db.rs
    │   ├── ckb/
    │   │   ├── actor.rs
    │   │   ├── config.rs
    │   │   ├── contracts.rs
    │   │   ├── error.rs
    │   │   ├── mod.rs
    │   │   ├── funding/
    │   │   │   ├── funding_tx.rs
    │   │   │   └── mod.rs
    │   │   └── tests/
    │   │       ├── actor.rs
    │   │       ├── config.rs
    │   │       ├── mod.rs
    │   │       └── test_utils.rs
    │   ├── fiber/
    │   │   ├── channel.rs
    │   │   ├── config.rs
    │   │   ├── fee.rs
    │   │   ├── gossip.rs
    │   │   ├── graph.rs
    │   │   ├── hash_algorithm.rs
    │   │   ├── history.rs
    │   │   ├── key.rs
    │   │   ├── mod.rs
    │   │   ├── network.rs
    │   │   ├── path.rs
    │   │   ├── serde_utils.rs
    │   │   ├── types.rs
    │   │   ├── gen/
    │   │   │   ├── fiber.rs
    │   │   │   ├── gossip.rs
    │   │   │   ├── invoice.rs
    │   │   │   └── mod.rs
    │   │   ├── schema/
    │   │   │   ├── README.md
    │   │   │   ├── blockchain.mol
    │   │   │   ├── fiber.mol
    │   │   │   ├── gen.sh
    │   │   │   ├── gossip.mol
    │   │   │   └── invoice.mol
    │   │   └── tests/
    │   │       ├── channel.rs
    │   │       ├── gossip.rs
    │   │       ├── graph.rs
    │   │       ├── hash_algorithm.rs
    │   │       ├── history.rs
    │   │       ├── mod.rs
    │   │       ├── network.rs
    │   │       ├── path.rs
    │   │       ├── payment.rs
    │   │       ├── serde_utils.rs
    │   │       ├── test_utils.rs
    │   │       ├── tlc_op.rs
    │   │       └── types.rs
    │   ├── invoice/
    │   │   ├── command.rs
    │   │   ├── errors.rs
    │   │   ├── invoice_impl.rs
    │   │   ├── mod.rs
    │   │   ├── store.rs
    │   │   ├── utils.rs
    │   │   └── tests/
    │   │       ├── invoice_impl.rs
    │   │       └── mod.rs
    │   ├── rpc/
    │   │   ├── README.md
    │   │   ├── cch.rs
    │   │   ├── channel.rs
    │   │   ├── config.rs
    │   │   ├── dev.rs
    │   │   ├── graph.rs
    │   │   ├── info.rs
    │   │   ├── invoice.rs
    │   │   ├── mod.rs
    │   │   ├── payment.rs
    │   │   ├── peer.rs
    │   │   └── utils.rs
    │   ├── store/
    │   │   ├── db_migrate.rs
    │   │   ├── migration.rs
    │   │   ├── mod.rs
    │   │   ├── schema.rs
    │   │   ├── store.rs
    │   │   └── tests/
    │   │       ├── migrate.rs
    │   │       ├── mod.rs
    │   │       └── store.rs
    │   ├── tests/
    │   │   └── mod.rs
    │   └── watchtower/
    │       ├── actor.rs
    │       ├── mod.rs
    │       └── store.rs
    ├── tests/
    │   ├── bruno/
    │   │   ├── bruno.json
    │   │   ├── e2e/
    │   │   │   ├── 3-nodes-transfer/
    │   │   │   │   ├── README.md
    │   │   │   │   ├── 01-node1-connect-node2.bru
    │   │   │   │   ├── 02-node2-connect-node3.bru
    │   │   │   │   ├── 03-node1-node2-open-channel.bru
    │   │   │   │   ├── 04-node2-get-auto-accepted-channel.bru
    │   │   │   │   ├── 06-ckb-generate-blocks.bru
    │   │   │   │   ├── 07-node2-node3-open-channel.bru
    │   │   │   │   ├── 08-node3-get-auto-accepted-channel.bru
    │   │   │   │   ├── 10-ckb-generate-blocks.bru
    │   │   │   │   ├── 10-node2-list-channels.bru
    │   │   │   │   ├── 11-node3-gen-invoice.bru
    │   │   │   │   ├── 12-node1-add-tlc.bru
    │   │   │   │   ├── 13-node2-add-tlc.bru
    │   │   │   │   ├── 14-node3-get-invoice.bru
    │   │   │   │   ├── 14-node3-remove-tlc.bru
    │   │   │   │   ├── 15-node2-remove-tlc.bru
    │   │   │   │   ├── 16-node3-gen-invoice.bru
    │   │   │   │   ├── 17-node1-add-tlc.bru
    │   │   │   │   ├── 18-node2-add-tlc.bru
    │   │   │   │   ├── 19-node3-remove-tlc.bru
    │   │   │   │   ├── 20-node2-remove-tlc.bru
    │   │   │   │   ├── 20-node3-list-channels.bru
    │   │   │   │   ├── 21-node1-send-shutdown-channel-1.bru
    │   │   │   │   └── 23-node2-send-shutdown-channel-2.bru
    │   │   │   ├── cross-chain-hub/
    │   │   │   │   ├── README.md
    │   │   │   │   ├── 01-add-btc-invoice.bru
    │   │   │   │   ├── 02-create-send-btc-order.bru
    │   │   │   │   ├── 03-node1-connect-node3.bru
    │   │   │   │   ├── 04-node1-open-channel-to-node3.bru
    │   │   │   │   ├── 05-node3-accept-channel.bru
    │   │   │   │   ├── 06-ckb-generate-blocks.bru
    │   │   │   │   ├── 07-node1-add-tlc.bru
    │   │   │   │   ├── 08-check-btc-received.bru
    │   │   │   │   ├── 09-create-receive-btc-order.bru
    │   │   │   │   ├── 10-pay-btc-invoice.bru
    │   │   │   │   ├── 11-get-receive-btc-order-tlc-id.bru
    │   │   │   │   ├── 12-remove-tlc-for-receive-btc-order.bru
    │   │   │   │   ├── 13-node1-send-shutdown-channel.bru
    │   │   │   │   ├── 14-node3-send-shutdown-channel.bru
    │   │   │   │   └── 15-node3-list-channel.bru
    │   │   │   ├── invoice-ops/
    │   │   │   │   ├── 1-gen-invoice.bru
    │   │   │   │   ├── 2-gen-invoice-duplicate.bru
    │   │   │   │   ├── 3-invoice-decode.bru
    │   │   │   │   ├── 4-get-invoice.bru
    │   │   │   │   └── 5-cancel-invoice.bru
    │   │   │   ├── open-use-close-a-channel/
    │   │   │   │   ├── README.md
    │   │   │   │   ├── 01-connect-peer.bru
    │   │   │   │   ├── 02-open-channel.bru
    │   │   │   │   ├── 03-get-auto-accepted-channel.bru
    │   │   │   │   ├── 06-generate-a-few-blocks.bru
    │   │   │   │   ├── 07-add-tlc-from-NODE3.bru
    │   │   │   │   ├── 08-add-tlc-from-NODE1-err.bru
    │   │   │   │   ├── 09-add-tlc-from-NODE3.bru
    │   │   │   │   ├── 10-add-tlc-from-NODE1-amount-err.bru
    │   │   │   │   ├── 10-add-tlc-from-NODE1-balance-err.bru
    │   │   │   │   ├── 11-add-tlc-from-NODE3.bru
    │   │   │   │   ├── 12-add-tlc-from-NODE3.bru
    │   │   │   │   ├── 13-remove-tlc-from-NODE1.bru
    │   │   │   │   ├── 14-remove-tlc-from-NODE3.bru
    │   │   │   │   ├── 15-shutdown-from-NODE1.bru
    │   │   │   │   ├── 16-remove-tlc-from-NODE1.bru
    │   │   │   │   ├── 17-remove-tlc-from-NODE3.bru
    │   │   │   │   ├── 18-remove-tlc-from-NODE1.bru
    │   │   │   │   ├── 19-remove-tlc-from-NODE1.bru
    │   │   │   │   └── 20-list-channel-from-NODE1.bru
    │   │   │   ├── reestablish/
    │   │   │   │   ├── 01-connect-peer.bru
    │   │   │   │   ├── 02-open-channel.bru
    │   │   │   │   ├── 03-get-auto-accepted-channel.bru
    │   │   │   │   ├── 06-generate-a-few-blocks.bru
    │   │   │   │   ├── 07-add-tlc-from-NODE3.bru
    │   │   │   │   ├── 08-disconnect-NODE1.bru
    │   │   │   │   ├── 09-reconnect-peer-NODE1.bru
    │   │   │   │   ├── 10-remove-tlc-from-NODE1.bru
    │   │   │   │   └── 11-shutdown-from-NODE1.bru
    │   │   │   ├── router-pay/
    │   │   │   │   ├── 01-node1-connect-node2.bru
    │   │   │   │   ├── 02-node2-connect-node3.bru
    │   │   │   │   ├── 03-node1-node2-open-channel.bru
    │   │   │   │   ├── 04-node2-get-auto-accepted-channel.bru
    │   │   │   │   ├── 06-ckb-generate-blocks.bru
    │   │   │   │   ├── 07-node2-node3-open-channel.bru
    │   │   │   │   ├── 08-node3-get-auto-accepted-channel.bru
    │   │   │   │   ├── 10-ckb-generate-blocks.bru
    │   │   │   │   ├── 11-node2-list-channels.bru
    │   │   │   │   ├── 11-node2-list-graph-channels.bru
    │   │   │   │   ├── 11-node3-gen-invoice.bru
    │   │   │   │   ├── 12-node1-send-payment.bru
    │   │   │   │   ├── 12-node1-to-get-payment-status.bru
    │   │   │   │   ├── 13-node-send-duplicate-payment-err.bru
    │   │   │   │   ├── 13-node2-list-channels.bru
    │   │   │   │   ├── 14-node3-gen-invoice-later.bru
    │   │   │   │   ├── 15-node1-send-payment-with-invoice.bru
    │   │   │   │   ├── 16-node1-get-nodes.bru
    │   │   │   │   ├── 16-node1-send-payment-keysend.bru
    │   │   │   │   ├── 17-node1-get-payment-status.bru
    │   │   │   │   ├── 18-node1-get-channels.bru
    │   │   │   │   ├── 19-node1-get-nodes-page.bru
    │   │   │   │   ├── 20-node1-get-nodes-page-2.bru
    │   │   │   │   ├── 21-node1-get-nodes-page-3.bru
    │   │   │   │   ├── 21-node2-list-channels.bru
    │   │   │   │   ├── 22-node3-gen-expiring-invoice.bru
    │   │   │   │   ├── 23-node1-send-payment-will-fail.bru
    │   │   │   │   ├── 24-node1-gen-invoice-for-self.bru
    │   │   │   │   ├── 25-node1-pay-self-with-node2-err.bru
    │   │   │   │   ├── 26-node2-node1-open-channel.bru
    │   │   │   │   ├── 27-ckb-generate-blocks.bru
    │   │   │   │   ├── 28-node1-list-graph-channels.bru
    │   │   │   │   ├── 29-node1-pay-self-with-node2-succ.bru
    │   │   │   │   ├── 30-node2-list-graph-chanels.bru
    │   │   │   │   ├── 31-node1-get-payment-status.bru
    │   │   │   │   ├── 32-node2-list-channels.bru
    │   │   │   │   ├── 33-node2-update-channel.bru
    │   │   │   │   ├── 34-node1-send-payment.bru
    │   │   │   │   └── 35-node1-get-payment-status.bru
    │   │   │   ├── shutdown-force/
    │   │   │   │   ├── 01-connect-peer.bru
    │   │   │   │   ├── 02-open-channel.bru
    │   │   │   │   ├── 03-get-auto-accepted-channel.bru
    │   │   │   │   ├── 04-generate-a-few-blocks.bru
    │   │   │   │   ├── 05-shutdown-force-NODE1.bru
    │   │   │   │   ├── 06-generate-a-few-blocks.bru
    │   │   │   │   └── 07-list-channel.bru
    │   │   │   ├── udt/
    │   │   │   │   ├── 01-node1-connect-node2.bru
    │   │   │   │   ├── 02-node1-node2-open-channel-amount-err.bru
    │   │   │   │   ├── 03-node2-list-channel-empty.bru
    │   │   │   │   ├── 04-node1-node2-open-channel.bru
    │   │   │   │   ├── 05-node2-list-channel.bru
    │   │   │   │   ├── 06-ckb-generate-blocks.bru
    │   │   │   │   ├── 07-node2-gen-invoice.bru
    │   │   │   │   ├── 08-node1-add-tlc.bru
    │   │   │   │   ├── 09-node2-remove-tlc.bru
    │   │   │   │   ├── 10-node1-node2-open-channel-invalid.bru
    │   │   │   │   ├── 11-node1-node2-open-channel-no-auto-accept.bru
    │   │   │   │   ├── 12-node2-accept-channel.bru
    │   │   │   │   ├── 13-ckb-generate-blocks.bru
    │   │   │   │   ├── 14-node2-list-channel-expect-two-channel.bru
    │   │   │   │   └── 15-node1-send-shutdown-channel.bru
    │   │   │   ├── udt-router-pay/
    │   │   │   │   ├── 01-node1-connect-node2.bru
    │   │   │   │   ├── 02-node2-connect-node3.bru
    │   │   │   │   ├── 03-node1-node2-open-channel.bru
    │   │   │   │   ├── 04-node2-get-auto-accepted-channel.bru
    │   │   │   │   ├── 06-ckb-generate-blocks.bru
    │   │   │   │   ├── 07-node2-node3-open-channel.bru
    │   │   │   │   ├── 08-node3-get-auto-accepted-channel.bru
    │   │   │   │   ├── 10-ckb-generate-blocks.bru
    │   │   │   │   ├── 11-node2-list-channels.bru
    │   │   │   │   ├── 11-node3-gen-invoice.bru
    │   │   │   │   ├── 12-node1-send-payment.bru
    │   │   │   │   ├── 13-node3-gen-invoice-later.bru
    │   │   │   │   ├── 14-node1-send-payment-with-invoice.bru
    │   │   │   │   ├── 15-node1-send-payment-keysend.bru
    │   │   │   │   ├── 16-node1-send-payment-keysend-large-amount.bru
    │   │   │   │   └── 17-node2-list-channels.bru
    │   │   │   └── watchtower/
    │   │   │       ├── force-close/
    │   │   │       │   ├── 01-connect-peer.bru
    │   │   │       │   ├── 02-open-channel.bru
    │   │   │       │   ├── 03-accept-channel.bru
    │   │   │       │   ├── 04-generate-a-few-blocks.bru
    │   │   │       │   ├── 05-node2-gen-invoice.bru
    │   │   │       │   ├── 06-node1-send-payment-with-invoice.bru
    │   │   │       │   ├── 07-force-close.bru
    │   │   │       │   ├── 08-get-force-closed-commitment-tx-hash.bru
    │   │   │       │   ├── 09-generate-a-few-blocks-for-commitment-tx.bru
    │   │   │       │   ├── 10-generate-a-few-blocks-for-settlement-tx-generated.bru
    │   │   │       │   ├── 11-generate-a-few-blocks-for-settlement-tx-committed.bru
    │   │   │       │   ├── 12-check-commitment-tx.bru
    │   │   │       │   ├── 13-check-balance-node1.bru
    │   │   │       │   └── 14-check-balance-node2.bru
    │   │   │       ├── force-close-after-multiple-payments/
    │   │   │       │   ├── 01-connect-peer.bru
    │   │   │       │   ├── 02-open-channel.bru
    │   │   │       │   ├── 03-accept-channel.bru
    │   │   │       │   ├── 04-generate-a-few-blocks.bru
    │   │   │       │   ├── 05-node2-gen-invoice.bru
    │   │   │       │   ├── 06-node1-send-payment-with-invoice.bru
    │   │   │       │   ├── 07-node1-gen-invoice.bru
    │   │   │       │   ├── 08-node2-send-payment-with-invoice.bru
    │   │   │       │   ├── 09-force-close.bru
    │   │   │       │   ├── 10-generate-a-few-blocks-for-commitment-tx.bru
    │   │   │       │   ├── 11-generate-a-few-blocks-for-settlement-tx-generated.bru
    │   │   │       │   ├── 12-generate-a-few-blocks-for-settlement-tx-committed.bru
    │   │   │       │   ├── 13-get-force-closed-commitment-tx-hash.bru
    │   │   │       │   ├── 14-check-commitment-tx.bru
    │   │   │       │   ├── 15-check-balance-node1.bru
    │   │   │       │   └── 16-check-balance-node2.bru
    │   │   │       ├── force-close-after-open-channel/
    │   │   │       │   ├── 01-connect-peer.bru
    │   │   │       │   ├── 02-open-channel.bru
    │   │   │       │   ├── 03-accept-channel.bru
    │   │   │       │   ├── 04-generate-a-few-blocks.bru
    │   │   │       │   ├── 05-force-close.bru
    │   │   │       │   ├── 06-get-force-closed-commitment-tx-hash.bru
    │   │   │       │   ├── 07-generate-a-few-blocks-for-commitment-tx.bru
    │   │   │       │   ├── 08-generate-a-few-blocks-for-settlement-tx-generated.bru
    │   │   │       │   ├── 09-generate-a-few-blocks-for-settlement-tx-committed.bru
    │   │   │       │   ├── 10-check-commitment-tx.bru
    │   │   │       │   ├── 11-check-balance-node1.bru
    │   │   │       │   └── 12-check-balance-node2.bru
    │   │   │       └── revocation/
    │   │   │           ├── 01-connect-peer.bru
    │   │   │           ├── 02-open-channel.bru
    │   │   │           ├── 03-get-auto-accepted-channel.bru
    │   │   │           ├── 04-generate-a-few-blocks.bru
    │   │   │           ├── 05-node3-gen-invoice.bru
    │   │   │           ├── 06-node1-send-payment-with-invoice.bru
    │   │   │           ├── 07-submit-old-version-commitment-tx.bru
    │   │   │           ├── 08-generate-a-few-blocks-for-commitment-tx.bru
    │   │   │           ├── 09-generate-a-few-blocks-for-revocation-tx.bru
    │   │   │           └── 10-check-commitment-tx.bru
    │   │   ├── environments/
    │   │   │   ├── test.bru
    │   │   │   └── xudt-test.bru
    │   │   └── unit/
    │   │       ├── connect-non-existent-peer.bru
    │   │       └── start.sh
    │   ├── deploy/
    │   │   ├── deploy.sh
    │   │   ├── generate-blocks.sh
    │   │   ├── init-dev-chain.sh
    │   │   ├── .gitignore
    │   │   ├── contracts/
    │   │   │   ├── README.md
    │   │   │   ├── always_success
    │   │   │   ├── auth
    │   │   │   ├── commitment-lock
    │   │   │   ├── funding-lock
    │   │   │   ├── simple_udt
    │   │   │   └── xudt_rce
    │   │   ├── lnd-init/
    │   │   │   ├── README.md
    │   │   │   ├── setup-lnd.sh
    │   │   │   ├── .gitignore
    │   │   │   ├── bitcoind/
    │   │   │   │   └── bitcoin.conf
    │   │   │   ├── lnd-bob/
    │   │   │   │   └── lnd.conf
    │   │   │   └── lnd-ingrid/
    │   │   │       └── lnd.conf
    │   │   ├── migrations/
    │   │   │   └── templates/
    │   │   │       ├── commitment-lock.toml
    │   │   │       ├── funding-lock.toml
    │   │   │       ├── simple-udt.toml
    │   │   │       └── xudt.toml
    │   │   └── udt-init/
    │   │       ├── README.md
    │   │       ├── Cargo.lock
    │   │       ├── Cargo.toml
    │   │       ├── .gitignore
    │   │       └── src/
    │   │           └── main.rs
    │   └── nodes/
    │       ├── start.sh
    │       ├── 1/
    │       │   ├── ckb/
    │       │   │   ├── key
    │       │   │   └── wallet
    │       │   └── fiber/
    │       │       └── sk
    │       ├── 2/
    │       │   ├── ckb/
    │       │   │   ├── key
    │       │   │   └── wallet
    │       │   └── fiber/
    │       │       └── sk
    │       ├── 3/
    │       │   ├── cch/
    │       │   │   └── .gitkeep
    │       │   ├── ckb/
    │       │   │   ├── key
    │       │   │   └── wallet
    │       │   └── fiber/
    │       │       └── sk
    │       ├── bootnode/
    │       │   ├── ckb/
    │       │   │   ├── key
    │       │   │   └── wallet
    │       │   └── fiber/
    │       │       └── sk
    │       └── deployer/
    │           ├── config.yml
    │           ├── dev.toml
    │           ├── ckb/
    │           │   ├── key
    │           │   └── wallet
    │           └── fiber/
    │               └── sk
    └── .github/
        ├── codecov.yaml
        └── workflows/
            ├── ci.yml
            ├── e2e.yml
            └── release.yml

================================================
File: README.md
================================================
# Fiber Network Node

Fiber Network Node (FNN) is a reference implementation of Fiber Network Protocol (FNP). In the current stage, it's not a production-ready implementation, but a prototype to demonstrate the feasibility of FNP. It's capable of:

* Establishing connections with other FNN
* Creating and closing fiber channel
* Payments over fiber channel (via [fiber-scripts])
* Cross-chain asset transfer

Please note that the implementation is still under development, there are many limitations and known issues, you may find or report them in the issue tracker.

But as a prototype, it's a good starting point for developers to understand the FNP and try out the integration with their applications.

## Build and run a testnet node

1. Build the project, if you are using the released binary, you can skip this step:

```
cargo build --release
```

2. Create a data folder for the node, then copy the built binary and testnet config file to it:

```
mkdir /folder-to/my-fnn
// if you are using the released binary, replace target/release/fnn with the path of released binary
cp target/release/fnn /folder-to/my-fnn
cp config/testnet/config.yml /folder-to/my-fnn
cd /folder-to/my-fnn
```

3. FNN has the built-in wallet functionality to sign funding transactions, let's create or import a private key first. The private key is stored in the data folder and named `ckb/key`. You may use the ckb-cli to generate a new key or export an existing key:

```
mkdir ckb
ckb-cli account export --lock-arg <lock_arg> --extended-privkey-path ./ckb/exported-key
// ckb-cli exports master private key and chain code, FNN only needs the private key part
head -n 1 ./ckb/exported-key > ./ckb/key
```

4. Start the node, by default it will output logs to the console, you may redirect it to a file:

```
RUST_LOG=info ./fnn -c config.yml -d .
```

## Testnet compatibility issues

The current state of the FNN is not stable, the protocol and storage format may changed between versions. We strongly recommend you to close the channel before upgrading the node, otherwise, you may lose the channel state:

1. [list all channels](./src/rpc/README.md#channel-list_channels) and [close](./src/rpc/README.md#channel-shutdown_channel) them via RPC.

2. Stop the node and remove the storage of the node:

```
rm -rf /folder-to/my-fnn/fiber/store
```

3. Repalce the fnn binary with the new version and start the node again.


If you want to keep the channel state, you may try to migrate the storage format manually:

1. Stop the node.

2. Backup the storage folder `/folder-to/my-fnn/fiber/store`.

3. Run the fnn-migrate (it can be found in the release binary package) to migrate the storage format:

```
fnn-migrate -p /folder-to/my-fnn/fiber/store
```

4. Repalce the fnn binary with the new version and start the node again.

## Documentation

* [Light Paper](./docs/light-paper.md)
* [RPC Documentation](./src/rpc/README.md)
* [P2P Message Protocol](./docs/specs/p2p-message.md)
* [Invoice Protocol](./docs/specs/payment-invoice.md)

**We are in a actively developing stage, don't hesitate to [report issues](https://github.com/nervosnetwork/fiber/issues) or ask for help in the [channel of the Nervos dev community](https://discord.gg/c5gntbFd).**

## Testnet deployment information

* TODO: Add testnet deployed nodes information *

[fiber-scripts]: https://github.com/nervosnetwork/fiber-scripts


================================================
File: Cargo.toml
================================================
[package]
name = "fnn"
version = "0.3.1"
edition = "2021"
build = "src/build.rs"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]
clap = { version = "4.5.2", features = ["derive", "env", "string"] }
clap-serde-derive = "0.2.1"
serde = { version = "1.0.197", features = ["derive"] }
serde_yaml = "0.9.32"
lightning-invoice = { version = "0.29.0" }
bitcoin = { version = "0.30.2", features = ["serde", "rand"] }
bech32 = "0.8"
rand = "0.8.5"
serde_json = { version = "1.0" }
home = "0.5.9"
ckb-sdk = "3.4"
thiserror = "1.0.58"
anyhow = "1.0.81"
tentacle = { version = "0.6.6", default-features = false, features = ["upnp", "parking_lot", "openssl-vendored", "tokio-runtime", "tokio-timer", "ws"] }
futures = "0.3.30"
once_cell = "1.19.0"
tokio-util = { version = "0.7.10", features = ["rt"] }
molecule = { version = "0.8.0", default-features = false }
ckb-types = "0.118.0"
ckb-gen-types = "0.118.0"
ckb-jsonrpc-types = "0.118.0"
ckb-chain-spec    = "0.118.0"
ckb-resource      = "0.118.0"
rocksdb = { package = "ckb-rocksdb", version = "=0.21.1", features = [
    "lz4"
], default-features = false }
serde_with = { version = "3.7.0", features = ["macros", "base64"] }
hex = "0.4.3"
jsonrpsee = { version = "0.22", features = ["server", "macros"] }
bitflags = { version = "2.5.0", features = ["serde"] }
ckb-hash = "0.115.0"
secp256k1 = { version = "0.28.0", features = ["serde", "recovery", "rand-std"] }
musig2 = { version = "0.0.11", features = ["secp256k1", "serde"] }
ractor = "0.14.2"
arcode = "0.2.4"
nom = "7.1.3"
regex = "1.10.5"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
socket2 = "0.5.7"
lnd-grpc-tonic-client = "0.3.0"
git-version = "0.3.9"
fiber-sphinx = "2.1.0"
strum = { version = "0.26", features = ["derive"] }
tokio = { version = "1", features = [
    "io-util",
    "macros",
    "rt",
    "rt-multi-thread",
    "sync",
    "net",
    "time",
    "signal",
] }
indicatif = "0.16"
console = "0.15.8"
bincode = "1.3.3"
num_enum = "0.7.3"

[features]
default = []
portable = ["rocksdb/portable"]

[profile.release]
panic = "abort"
overflow-checks = true

[profile.dev]
panic = "abort"

[profile.quick_test]
inherits = "test"
opt-level = 3
debug = false

[dev-dependencies]
tempfile = "3.10.1"
ckb-testtool = "0.13.2"
ciborium = "0.2.2"

[lints.clippy]
needless-return = "allow"
mutable-key-type = "allow"
upper-case-acronyms = "allow"
fallible-impl-from = "allow"
expect-fun-call = "allow"
large-enum-variant = "allow"


================================================
File: Makefile
================================================
CARGO_TARGET_DIR ?= target
COVERAGE_PROFRAW_DIR ?= ${CARGO_TARGET_DIR}/coverage
GRCOV_OUTPUT ?= coverage-report.info
GRCOV_EXCL_START = ^\s*((log::|tracing::)?(trace|debug|info|warn|error)|(debug_)?assert(_eq|_ne|_error_eq))!\($$
GRCOV_EXCL_STOP  = ^\s*\)(;)?$$
GRCOV_EXCL_LINE = ^\s*(\})*(\))*(;)*$$|\s*((log::|tracing::)?(trace|debug|info|warn|error)|(debug_)?assert(_eq|_ne|_error_eq))!\(.*\)(;)?$$

.PHONY: test
test:
	TEST_TEMP_RETAIN=1 RUST_LOG=off cargo nextest run --no-fail-fast

.PHONY: clippy
clippy:
	cargo clippy --all --all-targets --all-features -- -D warnings -A clippy::module-inception

.PHONY: bless
bless:
	cargo clippy --fix --allow-dirty --allow-staged --all --all-targets --all-features

.PHONY: fmt
fmt:
	cargo fmt --all -- --check

coverage-clean:
	rm -rf "${CARGO_TARGET_DIR}/*.profraw" "${GRCOV_OUTPUT}" "${GRCOV_OUTPUT:.info=}"

coverage-install-tools:
	rustup component add llvm-tools-preview
	grcov --version || cargo install --locked grcov

coverage-run-unittests:
	mkdir -p "${COVERAGE_PROFRAW_DIR}"
	rm -f "${COVERAGE_PROFRAW_DIR}/*.profraw"
	RUSTFLAGS="${RUSTFLAGS} -Cinstrument-coverage" \
		RUST_LOG=off \
		LLVM_PROFILE_FILE="${COVERAGE_PROFRAW_DIR}/unittests-%p-%m.profraw" \
		TEST_TEMP_RETAIN=1 \
			cargo test --all

coverage-collect-data:
	grcov "${COVERAGE_PROFRAW_DIR}" --binary-path "${CARGO_TARGET_DIR}/debug/" \
		-s . -t lcov --branch --ignore-not-existing \
		--ignore "/*" \
		--ignore "*/tests/*" \
		--ignore "*/tests.rs" \
		--excl-br-start "${GRCOV_EXCL_START}" --excl-br-stop "${GRCOV_EXCL_STOP}" \
		--excl-start    "${GRCOV_EXCL_START}" --excl-stop    "${GRCOV_EXCL_STOP}" \
		--excl-br-line  "${GRCOV_EXCL_LINE}" \
		--excl-line     "${GRCOV_EXCL_LINE}" \
		-o "${GRCOV_OUTPUT}"

coverage-generate-report:
	genhtml --ignore-errors inconsistent --ignore-errors corrupt --ignore-errors range --ignore-errors unmapped -o "${GRCOV_OUTPUT:.info=}" "${GRCOV_OUTPUT}"

coverage: coverage-run-unittests coverage-collect-data coverage-generate-report

.PHONY: gen-rpc-doc
gen-rpc-doc:
	$(if $(shell command -v fiber-rpc-gen),,cargo install fiber-rpc-gen --version 0.1.8 --force)
	fiber-rpc-gen ./src/
	if grep -q "TODO: add desc" ./src/rpc/README.md; then \
        echo "Warning: There are 'TODO: add desc' in src/rpc/README.md, please add documentation comments to resolve them"; \
		exit 1; \
    fi

.PHONY: check-dirty-rpc-doc
check-dirty-rpc-doc: gen-rpc-doc
	git diff --exit-code ./src/rpc/README.md


================================================
File: rust-toolchain.toml
================================================
[toolchain]
channel = "1.81.0"
components = [ "rustfmt", "clippy" ]
profile = "minimal"


================================================
File: config/testnet/config.yml
================================================
# This configuration file only contains the necessary configurations for the testnet deployment.
# All options' descriptions can be found via `fnn --help` and be overridden by command line arguments or environment variables.
fiber:
  listening_addr: "/ip4/127.0.0.1/tcp/8228"
  bootnode_addrs:
    - "/ip4/54.179.226.154/tcp/8228/p2p/Qmes1EBD4yNo9Ywkfe6eRw9tG1nVNGLDmMud1xJMsoYFKy"
    - "/ip4/54.179.226.154/tcp/18228/p2p/QmdyQWjPtbK4NWWsvy8s69NGJaQULwgeQDT5ZpNDrTNaeV"
  announce_listening_addr: true
  announced_addrs:
    # If you want to announce your fiber node public address to the network, you need to add the address here, please change the ip to your public ip accordingly.
    # - "/ip4/YOUR-FIBER-NODE-PUBLIC-IP/tcp/8228"
  chain: testnet
  # lock script configurations related to fiber network
  # https://github.com/nervosnetwork/fiber-scripts/blob/main/deployment/testnet/migrations/2024-09-14-084742.json
  scripts:
    - name: FundingLock
      script:
        code_hash: 0x6c67887fe201ee0c7853f1682c0b77c0e6214044c156c7558269390a8afa6d7c
        hash_type: type
        args: 0x
      cell_deps:
        - out_point:
            tx_hash: 0x89af398edc7ed0054506b33349b031097d94378e11e77bf0690ee69d82623a43
            index: 0x0
          dep_type: code
        - out_point:
            tx_hash: 0xbfd6d68b328a02606f1f65ee0f79f8ed5f76dfe86998c7aaa9ee4720d53f4c49 # ckb_auth
            index: 0x0
          dep_type: code
    - name: CommitmentLock
      script:
        code_hash: 0x740dee83f87c6f309824d8fd3fbdd3c8380ee6fc9acc90b1a748438afcdf81d8
        hash_type: type
        args: 0x
      cell_deps:
        - out_point:
            tx_hash: 0x89af398edc7ed0054506b33349b031097d94378e11e77bf0690ee69d82623a43
            index: 0x1
          dep_type: code
        - out_point:
            tx_hash: 0xbfd6d68b328a02606f1f65ee0f79f8ed5f76dfe86998c7aaa9ee4720d53f4c49 #ckb_auth
            index: 0x0
          dep_type: code

rpc:
  # By default RPC only binds to localhost, thus it only allows accessing from the same machine.
  # Allowing arbitrary machines to access the JSON-RPC port is dangerous and strongly discouraged.
  # Please strictly limit the access to only trusted machines.
  listening_addr: "127.0.0.1:8227"

ckb:
  rpc_url: "https://testnet.ckbapp.dev/"
  udt_whitelist:
    - name: RUSD
      script:
        code_hash: 0x1142755a044bf2ee358cba9f2da187ce928c91cd4dc8692ded0337efa677d21a
        hash_type: type
        args: 0x878fcc6f1f08d48e87bb1c3b3d5083f23f8a39c5d5c764f253b55b998526439b
      cell_deps:
        - tx_hash: 0xed7d65b9ad3d99657e37c4285d585fea8a5fcaf58165d54dacf90243f911548b
          index: 0
          dep_type: code
      auto_accept_amount: 1000000000

services:
  - fiber
  - rpc
  - ckb


================================================
File: docs/light-paper-cn.md
================================================
# Fiber Network：基于 CKB 的闪电网络

## 概述

Fiber Network 是一个基于 Nervos CKB 和链外通道构建的下一代公共闪电网络，可以为 RGB++ 资产提供快速、低成本和去中⼼化的多币种⽀付和点对点交易。

## 背景

### 区块链技术的发展与挑战

区块链技术自比特币问世以来，经历了迅猛的发展。从最初的简单支付功能，逐步扩展到智能合约、去中心化金融（DeFi）、非同质化代币（NFT）等广泛的应用领域。尽管区块链技术在安全性、透明度和去中心化方面具备显著优势，但其在扩展性和交易速度方面面临诸多挑战。

1. 扩展性问题：传统区块链如比特币和以太坊在交易吞吐量上存在显著瓶颈。由于比特币的区块大小限制和10分钟的区块生成时间，其网络每秒只能处理约7笔交易；以太坊尽管有所改进，但每秒处理交易的能力也远低于传统支付网络。

2. 高昂的交易费用：随着网络拥堵的加剧，交易费用显著上升。例如，以太坊网络上高峰期的 Gas 费用可能高于交易金额本身，这严重影响了用户体验并降低了小额支付的可行性。

3. 交易确认时间长：在传统区块链网络中，交易需要等待多个区块确认才能被视为最终确认。这一过程可能耗时数分钟到数小时，不适用于即时支付的应用场景。

Nervos CKB 虽然在性能以及确认时间上有所改进，但仍然需要进一步提高交易速度和降低交易成本，以满足小额支付和即时支付的需求。

### 闪电网络的启示

闪电网络（Lightning Network）作为比特币网络的二层扩展解决方案，通过链下交易和支付通道技术，成功实现了快速、低成本的微支付。其核心理念包括：

1. 支付通道：用户在链上创建支付通道，通道开启后，双方可以无限次地进行链下交易，只有在通道关闭时才进行链上结算。这显著减少了链上交易数量，提升了交易速度，降低了交易费用。

2. 哈希时间锁合约（HTLC）：通过 HTLC 技术闪电网络可以确保资金的安全转移，避免交易对手风险。即使在链下交易失败的情况下，用户也能通过链上合约获得资金保障。

3. 路由机制：闪电网络使用多跳路由，使得用户不需要与收款方开设直接通道即可完成支付，因此提高了网络的灵活性和可用性。

## Nervos CKB 的优势

Nervos CKB 是一个专注于通用性和安全性的区块链平台。其独特的设计使其在解决区块链扩展性和互操作性问题上具备独特优势：

1. 共识机制：基于 [NC-Max](https://eprint.iacr.org/2020/1101) 共识协议，同时在结合了工作量证明（PoW）和状态租赁机制，确保网络安全性和资源利用的有效性。

2. 强大的智能合约模型：CKB 独有的 Cell 模型和 RISC-V 指令集虚拟机大大增强了 UTXO 模型的能力，不仅支持图灵完备的智能合约，还能轻松实现抽象账户以及 covenant 等特性，为去中心化应用提供了更灵活的可编程性，以及更好的互操作性和扩展性。

3. 经济模型：CKB 的经济模型鼓励长期持有和合理使用网络资源，为去中心化应用，开发者和用户提供了安全可持续的去中心化生态环境。

## Fiber Network 项目的意义

通过在 Nervos CKB 上构建链外通道，我们希望结合闪电网络的成功经验和 CKB 的技术优势，构建一个快速、低成本和去中心化的多资产实时支付交换网络。具体而言：

1. 解决扩展性问题：通过链下支付通道和多跳路由技术，Fiber network 可以实现高吞吐量的交易处理，从而满足大规模用户的需求。

2. 降低交易成本：减少链上交易频次，降低用户的交易费用，使得小额支付变得可行和高效。

3. 提高交易速度：通过即时确认的链下交易，实现秒级支付确认体验，适用于各种即时支付场景。

4. 多资产支持：支持多种数字资产的支付，为用户提供更广泛的支付选择。

5. 支持网络互操作: 支持与比特币闪电网络的互操作，为跨链支付和资产转移提供支持。

## 架构设计

### 总体架构

Fiber Network 总体架构包括以下核心模块：

1. 链下支付通道（Fiber Channels）

2. 链上合约（HTLC）

3. 多跳路由（Multi-Hop Routing）

4. 监控服务（Watchtower Service）

### 链下支付通道

链下支付通道是 Fiber Network 的核心，通过它可以实现多次链下交易，仅在通道关闭时进行链上结算。这种机制显著减少了链上交易的数量，提高了交易速度和降低了交易费用。

大致的工作流程如下：

1. 通道创建：双方用户在链上创建支付通道，锁定一定数量的 CKB 或者 RGB++ 资产。

2. 链下交易：在通道开启期间，双方可以任意次进行链下交易，每次交易都更新通道状态，但不需要立即广播到链上。

3. 通道关闭：当任一方决定关闭通道时，将最后的通道状态广播到链上进行结算，确保双方的最终余额得到确认。

具体的消息交互格式可以参考 [Fiber Network P2P Message Protocol](./specs/p2p-message.md)。

### 链上合约

目前我们采用哈希时间锁合约（HTLC） 来确保链下交易的安全性并兼容闪电网络。通过它可以避免交易对手风险，确保即使在链下交易失败的情况下，用户也能通过链上合约获得资金保障。

大致的工作流程如下：

1. 交易发起：支付发起方创建一个带有哈希锁定和时间锁定条件的交易，锁定一定数量的 CKB。

2. 哈希验证：支付接收方必须在规定时间内提供正确的哈希原象，才能解锁交易，完成资金转移。

3. 超时退款：如果接收方在规定时间内未能提供正确的哈希原象，交易将自动解锁并退款给支付发起方。

得益于 CKB 的图灵完备性，我们可以实现更灵活以及更安全的链上合约。之后会进一步扩展合约的功能，比如引入基于版本号的撤销机制和更安全的 Point Time-Locked Contracts。

### 多跳路由

多跳路由技术允许用户在没有和对方直接建立支付通道的情况下，通过多个中间节点完成支付。这种机制增强了网络的灵活性和覆盖范围。

工作流程：

1. 路径发现：支付发起方通过路由模块发现从自身到支付接收方的最优路径。

2. 路径锁定：在路径上的每个节点都创建相应的 HTLC 合约，确保资金安全转移。

3. 支付完成：支付接收方解锁 HTLC，资金依次转移到路径上的各个节点。

同时我们也会在这里用HTLC合约实现跨链的支付，通过 cross-chain hub service 的方式来支持与闪电网络的互操作，具体可以参考 [Payment Channel Cross-Chain Protocol with HTLC](./specs/cross-chain-htlc.md)。

### 监控服务

监控服务是 Fiber Network 的重要组成部分，它负责监控链下支付通道的状态，确保通道的安全性和资金的安全。功能和作用如下：

1. 通道监控：实时监控所有参与用户的支付通道状态，包括通道创建、更新和关闭的过程。

2. 异常检测：检测通道中的异常活动，如恶意用户试图以旧状态关闭通道或企图双花攻击。

3. 主动响应：在检测到异常时，及时向区块链网络广播最新的通道状态，防止恶意行为导致的资金损失。

## 当前进展和计划

目前我们已经完成一个 Fiber Network 的原型，实现了两个节点之间的通道的创建、更新和关闭的基本功能，同时也验证了和比特币闪电网络做跨链的功能。 项目代码可在这 2 个 GitHub 仓库中找到：

1. https://github.com/nervosnetwork/fiber

2. https://github.com/nervosnetwork/fiber-scripts

接下来的工作计划准备完成多跳路由和监控服务，以及完善 RPC 接口和 SDK，使得更多的开发者可以方便的接入 Fiber Network。

多跳路由协议基于 Dijkstra 算法来搜索支付路径，以此降低路由费用，并提高多跳路径支付成功率。 在 Fiber Network 上线运行之后， 我们会根据网络流量和运行情况优化路由算法， 预计将会提供 2～3 种路径搜索策略，以适应用户不同的路由偏好和需求。Fiber Network 还将引入多路径支付策略，将较大的支付额分成多份，每一份由不同的路径传送，进一步增加支付成功概率。

监控服务将由 Fiber Network 中的一些节点提供， 他们保持在线，关注网络中的异常情况，帮助保护通道中的资产。监控服务还将追踪 cross-chain hub service。即使用户在一段时间内离线， 监控服务也能确保与闪电网络的交换能成功进行。

此外，我们还将考虑在 Fiber Network 中加入更多功能，比如，利用 CKB 的可编程性实现隐私保护算法， 并基于此优化路由算法和监控服务，保护用户支付信息的安全和隐私。


================================================
File: docs/light-paper.md
================================================
# Fiber Network: A Lightning Network Based on CKB

## Overview

Fiber Network is a next-generation, common lightning network built on Nervos CKB and off-chain channels. It is designed to provide fast, low-cost, and decentralized multi-token payments and peer-to-peer transactions for RGB++ assets.

## Background

### Evolution and Challenges of Blockchain Technology

Blockchain technology has undergone rapid evolution since the inception of Bitcoin. Initially designed for simple payments, it has gradually expanded into various domains such as smart contracts, decentralized finance (DeFi), and non-fungible tokens (NFTs). Despite its significant advantages in security, transparency, and decentralization, blockchain technology faces several challenges in scalability and transaction speed.

1. Scalability. Traditional blockchains like Bitcoin and Ethereum face significant bottlenecks in transaction throughput. Due to Bitcoin's block size limit and 10-minute block generation time, its network can only process about 7 transactions per second; Ethereum, despite improvements, still has a transaction processing capacity far below traditional payment networks.

2. High transaction fees. As network congestion increases, transaction fees rise significantly. For instance, gas fees on the Ethereum network during peak times may exceed the transaction amount itself, severely affecting user experience and reducing the feasibility of micropayments.

3. Long transaction confirmation times. In traditional blockchain networks, transactions need to wait for multiple block confirmations to be considered final. This process can take minutes to hours, making it unsuitable for instant payment scenarios.

Although Nervos CKB has made improvements in terms of performance and confirmation times, it still needs to further increase transaction speed and reduce transaction costs to meet the demands of micropayments and instant payments.


### Inspiration from the Lightning Network

The Lightning Network, a layer 2 scaling solution for the Bitcoin network, has successfully achieved fast, low-cost micropayments through off-chain transactions and payment channels. Its core concepts include:

1. Payment channels: Users create payment channels on-chain. Once a channel is opened, both parties can conduct unlimited off-chain transactions, only settling on-chain when the channel is closed. This significantly reduces the number of on-chain transactions, improves transaction speed, and lowers transaction fees.

2. Hash Time-Locked Contracts (HTLC): Through HTLCs, the Lightning Network ensures secure fund transfers, mitigating counterparty risk. Even if off-chain transactions fail, users can still secure their funds through on-chain contracts.

3. Routing mechanism: The Lightning Network uses multi-hop routing, allowing users to complete payments without opening direct channels with recipients, thus enhancing network flexibility and usability.


## Advantages of Nervos CKB

Nervos CKB is a blockchain platform focused on versatility and security. Its unique design offers distinct advantages in addressing blockchain scalability and interoperability issues:

1. Consensus mechanism: Based on the [NC-Max](https://eprint.iacr.org/2020/1101) consensus protocol, it combines Proof of Work (PoW) with state rent mechanisms, ensuring network security and effective resource utilization.

2. Powerful smart contract capabilities: CKB's unique Cell model and RISC-V instruction set virtual machine significantly enhance the capabilities of the UTXO model. This not only supports Turing-complete smart contracts but also easily implements features such as account abstraction and covenants, providing more flexible programmability, better interoperability, and scalability for decentralized applications.

3. Tokenomics: CKB's tokenomics encourages long-term holding and rational use of network resources, providing a secure and sustainable decentralized environment for applications, developers, and users.

## Significance of the Fiber Network Project

By building off-chain channels on Nervos CKB, we aim to combine the successful experience of the Lightning Network with CKB's technical advantages to create a fast, low-cost, and decentralized multi-asset real-time payment network. Specifically:

1. Solving scalability issues: Through off-chain payment channels and multi-hop routing, Fiber Network can achieve high-throughput transaction processing, meeting the needs of large-scale users.

2. Reducing transaction costs: By reducing the frequency of on-chain transactions, it lowers transaction fees, making micropayments feasible and efficient.

3. Improving transaction speed: The instant confirmation of off-chain transactions provides a split second payment confirmation experience suitable for various instant payment scenarios.

4. Multi-asset support: Fiber Network supports payments in a variety of digital assets, offering users a broader range of payment options.

5. Interoperability: Fiber Network supports interoperability with the Bitcoin Lightning Network, providing support for cross-chain payments and asset transfers.


## Architecture Design

### Overall Architecture

The overall architecture of Fiber Network includes the following core modules:

1. Off-Chain Payment Channels (Fiber Channels)

2. On-Chain Contracts (HTLC)

3. Multi-Hop Routing

4. Watchtower Service

### Off-chain Payment Channels

Off-chain payment channels are the core of Fiber Network, enabling multiple off-chain transactions with on-chain settlement only when the channel is closed. This mechanism significantly reduces the number of on-chain transactions, improves transaction speed, and lowers transaction fees.
The general workflow is as follows:

1. Opening a Channel: Two parties open a payment channel on-chain, locking a certain amount of CKB or RGB++ assets.

2. Off-chain transactions: When the channel is open, both parties can conduct an unlimited number of off-chain transactions, updating the channel state with each transaction without immediate broadcasting to the chain.

3. Closing the Channel: When either party decides to close the channel, the final channel state is broadcasted on-chain for settlement, ensuring the final balances of both parties are confirmed.

The message interaction format can be referenced in the [Fiber Network P2P Message Protocol](./specs/p2p-message.md).

### On-Chain Contracts

Currently, we use Hash Time-Locked Contracts (HTLC) to ensure the security of off-chain transactions and maintain compatibility with the Lightning Network. This mitigates counterparty risk, ensuring that even if off-chain transactions fail, users can still secure their funds through on-chain contracts.

The general workflow is as follows:

1. Transaction initiation: The payment initiator creates a transaction with hashlock and timelock, and locks a certain amount of CKB.

2. Hash verification: The payment recipient must provide the correct hash preimage within the specified time to unlock the transaction and complete the fund transfer.

3. Timeout refund: If the recipient fails to provide the correct hash preimage within the specified time, the transaction will automatically unlock and refund to the payment initiator.

Thanks to CKB's Turing completeness, we can implement more flexible and secure on-chain contracts. We will further expand the contract's functionality in the future, such as introducing a version-based revocation mechanism and more secure Point Time-Locked Contracts.

### Multi-hop Routing

Multi-hop routing allows users to complete payments through multiple intermediate nodes without establishing direct payment channels with the counterparty. This mechanism enhances the network's flexibility and coverage.

The general workflow is as follows:

1. Path discovery: The payment initiator discovers the optimal path from themselves to the payment recipient through the routing module.

2. Path locking: Each node on the path creates corresponding HTLC contracts, ensuring secure fund transfers.

3. Payment completion: The payment recipient unlocks the HTLC, and funds are transferred sequentially to each node on the path.

We will also implement cross-chain payments here using HTLC contracts, supporting interoperability with the Lightning Network through the cross-chain hub service. For more details, please refer to [Payment Channel Cross-Chain Protocol with HTLC](./specs/cross-chain-htlc.md).

### Watchtower Service

The watchtower service is an essential component of Fiber Network, responsible for monitoring the state of off-chain payment channels and ensuring the security of channels and funds. Its functions and roles are as follows:

1. Channel monitoring: Real-time monitoring of the payment channel state of all participating users, including opening, updating, and closing channels.

2. Anomaly detection: Detecting abnormal activities in channels, such as malicious users attempting to close channels with old states or double-spending attacks.

3. Proactive response: When anomalies are detected, promptly broadcasting the latest channel state to the blockchain network to prevent fund losses due to malicious behavior.

## Current Progress and Future Plans

We have currently completed a prototype of Fiber Network, implementing basic functions of opening, updating, and closing channels between two nodes, and also verifying cross-chain functionality with the Bitcoin Lightning Network. The project code can be found in the following GitHub repositories:

1. https://github.com/nervosnetwork/fiber

2. https://github.com/nervosnetwork/fiber-scripts

Our next steps include completing multi-hop routing and watchtower services, as well as improving the RPC interface and SDK to facilitate easier access for developers to Fiber Network.

The multi-hop routing protocol is based on the Dijkstra algorithm to search for payment paths, thereby reducing routing fees and improving the success rate of multi-hop path payments. After Fiber Network goes live, we will optimize the routing algorithm based on network traffic and operational conditions. We expect to provide 2 or 3 path search strategies to adapt to users' different routing preferences and needs. Fiber Network will also introduce multi-path payment strategies, dividing larger payment amounts into multiple parts, each transmitted through different paths, further increasing the probability of successful payments.

The watchtower service will be provided by some nodes in Fiber Network. These nodes will stay online, monitor abnormal situations in the network, and help protect assets in channels. The monitoring service will also track the cross-chain hub service. Even if users are offline for a period, the monitoring service can ensure successful exchanges with the Lightning Network.

Additionally, we will consider adding more features to Fiber Network, such as implementing privacy protection algorithms leveraging CKB's programmability, and based on this, optimizing routing algorithms and watchtower services to enhance the security and privacy of users’ payment information.


================================================
File: docs/dev/README.md
================================================
# Development

## Run 3 nodes with default balances and deploy contracts to the devchain

Below command automatically start 3 FNN and 1 ckb node.
When we have not intialized the dev chain for ckb, this command will automatically do that.

```
./tests/nodes/start.sh
```

Running above commmand with environment variable `REMOVE_OLD_STATE` to `y` will remove all old states.
i.e.

```
REMOVE_OLD_STATE=y ./tests/nodes/start.sh
```

will start nodes in a clean state. This is useful in case like database schema are changed in development environment.

## (Re)Initialize a dev chain (optional)

We can (re)initialize the dev chain to transfer some balances from the default dev chain account (corresponding to NODE3) and deploy contracts to it. This is normally not needed as above command automatically do that. `-f` parameter may be used to forcefully clean all old state and reintialize the dev chain.

```
./tests/deploy/init-dev-chain.sh [-f]
```

## Run some simple tests to the dev chain

```
cd tests/bruno
npm exec -- @usebruno/cli run e2e/open-use-close-a-channel -r --env test
```


================================================
File: docs/notes/README.md
================================================
# Developing Notes

The notes presented in this directory are intended to group multiple related docs into a
more readable and more maintainable way. Below is a few use cases for these notes.

- Explaining some concepts across multiple source code locations.
- Giving an overview of some historical background on implementation.


This is inspired by the notes in GHC source code. See [The Notes of GHC](https://www.stackbuilders.com/blog/the-notes-of-ghc/).

================================================
File: docs/notes/state-updates-across-multiple-actors.md
================================================
# State updates across multiple actors

One of the major problems of actor model is that updating multiple actors as a single atomic operation is a challenging task. For example, sometimes we want to update the channel actor and network actor atomically. Normally, it should not be a big problem even if there is a short period when the states shared between different actors are inconsistent, but we should be especially careful while updating these states.

================================================
File: docs/specs/cross-chain-htlc.md
================================================
# Payment Channel Cross-Chain Protocol with HTLC

## Synopsis

In the rapidly evolving world of blockchain technology, interoperability between different networks is becoming increasingly crucial. One of the most promising solutions to this challenge is the use of payment channel cross-chain protocols based on Hash Time-Locked Contracts (HTLCs). This post will delve into how HTLCs can be used to ensure atomic payments across different blockchain networks using the same preimage.

## What is HTLC?

Hash Time-Locked Contracts (HTLCs) are a type of smart contract used to facilitate conditional payments. They are designed to ensure that a transaction is either completed within a specified timeframe or canceled. The key components of an HTLC are:

1. **Hashlock**: A cryptographic hash of a secret (preimage) that must be revealed to complete the transaction.
2. **Timelock**: A time constraint that ensures the transaction is either completed within a certain period or reverted.

## Cross-Chain Payments with HTLC

Cross-chain payments involve transferring value across different blockchain networks, which can be difficult due to the absence of direct interoperability. To address this challenge, Hashed Time Lock Contracts (HTLCs) offer a solution by facilitating atomic swaps. These swaps guarantee that transactions are either executed in full or not at all, eliminating the possibility of partial transfers.

To ensure stability in cross-chain payments, the assets utilized in different blockchain networks must maintain a fixed swap ratio. For instance, the Bitcoin payment channel exclusively supports BTC. Meanwhile, CKB can incorporate a wrapped BTC token via the UDT channel, establishing a consistent 1:1 ratio with Bitcoin.

Another requirement is that the two networks must use the same hash algorithm for HTLCs.

## Specification

The protocol has three actors:

- Alice in the Blockchain A who wants to send funds to Bob.
- Bob in the Blockchain B who wants to receive funds from Alice.
- Ingrid is the cross-chain hub service provider who runs the payment channel nodes for both Blockchain A and Blockchain B.

To understand how HTLCs can be used for cross-chain payments, let's break down the process:

1. **Negotiating**:
   - Bob wants to receive $N_b$ amount of asset $T_b$ in the Blockchain B.
   - Alice negotiates with Ingrid that if Alice pays $N_a$ amount of asset $T_a$ in the Blockchain A to Ingrid, Ingrid will send $N_b$ amount of asset $T_b$ to Bob in the Blockchain B.

2. **Offering HTLCs**:
   - Alice offers an HTLC with $N_a$ amount of $T_a$ on Blockchain A to Ingrid, locking her funds with a hashlock and a timelock. The hashlock is derived from a secret preimage $S$ that only Bob knows.
   - Ingrid, upon receiving the hashlock from Alice, creates a corresponding HTLC on Blockchain B with $N_b$ amount of $T_b$, locking his funds with the same hashlock and a timelock.

3. **Revealing the Preimage**:
   - To claim the funds on Blockchain B, Bob must reveal the preimage to Ingrid.
   - Once Ingrid has the preimage, he can use it to unlock the funds on Blockchain A.
   - Both transactions are completed atomically, meaning either both are completed, or neither is.

## Example Between Bitcoin and CKB

### Setup

- Alice is in the Blockchain CKB and runs a FNN (Fiber Network Node).
- Bob is in the Blockchain Bitcoin and runs any BOLT compatible lightning node.
- Ingrid is the cross-chain hub service provider who runs both a FNN in CKB and a BOLT lighting node in Bitcoin.
- The asset used in Blockchain Bitcoin ($T_b$) is BTC.
- Ingrid configures a UDT asset $T_a$ in CKB as the wrapped BTC.

### From CKB to Bitcoin

- Bob wants to receive $X$ BTC in Bitcoin.
- Alice negotiates the swap with Ingrid that if Alice sends $X+F$ wrapped BTC in CKB to Ingrid, Ingrid with send $X$ BTC in Bitcoin to Bob. Ingrid will keep $F$ BTC as the fee.

### From Bitcoin to CKB

- Alice wants to receive $X$ wrapped BTC in CKB.
- Alice negotiates the swap with Ingrid that if Bob sends $X+F$ BTC in Bitcoin to Ingrid, Ingrid with send $X$ wrapped BTC in CKB to Alice. Ingrid will keep $F$ wrapped BTC as the fee.

## Benefits of Using HTLC for Cross-Chain Payments

1. **Security**: The use of cryptographic hash functions ensures that the transactions are secure and tamper-proof.
2. **Atomicity**: The all-or-nothing nature of HTLCs ensures that funds are not lost or stuck in limbo.
3. **Interoperability**: HTLCs enable seamless value transfer between different blockchain networks without the need for a trusted third party.
4. **Compatibility**: The HTLC cross-chain protocol can seamlessly integrate with the existing Bitcoin payment channel network without requiring any modifications.

## Future Works

While HTLCs have proven to be a valuable tool for enabling secure cross-chain payments, future research is exploring the potential of Point Time-Locked Contracts (PTLCs) as an improvement over the current HTLC design. PTLCs replace the hash function used in HTLCs with a public key cryptography scheme, offering several advantages:

- Improved privacy: PTLCs hide the payment hash, making it more difficult for observers to link payments across different hops in the network.
- Reduced on-chain footprint: By using adaptor signatures, PTLCs can reduce the amount of data that needs to be stored on-chain, leading to lower transaction fees and improved scalability.
- Enhanced security: PTLCs are less vulnerable to certain types of attacks, such as the wormhole attack, which can be used to steal funds in HTLC-based payment channels.

Migrating from HTLCs to PTLCs could potentially unlock new possibilities for cross-chain protocols, enabling more private, efficient, and secure value transfer across different blockchain networks. As the technology matures and wildly adopted in Bitcoin, it is likely that more projects will explore the use of PTLCs to enhance their cross-chain payment capabilities and drive further innovation in the blockchain ecosystem.


================================================
File: docs/specs/p2p-message.md
================================================
# Fiber Network P2P Message Protocol

This document describes the protocol between nodes of the fiber network on CKB, used to establish payment channels, construct transactions, close channels, and perform payment operations. Essentially, it is an adaptation and simplification of [BOLT 02] to suit the transaction structure of CKB.

Please note that BOLT 02 uses HTLC (Hashed Time Locked Contract) for payment operations, and many message definitions use HTLC as field names and descriptions. In this document, we will use TLC instead of HTLC to facilitate future support for PTLC (Point Time Locked Contract). Additionally, this protocol will use [Molecule] to define message formats, making it easier to integrate with CKB.

***This document is a work in progress and may be updated at any time.***

## Channel Establishment

We use a protocol similar to BOLTS 02 Channel Establishment v2 to establish payment channels, an example process is as follows:

```
    +-------+                              +-------+
    |       |--(1)--- OpenChannel     ---->|       |
    |       |<-(2)--- AcceptChannel   -----|       |
    |       |                              |       |
--->|       |      <tx collaboration>      |       |
|   |       |                              |       |
|   |       |--(3)--  commitment_signed -->|       |
|   |       |<-(4)--  commitment_signed ---|       |
|   |   A   |                              |   B   |
|   |       |<-(5)--  tx_signatures -------|       |
|   |       |--(6)--  tx_signatures ------>|       |
|   |       |                              |       |
|   |       |--(a)--- tx_init_rbf -------->|       |
----|       |<-(b)--- tx_ack_rbf ----------|       |
    |       |                              |       |
    |       |    <tx rbf collaboration>    |       |
    |       |                              |       |
    |       |--(c)--  commitment_signed -->|       |
    |       |<-(d)--  commitment_signed ---|       |
    |       |                              |       |
    |       |<-(e)--  tx_signatures -------|       |
    |       |--(f)--  tx_signatures ------>|       |
    |       |                              |       |
    |       |--(7)--- channel_ready  ----->|       |
    |       |<-(8)--- channel_ready  ------|       |
    +-------+                              +-------+

    - where node A is *opener*/*initiator* and node B is
      *accepter*/*non-initiator*
```
### OpenChannel

`OpenChannel` is sent by the initiator of the channel to the receiver of the channel to request the establishment of a payment channel.

```
table OpenChannel {
    chain_hash:                  Byte32,
    channel_id:                  Byte32,
    funding_type_script:         ScriptOpt,
    funding_amount:              Uint128,
    funding_fee_rate:            Uint64,
    commitment_fee_rate:         Uint64,
    max_tlc_value_in_flight:     Uint128,
    max_tlc_number_in_flight:    Uint64,
    min_tlc_value:               Uint128,
    to_self_delay:               Uint64,
    funding_pubkey:              Byte33,
    tlc_basepoint:               Byte33,
    first_per_commitment_point:  Byte33,
    second_per_commitment_point: Byte33,
    next_local_nonce:            Byte66,
    channel_flags:               Byte,
}
```

- chain_hash: Chain genesis block hash
- channel_id: The ID of the channel, which is a temporary ID derived from the tlc_basepoint before the channel is officially established. After the channel is established, it will be replaced with the actual channel ID, derived from a blake2b hash of the sorted tlc_basepoints of both parties.
- funding_type_script: Specifies the asset type of the channel. If empty, it indicates using CKB native token as the asset.
- funding_amount: The amount of assets the channel initiator wants to contribute.
- funding_fee_rate: Funding transaction fee rate, in shannons per kilo-bytes.
- commitment_fee_rate: Commitment transaction fee rate, in shannons per kilo-bytes.
- max_tlc_value_in_flight: The maximum total value of unconfirmed TLCs (Time Locked Contracts) that the channel initiator can accept in this channel.
- max_tlc_number_in_flight: The maximum number of unconfirmed TLCs that the channel initiator can accept in this channel.
- min_tlc_value: The minimum value of TLCs that the channel initiator can accept.
- to_self_delay: The delay time for the channel initiator to unlock the outputs from the commitment transaction, in EpochNumberWithFraction.
- funding_pubkey: The pubkey of the channel initiator, used for generating 2-2 multisig contracts.
- tlc_basepoint: The master key used to derive child keys required for tlcs, we will use the same method as lightning network to derive these keys, see [Secret Derivations] for more details.
- first_per_commitment_point:
- second_per_commitment_point:
- next_local_nonce: Used for generating partial signatures for unlocking 2-2 Schnorr multisig.
- channel_flags: Channel flags, currently only using one bit to indicate whether to broadcast this channel information on the P2P network.

### AcceptChannel

`AcceptChannel` is sent by the receiver of the channel to the initiator of the channel to accept the establishment of a payment channel.

```
table AcceptChannel {
    channel_id:                  Byte32,
    funding_amount:              Uint128,
    max_tlc_value_in_flight:     Uint128,
    max_tlc_number_in_flight:    Uint64,
    min_tlc_value:               Uint128,
    to_self_delay:               Uint64,
    funding_pubkey:              Byte33,
    tlc_basepoint:               Byte33,
    payment_basepoint:           Byte33,
    delayed_payment_basepoint:   Byte33,
    first_per_commitment_point:  Byte33,
    second_per_commitment_point: Byte33,
    next_local_nonce:            Byte66,
}
```

- channel_id: The ID of the channel, must match the channel_id in OpenChannel.
- funding_amount: The amount of assets the channel receiver wants to contribute, can be 0, indicating no contribution.
- max_tlc_value_in_flight: The maximum total value of unconfirmed TLCs that the channel receiver can accept in this channel.
- max_tlc_number_in_flight: The maximum number of unconfirmed TLCs that the channel receiver can accept in this channel.
- min_tlc_value: The minimum value of TLCs that the channel receiver can accept.
- to_self_delay: The delay time for the channel receiver to unlock the outputs from the commitment transaction, in EpochNumberWithFraction.
- funding_pubkey: The pubkey of the channel receiver, used for generating 2-2 multisig contracts.
- tlc_basepoint: See the description in `OpenChannel` message.
- first_per_commitment_point:
- second_per_commitment_point:
- next_local_nonce: Used for generating partial signatures for unlocking 2-2 Schnorr multisig.

### CommitmentSigned

After both parties establish the funding transaction and complete the signing of the commitment transaction in the [Transaction Collaboration](#Transaction-Collaboration) process, they will send CommitmentSigned messages to each other.

```
table CommitmentSigned {
    channel_id:        Byte32,
	partial_signature: Byte32,
    next_local_nonce:  Byte66,
}
```

The meaning of each field is as follows:

- partial_signature: The partial signature for unlocking the 2-2 Schnorr multisig.
- next_local_nonce: Used for generating the next commitment transaction partial signature.

### TxSignatures

After both parties have signed the commitment transaction and verified the correctness of each other's signatures, they need to send TxSignatures messages to each other to complete the signing of the funding transaction.

```
table TxSignatures {
    channel_id: Byte32,
    tx_hash:    Byte32,
    witnesses:  BytesVec,
}
```

Here, tx_hash is the hash of the corresponding funding transaction, and witnesses corresponds to the signed witnesses of all inputs of the contributor. If a party's contribution is 0 (i.e., no inputs), an empty witnesses message should also be sent to complete the message exchange.

In addition, in order to simplify the message interaction process, we defined that the party with the lesser amount of funding must send the
TxSignatures message first, in the case of the same amount, the one with the smaller funding_pubkey must send the TxSignatures message first. This avoids deadlocks caused by both parties waiting for the other party's TxSignatures message at the same time.

### ChannelReady

After completing the signing and broadcasting the funding transaction, both parties send ChannelReady messages to each other to indicate the channel is ready.

```
table ChannelReady {
    channel_id: Byte32,
}
```

## Transaction Collaboration

In the fiber network, the channel initiator begins the transaction construction protocol using the TxUpdate message. The responder replies with either TxUpdate or TxComplete messages. The transaction construction process is completed when both nodes have sent and received consecutive TxComplete messages.

Here is the `Dual Funding` example, A initially funds part of the channel (2 inputs), then B adds their contribution (1 input). A replies with TxComplete, and B responds with TxComplete, completing the transaction construction process.

```
    +-------+                       +-------+
    |       |--(1)- tx_update   --->|       |
    |       |<-(2)- tx_update   ----|       |
    |   A   |--(3)- tx_complete --->|   B   |
    |       |<-(4)- tx_complete ----|       |
    +-------+                       +-------+
```

Since CKB's transaction structure is more complex than Bitcoin's, the message structure is simplified compared to BOLT 02 interactive transaction construction. We use the full CKB transaction structure for transaction collaboration, without defining separate messages like tx_add_input, tx_add_output, tx_remove_input, and tx_remove_output. Nodes are required to parse the inputs of the transactions and do not need to provide previous tx in the messages. The specific message definitions are as follows:

### TxUpdate

The TxUpdate message is used by the channel initiator to start the transaction construction protocol.

```
table TxUpdate {
    channel_id: Byte32,
    tx:         Transaction,
}
```

Both parties must save the funding tx field of the previous message to compare it with the latest message field. They must also mark which inputs/outputs belong to their side. If a TxUpdate message from the other party removes or modifies inputs/outputs from their side, it is considered an illegal operation, and the entire process should be terminated.

### TxComplete

After successfully exchanging TxComplete messages, both parties should have constructed the transaction and move to the next part of the protocol to exchange signatures for the commitment transaction.


```
table TxComplete {
    channel_id: Byte32,
}
```

### TxAbort

During the transaction collaboration process, a node can send a TxAbort message to terminate the collaboration before sending the TxSignatures message.

```
table TxAbort {
    channel_id: Byte32,
    message:    Bytes,
}
```

### TxInitRbf

After broadcasting the funding transaction, if the channel initiator finds that the fee is insufficient, they can send a TxInitRbf message to request the other party's cooperation in performing RBF (Replace-By-Fee) operation to increase the fee and rebroadcast the funding transaction.

```
table TxInitRBF {
    channel_id: Byte32,
    fee_rate:   Uint64,
}
```

### TxAckRbf

Upon receiving a TxInitRbf message, the channel responder can send a TxAckRbf message to agree to the RBF operation.

```
table TxAckRBF {
    channel_id: Byte32,
}
```

After receiving the TxAckRbf message from the other party, the channel initiator can restart the process of funding transaction collaboration with the new fee rate. It should be noted that the new funding transaction must have overlapping inputs with the previous funding transaction to ensure it meets the RBF rules.

## Channel Closing

Nodes can negotiate to close a channel mutually, unlike a unilateral close, which allows nodes to immediately obtain funds. The process of closing a channel is as follows:

```
    +-------+                             +-------+
    |       |--(1)- shutdown           -->|       |
    |       |<-(2)- shutdown           ---|       |
    |   A   | <complete all pending TLCs> |   B   |
    |       |<-(3)- closing_signed     ---|       |
    |       |--(4)- closing_signed     -->|       |
    +-------+                             +-------+
```

### Shutdown

Any node can send a Shutdown message to request the closure of the channel.

```
table Shutdown {
    channel_id:   Byte32,
    close_script: Script,
    fee_rate:     Uint64,
}
```

The close_script specifies the lock script to which the assets will be sent when the channel is closed.

### ClosingSigned

After completing all pending Time Locked Contracts (TLCs) in the channel, either party can send a ClosingSigned message to sign the close transaction.

```
table ClosingSigned {
    channel_id:         Byte32,
    partial_signature:  Byte32,
}
```

If the receiver verified the correctness of the signature, they will respond with a ClosingSigned message, completing the channel closure.

## Payment Operation

After establishing a channel, nodes can perform payment operations by sending AddTlc messages for payment requests and then updating the commitment transactions through CommitmentSigned and RevokeAndAck messages. Here is an example process:

```
    +-------+                               +-------+
    |       |--(1)---- add_tlc         ---->|       |
    |       |                               |       |
    |       |--(2)---- commitment_signed -->|       |
    |       |<-(3)---- revoke_and_ack  -----|       |
    |       |                               |       |
    |       |<-(4)---- commitment_signed ---|       |
    |       |--(5)---- revoke_and_ack  ---->|       |
    |       |                               |       |
    |   A   |                               |   B   |
    |       |                               |       |
    |       |<-(6)---- remove_tlc      -----|       |
    |       |                               |       |
    |       |<-(7)---- commitment_signed ---|       |
    |       |--(8)---- revoke_and_ack  ---->|       |
    |       |                               |       |
    |       |--(9)---- commitment_signed -->|       |
    |       |<-(10)---- revoke_and_ack  ----|       |
    +-------+                               +-------+
```

### AddTlc

Either node can send an AddTlc message to the other party to initiate a payment operation. This message can also be used to forward payment requests from other nodes.

```
table AddTlc {
    channel_id:     Byte32,
    tlc_id:         Uint64,
    amount:         Uint128,
    payment_hash:   Byte32,
    expiry:         Uint64,
}
```

- channel_id: ID of the channel.
- tlc_id: ID of the TLC (Time Locked Contract), used to uniquely identify a TLC. The first TLC in the channel has an ID of 0, and subsequent IDs increment by 1.
- amount: Amount of assets requested for payment.
- payment_hash: Hash value used to identify the payment request for subsequent payment verification.
- expiry: Expiry time of the payment request, specified as an absolute timestamp. When forwarding a payment request, this field should be decremented appropriately.

## RevokeAndAck

Upon receiving the CommitmentSigned message and verifying the signature, the node may reveal the previous commitment transaction secret to the other party by sending a RevokeAndAck message.

```
table RevokeAndAck {
    channel_id:                 Byte32,
    per_commitment_secret:      Byte32,
    next_per_commitment_point:  Byte33,
    next_local_nonce:           Byte66,
}
```

- per_commitment_secret: Secret used to generate the revocation secret key for the previous commitment transaction.
- next_per_commitment_point: Point used to generate the next revocation public key.
- next_local_nonce: Used for generating the partial signature for the next commitment transaction.

Upon receiving the RevokeAndAck message, the node should update the remote commitment transaction.

## RemoveTlc

To simplify the implementation, only the recipient of the AddTkc message can remove the TLC.

```
table RemoveTlc {
    channel_id:         Byte32,
    tlc_id:             Uint64,
    reason:             RemoveTlcReason
}

union RemoveTlcReason {
    RemoveTlcFulfill,
    RemoveTlcFail,
}

struct RemoveTlcFulfill {
    payment_preimage:   Byte32,
}

struct RemoveTlcFail {
    error_code:         Uint32,
}
```

- channel_id: ID of the channel.
- tlc_id: ID of the TLC being removed.
- reason: Reason for removing the TLC, which can be either RemoveTlcFulfill or RemoveTlcFail.
    - RemoveTlcFulfill: Contains the payment_preimage required to fulfill the payment.
    - RemoveTlcFail: Contains an error_code indicating the reason for failure.

[BOLT 02]: https://github.com/lightning/bolts/blob/master/02-peer-protocol.md#channel-establishment-v2
[Molecule]: https://github.com/nervosnetwork/molecule
[Secret Derivations]: https://github.com/lnbook/lnbook/blob/54453c7b1cf82186614ab929b80876ba18bdc65d/07_payment_channels.asciidoc#revocation_sidebar


================================================
File: docs/specs/payment-invoice.md
================================================
# Fiber Network Invoice Protocol

## Overall Design

Fiber network invoice will be generated and parsed by Fiber Node, we referred to the design of [BOLT 11](https://github.com/lightning/bolts/blob/master/11-payment-encoding.md), and made some adjustments from an implementation perspective.

- The invoice is encode/decoded base on [molecule](https://github.com/nervosnetwork/molecule), which is widely used in the CKB projects.
- Instead of using `bech32`, we switch to `bech32m`.
- The interface and usage is similar to [lightning-invoice](https://github.com/lightningdevkit/rust-lightning/tree/main/lightning-invoice/src) as possible, but not compatible with lightning invoice, any cross-chain compatibility needs will be handled through the hub in FNN.

## Human-readable part

The human-readable part contains these two most important fields:

1. `prefix`: [mandatory] Specify the currency and network of payment
    - `fibb` for the CKB mainnet,  `fibb` means `fiber bytes`, since in CKB ecosystem 1 CKB equals 1 Byte.
    - `fibt` for the CKB testnet
    - `fibd` for the CKB dev
2. `amount`: [optional] An optional number in that currency.
    - A standalone number, means the amount of CKB or UDT, for CKB it will be in unit of `shannon`, 1 CKB = 10^8 shannon
    - An empty value for this field means the amount of payment is not specified, which maybe used in the scenario of donation.

## Encoding and Decoding

With `molecule`, the data part can be easily converted to bytes. Considering that the bytes generated by molecule are not optimized for space and may contain consecutive zeros when certain fields are empty, the result from `bechm32` encoding is relatively long. We use [arcode-rs](https://github.com/cgbur/arcode-rs) to compress the bytes losslessly before `bechm32` encoding, resulting in a length reduction of almost half:

`data = compressed(data part molecule bytes) + signature`

`encode(&hrp, data, Variant::Bech32m)`

For decoding, we simply perform the inverse decompression operation.

The `signature` field: [optional] with type of `[u8; 65]` = 520 bits

- The secp256k1 signature of the entire invoice, can be used to verify the integrity and correctness of the invoice, may also be used to imply the generator node of this invoice.
By default, this filed is none, the method to generate signature:
  - `message_hash = SHA256-hash (((human-readable part) → bytes) + (data bytes))`
       then sign it with `Secp256k1`
  - It may use a customized sign function: `Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key)`

## Data Part

The data part is designed to add non-mandatory fields easily, and it is very likely that new field will be added in the future:

1. `timestamp`: [mandatory] 128 bits
    - milliseconds since 1970
    - The time the invoice was generated
2. `payment_hash`: [mandatory] 256 bits
    - SHA256 payment_hash, could specified when creating a invoice, but we need to make sure `payment_hash` is the unique identifier of a invoice.
    - If creating a `HODL` invoice, a `preimage` parameter must be provided, and the `payment_hash` is generated using `blake2b_256(preimage)` when the invoice is created.
    - For `AMP invoices` (Atomic Multi-path Payments), the `payment_hash` is randomly generated.
3. `expiry`: [optional] 32 bits
    - `timestamp + expiry` is the expiration time of the invoice
    - Unit: seconds
4. `description`: [optional] variable length
    - A string of UTF-8 text to display payment information, such as "a cup of coffee"
5. `final htlc timeout`: [optional] 32 bits
    - Specifies the final htlc timeout, which may be longer because it may take more hops to reach CKB network
    - Unit: seconds
6. `fallback`: [optional] variable length
    - A CKB address used for fallback in case the invoice payment fails
7. `feature`: [optional] 32 bits
    - Feature flag to specify features supported by the payment
8. `payee_public_key`: [optional] 33 bytes
    - The public key of the payee
9. `udt_script`: [optional] variable length
    - The script specified for the UDT token
10. `hash_algorithm`: [optional] 1 byte
    - The hash algorithm used to generate the `payment_hash` from the preimage. When this is missing, the default hash algorithm ckb hash is used.
        - 0: ckb hash
        - 1: sha256


================================================
File: migrate/Cargo.lock
================================================
# This file is automatically @generated by Cargo.
# It is not intended for manual editing.
version = 3

[[package]]
name = "addr2line"
version = "0.24.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "dfbe277e56a376000877090da837660b4427aad530e3028d44e0bffe4f89a1c1"
dependencies = [
 "gimli",
]

[[package]]
name = "adler2"
version = "2.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "512761e0bb2578dd7380c6baaa0f4ce03e84f95e960231d1dec8bf4d7d6e2627"

[[package]]
name = "aead"
version = "0.5.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d122413f284cf2d62fb1b7db97e02edb8cda96d769b16e443a4f6195e35662b0"
dependencies = [
 "crypto-common",
 "generic-array",
]

[[package]]
name = "ahash"
version = "0.7.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "891477e0c6a8957309ee5c45a6368af3ae14bb510732d2684ffa19af310920f9"
dependencies = [
 "getrandom 0.2.15",
 "once_cell",
 "version_check",
]

[[package]]
name = "aho-corasick"
version = "1.1.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8e60d3430d3a69478ad0993f19238d2df97c507009a52b3c10addcd7f6bcb916"
dependencies = [
 "memchr",
]

[[package]]
name = "android-tzdata"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e999941b234f3131b00bc13c22d06e8c5ff726d1b6318ac7eb276997bbb4fef0"

[[package]]
name = "android_system_properties"
version = "0.1.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "819e7219dbd41043ac279b19830f2efc897156490d7fd6ea916720117ee66311"
dependencies = [
 "libc",
]

[[package]]
name = "anstream"
version = "0.6.18"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8acc5369981196006228e28809f761875c0327210a891e941f4c683b3a99529b"
dependencies = [
 "anstyle",
 "anstyle-parse",
 "anstyle-query",
 "anstyle-wincon",
 "colorchoice",
 "is_terminal_polyfill",
 "utf8parse",
]

[[package]]
name = "anstyle"
version = "1.0.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "55cc3b69f167a1ef2e161439aa98aed94e6028e5f9a59be9a6ffb47aef1651f9"

[[package]]
name = "anstyle-parse"
version = "0.2.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3b2d16507662817a6a20a9ea92df6652ee4f94f914589377d69f3b21bc5798a9"
dependencies = [
 "utf8parse",
]

[[package]]
name = "anstyle-query"
version = "1.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "79947af37f4177cfead1110013d678905c37501914fba0efea834c3fe9a8d60c"
dependencies = [
 "windows-sys 0.59.0",
]

[[package]]
name = "anstyle-wincon"
version = "3.0.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ca3534e77181a9cc07539ad51f2141fe32f6c3ffd4df76db8ad92346b003ae4e"
dependencies = [
 "anstyle",
 "once_cell",
 "windows-sys 0.59.0",
]

[[package]]
name = "anyhow"
version = "1.0.95"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "34ac096ce696dc2fcabef30516bb13c0a68a11d30131d3df6f04711467681b04"

[[package]]
name = "arcode"
version = "0.2.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7cf9ecf0f36fbecd0fd1be1eaa0b25fc67051d9a2f6b25892e6e6ebb7db629cb"
dependencies = [
 "bitbit",
 "fenwick",
]

[[package]]
name = "arrayvec"
version = "0.7.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7c02d123df017efcdfbd739ef81735b36c5ba83ec3c59c80a9d7ecc718f92e50"

[[package]]
name = "async-stream"
version = "0.3.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0b5a71a6f37880a80d1d7f19efd781e4b5de42c88f0722cc13bcb6cc2cfe8476"
dependencies = [
 "async-stream-impl",
 "futures-core",
 "pin-project-lite",
]

[[package]]
name = "async-stream-impl"
version = "0.3.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c7c24de15d275a1ecfd47a380fb4d5ec9bfe0933f309ed5e705b775596a3574d"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "async-trait"
version = "0.1.85"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3f934833b4b7233644e5848f235df3f57ed8c80f1528a26c3dfa13d2147fa056"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "attohttpc"
version = "0.24.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8d9a9bf8b79a749ee0b911b91b671cc2b6c670bdbc7e3dfd537576ddc94bb2a2"
dependencies = [
 "http 0.2.12",
 "log",
 "url",
]

[[package]]
name = "autocfg"
version = "1.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ace50bade8e6234aa140d9a2f552bbee1db4d353f69b8217bc503490fc1a9f26"

[[package]]
name = "axum"
version = "0.5.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "acee9fd5073ab6b045a275b3e709c163dd36c90685219cb21804a147b58dba43"
dependencies = [
 "async-trait",
 "axum-core 0.2.9",
 "bitflags 1.3.2",
 "bytes",
 "futures-util",
 "http 0.2.12",
 "http-body",
 "hyper",
 "itoa",
 "matchit 0.5.0",
 "memchr",
 "mime",
 "percent-encoding",
 "pin-project-lite",
 "serde",
 "sync_wrapper",
 "tokio",
 "tower",
 "tower-http",
 "tower-layer",
 "tower-service",
]

[[package]]
name = "axum"
version = "0.6.20"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3b829e4e32b91e643de6eafe82b1d90675f5874230191a4ffbc1b336dec4d6bf"
dependencies = [
 "async-trait",
 "axum-core 0.3.4",
 "bitflags 1.3.2",
 "bytes",
 "futures-util",
 "http 0.2.12",
 "http-body",
 "hyper",
 "itoa",
 "matchit 0.7.3",
 "memchr",
 "mime",
 "percent-encoding",
 "pin-project-lite",
 "rustversion",
 "serde",
 "sync_wrapper",
 "tower",
 "tower-layer",
 "tower-service",
]

[[package]]
name = "axum-core"
version = "0.2.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "37e5939e02c56fecd5c017c37df4238c0a839fa76b7f97acdd7efb804fd181cc"
dependencies = [
 "async-trait",
 "bytes",
 "futures-util",
 "http 0.2.12",
 "http-body",
 "mime",
 "tower-layer",
 "tower-service",
]

[[package]]
name = "axum-core"
version = "0.3.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "759fa577a247914fd3f7f76d62972792636412fbfd634cd452f6a385a74d2d2c"
dependencies = [
 "async-trait",
 "bytes",
 "futures-util",
 "http 0.2.12",
 "http-body",
 "mime",
 "rustversion",
 "tower-layer",
 "tower-service",
]

[[package]]
name = "backtrace"
version = "0.3.74"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8d82cb332cdfaed17ae235a638438ac4d4839913cc2af585c3c6746e8f8bee1a"
dependencies = [
 "addr2line",
 "cfg-if 1.0.0",
 "libc",
 "miniz_oxide",
 "object",
 "rustc-demangle",
 "windows-targets 0.52.6",
]

[[package]]
name = "base16ct"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4c7f02d4ea65f2c1853089ffd8d2787bdbc63de2f0d29dedbcf8ccdfa0ccd4cf"

[[package]]
name = "base64"
version = "0.13.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9e1b586273c5702936fe7b7d6896644d8be71e6314cfe09d3167c95f712589e8"

[[package]]
name = "base64"
version = "0.21.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9d297deb1925b89f2ccc13d7635fa0714f12c87adce1c75356b39ca9b7178567"

[[package]]
name = "base64"
version = "0.22.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "72b3254f16251a8381aa12e40e3c4d2f0199f8c6508fbecb9d91f575e0fbb8c6"

[[package]]
name = "bech32"
version = "0.8.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cf9ff0bbfd639f15c74af777d81383cf53efb7c93613f6cab67c6c11e05bbf8b"

[[package]]
name = "bech32"
version = "0.9.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d86b93f97252c47b41663388e6d155714a9d0c398b99f1005cbc5f978b29f445"

[[package]]
name = "beef"
version = "0.5.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3a8241f3ebb85c056b509d4327ad0358fbbba6ffb340bf388f26350aeda225b1"
dependencies = [
 "serde",
]

[[package]]
name = "bincode"
version = "1.3.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b1f45e9417d87227c7a56d22e471c6206462cba514c7590c09aff4cf6d1ddcad"
dependencies = [
 "serde",
]

[[package]]
name = "bindgen"
version = "0.68.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "726e4313eb6ec35d2730258ad4e15b547ee75d6afaa1361a922e78e59b7d8078"
dependencies = [
 "bitflags 2.7.0",
 "cexpr",
 "clang-sys",
 "lazy_static",
 "lazycell",
 "log",
 "peeking_take_while",
 "prettyplease",
 "proc-macro2",
 "quote",
 "regex",
 "rustc-hash",
 "shlex",
 "syn 2.0.96",
 "which",
]

[[package]]
name = "bit-vec"
version = "0.6.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "349f9b6a179ed607305526ca489b34ad0a41aed5f7980fa90eb03160b69598fb"

[[package]]
name = "bitbit"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "341ee439c53e593fa7de26dead9515601539b6cf9a53e3368c1405471e3ea322"

[[package]]
name = "bitcoin"
version = "0.30.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1945a5048598e4189e239d3f809b19bdad4845c4b2ba400d304d2dcf26d2c462"
dependencies = [
 "bech32 0.9.1",
 "bitcoin-private",
 "bitcoin_hashes 0.12.0",
 "hex_lit",
 "secp256k1 0.27.0",
 "serde",
]

[[package]]
name = "bitcoin-io"
version = "0.1.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0b47c4ab7a93edb0c7198c5535ed9b52b63095f4e9b45279c6736cec4b856baf"

[[package]]
name = "bitcoin-private"
version = "0.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "73290177011694f38ec25e165d0387ab7ea749a4b81cd4c80dae5988229f7a57"

[[package]]
name = "bitcoin_hashes"
version = "0.12.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5d7066118b13d4b20b23645932dfb3a81ce7e29f95726c2036fa33cd7b092501"
dependencies = [
 "bitcoin-private",
 "serde",
]

[[package]]
name = "bitcoin_hashes"
version = "0.14.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bb18c03d0db0247e147a21a6faafd5a7eb851c743db062de72018b6b7e8e4d16"
dependencies = [
 "bitcoin-io",
 "hex-conservative 0.2.1",
]

[[package]]
name = "bitflags"
version = "1.3.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bef38d45163c2f1dde094a7dfd33ccf595c92905c8f8f4fdc18d06fb1037718a"

[[package]]
name = "bitflags"
version = "2.7.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1be3f42a67d6d345ecd59f675f3f012d6974981560836e938c22b424b85ce1be"
dependencies = [
 "serde",
]

[[package]]
name = "blake2b-ref"
version = "0.3.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "294d17c72e0ba59fad763caa112368d0672083779cdebbb97164f4bb4c1e339a"

[[package]]
name = "blake2b-rs"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a89a8565807f21b913288968e391819e7f9b2f0f46c7b89549c051cccf3a2771"
dependencies = [
 "cc",
 "cty",
]

[[package]]
name = "block-buffer"
version = "0.9.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4152116fd6e9dadb291ae18fc1ec3575ed6d84c29642d97890f4b4a3417297e4"
dependencies = [
 "generic-array",
]

[[package]]
name = "block-buffer"
version = "0.10.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3078c7629b62d3f0439517fa394996acacc5cbc91c5a20d8c658e77abd503a71"
dependencies = [
 "generic-array",
]

[[package]]
name = "bon"
version = "2.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "97493a391b4b18ee918675fb8663e53646fd09321c58b46afa04e8ce2499c869"
dependencies = [
 "bon-macros",
 "rustversion",
]

[[package]]
name = "bon-macros"
version = "2.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2a2af3eac944c12cdf4423eab70d310da0a8e5851a18ffb192c0a5e3f7ae1663"
dependencies = [
 "darling",
 "ident_case",
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "bs58"
version = "0.5.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bf88ba1141d185c399bee5288d850d63b8369520c1eafc32a0430b5b6c287bf4"
dependencies = [
 "tinyvec",
]

[[package]]
name = "bumpalo"
version = "3.16.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "79296716171880943b8470b5f8d03aa55eb2e645a4874bdbb28adb49162e012c"

[[package]]
name = "byteorder"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1fd0f2584146f6f2ef48085050886acf353beff7305ebd1ae69500e27c67f64b"

[[package]]
name = "bytes"
version = "1.9.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "325918d6fe32f23b19878fe4b34794ae41fc19ddbe53b10571a4874d44ffd39b"
dependencies = [
 "serde",
]

[[package]]
name = "cacache"
version = "12.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "142316461ed3a3dfcba10417317472da5bfd0461e4d276bf7c07b330766d9490"
dependencies = [
 "digest 0.10.7",
 "either",
 "futures",
 "hex",
 "libc",
 "memmap2",
 "miette",
 "reflink-copy",
 "serde",
 "serde_derive",
 "serde_json",
 "sha1",
 "sha2",
 "ssri",
 "tempfile",
 "thiserror 1.0.69",
 "tokio",
 "tokio-stream",
 "walkdir",
]

[[package]]
name = "cc"
version = "1.2.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c8293772165d9345bdaaa39b45b2109591e63fe5e6fbc23c6ff930a048aa310b"
dependencies = [
 "jobserver",
 "libc",
 "shlex",
]

[[package]]
name = "cexpr"
version = "0.6.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6fac387a98bb7c37292057cffc56d62ecb629900026402633ae9160df93a8766"
dependencies = [
 "nom",
]

[[package]]
name = "cfg-if"
version = "0.1.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4785bdd1c96b2a846b2bd7cc02e86b6b3dbf14e7e53446c4f54c92a361040822"

[[package]]
name = "cfg-if"
version = "1.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "baf1de4339761588bc0619e3cbc0120ee582ebb74b53b4efbf79117bd2da40fd"

[[package]]
name = "chacha20"
version = "0.9.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c3613f74bd2eac03dad61bd53dbe620703d4371614fe0bc3b9f04dd36fe4e818"
dependencies = [
 "cfg-if 1.0.0",
 "cipher",
 "cpufeatures",
]

[[package]]
name = "chacha20poly1305"
version = "0.10.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "10cd79432192d1c0f4e1a0fef9527696cc039165d729fb41b3f4f4f354c2dc35"
dependencies = [
 "aead",
 "chacha20",
 "cipher",
 "poly1305",
 "zeroize",
]

[[package]]
name = "chrono"
version = "0.4.39"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7e36cc9d416881d2e24f9a963be5fb1cd90966419ac844274161d10488b3e825"
dependencies = [
 "android-tzdata",
 "iana-time-zone",
 "num-traits",
 "serde",
 "windows-targets 0.52.6",
]

[[package]]
name = "cipher"
version = "0.4.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "773f3b9af64447d2ce9850330c473515014aa235e6a783b02db81ff39e4a3dad"
dependencies = [
 "crypto-common",
 "inout",
 "zeroize",
]

[[package]]
name = "ckb-chain-spec"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "38fa470ac81179a066b3dd3e0d56e8fb9988aaddf5c2ae921cbc2ee6c60bbc56"
dependencies = [
 "cacache",
 "ckb-constant",
 "ckb-crypto",
 "ckb-dao-utils",
 "ckb-error",
 "ckb-hash 0.118.0",
 "ckb-jsonrpc-types",
 "ckb-logger",
 "ckb-pow",
 "ckb-rational",
 "ckb-resource",
 "ckb-traits",
 "ckb-types",
 "serde",
 "toml",
]

[[package]]
name = "ckb-channel"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "081350579a7d6cee3c7d3b82b3667860517e785269f8cd72b27ae472775d9c04"
dependencies = [
 "crossbeam-channel",
]

[[package]]
name = "ckb-constant"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fce0d46bfe7d555b60e7e1b589643bcd2d6a40e4cc0a04c5e9412dbb30c1f206"

[[package]]
name = "ckb-crypto"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d2b268e177104ec7089656562adac06dd8209298873cb806fff76c1d3df16566"
dependencies = [
 "ckb-fixed-hash",
 "faster-hex",
 "lazy_static",
 "rand 0.8.5",
 "secp256k1 0.29.1",
 "thiserror 1.0.69",
]

[[package]]
name = "ckb-dao-utils"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1df36dfa384153423e777f3f40beeb5fbb42d5ba223d411d7850bf72e190428e"
dependencies = [
 "byteorder",
 "ckb-error",
 "ckb-types",
]

[[package]]
name = "ckb-error"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e6726194aed3b38485270e64d3823b3fb5e9d7ce6ea2ea117106f97619272de5"
dependencies = [
 "anyhow",
 "ckb-occupied-capacity",
 "derive_more",
 "thiserror 1.0.69",
]

[[package]]
name = "ckb-fixed-hash"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e497f03441f4622bc6d1d44db95ff47c37bec03ef2c8132ca19ac8005c70995f"
dependencies = [
 "ckb-fixed-hash-core",
 "ckb-fixed-hash-macros",
]

[[package]]
name = "ckb-fixed-hash-core"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bb5f80c82b9b0498272f085b86824cfe0b76a2c04ee653a91f9ff362fd9b6f6c"
dependencies = [
 "ckb_schemars",
 "faster-hex",
 "serde",
 "thiserror 1.0.69",
]

[[package]]
name = "ckb-fixed-hash-macros"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "00ede2291016d17450e9d117fac6fb515629779e31ea452d5146a117cd12bf0f"
dependencies = [
 "ckb-fixed-hash-core",
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "ckb-gen-types"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e0a7891f62f4ae4f018bfde91a46178c78491a1dfee740a20b994003a23f10af"
dependencies = [
 "cfg-if 1.0.0",
 "ckb-error",
 "ckb-fixed-hash",
 "ckb-hash 0.118.0",
 "ckb-occupied-capacity",
 "molecule",
 "numext-fixed-uint",
]

[[package]]
name = "ckb-hash"
version = "0.115.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "37a80b274a236255963e7a9fe73eea35623a46de7f2d8548278f024b5eb0a7c7"
dependencies = [
 "blake2b-ref",
 "blake2b-rs",
]

[[package]]
name = "ckb-hash"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d96b7aec74956ae5e79d0fc68e5903dc2b133c2c64644514485bbc9feb5367eb"
dependencies = [
 "blake2b-ref",
 "blake2b-rs",
]

[[package]]
name = "ckb-jsonrpc-types"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "44e622a66404770b52da9dfbc9b994f2b711ea2368ef23cc9b1c96ca38491ecf"
dependencies = [
 "ckb-types",
 "ckb_schemars",
 "faster-hex",
 "serde",
 "serde_json",
]

[[package]]
name = "ckb-librocksdb-sys"
version = "8.5.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2e68e0993f54ba0d21152419a0668caa92adc928b5a9b01e45871ec055a31ce2"
dependencies = [
 "bindgen",
 "cc",
 "glob",
 "libc",
 "pkg-config",
 "rust-ini",
]

[[package]]
name = "ckb-logger"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c76af0252cd14e57fafac7c67282eedb9c7bbf40a529ed4eb1bb85067b767e7a"
dependencies = [
 "log",
]

[[package]]
name = "ckb-merkle-mountain-range"
version = "0.5.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "56ccb671c5921be8a84686e6212ca184cb1d7c51cadcdbfcbd1cc3f042f5dfb8"
dependencies = [
 "cfg-if 1.0.0",
]

[[package]]
name = "ckb-mock-tx-types"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fd785084e7c3903cb49f0d2abb12c56880827cae14723cd4fed1bf3fa26a74db"
dependencies = [
 "ckb-jsonrpc-types",
 "ckb-traits",
 "ckb-types",
 "serde",
]

[[package]]
name = "ckb-occupied-capacity"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5e01910f17fcdb1850df67a5b340bbb98d18948eacb476fc85d9a7699294d7ab"
dependencies = [
 "ckb-occupied-capacity-core",
 "ckb-occupied-capacity-macros",
]

[[package]]
name = "ckb-occupied-capacity-core"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "21ead5905cedba4acf082f88723c8f42a508bd28fd9c00e1dbf170049ef778b4"
dependencies = [
 "serde",
]

[[package]]
name = "ckb-occupied-capacity-macros"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "893198354933ba8fa0a1d99c013c819a295f6ae30b1af89fc14e0b62d7afa024"
dependencies = [
 "ckb-occupied-capacity-core",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "ckb-pow"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "069c3db99adb9d350d186de8e02a43e77dff7be2a8b9b7cf61ba80a280e2dd00"
dependencies = [
 "byteorder",
 "ckb-hash 0.118.0",
 "ckb-types",
 "eaglesong",
 "log",
 "serde",
]

[[package]]
name = "ckb-rational"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7be813511d1c17a6bab8a7dcfbee6e086aa2bae3bb77cfd4a570abfb67af2c16"
dependencies = [
 "numext-fixed-uint",
 "serde",
]

[[package]]
name = "ckb-resource"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d1e74f9bc4039a4cf6d579dc8b444b3d76780e51aab94daccdd5e6e58d01cc32"
dependencies = [
 "ckb-system-scripts",
 "ckb-types",
 "includedir",
 "includedir_codegen",
 "phf",
 "serde",
 "walkdir",
]

[[package]]
name = "ckb-rocksdb"
version = "0.21.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "050f7c70a451b9606a5d4e1cf696fec2517e65c3bfcbefadb6b114cc0fa7673b"
dependencies = [
 "ckb-librocksdb-sys",
 "libc",
 "tempfile",
]

[[package]]
name = "ckb-script"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f6b92a1f4f059f4680b08817dfb739a40356dcf4798b3cb8ae1f1d67218eb0fb"
dependencies = [
 "byteorder",
 "ckb-chain-spec",
 "ckb-error",
 "ckb-hash 0.118.0",
 "ckb-logger",
 "ckb-traits",
 "ckb-types",
 "ckb-vm",
 "faster-hex",
 "serde",
 "tokio",
]

[[package]]
name = "ckb-sdk"
version = "3.4.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "75d816b57b37c49a99c715f07e120928d8139993523efec0b9e2faa94db7edce"
dependencies = [
 "anyhow",
 "bech32 0.8.1",
 "bitflags 1.3.2",
 "bytes",
 "ckb-chain-spec",
 "ckb-crypto",
 "ckb-dao-utils",
 "ckb-hash 0.118.0",
 "ckb-jsonrpc-types",
 "ckb-mock-tx-types",
 "ckb-resource",
 "ckb-script",
 "ckb-traits",
 "ckb-types",
 "dashmap 5.5.3",
 "derive-getters",
 "dyn-clone",
 "enum-repr-derive",
 "futures",
 "jsonrpc-core",
 "lazy_static",
 "log",
 "lru",
 "parking_lot",
 "reqwest",
 "secp256k1 0.29.1",
 "serde",
 "serde_derive",
 "serde_json",
 "sha3",
 "sparse-merkle-tree",
 "thiserror 1.0.69",
 "tokio",
 "tokio-util",
]

[[package]]
name = "ckb-system-scripts"
version = "0.5.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fa5c59063142de7a68cfad4449c6b3863563856219a2925dfb8c5f019ec2aa47"
dependencies = [
 "blake2b-rs",
 "faster-hex",
 "includedir",
 "includedir_codegen",
 "phf",
]

[[package]]
name = "ckb-traits"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b6500281355bbf7a235fb386b2883e8ffb8cb5bab8447bd86dd229148ec52704"
dependencies = [
 "ckb-types",
]

[[package]]
name = "ckb-types"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "88f4ef54b7665440d1984489c580e8d540888496d7b9ff8d57262ac583ff97a4"
dependencies = [
 "bit-vec",
 "bytes",
 "ckb-channel",
 "ckb-constant",
 "ckb-error",
 "ckb-fixed-hash",
 "ckb-gen-types",
 "ckb-hash 0.118.0",
 "ckb-merkle-mountain-range",
 "ckb-occupied-capacity",
 "ckb-rational",
 "derive_more",
 "golomb-coded-set",
 "merkle-cbt",
 "molecule",
 "numext-fixed-uint",
 "once_cell",
 "paste",
]

[[package]]
name = "ckb-vm"
version = "0.24.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ddff96029d3298cb630e95f29d4b9a93384e938a0b75758684aa8794b53bdd1a"
dependencies = [
 "byteorder",
 "bytes",
 "cc",
 "ckb-vm-definitions",
 "derive_more",
 "goblin 0.2.3",
 "goblin 0.4.0",
 "rand 0.7.3",
 "scroll",
 "serde",
]

[[package]]
name = "ckb-vm-definitions"
version = "0.24.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c280bf1d589d23ab0358f58601c2187fc6be86a131644583ef72ea96a0a13ddd"
dependencies = [
 "paste",
]

[[package]]
name = "ckb_schemars"
version = "0.8.19"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f21f99fca82a4eb8708e406e99246987b087ecc1e1babeece1a0b1d5238b1750"
dependencies = [
 "ckb_schemars_derive",
 "dyn-clone",
 "serde",
 "serde_json",
]

[[package]]
name = "ckb_schemars_derive"
version = "0.8.19"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "40c813b4fadbdd9f33b1cf02a1ddfa9537d955c8d2fbe150d1fc1684dbf78e73"
dependencies = [
 "proc-macro2",
 "quote",
 "serde_derive_internals",
 "syn 1.0.109",
]

[[package]]
name = "clang-sys"
version = "1.8.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0b023947811758c97c59bf9d1c188fd619ad4718dcaa767947df1cadb14f39f4"
dependencies = [
 "glob",
 "libc",
 "libloading",
]

[[package]]
name = "clap"
version = "4.5.26"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a8eb5e908ef3a6efbe1ed62520fb7287959888c88485abe072543190ecc66783"
dependencies = [
 "clap_builder",
 "clap_derive",
]

[[package]]
name = "clap-serde-derive"
version = "0.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c4b7d643cbdc3a4eb0b5db8b9844ab2002bc4be44c1244db5cd27df8e594c125"
dependencies = [
 "clap",
 "clap-serde-proc",
 "serde",
]

[[package]]
name = "clap-serde-proc"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f6725cfcf906f158cdad4ca9a2a426133b36a3f91b5da2b971f8b956823ef55e"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "clap_builder"
version = "4.5.26"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "96b01801b5fc6a0a232407abc821660c9c6d25a1cafc0d4f85f29fb8d9afc121"
dependencies = [
 "anstream",
 "anstyle",
 "clap_lex",
 "strsim",
]

[[package]]
name = "clap_derive"
version = "4.5.24"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "54b755194d6389280185988721fffba69495eed5ee9feeee9a599b53db80318c"
dependencies = [
 "heck 0.5.0",
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "clap_lex"
version = "0.7.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f46ad14479a25103f283c0f10005961cf086d8dc42205bb44c46ac563475dca6"

[[package]]
name = "colorchoice"
version = "1.0.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5b63caa9aa9397e2d9480a9b13673856c78d8ac123288526c37d7839f2a86990"

[[package]]
name = "console"
version = "0.15.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ea3c6ecd8059b57859df5c69830340ed3c41d30e3da0c1cbed90a96ac853041b"
dependencies = [
 "encode_unicode",
 "libc",
 "once_cell",
 "unicode-width 0.2.0",
 "windows-sys 0.59.0",
]

[[package]]
name = "const-random"
version = "0.1.18"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "87e00182fe74b066627d63b85fd550ac2998d4b0bd86bfed477a0ae4c7c71359"
dependencies = [
 "const-random-macro",
]

[[package]]
name = "const-random-macro"
version = "0.1.16"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f9d839f2a20b0aee515dc581a6172f2321f96cab76c1a38a4c584a194955390e"
dependencies = [
 "getrandom 0.2.15",
 "once_cell",
 "tiny-keccak",
]

[[package]]
name = "convert_case"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6245d59a3e82a7fc217c5828a6692dbc6dfb63a0c8c90495621f7b9d79704a0e"

[[package]]
name = "core-foundation"
version = "0.9.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "91e195e091a93c46f7102ec7818a2aa394e1e1771c3ab4825963fa03e45afb8f"
dependencies = [
 "core-foundation-sys",
 "libc",
]

[[package]]
name = "core-foundation-sys"
version = "0.8.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "773648b94d0e5d620f64f280777445740e61fe701025087ec8b57f45c791888b"

[[package]]
name = "cpufeatures"
version = "0.2.16"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "16b80225097f2e5ae4e7179dd2266824648f3e2f49d9134d584b76389d31c4c3"
dependencies = [
 "libc",
]

[[package]]
name = "crc32fast"
version = "1.4.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a97769d94ddab943e4510d138150169a2758b5ef3eb191a9ee688de3e23ef7b3"
dependencies = [
 "cfg-if 1.0.0",
]

[[package]]
name = "crossbeam-channel"
version = "0.5.14"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "06ba6d68e24814cb8de6bb986db8222d3a027d15872cabc0d18817bc3c0e4471"
dependencies = [
 "crossbeam-utils",
]

[[package]]
name = "crossbeam-utils"
version = "0.8.21"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d0a5c400df2834b80a4c3327b3aad3a4c4cd4de0629063962b03235697506a28"

[[package]]
name = "crunchy"
version = "0.2.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7a81dae078cea95a014a339291cec439d2f232ebe854a9d672b796c6afafa9b7"

[[package]]
name = "crypto-common"
version = "0.1.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1bfb12502f3fc46cca1bb51ac28df9d618d813cdc3d2f25b9fe775a34af26bb3"
dependencies = [
 "generic-array",
 "rand_core 0.6.4",
 "typenum",
]

[[package]]
name = "cty"
version = "0.2.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b365fabc795046672053e29c954733ec3b05e4be654ab130fe8f1f94d7051f35"

[[package]]
name = "curve25519-dalek"
version = "4.1.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "97fb8b7c4503de7d6ae7b42ab72a5a59857b4c937ec27a3d4539dba95b5ab2be"
dependencies = [
 "cfg-if 1.0.0",
 "cpufeatures",
 "curve25519-dalek-derive",
 "fiat-crypto",
 "rustc_version",
 "subtle",
 "zeroize",
]

[[package]]
name = "curve25519-dalek-derive"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f46882e17999c6cc590af592290432be3bce0428cb0d5f8b6715e4dc7b383eb3"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "darling"
version = "0.20.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6f63b86c8a8826a49b8c21f08a2d07338eec8d900540f8630dc76284be802989"
dependencies = [
 "darling_core",
 "darling_macro",
]

[[package]]
name = "darling_core"
version = "0.20.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "95133861a8032aaea082871032f5815eb9e98cef03fa916ab4500513994df9e5"
dependencies = [
 "fnv",
 "ident_case",
 "proc-macro2",
 "quote",
 "strsim",
 "syn 2.0.96",
]

[[package]]
name = "darling_macro"
version = "0.20.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d336a2a514f6ccccaa3e09b02d41d35330c07ddf03a62165fcec10bb561c7806"
dependencies = [
 "darling_core",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "dashmap"
version = "5.5.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "978747c1d849a7d2ee5e8adc0159961c48fb7e5db2f06af6723b80123bb53856"
dependencies = [
 "cfg-if 1.0.0",
 "hashbrown 0.14.5",
 "lock_api",
 "once_cell",
 "parking_lot_core",
]

[[package]]
name = "dashmap"
version = "6.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5041cc499144891f3790297212f32a74fb938e5136a14943f338ef9e0ae276cf"
dependencies = [
 "cfg-if 1.0.0",
 "crossbeam-utils",
 "hashbrown 0.14.5",
 "lock_api",
 "once_cell",
 "parking_lot_core",
]

[[package]]
name = "data-encoding"
version = "2.6.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e8566979429cf69b49a5c740c60791108e86440e8be149bbea4fe54d2c32d6e2"

[[package]]
name = "deranged"
version = "0.3.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b42b6fa04a440b495c8b04d0e71b707c585f83cb9cb28cf8cd0d976c315e31b4"
dependencies = [
 "powerfmt",
 "serde",
]

[[package]]
name = "derive-getters"
version = "0.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0122f262bf9c9a367829da84f808d9fb128c10ef283bbe7b0922a77cf07b2747"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "derive_more"
version = "0.99.18"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5f33878137e4dafd7fa914ad4e259e18a4e8e532b9617a2d0150262bf53abfce"
dependencies = [
 "convert_case",
 "proc-macro2",
 "quote",
 "rustc_version",
 "syn 2.0.96",
]

[[package]]
name = "digest"
version = "0.9.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d3dd60d1080a57a05ab032377049e0591415d2b31afd7028356dbf3cc6dcb066"
dependencies = [
 "generic-array",
]

[[package]]
name = "digest"
version = "0.10.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9ed9a281f7bc9b7576e61468ba615a66a5c8cfdff42420a70aa82701a3b1e292"
dependencies = [
 "block-buffer 0.10.4",
 "crypto-common",
 "subtle",
]

[[package]]
name = "displaydoc"
version = "0.2.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "97369cbbc041bc366949bc74d34658d6cda5621039731c6310521892a3a20ae0"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "dlv-list"
version = "0.5.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "442039f5147480ba31067cb00ada1adae6892028e40e45fc5de7b7df6dcc1b5f"
dependencies = [
 "const-random",
]

[[package]]
name = "dyn-clone"
version = "1.0.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0d6ef0072f8a535281e4876be788938b528e9a1d43900b82c2569af7da799125"

[[package]]
name = "eaglesong"
version = "0.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8d978bd5d343e8ab9b5c0fc8d93ff9c602fdc96616ffff9c05ac7a155419b824"

[[package]]
name = "either"
version = "1.13.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "60b1af1c220855b6ceac025d3f6ecdd2b7c4894bfe9cd9bda4fbb4bc7c0d4cf0"

[[package]]
name = "encode_unicode"
version = "1.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "34aa73646ffb006b8f5147f3dc182bd4bcb190227ce861fc4a4844bf8e3cb2c0"

[[package]]
name = "encoding_rs"
version = "0.8.35"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "75030f3c4f45dafd7586dd6780965a8c7e8e285a5ecb86713e63a79c5b2766f3"
dependencies = [
 "cfg-if 1.0.0",
]

[[package]]
name = "enum-repr-derive"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c6f2936062c28214e84685742fa4affc52a39d036e8a3dcf98034810e449ec95"
dependencies = [
 "proc-macro-error",
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "equivalent"
version = "1.0.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5443807d6dff69373d433ab9ef5378ad8df50ca6298caf15de6e52e24aaf54d5"

[[package]]
name = "errno"
version = "0.3.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "33d852cb9b869c2a9b3df2f71a3074817f01e1844f839a144f5fcef059a4eb5d"
dependencies = [
 "libc",
 "windows-sys 0.59.0",
]

[[package]]
name = "faster-hex"
version = "0.6.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "51e2ce894d53b295cf97b05685aa077950ff3e8541af83217fc720a6437169f8"

[[package]]
name = "fastrand"
version = "2.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "37909eebbb50d72f9059c3b6d82c0463f2ff062c9e95845c43a6c9c0355411be"

[[package]]
name = "fenwick"
version = "1.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5ad8c7269456fd609f700340399dca5fa160c4785c9623f87b6079e5a479f28b"

[[package]]
name = "fiat-crypto"
version = "0.2.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "28dea519a9695b9977216879a3ebfddf92f1c08c05d984f8996aecd6ecdc811d"

[[package]]
name = "fiber-sphinx"
version = "2.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5bf0842bceebcf3b9f660ab011f65b5ab79d5500ffdd22d509319501c6efd3fc"
dependencies = [
 "chacha20",
 "hmac",
 "secp256k1 0.28.2",
 "sha2",
 "thiserror 1.0.69",
]

[[package]]
name = "fixedbitset"
version = "0.4.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0ce7134b9999ecaf8bcd65542e436736ef32ddca1b3e06094cb6ec5755203b80"

[[package]]
name = "flate2"
version = "1.0.35"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c936bfdafb507ebbf50b8074c54fa31c5be9a1e7e5f467dd659697041407d07c"
dependencies = [
 "crc32fast",
 "miniz_oxide",
]

[[package]]
name = "fnn"
version = "0.2.0"
source = "git+https://github.com/nervosnetwork/fiber.git?tag=v0.2.0#087b087ecc3a4611c58a9b8f74ce871a9150b5e1"
dependencies = [
 "anyhow",
 "arcode",
 "bech32 0.8.1",
 "bincode",
 "bitcoin",
 "bitflags 2.7.0",
 "ckb-chain-spec",
 "ckb-gen-types",
 "ckb-hash 0.115.0",
 "ckb-jsonrpc-types",
 "ckb-resource",
 "ckb-rocksdb",
 "ckb-sdk",
 "ckb-types",
 "clap",
 "clap-serde-derive",
 "console",
 "fiber-sphinx",
 "futures",
 "git-version",
 "hex",
 "home",
 "indicatif",
 "jsonrpsee",
 "lightning-invoice",
 "lnd-grpc-tonic-client",
 "molecule",
 "musig2",
 "nom",
 "num_enum",
 "once_cell",
 "ractor 0.9.7",
 "rand 0.8.5",
 "regex",
 "secp256k1 0.28.2",
 "serde",
 "serde_json",
 "serde_with",
 "serde_yaml",
 "socket2",
 "strum",
 "tentacle",
 "thiserror 1.0.69",
 "tokio",
 "tokio-util",
 "tracing",
 "tracing-subscriber",
]

[[package]]
name = "fnn"
version = "0.2.1"
source = "git+https://github.com/nervosnetwork/fiber.git?tag=v0.2.1#82d282e134ce29ea589ada85226deb982fa6aa97"
dependencies = [
 "anyhow",
 "arcode",
 "bech32 0.8.1",
 "bincode",
 "bitcoin",
 "bitflags 2.7.0",
 "ckb-chain-spec",
 "ckb-gen-types",
 "ckb-hash 0.115.0",
 "ckb-jsonrpc-types",
 "ckb-resource",
 "ckb-rocksdb",
 "ckb-sdk",
 "ckb-types",
 "clap",
 "clap-serde-derive",
 "console",
 "fiber-sphinx",
 "futures",
 "git-version",
 "hex",
 "home",
 "indicatif",
 "jsonrpsee",
 "lightning-invoice",
 "lnd-grpc-tonic-client",
 "molecule",
 "musig2",
 "nom",
 "num_enum",
 "once_cell",
 "ractor 0.14.2",
 "rand 0.8.5",
 "regex",
 "secp256k1 0.28.2",
 "serde",
 "serde_json",
 "serde_with",
 "serde_yaml",
 "socket2",
 "strum",
 "tentacle",
 "thiserror 1.0.69",
 "tokio",
 "tokio-util",
 "tracing",
 "tracing-subscriber",
]

[[package]]
name = "fnn"
version = "0.2.1"
source = "git+https://github.com/nervosnetwork/fiber.git?tag=v0.3.0-rc1#18e882feb428b9f540a437a99171230d1fbd21b1"
dependencies = [
 "anyhow",
 "arcode",
 "bech32 0.8.1",
 "bincode",
 "bitcoin",
 "bitflags 2.7.0",
 "ckb-chain-spec",
 "ckb-gen-types",
 "ckb-hash 0.115.0",
 "ckb-jsonrpc-types",
 "ckb-resource",
 "ckb-rocksdb",
 "ckb-sdk",
 "ckb-types",
 "clap",
 "clap-serde-derive",
 "console",
 "fiber-sphinx",
 "futures",
 "git-version",
 "hex",
 "home",
 "indicatif",
 "jsonrpsee",
 "lightning-invoice",
 "lnd-grpc-tonic-client",
 "molecule",
 "musig2",
 "nom",
 "num_enum",
 "once_cell",
 "ractor 0.14.2",
 "rand 0.8.5",
 "regex",
 "secp256k1 0.28.2",
 "serde",
 "serde_json",
 "serde_with",
 "serde_yaml",
 "socket2",
 "strum",
 "tentacle",
 "thiserror 1.0.69",
 "tokio",
 "tokio-util",
 "tracing",
 "tracing-subscriber",
]

[[package]]
name = "fnn"
version = "0.3.1"
dependencies = [
 "anyhow",
 "arcode",
 "bech32 0.8.1",
 "bincode",
 "bitcoin",
 "bitflags 2.7.0",
 "ckb-chain-spec",
 "ckb-gen-types",
 "ckb-hash 0.115.0",
 "ckb-jsonrpc-types",
 "ckb-resource",
 "ckb-rocksdb",
 "ckb-sdk",
 "ckb-types",
 "clap",
 "clap-serde-derive",
 "console",
 "fiber-sphinx",
 "futures",
 "git-version",
 "hex",
 "home",
 "indicatif",
 "jsonrpsee",
 "lightning-invoice",
 "lnd-grpc-tonic-client",
 "molecule",
 "musig2",
 "nom",
 "num_enum",
 "once_cell",
 "ractor 0.14.2",
 "rand 0.8.5",
 "regex",
 "secp256k1 0.28.2",
 "serde",
 "serde_json",
 "serde_with",
 "serde_yaml",
 "socket2",
 "strum",
 "tentacle",
 "thiserror 1.0.69",
 "tokio",
 "tokio-util",
 "tracing",
 "tracing-subscriber",
]

[[package]]
name = "fnn"
version = "0.3.1"
source = "git+https://github.com/nervosnetwork/fiber.git?tag=v0.3.1#d0f0ebd74b5fda3c329b3b89530dcc368cdaf10a"
dependencies = [
 "anyhow",
 "arcode",
 "bech32 0.8.1",
 "bincode",
 "bitcoin",
 "bitflags 2.7.0",
 "ckb-chain-spec",
 "ckb-gen-types",
 "ckb-hash 0.115.0",
 "ckb-jsonrpc-types",
 "ckb-resource",
 "ckb-rocksdb",
 "ckb-sdk",
 "ckb-types",
 "clap",
 "clap-serde-derive",
 "console",
 "fiber-sphinx",
 "futures",
 "git-version",
 "hex",
 "home",
 "indicatif",
 "jsonrpsee",
 "lightning-invoice",
 "lnd-grpc-tonic-client",
 "molecule",
 "musig2",
 "nom",
 "num_enum",
 "once_cell",
 "ractor 0.14.2",
 "rand 0.8.5",
 "regex",
 "secp256k1 0.28.2",
 "serde",
 "serde_json",
 "serde_with",
 "serde_yaml",
 "socket2",
 "strum",
 "tentacle",
 "thiserror 1.0.69",
 "tokio",
 "tokio-util",
 "tracing",
 "tracing-subscriber",
]

[[package]]
name = "fnn"
version = "0.3.1"
source = "git+https://github.com/chenyukang/fiber.git?branch=yukang-fix-480-keep-fail-tlc#6eb9d269517cb592f9f0526293d51a178c9d4cc0"
dependencies = [
 "anyhow",
 "arcode",
 "bech32 0.8.1",
 "bincode",
 "bitcoin",
 "bitflags 2.7.0",
 "ckb-chain-spec",
 "ckb-gen-types",
 "ckb-hash 0.115.0",
 "ckb-jsonrpc-types",
 "ckb-resource",
 "ckb-rocksdb",
 "ckb-sdk",
 "ckb-types",
 "clap",
 "clap-serde-derive",
 "console",
 "fiber-sphinx",
 "futures",
 "git-version",
 "hex",
 "home",
 "indicatif",
 "jsonrpsee",
 "lightning-invoice",
 "lnd-grpc-tonic-client",
 "molecule",
 "musig2",
 "nom",
 "num_enum",
 "once_cell",
 "ractor 0.14.2",
 "rand 0.8.5",
 "regex",
 "secp256k1 0.28.2",
 "serde",
 "serde_json",
 "serde_with",
 "serde_yaml",
 "socket2",
 "strum",
 "tentacle",
 "thiserror 1.0.69",
 "tokio",
 "tokio-util",
 "tracing",
 "tracing-subscriber",
]

[[package]]
name = "fnn-migrate"
version = "0.3.0"
dependencies = [
 "bincode",
 "ckb-rocksdb",
 "clap",
 "console",
 "fnn 0.2.0",
 "fnn 0.2.1 (git+https://github.com/nervosnetwork/fiber.git?tag=v0.2.1)",
 "fnn 0.2.1 (git+https://github.com/nervosnetwork/fiber.git?tag=v0.3.0-rc1)",
 "fnn 0.3.1",
 "fnn 0.3.1 (git+https://github.com/nervosnetwork/fiber.git?tag=v0.3.1)",
 "fnn 0.3.1 (git+https://github.com/chenyukang/fiber.git?branch=yukang-fix-480-keep-fail-tlc)",
 "hex",
 "indicatif",
 "serde",
 "serde_json",
 "thiserror 1.0.69",
 "tracing",
 "tracing-subscriber",
]

[[package]]
name = "fnv"
version = "1.0.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3f9eec918d3f24069decb9af1554cad7c880e2da24a9afd88aca000531ab82c1"

[[package]]
name = "foreign-types"
version = "0.3.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f6f339eb8adc052cd2ca78910fda869aefa38d22d5cb648e6485e4d3fc06f3b1"
dependencies = [
 "foreign-types-shared",
]

[[package]]
name = "foreign-types-shared"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "00b0228411908ca8685dba7fc2cdd70ec9990a6e753e89b6ac91a84c40fbaf4b"

[[package]]
name = "form_urlencoded"
version = "1.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e13624c2627564efccf4934284bdd98cbaa14e79b0b5a141218e507b3a823456"
dependencies = [
 "percent-encoding",
]

[[package]]
name = "futures"
version = "0.3.31"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "65bc07b1a8bc7c85c5f2e110c476c7389b4554ba72af57d8445ea63a576b0876"
dependencies = [
 "futures-channel",
 "futures-core",
 "futures-executor",
 "futures-io",
 "futures-sink",
 "futures-task",
 "futures-util",
]

[[package]]
name = "futures-channel"
version = "0.3.31"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2dff15bf788c671c1934e366d07e30c1814a8ef514e1af724a602e8a2fbe1b10"
dependencies = [
 "futures-core",
 "futures-sink",
]

[[package]]
name = "futures-core"
version = "0.3.31"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "05f29059c0c2090612e8d742178b0580d2dc940c837851ad723096f87af6663e"

[[package]]
name = "futures-executor"
version = "0.3.31"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1e28d1d997f585e54aebc3f97d39e72338912123a67330d723fdbb564d646c9f"
dependencies = [
 "futures-core",
 "futures-task",
 "futures-util",
]

[[package]]
name = "futures-io"
version = "0.3.31"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9e5c1b78ca4aae1ac06c48a526a655760685149f0d465d21f37abfe57ce075c6"

[[package]]
name = "futures-macro"
version = "0.3.31"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "162ee34ebcb7c64a8abebc059ce0fee27c2262618d7b60ed8faf72fef13c3650"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "futures-sink"
version = "0.3.31"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e575fab7d1e0dcb8d0c7bcf9a63ee213816ab51902e6d244a95819acacf1d4f7"

[[package]]
name = "futures-task"
version = "0.3.31"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f90f7dce0722e95104fcb095585910c0977252f286e354b5e3bd38902cd99988"

[[package]]
name = "futures-util"
version = "0.3.31"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9fa08315bb612088cc391249efdc3bc77536f16c91f6cf495e6fbe85b20a4a81"
dependencies = [
 "futures-channel",
 "futures-core",
 "futures-io",
 "futures-macro",
 "futures-sink",
 "futures-task",
 "memchr",
 "pin-project-lite",
 "pin-utils",
 "slab",
]

[[package]]
name = "generic-array"
version = "0.14.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "85649ca51fd72272d7821adaf274ad91c288277713d9c18820d8499a7ff69e9a"
dependencies = [
 "typenum",
 "version_check",
]

[[package]]
name = "getrandom"
version = "0.1.16"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8fc3cb4d91f53b50155bdcfd23f6a4c39ae1969c2ae85982b135750cccaf5fce"
dependencies = [
 "cfg-if 1.0.0",
 "libc",
 "wasi 0.9.0+wasi-snapshot-preview1",
]

[[package]]
name = "getrandom"
version = "0.2.15"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c4567c8db10ae91089c99af84c68c38da3ec2f087c3f82960bcdbf3656b6f4d7"
dependencies = [
 "cfg-if 1.0.0",
 "js-sys",
 "libc",
 "wasi 0.11.0+wasi-snapshot-preview1",
 "wasm-bindgen",
]

[[package]]
name = "gimli"
version = "0.31.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "07e28edb80900c19c28f1072f2e8aeca7fa06b23cd4169cefe1af5aa3260783f"

[[package]]
name = "git-version"
version = "0.3.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1ad568aa3db0fcbc81f2f116137f263d7304f512a1209b35b85150d3ef88ad19"
dependencies = [
 "git-version-macro",
]

[[package]]
name = "git-version-macro"
version = "0.3.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "53010ccb100b96a67bc32c0175f0ed1426b31b655d562898e57325f81c023ac0"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "glob"
version = "0.3.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a8d1add55171497b4705a648c6b583acafb01d58050a51727785f0b2c8e0a2b2"

[[package]]
name = "goblin"
version = "0.2.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d20fd25aa456527ce4f544271ae4fea65d2eda4a6561ea56f39fb3ee4f7e3884"
dependencies = [
 "log",
 "plain",
 "scroll",
]

[[package]]
name = "goblin"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "532a09cd3df2c6bbfc795fb0434bff8f22255d1d07328180e918a2e6ce122d4d"
dependencies = [
 "log",
 "plain",
 "scroll",
]

[[package]]
name = "golomb-coded-set"
version = "0.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "812f314a99fb5b7f0f9d0a8388539578f83f3aca6a65f588b8dbeefb731e2f98"
dependencies = [
 "siphasher",
]

[[package]]
name = "h2"
version = "0.3.26"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "81fe527a889e1532da5c525686d96d4c2e74cdd345badf8dfef9f6b39dd5f5e8"
dependencies = [
 "bytes",
 "fnv",
 "futures-core",
 "futures-sink",
 "futures-util",
 "http 0.2.12",
 "indexmap 2.7.0",
 "slab",
 "tokio",
 "tokio-util",
 "tracing",
]

[[package]]
name = "hashbrown"
version = "0.12.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8a9ee70c43aaf417c914396645a0fa852624801b24ebb7ae78fe8272889ac888"
dependencies = [
 "ahash",
]

[[package]]
name = "hashbrown"
version = "0.13.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "43a3c133739dddd0d2990f9a4bdf8eb4b21ef50e4851ca85ab661199821d510e"

[[package]]
name = "hashbrown"
version = "0.14.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e5274423e17b7c9fc20b6e7e208532f9b19825d82dfd615708b70edd83df41f1"

[[package]]
name = "hashbrown"
version = "0.15.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bf151400ff0baff5465007dd2f3e717f3fe502074ca563069ce3a6629d07b289"

[[package]]
name = "heapsize"
version = "0.4.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1679e6ea370dee694f91f1dc469bf94cf8f52051d147aec3e1f9497c6fc22461"
dependencies = [
 "winapi",
]

[[package]]
name = "heck"
version = "0.4.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "95505c38b4572b2d910cecb0281560f54b440a19336cbbcb27bf6ce6adc6f5a8"

[[package]]
name = "heck"
version = "0.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2304e00983f87ffb38b55b444b5e3b60a884b5d30c0fca7d82fe33449bbe55ea"

[[package]]
name = "hex"
version = "0.4.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7f24254aa9a54b5c858eaee2f5bccdb46aaf0e486a595ed5fd8f86ba55232a70"

[[package]]
name = "hex-conservative"
version = "0.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "212ab92002354b4819390025006c897e8140934349e8635c9b077f47b4dcbd20"

[[package]]
name = "hex-conservative"
version = "0.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5313b072ce3c597065a808dbf612c4c8e8590bdbf8b579508bf7a762c5eae6cd"
dependencies = [
 "arrayvec",
]

[[package]]
name = "hex_lit"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3011d1213f159867b13cfd6ac92d2cd5f1345762c63be3554e84092d85a50bbd"

[[package]]
name = "hmac"
version = "0.12.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6c49c37c09c17a53d937dfbb742eb3a961d65a994e6bcdcf37e7399d0cc8ab5e"
dependencies = [
 "digest 0.10.7",
]

[[package]]
name = "home"
version = "0.5.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "589533453244b0995c858700322199b2becb13b627df2851f64a2775d024abcf"
dependencies = [
 "windows-sys 0.59.0",
]

[[package]]
name = "http"
version = "0.2.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "601cbb57e577e2f5ef5be8e7b83f0f63994f25aa94d673e54a92d5c516d101f1"
dependencies = [
 "bytes",
 "fnv",
 "itoa",
]

[[package]]
name = "http"
version = "1.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f16ca2af56261c99fba8bac40a10251ce8188205a4c448fbb745a2e4daa76fea"
dependencies = [
 "bytes",
 "fnv",
 "itoa",
]

[[package]]
name = "http-body"
version = "0.4.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7ceab25649e9960c0311ea418d17bee82c0dcec1bd053b5f9a66e265a693bed2"
dependencies = [
 "bytes",
 "http 0.2.12",
 "pin-project-lite",
]

[[package]]
name = "http-range-header"
version = "0.3.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "add0ab9360ddbd88cfeb3bd9574a1d85cfdfa14db10b3e21d3700dbc4328758f"

[[package]]
name = "httparse"
version = "1.9.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7d71d3574edd2771538b901e6549113b4006ece66150fb69c0fb6d9a2adae946"

[[package]]
name = "httpdate"
version = "1.0.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "df3b46402a9d5adb4c86a0cf463f42e19994e3ee891101b1841f30a545cb49a9"

[[package]]
name = "hyper"
version = "0.14.32"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "41dfc780fdec9373c01bae43289ea34c972e40ee3c9f6b3c8801a35f35586ce7"
dependencies = [
 "bytes",
 "futures-channel",
 "futures-core",
 "futures-util",
 "h2",
 "http 0.2.12",
 "http-body",
 "httparse",
 "httpdate",
 "itoa",
 "pin-project-lite",
 "socket2",
 "tokio",
 "tower-service",
 "tracing",
 "want",
]

[[package]]
name = "hyper-openssl"
version = "0.9.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d6ee5d7a8f718585d1c3c61dfde28ef5b0bb14734b4db13f5ada856cdc6c612b"
dependencies = [
 "http 0.2.12",
 "hyper",
 "linked_hash_set",
 "once_cell",
 "openssl",
 "openssl-sys",
 "parking_lot",
 "tokio",
 "tokio-openssl",
 "tower-layer",
]

[[package]]
name = "hyper-timeout"
version = "0.4.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bbb958482e8c7be4bc3cf272a766a2b0bf1a6755e7a6ae777f017a31d11b13b1"
dependencies = [
 "hyper",
 "pin-project-lite",
 "tokio",
 "tokio-io-timeout",
]

[[package]]
name = "hyper-tls"
version = "0.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d6183ddfa99b85da61a140bea0efc93fdf56ceaa041b37d553518030827f9905"
dependencies = [
 "bytes",
 "hyper",
 "native-tls",
 "tokio",
 "tokio-native-tls",
]

[[package]]
name = "iana-time-zone"
version = "0.1.61"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "235e081f3925a06703c2d0117ea8b91f042756fd6e7a6e5d901e8ca1a996b220"
dependencies = [
 "android_system_properties",
 "core-foundation-sys",
 "iana-time-zone-haiku",
 "js-sys",
 "wasm-bindgen",
 "windows-core 0.52.0",
]

[[package]]
name = "iana-time-zone-haiku"
version = "0.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f31827a206f56af32e590ba56d5d2d085f558508192593743f16b2306495269f"
dependencies = [
 "cc",
]

[[package]]
name = "icu_collections"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "db2fa452206ebee18c4b5c2274dbf1de17008e874b4dc4f0aea9d01ca79e4526"
dependencies = [
 "displaydoc",
 "yoke",
 "zerofrom",
 "zerovec",
]

[[package]]
name = "icu_locid"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "13acbb8371917fc971be86fc8057c41a64b521c184808a698c02acc242dbf637"
dependencies = [
 "displaydoc",
 "litemap",
 "tinystr",
 "writeable",
 "zerovec",
]

[[package]]
name = "icu_locid_transform"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "01d11ac35de8e40fdeda00d9e1e9d92525f3f9d887cdd7aa81d727596788b54e"
dependencies = [
 "displaydoc",
 "icu_locid",
 "icu_locid_transform_data",
 "icu_provider",
 "tinystr",
 "zerovec",
]

[[package]]
name = "icu_locid_transform_data"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fdc8ff3388f852bede6b579ad4e978ab004f139284d7b28715f773507b946f6e"

[[package]]
name = "icu_normalizer"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "19ce3e0da2ec68599d193c93d088142efd7f9c5d6fc9b803774855747dc6a84f"
dependencies = [
 "displaydoc",
 "icu_collections",
 "icu_normalizer_data",
 "icu_properties",
 "icu_provider",
 "smallvec",
 "utf16_iter",
 "utf8_iter",
 "write16",
 "zerovec",
]

[[package]]
name = "icu_normalizer_data"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f8cafbf7aa791e9b22bec55a167906f9e1215fd475cd22adfcf660e03e989516"

[[package]]
name = "icu_properties"
version = "1.5.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "93d6020766cfc6302c15dbbc9c8778c37e62c14427cb7f6e601d849e092aeef5"
dependencies = [
 "displaydoc",
 "icu_collections",
 "icu_locid_transform",
 "icu_properties_data",
 "icu_provider",
 "tinystr",
 "zerovec",
]

[[package]]
name = "icu_properties_data"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "67a8effbc3dd3e4ba1afa8ad918d5684b8868b3b26500753effea8d2eed19569"

[[package]]
name = "icu_provider"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6ed421c8a8ef78d3e2dbc98a973be2f3770cb42b606e3ab18d6237c4dfde68d9"
dependencies = [
 "displaydoc",
 "icu_locid",
 "icu_provider_macros",
 "stable_deref_trait",
 "tinystr",
 "writeable",
 "yoke",
 "zerofrom",
 "zerovec",
]

[[package]]
name = "icu_provider_macros"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1ec89e9337638ecdc08744df490b221a7399bf8d164eb52a665454e60e075ad6"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "ident_case"
version = "1.0.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b9e0384b61958566e926dc50660321d12159025e767c18e043daf26b70104c39"

[[package]]
name = "idna"
version = "1.0.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "686f825264d630750a544639377bae737628043f20d38bbc029e8f29ea968a7e"
dependencies = [
 "idna_adapter",
 "smallvec",
 "utf8_iter",
]

[[package]]
name = "idna_adapter"
version = "1.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "daca1df1c957320b2cf139ac61e7bd64fed304c5040df000a745aa1de3b4ef71"
dependencies = [
 "icu_normalizer",
 "icu_properties",
]

[[package]]
name = "igd-next"
version = "0.15.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "76b0d7d4541def58a37bf8efc559683f21edce7c82f0d866c93ac21f7e098f93"
dependencies = [
 "attohttpc",
 "log",
 "rand 0.8.5",
 "url",
 "xmltree",
]

[[package]]
name = "includedir"
version = "0.6.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "afd126bd778c00c43a9dc76d1609a0894bf4222088088b2217ccc0ce9e816db7"
dependencies = [
 "flate2",
 "phf",
]

[[package]]
name = "includedir_codegen"
version = "0.6.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0ac1500c9780957c9808c4ec3b94002f35aab01483833f5a8bce7dfb243e3148"
dependencies = [
 "flate2",
 "phf_codegen",
 "walkdir",
]

[[package]]
name = "indexmap"
version = "1.9.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bd070e393353796e801d209ad339e89596eb4c8d430d18ede6a1cced8fafbd99"
dependencies = [
 "autocfg",
 "hashbrown 0.12.3",
 "serde",
]

[[package]]
name = "indexmap"
version = "2.7.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "62f822373a4fe84d4bb149bf54e584a7f4abec90e072ed49cda0edea5b95471f"
dependencies = [
 "equivalent",
 "hashbrown 0.15.2",
 "serde",
]

[[package]]
name = "indicatif"
version = "0.16.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2d207dc617c7a380ab07ff572a6e52fa202a2a8f355860ac9c38e23f8196be1b"
dependencies = [
 "console",
 "lazy_static",
 "number_prefix",
 "regex",
]

[[package]]
name = "inout"
version = "0.1.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a0c10553d664a4d0bcff9f4215d0aac67a639cc68ef660840afe309b807bc9f5"
dependencies = [
 "generic-array",
]

[[package]]
name = "ipnet"
version = "2.10.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ddc24109865250148c2e0f3d25d4f0f479571723792d3802153c60922a4fb708"

[[package]]
name = "is_terminal_polyfill"
version = "1.70.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7943c866cc5cd64cbc25b2e01621d07fa8eb2a1a23160ee81ce38704e97b8ecf"

[[package]]
name = "itertools"
version = "0.10.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b0fd2260e829bddf4cb6ea802289de2f86d6a7a690192fbe91b3f46e0f2c8473"
dependencies = [
 "either",
]

[[package]]
name = "itertools"
version = "0.12.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ba291022dbbd398a455acf126c1e341954079855bc60dfdda641363bd6922569"
dependencies = [
 "either",
]

[[package]]
name = "itoa"
version = "1.0.14"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d75a2a4b1b190afb6f5425f10f6a8f959d2ea0b9c2b1d79553551850539e4674"

[[package]]
name = "jobserver"
version = "0.1.32"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "48d1dbcbbeb6a7fec7e059840aa538bd62aaccf972c7346c4d9d2059312853d0"
dependencies = [
 "libc",
]

[[package]]
name = "js-sys"
version = "0.3.77"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1cfaf33c695fc6e08064efbc1f72ec937429614f25eef83af942d0e227c3a28f"
dependencies = [
 "once_cell",
 "wasm-bindgen",
]

[[package]]
name = "jsonrpc-core"
version = "18.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "14f7f76aef2d054868398427f6c54943cf3d1caa9a7ec7d0c38d69df97a965eb"
dependencies = [
 "futures",
 "futures-executor",
 "futures-util",
 "log",
 "serde",
 "serde_derive",
 "serde_json",
]

[[package]]
name = "jsonrpsee"
version = "0.22.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cfdb12a2381ea5b2e68c3469ec604a007b367778cdb14d09612c8069ebd616ad"
dependencies = [
 "jsonrpsee-core",
 "jsonrpsee-proc-macros",
 "jsonrpsee-server",
 "jsonrpsee-types",
 "tokio",
 "tracing",
]

[[package]]
name = "jsonrpsee-core"
version = "0.22.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b4b257e1ec385e07b0255dde0b933f948b5c8b8c28d42afda9587c3a967b896d"
dependencies = [
 "anyhow",
 "async-trait",
 "beef",
 "futures-util",
 "hyper",
 "jsonrpsee-types",
 "parking_lot",
 "rand 0.8.5",
 "rustc-hash",
 "serde",
 "serde_json",
 "thiserror 1.0.69",
 "tokio",
 "tracing",
]

[[package]]
name = "jsonrpsee-proc-macros"
version = "0.22.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7d0bb047e79a143b32ea03974a6bf59b62c2a4c5f5d42a381c907a8bbb3f75c0"
dependencies = [
 "heck 0.4.1",
 "proc-macro-crate",
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "jsonrpsee-server"
version = "0.22.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "12d8b6a9674422a8572e0b0abb12feeb3f2aeda86528c80d0350c2bd0923ab41"
dependencies = [
 "futures-util",
 "http 0.2.12",
 "hyper",
 "jsonrpsee-core",
 "jsonrpsee-types",
 "pin-project",
 "route-recognizer",
 "serde",
 "serde_json",
 "soketto",
 "thiserror 1.0.69",
 "tokio",
 "tokio-stream",
 "tokio-util",
 "tower",
 "tracing",
]

[[package]]
name = "jsonrpsee-types"
version = "0.22.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "150d6168405890a7a3231a3c74843f58b8959471f6df76078db2619ddee1d07d"
dependencies = [
 "anyhow",
 "beef",
 "serde",
 "serde_json",
 "thiserror 1.0.69",
]

[[package]]
name = "keccak"
version = "0.1.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ecc2af9a1119c51f12a14607e783cb977bde58bc069ff0c3da1095e635d70654"
dependencies = [
 "cpufeatures",
]

[[package]]
name = "lazy_static"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bbd2bcb4c963f2ddae06a2efc7e9f3591312473c50c6685e1f298068316e66fe"

[[package]]
name = "lazycell"
version = "1.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "830d08ce1d1d941e6b30645f1a0eb5643013d835ce3779a5fc208261dbe10f55"

[[package]]
name = "libc"
version = "0.2.169"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b5aba8db14291edd000dfcc4d620c7ebfb122c613afb886ca8803fa4e128a20a"

[[package]]
name = "libloading"
version = "0.8.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fc2f4eb4bc735547cfed7c0a4922cbd04a4655978c09b54f1f7b228750664c34"
dependencies = [
 "cfg-if 1.0.0",
 "windows-targets 0.52.6",
]

[[package]]
name = "lightning"
version = "0.0.121"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5b0c1f811ae288f86c6767055c55b5f7a721ca1e61bf1897a9ae2ec663e8aba1"
dependencies = [
 "bitcoin",
 "hex-conservative 0.1.2",
]

[[package]]
name = "lightning-invoice"
version = "0.29.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5b186aca4a605d4db3b85979922be287b9ebd5dedd8132963bb9dbeb8f7d2a04"
dependencies = [
 "bech32 0.9.1",
 "bitcoin",
 "lightning",
 "num-traits",
 "secp256k1 0.27.0",
]

[[package]]
name = "linked-hash-map"
version = "0.5.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0717cef1bc8b636c6e1c1bbdefc09e6322da8a9321966e8928ef80d20f7f770f"

[[package]]
name = "linked_hash_set"
version = "0.1.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bae85b5be22d9843c80e5fc80e9b64c8a3b1f98f867c709956eca3efff4e92e2"
dependencies = [
 "linked-hash-map",
]

[[package]]
name = "linux-raw-sys"
version = "0.4.15"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d26c52dbd32dccf2d10cac7725f8eae5296885fb5703b261f7d0a0739ec807ab"

[[package]]
name = "litemap"
version = "0.7.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4ee93343901ab17bd981295f2cf0026d4ad018c7c31ba84549a4ddbb47a45104"

[[package]]
name = "lnd-grpc-tonic-client"
version = "0.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d09ab65602a2f5b9582e81aa850e7a341ca4e5d26aa144d12c5384ba5fe9d112"
dependencies = [
 "hex",
 "hyper",
 "hyper-openssl",
 "openssl",
 "prost 0.12.6",
 "thiserror 1.0.69",
 "tonic 0.11.0",
 "tonic-build",
 "tonic-openssl",
 "tower-service",
]

[[package]]
name = "lock_api"
version = "0.4.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "07af8b9cdd281b7915f413fa73f29ebd5d55d0d3f0155584dade1ff18cea1b17"
dependencies = [
 "autocfg",
 "scopeguard",
]

[[package]]
name = "log"
version = "0.4.22"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a7a70ba024b9dc04c27ea2f0c0548feb474ec5c54bba33a7f72f873a39d07b24"

[[package]]
name = "lru"
version = "0.7.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e999beba7b6e8345721bd280141ed958096a2e4abdf74f67ff4ce49b4b54e47a"
dependencies = [
 "hashbrown 0.12.3",
]

[[package]]
name = "matchers"
version = "0.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8263075bb86c5a1b1427b5ae862e8889656f126e9f77c484496e8b47cf5c5558"
dependencies = [
 "regex-automata 0.1.10",
]

[[package]]
name = "matchit"
version = "0.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "73cbba799671b762df5a175adf59ce145165747bb891505c43d09aefbbf38beb"

[[package]]
name = "matchit"
version = "0.7.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0e7465ac9959cc2b1404e8e2367b43684a6d13790fe23056cc8c6c5a6b7bcb94"

[[package]]
name = "memchr"
version = "2.7.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "78ca9ab1a0babb1e7d5695e3530886289c18cf2f87ec19a575a0abdce112e3a3"

[[package]]
name = "memmap2"
version = "0.5.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "83faa42c0a078c393f6b29d5db232d8be22776a891f8f56e5284faee4a20b327"
dependencies = [
 "libc",
]

[[package]]
name = "merkle-cbt"
version = "0.3.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "171d2f700835121c3b04ccf0880882987a050fd5c7ae88148abf537d33dd3a56"
dependencies = [
 "cfg-if 1.0.0",
]

[[package]]
name = "miette"
version = "5.10.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "59bb584eaeeab6bd0226ccf3509a69d7936d148cf3d036ad350abe35e8c6856e"
dependencies = [
 "miette-derive",
 "once_cell",
 "thiserror 1.0.69",
 "unicode-width 0.1.14",
]

[[package]]
name = "miette-derive"
version = "5.10.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "49e7bc1560b95a3c4a25d03de42fe76ca718ab92d1a22a55b9b4cf67b3ae635c"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "mime"
version = "0.3.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6877bb514081ee2a7ff5ef9de3281f14a4dd4bceac4c09388074a6b5df8a139a"

[[package]]
name = "minimal-lexical"
version = "0.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "68354c5c6bd36d73ff3feceb05efa59b6acb7626617f4962be322a825e61f79a"

[[package]]
name = "miniz_oxide"
version = "0.8.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b8402cab7aefae129c6977bb0ff1b8fd9a04eb5b51efc50a70bea51cda0c7924"
dependencies = [
 "adler2",
]

[[package]]
name = "mio"
version = "1.0.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2886843bf800fba2e3377cff24abf6379b4c4d5c6681eaf9ea5b0d15090450bd"
dependencies = [
 "libc",
 "wasi 0.11.0+wasi-snapshot-preview1",
 "windows-sys 0.52.0",
]

[[package]]
name = "molecule"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6efe1c7efcd0bdf4ca590e104bcb13087d9968956ae4ae98e92fb8c1da0f3730"
dependencies = [
 "bytes",
 "cfg-if 1.0.0",
 "faster-hex",
]

[[package]]
name = "multimap"
version = "0.10.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "defc4c55412d89136f966bbb339008b474350e5e6e78d2714439c386b3137a03"

[[package]]
name = "musig2"
version = "0.0.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bed08befaac75bfb31ca5e87678c4e8490bcd21d0c98ccb4f12f4065a7567e83"
dependencies = [
 "base16ct",
 "hmac",
 "once_cell",
 "secp",
 "secp256k1 0.28.2",
 "serde",
 "serdect",
 "sha2",
 "subtle",
]

[[package]]
name = "native-tls"
version = "0.2.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a8614eb2c83d59d1c8cc974dd3f920198647674a0a035e1af1fa58707e317466"
dependencies = [
 "libc",
 "log",
 "openssl",
 "openssl-probe",
 "openssl-sys",
 "schannel",
 "security-framework",
 "security-framework-sys",
 "tempfile",
]

[[package]]
name = "nohash-hasher"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2bf50223579dc7cdcfb3bfcacf7069ff68243f8c363f62ffa99cf000a6b9c451"

[[package]]
name = "nom"
version = "7.1.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d273983c5a657a70a3e8f2a01329822f3b8c8172b73826411a55751e404a0a4a"
dependencies = [
 "memchr",
 "minimal-lexical",
]

[[package]]
name = "nu-ansi-term"
version = "0.46.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "77a8165726e8236064dbb45459242600304b42a5ea24ee2948e18e023bf7ba84"
dependencies = [
 "overload",
 "winapi",
]

[[package]]
name = "num-conv"
version = "0.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "51d515d32fb182ee37cda2ccdcb92950d6a3c2893aa280e540671c2cd0f3b1d9"

[[package]]
name = "num-traits"
version = "0.2.19"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "071dfc062690e90b734c0b2273ce72ad0ffa95f0c74596bc250dcfd960262841"
dependencies = [
 "autocfg",
]

[[package]]
name = "num_enum"
version = "0.7.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4e613fc340b2220f734a8595782c551f1250e969d87d3be1ae0579e8d4065179"
dependencies = [
 "num_enum_derive",
]

[[package]]
name = "num_enum_derive"
version = "0.7.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "af1844ef2428cc3e1cb900be36181049ef3d3193c63e43026cfe202983b27a56"
dependencies = [
 "proc-macro-crate",
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "number_prefix"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "830b246a0e5f20af87141b25c173cd1b609bd7779a4617d6ec582abaf90870f3"

[[package]]
name = "numext-constructor"
version = "0.1.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "621fe0f044729f810c6815cdd77e8f5e0cd803ce4f6a38380ebfc1322af98661"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "numext-fixed-uint"
version = "0.1.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6c68c76f96d589d1009a666c5072f37f3114d682696505f2cf445f27766c7d70"
dependencies = [
 "numext-fixed-uint-core",
 "numext-fixed-uint-hack",
]

[[package]]
name = "numext-fixed-uint-core"
version = "0.1.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6aab1d6457b97b49482f22a92f0f58a2f39bdd7f3b2f977eae67e8bc206aa980"
dependencies = [
 "heapsize",
 "numext-constructor",
 "rand 0.7.3",
 "serde",
 "thiserror 1.0.69",
]

[[package]]
name = "numext-fixed-uint-hack"
version = "0.1.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0200f8d55c36ec1b6a8cf810115be85d4814f045e0097dfd50033ba25adb4c9e"
dependencies = [
 "numext-fixed-uint-core",
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "object"
version = "0.36.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "62948e14d923ea95ea2c7c86c71013138b66525b86bdc08d2dcc262bdb497b87"
dependencies = [
 "memchr",
]

[[package]]
name = "once_cell"
version = "1.20.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1261fe7e33c73b354eab43b1273a57c8f967d0391e80353e51f764ac02cf6775"

[[package]]
name = "opaque-debug"
version = "0.3.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c08d65885ee38876c4f86fa503fb49d7b507c2b62552df7c70b2fce627e06381"

[[package]]
name = "openssl"
version = "0.10.68"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6174bc48f102d208783c2c84bf931bb75927a617866870de8a4ea85597f871f5"
dependencies = [
 "bitflags 2.7.0",
 "cfg-if 1.0.0",
 "foreign-types",
 "libc",
 "once_cell",
 "openssl-macros",
 "openssl-sys",
]

[[package]]
name = "openssl-macros"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a948666b637a0f465e8564c73e89d4dde00d72d4d473cc972f390fc3dcee7d9c"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "openssl-probe"
version = "0.1.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ff011a302c396a5197692431fc1948019154afc178baf7d8e37367442a4601cf"

[[package]]
name = "openssl-src"
version = "300.4.1+3.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "faa4eac4138c62414b5622d1b31c5c304f34b406b013c079c2bbc652fdd6678c"
dependencies = [
 "cc",
]

[[package]]
name = "openssl-sys"
version = "0.9.104"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "45abf306cbf99debc8195b66b7346498d7b10c210de50418b5ccd7ceba08c741"
dependencies = [
 "cc",
 "libc",
 "openssl-src",
 "pkg-config",
 "vcpkg",
]

[[package]]
name = "ordered-multimap"
version = "0.6.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4ed8acf08e98e744e5384c8bc63ceb0364e68a6854187221c18df61c4797690e"
dependencies = [
 "dlv-list",
 "hashbrown 0.13.2",
]

[[package]]
name = "overload"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b15813163c1d831bf4a13c3610c05c0d03b39feb07f7e09fa234dac9b15aaf39"

[[package]]
name = "parking_lot"
version = "0.12.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f1bf18183cf54e8d6059647fc3063646a1801cf30896933ec2311622cc4b9a27"
dependencies = [
 "lock_api",
 "parking_lot_core",
]

[[package]]
name = "parking_lot_core"
version = "0.9.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1e401f977ab385c9e4e3ab30627d6f26d00e2c73eef317493c4ec6d468726cf8"
dependencies = [
 "cfg-if 1.0.0",
 "libc",
 "redox_syscall",
 "smallvec",
 "windows-targets 0.52.6",
]

[[package]]
name = "paste"
version = "1.0.15"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "57c0d7b74b563b49d38dae00a0c37d4d6de9b432382b2892f0574ddcae73fd0a"

[[package]]
name = "peeking_take_while"
version = "0.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "19b17cddbe7ec3f8bc800887bab5e717348c95ea2ca0b1bf0837fb964dc67099"

[[package]]
name = "percent-encoding"
version = "2.3.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e3148f5046208a5d56bcfc03053e3ca6334e51da8dfb19b6cdc8b306fae3283e"

[[package]]
name = "petgraph"
version = "0.6.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b4c5cc86750666a3ed20bdaf5ca2a0344f9c67674cae0515bec2da16fbaa47db"
dependencies = [
 "fixedbitset",
 "indexmap 2.7.0",
]

[[package]]
name = "phf"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3dfb61232e34fcb633f43d12c58f83c1df82962dcdfa565a4e866ffc17dafe12"
dependencies = [
 "phf_shared",
]

[[package]]
name = "phf_codegen"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cbffee61585b0411840d3ece935cce9cb6321f01c45477d30066498cd5e1a815"
dependencies = [
 "phf_generator",
 "phf_shared",
]

[[package]]
name = "phf_generator"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "17367f0cc86f2d25802b2c26ee58a7b23faeccf78a396094c13dced0d0182526"
dependencies = [
 "phf_shared",
 "rand 0.7.3",
]

[[package]]
name = "phf_shared"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c00cf8b9eafe68dde5e9eaa2cef8ee84a9336a47d566ec55ca16589633b65af7"
dependencies = [
 "siphasher",
]

[[package]]
name = "pin-project"
version = "1.1.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1e2ec53ad785f4d35dac0adea7f7dc6f1bb277ad84a680c7afefeae05d1f5916"
dependencies = [
 "pin-project-internal",
]

[[package]]
name = "pin-project-internal"
version = "1.1.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d56a66c0c55993aa927429d0f8a0abfd74f084e4d9c192cffed01e418d83eefb"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "pin-project-lite"
version = "0.2.16"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3b3cff922bd51709b605d9ead9aa71031d81447142d828eb4a6eba76fe619f9b"

[[package]]
name = "pin-utils"
version = "0.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8b870d8c151b6f2fb93e84a13146138f05d02ed11c7e7c54f8826aaaf7c9f184"

[[package]]
name = "pkg-config"
version = "0.3.31"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "953ec861398dccce10c670dfeaf3ec4911ca479e9c02154b3a215178c5f566f2"

[[package]]
name = "plain"
version = "0.2.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b4596b6d070b27117e987119b4dac604f3c58cfb0b191112e24771b2faeac1a6"

[[package]]
name = "poly1305"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8159bd90725d2df49889a078b54f4f79e87f1f8a8444194cdca81d38f5393abf"
dependencies = [
 "cpufeatures",
 "opaque-debug",
 "universal-hash",
]

[[package]]
name = "powerfmt"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "439ee305def115ba05938db6eb1644ff94165c5ab5e9420d1c1bcedbba909391"

[[package]]
name = "ppv-lite86"
version = "0.2.20"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "77957b295656769bb8ad2b6a6b09d897d94f05c41b069aede1fcdaa675eaea04"
dependencies = [
 "zerocopy",
]

[[package]]
name = "prettyplease"
version = "0.2.29"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6924ced06e1f7dfe3fa48d57b9f74f55d8915f5036121bef647ef4b204895fac"
dependencies = [
 "proc-macro2",
 "syn 2.0.96",
]

[[package]]
name = "proc-macro-crate"
version = "3.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8ecf48c7ca261d60b74ab1a7b20da18bede46776b2e55535cb958eb595c5fa7b"
dependencies = [
 "toml_edit",
]

[[package]]
name = "proc-macro-error"
version = "1.0.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "da25490ff9892aab3fcf7c36f08cfb902dd3e71ca0f9f9517bea02a73a5ce38c"
dependencies = [
 "proc-macro-error-attr",
 "proc-macro2",
 "quote",
 "syn 1.0.109",
 "version_check",
]

[[package]]
name = "proc-macro-error-attr"
version = "1.0.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a1be40180e52ecc98ad80b184934baf3d0d29f979574e439af5a55274b35f869"
dependencies = [
 "proc-macro2",
 "quote",
 "version_check",
]

[[package]]
name = "proc-macro2"
version = "1.0.93"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "60946a68e5f9d28b0dc1c21bb8a97ee7d018a8b322fa57838ba31cc878e22d99"
dependencies = [
 "unicode-ident",
]

[[package]]
name = "prost"
version = "0.10.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "71adf41db68aa0daaefc69bb30bcd68ded9b9abaad5d1fbb6304c4fb390e083e"
dependencies = [
 "bytes",
 "prost-derive 0.10.1",
]

[[package]]
name = "prost"
version = "0.12.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "deb1435c188b76130da55f17a466d252ff7b1418b2ad3e037d127b94e3411f29"
dependencies = [
 "bytes",
 "prost-derive 0.12.6",
]

[[package]]
name = "prost-build"
version = "0.12.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "22505a5c94da8e3b7c2996394d1c933236c4d743e81a410bcca4e6989fc066a4"
dependencies = [
 "bytes",
 "heck 0.5.0",
 "itertools 0.12.1",
 "log",
 "multimap",
 "once_cell",
 "petgraph",
 "prettyplease",
 "prost 0.12.6",
 "prost-types",
 "regex",
 "syn 2.0.96",
 "tempfile",
]

[[package]]
name = "prost-derive"
version = "0.10.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7b670f45da57fb8542ebdbb6105a925fe571b67f9e7ed9f47a06a84e72b4e7cc"
dependencies = [
 "anyhow",
 "itertools 0.10.5",
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "prost-derive"
version = "0.12.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "81bddcdb20abf9501610992b6759a4c888aef7d1a7247ef75e2404275ac24af1"
dependencies = [
 "anyhow",
 "itertools 0.12.1",
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "prost-types"
version = "0.12.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9091c90b0a32608e984ff2fa4091273cbdd755d54935c51d520887f4a1dbd5b0"
dependencies = [
 "prost 0.12.6",
]

[[package]]
name = "quote"
version = "1.0.38"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0e4dccaaaf89514f546c693ddc140f729f958c247918a13380cccc6078391acc"
dependencies = [
 "proc-macro2",
]

[[package]]
name = "ractor"
version = "0.9.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7dd876f0d609ba2ddc8a36136e9b81299312bd9fc9b71131381d16c9ce8e495a"
dependencies = [
 "async-trait",
 "dashmap 5.5.3",
 "futures",
 "once_cell",
 "rand 0.8.5",
 "tokio",
 "tracing",
]

[[package]]
name = "ractor"
version = "0.14.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "aeb2472c961aec135028ae83b64491243ef36402c4f93f04b4f29f9f5d8805a8"
dependencies = [
 "async-trait",
 "bon",
 "dashmap 6.1.0",
 "futures",
 "once_cell",
 "strum",
 "tokio",
 "tracing",
]

[[package]]
name = "rand"
version = "0.7.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6a6b1679d49b24bbfe0c803429aa1874472f50d9b363131f0e89fc356b544d03"
dependencies = [
 "getrandom 0.1.16",
 "libc",
 "rand_chacha 0.2.2",
 "rand_core 0.5.1",
 "rand_hc",
 "rand_pcg",
]

[[package]]
name = "rand"
version = "0.8.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "34af8d1a0e25924bc5b7c43c079c942339d8f0a8b57c39049bef581b46327404"
dependencies = [
 "libc",
 "rand_chacha 0.3.1",
 "rand_core 0.6.4",
]

[[package]]
name = "rand_chacha"
version = "0.2.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f4c8ed856279c9737206bf725bf36935d8666ead7aa69b52be55af369d193402"
dependencies = [
 "ppv-lite86",
 "rand_core 0.5.1",
]

[[package]]
name = "rand_chacha"
version = "0.3.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e6c10a63a0fa32252be49d21e7709d4d4baf8d231c2dbce1eaa8141b9b127d88"
dependencies = [
 "ppv-lite86",
 "rand_core 0.6.4",
]

[[package]]
name = "rand_core"
version = "0.5.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "90bde5296fc891b0cef12a6d03ddccc162ce7b2aff54160af9338f8d40df6d19"
dependencies = [
 "getrandom 0.1.16",
]

[[package]]
name = "rand_core"
version = "0.6.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ec0be4795e2f6a28069bec0b5ff3e2ac9bafc99e6a9a7dc3547996c5c816922c"
dependencies = [
 "getrandom 0.2.15",
]

[[package]]
name = "rand_hc"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ca3129af7b92a17112d59ad498c6f81eaf463253766b90396d39ea7a39d6613c"
dependencies = [
 "rand_core 0.5.1",
]

[[package]]
name = "rand_pcg"
version = "0.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "16abd0c1b639e9eb4d7c50c0b8100b0d0f849be2349829c740fe8e6eb4816429"
dependencies = [
 "rand_core 0.5.1",
]

[[package]]
name = "redox_syscall"
version = "0.5.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "03a862b389f93e68874fbf580b9de08dd02facb9a788ebadaf4a3fd33cf58834"
dependencies = [
 "bitflags 2.7.0",
]

[[package]]
name = "reflink-copy"
version = "0.1.22"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0a7aea22fc8204e0f291719120cbcdae4f25f0807d7b00f5b6b27d95a8f1a2ad"
dependencies = [
 "cfg-if 1.0.0",
 "rustix",
 "windows",
]

[[package]]
name = "regex"
version = "1.11.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b544ef1b4eac5dc2db33ea63606ae9ffcfac26c1416a2806ae0bf5f56b201191"
dependencies = [
 "aho-corasick",
 "memchr",
 "regex-automata 0.4.9",
 "regex-syntax 0.8.5",
]

[[package]]
name = "regex-automata"
version = "0.1.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6c230d73fb8d8c1b9c0b3135c5142a8acee3a0558fb8db5cf1cb65f8d7862132"
dependencies = [
 "regex-syntax 0.6.29",
]

[[package]]
name = "regex-automata"
version = "0.4.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "809e8dc61f6de73b46c85f4c96486310fe304c434cfa43669d7b40f711150908"
dependencies = [
 "aho-corasick",
 "memchr",
 "regex-syntax 0.8.5",
]

[[package]]
name = "regex-syntax"
version = "0.6.29"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f162c6dd7b008981e4d40210aca20b4bd0f9b60ca9271061b07f78537722f2e1"

[[package]]
name = "regex-syntax"
version = "0.8.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2b15c43186be67a4fd63bee50d0303afffcef381492ebe2c5d87f324e1b8815c"

[[package]]
name = "reqwest"
version = "0.11.27"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "dd67538700a17451e7cba03ac727fb961abb7607553461627b97de0b89cf4a62"
dependencies = [
 "base64 0.21.7",
 "bytes",
 "encoding_rs",
 "futures-core",
 "futures-util",
 "h2",
 "http 0.2.12",
 "http-body",
 "hyper",
 "hyper-tls",
 "ipnet",
 "js-sys",
 "log",
 "mime",
 "native-tls",
 "once_cell",
 "percent-encoding",
 "pin-project-lite",
 "rustls-pemfile",
 "serde",
 "serde_json",
 "serde_urlencoded",
 "sync_wrapper",
 "system-configuration",
 "tokio",
 "tokio-native-tls",
 "tower-service",
 "url",
 "wasm-bindgen",
 "wasm-bindgen-futures",
 "web-sys",
 "winreg",
]

[[package]]
name = "ring"
version = "0.17.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c17fa4cb658e3583423e915b9f3acc01cceaee1860e33d59ebae66adc3a2dc0d"
dependencies = [
 "cc",
 "cfg-if 1.0.0",
 "getrandom 0.2.15",
 "libc",
 "spin",
 "untrusted",
 "windows-sys 0.52.0",
]

[[package]]
name = "route-recognizer"
version = "0.3.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "afab94fb28594581f62d981211a9a4d53cc8130bbcbbb89a0440d9b8e81a7746"

[[package]]
name = "rust-ini"
version = "0.19.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7e2a3bcec1f113553ef1c88aae6c020a369d03d55b58de9869a0908930385091"
dependencies = [
 "cfg-if 1.0.0",
 "ordered-multimap",
]

[[package]]
name = "rustc-demangle"
version = "0.1.24"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "719b953e2095829ee67db738b3bfa9fa368c94900df327b3f07fe6e794d2fe1f"

[[package]]
name = "rustc-hash"
version = "1.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "08d43f7aa6b08d49f382cde6a7982047c3426db949b1424bc4b7ec9ae12c6ce2"

[[package]]
name = "rustc_version"
version = "0.4.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cfcb3a22ef46e85b45de6ee7e79d063319ebb6594faafcf1c225ea92ab6e9b92"
dependencies = [
 "semver",
]

[[package]]
name = "rustix"
version = "0.38.43"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a78891ee6bf2340288408954ac787aa063d8e8817e9f53abb37c695c6d834ef6"
dependencies = [
 "bitflags 2.7.0",
 "errno",
 "libc",
 "linux-raw-sys",
 "windows-sys 0.59.0",
]

[[package]]
name = "rustls-pemfile"
version = "1.0.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1c74cae0a4cf6ccbbf5f359f08efdf8ee7e1dc532573bf0db71968cb56b1448c"
dependencies = [
 "base64 0.21.7",
]

[[package]]
name = "rustversion"
version = "1.0.19"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f7c45b9784283f1b2e7fb61b42047c2fd678ef0960d4f6f1eba131594cc369d4"

[[package]]
name = "ryu"
version = "1.0.18"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f3cb5ba0dc43242ce17de99c180e96db90b235b8a9fdc9543c96d2209116bd9f"

[[package]]
name = "same-file"
version = "1.0.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "93fc1dc3aaa9bfed95e02e6eadabb4baf7e3078b0bd1b4d7b6b0b68378900502"
dependencies = [
 "winapi-util",
]

[[package]]
name = "schannel"
version = "0.1.27"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1f29ebaa345f945cec9fbbc532eb307f0fdad8161f281b6369539c8d84876b3d"
dependencies = [
 "windows-sys 0.59.0",
]

[[package]]
name = "scopeguard"
version = "1.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "94143f37725109f92c262ed2cf5e59bce7498c01bcc1502d7b9afe439a4e9f49"

[[package]]
name = "scroll"
version = "0.10.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fda28d4b4830b807a8b43f7b0e6b5df875311b3e7621d84577188c175b6ec1ec"
dependencies = [
 "scroll_derive",
]

[[package]]
name = "scroll_derive"
version = "0.10.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "aaaae8f38bb311444cfb7f1979af0bc9240d95795f75f9ceddf6a59b79ceffa0"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "secp"
version = "0.2.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1c4754628ff9006f80c6abd1cd1e88c5ca6f5a60eab151ad2e16268aab3514d0"
dependencies = [
 "base16ct",
 "once_cell",
 "secp256k1 0.28.2",
 "serde",
 "serdect",
 "subtle",
]

[[package]]
name = "secp256k1"
version = "0.27.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "25996b82292a7a57ed3508f052cfff8640d38d32018784acd714758b43da9c8f"
dependencies = [
 "bitcoin_hashes 0.12.0",
 "rand 0.8.5",
 "secp256k1-sys 0.8.1",
 "serde",
]

[[package]]
name = "secp256k1"
version = "0.28.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d24b59d129cdadea20aea4fb2352fa053712e5d713eee47d700cd4b2bc002f10"
dependencies = [
 "rand 0.8.5",
 "secp256k1-sys 0.9.2",
 "serde",
]

[[package]]
name = "secp256k1"
version = "0.29.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9465315bc9d4566e1724f0fffcbcc446268cb522e60f9a27bcded6b19c108113"
dependencies = [
 "secp256k1-sys 0.10.1",
]

[[package]]
name = "secp256k1"
version = "0.30.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b50c5943d326858130af85e049f2661ba3c78b26589b8ab98e65e80ae44a1252"
dependencies = [
 "bitcoin_hashes 0.14.0",
 "rand 0.8.5",
 "secp256k1-sys 0.10.1",
]

[[package]]
name = "secp256k1-sys"
version = "0.8.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "70a129b9e9efbfb223753b9163c4ab3b13cff7fd9c7f010fbac25ab4099fa07e"
dependencies = [
 "cc",
]

[[package]]
name = "secp256k1-sys"
version = "0.9.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e5d1746aae42c19d583c3c1a8c646bfad910498e2051c551a7f2e3c0c9fbb7eb"
dependencies = [
 "cc",
]

[[package]]
name = "secp256k1-sys"
version = "0.10.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d4387882333d3aa8cb20530a17c69a3752e97837832f34f6dccc760e715001d9"
dependencies = [
 "cc",
]

[[package]]
name = "security-framework"
version = "2.11.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "897b2245f0b511c87893af39b033e5ca9cce68824c4d7e7630b5a1d339658d02"
dependencies = [
 "bitflags 2.7.0",
 "core-foundation",
 "core-foundation-sys",
 "libc",
 "security-framework-sys",
]

[[package]]
name = "security-framework-sys"
version = "2.14.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "49db231d56a190491cb4aeda9527f1ad45345af50b0851622a7adb8c03b01c32"
dependencies = [
 "core-foundation-sys",
 "libc",
]

[[package]]
name = "semver"
version = "1.0.24"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3cb6eb87a131f756572d7fb904f6e7b68633f09cca868c5df1c4b8d1a694bbba"

[[package]]
name = "serde"
version = "1.0.217"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "02fc4265df13d6fa1d00ecff087228cc0a2b5f3c0e87e258d8b94a156e984c70"
dependencies = [
 "serde_derive",
]

[[package]]
name = "serde_derive"
version = "1.0.217"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5a9bf7cf98d04a2b28aead066b7496853d4779c9cc183c440dbac457641e19a0"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "serde_derive_internals"
version = "0.26.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "85bf8229e7920a9f636479437026331ce11aa132b4dde37d121944a44d6e5f3c"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "serde_json"
version = "1.0.135"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2b0d7ba2887406110130a978386c4e1befb98c674b4fba677954e4db976630d9"
dependencies = [
 "itoa",
 "memchr",
 "ryu",
 "serde",
]

[[package]]
name = "serde_urlencoded"
version = "0.7.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d3491c14715ca2294c4d6a88f15e84739788c1d030eed8c110436aafdaa2f3fd"
dependencies = [
 "form_urlencoded",
 "itoa",
 "ryu",
 "serde",
]

[[package]]
name = "serde_with"
version = "3.12.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d6b6f7f2fcb69f747921f79f3926bd1e203fce4fef62c268dd3abfb6d86029aa"
dependencies = [
 "base64 0.22.1",
 "chrono",
 "hex",
 "indexmap 1.9.3",
 "indexmap 2.7.0",
 "serde",
 "serde_derive",
 "serde_json",
 "serde_with_macros",
 "time",
]

[[package]]
name = "serde_with_macros"
version = "3.12.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8d00caa5193a3c8362ac2b73be6b9e768aa5a4b2f721d8f4b339600c3cb51f8e"
dependencies = [
 "darling",
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "serde_yaml"
version = "0.9.34+deprecated"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6a8b1a1a2ebf674015cc02edccce75287f1a0130d394307b36743c2f5d504b47"
dependencies = [
 "indexmap 2.7.0",
 "itoa",
 "ryu",
 "serde",
 "unsafe-libyaml",
]

[[package]]
name = "serdect"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a84f14a19e9a014bb9f4512488d9829a68e04ecabffb0f9904cd1ace94598177"
dependencies = [
 "base16ct",
 "serde",
]

[[package]]
name = "sha-1"
version = "0.9.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "99cd6713db3cf16b6c84e06321e049a9b9f699826e16096d23bbcc44d15d51a6"
dependencies = [
 "block-buffer 0.9.0",
 "cfg-if 1.0.0",
 "cpufeatures",
 "digest 0.9.0",
 "opaque-debug",
]

[[package]]
name = "sha-1"
version = "0.10.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f5058ada175748e33390e40e872bd0fe59a19f265d0158daa551c5a88a76009c"
dependencies = [
 "cfg-if 1.0.0",
 "cpufeatures",
 "digest 0.10.7",
]

[[package]]
name = "sha1"
version = "0.10.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e3bf829a2d51ab4a5ddf1352d8470c140cadc8301b2ae1789db023f01cedd6ba"
dependencies = [
 "cfg-if 1.0.0",
 "cpufeatures",
 "digest 0.10.7",
]

[[package]]
name = "sha2"
version = "0.10.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "793db75ad2bcafc3ffa7c68b215fee268f537982cd901d132f89c6343f3a3dc8"
dependencies = [
 "cfg-if 1.0.0",
 "cpufeatures",
 "digest 0.10.7",
]

[[package]]
name = "sha3"
version = "0.10.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "75872d278a8f37ef87fa0ddbda7802605cb18344497949862c0d4dcb291eba60"
dependencies = [
 "digest 0.10.7",
 "keccak",
]

[[package]]
name = "sharded-slab"
version = "0.1.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f40ca3c46823713e0d4209592e8d6e826aa57e928f09752619fc696c499637f6"
dependencies = [
 "lazy_static",
]

[[package]]
name = "shlex"
version = "1.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0fda2ff0d084019ba4d7c6f371c95d8fd75ce3524c3cb8fb653a3023f6323e64"

[[package]]
name = "signal-hook-registry"
version = "1.4.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a9e9e0b4211b72e7b8b6e85c807d36c212bdb33ea8587f7569562a84df5465b1"
dependencies = [
 "libc",
]

[[package]]
name = "siphasher"
version = "0.3.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "38b58827f4464d87d377d175e90bf58eb00fd8716ff0a62f80356b5e61555d0d"

[[package]]
name = "slab"
version = "0.4.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8f92a496fb766b417c996b9c5e57daf2f7ad3b0bebe1ccfca4856390e3d3bb67"
dependencies = [
 "autocfg",
]

[[package]]
name = "smallvec"
version = "1.13.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3c5e1a9a646d36c3599cd173a41282daf47c44583ad367b8e6837255952e5c67"

[[package]]
name = "socket2"
version = "0.5.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c970269d99b64e60ec3bd6ad27270092a5394c4e309314b18ae3fe575695fbe8"
dependencies = [
 "libc",
 "windows-sys 0.52.0",
]

[[package]]
name = "soketto"
version = "0.7.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "41d1c5305e39e09653383c2c7244f2f78b3bcae37cf50c64cb4789c9f5096ec2"
dependencies = [
 "base64 0.13.1",
 "bytes",
 "futures",
 "http 0.2.12",
 "httparse",
 "log",
 "rand 0.8.5",
 "sha-1 0.9.8",
]

[[package]]
name = "sparse-merkle-tree"
version = "0.6.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8851f6c92491ebe5528eabc1244292175a739eb0162974f9f9670a7dc748748b"
dependencies = [
 "blake2b-rs",
 "cc",
 "cfg-if 0.1.10",
]

[[package]]
name = "spin"
version = "0.9.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6980e8d7511241f8acf4aebddbb1ff938df5eebe98691418c4468d0b72a96a67"

[[package]]
name = "ssri"
version = "9.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "da7a2b3c2bc9693bcb40870c4e9b5bf0d79f9cb46273321bf855ec513e919082"
dependencies = [
 "base64 0.21.7",
 "digest 0.10.7",
 "hex",
 "miette",
 "serde",
 "sha-1 0.10.1",
 "sha2",
 "thiserror 1.0.69",
 "xxhash-rust",
]

[[package]]
name = "stable_deref_trait"
version = "1.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a8f112729512f8e442d81f95a8a7ddf2b7c6b8a1a6f509a95864142b30cab2d3"

[[package]]
name = "strsim"
version = "0.11.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7da8b5736845d9f2fcb837ea5d9e2628564b3b043a70948a3f0b778838c5fb4f"

[[package]]
name = "strum"
version = "0.26.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8fec0f0aef304996cf250b31b5a10dee7980c85da9d759361292b8bca5a18f06"
dependencies = [
 "strum_macros",
]

[[package]]
name = "strum_macros"
version = "0.26.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4c6bee85a5a24955dc440386795aa378cd9cf82acd5f764469152d2270e581be"
dependencies = [
 "heck 0.5.0",
 "proc-macro2",
 "quote",
 "rustversion",
 "syn 2.0.96",
]

[[package]]
name = "subtle"
version = "2.6.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "13c2bddecc57b384dee18652358fb23172facb8a2c51ccc10d74c157bdea3292"

[[package]]
name = "syn"
version = "1.0.109"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "72b64191b275b66ffe2469e8af2c1cfe3bafa67b529ead792a6d0160888b4237"
dependencies = [
 "proc-macro2",
 "quote",
 "unicode-ident",
]

[[package]]
name = "syn"
version = "2.0.96"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d5d0adab1ae378d7f53bdebc67a39f1f151407ef230f0ce2883572f5d8985c80"
dependencies = [
 "proc-macro2",
 "quote",
 "unicode-ident",
]

[[package]]
name = "sync_wrapper"
version = "0.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2047c6ded9c721764247e62cd3b03c09ffc529b2ba5b10ec482ae507a4a70160"

[[package]]
name = "synstructure"
version = "0.13.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c8af7666ab7b6390ab78131fb5b0fce11d6b7a6951602017c35fa82800708971"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "system-configuration"
version = "0.5.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ba3a3adc5c275d719af8cb4272ea1c4a6d668a777f37e115f6d11ddbc1c8e0e7"
dependencies = [
 "bitflags 1.3.2",
 "core-foundation",
 "system-configuration-sys",
]

[[package]]
name = "system-configuration-sys"
version = "0.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a75fb188eb626b924683e3b95e3a48e63551fcfb51949de2f06a9d91dbee93c9"
dependencies = [
 "core-foundation-sys",
 "libc",
]

[[package]]
name = "tempfile"
version = "3.15.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9a8a559c81686f576e8cd0290cd2a24a2a9ad80c98b3478856500fcbd7acd704"
dependencies = [
 "cfg-if 1.0.0",
 "fastrand",
 "getrandom 0.2.15",
 "once_cell",
 "rustix",
 "windows-sys 0.59.0",
]

[[package]]
name = "tentacle"
version = "0.6.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7a3374cb0b9cf25499dcb2e9ecf199af2f778b8d40dd01c413536de5b1574a2b"
dependencies = [
 "async-trait",
 "bytes",
 "futures",
 "httparse",
 "igd-next",
 "js-sys",
 "libc",
 "log",
 "molecule",
 "nohash-hasher",
 "parking_lot",
 "rand 0.8.5",
 "socket2",
 "tentacle-multiaddr",
 "tentacle-secio",
 "thiserror 1.0.69",
 "tokio",
 "tokio-tungstenite",
 "tokio-util",
 "tokio-yamux",
 "wasm-bindgen",
 "wasm-bindgen-futures",
 "winapi",
]

[[package]]
name = "tentacle-multiaddr"
version = "0.3.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8a9e71b28bf0bbf274b92f47cb2c5b42755d84a11e2246cf7bcb7b65c89483b9"
dependencies = [
 "bs58",
 "bytes",
 "serde",
 "sha2",
 "unsigned-varint",
]

[[package]]
name = "tentacle-secio"
version = "0.6.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "53d53673d63399e1d557c2e884b045d242811079d3b2f17a569310e5c3f1db33"
dependencies = [
 "bs58",
 "bytes",
 "chacha20poly1305",
 "futures",
 "getrandom 0.2.15",
 "hmac",
 "log",
 "molecule",
 "openssl",
 "openssl-sys",
 "rand 0.8.5",
 "rand_core 0.6.4",
 "ring",
 "secp256k1 0.30.0",
 "sha2",
 "tokio",
 "tokio-util",
 "unsigned-varint",
 "x25519-dalek",
]

[[package]]
name = "thiserror"
version = "1.0.69"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b6aaf5339b578ea85b50e080feb250a3e8ae8cfcdff9a461c9ec2904bc923f52"
dependencies = [
 "thiserror-impl 1.0.69",
]

[[package]]
name = "thiserror"
version = "2.0.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d452f284b73e6d76dd36758a0c8684b1d5be31f92b89d07fd5822175732206fc"
dependencies = [
 "thiserror-impl 2.0.11",
]

[[package]]
name = "thiserror-impl"
version = "1.0.69"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4fee6c4efc90059e10f81e6d42c60a18f76588c3d74cb83a0b242a2b6c7504c1"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "thiserror-impl"
version = "2.0.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "26afc1baea8a989337eeb52b6e72a039780ce45c3edfcc9c5b9d112feeb173c2"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "thread_local"
version = "1.1.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8b9ef9bad013ada3808854ceac7b46812a6465ba368859a37e2100283d2d719c"
dependencies = [
 "cfg-if 1.0.0",
 "once_cell",
]

[[package]]
name = "time"
version = "0.3.37"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "35e7868883861bd0e56d9ac6efcaaca0d6d5d82a2a7ec8209ff492c07cf37b21"
dependencies = [
 "deranged",
 "itoa",
 "num-conv",
 "powerfmt",
 "serde",
 "time-core",
 "time-macros",
]

[[package]]
name = "time-core"
version = "0.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ef927ca75afb808a4d64dd374f00a2adf8d0fcff8e7b184af886c3c87ec4a3f3"

[[package]]
name = "time-macros"
version = "0.2.19"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2834e6017e3e5e4b9834939793b282bc03b37a3336245fa820e35e233e2a85de"
dependencies = [
 "num-conv",
 "time-core",
]

[[package]]
name = "tiny-keccak"
version = "2.0.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2c9d3793400a45f954c52e73d068316d76b6f4e36977e3fcebb13a2721e80237"
dependencies = [
 "crunchy",
]

[[package]]
name = "tinystr"
version = "0.7.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9117f5d4db391c1cf6927e7bea3db74b9a1c1add8f7eda9ffd5364f40f57b82f"
dependencies = [
 "displaydoc",
 "zerovec",
]

[[package]]
name = "tinyvec"
version = "1.8.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "022db8904dfa342efe721985167e9fcd16c29b226db4397ed752a761cfce81e8"
dependencies = [
 "tinyvec_macros",
]

[[package]]
name = "tinyvec_macros"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1f3ccbac311fea05f86f61904b462b55fb3df8837a366dfc601a0161d0532f20"

[[package]]
name = "tokio"
version = "1.43.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3d61fa4ffa3de412bfea335c6ecff681de2b609ba3c77ef3e00e521813a9ed9e"
dependencies = [
 "backtrace",
 "bytes",
 "libc",
 "mio",
 "pin-project-lite",
 "signal-hook-registry",
 "socket2",
 "tokio-macros",
 "tracing",
 "windows-sys 0.52.0",
]

[[package]]
name = "tokio-io-timeout"
version = "1.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "30b74022ada614a1b4834de765f9bb43877f910cc8ce4be40e89042c9223a8bf"
dependencies = [
 "pin-project-lite",
 "tokio",
]

[[package]]
name = "tokio-macros"
version = "2.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6e06d43f1345a3bcd39f6a56dbb7dcab2ba47e68e8ac134855e7e2bdbaf8cab8"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "tokio-native-tls"
version = "0.3.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bbae76ab933c85776efabc971569dd6119c580d8f5d448769dec1764bf796ef2"
dependencies = [
 "native-tls",
 "tokio",
]

[[package]]
name = "tokio-openssl"
version = "0.6.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "59df6849caa43bb7567f9a36f863c447d95a11d5903c9cc334ba32576a27eadd"
dependencies = [
 "openssl",
 "openssl-sys",
 "tokio",
]

[[package]]
name = "tokio-stream"
version = "0.1.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "eca58d7bba4a75707817a2c44174253f9236b2d5fbd055602e9d5c07c139a047"
dependencies = [
 "futures-core",
 "pin-project-lite",
 "tokio",
 "tokio-util",
]

[[package]]
name = "tokio-tungstenite"
version = "0.26.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "be4bf6fecd69fcdede0ec680aaf474cdab988f9de6bc73d3758f0160e3b7025a"
dependencies = [
 "futures-util",
 "log",
 "tokio",
 "tungstenite",
]

[[package]]
name = "tokio-util"
version = "0.7.13"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d7fcaa8d55a2bdd6b83ace262b016eca0d79ee02818c5c1bcdf0305114081078"
dependencies = [
 "bytes",
 "futures-core",
 "futures-io",
 "futures-sink",
 "futures-util",
 "hashbrown 0.14.5",
 "pin-project-lite",
 "tokio",
]

[[package]]
name = "tokio-yamux"
version = "0.3.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "966579a01e6900c22634f5915fda56358496e71067f3dd26572f9fbe85f4b62e"
dependencies = [
 "bytes",
 "futures",
 "log",
 "nohash-hasher",
 "tokio",
 "tokio-util",
 "web-time",
]

[[package]]
name = "toml"
version = "0.5.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f4f7f0dd8d50a853a531c426359045b1998f04219d88799810762cd4ad314234"
dependencies = [
 "serde",
]

[[package]]
name = "toml_datetime"
version = "0.6.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0dd7358ecb8fc2f8d014bf86f6f638ce72ba252a2c3a2572f2a795f1d23efb41"

[[package]]
name = "toml_edit"
version = "0.22.22"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4ae48d6208a266e853d946088ed816055e556cc6028c5e8e2b84d9fa5dd7c7f5"
dependencies = [
 "indexmap 2.7.0",
 "toml_datetime",
 "winnow",
]

[[package]]
name = "tonic"
version = "0.7.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5be9d60db39854b30b835107500cf0aca0b0d14d6e1c3de124217c23a29c2ddb"
dependencies = [
 "async-stream",
 "async-trait",
 "axum 0.5.17",
 "base64 0.13.1",
 "bytes",
 "futures-core",
 "futures-util",
 "h2",
 "http 0.2.12",
 "http-body",
 "hyper",
 "hyper-timeout",
 "percent-encoding",
 "pin-project",
 "prost 0.10.4",
 "prost-derive 0.10.1",
 "tokio",
 "tokio-stream",
 "tokio-util",
 "tower",
 "tower-layer",
 "tower-service",
 "tracing",
 "tracing-futures",
]

[[package]]
name = "tonic"
version = "0.11.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "76c4eb7a4e9ef9d4763600161f12f5070b92a578e1b634db88a6887844c91a13"
dependencies = [
 "async-stream",
 "async-trait",
 "axum 0.6.20",
 "base64 0.21.7",
 "bytes",
 "h2",
 "http 0.2.12",
 "http-body",
 "hyper",
 "hyper-timeout",
 "percent-encoding",
 "pin-project",
 "prost 0.12.6",
 "tokio",
 "tokio-stream",
 "tower",
 "tower-layer",
 "tower-service",
 "tracing",
]

[[package]]
name = "tonic-build"
version = "0.11.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "be4ef6dd70a610078cb4e338a0f79d06bc759ff1b22d2120c2ff02ae264ba9c2"
dependencies = [
 "prettyplease",
 "proc-macro2",
 "prost-build",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "tonic-openssl"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cc64bfb2812f4311055de425e65745229551438db6add3815b489770da3b906d"
dependencies = [
 "async-stream",
 "futures",
 "openssl",
 "tokio",
 "tokio-openssl",
 "tonic 0.7.2",
]

[[package]]
name = "tower"
version = "0.4.13"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b8fa9be0de6cf49e536ce1851f987bd21a43b771b09473c3549a6c853db37c1c"
dependencies = [
 "futures-core",
 "futures-util",
 "indexmap 1.9.3",
 "pin-project",
 "pin-project-lite",
 "rand 0.8.5",
 "slab",
 "tokio",
 "tokio-util",
 "tower-layer",
 "tower-service",
 "tracing",
]

[[package]]
name = "tower-http"
version = "0.3.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f873044bf02dd1e8239e9c1293ea39dad76dc594ec16185d0a1bf31d8dc8d858"
dependencies = [
 "bitflags 1.3.2",
 "bytes",
 "futures-core",
 "futures-util",
 "http 0.2.12",
 "http-body",
 "http-range-header",
 "pin-project-lite",
 "tower",
 "tower-layer",
 "tower-service",
]

[[package]]
name = "tower-layer"
version = "0.3.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "121c2a6cda46980bb0fcd1647ffaf6cd3fc79a013de288782836f6df9c48780e"

[[package]]
name = "tower-service"
version = "0.3.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8df9b6e13f2d32c91b9bd719c00d1958837bc7dec474d94952798cc8e69eeec3"

[[package]]
name = "tracing"
version = "0.1.41"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "784e0ac535deb450455cbfa28a6f0df145ea1bb7ae51b821cf5e7927fdcfbdd0"
dependencies = [
 "log",
 "pin-project-lite",
 "tracing-attributes",
 "tracing-core",
]

[[package]]
name = "tracing-attributes"
version = "0.1.28"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "395ae124c09f9e6918a2310af6038fba074bcf474ac352496d5910dd59a2226d"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "tracing-core"
version = "0.1.33"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e672c95779cf947c5311f83787af4fa8fffd12fb27e4993211a84bdfd9610f9c"
dependencies = [
 "once_cell",
 "valuable",
]

[[package]]
name = "tracing-futures"
version = "0.2.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "97d095ae15e245a057c8e8451bab9b3ee1e1f68e9ba2b4fbc18d0ac5237835f2"
dependencies = [
 "pin-project",
 "tracing",
]

[[package]]
name = "tracing-log"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ee855f1f400bd0e5c02d150ae5de3840039a3f54b025156404e34c23c03f47c3"
dependencies = [
 "log",
 "once_cell",
 "tracing-core",
]

[[package]]
name = "tracing-subscriber"
version = "0.3.19"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e8189decb5ac0fa7bc8b96b7cb9b2701d60d48805aca84a238004d665fcc4008"
dependencies = [
 "matchers",
 "nu-ansi-term",
 "once_cell",
 "regex",
 "sharded-slab",
 "smallvec",
 "thread_local",
 "tracing",
 "tracing-core",
 "tracing-log",
]

[[package]]
name = "try-lock"
version = "0.2.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e421abadd41a4225275504ea4d6566923418b7f05506fbc9c0fe86ba7396114b"

[[package]]
name = "tungstenite"
version = "0.26.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "413083a99c579593656008130e29255e54dcaae495be556cc26888f211648c24"
dependencies = [
 "byteorder",
 "bytes",
 "data-encoding",
 "http 1.2.0",
 "httparse",
 "log",
 "rand 0.8.5",
 "sha1",
 "thiserror 2.0.11",
 "utf-8",
]

[[package]]
name = "typenum"
version = "1.17.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "42ff0bf0c66b8238c6f3b578df37d0b7848e55df8577b3f74f92a69acceeb825"

[[package]]
name = "unicode-ident"
version = "1.0.14"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "adb9e6ca4f869e1180728b7950e35922a7fc6397f7b641499e8f3ef06e50dc83"

[[package]]
name = "unicode-width"
version = "0.1.14"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7dd6e30e90baa6f72411720665d41d89b9a3d039dc45b8faea1ddd07f617f6af"

[[package]]
name = "unicode-width"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1fc81956842c57dac11422a97c3b8195a1ff727f06e85c84ed2e8aa277c9a0fd"

[[package]]
name = "universal-hash"
version = "0.5.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fc1de2c688dc15305988b563c3854064043356019f97a4b46276fe734c4f07ea"
dependencies = [
 "crypto-common",
 "subtle",
]

[[package]]
name = "unsafe-libyaml"
version = "0.2.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "673aac59facbab8a9007c7f6108d11f63b603f7cabff99fabf650fea5c32b861"

[[package]]
name = "unsigned-varint"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "eb066959b24b5196ae73cb057f45598450d2c5f71460e98c49b738086eff9c06"

[[package]]
name = "untrusted"
version = "0.9.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8ecb6da28b8a351d773b68d5825ac39017e680750f980f3a1a85cd8dd28a47c1"

[[package]]
name = "url"
version = "2.5.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "32f8b686cadd1473f4bd0117a5d28d36b1ade384ea9b5069a1c40aefed7fda60"
dependencies = [
 "form_urlencoded",
 "idna",
 "percent-encoding",
]

[[package]]
name = "utf-8"
version = "0.7.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "09cc8ee72d2a9becf2f2febe0205bbed8fc6615b7cb429ad062dc7b7ddd036a9"

[[package]]
name = "utf16_iter"
version = "1.0.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c8232dd3cdaed5356e0f716d285e4b40b932ac434100fe9b7e0e8e935b9e6246"

[[package]]
name = "utf8_iter"
version = "1.0.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b6c140620e7ffbb22c2dee59cafe6084a59b5ffc27a8859a5f0d494b5d52b6be"

[[package]]
name = "utf8parse"
version = "0.2.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "06abde3611657adf66d383f00b093d7faecc7fa57071cce2578660c9f1010821"

[[package]]
name = "valuable"
version = "0.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "830b7e5d4d90034032940e4ace0d9a9a057e7a45cd94e6c007832e39edb82f6d"

[[package]]
name = "vcpkg"
version = "0.2.15"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "accd4ea62f7bb7a82fe23066fb0957d48ef677f6eeb8215f372f52e48bb32426"

[[package]]
name = "version_check"
version = "0.9.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0b928f33d975fc6ad9f86c8f283853ad26bdd5b10b7f1542aa2fa15e2289105a"

[[package]]
name = "walkdir"
version = "2.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "29790946404f91d9c5d06f9874efddea1dc06c5efe94541a7d6863108e3a5e4b"
dependencies = [
 "same-file",
 "winapi-util",
]

[[package]]
name = "want"
version = "0.3.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bfa7760aed19e106de2c7c0b581b509f2f25d3dacaf737cb82ac61bc6d760b0e"
dependencies = [
 "try-lock",
]

[[package]]
name = "wasi"
version = "0.9.0+wasi-snapshot-preview1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cccddf32554fecc6acb585f82a32a72e28b48f8c4c1883ddfeeeaa96f7d8e519"

[[package]]
name = "wasi"
version = "0.11.0+wasi-snapshot-preview1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9c8d87e72b64a3b4db28d11ce29237c246188f4f51057d65a7eab63b7987e423"

[[package]]
name = "wasm-bindgen"
version = "0.2.100"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1edc8929d7499fc4e8f0be2262a241556cfc54a0bea223790e71446f2aab1ef5"
dependencies = [
 "cfg-if 1.0.0",
 "once_cell",
 "rustversion",
 "wasm-bindgen-macro",
]

[[package]]
name = "wasm-bindgen-backend"
version = "0.2.100"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2f0a0651a5c2bc21487bde11ee802ccaf4c51935d0d3d42a6101f98161700bc6"
dependencies = [
 "bumpalo",
 "log",
 "proc-macro2",
 "quote",
 "syn 2.0.96",
 "wasm-bindgen-shared",
]

[[package]]
name = "wasm-bindgen-futures"
version = "0.4.50"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "555d470ec0bc3bb57890405e5d4322cc9ea83cebb085523ced7be4144dac1e61"
dependencies = [
 "cfg-if 1.0.0",
 "js-sys",
 "once_cell",
 "wasm-bindgen",
 "web-sys",
]

[[package]]
name = "wasm-bindgen-macro"
version = "0.2.100"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7fe63fc6d09ed3792bd0897b314f53de8e16568c2b3f7982f468c0bf9bd0b407"
dependencies = [
 "quote",
 "wasm-bindgen-macro-support",
]

[[package]]
name = "wasm-bindgen-macro-support"
version = "0.2.100"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8ae87ea40c9f689fc23f209965b6fb8a99ad69aeeb0231408be24920604395de"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
 "wasm-bindgen-backend",
 "wasm-bindgen-shared",
]

[[package]]
name = "wasm-bindgen-shared"
version = "0.2.100"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1a05d73b933a847d6cccdda8f838a22ff101ad9bf93e33684f39c1f5f0eece3d"
dependencies = [
 "unicode-ident",
]

[[package]]
name = "web-sys"
version = "0.3.77"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "33b6dd2ef9186f1f2072e409e99cd22a975331a6b3591b12c764e0e55c60d5d2"
dependencies = [
 "js-sys",
 "wasm-bindgen",
]

[[package]]
name = "web-time"
version = "1.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5a6580f308b1fad9207618087a65c04e7a10bc77e02c8e84e9b00dd4b12fa0bb"
dependencies = [
 "js-sys",
 "wasm-bindgen",
]

[[package]]
name = "which"
version = "4.4.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "87ba24419a2078cd2b0f2ede2691b6c66d8e47836da3b6db8265ebad47afbfc7"
dependencies = [
 "either",
 "home",
 "once_cell",
 "rustix",
]

[[package]]
name = "winapi"
version = "0.3.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5c839a674fcd7a98952e593242ea400abe93992746761e38641405d28b00f419"
dependencies = [
 "winapi-i686-pc-windows-gnu",
 "winapi-x86_64-pc-windows-gnu",
]

[[package]]
name = "winapi-i686-pc-windows-gnu"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ac3b87c63620426dd9b991e5ce0329eff545bccbbb34f3be09ff6fb6ab51b7b6"

[[package]]
name = "winapi-util"
version = "0.1.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cf221c93e13a30d793f7645a0e7762c55d169dbb0a49671918a2319d289b10bb"
dependencies = [
 "windows-sys 0.59.0",
]

[[package]]
name = "winapi-x86_64-pc-windows-gnu"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "712e227841d057c1ee1cd2fb22fa7e5a5461ae8e48fa2ca79ec42cfc1931183f"

[[package]]
name = "windows"
version = "0.59.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7f919aee0a93304be7f62e8e5027811bbba96bcb1de84d6618be56e43f8a32a1"
dependencies = [
 "windows-core 0.59.0",
 "windows-targets 0.53.0",
]

[[package]]
name = "windows-core"
version = "0.52.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "33ab640c8d7e35bf8ba19b884ba838ceb4fba93a4e8c65a9059d08afcfc683d9"
dependencies = [
 "windows-targets 0.52.6",
]

[[package]]
name = "windows-core"
version = "0.59.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "810ce18ed2112484b0d4e15d022e5f598113e220c53e373fb31e67e21670c1ce"
dependencies = [
 "windows-implement",
 "windows-interface",
 "windows-result",
 "windows-strings",
 "windows-targets 0.53.0",
]

[[package]]
name = "windows-implement"
version = "0.59.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "83577b051e2f49a058c308f17f273b570a6a758386fc291b5f6a934dd84e48c1"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "windows-interface"
version = "0.59.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cb26fd936d991781ea39e87c3a27285081e3c0da5ca0fcbc02d368cc6f52ff01"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "windows-result"
version = "0.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d08106ce80268c4067c0571ca55a9b4e9516518eaa1a1fe9b37ca403ae1d1a34"
dependencies = [
 "windows-targets 0.53.0",
]

[[package]]
name = "windows-strings"
version = "0.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b888f919960b42ea4e11c2f408fadb55f78a9f236d5eef084103c8ce52893491"
dependencies = [
 "windows-targets 0.53.0",
]

[[package]]
name = "windows-sys"
version = "0.48.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "677d2418bec65e3338edb076e806bc1ec15693c5d0104683f2efe857f61056a9"
dependencies = [
 "windows-targets 0.48.5",
]

[[package]]
name = "windows-sys"
version = "0.52.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "282be5f36a8ce781fad8c8ae18fa3f9beff57ec1b52cb3de0789201425d9a33d"
dependencies = [
 "windows-targets 0.52.6",
]

[[package]]
name = "windows-sys"
version = "0.59.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1e38bc4d79ed67fd075bcc251a1c39b32a1776bbe92e5bef1f0bf1f8c531853b"
dependencies = [
 "windows-targets 0.52.6",
]

[[package]]
name = "windows-targets"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9a2fa6e2155d7247be68c096456083145c183cbbbc2764150dda45a87197940c"
dependencies = [
 "windows_aarch64_gnullvm 0.48.5",
 "windows_aarch64_msvc 0.48.5",
 "windows_i686_gnu 0.48.5",
 "windows_i686_msvc 0.48.5",
 "windows_x86_64_gnu 0.48.5",
 "windows_x86_64_gnullvm 0.48.5",
 "windows_x86_64_msvc 0.48.5",
]

[[package]]
name = "windows-targets"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9b724f72796e036ab90c1021d4780d4d3d648aca59e491e6b98e725b84e99973"
dependencies = [
 "windows_aarch64_gnullvm 0.52.6",
 "windows_aarch64_msvc 0.52.6",
 "windows_i686_gnu 0.52.6",
 "windows_i686_gnullvm 0.52.6",
 "windows_i686_msvc 0.52.6",
 "windows_x86_64_gnu 0.52.6",
 "windows_x86_64_gnullvm 0.52.6",
 "windows_x86_64_msvc 0.52.6",
]

[[package]]
name = "windows-targets"
version = "0.53.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b1e4c7e8ceaaf9cb7d7507c974735728ab453b67ef8f18febdd7c11fe59dca8b"
dependencies = [
 "windows_aarch64_gnullvm 0.53.0",
 "windows_aarch64_msvc 0.53.0",
 "windows_i686_gnu 0.53.0",
 "windows_i686_gnullvm 0.53.0",
 "windows_i686_msvc 0.53.0",
 "windows_x86_64_gnu 0.53.0",
 "windows_x86_64_gnullvm 0.53.0",
 "windows_x86_64_msvc 0.53.0",
]

[[package]]
name = "windows_aarch64_gnullvm"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2b38e32f0abccf9987a4e3079dfb67dcd799fb61361e53e2882c3cbaf0d905d8"

[[package]]
name = "windows_aarch64_gnullvm"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "32a4622180e7a0ec044bb555404c800bc9fd9ec262ec147edd5989ccd0c02cd3"

[[package]]
name = "windows_aarch64_gnullvm"
version = "0.53.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "86b8d5f90ddd19cb4a147a5fa63ca848db3df085e25fee3cc10b39b6eebae764"

[[package]]
name = "windows_aarch64_msvc"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "dc35310971f3b2dbbf3f0690a219f40e2d9afcf64f9ab7cc1be722937c26b4bc"

[[package]]
name = "windows_aarch64_msvc"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "09ec2a7bb152e2252b53fa7803150007879548bc709c039df7627cabbd05d469"

[[package]]
name = "windows_aarch64_msvc"
version = "0.53.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c7651a1f62a11b8cbd5e0d42526e55f2c99886c77e007179efff86c2b137e66c"

[[package]]
name = "windows_i686_gnu"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a75915e7def60c94dcef72200b9a8e58e5091744960da64ec734a6c6e9b3743e"

[[package]]
name = "windows_i686_gnu"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8e9b5ad5ab802e97eb8e295ac6720e509ee4c243f69d781394014ebfe8bbfa0b"

[[package]]
name = "windows_i686_gnu"
version = "0.53.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c1dc67659d35f387f5f6c479dc4e28f1d4bb90ddd1a5d3da2e5d97b42d6272c3"

[[package]]
name = "windows_i686_gnullvm"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0eee52d38c090b3caa76c563b86c3a4bd71ef1a819287c19d586d7334ae8ed66"

[[package]]
name = "windows_i686_gnullvm"
version = "0.53.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9ce6ccbdedbf6d6354471319e781c0dfef054c81fbc7cf83f338a4296c0cae11"

[[package]]
name = "windows_i686_msvc"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8f55c233f70c4b27f66c523580f78f1004e8b5a8b659e05a4eb49d4166cca406"

[[package]]
name = "windows_i686_msvc"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "240948bc05c5e7c6dabba28bf89d89ffce3e303022809e73deaefe4f6ec56c66"

[[package]]
name = "windows_i686_msvc"
version = "0.53.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "581fee95406bb13382d2f65cd4a908ca7b1e4c2f1917f143ba16efe98a589b5d"

[[package]]
name = "windows_x86_64_gnu"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "53d40abd2583d23e4718fddf1ebec84dbff8381c07cae67ff7768bbf19c6718e"

[[package]]
name = "windows_x86_64_gnu"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "147a5c80aabfbf0c7d901cb5895d1de30ef2907eb21fbbab29ca94c5b08b1a78"

[[package]]
name = "windows_x86_64_gnu"
version = "0.53.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2e55b5ac9ea33f2fc1716d1742db15574fd6fc8dadc51caab1c16a3d3b4190ba"

[[package]]
name = "windows_x86_64_gnullvm"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0b7b52767868a23d5bab768e390dc5f5c55825b6d30b86c844ff2dc7414044cc"

[[package]]
name = "windows_x86_64_gnullvm"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "24d5b23dc417412679681396f2b49f3de8c1473deb516bd34410872eff51ed0d"

[[package]]
name = "windows_x86_64_gnullvm"
version = "0.53.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0a6e035dd0599267ce1ee132e51c27dd29437f63325753051e71dd9e42406c57"

[[package]]
name = "windows_x86_64_msvc"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ed94fce61571a4006852b7389a063ab983c02eb1bb37b47f8272ce92d06d9538"

[[package]]
name = "windows_x86_64_msvc"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "589f6da84c646204747d1270a2a5661ea66ed1cced2631d546fdfb155959f9ec"

[[package]]
name = "windows_x86_64_msvc"
version = "0.53.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "271414315aff87387382ec3d271b52d7ae78726f5d44ac98b4f4030c91880486"

[[package]]
name = "winnow"
version = "0.6.24"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c8d71a593cc5c42ad7876e2c1fda56f314f3754c084128833e64f1345ff8a03a"
dependencies = [
 "memchr",
]

[[package]]
name = "winreg"
version = "0.50.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "524e57b2c537c0f9b1e69f1965311ec12182b4122e45035b1508cd24d2adadb1"
dependencies = [
 "cfg-if 1.0.0",
 "windows-sys 0.48.0",
]

[[package]]
name = "write16"
version = "1.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d1890f4022759daae28ed4fe62859b1236caebfc61ede2f63ed4e695f3f6d936"

[[package]]
name = "writeable"
version = "0.5.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1e9df38ee2d2c3c5948ea468a8406ff0db0b29ae1ffde1bcf20ef305bcc95c51"

[[package]]
name = "x25519-dalek"
version = "2.0.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c7e468321c81fb07fa7f4c636c3972b9100f0346e5b6a9f2bd0603a52f7ed277"
dependencies = [
 "curve25519-dalek",
 "rand_core 0.6.4",
 "serde",
 "zeroize",
]

[[package]]
name = "xml-rs"
version = "0.8.25"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c5b940ebc25896e71dd073bad2dbaa2abfe97b0a391415e22ad1326d9c54e3c4"

[[package]]
name = "xmltree"
version = "0.10.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d7d8a75eaf6557bb84a65ace8609883db44a29951042ada9b393151532e41fcb"
dependencies = [
 "xml-rs",
]

[[package]]
name = "xxhash-rust"
version = "0.8.15"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fdd20c5420375476fbd4394763288da7eb0cc0b8c11deed431a91562af7335d3"

[[package]]
name = "yoke"
version = "0.7.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "120e6aef9aa629e3d4f52dc8cc43a015c7724194c97dfaf45180d2daf2b77f40"
dependencies = [
 "serde",
 "stable_deref_trait",
 "yoke-derive",
 "zerofrom",
]

[[package]]
name = "yoke-derive"
version = "0.7.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2380878cad4ac9aac1e2435f3eb4020e8374b5f13c296cb75b4620ff8e229154"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
 "synstructure",
]

[[package]]
name = "zerocopy"
version = "0.7.35"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1b9b4fd18abc82b8136838da5d50bae7bdea537c574d8dc1a34ed098d6c166f0"
dependencies = [
 "byteorder",
 "zerocopy-derive",
]

[[package]]
name = "zerocopy-derive"
version = "0.7.35"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fa4f8080344d4671fb4e831a13ad1e68092748387dfc4f55e356242fae12ce3e"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "zerofrom"
version = "0.1.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cff3ee08c995dee1859d998dea82f7374f2826091dd9cd47def953cae446cd2e"
dependencies = [
 "zerofrom-derive",
]

[[package]]
name = "zerofrom-derive"
version = "0.1.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "595eed982f7d355beb85837f651fa22e90b3c044842dc7f2c2842c086f295808"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
 "synstructure",
]

[[package]]
name = "zeroize"
version = "1.8.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ced3678a2879b30306d323f4542626697a464a97c0a07c9aebf7ebca65cd4dde"
dependencies = [
 "zeroize_derive",
]

[[package]]
name = "zeroize_derive"
version = "1.4.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ce36e65b0d2999d2aafac989fb249189a141aee1f53c612c1f37d72631959f69"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]

[[package]]
name = "zerovec"
version = "0.10.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "aa2b893d79df23bfb12d5461018d408ea19dfafe76c2c7ef6d4eba614f8ff079"
dependencies = [
 "yoke",
 "zerofrom",
 "zerovec-derive",
]

[[package]]
name = "zerovec-derive"
version = "0.10.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6eafa6dfb17584ea3e2bd6e76e0cc15ad7af12b09abdd1ca55961bed9b1063c6"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.96",
]


================================================
File: migrate/Cargo.toml
================================================
[package]
name = "fnn-migrate"
version = "0.3.0"
edition = "2021"
build = "build.rs"

[dependencies]
rocksdb = { package = "ckb-rocksdb", version = "=0.21.1", features = [
    "lz4"
], default-features = false }

tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
indicatif = "0.16"
console = "0.15.8"
bincode = "1.3.3"
thiserror = "1.0.58"
serde = { version = "1.0.197", features = ["derive"] }
hex = "0.4.3"
clap = { version = "4.0", features = ["derive"] }
fiber = { package = "fnn", path = "../" }
serde_json = "1.0.135"

fiber_v020 = { package = "fnn", git = "https://github.com/nervosnetwork/fiber.git", tag = "v0.2.0" }
fiber_v021 = { package = "fnn", git = "https://github.com/nervosnetwork/fiber.git", tag = "v0.2.1" }
fiber_v030 = { package = "fnn", git = "https://github.com/nervosnetwork/fiber.git", tag = "v0.3.0-rc1" }
fiber_v031 = { package = "fnn", git = "https://github.com/nervosnetwork/fiber.git", tag = "v0.3.1" }
fiber_v032 = { package = "fnn", git = "https://github.com/chenyukang/fiber.git", branch = "yukang-fix-480-keep-fail-tlc"}

[features]
default = []
portable = ["rocksdb/portable"]


================================================
File: migrate/build.rs
================================================
use std::env;
use std::fs;
use std::path::Path;

fn main() {
    println!("cargo:rerun-if-changed=src/migrations");

    let out_dir = env::var("OUT_DIR").unwrap();
    let dest_path = Path::new(&out_dir).join("migrations.rs");

    let migrations_dir = Path::new("src/migrations");
    let mut migrations = Vec::new();

    for entry in fs::read_dir(migrations_dir).unwrap() {
        let entry = entry.unwrap();
        let path = entry.path();
        if path.is_file() {
            if let Some(stem) = path.file_stem() {
                if let Some(stem_str) = stem.to_str() {
                    if stem_str == "sample" || stem_str == "mod" {
                        continue;
                    }
                    migrations.push(stem_str.to_string());
                }
            }
        }
    }

    let mut code = String::new();
    code.push_str("pub fn add_migrations(db_migrate: &mut DbMigrate) {\n");

    for migration in migrations {
        code.push_str(&format!(
            "    db_migrate.add_migration(Arc::new({}::MigrationObj::new()));\n",
            migration
        ));
    }

    code.push_str("}\n");

    fs::write(dest_path, code).unwrap();
}


================================================
File: migrate/src/lib.rs
================================================
pub mod migrations;
pub mod util;


================================================
File: migrate/src/main.rs
================================================
use clap::Parser;
use fiber::store::db_migrate::DbMigrate;
use fnn_migrate::migrations::*;
use fnn_migrate::util::prompt;
use rocksdb::ops::Open;
use rocksdb::{DBCompressionType, Options, DB};
use std::path::Path;
use std::process::exit;
use std::{cmp::Ordering, sync::Arc};
use tracing::error;
use tracing_subscriber;

include!(concat!(env!("OUT_DIR"), "/migrations.rs"));

fn init_db_migrate(db: Arc<DB>) -> DbMigrate {
    let mut db_migrate = DbMigrate::new(db);
    add_migrations(&mut db_migrate);
    db_migrate
}

fn open_db(path: &Path) -> Result<Arc<DB>, String> {
    let mut options = Options::default();
    options.create_if_missing(false);
    options.set_compression_type(DBCompressionType::Lz4);
    let db = Arc::new(DB::open(&options, path).map_err(|e| e.to_string())?);
    Ok(db)
}

#[derive(Parser, Debug)]
#[command(author, version, about, long_about = None)]
struct Args {
    /// Path to the database
    #[arg(short, long)]
    path: String,

    /// Skip confirmation prompts
    #[arg(short, long, default_value_t = false)]
    skip_confirm: bool,
}

fn run_migrate<P: AsRef<Path>>(
    migrate: DbMigrate,
    path: P,
    skip_confirm: bool,
) -> Result<Arc<DB>, String> {
    if let Err(_) = migrate.init_or_check(path.as_ref()) {
        let result = migrate.check();
        if result == Ordering::Less {
            if !skip_confirm {
                let path_buf = path.as_ref().to_path_buf();
                let input = prompt(format!("\
                     Once the migration started, the data will be no longer compatible with all older version,\n\
                     so we strongly recommended you to backup the old data {} before migrating.\n\
                     \n\
                     \nIf you want to migrate the data, please input YES, otherwise, the current process will exit.\n\
                     > ", path_buf.display()).as_str());

                if input.trim().to_lowercase() != "yes" {
                    error!("Migration was declined since the user didn't confirm.");
                    return Err("need to run database migration".to_string());
                }
            }
            eprintln!("begin to migrate db ...");
            let db = migrate.migrate().expect("failed to migrate db");
            eprintln!("db migrated successfully, now your can restart the fiber node ...");
            return Ok(db);
        } else {
            assert_eq!(result, Ordering::Greater);
            return Err("incompatible database, need to upgrade fiber binary".to_string());
        }
    }
    Ok(migrate.db())
}

fn main() {
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::DEBUG)
        .with_target(false)
        .init();

    let args = Args::parse();
    let path = Path::new(&args.path);
    let skip_confirm = args.skip_confirm;

    let db = open_db(path).expect("failed to open db");
    let migrate = init_db_migrate(db);
    if let Err(err) = run_migrate(migrate, path, skip_confirm) {
        eprintln!("{}", err);
        exit(1);
    }
}


================================================
File: migrate/src/util.rs
================================================
use serde::{Deserialize, Serialize};
use std::io::{stdin, stdout, Write};

pub(crate) fn convert<Old, New>(old: Old) -> New
where
    Old: Serialize,
    New: for<'de> Deserialize<'de>,
{
    let buf = bincode::serialize(&old).unwrap();
    let new_value: New = bincode::deserialize(&buf).expect("deserialize to new state");
    new_value
}

pub fn prompt(msg: &str) -> String {
    let stdout = stdout();
    let mut stdout = stdout.lock();
    let stdin = stdin();

    write!(stdout, "{msg}").unwrap();
    stdout.flush().unwrap();

    let mut input = String::new();
    let _ = stdin.read_line(&mut input);

    input
}


================================================
File: migrate/src/migrations/mig_20250114.rs
================================================
use fiber::{store::migration::Migration, Error};
use indicatif::ProgressBar;
use rocksdb::ops::Iterate;
use rocksdb::ops::Put;
use rocksdb::DB;
use std::sync::Arc;
use tracing::info;

const MIGRATION_DB_VERSION: &str = "20250112205923";

use crate::util::convert;
pub use fiber_v020::fiber::channel::ChannelActorState as ChannelActorStateV020;
pub use fiber_v021::fiber::channel::ChannelActorState as ChannelActorStateV021;
pub use fiber_v030::fiber::channel::ChannelActorState as ChannelActorStateV030;

pub struct MigrationObj {
    version: String,
}

impl MigrationObj {
    pub fn new() -> Self {
        Self {
            version: MIGRATION_DB_VERSION.to_string(),
        }
    }
}

impl Migration for MigrationObj {
    fn migrate(
        &self,
        db: Arc<DB>,
        _pb: Arc<dyn Fn(u64) -> ProgressBar + Send + Sync>,
    ) -> Result<Arc<DB>, Error> {
        info!(
            "MigrationObj::migrate to {} ...........",
            MIGRATION_DB_VERSION
        );

        const CHANNEL_ACTOR_STATE_PREFIX: u8 = 0;
        let prefix = vec![CHANNEL_ACTOR_STATE_PREFIX];

        for (k, v) in db
            .prefix_iterator(prefix.as_slice())
            .take_while(move |(col_key, _)| col_key.starts_with(prefix.as_slice()))
        {
            // there maybe some existing nodes didn't set correct db version,
            // if we can deserialize the data correctly, just skip it.
            if let Ok(_) = bincode::deserialize::<ChannelActorStateV030>(&v) {
                continue;
            }

            if let Ok(_) = bincode::deserialize::<ChannelActorStateV021>(&v) {
                continue;
            }

            let old_channel_state: ChannelActorStateV020 =
                bincode::deserialize(&v).expect("deserialize to old channel state");

            let mut all_remote_nonces = old_channel_state.remote_nonces.clone();
            all_remote_nonces.sort_by(|a, b| b.0.cmp(&a.0));
            let last_committed_remote_nonce =
                all_remote_nonces.get(0).map(|(_, nonce)| nonce).cloned();

            // Depending on whether the receiver has received our RevokeAndAck message or not,
            // we need to set different last_revoke_and_ack_remote_nonce.
            // 1. The receiver has received our RevokeAndAck message.
            //    In this case, the last_revoke_and_ack_remote_nonce should be the remote nonce
            //    with the largest commitment number.
            // 2. The receiver has not received our RevokeAndAck message.
            //    In this case, the last_revoke_and_ack_remote_nonce should be the remote nonce
            //    with the second largest commitment number.
            // We can't determine which case is true unless we receive a Reestablish message from the peer,
            // which contains the remote's view on the last commitment number.
            // So this migration is not perfect, but it's the best we can do.
            let last_revoke_and_ack_remote_nonce =
                all_remote_nonces.get(0).map(|(_, nonce)| nonce).cloned();

            let new_channel_state = ChannelActorStateV021 {
                state: convert(old_channel_state.state),
                public_channel_info: old_channel_state
                    .public_channel_info
                    .map(|info| convert(info)),
                local_pubkey: convert(old_channel_state.local_pubkey),
                remote_pubkey: convert(old_channel_state.remote_pubkey),
                id: convert(old_channel_state.id),
                funding_tx: old_channel_state.funding_tx,
                funding_tx_confirmed_at: old_channel_state.funding_tx_confirmed_at,
                funding_udt_type_script: old_channel_state.funding_udt_type_script,
                is_acceptor: old_channel_state.is_acceptor,
                to_local_amount: old_channel_state.to_local_amount,
                to_remote_amount: old_channel_state.to_remote_amount,
                local_reserved_ckb_amount: old_channel_state.local_reserved_ckb_amount,
                remote_reserved_ckb_amount: old_channel_state.remote_reserved_ckb_amount,
                commitment_fee_rate: old_channel_state.commitment_fee_rate,
                commitment_delay_epoch: old_channel_state.commitment_delay_epoch,
                funding_fee_rate: old_channel_state.funding_fee_rate,
                signer: convert(old_channel_state.signer),
                local_channel_public_keys: convert(old_channel_state.local_channel_public_keys),
                commitment_numbers: convert(old_channel_state.commitment_numbers),
                local_constraints: convert(old_channel_state.local_constraints),
                remote_constraints: convert(old_channel_state.remote_constraints),
                tlc_state: convert(old_channel_state.tlc_state),
                remote_shutdown_script: old_channel_state.remote_shutdown_script,
                local_shutdown_script: old_channel_state.local_shutdown_script,
                // ++++++++ new fields +++++++++++
                last_commitment_signed_remote_nonce: old_channel_state
                    .last_used_nonce_in_commitment_signed,
                last_revoke_and_ack_remote_nonce,
                last_committed_remote_nonce,
                // --------- new fields ----------
                latest_commitment_transaction: old_channel_state.latest_commitment_transaction,
                remote_commitment_points: convert(old_channel_state.remote_commitment_points),
                remote_channel_public_keys: convert(old_channel_state.remote_channel_public_keys),
                local_shutdown_info: convert(old_channel_state.local_shutdown_info),
                remote_shutdown_info: convert(old_channel_state.remote_shutdown_info),
                reestablishing: old_channel_state.reestablishing,
                created_at: old_channel_state.created_at,
            };

            let new_channel_state_bytes =
                bincode::serialize(&new_channel_state).expect("serialize to new channel state");
            db.put(k, new_channel_state_bytes)
                .expect("save new channel state");
        }
        Ok(db)
    }

    fn version(&self) -> &str {
        &self.version
    }
}


================================================
File: migrate/src/migrations/mig_20250115.rs
================================================
use fiber::{
    fiber::config::{
        DEFAULT_TLC_EXPIRY_DELTA, DEFAULT_TLC_FEE_PROPORTIONAL_MILLIONTHS, DEFAULT_TLC_MAX_VALUE,
        DEFAULT_TLC_MIN_VALUE,
    },
    now_timestamp_as_millis_u64,
    store::migration::Migration,
    Error,
};
use indicatif::ProgressBar;
use rocksdb::ops::Iterate;
use rocksdb::ops::Put;
use rocksdb::DB;
use std::sync::Arc;
use tracing::info;

const MIGRATION_DB_VERSION: &str = "20250115051223";

pub use fiber_v030::fiber::channel::{
    ChannelTlcInfo as ChannelTlcInfoV030, PublicChannelInfo as PublicChannelInfoV030,
};

pub use fiber_v021::fiber::channel::ChannelActorState as ChannelActorStateV021;
pub use fiber_v030::fiber::channel::ChannelActorState as ChannelActorStateV030;

use crate::util::convert;

pub struct MigrationObj {
    version: String,
}

impl MigrationObj {
    pub fn new() -> Self {
        Self {
            version: MIGRATION_DB_VERSION.to_string(),
        }
    }
}

impl Migration for MigrationObj {
    fn migrate(
        &self,
        db: Arc<DB>,
        _pb: Arc<dyn Fn(u64) -> ProgressBar + Send + Sync>,
    ) -> Result<Arc<DB>, Error> {
        info!(
            "MigrationObj::migrate to {} ...........",
            MIGRATION_DB_VERSION
        );

        const CHANNEL_ACTOR_STATE_PREFIX: u8 = 0;
        let prefix = vec![CHANNEL_ACTOR_STATE_PREFIX];

        for (k, v) in db
            .prefix_iterator(prefix.as_slice())
            .take_while(move |(col_key, _)| col_key.starts_with(prefix.as_slice()))
        {
            if let Ok(_) = bincode::deserialize::<ChannelActorStateV030>(&v) {
                // there maybe some node didn't set correct db version,
                // if we can deserialize the data correctly, just skip it.
                continue;
            }

            let old_channel_state: ChannelActorStateV021 =
                bincode::deserialize(&v).expect("deserialize to old channel state");

            let now_timestamp = now_timestamp_as_millis_u64();
            let local_tlc_info = match old_channel_state.public_channel_info {
                Some(ref info) => ChannelTlcInfoV030 {
                    timestamp: now_timestamp,
                    enabled: info.enabled,
                    tlc_fee_proportional_millionths: info.tlc_fee_proportional_millionths,
                    tlc_expiry_delta: info.tlc_expiry_delta,
                    tlc_minimum_value: info.tlc_min_value,
                    tlc_maximum_value: DEFAULT_TLC_MAX_VALUE,
                },
                None => ChannelTlcInfoV030 {
                    timestamp: now_timestamp,
                    enabled: true,
                    tlc_fee_proportional_millionths: DEFAULT_TLC_FEE_PROPORTIONAL_MILLIONTHS,
                    tlc_expiry_delta: DEFAULT_TLC_EXPIRY_DELTA,
                    tlc_minimum_value: DEFAULT_TLC_MIN_VALUE,
                    tlc_maximum_value: DEFAULT_TLC_MAX_VALUE,
                },
            };
            let remote_tlc_info = None;
            let public_channel_info =
                old_channel_state
                    .public_channel_info
                    .clone()
                    .map(|info| PublicChannelInfoV030 {
                        local_channel_announcement_signature: info
                            .remote_channel_announcement_signature
                            .clone()
                            .map(convert),
                        remote_channel_announcement_signature: info
                            .remote_channel_announcement_signature
                            .clone()
                            .map(convert),
                        remote_channel_announcement_nonce: info.remote_channel_announcement_nonce,
                        channel_announcement: info.channel_announcement.clone().map(convert),
                        channel_update: info.channel_update.clone().map(convert),
                    });

            let new_channel_state = ChannelActorStateV030 {
                state: convert(old_channel_state.state),
                local_pubkey: convert(old_channel_state.local_pubkey),
                remote_pubkey: convert(old_channel_state.remote_pubkey),
                id: convert(old_channel_state.id),
                funding_tx: old_channel_state.funding_tx,
                funding_tx_confirmed_at: old_channel_state.funding_tx_confirmed_at,
                funding_udt_type_script: old_channel_state.funding_udt_type_script,
                is_acceptor: old_channel_state.is_acceptor,
                to_local_amount: old_channel_state.to_local_amount,
                to_remote_amount: old_channel_state.to_remote_amount,
                local_reserved_ckb_amount: old_channel_state.local_reserved_ckb_amount,
                remote_reserved_ckb_amount: old_channel_state.remote_reserved_ckb_amount,
                commitment_fee_rate: old_channel_state.commitment_fee_rate,
                commitment_delay_epoch: old_channel_state.commitment_delay_epoch,
                funding_fee_rate: old_channel_state.funding_fee_rate,
                signer: convert(old_channel_state.signer),
                local_channel_public_keys: convert(old_channel_state.local_channel_public_keys),
                commitment_numbers: convert(old_channel_state.commitment_numbers),
                local_constraints: convert(old_channel_state.local_constraints),
                remote_constraints: convert(old_channel_state.remote_constraints),
                tlc_state: convert(old_channel_state.tlc_state),
                remote_shutdown_script: old_channel_state.remote_shutdown_script,
                local_shutdown_script: old_channel_state.local_shutdown_script,
                last_commitment_signed_remote_nonce: old_channel_state
                    .last_commitment_signed_remote_nonce,
                last_revoke_and_ack_remote_nonce: old_channel_state
                    .last_revoke_and_ack_remote_nonce,
                last_committed_remote_nonce: old_channel_state.last_committed_remote_nonce,
                latest_commitment_transaction: old_channel_state.latest_commitment_transaction,
                remote_commitment_points: convert(old_channel_state.remote_commitment_points),
                remote_channel_public_keys: convert(old_channel_state.remote_channel_public_keys),
                local_shutdown_info: convert(old_channel_state.local_shutdown_info),
                remote_shutdown_info: convert(old_channel_state.remote_shutdown_info),
                reestablishing: old_channel_state.reestablishing,
                created_at: old_channel_state.created_at,
                // --------- changed fields ----------
                public_channel_info,
                // --------- new fields ----------
                local_tlc_info,
                remote_tlc_info,
            };

            let new_channel_state_bytes =
                bincode::serialize(&new_channel_state).expect("serialize to new channel state");

            db.put(k, new_channel_state_bytes)
                .expect("save new channel state");
        }
        Ok(db)
    }

    fn version(&self) -> &str {
        &self.version
    }
}


================================================
File: migrate/src/migrations/mig_20250123.rs
================================================
use fiber::{store::migration::Migration, Error};
use indicatif::ProgressBar;
use rocksdb::ops::Iterate;
use rocksdb::ops::Put;
use rocksdb::DB;
use std::{collections::HashSet, sync::Arc};
use tracing::info;

const MIGRATION_DB_VERSION: &str = "20250123051223";

pub use fiber_v031::fiber::channel::ChannelActorState as ChannelActorStateV031;
pub use fiber_v031::fiber::channel::{
    ChannelTlcInfo as ChannelTlcInfoV031, PendingTlcs as PendingTlcsV031, TlcInfo as TlcInfoV031,
    TlcState as TlcStateV031,
};

use crate::util::convert;
pub use fiber_v032::fiber::channel::ChannelActorState as ChannelActorStateV032;
pub use fiber_v032::fiber::channel::{
    ChannelTlcInfo as ChannelTlcInfoV032, PendingTlcs as PendingTlcsV032,
    PublicChannelInfo as PublicChannelInfoV032, TlcInfo as TlcInfoV032, TlcState as TlcStateV032,
};

pub struct MigrationObj {
    version: String,
}

impl MigrationObj {
    pub fn new() -> Self {
        Self {
            version: MIGRATION_DB_VERSION.to_string(),
        }
    }
}

fn convert_tlc_info(old: TlcInfoV031) -> TlcInfoV032 {
    TlcInfoV032 {
        channel_id: convert(old.channel_id),
        status: convert(old.status),
        tlc_id: convert(old.tlc_id),
        amount: convert(old.amount),
        payment_hash: convert(old.payment_hash),
        expiry: convert(old.expiry),
        hash_algorithm: convert(old.hash_algorithm),
        onion_packet: convert(old.onion_packet),
        shared_secret: convert(old.shared_secret),
        created_at: convert(old.created_at),
        removed_reason: convert(old.removed_reason),
        previous_tlc: convert(old.previous_tlc),
        // new field in v032
        removed_confirmed_at: None,
    }
}

fn convert_pending_tlcs(old: PendingTlcsV031) -> PendingTlcsV032 {
    PendingTlcsV032 {
        tlcs: old
            .tlcs
            .into_iter()
            .map(|tlc| (convert_tlc_info(tlc)))
            .collect(),
        next_tlc_id: convert(old.next_tlc_id),
    }
}

impl Migration for MigrationObj {
    fn migrate(
        &self,
        db: Arc<DB>,
        _pb: Arc<dyn Fn(u64) -> ProgressBar + Send + Sync>,
    ) -> Result<Arc<DB>, Error> {
        info!(
            "MigrationObj::migrate to {} ...........",
            MIGRATION_DB_VERSION
        );

        const CHANNEL_ACTOR_STATE_PREFIX: u8 = 0;
        let prefix = vec![CHANNEL_ACTOR_STATE_PREFIX];

        for (k, v) in db
            .prefix_iterator(prefix.as_slice())
            .take_while(move |(col_key, _)| col_key.starts_with(prefix.as_slice()))
        {
            let old_channel_state: ChannelActorStateV031 =
                bincode::deserialize(&v).expect("deserialize to old channel state");

            let old_tlc_state = old_channel_state.tlc_state.clone();
            let new_tlc_state = TlcStateV032 {
                offered_tlcs: convert_pending_tlcs(old_tlc_state.offered_tlcs),
                received_tlcs: convert_pending_tlcs(old_tlc_state.received_tlcs),
                retryable_tlc_operations: convert(old_tlc_state.retryable_tlc_operations),
                applied_add_tlcs: convert(old_tlc_state.applied_add_tlcs),
                // new field in v032
                applied_remove_tlcs: HashSet::new(),
                waiting_ack: old_tlc_state.waiting_ack,
            };

            let new_channel_state = ChannelActorStateV032 {
                state: convert(old_channel_state.state),
                local_pubkey: convert(old_channel_state.local_pubkey),
                remote_pubkey: convert(old_channel_state.remote_pubkey),
                id: convert(old_channel_state.id),
                funding_tx: old_channel_state.funding_tx,
                funding_tx_confirmed_at: old_channel_state.funding_tx_confirmed_at,
                funding_udt_type_script: old_channel_state.funding_udt_type_script,
                is_acceptor: old_channel_state.is_acceptor,
                to_local_amount: old_channel_state.to_local_amount,
                to_remote_amount: old_channel_state.to_remote_amount,
                local_reserved_ckb_amount: old_channel_state.local_reserved_ckb_amount,
                remote_reserved_ckb_amount: old_channel_state.remote_reserved_ckb_amount,
                commitment_fee_rate: old_channel_state.commitment_fee_rate,
                commitment_delay_epoch: old_channel_state.commitment_delay_epoch,
                funding_fee_rate: old_channel_state.funding_fee_rate,
                signer: convert(old_channel_state.signer),
                local_channel_public_keys: convert(old_channel_state.local_channel_public_keys),
                commitment_numbers: convert(old_channel_state.commitment_numbers),
                local_constraints: convert(old_channel_state.local_constraints),
                remote_constraints: convert(old_channel_state.remote_constraints),
                tlc_state: new_tlc_state,
                remote_shutdown_script: old_channel_state.remote_shutdown_script,
                local_shutdown_script: old_channel_state.local_shutdown_script,
                last_commitment_signed_remote_nonce: old_channel_state
                    .last_commitment_signed_remote_nonce,
                last_revoke_and_ack_remote_nonce: old_channel_state
                    .last_revoke_and_ack_remote_nonce,
                last_committed_remote_nonce: old_channel_state.last_committed_remote_nonce,
                latest_commitment_transaction: old_channel_state.latest_commitment_transaction,
                remote_commitment_points: convert(old_channel_state.remote_commitment_points),
                remote_channel_public_keys: convert(old_channel_state.remote_channel_public_keys),
                local_shutdown_info: convert(old_channel_state.local_shutdown_info),
                remote_shutdown_info: convert(old_channel_state.remote_shutdown_info),
                reestablishing: old_channel_state.reestablishing,
                created_at: old_channel_state.created_at,
                public_channel_info: convert(old_channel_state.public_channel_info),
                local_tlc_info: convert(old_channel_state.local_tlc_info),
                remote_tlc_info: convert(old_channel_state.remote_tlc_info),
            };

            let new_channel_state_bytes =
                bincode::serialize(&new_channel_state).expect("serialize to new channel state");

            db.put(k, new_channel_state_bytes)
                .expect("save new channel state");
        }
        Ok(db)
    }

    fn version(&self) -> &str {
        &self.version
    }
}


================================================
File: migrate/src/migrations/mod.rs
================================================
// following new migration should be added here ...
// pub(crate) mod sample;

pub mod mig_20250114;
pub mod mig_20250115;
pub mod mig_20250123;


================================================
File: migrate/src/migrations/sample.rs
================================================
use fiber::{store::migration::Migration, Error};
use indicatif::ProgressBar;
use rocksdb::{prelude::*, DB};
use std::sync::Arc;

// Remember to update the version number here
const MIGRATION_DB_VERSION: &str = "20311116135521";

pub struct MigrationObj {
    version: String,
}

impl MigrationObj {
    pub fn new() -> Self {
        Self {
            version: MIGRATION_DB_VERSION.to_string(),
        }
    }
}

impl Migration for MigrationObj {
    fn migrate(
        &self,
        db: Arc<DB>,
        _pb: Arc<dyn Fn(u64) -> ProgressBar + Send + Sync>,
    ) -> Result<Arc<DB>, Error> {
        eprintln!("MigrationObj::migrate .....{}....", MIGRATION_DB_VERSION);
        Ok(db)
    }

    fn version(&self) -> &str {
        &self.version
    }
}


================================================
File: src/actors.rs
================================================
use ractor::{async_trait as rasync_trait, Actor, ActorProcessingErr, ActorRef, SupervisionEvent};
use tokio_util::{sync::CancellationToken, task::TaskTracker};
use tracing::debug;

/// A root actor that listens for cancellation token and stops all sub actors (those who started by spawn_linked).
pub struct RootActor;

pub type RootActorMessage = String;

impl RootActor {
    pub async fn start(
        tracker: TaskTracker,
        token: CancellationToken,
    ) -> ActorRef<RootActorMessage> {
        Actor::spawn(
            Some("root actor".to_string()),
            RootActor {},
            (tracker, token),
        )
        .await
        .expect("start root actor")
        .0
    }
}

#[rasync_trait]
impl Actor for RootActor {
    type Msg = RootActorMessage;
    type State = ();
    type Arguments = (TaskTracker, CancellationToken);

    /// Spawn a thread that waits for token to be cancelled,
    /// after that kill all sub actors.
    async fn pre_start(
        &self,
        myself: ActorRef<Self::Msg>,
        (tracker, token): Self::Arguments,
    ) -> Result<Self::State, ActorProcessingErr> {
        tracker.spawn(async move {
            token.cancelled().await;
            debug!("Shutting down root actor due to cancellation token");
            myself.stop(Some("Cancellation token received".to_owned()));
        });
        Ok(())
    }

    async fn post_stop(
        &self,
        myself: ActorRef<Self::Msg>,
        _state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        debug!("Root actor stopped");
        myself
            .get_cell()
            .stop_children_and_wait(Some("Root actor stopped".to_string()), None)
            .await;
        Ok(())
    }

    async fn handle_supervisor_evt(
        &self,
        _myself: ActorRef<Self::Msg>,
        message: SupervisionEvent,
        _state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        match message {
            SupervisionEvent::ActorTerminated(who, _state, reason) => match reason {
                Some(reason) => {
                    debug!("Actor terminated for {:?} (id: {:?})", reason, who,);
                }
                None => {
                    debug!("Actor terminated for unknown reason (id: {:?})", who);
                }
            },
            SupervisionEvent::ActorFailed(who, err) => {
                panic!("Actor unexpectedly panicked (id: {:?}): {:?}", who, err);
            }
            _ => {}
        }
        Ok(())
    }
}


================================================
File: src/build.rs
================================================
use std::env;
use std::fs;
use std::path::Path;

fn main() {
    println!("cargo:rerun-if-changed=migrate/src/migrations");

    let out_dir = env::var("OUT_DIR").unwrap();
    let dest_path = Path::new(&out_dir).join("latest_db_version.rs");

    let migrations_dir = Path::new("migrate/src/migrations");
    let mut migrations = Vec::new();

    let mut latest_db_version = "".to_string();
    for entry in fs::read_dir(migrations_dir).unwrap() {
        let entry = entry.unwrap();
        let path = entry.path();
        if path.is_file() {
            if let Some(stem) = path.file_stem() {
                if let Some(stem_str) = stem.to_str() {
                    if stem_str == "sample" || stem_str == "mod" {
                        continue;
                    }
                    migrations.push(stem_str.to_string());

                    let source_code = fs::read_to_string(&path).unwrap();
                    let version = source_code
                        .lines()
                        .find(|line| line.starts_with("const MIGRATION_DB_VERSION"))
                        .unwrap()
                        .split_whitespace()
                        .last()
                        .unwrap()
                        .replace("\";", "")
                        .replace("\"", "");
                    if version > latest_db_version {
                        latest_db_version = version;
                    }
                }
            }
        }
    }

    let mut code = String::new();
    code.push_str(&format!(
        "    pub const LATEST_DB_VERSION: &str = \"{}\";\n",
        latest_db_version
    ));
    eprintln!("latest_db_version: {}", latest_db_version);
    eprintln!("dest_path: {:?}", dest_path);
    fs::write(dest_path, code).unwrap();
}


================================================
File: src/config.rs
================================================
use std::{fs::File, io::BufReader, path::PathBuf, process::exit, str::FromStr};

use clap::CommandFactory;
use clap_serde_derive::{
    clap::{self, Parser},
    ClapSerde,
};
use home::home_dir;
use serde::{Deserialize, Serialize};
use tracing::error;

use crate::{ckb::CkbConfig, CchConfig, FiberConfig, RpcConfig};

const DEFAULT_CONFIG_FILE_NAME: &str = "config.yml";
const DEFAULT_FIBER_DIR_NAME: &str = "fiber";
const DEFAULT_CCH_DIR_NAME: &str = "cch";

fn get_default_base_dir() -> PathBuf {
    let mut path = home_dir().expect("get home directory");
    path.push(".fiber-node");
    path
}

fn get_default_config_file() -> PathBuf {
    let mut path = get_default_base_dir();
    path.push(DEFAULT_CONFIG_FILE_NAME);
    path
}

#[derive(Serialize, Deserialize, Parser, Copy, Clone, Debug, PartialEq)]
enum Service {
    #[serde(alias = "fiber", alias = "FIBER")]
    FIBER,
    #[serde(alias = "cch", alias = "CCH")]
    CCH,
    #[serde(alias = "rpc", alias = "RPC")]
    RPC,
    #[serde(alias = "ckb", alias = "CKB")]
    CkbChain,
}

impl FromStr for Service {
    type Err = String;
    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s {
            "fiber" | "FIBER" => Ok(Self::FIBER),
            "cch" | "CCH" => Ok(Self::CCH),
            "rpc" | "RPC" => Ok(Self::RPC),
            "ckb" | "CKB" => Ok(Self::CkbChain),
            _ => Err(format!("invalid service {}", s)),
        }
    }
}

#[derive(Parser)]
#[command(author, version, about)]
struct Args {
    // We want to differentiate between when it is a user-set value or it is the default value.
    // If the user has not set default value but set `base_dir` instead then we will use `config.yml`,
    // under base dir.
    /// config file
    #[arg(short, long = "config", help = format!("config file [default: {:?} or $BASE_DIR/config.yml]", get_default_config_file()))]
    config_file: Option<std::path::PathBuf>,

    /// base directory
    #[arg(short = 'd', long = "dir", help = format!("base directory for all [default: {:?}]", get_default_base_dir()))]
    base_dir: Option<std::path::PathBuf>,

    /// services to run (can be any of `ckb`, separated by `,`)
    #[arg(short, long, value_parser, num_args = 0.., value_delimiter = ',')]
    services: Vec<Service>,

    /// config for fiber network
    #[command(flatten)]
    pub fiber: <FiberConfig as ClapSerde>::Opt,

    /// config for cch (cross chain hub)
    #[command(flatten)]
    pub cch: <CchConfig as ClapSerde>::Opt,

    /// config for rpc
    #[command(flatten)]
    pub rpc: <RpcConfig as ClapSerde>::Opt,

    /// config for ckb
    #[command(flatten)]
    pub ckb: <CkbConfig as ClapSerde>::Opt,
}

#[derive(Deserialize)]
struct SerializedConfig {
    services: Option<Vec<Service>>,
    fiber: Option<<FiberConfig as ClapSerde>::Opt>,
    cch: Option<<CchConfig as ClapSerde>::Opt>,
    rpc: Option<<RpcConfig as ClapSerde>::Opt>,
    ckb: Option<<CkbConfig as ClapSerde>::Opt>,
}

#[derive(Debug)]
pub struct Config {
    // fiber config, None represents that we should not run fiber service
    pub fiber: Option<FiberConfig>,
    // cch config, None represents that we should not run cch service
    pub cch: Option<CchConfig>,
    // rpc server config, None represents that we should not run rpc service
    pub rpc: Option<RpcConfig>,
    // ckb actor config, None represents that we should not run ckb actor
    pub ckb: Option<CkbConfig>,
    pub base_dir: PathBuf,
}

pub(crate) fn print_help_and_exit(code: i32) {
    use std::io::IsTerminal;
    if std::io::stdout().is_terminal() {
        let mut cmd = Args::command();
        cmd.print_help().expect("print help");
    }
    exit(code);
}

impl Config {
    pub fn parse() -> Self {
        // Parse whole args with clap
        let mut args = Args::parse();

        // Base directory for all things to be stored to disk
        let base_dir = args.base_dir.clone().unwrap_or(get_default_base_dir());

        // Get config file by
        // 1. Using the explicitly set command line argument `config`
        // 2. Prepending `config.yml` to the explicitly set command line argument `dir`
        // 3. Using the default `config.yml` file
        let config_file = args
            .config_file
            .or(args.base_dir.map(|x| x.join(DEFAULT_CONFIG_FILE_NAME)))
            .unwrap_or(get_default_config_file());

        let config_from_file = File::open(config_file).map(BufReader::new).map(|f| {
            serde_yaml::from_reader::<_, SerializedConfig>(f).expect("valid config file format")
        });

        // Services to run can be passed from
        // 1. command line
        // 2. config file
        // If command line arguments contain services, then don't read config file
        // for services to run any more, otherwise use config file for that.
        let services = if args.services.is_empty() {
            config_from_file
                .as_ref()
                .ok()
                .and_then(|x| x.services.clone())
                .unwrap_or_default()
        } else {
            args.services
        };

        if services.is_empty() {
            error!("Must run at least one service. Specifying services to run by command line or config file.");
            print_help_and_exit(1)
        };

        // Set default fiber/ckb base directory. These may be overridden by values explicitly set by the user.
        args.fiber.base_dir = Some(Some(base_dir.join(DEFAULT_FIBER_DIR_NAME)));
        args.ckb.base_dir = Some(Some(base_dir.join(crate::ckb::DEFAULT_CKB_BASE_DIR_NAME)));
        args.cch.base_dir = Some(Some(base_dir.join(DEFAULT_CCH_DIR_NAME)));

        let (fiber, cch, rpc, ckb) = config_from_file
            .map(|x| {
                let SerializedConfig {
                    services: _,
                    fiber,
                    cch,
                    rpc,
                    ckb,
                } = x;
                (
                    // Successfully read config file, merging these options with the default ones.
                    fiber.map(|c| FiberConfig::from(c).merge(&mut args.fiber)),
                    cch.map(|c| CchConfig::from(c).merge(&mut args.cch)),
                    rpc.map(|c| RpcConfig::from(c).merge(&mut args.rpc)),
                    ckb.map(|c| CkbConfig::from(c).merge(&mut args.ckb)),
                )
            })
            .unwrap_or((None, None, None, None));
        let (fiber, cch, rpc, ckb) = (
            fiber.unwrap_or(FiberConfig::from(&mut args.fiber)),
            cch.unwrap_or(CchConfig::from(&mut args.cch)),
            rpc.unwrap_or(RpcConfig::from(&mut args.rpc)),
            ckb.unwrap_or(CkbConfig::from(&mut args.ckb)),
        );

        let fiber = services.contains(&Service::FIBER).then_some(fiber);
        let cch = services.contains(&Service::CCH).then_some(cch);
        let rpc = services.contains(&Service::RPC).then_some(rpc);
        let ckb = services.contains(&Service::CkbChain).then_some(ckb);

        Self {
            fiber,
            cch,
            rpc,
            ckb,
            base_dir,
        }
    }
}


================================================
File: src/errors.rs
================================================
use ckb_sdk::RpcError;
use ractor::{MessagingErr, SpawnErr};
use tentacle::{error::SendErrorKind, secio::PeerId};
use thiserror::Error;

use crate::{
    ckb::FundingError,
    fiber::{
        channel::{ChannelActorMessage, ProcessingChannelError},
        graph::PathFindError,
        types::Hash256,
        NetworkActorMessage,
    },
};

use crate::invoice::InvoiceError;

#[derive(Error, Debug)]
pub enum Error {
    #[error("IO error: {0}")]
    IO(#[from] std::io::Error),
    #[error("Peer not found error: {0:?}")]
    PeerNotFound(PeerId),
    #[error("Channel not found error: {0:?}")]
    ChannelNotFound(Hash256),
    #[error("Failed to send tentacle message: {0}")]
    TentacleSend(#[from] SendErrorKind),
    #[error("Failed to spawn actor: {0}")]
    SpawnErr(#[from] SpawnErr),
    #[error("Failed to send channel actor message: {0}")]
    ChannelMessagingErr(#[from] MessagingErr<ChannelActorMessage>),
    #[error("Failed to send network actor message: {0}")]
    NetworkMessagingErr(#[from] MessagingErr<NetworkActorMessage>),
    #[error("Failed to processing channel: {0}")]
    ChannelError(#[from] ProcessingChannelError),
    #[error("Invoice error: {0:?}")]
    CkbInvoiceError(#[from] InvoiceError),
    #[error("Funding error: {0}")]
    FundingError(#[from] FundingError),
    #[error("Send payment error: {0}")]
    SendPaymentError(String),
    #[error("Send payment first hop error: {0}")]
    SendPaymentFirstHopError(String, bool),
    #[error("InvalidParameter: {0}")]
    InvalidParameter(String),
    #[error("Network Graph error: {0}")]
    NetworkGraphError(#[from] PathFindError),
    #[error("Invalid peer message: {0}")]
    InvalidPeerMessage(String),
    #[error("Onion packet error: {0}")]
    InvalidOnionPacket(crate::fiber::types::Error),
    #[error("Ckb Rpc error: {0}")]
    CkbRpcError(RpcError),
    #[error("Database error: {0}")]
    DBInternalError(String),
    #[error("Internal error: {0}")]
    InternalError(anyhow::Error),
    #[error("Invalid chain hash: {0} (expecting {1})")]
    InvalidChainHash(Hash256, Hash256),
}

pub type Result<T> = std::result::Result<T, Error>;


================================================
File: src/lib.rs
================================================
mod config;
pub use config::Config;

#[cfg(test)]
mod tests;
use fiber::types::Hash256;
use rand::Rng;
#[cfg(test)]
pub use tests::*;

pub mod ckb;
pub mod fiber;
pub use fiber::{start_network, FiberConfig, NetworkServiceEvent};
pub mod cch;
pub use cch::{start_cch, CchActor, CchConfig};

pub mod rpc;
pub use rpc::{start_rpc, RpcConfig};
pub mod invoice;
pub mod store;
pub mod watchtower;

mod errors;
pub use errors::{Error, Result};

pub mod actors;

pub mod tasks;

use git_version::git_version;

const GIT_VERSION: &str = git_version!(fallback = "unknown");

pub fn get_git_version() -> &'static str {
    GIT_VERSION
}

pub fn get_node_prefix() -> &'static str {
    static INSTANCE: once_cell::sync::OnceCell<String> = once_cell::sync::OnceCell::new();
    INSTANCE.get_or_init(|| std::env::var("LOG_PREFIX").unwrap_or_else(|_| "".to_string()))
}

pub fn now_timestamp_as_millis_u64() -> u64 {
    std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .expect("Duration since unix epoch")
        .as_millis() as u64
}

pub fn gen_rand_sha256_hash() -> Hash256 {
    let mut rng = rand::thread_rng();
    let mut result = [0u8; 32];
    rng.fill(&mut result[..]);
    result.into()
}

pub mod macros {
    #[macro_export]
    macro_rules! unwrap_or_return {
        ($expr:expr, $msg:expr) => {
            match $expr {
                Ok(val) => val,
                Err(err) => {
                    error!("{}: {:?}", $msg, err);
                    return;
                }
            }
        };
        ($expr:expr) => {
            match $expr {
                Ok(val) => val,
                Err(err) => {
                    error!("{:?}", err);
                    return;
                }
            }
        };
    }
}


================================================
File: src/main.rs
================================================
use ckb_chain_spec::ChainSpec;
use ckb_resource::Resource;
use core::default::Default;
use fnn::actors::RootActor;
use fnn::cch::CchMessage;
use fnn::ckb::{contracts::try_init_contracts_context, CkbChainActor};
use fnn::fiber::{channel::ChannelSubscribers, graph::NetworkGraph, network::init_chain_hash};
use fnn::store::Store;
use fnn::tasks::{
    cancel_tasks_and_wait_for_completion, new_tokio_cancellation_token, new_tokio_task_tracker,
};
use fnn::watchtower::{
    WatchtowerActor, WatchtowerMessage, DEFAULT_WATCHTOWER_CHECK_INTERVAL_SECONDS,
};
#[cfg(debug_assertions)]
use fnn::NetworkServiceEvent;
use fnn::{start_cch, start_network, start_rpc, Config};
use ractor::Actor;
#[cfg(debug_assertions)]
use std::collections::HashMap;
use std::fmt::Debug;
use std::path::Path;
use std::sync::Arc;
use std::time::Duration;
use tokio::select;
use tokio::sync::{mpsc, RwLock};
use tracing::{debug, info, info_span, trace};
use tracing_subscriber::{field::MakeExt, fmt, fmt::format, EnvFilter};

pub struct ExitMessage(String);

#[tokio::main]
pub async fn main() -> Result<(), ExitMessage> {
    // ractor will set "id" for each actor:
    // https://github.com/slawlor/ractor/blob/67d657e4cdcb8884a9ccc9b758704cbb447ac163/ractor/src/actor/mod.rs#L701
    // here we map it with the node prefix
    let node_formatter = format::debug_fn(|writer, field, value| {
        let prefix = if field.name() == "id" {
            let r = fnn::get_node_prefix();
            if !r.is_empty() {
                format!(" on {}", r)
            } else {
                "".to_string()
            }
        } else {
            "".to_string()
        };
        write!(writer, "{}: {:?}{}", field, value, prefix)
    })
    .delimited(", ");
    fmt()
        .with_env_filter(EnvFilter::from_default_env())
        .pretty()
        .fmt_fields(node_formatter)
        .try_init()
        .map_err(|err| ExitMessage(format!("failed to initialize logger: {}", err)))?;

    info!("Starting node with git version {}", fnn::get_git_version());

    let _span = info_span!("node", node = fnn::get_node_prefix()).entered();

    let config = Config::parse();

    let store_path = config
        .fiber
        .as_ref()
        .ok_or_else(|| ExitMessage("fiber config is required but absent".to_string()))?
        .store_path();

    let store = Store::new(store_path).map_err(|err| ExitMessage(err.to_string()))?;

    let tracker = new_tokio_task_tracker();
    let token = new_tokio_cancellation_token();
    let root_actor = RootActor::start(tracker, token).await;
    let subscribers = ChannelSubscribers::default();

    #[cfg(debug_assertions)]
    let rpc_dev_module_commitment_txs = config.rpc.as_ref().and_then(|rpc_config| {
        if rpc_config.is_module_enabled("dev") {
            Some(Arc::new(RwLock::new(HashMap::new())))
        } else {
            None
        }
    });

    let (network_actor, ckb_chain_actor, network_graph) = match config.fiber.clone() {
        Some(fiber_config) => {
            // TODO: this is not a super user friendly error message which has actionable information
            // for the user to fix the error and start the node.
            let ckb_config = config.ckb.clone().ok_or_else(|| {
                ExitMessage(
                    "service fiber requires service ckb which is not enabled in the config file"
                        .to_string(),
                )
            })?;
            let node_public_key = fiber_config.public_key();

            let chain = fiber_config.chain.as_str();
            let chain_spec = ChainSpec::load_from(&match chain {
                "mainnet" => Resource::bundled("specs/mainnet.toml".to_string()),
                "testnet" => Resource::bundled("specs/testnet.toml".to_string()),
                path => Resource::file_system(Path::new(&config.base_dir).join(path)),
            })
            .map_err(|err| ExitMessage(format!("failed to load chain spec: {}", err)))?;
            let genesis_block = chain_spec.build_genesis().map_err(|err| {
                ExitMessage(format!("failed to build ckb genesis block: {}", err))
            })?;

            init_chain_hash(genesis_block.hash().into());
            try_init_contracts_context(
                genesis_block,
                fiber_config.scripts.clone(),
                ckb_config.udt_whitelist.clone().unwrap_or_default(),
            )
            .map_err(|err| ExitMessage(format!("failed to init contracts context: {}", err)))?;

            let ckb_chain_actor = Actor::spawn_linked(
                Some("ckb".to_string()),
                CkbChainActor {},
                ckb_config.clone(),
                root_actor.get_cell(),
            )
            .await
            .map_err(|err| ExitMessage(format!("failed to start ckb actor: {}", err)))?
            .0;

            const CHANNEL_SIZE: usize = 4000;
            let (event_sender, mut event_receiver) = mpsc::channel(CHANNEL_SIZE);

            let network_graph = Arc::new(RwLock::new(NetworkGraph::new(
                store.clone(),
                node_public_key.clone().into(),
                fiber_config.announce_private_addr(),
            )));

            // we use the default funding lock script as the shutdown script for the network actor
            let default_shutdown_script = ckb_config
                .get_default_funding_lock_script()
                .expect("get default funding lock script should be ok");

            info!("Starting fiber");
            let network_actor = start_network(
                fiber_config.clone(),
                ckb_chain_actor.clone(),
                event_sender,
                new_tokio_task_tracker(),
                root_actor.get_cell(),
                store.clone(),
                subscribers.clone(),
                network_graph.clone(),
                default_shutdown_script,
            )
            .await;

            let watchtower_actor = Actor::spawn_linked(
                Some("watchtower".to_string()),
                WatchtowerActor::new(store.clone()),
                ckb_config,
                root_actor.get_cell(),
            )
            .await
            .map_err(|err| ExitMessage(format!("failed to start watchtower actor: {}", err)))?
            .0;

            watchtower_actor.send_interval(
                Duration::from_secs(
                    fiber_config
                        .watchtower_check_interval_seconds
                        .unwrap_or(DEFAULT_WATCHTOWER_CHECK_INTERVAL_SECONDS),
                ),
                || WatchtowerMessage::PeriodicCheck,
            );

            #[cfg(debug_assertions)]
            let rpc_dev_module_commitment_txs_clone = rpc_dev_module_commitment_txs.clone();
            new_tokio_task_tracker().spawn(async move {
                let token = new_tokio_cancellation_token();
                loop {
                    select! {
                        event = event_receiver.recv() => {
                            match event {
                                None => {
                                    trace!("Event receiver completed, stopping event processing service");
                                    break;
                                }
                                Some(event) => {
                                    // we may forward more events to the rpc dev module in the future for integration testing
                                    // for now, we only forward RemoteCommitmentSigned events, which are used for submitting outdated commitment transactions
                                    #[cfg(debug_assertions)]
                                    if let Some(rpc_dev_module_commitment_txs) = rpc_dev_module_commitment_txs_clone.as_ref() {
                                        if let NetworkServiceEvent::RemoteCommitmentSigned(_, channel_id, commitment_tx, _) = event.clone() {
                                            let lock_args = commitment_tx.outputs().get(0).unwrap().lock().args().raw_data();
                                            let version = u64::from_be_bytes(lock_args[28..36].try_into().unwrap());
                                            rpc_dev_module_commitment_txs.write().await.insert((channel_id, version), commitment_tx);
                                        }
                                    }
                                    // forward the event to the watchtower actor
                                    let _ = watchtower_actor.send_message(WatchtowerMessage::NetworkServiceEvent(event));
                                }
                            }
                        }
                        _ = token.cancelled() => {
                            debug!("Cancellation received, stopping event processing service");
                            break;
                        }
                    }
                }
                debug!("Event processing service exited");
            });

            (
                Some(network_actor),
                Some(ckb_chain_actor),
                Some(network_graph),
            )
        }
        None => (None, None, None),
    };

    let cch_actor = match config.cch {
        Some(cch_config) => {
            info!("Starting cch");
            let ignore_startup_failure = cch_config.ignore_startup_failure;
            match start_cch(
                cch_config,
                new_tokio_task_tracker(),
                new_tokio_cancellation_token(),
                root_actor.get_cell(),
                network_actor.clone(),
            )
            .await
            {
                Err(err) => {
                    if ignore_startup_failure {
                        info!("Cross-chain service failed to start and is ignored by the config option ignore_startup_failure: {}", err);
                        None
                    } else {
                        return ExitMessage::err(format!(
                            "cross-chain service failed to start: {}",
                            err
                        ));
                    }
                }
                Ok(actor) => {
                    subscribers.pending_received_tlcs_subscribers.subscribe(
                        actor.clone(),
                        |tlc_notification| {
                            Some(CchMessage::PendingReceivedTlcNotification(tlc_notification))
                        },
                    );
                    subscribers.settled_tlcs_subscribers.subscribe(
                        actor.clone(),
                        |tlc_notification| {
                            Some(CchMessage::SettledTlcNotification(tlc_notification))
                        },
                    );

                    Some(actor)
                }
            }
        }
        None => None,
    };

    // Start rpc service
    let rpc_server_handle = match (config.rpc, network_graph) {
        (Some(rpc_config), Some(network_graph)) => {
            let handle = start_rpc(
                rpc_config,
                config.ckb,
                config.fiber,
                network_actor,
                cch_actor,
                store,
                network_graph,
                #[cfg(debug_assertions)] ckb_chain_actor,
                #[cfg(debug_assertions)] rpc_dev_module_commitment_txs,
            )
            .await;
            Some(handle)
        },
        (Some(_), None) => return ExitMessage::err(
            "RPC requires network graph in the fiber service which is not enabled in the config file"
            .to_string()
        ),
        _ => None,
    };

    signal_listener().await;
    if let Some(handle) = rpc_server_handle {
        handle
            .stop()
            .map_err(|err| ExitMessage(format!("failed to stop rpc server: {}", err)))?;
        handle.stopped().await;
    }
    cancel_tasks_and_wait_for_completion().await;

    Ok(())
}

impl Debug for ExitMessage {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "Exit because {}", self.0)
    }
}

impl ExitMessage {
    pub fn err(message: String) -> Result<(), ExitMessage> {
        Err(ExitMessage(message))
    }
}

#[cfg(target_family = "unix")]
async fn signal_listener() {
    use tokio::signal::unix::{signal, SignalKind};
    // SIGTERM is commonly sent for graceful shutdown of applications, followed by 30 seconds of grace time, then a SIGKILL.
    let mut sigterm = signal(SignalKind::terminate()).expect("listen for SIGTERM");
    // SIGINT is usually sent due to ctrl-c in the terminal.
    let mut sigint = signal(SignalKind::interrupt()).expect("listen for SIGINT");

    tokio::select! {
        _ = sigterm.recv() => info!("SIGTERM received, shutting down"),
        _ = sigint.recv() => info!("SIGINT received, shutting down"),
    };
}

#[cfg(not(target_family = "unix"))]
async fn signal_listener() {
    tokio::signal::ctrl_c()
        .await
        .expect("listen for Ctrl-c signal");
    tracing::info!("Ctrl-c received, shutting down");
}


================================================
File: src/tasks.rs
================================================
use tokio_util::{sync::CancellationToken, task::TaskTracker};

#[derive(Debug, Clone)]
pub struct TaskTrackerWithCancellation {
    tracker: TaskTracker,
    token: CancellationToken,
}

impl Default for TaskTrackerWithCancellation {
    fn default() -> Self {
        Self::new()
    }
}

impl TaskTrackerWithCancellation {
    pub fn new() -> Self {
        Self {
            tracker: TaskTracker::new(),
            token: CancellationToken::new(),
        }
    }

    pub async fn close(&self) {
        self.token.cancel();
        self.tracker.close();
        self.tracker.wait().await;
    }
}

static TOKIO_TASK_TRACKER_WITH_CANCELLATION: once_cell::sync::Lazy<TaskTrackerWithCancellation> =
    once_cell::sync::Lazy::new(TaskTrackerWithCancellation::new);

/// Create a new CancellationToken for exit signal
pub fn new_tokio_cancellation_token() -> CancellationToken {
    TOKIO_TASK_TRACKER_WITH_CANCELLATION.token.clone()
}

/// Create a new TaskTracker to track task progress
pub fn new_tokio_task_tracker() -> TaskTracker {
    TOKIO_TASK_TRACKER_WITH_CANCELLATION.tracker.clone()
}

/// Shutdown all tasks, and wait for their completion.
pub async fn cancel_tasks_and_wait_for_completion() {
    TOKIO_TASK_TRACKER_WITH_CANCELLATION.close().await;
}


================================================
File: src/cch/actor.rs
================================================
use anyhow::{anyhow, Context, Result};
use futures::StreamExt as _;
use hex::ToHex;
use lightning_invoice::Bolt11Invoice;
use lnd_grpc_tonic_client::{
    create_invoices_client, create_router_client, invoicesrpc, lnrpc, routerrpc, InvoicesClient,
    RouterClient, Uri,
};
use ractor::{call, RpcReplyPort};
use ractor::{Actor, ActorCell, ActorProcessingErr, ActorRef};
use serde::Deserialize;
use std::str::FromStr;
use std::time::{Duration, SystemTime, UNIX_EPOCH};
use tokio::{select, time::sleep};
use tokio_util::{sync::CancellationToken, task::TaskTracker};

use crate::ckb::contracts::{get_script_by_contract, Contract};
use crate::fiber::channel::{
    AddTlcCommand, ChannelCommand, ChannelCommandWithId, RemoveTlcCommand, TlcNotification,
};
use crate::fiber::hash_algorithm::HashAlgorithm;
use crate::fiber::types::{Hash256, RemoveTlcFulfill, RemoveTlcReason, NO_SHARED_SECRET};
use crate::fiber::{NetworkActorCommand, NetworkActorMessage};
use crate::invoice::Currency;
use crate::now_timestamp_as_millis_u64;

use super::error::CchDbError;
use super::{CchConfig, CchError, CchOrderStatus, CchOrdersDb, ReceiveBTCOrder, SendBTCOrder};

pub const BTC_PAYMENT_TIMEOUT_SECONDS: i32 = 60;
pub const DEFAULT_ORDER_EXPIRY_SECONDS: u64 = 86400; // 24 hours

pub async fn start_cch(
    config: CchConfig,
    tracker: TaskTracker,
    token: CancellationToken,
    root_actor: ActorCell,
    network_actor: Option<ActorRef<NetworkActorMessage>>,
) -> Result<ActorRef<CchMessage>> {
    let (actor, _handle) = Actor::spawn_linked(
        Some("cch actor".to_string()),
        CchActor::new(config, tracker, token, network_actor),
        (),
        root_actor,
    )
    .await?;
    Ok(actor)
}

#[derive(Debug)]
pub struct SettleSendBTCOrderEvent {
    payment_hash: String,
    preimage: Option<String>,
    status: CchOrderStatus,
}

#[derive(Debug)]
pub struct SettleReceiveBTCOrderEvent {
    payment_hash: String,
    preimage: Option<String>,
    status: CchOrderStatus,
}

#[derive(Clone, Debug, Deserialize)]
pub struct SendBTC {
    pub btc_pay_req: String,
    pub currency: Currency,
}

#[derive(Clone, Debug, Deserialize)]
pub struct ReceiveBTC {
    /// Payment hash for the HTLC for both CKB and BTC.
    pub payment_hash: String,

    /// Assume that the cross-chain hub already has a channel to the payee and the channel has
    /// enough balance to pay the order.
    /// TODO: Let the cross-chain hub create a channel to the payee on demand.
    pub channel_id: Hash256,
    /// Amount required to pay in Satoshis via BTC, including the fee for the cross-chain hub
    pub amount_sats: u128,
    /// Expiry set for the HTLC for the CKB payment to the payee.
    pub final_tlc_expiry: u64,
}

pub enum CchMessage {
    SendBTC(SendBTC, RpcReplyPort<Result<SendBTCOrder, CchError>>),
    ReceiveBTC(ReceiveBTC, RpcReplyPort<Result<ReceiveBTCOrder, CchError>>),

    GetReceiveBTCOrder(String, RpcReplyPort<Result<ReceiveBTCOrder, CchError>>),

    SettleSendBTCOrder(SettleSendBTCOrderEvent),
    SettleReceiveBTCOrder(SettleReceiveBTCOrderEvent),

    PendingReceivedTlcNotification(TlcNotification),
    SettledTlcNotification(TlcNotification),
}

#[derive(Clone)]
struct LndConnectionInfo {
    uri: Uri,
    cert: Option<Vec<u8>>,
    macaroon: Option<Vec<u8>>,
}

impl LndConnectionInfo {
    async fn create_router_client(
        &self,
    ) -> Result<RouterClient, lnd_grpc_tonic_client::channel::Error> {
        create_router_client(
            self.uri.clone(),
            self.cert.as_deref(),
            self.macaroon.as_deref(),
        )
        .await
    }

    async fn create_invoices_client(
        &self,
    ) -> Result<InvoicesClient, lnd_grpc_tonic_client::channel::Error> {
        create_invoices_client(
            self.uri.clone(),
            self.cert.as_deref(),
            self.macaroon.as_deref(),
        )
        .await
    }
}

pub struct CchActor {
    config: CchConfig,
    tracker: TaskTracker,
    token: CancellationToken,
    network_actor: Option<ActorRef<NetworkActorMessage>>,
}

pub struct CchState {
    lnd_connection: LndConnectionInfo,
    orders_db: CchOrdersDb,
}

#[ractor::async_trait]
impl Actor for CchActor {
    type Msg = CchMessage;
    type State = CchState;
    type Arguments = ();

    async fn pre_start(
        &self,
        myself: ActorRef<Self::Msg>,
        _config: Self::Arguments,
    ) -> Result<Self::State, ActorProcessingErr> {
        let lnd_rpc_url: Uri = self.config.lnd_rpc_url.clone().try_into()?;
        let cert = match self.config.resolve_lnd_cert_path() {
            Some(path) => Some(
                tokio::fs::read(&path)
                    .await
                    .with_context(|| format!("read cert file {}", path.display()))?,
            ),
            None => None,
        };
        let macaroon = match self.config.resolve_lnd_macaroon_path() {
            Some(path) => Some(
                tokio::fs::read(&path)
                    .await
                    .with_context(|| format!("read macaroon file {}", path.display()))?,
            ),
            None => None,
        };
        let lnd_connection = LndConnectionInfo {
            uri: lnd_rpc_url,
            cert,
            macaroon,
        };

        let payments_tracker =
            LndPaymentsTracker::new(myself.clone(), lnd_connection.clone(), self.token.clone());
        self.tracker
            .spawn(async move { payments_tracker.run().await });

        Ok(CchState {
            lnd_connection,
            orders_db: Default::default(),
        })
    }

    async fn handle(
        &self,
        myself: ActorRef<Self::Msg>,
        message: Self::Msg,
        state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        match message {
            CchMessage::SendBTC(send_btc, port) => {
                let result = self.send_btc(state, send_btc).await;
                if !port.is_closed() {
                    // ignore error
                    let _ = port.send(result);
                }
                Ok(())
            }
            CchMessage::ReceiveBTC(receive_btc, port) => {
                let result = self.receive_btc(myself, state, receive_btc).await;
                if !port.is_closed() {
                    // ignore error
                    let _ = port.send(result);
                }
                Ok(())
            }
            CchMessage::GetReceiveBTCOrder(payment_hash, port) => {
                let result = state
                    .orders_db
                    .get_receive_btc_order(&payment_hash)
                    .await
                    .map_err(Into::into);
                if !port.is_closed() {
                    // ignore error
                    let _ = port.send(result);
                }
                Ok(())
            }
            CchMessage::SettleSendBTCOrder(event) => {
                tracing::debug!("settle_send_btc_order {:?}", event);
                if let Err(err) = self.settle_send_btc_order(state, event).await {
                    tracing::error!("settle_send_btc_order failed: {}", err);
                }
                Ok(())
            }
            CchMessage::SettleReceiveBTCOrder(event) => {
                tracing::debug!("settle_receive_btc_order {:?}", event);
                if let Err(err) = self.settle_receive_btc_order(state, event).await {
                    tracing::error!("settle_receive_btc_order failed: {}", err);
                }
                Ok(())
            }
            CchMessage::PendingReceivedTlcNotification(tlc_notification) => {
                if let Err(err) = self
                    .handle_pending_received_tlc_notification(state, tlc_notification)
                    .await
                {
                    tracing::error!("handle_pending_received_tlc_notification failed: {}", err);
                }
                Ok(())
            }
            CchMessage::SettledTlcNotification(tlc_notification) => {
                if let Err(err) = self
                    .handle_settled_tlc_notification(state, tlc_notification)
                    .await
                {
                    tracing::error!("handle_settled_tlc_notification failed: {}", err);
                }
                Ok(())
            }
        }
    }
}

impl CchActor {
    pub fn new(
        config: CchConfig,
        tracker: TaskTracker,
        token: CancellationToken,
        network_actor: Option<ActorRef<NetworkActorMessage>>,
    ) -> Self {
        Self {
            config,
            tracker,
            token,
            network_actor,
        }
    }

    async fn send_btc(
        &self,
        state: &mut CchState,
        send_btc: SendBTC,
    ) -> Result<SendBTCOrder, CchError> {
        let duration_since_epoch = SystemTime::now().duration_since(UNIX_EPOCH)?;

        let invoice = Bolt11Invoice::from_str(&send_btc.btc_pay_req)?;
        tracing::debug!("BTC invoice: {:?}", invoice);

        let expiry = invoice
            .expires_at()
            .and_then(|expired_at| expired_at.checked_sub(duration_since_epoch))
            .map(|duration| duration.as_secs())
            .ok_or(CchError::BTCInvoiceExpired)?;

        let amount_msat = invoice
            .amount_milli_satoshis()
            .ok_or(CchError::BTCInvoiceMissingAmount)? as u128;

        let fee_sats = amount_msat * (self.config.fee_rate_per_million_sats as u128)
            / 1_000_000_000u128
            + (self.config.base_fee_sats as u128);

        let wrapped_btc_type_script: ckb_jsonrpc_types::Script = get_script_by_contract(
            Contract::SimpleUDT,
            hex::decode(
                self.config
                    .wrapped_btc_type_script_args
                    .trim_start_matches("0x"),
            )
            .map_err(|_| {
                CchError::HexDecodingError(self.config.wrapped_btc_type_script_args.clone())
            })?
            .as_ref(),
        )
        .into();
        let mut order = SendBTCOrder {
            expires_after: expiry,
            wrapped_btc_type_script,
            fee_sats,
            currency: send_btc.currency,
            created_at: duration_since_epoch.as_secs(),
            ckb_final_tlc_expiry_delta: self.config.ckb_final_tlc_expiry_delta,
            btc_pay_req: send_btc.btc_pay_req,
            ckb_pay_req: Default::default(),
            payment_hash: format!("0x{}", invoice.payment_hash().encode_hex::<String>()),
            payment_preimage: None,
            channel_id: None,
            tlc_id: None,
            amount_sats: amount_msat.div_ceil(1_000u128) + fee_sats,
            status: CchOrderStatus::Pending,
        };
        order.generate_ckb_invoice()?;

        state.orders_db.insert_send_btc_order(order.clone()).await?;
        // TODO(now): save order and invoice into db: store.insert_invoice(invoice.clone())

        Ok(order)
    }

    // On receiving new TLC, check whether it matches the SendBTC order
    async fn handle_pending_received_tlc_notification(
        &self,
        state: &mut CchState,
        tlc_notification: TlcNotification,
    ) -> Result<()> {
        let payment_hash = format!("{:#x}", tlc_notification.tlc.payment_hash);
        tracing::debug!("[inbounding tlc] payment hash: {}", payment_hash);

        let mut order = match state.orders_db.get_send_btc_order(&payment_hash).await {
            Err(CchDbError::NotFound(_)) => return Ok(()),
            Err(err) => return Err(err.into()),
            Ok(order) => order,
        };

        if order.status != CchOrderStatus::Pending {
            return Err(CchError::SendBTCOrderAlreadyPaid.into());
        }

        if tlc_notification.tlc.amount < order.amount_sats {
            // TODO: split the payment into multiple parts
            return Err(CchError::SendBTCReceivedAmountTooSmall.into());
        }

        order.channel_id = Some(tlc_notification.channel_id);
        order.tlc_id = Some(tlc_notification.tlc.tlc_id.into());
        state.orders_db.update_send_btc_order(order.clone()).await?;

        let req = routerrpc::SendPaymentRequest {
            payment_request: order.btc_pay_req.clone(),
            timeout_seconds: BTC_PAYMENT_TIMEOUT_SECONDS,
            ..Default::default()
        };
        tracing::debug!("[inbounding tlc] SendPaymentRequest: {:?}", req);

        let mut client = state.lnd_connection.create_router_client().await?;
        // TODO: set a fee
        let mut stream = client.send_payment_v2(req).await?.into_inner();
        // Wait for the first message then quit
        select! {
            payment_result_opt = stream.next() => {
                tracing::debug!("[inbounding tlc] payment result: {:?}", payment_result_opt);
                if let Some(Ok(payment)) = payment_result_opt {
                    order.status = lnrpc::payment::PaymentStatus::try_from(payment.status)?.into();
                    state.orders_db
                        .update_send_btc_order(order)
                        .await?;
                }
            }
            _ = self.token.cancelled() => {
                tracing::debug!("Cancellation received, shutting down cch service");
                return Ok(());
            }
        }

        Ok(())
    }

    async fn handle_settled_tlc_notification(
        &self,
        state: &mut CchState,
        tlc_notification: TlcNotification,
    ) -> Result<()> {
        let payment_hash = format!("{:#x}", tlc_notification.tlc.payment_hash);
        tracing::debug!("[settled tlc] payment hash: {}", payment_hash);

        match state.orders_db.get_receive_btc_order(&payment_hash).await {
            Err(CchDbError::NotFound(_)) => return Ok(()),
            Err(err) => return Err(err.into()),
            _ => {
                // ignore
            }
        };

        let preimage = tlc_notification
            .tlc
            .payment_preimage
            .ok_or(CchError::ReceiveBTCMissingPreimage)?;

        tracing::debug!("[settled tlc] preimage: {:#x}", preimage);

        // settle the lnd invoice
        let req = invoicesrpc::SettleInvoiceMsg {
            preimage: preimage.as_ref().to_vec(),
        };
        tracing::debug!("[settled tlc] SettleInvoiceMsg: {:?}", req);

        let mut client = state.lnd_connection.create_invoices_client().await?;
        // TODO: set a fee
        let resp = client.settle_invoice(req).await?.into_inner();
        tracing::debug!("[settled tlc] SettleInvoiceResp: {:?}", resp);

        Ok(())
    }

    async fn settle_send_btc_order(
        &self,
        state: &mut CchState,
        event: SettleSendBTCOrderEvent,
    ) -> Result<()> {
        let mut order = match state
            .orders_db
            .get_send_btc_order(&event.payment_hash)
            .await
        {
            Err(CchDbError::NotFound(_)) => return Ok(()),
            Err(err) => return Err(err.into()),
            Ok(order) => order,
        };

        order.status = event.status;
        if let (Some(preimage), Some(network_actor), Some(channel_id), Some(tlc_id)) = (
            event.preimage,
            &self.network_actor,
            order.channel_id,
            order.tlc_id,
        ) {
            tracing::info!(
                "SettleSendBTCOrder: payment_hash={}, status={:?}",
                event.payment_hash,
                event.status
            );
            order.payment_preimage = Some(preimage.clone());

            let message = move |rpc_reply| -> NetworkActorMessage {
                NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                    ChannelCommandWithId {
                        channel_id,
                        command: ChannelCommand::RemoveTlc(
                            RemoveTlcCommand {
                                id: tlc_id,
                                reason: RemoveTlcReason::RemoveTlcFulfill(RemoveTlcFulfill {
                                    payment_preimage: Hash256::from_str(&preimage)
                                        .expect("decode preimage"),
                                }),
                            },
                            rpc_reply,
                        ),
                    },
                ))
            };

            call!(network_actor, message)
                .expect("call actor")
                .map_err(|msg| anyhow!(msg))?;
        }

        state.orders_db.update_send_btc_order(order).await?;

        Ok(())
    }

    async fn receive_btc(
        &self,
        myself: ActorRef<CchMessage>,
        state: &mut CchState,
        receive_btc: ReceiveBTC,
    ) -> Result<ReceiveBTCOrder, CchError> {
        let duration_since_epoch = SystemTime::now().duration_since(UNIX_EPOCH)?;
        let hash_bin = hex::decode(receive_btc.payment_hash.trim_start_matches("0x"))
            .map_err(|_| CchError::HexDecodingError(receive_btc.payment_hash.clone()))?;

        let amount_sats = receive_btc.amount_sats;
        let fee_sats = amount_sats * (self.config.fee_rate_per_million_sats as u128)
            / 1_000_000u128
            + (self.config.base_fee_sats as u128);
        if amount_sats <= fee_sats {
            return Err(CchError::ReceiveBTCOrderAmountTooSmall);
        }
        if amount_sats > (i64::MAX / 1_000i64) as u128 {
            return Err(CchError::ReceiveBTCOrderAmountTooLarge);
        }

        let mut client = state.lnd_connection.create_invoices_client().await?;
        let req = invoicesrpc::AddHoldInvoiceRequest {
            hash: hash_bin,
            value_msat: (amount_sats * 1_000u128) as i64,
            expiry: DEFAULT_ORDER_EXPIRY_SECONDS as i64,
            cltv_expiry: self.config.btc_final_tlc_expiry + receive_btc.final_tlc_expiry,
            ..Default::default()
        };
        let invoice = client
            .add_hold_invoice(req)
            .await
            .map_err(|err| CchError::LndRpcError(err.to_string()))?
            .into_inner();
        let btc_pay_req = invoice.payment_request;

        let wrapped_btc_type_script: ckb_jsonrpc_types::Script = get_script_by_contract(
            Contract::SimpleUDT,
            hex::decode(
                self.config
                    .wrapped_btc_type_script_args
                    .trim_start_matches("0x"),
            )
            .map_err(|_| {
                CchError::HexDecodingError(self.config.wrapped_btc_type_script_args.clone())
            })?
            .as_ref(),
        )
        .into();
        let order = ReceiveBTCOrder {
            created_at: duration_since_epoch.as_secs(),
            expires_after: DEFAULT_ORDER_EXPIRY_SECONDS,
            ckb_final_tlc_expiry_delta: receive_btc.final_tlc_expiry,
            btc_pay_req,
            payment_hash: receive_btc.payment_hash.clone(),
            payment_preimage: None,
            amount_sats,
            fee_sats,
            status: CchOrderStatus::Pending,
            wrapped_btc_type_script,
            // TODO: check the channel exists and has enough local balance.
            channel_id: receive_btc.channel_id,
            tlc_id: None,
        };

        state
            .orders_db
            .insert_receive_btc_order(order.clone())
            .await?;

        let invoice_tracker = LndInvoiceTracker::new(
            myself,
            receive_btc.payment_hash,
            state.lnd_connection.clone(),
            self.token.clone(),
        );
        self.tracker
            .spawn(async move { invoice_tracker.run().await });

        Ok(order)
    }

    async fn settle_receive_btc_order(
        &self,
        state: &mut CchState,
        event: SettleReceiveBTCOrderEvent,
    ) -> Result<()> {
        let mut order = match state
            .orders_db
            .get_receive_btc_order(&event.payment_hash)
            .await
        {
            Err(CchDbError::NotFound(_)) => return Ok(()),
            Err(err) => return Err(err.into()),
            Ok(order) => order,
        };

        if event.status == CchOrderStatus::Accepted && self.network_actor.is_some() {
            // AddTlc to initiate the CKB payment
            let message = |rpc_reply| -> NetworkActorMessage {
                NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                    ChannelCommandWithId {
                        channel_id: order.channel_id,
                        command: ChannelCommand::AddTlc(
                            AddTlcCommand {
                                amount: order.amount_sats - order.fee_sats,
                                payment_hash: Hash256::from_str(&order.payment_hash)
                                    .expect("parse Hash256"),
                                expiry: now_timestamp_as_millis_u64()
                                    + self.config.ckb_final_tlc_expiry_delta,
                                hash_algorithm: HashAlgorithm::Sha256,
                                onion_packet: None,
                                shared_secret: NO_SHARED_SECRET,
                                previous_tlc: None,
                            },
                            rpc_reply,
                        ),
                    },
                ))
            };
            let tlc_response = call!(
                self.network_actor
                    .as_ref()
                    .expect("CCH requires network actor"),
                message
            )
            .expect("call actor")
            .map_err(|msg| anyhow!(msg))?;
            order.tlc_id = Some(tlc_response.tlc_id);
        }

        order.status = event.status;
        order.payment_preimage = event.preimage.clone();

        state
            .orders_db
            .update_receive_btc_order(order.clone())
            .await?;
        Ok(())
    }
}

struct LndPaymentsTracker {
    cch_actor: ActorRef<CchMessage>,
    lnd_connection: LndConnectionInfo,
    token: CancellationToken,
}

impl LndPaymentsTracker {
    fn new(
        cch_actor: ActorRef<CchMessage>,
        lnd_connection: LndConnectionInfo,
        token: CancellationToken,
    ) -> Self {
        Self {
            cch_actor,
            lnd_connection,
            token,
        }
    }

    async fn run(self) {
        tracing::debug!(
            target: "fnn::cch::actor::tracker::lnd_payments",
            "will connect {}",
            self.lnd_connection.uri
        );

        // TODO: clean up expired orders
        loop {
            select! {
                result = self.run_inner() => {
                    match result {
                        Ok(_) => {
                            break;
                        }
                        Err(err) => {
                            tracing::error!(
                                target: "fnn::cch::actor::tracker::lnd_payments",
                                "Error tracking LND payments, retry 15 seconds later: {:?}",
                                err
                            );
                            select! {
                                _ = sleep(Duration::from_secs(15)) => {
                                    // continue
                                }
                                _ = self.token.cancelled() => {
                                    tracing::debug!("Cancellation received, shutting down cch service");
                                    return;
                                }
                            }
                        }
                    }
                }
                _ = self.token.cancelled() => {
                    tracing::debug!("Cancellation received, shutting down cch service");
                    return;
                }
            }
        }
    }

    async fn run_inner(&self) -> Result<()> {
        let mut client = self.lnd_connection.create_router_client().await?;
        let mut stream = client
            .track_payments(routerrpc::TrackPaymentsRequest {
                no_inflight_updates: true,
            })
            .await?
            .into_inner();

        loop {
            select! {
                payment_opt = stream.next() => {
                    match payment_opt {
                        Some(Ok(payment)) => self.on_payment(payment).await?,
                        Some(Err(err)) => return Err(err.into()),
                        None => return Err(anyhow!("unexpected closed stream")),
                    }
                }
                _ = self.token.cancelled() => {
                    tracing::debug!("Cancellation received, shutting down cch service");
                    return Ok(());
                }
            }
        }
    }

    async fn on_payment(&self, payment: lnrpc::Payment) -> Result<()> {
        tracing::debug!(target: "fnn::cch::actor::tracker::lnd_payments", "payment: {:?}", payment);
        let event = CchMessage::SettleSendBTCOrder(SettleSendBTCOrderEvent {
            payment_hash: format!("0x{}", payment.payment_hash),
            preimage: (!payment.payment_preimage.is_empty())
                .then(|| format!("0x{}", payment.payment_preimage)),
            status: lnrpc::payment::PaymentStatus::try_from(payment.status)
                .map(Into::into)
                .unwrap_or(CchOrderStatus::InFlight),
        });
        self.cch_actor.cast(event).map_err(Into::into)
    }
}

/// Subscribe single invoice.
///
/// Lnd does not notify Accepted event in SubscribeInvoices rpc.
///
/// <https://github.com/lightningnetwork/lnd/blob/07b6af41dbe2a5a1c85e5c46cc41019b64640d90/invoices/invoiceregistry.go#L292-L293>
struct LndInvoiceTracker {
    cch_actor: ActorRef<CchMessage>,
    payment_hash: String,
    lnd_connection: LndConnectionInfo,
    token: CancellationToken,
}

impl LndInvoiceTracker {
    fn new(
        cch_actor: ActorRef<CchMessage>,
        payment_hash: String,
        lnd_connection: LndConnectionInfo,
        token: CancellationToken,
    ) -> Self {
        Self {
            cch_actor,
            payment_hash,
            lnd_connection,
            token,
        }
    }

    async fn run(self) {
        tracing::debug!(
            target: "fnn::cch::actor::tracker::lnd_invoice",
            "will connect {}",
            self.lnd_connection.uri
        );
        loop {
            select! {
                result = self.run_inner() => {
                    match result {
                        Ok(_) => {
                            break;
                        }
                        Err(err) => {
                            tracing::error!(
                                target: "fnn::cch::actor::tracker::lnd_invoice",
                                "Error tracking LND invoices, retry 15 seconds later: {:?}",
                                err
                            );
                            select! {
                                _ = sleep(Duration::from_secs(15)) => {
                                    // continue
                                }
                                _ = self.token.cancelled() => {
                                    tracing::debug!("Cancellation received, shutting down cch service");
                                    return;
                                }
                            }
                        }
                    }
                }
                _ = self.token.cancelled() => {
                    tracing::debug!("Cancellation received, shutting down cch service");
                    return;
                }
            }
        }
    }

    async fn run_inner(&self) -> Result<()> {
        let mut client = self.lnd_connection.create_invoices_client().await?;
        // TODO: clean up expired orders
        let mut stream = client
            .subscribe_single_invoice(invoicesrpc::SubscribeSingleInvoiceRequest {
                r_hash: hex::decode(self.payment_hash.trim_start_matches("0x"))?,
            })
            .await?
            .into_inner();

        loop {
            select! {
                invoice_opt = stream.next() => {
                    match invoice_opt {
                        Some(Ok(invoice)) => if self.on_invoice(invoice).await? {
                            return Ok(());
                        },
                        Some(Err(err)) => return Err(err.into()),
                        None => return Err(anyhow!("unexpected closed stream")),
                    }
                }
                _ = self.token.cancelled() => {
                    tracing::debug!("Cancellation received, shutting down cch service");
                    return Ok(());
                }
            }
        }
    }

    // Return true to quit the tracker
    async fn on_invoice(&self, invoice: lnrpc::Invoice) -> Result<bool> {
        tracing::debug!("[LndInvoiceTracker] invoice: {:?}", invoice);
        let status = lnrpc::invoice::InvoiceState::try_from(invoice.state)
            .map(Into::into)
            .unwrap_or(CchOrderStatus::Pending);
        let event = CchMessage::SettleReceiveBTCOrder(SettleReceiveBTCOrderEvent {
            payment_hash: format!("0x{}", hex::encode(invoice.r_hash)),
            preimage: (!invoice.r_preimage.is_empty())
                .then(|| format!("0x{}", hex::encode(invoice.r_preimage))),
            status,
        });
        self.cch_actor.cast(event)?;
        // Quit tracker when the status is final
        Ok(status == CchOrderStatus::Succeeded || status == CchOrderStatus::Failed)
    }
}


================================================
File: src/cch/config.rs
================================================
use std::path::PathBuf;

use clap_serde_derive::ClapSerde;

/// Default cross-chain order expiry time in seconds.
pub const DEFAULT_ORDER_EXPIRY_TIME: u64 = 3600;
/// Default BTC final-hop HTLC expiry time in seconds.
pub const DEFAULT_BTC_FINAL_TLC_EXPIRY_TIME: u64 = 36;
/// Default CKB final-hop HTLC expiry delta in timestamp (in milliseconds), 24 hours.
pub const DEFAULT_CKB_FINAL_TLC_EXPIRY_DELTA: u64 = 24 * 60 * 60 * 1000;

// Use prefix `cch-`/`CCH_`
#[derive(ClapSerde, Debug, Clone)]
pub struct CchConfig {
    /// cch base directory
    #[arg(
        name = "CCH_BASE_DIR",
        long = "cch-base-dir",
        env,
        help = "base directory for cch [default: $BASE_DIR/cch]"
    )]
    pub base_dir: Option<PathBuf>,

    #[default("https://127.0.0.1:10009".to_string())]
    #[arg(
        name = "CCH_LND_RPC_URL",
        long = "cch-lnd-rpc-url",
        env,
        help = "lnd grpc endpoint, default is http://127.0.0.1:10009"
    )]
    pub lnd_rpc_url: String,

    #[arg(
        name = "CCH_LND_CERT_PATH",
        long = "cch-lnd-cert-path",
        env,
        help = "Path to the TLS cert file for the grpc connection. Leave it empty to use wellknown CA certificates like Let's Encrypt."
    )]
    pub lnd_cert_path: Option<String>,

    #[arg(
        name = "CCH_LND_MACAROON_PATH",
        long = "cch-lnd-macaroon-path",
        env,
        help = "Path to the Macaroon file for the grpc connection"
    )]
    pub lnd_macaroon_path: Option<String>,

    // TODO: use hex type
    #[arg(
        name = "CCH_WRAPPED_BTC_TYPE_SCRIPT_ARGS",
        long = "cch-wrapped-btc-type-script-args",
        env,
        help = "Wrapped BTC type script args. It must be a UDT with 8 decimal places."
    )]
    pub wrapped_btc_type_script_args: String,

    /// Cross-chain order expiry time in seconds.
    #[default(DEFAULT_ORDER_EXPIRY_TIME)]
    #[arg(
        name = "CCH_ORDER_EXPIRY",
        long = "cch-order-expiry",
        env,
        help = format!("order expiry time in seconds, default is {}", DEFAULT_ORDER_EXPIRY_TIME),
    )]
    pub order_expiry: u64,

    #[default(0)]
    #[arg(
        name = "CCH_BASE_FEE_SATS",
        long = "cch-base-fee-sats",
        env,
        help = "The base fee charged for each cross-chain order, default is 0"
    )]
    pub base_fee_sats: u64,

    #[default(1)]
    #[arg(
        name = "CCH_FEE_RATE_PER_MILLION_SATS",
        long = "cch-fee-rate-per-million-sats",
        env,
        help = "The proportional fee charged per million satoshis based on the cross-chain order value, default is 1"
    )]
    pub fee_rate_per_million_sats: u64,

    /// Final tlc expiry time for BTC network.
    #[default(DEFAULT_BTC_FINAL_TLC_EXPIRY_TIME)]
    #[arg(
        name = "CCH_BTC_FINAL_TLC_EXPIRY",
        long = "cch-btc-final-tlc-expiry",
        env,
        help = format!("final tlc expiry time in seconds for BTC network, default is {}", DEFAULT_BTC_FINAL_TLC_EXPIRY_TIME),
    )]
    pub btc_final_tlc_expiry: u64,

    /// Tlc expiry time for CKB network in blocks.
    #[default(DEFAULT_CKB_FINAL_TLC_EXPIRY_DELTA)]
    #[arg(
        name = "CCH_CKB_FINAL_TLC_EXPIRY_DELTA",
        long = "cch-ckb-final-tlc-expiry-delta",
        env,
        help = format!("final tlc expiry delta in timestamp for CKB network, default is {}", DEFAULT_CKB_FINAL_TLC_EXPIRY_DELTA),
    )]
    pub ckb_final_tlc_expiry_delta: u64,

    /// Ignore the failure when starting the cch service.
    #[default(false)]
    #[arg(skip)]
    pub ignore_startup_failure: bool,
}

impl CchConfig {
    pub fn resolve_lnd_cert_path(&self) -> Option<PathBuf> {
        self.lnd_cert_path.as_ref().map(|lnd_cert_path| {
            let path = PathBuf::from(lnd_cert_path);
            match (self.base_dir.clone(), path.is_relative()) {
                (Some(base_dir), true) => base_dir.join(path),
                _ => path,
            }
        })
    }

    pub fn resolve_lnd_macaroon_path(&self) -> Option<PathBuf> {
        self.lnd_macaroon_path.as_ref().map(|lnd_macaroon_path| {
            let path = PathBuf::from(lnd_macaroon_path);
            match (self.base_dir.clone(), path.is_relative()) {
                (Some(base_dir), true) => base_dir.join(path),
                _ => path,
            }
        })
    }
}


================================================
File: src/cch/error.rs
================================================
use std::time::SystemTimeError;

use jsonrpsee::types::{error::CALL_EXECUTION_FAILED_CODE, ErrorObjectOwned};
use thiserror::Error;

#[derive(Error, Debug)]
pub enum CchDbError {
    #[error("Inserting duplicated key: {0}")]
    Duplicated(String),

    #[error("Key not found: {0}")]
    NotFound(String),
}

#[derive(Error, Debug)]
pub enum CchError {
    #[error("Database error: {0}")]
    DbError(#[from] CchDbError),
    #[error("BTC invoice parse error: {0}")]
    BTCInvoiceParseError(#[from] lightning_invoice::ParseOrSemanticError),
    #[error("BTC invoice expired")]
    BTCInvoiceExpired,
    #[error("BTC invoice missing amount")]
    BTCInvoiceMissingAmount,
    #[error("CKB invoice error: {0}")]
    CKBInvoiceError(#[from] crate::invoice::InvoiceError),
    #[error("SendBTC order already paid")]
    SendBTCOrderAlreadyPaid,
    #[error("SendBTC received payment amount is too small")]
    SendBTCReceivedAmountTooSmall,
    #[error("ReceiveBTC order payment amount is too small")]
    ReceiveBTCOrderAmountTooSmall,
    #[error("ReceiveBTC order payment amount is too large")]
    ReceiveBTCOrderAmountTooLarge,
    #[error("ReceiveBTC order already paid")]
    ReceiveBTCOrderAlreadyPaid,
    #[error("ReceiveBTC received payment amount is too small")]
    ReceiveBTCReceivedAmountTooSmall,
    #[error("ReceiveBTC expected preimage but missing")]
    ReceiveBTCMissingPreimage,
    #[error("System time error: {0}")]
    SystemTimeError(#[from] SystemTimeError),
    #[error("JSON serialization error: {0}")]
    JSONSerializationError(#[from] serde_json::Error),
    #[error("Hex decoding error from string: {0}")]
    HexDecodingError(String),
    #[error("Lnd channel error: {0}")]
    LndChannelError(#[from] lnd_grpc_tonic_client::channel::Error),
    #[error("Lnd RPC error: {0}")]
    LndRpcError(String),
}

pub type CchResult<T> = std::result::Result<T, CchError>;

impl From<CchError> for ErrorObjectOwned {
    fn from(val: CchError) -> Self {
        // TODO: categorize error codes
        ErrorObjectOwned::owned(
            CALL_EXECUTION_FAILED_CODE,
            val.to_string(),
            Option::<()>::None,
        )
    }
}


================================================
File: src/cch/mod.rs
================================================
mod actor;
pub use actor::{start_cch, CchActor, CchMessage, ReceiveBTC, SendBTC};

mod error;
pub use error::{CchError, CchResult};

mod config;
pub use config::{
    CchConfig, DEFAULT_BTC_FINAL_TLC_EXPIRY_TIME, DEFAULT_CKB_FINAL_TLC_EXPIRY_DELTA,
    DEFAULT_ORDER_EXPIRY_TIME,
};

mod order;
pub use order::{CchOrderStatus, ReceiveBTCOrder, SendBTCOrder};

mod orders_db;
pub use orders_db::CchOrdersDb;


================================================
File: src/cch/order.rs
================================================
use super::CchError;
use lnd_grpc_tonic_client::lnrpc;
use serde::{Deserialize, Serialize};
use serde_with::serde_as;
use std::{str::FromStr as _, time::Duration};

use crate::{
    fiber::{
        serde_utils::{U128Hex, U64Hex},
        types::Hash256,
    },
    invoice::{Currency, InvoiceBuilder},
};

/// The status of a cross-chain hub order, will update as the order progresses.
#[derive(Debug, Copy, Clone, Serialize, Deserialize, Eq, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum CchOrderStatus {
    /// Order is created and has not send out payments yet.
    Pending = 0,
    /// HTLC in the first half is accepted.
    Accepted = 1,
    /// There's an outgoing payment in flight for the second half.
    InFlight = 2,
    /// Order is settled.
    Succeeded = 3,
    /// Order is failed.
    Failed = 4,
}

/// lnd payment is the second half of SendBTCOrder
impl From<lnrpc::payment::PaymentStatus> for CchOrderStatus {
    fn from(status: lnrpc::payment::PaymentStatus) -> Self {
        use lnrpc::payment::PaymentStatus;
        match status {
            PaymentStatus::Succeeded => CchOrderStatus::Succeeded,
            PaymentStatus::Failed => CchOrderStatus::Failed,
            _ => CchOrderStatus::InFlight,
        }
    }
}

/// lnd invoice is the first half of ReceiveBTCOrder
impl From<lnrpc::invoice::InvoiceState> for CchOrderStatus {
    fn from(state: lnrpc::invoice::InvoiceState) -> Self {
        use lnrpc::invoice::InvoiceState;
        // Set to InFlight only when a CKB HTLC is created
        match state {
            InvoiceState::Accepted => CchOrderStatus::Accepted,
            InvoiceState::Canceled => CchOrderStatus::Failed,
            InvoiceState::Settled => CchOrderStatus::Succeeded,
            _ => CchOrderStatus::Pending,
        }
    }
}

#[serde_as]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SendBTCOrder {
    // Seconds since epoch when the order is created
    #[serde_as(as = "U64Hex")]
    pub created_at: u64,
    // Seconds after timestamp that the order expires
    #[serde_as(as = "U64Hex")]
    pub expires_after: u64,
    // The minimal expiry delta in milliseconds of the final TLC hop in the CKB network
    #[serde_as(as = "U64Hex")]
    pub ckb_final_tlc_expiry_delta: u64,

    pub currency: Currency,
    pub wrapped_btc_type_script: ckb_jsonrpc_types::Script,

    pub btc_pay_req: String,
    pub ckb_pay_req: String,
    pub payment_hash: String,
    pub payment_preimage: Option<String>,
    pub channel_id: Option<Hash256>,
    #[serde_as(as = "Option<U64Hex>")]
    pub tlc_id: Option<u64>,

    #[serde_as(as = "U128Hex")]
    /// Amount required to pay in Satoshis via wrapped BTC, including the fee for the cross-chain hub
    pub amount_sats: u128,
    #[serde_as(as = "U128Hex")]
    pub fee_sats: u128,

    pub status: CchOrderStatus,
}

impl SendBTCOrder {
    pub fn generate_ckb_invoice(&mut self) -> Result<(), CchError> {
        let invoice_builder = InvoiceBuilder::new(self.currency)
            .amount(Some(self.amount_sats))
            .payment_hash(
                Hash256::from_str(&self.payment_hash)
                    .map_err(|_| CchError::HexDecodingError(self.payment_hash.clone()))?,
            )
            .expiry_time(Duration::from_secs(self.expires_after))
            .final_expiry_delta(self.ckb_final_tlc_expiry_delta)
            .udt_type_script(self.wrapped_btc_type_script.clone().into());

        let invoice = invoice_builder.build()?;
        self.ckb_pay_req = invoice.to_string();

        Ok(())
    }
}

#[serde_as]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReceiveBTCOrder {
    // Seconds since epoch when the order is created
    #[serde_as(as = "U64Hex")]
    pub created_at: u64,
    // Seconds after timestamp that the order expires
    #[serde_as(as = "U64Hex")]
    pub expires_after: u64,
    // The minimal expiry in seconds of the final TLC in the CKB network
    #[serde_as(as = "U64Hex")]
    pub ckb_final_tlc_expiry_delta: u64,

    pub wrapped_btc_type_script: ckb_jsonrpc_types::Script,

    pub btc_pay_req: String,
    pub payment_hash: String,
    pub payment_preimage: Option<String>,
    pub channel_id: Hash256,
    #[serde_as(as = "Option<U64Hex>")]
    pub tlc_id: Option<u64>,

    /// Amount required to pay in Satoshis via BTC, including the fee for the cross-chain hub
    #[serde_as(as = "U128Hex")]
    pub amount_sats: u128,
    #[serde_as(as = "U128Hex")]
    pub fee_sats: u128,

    pub status: CchOrderStatus,
}


================================================
File: src/cch/orders_db.rs
================================================
use std::collections::HashMap;

use super::{error::CchDbError, ReceiveBTCOrder, SendBTCOrder};

// TODO: persist orders
#[derive(Default)]
pub struct CchOrdersDb {
    /// SendBTCOrder map by payment hash
    send_btc_orders: HashMap<String, SendBTCOrder>,
    receive_btc_orders: HashMap<String, ReceiveBTCOrder>,
}

impl CchOrdersDb {
    pub async fn insert_send_btc_order(&mut self, order: SendBTCOrder) -> Result<(), CchDbError> {
        let key = order.payment_hash.clone();
        match self.send_btc_orders.insert(key.clone(), order) {
            Some(_) => Err(CchDbError::Duplicated(key)),
            None => Ok(()),
        }
    }

    pub async fn get_send_btc_order(
        &mut self,
        payment_hash: &str,
    ) -> Result<SendBTCOrder, CchDbError> {
        self.send_btc_orders
            .get(payment_hash)
            .ok_or_else(|| CchDbError::NotFound(payment_hash.to_string()))
            .cloned()
    }

    pub async fn update_send_btc_order(&mut self, order: SendBTCOrder) -> Result<(), CchDbError> {
        let key = order.payment_hash.clone();
        match self.send_btc_orders.insert(key.clone(), order) {
            Some(_) => Ok(()),
            None => Err(CchDbError::NotFound(key)),
        }
    }

    pub async fn insert_receive_btc_order(
        &mut self,
        order: ReceiveBTCOrder,
    ) -> Result<(), CchDbError> {
        let key = order.payment_hash.clone();
        match self.receive_btc_orders.insert(key.clone(), order) {
            Some(_) => Err(CchDbError::Duplicated(key)),
            None => Ok(()),
        }
    }

    pub async fn get_receive_btc_order(
        &mut self,
        payment_hash: &str,
    ) -> Result<ReceiveBTCOrder, CchDbError> {
        self.receive_btc_orders
            .get(payment_hash)
            .ok_or_else(|| CchDbError::NotFound(payment_hash.to_string()))
            .cloned()
    }

    pub async fn update_receive_btc_order(
        &mut self,
        order: ReceiveBTCOrder,
    ) -> Result<(), CchDbError> {
        let key = order.payment_hash.clone();
        match self.receive_btc_orders.insert(key.clone(), order) {
            Some(_) => Ok(()),
            None => Err(CchDbError::NotFound(key)),
        }
    }
}


================================================
File: src/ckb/actor.rs
================================================
use ckb_sdk::{rpc::ResponseFormatGetter, CkbRpcClient, RpcError};
use ckb_types::{core::TransactionView, packed, prelude::*, H256};
use ractor::{
    concurrency::{sleep, Duration},
    Actor, ActorProcessingErr, ActorRef, RpcReplyPort,
};
use tracing::debug;

use crate::ckb::contracts::{get_script_by_contract, Contract};

use super::{funding::FundingContext, CkbConfig, FundingError, FundingRequest, FundingTx};

pub struct CkbChainActor {}

#[derive(Clone, Debug)]
pub struct CkbChainState {
    config: CkbConfig,
    secret_key: secp256k1::SecretKey,
    funding_source_lock_script: packed::Script,
}

#[derive(Debug, Clone)]
pub struct TraceTxRequest {
    pub tx_hash: packed::Byte32,
    // How many confirmations required to consider the transaction committed.
    pub confirmations: u64,
}

#[derive(Debug)]
pub struct TraceTxResponse {
    pub tx: Option<ckb_jsonrpc_types::TransactionView>,
    pub status: ckb_jsonrpc_types::TxStatus,
}

impl TraceTxResponse {
    pub fn new(
        tx: Option<ckb_jsonrpc_types::TransactionView>,
        status: ckb_jsonrpc_types::TxStatus,
    ) -> Self {
        Self { tx, status }
    }
}

#[derive(Debug, Clone)]
pub struct GetBlockTimestampRequest {
    block_hash: H256,
}

impl GetBlockTimestampRequest {
    pub fn from_block_hash(block_hash: H256) -> Self {
        Self { block_hash }
    }

    pub fn block_hash(&self) -> H256 {
        self.block_hash.clone()
    }
}

pub type GetBlockTimestampResponse = u64;

#[derive(Debug)]
pub enum CkbChainMessage {
    Fund(
        FundingTx,
        FundingRequest,
        RpcReplyPort<Result<FundingTx, FundingError>>,
    ),
    Sign(FundingTx, RpcReplyPort<Result<FundingTx, FundingError>>),
    SendTx(TransactionView, RpcReplyPort<Result<(), RpcError>>),
    TraceTx(TraceTxRequest, RpcReplyPort<TraceTxResponse>),
    GetBlockTimestamp(
        GetBlockTimestampRequest,
        RpcReplyPort<Result<Option<GetBlockTimestampResponse>, RpcError>>,
    ),
}

#[ractor::async_trait]
impl Actor for CkbChainActor {
    type Msg = CkbChainMessage;
    type State = CkbChainState;
    type Arguments = CkbConfig;

    async fn pre_start(
        &self,
        _myself: ActorRef<Self::Msg>,
        config: Self::Arguments,
    ) -> Result<Self::State, ActorProcessingErr> {
        let secret_key = config.read_secret_key()?;
        let secp = secp256k1::Secp256k1::new();
        let pub_key = secret_key.public_key(&secp);
        let pub_key_hash = ckb_hash::blake2b_256(pub_key.serialize());
        let funding_source_lock_script =
            get_script_by_contract(Contract::Secp256k1Lock, &pub_key_hash[0..20]);
        Ok(CkbChainState {
            config,
            secret_key,
            funding_source_lock_script,
        })
    }

    async fn handle(
        &self,
        myself: ActorRef<Self::Msg>,
        message: Self::Msg,
        state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        use CkbChainMessage::{Fund, SendTx, Sign, TraceTx};
        match message {
            Fund(tx, request, reply_port) => {
                let context = state.build_funding_context(&request);
                if !reply_port.is_closed() {
                    tokio::task::block_in_place(move || {
                        let result = tx.fulfill(request, context);
                        if !reply_port.is_closed() {
                            // ignore error
                            let _ = reply_port.send(result);
                        }
                    });
                }
            }
            Sign(tx, reply_port) => {
                if !reply_port.is_closed() {
                    let secret_key = state.secret_key;
                    let rpc_url = state.config.rpc_url.clone();
                    tokio::task::block_in_place(move || {
                        let result = tx.sign(secret_key, rpc_url);
                        if !reply_port.is_closed() {
                            // ignore error
                            let _ = reply_port.send(result);
                        }
                    });
                }
            }
            SendTx(tx, reply_port) => {
                let rpc_url = state.config.rpc_url.clone();
                tokio::task::block_in_place(move || {
                    let ckb_client = CkbRpcClient::new(&rpc_url);
                    let result = match ckb_client.send_transaction(tx.data().into(), None) {
                        Ok(_) => Ok(()),
                        Err(err) => {
                            //FIXME(yukang): RBF or duplicated transaction handling
                            match err {
                                RpcError::Rpc(e)
                                    if (e.code.code() == -1107 || e.code.code() == -1111) =>
                                {
                                    tracing::warn!(
                                        "[{}] transaction { } already in pool",
                                        myself.get_name().unwrap_or_default(),
                                        tx.hash(),
                                    );
                                    Ok(())
                                }
                                _ => {
                                    tracing::error!(
                                        "[{}] send transaction {} failed: {:?}",
                                        myself.get_name().unwrap_or_default(),
                                        tx.hash(),
                                        err
                                    );
                                    Err(err)
                                }
                            }
                        }
                    };
                    if !reply_port.is_closed() {
                        // ignore error
                        let _ = reply_port.send(result);
                    }
                });
            }
            TraceTx(
                TraceTxRequest {
                    tx_hash,
                    confirmations,
                },
                reply_port,
            ) => {
                debug!(
                    "[{}] trace transaction {} with {} confs",
                    myself.get_name().unwrap_or_default(),
                    tx_hash,
                    confirmations
                );
                // TODO: Need a better way to trace the transaction.
                while !reply_port.is_closed() {
                    let actor_name = myself.get_name().unwrap_or_default();
                    let rpc_url = state.config.rpc_url.clone();
                    let tx_hash = tx_hash.clone();
                    let status = tokio::task::block_in_place(move || {
                        let ckb_client = CkbRpcClient::new(&rpc_url);
                        // FIXME: `get_transaction_status` is only called with verbosity = 1 in sdk now
                        match ckb_client.get_only_committed_transaction(tx_hash.unpack()) {
                            Ok(resp) => match resp.tx_status.status {
                                ckb_jsonrpc_types::Status::Committed => {
                                    match ckb_client.get_tip_block_number() {
                                        Ok(tip_number) => {
                                            let tip_number: u64 = tip_number.into();
                                            let commit_number: u64 = resp
                                                .tx_status
                                                .block_number
                                                .unwrap_or_default()
                                                .into();
                                            let transaction = match resp
                                                .transaction
                                                .map(|x| x.get_value())
                                                .transpose()
                                            {
                                                Ok(Some(tx)) => Some(tx),
                                                Ok(None) => None,
                                                Err(err) => {
                                                    tracing::error!(
                                                        "[{}] get transaction failed: {:?}",
                                                        actor_name,
                                                        err
                                                    );
                                                    None
                                                }
                                            };
                                            (tip_number >= commit_number + confirmations).then_some(
                                                TraceTxResponse::new(transaction, resp.tx_status),
                                            )
                                        }
                                        Err(err) => {
                                            tracing::error!(
                                                "[{}] get tip block number failed: {:?}",
                                                actor_name,
                                                err
                                            );
                                            None
                                        }
                                    }
                                }
                                ckb_jsonrpc_types::Status::Rejected => {
                                    Some(TraceTxResponse::new(None, resp.tx_status))
                                }
                                _ => None,
                            },
                            Err(err) => {
                                tracing::error!(
                                    "[{}] get transaction status failed: {:?}",
                                    actor_name,
                                    err
                                );
                                None
                            }
                        }
                    });
                    match status {
                        Some(status) => {
                            if !reply_port.is_closed() {
                                // ignore error
                                let _ = reply_port.send(status);
                            }
                            return Ok(());
                        }
                        None => sleep(Duration::from_secs(5)).await,
                    }
                }
            }
            CkbChainMessage::GetBlockTimestamp(
                GetBlockTimestampRequest { block_hash },
                reply_port,
            ) => {
                let rpc_url = state.config.rpc_url.clone();
                tokio::task::block_in_place(move || {
                    let ckb_client = CkbRpcClient::new(&rpc_url);
                    let _ = reply_port.send(
                        ckb_client
                            .get_header(block_hash)
                            .map(|x| x.map(|x| x.inner.timestamp.into())),
                    );
                });
            }
        }
        Ok(())
    }
}

impl CkbChainState {
    fn build_funding_context(&self, request: &FundingRequest) -> FundingContext {
        FundingContext {
            secret_key: self.secret_key,
            rpc_url: self.config.rpc_url.clone(),
            funding_source_lock_script: self.funding_source_lock_script.clone(),
            funding_cell_lock_script: request.script.clone(),
        }
    }
}


================================================
File: src/ckb/config.rs
================================================
use ckb_hash::blake2b_256;
use clap_serde_derive::ClapSerde;
use secp256k1::{Secp256k1, SecretKey};
use serde_with::serde_as;
use std::{
    io::{ErrorKind, Read},
    path::PathBuf,
    str::FromStr,
};

use ckb_types::core::ScriptHashType;
use ckb_types::prelude::Builder;
use ckb_types::prelude::Pack;
use ckb_types::H256;
use ckb_types::{
    core::DepType,
    packed::{CellDep, OutPoint, Script},
};
use clap_serde_derive::clap::{self};
use molecule::prelude::Entity;
use serde::{Deserialize, Serialize};

use super::contracts::{get_script_by_contract, Contract};

pub const DEFAULT_CKB_BASE_DIR_NAME: &str = "ckb";
const DEFAULT_CKB_NODE_RPC_URL: &str = "http://127.0.0.1:8114";

#[derive(ClapSerde, Debug, Clone)]
pub struct CkbConfig {
    /// ckb base directory
    #[arg(
        name = "CKB_BASE_DIR",
        long = "ckb-base-dir",
        env,
        help = format!("base directory for ckb actor [default: $BASE_DIR/{}]", DEFAULT_CKB_BASE_DIR_NAME)
    )]
    pub base_dir: Option<PathBuf>,

    #[default(DEFAULT_CKB_NODE_RPC_URL.to_string())]
    #[arg(
        name = "CKB_NODE_RPC_URL",
        long = "ckb-node-rpc-url",
        env,
        help = "rpc url to connect the ckb node [default: http://127.0.0.1:8114]"
    )]
    pub rpc_url: String,

    #[arg(
        name = "CKB_UDT_WHITELIST",
        long = "ckb-udt-whitelist",
        env,
        help = "a list of supported UDT scripts"
    )]
    pub udt_whitelist: Option<UdtCfgInfos>,
}

impl CkbConfig {
    pub fn base_dir(&self) -> &PathBuf {
        self.base_dir.as_ref().expect("have set base dir")
    }

    pub fn create_base_dir(&self) -> crate::Result<()> {
        if !self.base_dir().exists() {
            std::fs::create_dir_all(self.base_dir()).map_err(Into::into)
        } else {
            Ok(())
        }
    }

    // TODO: Use keystore and password to read secret key and add an RPC method to authorize the secret key access.
    pub fn read_secret_key(&self) -> crate::Result<SecretKey> {
        self.create_base_dir()?;
        let path = self.base_dir().join("key");
        let mut file = std::fs::File::open(&path)?;

        let warn = |m: bool, d: &str| {
            if m {
                tracing::warn!(
                    "Your secret file's permission is not {}, path: {:?}. \
                Please fix it as soon as possible",
                    d,
                    path
                )
            }
        };
        #[cfg(unix)]
        {
            use std::os::unix::fs::PermissionsExt;
            warn(
                file.metadata()?.permissions().mode() & 0o177 != 0,
                "less than 0o600",
            );
        }
        #[cfg(not(unix))]
        {
            warn(!file.metadata()?.permissions().readonly(), "readonly");
        }

        let mut key_hex: String = Default::default();
        file.read_to_string(&mut key_hex)?;
        let key_bin = hex::decode(key_hex.trim())
            .map_err(|_| std::io::Error::new(ErrorKind::InvalidData, "invalid secret key data"))?;
        SecretKey::from_slice(&key_bin).map_err(|_| {
            std::io::Error::new(ErrorKind::InvalidData, "invalid secret key data").into()
        })
    }

    pub fn get_default_funding_lock_script(&self) -> crate::Result<Script> {
        let secret_key = self.read_secret_key()?;
        let secp = Secp256k1::new();
        let pubkey_hash = blake2b_256(secret_key.public_key(&secp).serialize());
        Ok(get_script_by_contract(
            Contract::Secp256k1Lock,
            &pubkey_hash[0..20],
        ))
    }
}

serde_with::serde_conv!(
    ScriptHashTypeWrapper,
    ScriptHashType,
    |s: &ScriptHashType| -> String {
        let v = match s {
            ScriptHashType::Type => "type",
            ScriptHashType::Data => "data",
            ScriptHashType::Data1 => "data1",
            ScriptHashType::Data2 => "data2",
        };
        v.to_string()
    },
    |s: String| {
        let v = match s.to_lowercase().as_str() {
            "type" => ScriptHashType::Type,
            "data" => ScriptHashType::Data,
            "data1" => ScriptHashType::Data1,
            "data2" => ScriptHashType::Data2,
            _ => return Err("invalid hash type"),
        };
        Ok(v)
    }
);

serde_with::serde_conv!(
    DepTypeWrapper,
    DepType,
    |s: &DepType| -> String {
        let v = match s {
            DepType::Code => "code",
            DepType::DepGroup => "dep_group",
        };
        v.to_string()
    },
    |s: String| {
        let v = match s.to_lowercase().as_str() {
            "code" => DepType::Code,
            "dep_group" => DepType::DepGroup,
            _ => return Err("invalid hash type"),
        };
        Ok(v)
    }
);

#[serde_as]
#[derive(Serialize, Deserialize, Debug, Clone, Default, Eq, PartialEq, Hash)]
pub struct UdtScript {
    pub code_hash: H256,
    #[serde_as(as = "ScriptHashTypeWrapper")]
    pub hash_type: ScriptHashType,
    /// args may be used in pattern matching
    pub args: String,
}

#[serde_as]
#[derive(Serialize, Deserialize, Clone, Debug, Eq, PartialEq, Hash)]
pub struct UdtCellDep {
    #[serde_as(as = "DepTypeWrapper")]
    pub dep_type: DepType,
    pub tx_hash: H256,
    pub index: u32,
}

#[derive(Serialize, Deserialize, Clone, Debug, Default, Eq, PartialEq, Hash)]
pub struct UdtArgInfo {
    pub name: String,
    pub script: UdtScript,
    pub auto_accept_amount: Option<u128>,
    pub cell_deps: Vec<UdtCellDep>,
}

/// The UDT configurations
#[derive(Serialize, Deserialize, Clone, Debug, Default, Eq, PartialEq, Hash)]
pub struct UdtCfgInfos(pub Vec<UdtArgInfo>);

impl FromStr for UdtCfgInfos {
    type Err = serde_json::Error;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        serde_json::from_str(s)
    }
}

impl From<&UdtCellDep> for CellDep {
    fn from(cell_dep: &UdtCellDep) -> Self {
        CellDep::new_builder()
            .dep_type(cell_dep.dep_type.into())
            .out_point(
                OutPoint::new_builder()
                    .tx_hash(cell_dep.tx_hash.pack())
                    .index(cell_dep.index.pack())
                    .build(),
            )
            .build()
    }
}


================================================
File: src/ckb/contracts.rs
================================================
use ckb_types::{
    core::{BlockView, DepType, ScriptHashType},
    packed::{CellDep, CellDepVec, CellDepVecBuilder, CellOutput, OutPoint, Script},
    prelude::{Builder, Entity, Pack, PackVec},
};
use once_cell::sync::OnceCell;
use regex::Regex;
use serde::{Deserialize, Serialize};
use std::{collections::HashMap, vec};
use thiserror::Error;
use tracing::info;

use crate::fiber::config::FiberScript;

use super::config::{UdtArgInfo, UdtCfgInfos};

#[derive(Serialize, Deserialize, Debug, PartialEq, Eq, Clone, Copy, Hash)]
pub enum Contract {
    CkbAuth,
    FundingLock,
    CommitmentLock,
    Secp256k1Lock,
    SimpleUDT,
}

#[derive(Clone, Debug)]
pub struct ContractsInfo {
    pub contract_default_scripts: HashMap<Contract, Script>,
    pub script_cell_deps: HashMap<Contract, Vec<CellDep>>,
    pub udt_whitelist: UdtCfgInfos,
}

#[derive(Clone, Debug)]
pub struct ContractsContext {
    pub contracts: ContractsInfo,
}

#[derive(Debug, Error)]
pub enum ContractsContextError {
    #[error("Context already initialized")]
    ContextAlreadyInitialized,

    #[error("Genesis block transaction #{0} should exist")]
    GenesisBlockTransactionNotFound(usize),

    #[error("Genesis block transaction #0 output #{0} should exist")]
    GenesisBlockTransaction0OutputNotFound(usize),

    #[error("Genesis block secp256k1 binary cell type script should exist")]
    GenesisBlockSecp256k1BinaryCellTypeScriptNotFound,
}

impl ContractsContext {
    pub fn try_new(
        genesis_block: BlockView,
        fiber_scripts: Vec<FiberScript>,
        udt_whitelist: UdtCfgInfos,
    ) -> Result<Self, ContractsContextError> {
        let mut contract_default_scripts: HashMap<Contract, Script> = HashMap::new();
        let mut script_cell_deps: HashMap<Contract, Vec<CellDep>> = HashMap::new();

        let genesis_tx = genesis_block
            .transaction(0)
            .ok_or(ContractsContextError::GenesisBlockTransactionNotFound(0))?;

        // setup secp256k1
        let secp256k1_binary_cell = genesis_tx
            .output(1)
            .ok_or(ContractsContextError::GenesisBlockTransaction0OutputNotFound(1))?;
        let secp256k1_binary_cell_type_script = secp256k1_binary_cell
            .type_()
            .to_opt()
            .ok_or(ContractsContextError::GenesisBlockSecp256k1BinaryCellTypeScriptNotFound)?;
        contract_default_scripts.insert(
            Contract::Secp256k1Lock,
            Script::new_builder()
                .code_hash(secp256k1_binary_cell_type_script.calc_script_hash())
                .hash_type(ScriptHashType::Type.into())
                .build(),
        );

        let secp256k1_dep_group_tx_hash = genesis_block
            .transaction(1)
            .ok_or(ContractsContextError::GenesisBlockTransactionNotFound(1))?
            .hash();
        let secp256k1_dep_group_out_point = OutPoint::new_builder()
            .tx_hash(secp256k1_dep_group_tx_hash)
            .index(0u32.pack())
            .build();
        script_cell_deps.insert(
            Contract::Secp256k1Lock,
            vec![CellDep::new_builder()
                .out_point(secp256k1_dep_group_out_point)
                .dep_type(DepType::DepGroup.into())
                .build()],
        );

        let genesis_hash = genesis_block.hash();
        match format!("{genesis_hash:#x}").as_str() {
            "0x92b197aa1fba0f63633922c61c92375c9c074a93e85963554f5499fe1450d0e5" => {
                info!("Creating ContractsContext for mainnet");
            }
            "0x10639e0895502b5688a6be8cf69460d76541bfa4821629d86d62ba0aae3f9606" => {
                info!("Creating ContractsContext for testnet");
            }
            _ => {
                info!("Creating ContractsContext for dev");
                // index from 5 ~ 8 are the default contracts: CkbAuth, FundingLock, CommitmentLock, SimpleUDT
                let ckb_auth_cell_dep = CellDep::new_builder()
                    .out_point(
                        OutPoint::new_builder()
                            .tx_hash(genesis_tx.hash())
                            .index(5u32.pack())
                            .build(),
                    )
                    .dep_type(DepType::Code.into())
                    .build();
                script_cell_deps.insert(Contract::CkbAuth, vec![ckb_auth_cell_dep.clone()]);

                let contract_map = [
                    (Contract::FundingLock, 6u32),
                    (Contract::CommitmentLock, 7u32),
                    (Contract::SimpleUDT, 8u32),
                ];
                for (contract, index) in contract_map.into_iter() {
                    let cell_dep = CellDep::new_builder()
                        .out_point(
                            OutPoint::new_builder()
                                .tx_hash(genesis_tx.hash())
                                .index(index.pack())
                                .build(),
                        )
                        .dep_type(DepType::Code.into())
                        .build();
                    let output_data = genesis_tx
                        .outputs_data()
                        .get(index as usize)
                        .ok_or(
                            ContractsContextError::GenesisBlockTransaction0OutputNotFound(
                                index as usize,
                            ),
                        )?
                        .raw_data();
                    let cell_deps =
                        if matches!(contract, Contract::FundingLock | Contract::CommitmentLock) {
                            vec![cell_dep, ckb_auth_cell_dep.clone()]
                        } else {
                            vec![cell_dep]
                        };
                    script_cell_deps.insert(contract, cell_deps);
                    contract_default_scripts.insert(
                        contract,
                        Script::new_builder()
                            .code_hash(CellOutput::calc_data_hash(&output_data))
                            .hash_type(ScriptHashType::Data1.into())
                            .build(),
                    );
                }
            }
        }

        // allow for overriding the default scripts and cell deps
        for fiber_script in fiber_scripts {
            let FiberScript {
                name,
                script,
                cell_deps,
            } = fiber_script;
            contract_default_scripts.insert(name, script.into());
            script_cell_deps.insert(name, cell_deps.into_iter().map(CellDep::from).collect());
        }

        Ok(Self {
            contracts: ContractsInfo {
                contract_default_scripts,
                script_cell_deps,
                udt_whitelist,
            },
        })
    }

    fn get_contracts_map(&self) -> &HashMap<Contract, Script> {
        &self.contracts.contract_default_scripts
    }

    pub(crate) fn get_cell_deps(&self, contracts: Vec<Contract>) -> CellDepVec {
        let mut builder: CellDepVecBuilder = CellDepVec::new_builder();
        for contract in contracts {
            if let Some(cell_deps) = self.contracts.script_cell_deps.get(&contract) {
                builder = builder.extend(cell_deps.clone());
            }
        }
        builder.build()
    }

    pub fn get_udt_whitelist(&self) -> &UdtCfgInfos {
        &self.contracts.udt_whitelist
    }

    pub(crate) fn get_script(&self, contract: Contract, args: &[u8]) -> Script {
        self.get_contracts_map()
            .get(&contract)
            .unwrap_or_else(|| panic!("Contract {:?} should exist", contract))
            .clone()
            .as_builder()
            .args(args.pack())
            .build()
    }

    pub(crate) fn get_udt_info(&self, udt_script: &Script) -> Option<&UdtArgInfo> {
        for udt in &self.get_udt_whitelist().0 {
            if let Ok(_type) = udt_script.hash_type().try_into() {
                if udt.script.code_hash.pack() == udt_script.code_hash()
                    && udt.script.hash_type == _type
                {
                    let args = format!("0x{:x}", udt_script.args().raw_data());
                    let pattern = Regex::new(&udt.script.args).expect("invalid expression");
                    if pattern.is_match(&args) {
                        return Some(udt);
                    }
                }
            }
        }
        None
    }
}

pub static CONTRACTS_CONTEXT_INSTANCE: OnceCell<ContractsContext> = OnceCell::new();

pub fn try_init_contracts_context(
    genesis_block: BlockView,
    fiber_scripts: Vec<FiberScript>,
    udt_whitelist: UdtCfgInfos,
) -> Result<(), ContractsContextError> {
    CONTRACTS_CONTEXT_INSTANCE
        .set(ContractsContext::try_new(
            genesis_block,
            fiber_scripts,
            udt_whitelist,
        )?)
        .map_err(|_| ContractsContextError::ContextAlreadyInitialized)
}

#[cfg(not(test))]
fn get_contracts_context() -> &'static ContractsContext {
    CONTRACTS_CONTEXT_INSTANCE
        .get()
        .expect("init_contracts_context should be called first")
}

#[cfg(test)]
fn get_contracts_context() -> ContractsContext {
    super::tests::test_utils::MOCK_CONTEXT
        .read()
        .expect("read mock context")
        .contracts_context
        .clone()
}

pub fn get_script_by_contract(contract: Contract, args: &[u8]) -> Script {
    get_contracts_context().get_script(contract, args)
}

pub fn get_cell_deps_by_contracts(contracts: Vec<Contract>) -> CellDepVec {
    get_contracts_context().get_cell_deps(contracts)
}

fn get_udt_info(script: &Script) -> Option<UdtArgInfo> {
    get_contracts_context().get_udt_info(script).cloned()
}

pub fn check_udt_script(script: &Script) -> bool {
    get_udt_info(script).is_some()
}

pub fn get_udt_cell_deps(script: &Script) -> Option<CellDepVec> {
    get_udt_info(script).map(|udt| {
        udt.cell_deps
            .iter()
            .map(CellDep::from)
            .collect::<Vec<_>>()
            .pack()
    })
}

pub fn get_udt_whitelist() -> UdtCfgInfos {
    get_contracts_context().get_udt_whitelist().clone()
}

pub fn is_udt_type_auto_accept(script: &Script, amount: u128) -> bool {
    if let Some(udt_info) = get_udt_info(script) {
        if let Some(auto_accept_amount) = udt_info.auto_accept_amount {
            return amount >= auto_accept_amount;
        }
    }
    false
}

pub fn get_cell_deps(contracts: Vec<Contract>, udt_script: &Option<Script>) -> CellDepVec {
    let cell_deps = get_cell_deps_by_contracts(contracts);
    if let Some(udt_script) = udt_script {
        if let Some(udt_cell_deps) = get_udt_cell_deps(udt_script) {
            let res = cell_deps
                .into_iter()
                .chain(udt_cell_deps)
                .collect::<Vec<CellDep>>();
            return res.pack();
        }
    }
    cell_deps
}


================================================
File: src/ckb/error.rs
================================================
use ckb_sdk::{tx_builder::TxBuilderError, unlock::UnlockError, RpcError};
use thiserror::Error;

#[derive(Error, Debug)]
pub enum FundingError {
    #[error("Funding tx is absent")]
    AbsentTx,

    #[error("Failed to call CKB node RPC: {0}")]
    CkbRpcError(#[from] RpcError),

    #[error("Failed to build CKB tx: {0}")]
    CkbTxBuilderError(#[from] TxBuilderError),

    #[error("Failed to sign CKB tx: {0}")]
    CkbTxUnlockError(#[from] UnlockError),

    #[error("Dead cell found in the tx")]
    DeadCell,

    #[error("The channel is invalid to fund")]
    InvalidChannel,
}

#[derive(Error, Debug)]
pub enum CkbChainError {
    #[error("Funding error: {0}")]
    FundingError(#[from] FundingError),
}


================================================
File: src/ckb/mod.rs
================================================
mod actor;
mod error;
mod funding;

pub use actor::{
    CkbChainActor, CkbChainMessage, GetBlockTimestampRequest, GetBlockTimestampResponse,
    TraceTxRequest, TraceTxResponse,
};
pub use config::{CkbConfig, DEFAULT_CKB_BASE_DIR_NAME};
pub use error::{CkbChainError, FundingError};
pub use funding::{FundingRequest, FundingTx};

pub mod config;
pub mod contracts;

#[cfg(test)]
pub mod tests;


================================================
File: src/ckb/funding/funding_tx.rs
================================================
use super::super::FundingError;
use crate::{ckb::contracts::get_udt_cell_deps, fiber::serde_utils::EntityHex};
use anyhow::anyhow;
use ckb_sdk::{
    constants::SIGHASH_TYPE_HASH,
    rpc::ckb_indexer::SearchMode,
    traits::{
        CellCollector, CellDepResolver, CellQueryOptions, DefaultCellCollector,
        DefaultCellDepResolver, DefaultHeaderDepResolver, DefaultTransactionDependencyProvider,
        HeaderDepResolver, SecpCkbRawKeySigner, TransactionDependencyProvider, ValueRangeOption,
    },
    tx_builder::{unlock_tx, CapacityBalancer, TxBuilder, TxBuilderError},
    unlock::{ScriptUnlocker, SecpSighashUnlocker},
    CkbRpcClient, ScriptId,
};
use ckb_types::{
    core::{BlockView, Capacity, TransactionView},
    packed::{self, Bytes, CellInput, CellOutput, Script, Transaction},
    prelude::*,
};
use molecule::{
    bytes::{BufMut as _, BytesMut},
    prelude::*,
};
use serde::Deserialize;
use serde_with::serde_as;
use std::collections::{HashMap, HashSet};
use tracing::debug;

/// Funding transaction wrapper.
///
/// It includes extra fields to verify the transaction.
#[derive(Clone, Debug, Default)]
pub struct FundingTx {
    tx: Option<TransactionView>,
}

impl From<TransactionView> for FundingTx {
    fn from(tx: TransactionView) -> Self {
        Self { tx: Some(tx) }
    }
}

impl From<Transaction> for FundingTx {
    fn from(tx: Transaction) -> Self {
        Self {
            tx: Some(tx.into_view()),
        }
    }
}

#[serde_as]
#[derive(Clone, Debug, Default, Deserialize)]
pub struct FundingRequest {
    /// The funding cell lock script args
    #[serde_as(as = "EntityHex")]
    pub script: Script,
    #[serde_as(as = "Option<EntityHex>")]
    pub udt_type_script: Option<packed::Script>,
    /// Assets amount to be provided by the local party
    pub local_amount: u128,
    /// Fee to be provided by the local party
    pub funding_fee_rate: u64,
    /// Assets amount to be provided by the remote party
    pub remote_amount: u128,
    /// CKB amount to be provided by the local party.
    pub local_reserved_ckb_amount: u64,
    /// CKB amount to be provided by the remote party.
    pub remote_reserved_ckb_amount: u64,
}

// TODO: trace locked cells
#[derive(Clone, Debug)]
pub struct FundingContext {
    pub secret_key: secp256k1::SecretKey,
    pub rpc_url: String,
    pub funding_source_lock_script: packed::Script,
    pub funding_cell_lock_script: packed::Script,
}

#[allow(dead_code)]
struct FundingTxBuilder {
    funding_tx: FundingTx,
    request: FundingRequest,
    context: FundingContext,
}

impl TxBuilder for FundingTxBuilder {
    fn build_base(
        &self,
        cell_collector: &mut dyn CellCollector,
        _cell_dep_resolver: &dyn CellDepResolver,
        _header_dep_resolver: &dyn HeaderDepResolver,
        _tx_dep_provider: &dyn TransactionDependencyProvider,
    ) -> Result<TransactionView, TxBuilderError> {
        let (funding_cell_output, funding_cell_output_data) = self
            .build_funding_cell()
            .map_err(|err| TxBuilderError::Other(err.into()))?;

        let mut inputs = vec![];
        let mut cell_deps = HashSet::new();

        // Funding cell does not need new cell deps and header deps. The type script deps will be added with inputs.
        let mut outputs: Vec<packed::CellOutput> = vec![funding_cell_output];
        let mut outputs_data: Vec<packed::Bytes> = vec![funding_cell_output_data];

        if let Some(ref tx) = self.funding_tx.tx {
            inputs = tx.inputs().into_iter().collect();
            cell_deps = tx.cell_deps().into_iter().collect();
        }
        self.build_udt_inputs_outputs(
            cell_collector,
            &mut inputs,
            &mut outputs,
            &mut outputs_data,
            &mut cell_deps,
        )?;
        if let Some(ref tx) = self.funding_tx.tx {
            for (i, output) in tx.outputs().into_iter().enumerate().skip(1) {
                outputs.push(output.clone());
                outputs_data.push(tx.outputs_data().get(i).unwrap_or_default().clone());
            }
        }

        let builder = match self.funding_tx.tx {
            Some(ref tx) => tx.as_advanced_builder(),
            None => packed::Transaction::default().as_advanced_builder(),
        };

        // set a placeholder_witness for calculating transaction fee according to transaction size
        let placeholder_witness = packed::WitnessArgs::new_builder()
            .lock(Some(molecule::bytes::Bytes::from(vec![0u8; 170])).pack())
            .build();

        let tx_builder = builder
            .set_inputs(inputs)
            .set_outputs(outputs)
            .set_outputs_data(outputs_data)
            .set_cell_deps(cell_deps.into_iter().collect())
            .set_witnesses(vec![placeholder_witness.as_bytes().pack()]);
        let tx = tx_builder.build();
        Ok(tx)
    }
}

impl FundingTxBuilder {
    fn build_funding_cell(&self) -> Result<(packed::CellOutput, packed::Bytes), FundingError> {
        // If outputs is not empty, assume that the remote party has already funded.
        let remote_funded = self
            .funding_tx
            .tx
            .as_ref()
            .map(|tx| !tx.outputs().is_empty())
            .unwrap_or(false);

        match self.request.udt_type_script {
            Some(ref udt_type_script) => {
                let mut udt_amount = self.request.local_amount;
                let mut ckb_amount = self.request.local_reserved_ckb_amount;

                // To make tx building easier, do not include the amount not funded yet in the
                // funding cell.
                if remote_funded {
                    udt_amount += self.request.remote_amount;
                    ckb_amount = ckb_amount
                        .checked_add(self.request.remote_reserved_ckb_amount)
                        .ok_or(FundingError::InvalidChannel)?;
                }

                let udt_output = packed::CellOutput::new_builder()
                    .capacity(Capacity::shannons(ckb_amount).pack())
                    .type_(Some(udt_type_script.clone()).pack())
                    .lock(self.context.funding_cell_lock_script.clone())
                    .build();
                let mut data = BytesMut::with_capacity(16);
                data.put(&udt_amount.to_le_bytes()[..]);

                // TODO: xudt extension
                Ok((udt_output, data.freeze().pack()))
            }
            None => {
                let mut ckb_amount =
                    self.request.local_amount as u64 + self.request.local_reserved_ckb_amount;
                if remote_funded {
                    ckb_amount = ckb_amount
                        .checked_add(
                            self.request.remote_amount as u64
                                + self.request.remote_reserved_ckb_amount,
                        )
                        .ok_or(FundingError::InvalidChannel)?;
                }
                let ckb_output = packed::CellOutput::new_builder()
                    .capacity(Capacity::shannons(ckb_amount).pack())
                    .lock(self.context.funding_cell_lock_script.clone())
                    .build();
                Ok((ckb_output, packed::Bytes::default()))
            }
        }
    }

    fn build_udt_inputs_outputs(
        &self,
        cell_collector: &mut dyn CellCollector,
        inputs: &mut Vec<CellInput>,
        outputs: &mut Vec<packed::CellOutput>,
        outputs_data: &mut Vec<packed::Bytes>,
        cell_deps: &mut HashSet<packed::CellDep>,
    ) -> Result<(), TxBuilderError> {
        let udt_amount = self.request.local_amount;
        // return early if we don't need to build UDT cell
        if self.request.udt_type_script.is_none() || udt_amount == 0 {
            return Ok(());
        }

        let udt_type_script = self.request.udt_type_script.clone().ok_or_else(|| {
            TxBuilderError::InvalidParameter(anyhow!("UDT type script not configured"))
        })?;
        let owner = self.context.funding_source_lock_script.clone();
        let mut found_udt_amount = 0;

        let mut query = CellQueryOptions::new_lock(owner.clone());
        query.script_search_mode = Some(SearchMode::Exact);
        query.secondary_script = Some(udt_type_script.clone());
        query.data_len_range = Some(ValueRangeOption::new_min(16));

        loop {
            // each query will found at most one cell because of `min_total_capacity == 1` in CellQueryOptions
            let (udt_cells, _) = cell_collector.collect_live_cells(&query, true)?;
            if udt_cells.is_empty() {
                break;
            }
            for cell in udt_cells.iter() {
                let mut amount_bytes = [0u8; 16];
                amount_bytes.copy_from_slice(&cell.output_data.as_ref()[0..16]);
                let cell_udt_amount = u128::from_le_bytes(amount_bytes);
                let ckb_amount: u64 = cell.output.capacity().unpack();
                debug!(
                    "found udt cell ckb_amount: {:?} udt_amount: {:?} cell: {:?}",
                    ckb_amount, cell_udt_amount, cell
                );
                found_udt_amount += cell_udt_amount;
                inputs.push(CellInput::new(cell.out_point.clone(), 0));

                if found_udt_amount >= udt_amount {
                    let change_output_data: Bytes =
                        (found_udt_amount - udt_amount).to_le_bytes().pack();

                    let dummy_output = CellOutput::new_builder()
                        .lock(owner)
                        .type_(Some(udt_type_script.clone()).pack())
                        .build();
                    let required_capacity = dummy_output
                        .occupied_capacity(
                            Capacity::bytes(change_output_data.len())
                                .map_err(|err| TxBuilderError::Other(err.into()))?,
                        )
                        .map_err(|err| TxBuilderError::Other(err.into()))?
                        .pack();
                    let change_output = dummy_output
                        .as_builder()
                        .capacity(required_capacity)
                        .build();

                    outputs.push(change_output);
                    outputs_data.push(change_output_data);

                    debug!("find proper UDT owner cells: {:?}", inputs);
                    // we need to filter the cell deps by the contracts_context
                    let udt_cell_deps = get_udt_cell_deps(&udt_type_script)
                        .ok_or_else(|| TxBuilderError::ResolveCellDepFailed(udt_type_script))?;
                    for cell_dep in udt_cell_deps {
                        cell_deps.insert(cell_dep);
                    }
                    return Ok(());
                }
            }
        }
        return Err(TxBuilderError::Other(anyhow!(
            "can not find enough UDT owner cells for funding transaction"
        )));
    }

    fn build(self) -> Result<FundingTx, FundingError> {
        // Build ScriptUnlocker
        let signer = SecpCkbRawKeySigner::new_with_secret_keys(vec![]);
        let sighash_unlocker = SecpSighashUnlocker::from(Box::new(signer) as Box<_>);
        let sighash_script_id = ScriptId::new_type(SIGHASH_TYPE_HASH.clone());
        let mut unlockers = HashMap::default();
        unlockers.insert(
            sighash_script_id,
            Box::new(sighash_unlocker) as Box<dyn ScriptUnlocker>,
        );

        let sender = self.context.funding_source_lock_script.clone();
        // Build CapacityBalancer
        let placeholder_witness = packed::WitnessArgs::new_builder()
            .lock(Some(molecule::bytes::Bytes::from(vec![0u8; 170])).pack())
            .build();

        let balancer = CapacityBalancer::new_simple(
            sender.clone(),
            placeholder_witness,
            self.request.funding_fee_rate,
        );

        let ckb_client = CkbRpcClient::new(&self.context.rpc_url);
        let cell_dep_resolver = ckb_client
            .get_block_by_number(0.into())
            .map_err(FundingError::CkbRpcError)?
            .and_then(|genesis_block| {
                DefaultCellDepResolver::from_genesis(&BlockView::from(genesis_block)).ok()
            })
            .ok_or_else(|| {
                FundingError::CkbTxBuilderError(TxBuilderError::ResolveCellDepFailed(sender))
            })?;

        let header_dep_resolver = DefaultHeaderDepResolver::new(&self.context.rpc_url);
        let mut cell_collector = DefaultCellCollector::new(&self.context.rpc_url);
        let tx_dep_provider = DefaultTransactionDependencyProvider::new(&self.context.rpc_url, 10);

        let (tx, _) = self.build_unlocked(
            &mut cell_collector,
            &cell_dep_resolver,
            &header_dep_resolver,
            &tx_dep_provider,
            &balancer,
            &unlockers,
        )?;

        let mut funding_tx = self.funding_tx;
        let tx_builder = tx.as_advanced_builder();
        debug!("final tx_builder: {:?}", tx_builder);
        funding_tx.update_for_self(tx)?;
        Ok(funding_tx)
    }
}

impl FundingTx {
    pub fn new() -> Self {
        Self::default()
    }

    pub fn take(&mut self) -> Option<TransactionView> {
        self.tx.take()
    }

    pub fn as_ref(&self) -> Option<&TransactionView> {
        self.tx.as_ref()
    }

    pub fn into_inner(self) -> Option<TransactionView> {
        self.tx
    }

    pub fn fulfill(
        self,
        request: FundingRequest,
        context: FundingContext,
    ) -> Result<Self, FundingError> {
        let builder = FundingTxBuilder {
            funding_tx: self,
            request,
            context,
        };
        builder.build()
    }

    pub fn sign(
        mut self,
        secret_key: secp256k1::SecretKey,
        rpc_url: String,
    ) -> Result<Self, FundingError> {
        // Convert between different versions of secp256k1.
        // This app requires 0.28 because of:
        // ```
        // #[derive(Copy, Clone, PartialOrd, Ord, PartialEq, Eq, Hash, Serialize, Deserialize, Debug)]
        // pub struct Signature(pub Secp256k1Signature);
        // ```
        //
        // However, ckb-sdk-rust still uses 0.24.
        //
        // It's complex to use map_err and return an error as well because secp256k1 used by ckb sdk is not public.
        // Expect is OK here since the secret key is valid and can be parsed in both versions.
        let signer = SecpCkbRawKeySigner::new_with_secret_keys(vec![std::str::FromStr::from_str(
            hex::encode(secret_key.as_ref()).as_ref(),
        )
        .expect("convert secret key between different secp256k1 versions")]);
        let sighash_unlocker = SecpSighashUnlocker::from(Box::new(signer) as Box<_>);
        let sighash_script_id = ScriptId::new_type(SIGHASH_TYPE_HASH.clone());
        let mut unlockers = HashMap::default();
        unlockers.insert(
            sighash_script_id,
            Box::new(sighash_unlocker) as Box<dyn ScriptUnlocker>,
        );
        let tx = self.take().ok_or(FundingError::AbsentTx)?;
        let tx_dep_provider = DefaultTransactionDependencyProvider::new(&rpc_url, 10);

        let (tx, _) = unlock_tx(tx, &tx_dep_provider, &unlockers)?;
        self.update_for_self(tx)?;
        Ok(self)
    }

    // TODO: verify the transaction
    pub fn update_for_self(&mut self, tx: TransactionView) -> Result<(), FundingError> {
        self.tx = Some(tx);
        Ok(())
    }

    // TODO: verify the transaction
    pub fn update_for_peer(&mut self, tx: TransactionView) -> Result<(), FundingError> {
        self.tx = Some(tx);
        Ok(())
    }
}


================================================
File: src/ckb/funding/mod.rs
================================================
mod funding_tx;

pub(crate) use funding_tx::FundingContext;
pub use funding_tx::{FundingRequest, FundingTx};


================================================
File: src/ckb/tests/actor.rs
================================================
use ckb_jsonrpc_types::Status;
use ckb_types::core::TransactionView;
use ckb_types::packed::{CellInput, CellOutput};
use ckb_types::prelude::{Builder, Pack};
use molecule::prelude::Entity;
use ractor::{Actor, ActorRef};

use super::test_utils::{submit_tx, MockChainActor};
use crate::ckb::actor::CkbChainMessage;
use crate::ckb::contracts::{get_cell_deps_by_contracts, get_script_by_contract, Contract};

pub async fn create_mock_chain_actor() -> ActorRef<CkbChainMessage> {
    Actor::spawn(None, MockChainActor::new(), ())
        .await
        .expect("start mock chain actor")
        .0
}

#[tokio::test]
async fn test_submit_empty_tx() {
    let actor = create_mock_chain_actor().await;
    assert_eq!(
        submit_tx(actor, TransactionView::new_advanced_builder().build()).await,
        Status::Committed
    );
}

#[tokio::test]
async fn test_submit_one_output_tx() {
    let actor = create_mock_chain_actor().await;
    assert_eq!(
        submit_tx(
            actor,
            TransactionView::new_advanced_builder()
                .output(CellOutput::default())
                .output_data(Default::default())
                .build()
        )
        .await,
        Status::Committed
    );
}

#[tokio::test]
async fn test_submit_mocked_secp256k1_tx() {
    let actor = create_mock_chain_actor().await;
    let capacity = 100u64;
    let output = CellOutput::new_builder()
        .capacity(capacity.pack())
        .lock(get_script_by_contract(
            Contract::Secp256k1Lock,
            &b"whatever1"[..],
        ))
        .build();
    let tx = TransactionView::new_advanced_builder()
        .output(output)
        .output_data(Default::default())
        .build();
    assert_eq!(
        submit_tx(actor.clone(), tx.clone()).await,
        Status::Committed
    );
    let out_point = tx.output_pts_iter().next().unwrap();
    let tx = TransactionView::new_advanced_builder()
        .cell_deps(get_cell_deps_by_contracts(vec![Contract::Secp256k1Lock]))
        .input(
            CellInput::new_builder()
                .previous_output(out_point.clone())
                .build(),
        )
        .output(
            CellOutput::new_builder()
                .capacity(capacity.pack())
                .lock(get_script_by_contract(
                    Contract::FundingLock,
                    &b"whatever2"[..],
                ))
                .build(),
        )
        .output_data(Default::default())
        .build();
    assert_eq!(submit_tx(actor, tx).await, Status::Committed);
}

#[tokio::test]
async fn test_repeatedly_consume_the_same_cell() {
    let actor = create_mock_chain_actor().await;
    let capacity = 100u64;
    let output = CellOutput::new_builder()
        .capacity(capacity.pack())
        .lock(get_script_by_contract(
            Contract::Secp256k1Lock,
            &b"whatever1"[..],
        ))
        .build();
    let tx = TransactionView::new_advanced_builder()
        .output(output)
        .output_data(Default::default())
        .build();
    assert_eq!(
        submit_tx(actor.clone(), tx.clone()).await,
        Status::Committed
    );
    let out_point = tx.output_pts_iter().next().unwrap();
    let tx = TransactionView::new_advanced_builder()
        .cell_deps(get_cell_deps_by_contracts(vec![Contract::Secp256k1Lock]))
        .input(
            CellInput::new_builder()
                .previous_output(out_point.clone())
                .build(),
        )
        .output(
            CellOutput::new_builder()
                .capacity(capacity.pack())
                .lock(get_script_by_contract(
                    Contract::FundingLock,
                    &b"whatever2"[..],
                ))
                .build(),
        )
        .output_data(Default::default())
        .build();
    assert_eq!(submit_tx(actor.clone(), tx).await, Status::Committed);
    let tx = TransactionView::new_advanced_builder()
        .cell_deps(get_cell_deps_by_contracts(vec![Contract::Secp256k1Lock]))
        .input(
            CellInput::new_builder()
                .previous_output(out_point.clone())
                .build(),
        )
        .output(
            CellOutput::new_builder()
                .capacity(capacity.pack())
                .lock(get_script_by_contract(
                    Contract::FundingLock,
                    &b"whatever3"[..],
                ))
                .build(),
        )
        .output_data(Default::default())
        .build();
    assert_eq!(submit_tx(actor, tx).await, Status::Rejected);
}

#[tokio::test]
async fn test_submit_malformed_commitment_tx() {
    let actor = create_mock_chain_actor().await;
    let capacity = 100u64;
    let output = CellOutput::new_builder()
        .capacity(capacity.pack())
        .lock(get_script_by_contract(
            Contract::FundingLock,
            &b"whatever1"[..],
        ))
        .build();
    let tx = TransactionView::new_advanced_builder()
        .output(output)
        .output_data(Default::default())
        .build();
    assert_eq!(
        submit_tx(actor.clone(), tx.clone()).await,
        Status::Committed
    );
    let out_point = tx.output_pts_iter().next().unwrap();
    let tx = TransactionView::new_advanced_builder()
        .cell_deps(get_cell_deps_by_contracts(vec![Contract::FundingLock]))
        .input(
            CellInput::new_builder()
                .previous_output(out_point.clone())
                .build(),
        )
        .output(
            CellOutput::new_builder()
                .capacity(capacity.pack())
                .lock(get_script_by_contract(
                    Contract::CommitmentLock,
                    &b"whatever2"[..],
                ))
                .build(),
        )
        .output_data(Default::default())
        .build();
    assert_eq!(submit_tx(actor, tx).await, Status::Rejected);
}


================================================
File: src/ckb/tests/config.rs
================================================
use crate::ckb::config::{UdtArgInfo, UdtCellDep, UdtCfgInfos, UdtScript};
use crate::fiber::gen::fiber::UdtCfgInfos as MoleculeUdtCfgInfos;
use ckb_types::core::{DepType, ScriptHashType};
use ckb_types::H256;
use molecule::prelude::Entity;

#[test]
fn test_udt_whitelist() {
    let udt_whitelist = UdtCfgInfos(vec![UdtArgInfo {
        name: "SimpleUDT".to_string(),
        script: UdtScript {
            code_hash: H256::from([0u8; 32]),
            hash_type: ScriptHashType::Data,
            args: "0x00".to_string(),
        },
        auto_accept_amount: Some(100),
        cell_deps: vec![UdtCellDep {
            dep_type: DepType::Code,
            tx_hash: H256::from([0u8; 32]),
            index: 0,
        }],
    }]);

    let serialized = MoleculeUdtCfgInfos::from(udt_whitelist.clone()).as_bytes();
    let deserialized =
        UdtCfgInfos::from(MoleculeUdtCfgInfos::from_slice(&serialized).expect("invalid mol"));
    assert_eq!(udt_whitelist, deserialized);
}


================================================
File: src/ckb/tests/mod.rs
================================================
pub mod actor;
mod config;

pub mod test_utils;


================================================
File: src/ckb/tests/test_utils.rs
================================================
use anyhow::anyhow;
use ckb_jsonrpc_types::TxStatus;
use ckb_testtool::context::Context;
use ckb_types::{
    bytes::Bytes,
    core::{DepType, TransactionView},
    packed::{CellDep, CellOutput, OutPoint, Script, Transaction},
    prelude::{Builder, Entity, IntoTransactionView, Pack, PackVec, Unpack},
    H256,
};
use once_cell::sync::{Lazy, OnceCell};
use std::{collections::HashMap, sync::Arc, sync::RwLock};
use tokio::sync::RwLock as TokioRwLock;

use crate::{
    ckb::{
        config::UdtCfgInfos,
        contracts::{Contract, ContractsContext, ContractsInfo},
        TraceTxRequest, TraceTxResponse,
    },
    now_timestamp_as_millis_u64,
};

use crate::ckb::CkbChainMessage;

use ckb_types::packed::Byte32;
use ractor::{
    call_t, concurrency::Duration, Actor, ActorProcessingErr, ActorRef, OutputPort, RpcReplyPort,
    SupervisionEvent,
};
use tracing::{debug, error};

pub const TRACE_TX_WAITING_FOR_NOTIFICATION_MS: u64 = 2 * 1000;
pub const TRACE_TX_TIMEOUT_MS: u64 = 3 * 1000;

type TxNotification = (
    Byte32,
    ckb_jsonrpc_types::TransactionView,
    ckb_jsonrpc_types::Status,
);

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum CellStatus {
    // This cell has been consumed. If any transaction
    // tries to consume the same cell, it should be rejected.
    Consumed,
}

pub static MOCK_CONTEXT: Lazy<RwLock<MockContext>> = Lazy::new(|| RwLock::new(MockContext::new()));

pub struct MockContext {
    pub context: Context,
    pub contracts_context: ContractsContext,
}

impl Default for MockContext {
    fn default() -> Self {
        Self::new()
    }
}

impl MockContext {
    pub fn new() -> Self {
        let binaries = [
            (
                Contract::CkbAuth,
                Bytes::from_static(include_bytes!("../../../tests/deploy/contracts/auth")),
            ),
            (
                Contract::FundingLock,
                Bytes::from_static(include_bytes!(
                    "../../../tests/deploy/contracts/funding-lock"
                )),
            ),
            (
                Contract::CommitmentLock,
                Bytes::from_static(include_bytes!(
                    "../../../tests/deploy/contracts/commitment-lock"
                )),
            ),
            // mock secp256k1 lock script
            (
                Contract::Secp256k1Lock,
                Bytes::from_static(include_bytes!(
                    "../../../tests/deploy/contracts/always_success"
                )),
            ),
            (
                Contract::SimpleUDT,
                Bytes::from_static(include_bytes!("../../../tests/deploy/contracts/simple_udt")),
            ),
        ];
        let mut context = Context::new_with_deterministic_rng();
        let mut contract_default_scripts: HashMap<Contract, Script> = HashMap::new();
        let mut script_cell_deps: HashMap<Contract, Vec<CellDep>> = HashMap::new();

        for (contract, binary) in binaries.into_iter() {
            let out_point = context.deploy_cell(binary);
            let script = context
                .build_script(&out_point, Default::default())
                .expect("valid script");
            contract_default_scripts.insert(contract, script);
            let cell_dep = CellDep::new_builder()
                .out_point(out_point)
                .dep_type(DepType::Code.into())
                .build();

            let cell_deps = if matches!(contract, Contract::FundingLock)
                || matches!(contract, Contract::CommitmentLock)
            {
                // FundingLock and CommitmentLock depend on CkbAuth
                vec![
                    cell_dep,
                    script_cell_deps
                        .get(&Contract::CkbAuth)
                        .unwrap()
                        .clone()
                        .first()
                        .unwrap()
                        .clone(),
                ]
            } else {
                vec![cell_dep]
            };
            script_cell_deps.insert(contract, cell_deps);
        }

        let contracts = ContractsInfo {
            contract_default_scripts,
            script_cell_deps,
            udt_whitelist: UdtCfgInfos::default(),
        };
        let contracts_context = ContractsContext { contracts };
        MockContext {
            context,
            contracts_context,
        }
    }
}

enum TraceTxResult {
    Found(TxNotification),
    Timeout(),
}

// A simple actor to wait for the tx notifications from mock chain actor,
// Sometimes we are sending SendTx to the mock chain actor after a TraceTx request.
// In this case, we don't want to prematurely tell the caller that the transaction
// does not exists. So we use this actor to wait for the tx notifications from the
// mock chain actor.
struct TraceTxReplier {
    tx_hash: Byte32,
}

impl TraceTxReplier {
    pub fn new(tx_hash: Byte32) -> Self {
        Self { tx_hash }
    }
}

#[ractor::async_trait]
impl Actor for TraceTxReplier {
    type Msg = TraceTxResult;
    type Arguments = (
        Arc<OutputPort<TxNotification>>,
        Duration,
        RpcReplyPort<TraceTxResponse>,
    );
    type State = Option<RpcReplyPort<TraceTxResponse>>;

    async fn pre_start(
        &self,
        myself: ActorRef<Self::Msg>,
        (notifier, timeout, reply_port): Self::Arguments,
    ) -> Result<Self::State, ActorProcessingErr> {
        myself.send_after(timeout, TraceTxResult::Timeout);
        let hash = self.tx_hash.clone();
        notifier.subscribe(myself, move |notification| {
            if notification.0 == hash {
                Some(TraceTxResult::Found(notification))
            } else {
                None
            }
        });
        Ok(Some(reply_port))
    }

    async fn handle(
        &self,
        myself: ActorRef<Self::Msg>,
        message: Self::Msg,
        reply_port: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        let (tx, status) = match message {
            TraceTxResult::Found((_hash, tx, status)) => (Some(tx), status),
            TraceTxResult::Timeout() => {
                debug!("Timeout waiting for tx notification: {:?}", self.tx_hash);
                (None, ckb_jsonrpc_types::Status::Unknown)
            }
        };

        reply_trace_tx(
            tx,
            status,
            reply_port
                .take()
                .expect("state is initialized, and handle function will only be called once"),
        );

        myself.stop(Some("handled trace tx result".to_string()));
        Ok(())
    }
}

fn reply_trace_tx(
    tx: Option<ckb_jsonrpc_types::TransactionView>,
    status: ckb_jsonrpc_types::Status,
    reply_port: RpcReplyPort<TraceTxResponse>,
) {
    let block_hash = tx.as_ref().map(|tx| tx.hash.clone());
    let status = TxStatus {
        status,
        // Some tests may require the block hash and block number to be set.
        block_number: Some(Default::default()),
        block_hash: block_hash.clone(),
        tx_index: None,
        reason: None,
    };
    let response = TraceTxResponse { tx, status };

    if let Err(e) = reply_port.send(response) {
        error!(
            "Sending trace tx result of {:?} failed: {:?}",
            block_hash, e
        );
    };
}

pub struct MockChainActorState {
    tx_status: HashMap<
        Byte32,
        (
            ckb_jsonrpc_types::TransactionView,
            ckb_jsonrpc_types::Status,
        ),
    >,
    tx_notifications: Arc<OutputPort<TxNotification>>,
    cell_status: HashMap<OutPoint, CellStatus>,
}

impl Default for MockChainActorState {
    fn default() -> Self {
        Self::new()
    }
}

impl MockChainActorState {
    pub fn new() -> Self {
        Self {
            tx_status: HashMap::new(),
            tx_notifications: Arc::new(OutputPort::default()),
            cell_status: HashMap::new(),
        }
    }
}

pub struct MockChainActor {}

impl Default for MockChainActor {
    fn default() -> Self {
        Self::new()
    }
}

impl MockChainActor {
    pub fn new() -> Self {
        Self {}
    }

    pub async fn start_trace_tx_replier(
        &self,
        myself: ActorRef<CkbChainMessage>,
        tx_hash: Byte32,
        notifier: Arc<OutputPort<TxNotification>>,
        timeout: Duration,
        reply_port: RpcReplyPort<TraceTxResponse>,
    ) {
        let _ = Actor::spawn_linked(
            None,
            TraceTxReplier::new(tx_hash),
            (notifier, timeout, reply_port),
            myself.get_cell(),
        )
        .await
        .expect("start trace tx replier");
    }
}

#[ractor::async_trait]
impl Actor for MockChainActor {
    type Msg = CkbChainMessage;
    type State = MockChainActorState;
    type Arguments = ();

    async fn pre_start(
        &self,
        _: ActorRef<Self::Msg>,
        _: Self::Arguments,
    ) -> Result<Self::State, ActorProcessingErr> {
        Ok(Self::State::new())
    }

    async fn handle(
        &self,
        myself: ActorRef<Self::Msg>,
        message: Self::Msg,
        state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        use CkbChainMessage::*;
        match message {
            Fund(tx, request, reply_port) => {
                let mut fulfilled_tx = tx.clone();
                let outputs = fulfilled_tx
                    .as_ref()
                    .map(|x| x.outputs())
                    .unwrap_or_default();
                let outputs = match outputs.get(0) {
                    Some(output) => {
                        if output.lock() != request.script {
                            error!(
                                    "funding request script ({:?}) does not match the first output lock script ({:?})", request.script, output.lock()
                                );
                            return Ok(());
                        }
                        let current_capacity: u64 = output.capacity().unpack();
                        let capacity = request.local_amount as u64
                            + request.local_reserved_ckb_amount
                            + current_capacity;
                        let mut outputs_builder = outputs.as_builder();

                        outputs_builder
                            .replace(0, output.as_builder().capacity(capacity.pack()).build());
                        outputs_builder.build()
                    }
                    None => [CellOutput::new_builder()
                        .capacity(
                            (request.local_amount as u64 + request.local_reserved_ckb_amount)
                                .pack(),
                        )
                        .lock(request.script.clone())
                        .build()]
                    .pack(),
                };

                let outputs_data = fulfilled_tx
                    .as_ref()
                    .map(|x| x.outputs_data())
                    .unwrap_or_default();
                let outputs_data = if outputs_data.is_empty() {
                    [Default::default()].pack()
                } else {
                    outputs_data
                };

                let tx_builder = fulfilled_tx
                    .take()
                    .map(|x| x.as_advanced_builder())
                    .unwrap_or_default();

                fulfilled_tx
                    .update_for_self(
                        tx_builder
                            .set_outputs(outputs.into_iter().collect())
                            .set_outputs_data(outputs_data.into_iter().collect())
                            .build(),
                    )
                    .expect("update tx");

                debug!(
                    "Fulfilling funding request: request: {:?}, original tx: {:?}, fulfilled tx: {:?}",
                    request, &tx, &fulfilled_tx
                );

                if let Err(e) = reply_port.send(Ok(fulfilled_tx)) {
                    error!(
                        "[{}] send reply failed: {:?}",
                        myself.get_name().unwrap_or_default(),
                        e
                    );
                }
            }
            Sign(tx, reply_port) => {
                // We don't need to sign the funding transaction in mock chain actor,
                // as any funding transaction is considered correct if we can successfully
                // run the scripts of transaction inputs, and we don't have inputs in the
                // funding transaction.
                let signed_tx = tx.clone();
                debug!(
                    "Signing transaction: original tx: {:?}, signed tx: {:?}",
                    &tx, &signed_tx
                );
                if let Err(e) = reply_port.send(Ok(signed_tx)) {
                    error!(
                        "[{}] send reply failed: {:?}",
                        myself.get_name().unwrap_or_default(),
                        e
                    );
                }
            }
            SendTx(tx, reply_port) => {
                const MAX_CYCLES: u64 = 100_000_000;
                let mut f = || {
                    // Mark the inputs as consumed
                    for input in tx.input_pts_iter() {
                        match state.cell_status.entry(input.clone()) {
                            std::collections::hash_map::Entry::Occupied(mut entry) => {
                                if *entry.get() == CellStatus::Consumed {
                                    return (
                                        ckb_jsonrpc_types::Status::Rejected,
                                        Err(ckb_sdk::RpcError::Other(anyhow!(
                                            "Cell {:?} already consumed",
                                            &input
                                        ))),
                                    );
                                }
                                *entry.get_mut() = CellStatus::Consumed;
                            }
                            std::collections::hash_map::Entry::Vacant(entry) => {
                                debug!("Consuming cell {:?}", &input);
                                entry.insert(CellStatus::Consumed);
                            }
                        }
                    }
                    let context = &mut MOCK_CONTEXT.write().unwrap().context;
                    match context.verify_tx(&tx, MAX_CYCLES) {
                        Ok(c) => {
                            debug!("Verified transaction: {:?} with {} CPU cycles", tx, c);
                            // Also save the outputs to the context, so that we can refer to
                            // these out points later.
                            for outpoint in tx.output_pts().into_iter() {
                                let index: u32 = outpoint.index().unpack();
                                let index = index as usize;
                                let cell = tx.outputs().get(index).unwrap();
                                let data = tx.outputs_data().get(index).unwrap();
                                context.create_cell_with_out_point(
                                    outpoint.clone(),
                                    cell,
                                    data.as_bytes(),
                                );
                            }
                            (ckb_jsonrpc_types::Status::Committed, Ok(()))
                        }
                        Err(e) => (
                            ckb_jsonrpc_types::Status::Rejected,
                            Err(ckb_sdk::RpcError::Other(anyhow!(
                                "Failed to verify transaction: {:?}, error: {:?}",
                                tx,
                                e
                            ))),
                        ),
                    }
                };
                let (status, result) = f();
                debug!(
                    "Transaction verfication result: tx {:?}, status: {:?}",
                    &tx, &status
                );
                state
                    .tx_notifications
                    .send((tx.hash(), tx.clone().into(), status.clone()));
                state.tx_status.insert(tx.hash(), (tx.into(), status));
                if let Err(e) = reply_port.send(result) {
                    error!(
                        "[{}] send reply failed: {:?}",
                        myself.get_name().unwrap_or_default(),
                        e
                    );
                }
            }
            TraceTx(tx, reply_port) => {
                debug!("Tracing transaction: {:?}", &tx);
                match state.tx_status.get(&tx.tx_hash).cloned() {
                    Some((tx_view, status)) => {
                        reply_trace_tx(Some(tx_view), status, reply_port);
                    }
                    // The transaction is not found in the tx_status, we need to wait for the
                    // tx notification from the mock chain actor.
                    None => {
                        self.start_trace_tx_replier(
                            myself,
                            tx.tx_hash,
                            state.tx_notifications.clone(),
                            Duration::from_millis(TRACE_TX_WAITING_FOR_NOTIFICATION_MS),
                            reply_port,
                        )
                        .await;
                    }
                };
            }
            GetBlockTimestamp(request, rpc_reply_port) => {
                // The problem of channel announcement is that each nodes will query the block timestamp
                // and use it as the channel announcement timestamp.
                // Guaranteeing the block timestamp is the same across all nodes is important
                // because if a node A has a greater channel announcement timestamp than node B, then when
                // A tries to get broadcast messages after this channel announcement timestamp, B will return
                // the channel announcement. But for A, it is not a later broadcast message. This process will
                // cause an infinite loop.
                // So here we create an static lock which is shared across all nodes, and we use this lock to
                // guarantee that the block timestamp is the same across all nodes.
                static BLOCK_TIMESTAMP: OnceCell<TokioRwLock<HashMap<H256, u64>>> = OnceCell::new();
                BLOCK_TIMESTAMP.get_or_init(|| TokioRwLock::new(HashMap::new()));
                let timestamp = *BLOCK_TIMESTAMP
                    .get()
                    .unwrap()
                    .write()
                    .await
                    .entry(request.block_hash())
                    .or_insert(now_timestamp_as_millis_u64());

                let _ = rpc_reply_port.send(Ok(Some(timestamp)));
            }
        }
        Ok(())
    }

    async fn handle_supervisor_evt(
        &self,
        _myself: ActorRef<Self::Msg>,
        _message: SupervisionEvent,
        _state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        Ok(())
    }
}

pub async fn submit_tx(
    mock_actor: ActorRef<CkbChainMessage>,
    tx: TransactionView,
) -> ckb_jsonrpc_types::Status {
    pub const TIMEOUT: u64 = 1000;
    debug!("Calling chain actor to submit tx: {:?}", &tx);
    if let Err(error) = call_t!(mock_actor, CkbChainMessage::SendTx, TIMEOUT, tx.clone())
        .expect("chain actor alive")
    {
        error!("submit tx failed: {:?}", error);
        return ckb_jsonrpc_types::Status::Rejected;
    }
    trace_tx(mock_actor, tx).await
}

pub async fn trace_tx(
    mock_actor: ActorRef<CkbChainMessage>,
    tx: TransactionView,
) -> ckb_jsonrpc_types::Status {
    trace_tx_hash(mock_actor, tx.hash()).await
}

pub async fn trace_tx_hash(
    mock_actor: ActorRef<CkbChainMessage>,
    tx_hash: Byte32,
) -> ckb_jsonrpc_types::Status {
    let request = TraceTxRequest {
        tx_hash,
        confirmations: 1,
    };
    call_t!(
        mock_actor,
        CkbChainMessage::TraceTx,
        TRACE_TX_TIMEOUT_MS,
        request
    )
    .expect("chain actor alive")
    .status
    .status
}

pub async fn get_tx_from_hash(
    mock_actor: ActorRef<CkbChainMessage>,
    tx_hash: Byte32,
) -> Result<TransactionView, anyhow::Error> {
    pub const TIMEOUT: u64 = 1000;
    let request = TraceTxRequest {
        tx_hash,
        confirmations: 1,
    };
    call_t!(
        mock_actor,
        CkbChainMessage::TraceTx,
        TIMEOUT,
        request.clone()
    )?
    .tx
    .map(|tx| Transaction::from(tx.inner).into_view())
    .ok_or(anyhow!("tx not found in trace tx response"))
}


================================================
File: src/fiber/channel.rs
================================================
use crate::debug_event;
#[cfg(debug_assertions)]
use crate::fiber::network::DebugEvent;
use crate::fiber::types::BroadcastMessageWithTimestamp;
use bitflags::bitflags;
use futures::future::OptionFuture;
use secp256k1::XOnlyPublicKey;
use tracing::{debug, error, info, trace, warn};

use crate::{
    ckb::{
        contracts::{get_cell_deps, get_script_by_contract, Contract},
        FundingRequest,
    },
    fiber::{
        config::{DEFAULT_MIN_SHUTDOWN_FEE, MAX_PAYMENT_TLC_EXPIRY_LIMIT, MIN_TLC_EXPIRY_DELTA},
        fee::{
            calculate_commitment_tx_fee, calculate_shutdown_tx_fee, calculate_tlc_forward_fee,
            shutdown_tx_size,
        },
        hash_algorithm::HashAlgorithm,
        key::blake2b_hash_with_salt,
        network::{
            get_chain_hash, sign_network_message, FiberMessageWithPeerId, SendOnionPacketCommand,
        },
        serde_utils::{CompactSignatureAsBytes, EntityHex, PubNonceAsBytes},
        types::{
            AcceptChannel, AddTlc, AnnouncementSignatures, BroadcastMessageQuery,
            BroadcastMessageQueryFlags, ChannelAnnouncement, ChannelReady, ChannelUpdate,
            ClosingSigned, CommitmentSigned, EcdsaSignature, FiberChannelMessage, FiberMessage,
            Hash256, OpenChannel, PaymentOnionPacket, PeeledPaymentOnionPacket, Privkey, Pubkey,
            ReestablishChannel, RemoveTlc, RemoveTlcFulfill, RemoveTlcReason, RevokeAndAck,
            Shutdown, TlcErr, TlcErrPacket, TlcErrorCode, TxCollaborationMsg, TxComplete, TxUpdate,
            NO_SHARED_SECRET,
        },
        NetworkActorCommand, NetworkActorEvent, NetworkActorMessage, ASSUME_NETWORK_ACTOR_ALIVE,
    },
    invoice::{CkbInvoice, CkbInvoiceStatus, InvoiceStore},
    now_timestamp_as_millis_u64, NetworkServiceEvent,
};
use ckb_hash::{blake2b_256, new_blake2b};
use ckb_sdk::{Since, SinceType};
use ckb_types::{
    core::{
        Capacity, CapacityError, EpochNumberWithFraction, FeeRate, TransactionBuilder,
        TransactionView,
    },
    packed::{Bytes, CellInput, CellOutput, OutPoint, Script, Transaction},
    prelude::{AsTransactionBuilder, IntoTransactionView, Pack, Unpack},
    H256,
};
use molecule::prelude::{Builder, Entity};
use musig2::{
    aggregate_partial_signatures,
    errors::{RoundFinalizeError, SigningError, VerifyError},
    secp::Point,
    sign_partial, verify_partial, AggNonce, CompactSignature, KeyAggContext, PartialSignature,
    PubNonce, SecNonce,
};
use ractor::{
    async_trait as rasync_trait, call, concurrency::Duration, Actor, ActorProcessingErr, ActorRef,
    OutputPort, RpcReplyPort,
};
use serde::{Deserialize, Serialize};
use serde_with::serde_as;
use tentacle::secio::PeerId;
use thiserror::Error;
use tokio::sync::oneshot;

use super::{graph::ChannelUpdateInfo, types::ForwardTlcResult};
use std::{
    collections::HashSet,
    fmt::{self, Debug, Display},
    sync::Arc,
    time::{SystemTime, UNIX_EPOCH},
};

use super::types::{ChannelUpdateChannelFlags, ChannelUpdateMessageFlags, UpdateTlcInfo};

// - `empty_witness_args`: 16 bytes, fixed to 0x10000000100000001000000010000000, for compatibility with the xudt
// - `pubkey`: 32 bytes, x only aggregated public key
// - `signature`: 64 bytes, aggregated signature
pub const FUNDING_CELL_WITNESS_LEN: usize = 16 + 32 + 64;

// - `empty_witness_args`: 16 bytes, fixed to 0x10000000100000001000000010000000, for compatibility with the xudt
// - `unlock_type`: 1 byte
// - `pubkey`: 32 bytes, x only aggregated public key
// - `signature`: 64 bytes, aggregated signature
pub const COMMITMENT_CELL_WITNESS_LEN: usize = 16 + 1 + 32 + 64;

// Some part of the code liberally gets previous commitment number, which is
// the current commitment number minus 1. We deliberately set initial commitment number to 1,
// so that we can get previous commitment point/number without checking if the channel
// is funded or not.
pub const INITIAL_COMMITMENT_NUMBER: u64 = 0;

const RETRYABLE_TLC_OPS_INTERVAL: Duration = Duration::from_millis(1000);

#[derive(Debug)]
pub enum ChannelActorMessage {
    /// Command are the messages that are sent to the channel actor to perform some action.
    /// It is normally generated from a user request.
    Command(ChannelCommand),
    /// Some system events associated to a channel, such as the funding transaction confirmed.
    Event(ChannelEvent),
    /// PeerMessage are the messages sent from the peer.
    PeerMessage(FiberChannelMessage),
}

#[derive(Debug, Serialize, Deserialize)]
pub struct AddTlcResponse {
    pub tlc_id: u64,
}

#[derive(Clone)]
pub struct TlcNotifyInfo {
    pub payment_hash: Hash256,
    pub tlc_id: TLCId,
    pub amount: u128,
    pub payment_preimage: Option<Hash256>,
}

#[derive(Clone)]
pub struct TlcNotification {
    pub channel_id: Hash256,
    pub tlc: TlcNotifyInfo,
    pub script: Script,
}

#[derive(Debug)]
pub enum ChannelCommand {
    TxCollaborationCommand(TxCollaborationCommand),
    CommitmentSigned(),
    AddTlc(AddTlcCommand, RpcReplyPort<Result<AddTlcResponse, TlcErr>>),
    RemoveTlc(
        RemoveTlcCommand,
        RpcReplyPort<Result<(), ProcessingChannelError>>,
    ),
    Shutdown(ShutdownCommand, RpcReplyPort<Result<(), String>>),
    Update(UpdateCommand, RpcReplyPort<Result<(), String>>),
    ForwardTlcResult(ForwardTlcResult),
    #[cfg(test)]
    ReloadState(ReloadParams),
}

impl Display for ChannelCommand {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            ChannelCommand::TxCollaborationCommand(_) => write!(f, "TxCollaborationCommand"),
            ChannelCommand::CommitmentSigned() => write!(f, "CommitmentSigned"),
            ChannelCommand::AddTlc(_, _) => write!(f, "AddTlc"),
            ChannelCommand::RemoveTlc(_, _) => write!(f, "RemoveTlc"),
            ChannelCommand::Shutdown(_, _) => write!(f, "Shutdown"),
            ChannelCommand::Update(_, _) => write!(f, "Update"),
            ChannelCommand::ForwardTlcResult(_) => write!(f, "ForwardTlcResult"),
            #[cfg(test)]
            ChannelCommand::ReloadState(_) => write!(f, "ReloadState"),
        }
    }
}

#[cfg(test)]
#[derive(Debug)]
pub struct ReloadParams {
    pub notify_changes: bool,
}

#[cfg(test)]
impl Default for ReloadParams {
    fn default() -> Self {
        Self {
            notify_changes: true,
        }
    }
}

#[derive(Debug)]
pub enum TxCollaborationCommand {
    TxUpdate(TxUpdateCommand),
    TxComplete(),
}

#[derive(Debug, Clone)]
pub struct AddTlcCommand {
    pub amount: u128,
    pub payment_hash: Hash256,
    pub expiry: u64,
    pub hash_algorithm: HashAlgorithm,
    /// Onion packet for the next node
    pub onion_packet: Option<PaymentOnionPacket>,
    /// Shared secret used in forwarding.
    ///
    /// Save it for outbound (offered) TLC to backward errors.
    /// Use all zeros when no shared secrets are available.
    pub shared_secret: [u8; 32],
    pub previous_tlc: Option<PrevTlcInfo>,
}

#[derive(Debug, Clone)]
pub struct RemoveTlcCommand {
    pub id: u64,
    pub reason: RemoveTlcReason,
}

#[derive(Debug)]
pub struct ShutdownCommand {
    pub close_script: Script,
    pub fee_rate: FeeRate,
    pub force: bool,
}

#[derive(Debug)]
pub struct UpdateCommand {
    pub enabled: Option<bool>,
    pub tlc_expiry_delta: Option<u64>,
    pub tlc_minimum_value: Option<u128>,
    pub tlc_fee_proportional_millionths: Option<u128>,
}

#[derive(Debug)]
pub struct ChannelCommandWithId {
    pub channel_id: Hash256,
    pub command: ChannelCommand,
}

pub const DEFAULT_FEE_RATE: u64 = 1_000;
pub const DEFAULT_COMMITMENT_FEE_RATE: u64 = 1_000;
// The default commitment delay is 6 epochs = 24 hours.
pub const DEFAULT_COMMITMENT_DELAY_EPOCHS: u64 = 6;
// The min commitment delay is 1 epoch = 4 hours.
pub const MIN_COMMITMENT_DELAY_EPOCHS: u64 = 1;
// The max commitment delay is 84 epochs = 14 days.
pub const MAX_COMMITMENT_DELAY_EPOCHS: u64 = 84;
pub const DEFAULT_MAX_TLC_VALUE_IN_FLIGHT: u128 = u128::MAX;
pub const DEFAULT_MIN_TLC_VALUE: u128 = 0;
pub const SYS_MAX_TLC_NUMBER_IN_FLIGHT: u64 = 253;
pub const MAX_TLC_NUMBER_IN_FLIGHT: u64 = 125;

#[derive(Debug)]
pub struct TxUpdateCommand {
    pub transaction: Transaction,
}

pub struct OpenChannelParameter {
    pub funding_amount: u128,
    pub seed: [u8; 32],
    pub tlc_info: ChannelTlcInfo,
    pub public_channel_info: Option<PublicChannelInfo>,
    pub funding_udt_type_script: Option<Script>,
    pub shutdown_script: Script,
    pub channel_id_sender: oneshot::Sender<Hash256>,
    pub commitment_fee_rate: Option<u64>,
    pub commitment_delay_epoch: Option<EpochNumberWithFraction>,
    pub funding_fee_rate: Option<u64>,
    pub max_tlc_value_in_flight: u128,
    pub max_tlc_number_in_flight: u64,
}

pub struct AcceptChannelParameter {
    pub funding_amount: u128,
    pub reserved_ckb_amount: u64,
    pub tlc_info: ChannelTlcInfo,
    pub public_channel_info: Option<PublicChannelInfo>,
    pub seed: [u8; 32],
    pub open_channel: OpenChannel,
    pub shutdown_script: Script,
    pub channel_id_sender: Option<oneshot::Sender<Hash256>>,
    pub max_tlc_value_in_flight: u128,
    pub max_tlc_number_in_flight: u64,
}

pub enum ChannelInitializationParameter {
    /// To open a new channel to another peer, the funding amount,
    /// the temporary channel id a unique channel seed to generate
    /// channel secrets must be given.
    OpenChannel(OpenChannelParameter),
    /// To accept a new channel from another peer, the funding amount,
    /// a unique channel seed to generate unique channel id,
    /// original OpenChannel message and an oneshot
    /// channel to receive the new channel ID must be given.
    AcceptChannel(AcceptChannelParameter),
    /// Reestablish a channel with given channel id.
    ReestablishChannel(Hash256),
}

#[derive(Clone)]
pub struct ChannelSubscribers {
    pub pending_received_tlcs_subscribers: Arc<OutputPort<TlcNotification>>,
    pub settled_tlcs_subscribers: Arc<OutputPort<TlcNotification>>,
}

impl Default for ChannelSubscribers {
    fn default() -> Self {
        Self {
            pending_received_tlcs_subscribers: Arc::new(OutputPort::default()),
            settled_tlcs_subscribers: Arc::new(OutputPort::default()),
        }
    }
}

pub struct ChannelActor<S> {
    local_pubkey: Pubkey,
    remote_pubkey: Pubkey,
    network: ActorRef<NetworkActorMessage>,
    store: S,
    subscribers: ChannelSubscribers,
}

impl<S> ChannelActor<S>
where
    S: InvoiceStore + ChannelActorStateStore,
{
    pub fn new(
        local_pubkey: Pubkey,
        remote_pubkey: Pubkey,
        network: ActorRef<NetworkActorMessage>,
        store: S,
        subscribers: ChannelSubscribers,
    ) -> Self {
        Self {
            local_pubkey,
            remote_pubkey,
            network,
            store,
            subscribers,
        }
    }

    pub fn get_local_pubkey(&self) -> Pubkey {
        self.local_pubkey
    }

    pub fn get_remote_pubkey(&self) -> Pubkey {
        self.remote_pubkey
    }

    pub fn get_remote_peer_id(&self) -> PeerId {
        self.remote_pubkey.tentacle_peer_id()
    }

    pub async fn handle_peer_message(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
        message: FiberChannelMessage,
    ) -> Result<(), ProcessingChannelError> {
        if state.reestablishing {
            match message {
                FiberChannelMessage::ReestablishChannel(ref reestablish_channel) => {
                    state
                        .handle_reestablish_channel_message(reestablish_channel, &self.network)
                        .await?;
                }
                _ => {
                    debug!("Ignoring message while reestablishing: {:?}", message);
                }
            }
            return Ok(());
        }

        match message {
            FiberChannelMessage::AnnouncementSignatures(announcement_signatures) => {
                if !state.is_public() {
                    return Err(ProcessingChannelError::InvalidState(
                        "Received AnnouncementSignatures message, but the channel is not public"
                            .to_string(),
                    ));
                }
                match state.state {
                    ChannelState::ChannelReady() => {}
                    ChannelState::AwaitingChannelReady(flags)
                        if flags.contains(AwaitingChannelReadyFlags::CHANNEL_READY) => {}
                    _ => {
                        return Err(ProcessingChannelError::InvalidState(format!(
                                "Received unexpected AnnouncementSignatures message in state {:?}, expecting state AwaitingChannelReady::CHANNEL_READY or ChannelReady",
                                state.state
                            )));
                    }
                }

                // TODO: check announcement_signatures validity here.
                let AnnouncementSignatures {
                    node_signature,
                    partial_signature,
                    ..
                } = announcement_signatures;
                state.update_remote_channel_announcement_signature(
                    node_signature,
                    partial_signature,
                );
                state.maybe_public_channel_is_ready(&self.network).await;
                Ok(())
            }
            FiberChannelMessage::AcceptChannel(accept_channel) => {
                state.handle_accept_channel_message(accept_channel)?;
                let old_id = state.get_id();
                state.fill_in_channel_id();
                self.network
                    .send_message(NetworkActorMessage::new_event(
                        NetworkActorEvent::ChannelAccepted(
                            state.get_remote_peer_id(),
                            state.get_id(),
                            old_id,
                            state.to_local_amount,
                            state.to_remote_amount,
                            state.get_funding_lock_script(),
                            state.funding_udt_type_script.clone(),
                            state.local_reserved_ckb_amount,
                            state.remote_reserved_ckb_amount,
                            state.funding_fee_rate,
                        ),
                    ))
                    .expect(ASSUME_NETWORK_ACTOR_ALIVE);
                Ok(())
            }
            FiberChannelMessage::TxUpdate(tx) => {
                state.handle_tx_collaboration_msg(TxCollaborationMsg::TxUpdate(tx), &self.network)
            }
            FiberChannelMessage::TxComplete(tx) => {
                state.handle_tx_collaboration_msg(
                    TxCollaborationMsg::TxComplete(tx),
                    &self.network,
                )?;
                if let ChannelState::CollaboratingFundingTx(flags) = state.state {
                    if flags.contains(CollaboratingFundingTxFlags::COLLABRATION_COMPLETED) {
                        self.handle_commitment_signed_command(state)?;
                    }
                }
                Ok(())
            }
            FiberChannelMessage::CommitmentSigned(commitment_signed) => {
                self.handle_commitment_signed_peer_message(myself, state, commitment_signed)
                    .await
            }
            FiberChannelMessage::TxSignatures(tx_signatures) => {
                // We're the one who sent tx_signature first, and we received a tx_signature message.
                // This means that the tx_signature procedure is now completed. Just change state,
                // and exit.
                if state.should_local_send_tx_signatures_first() {
                    let new_witnesses: Vec<_> = tx_signatures
                        .witnesses
                        .into_iter()
                        .map(|x| x.pack())
                        .collect();
                    debug!(
                        "Updating funding tx witnesses of {:?} to {:?}",
                        state.must_get_funding_transaction().calc_tx_hash(),
                        new_witnesses.iter().map(|x| hex::encode(x.as_slice()))
                    );
                    state.funding_tx = Some(
                        state
                            .must_get_funding_transaction()
                            .as_advanced_builder()
                            .set_witnesses(new_witnesses)
                            .build()
                            .data(),
                    );
                    self.network
                        .send_message(NetworkActorMessage::new_event(
                            NetworkActorEvent::FundingTransactionPending(
                                state.must_get_funding_transaction().clone(),
                                state.must_get_funding_transaction_outpoint(),
                                state.get_id(),
                            ),
                        ))
                        .expect(ASSUME_NETWORK_ACTOR_ALIVE);

                    state.update_state(ChannelState::AwaitingChannelReady(
                        AwaitingChannelReadyFlags::empty(),
                    ));
                    return Ok(());
                };

                state.handle_tx_signatures(&self.network, Some(tx_signatures.witnesses))?;
                Ok(())
            }
            FiberChannelMessage::RevokeAndAck(revoke_and_ack) => {
                let need_commitment_signed =
                    state.handle_revoke_and_ack_peer_message(&self.network, revoke_and_ack)?;
                self.update_tlc_status_on_ack(myself, state).await;
                if need_commitment_signed {
                    self.handle_commitment_signed_command(state)?;
                }
                Ok(())
            }
            FiberChannelMessage::ChannelReady(_channel_ready) => {
                let flags = match state.state {
                    ChannelState::AwaitingTxSignatures(flags) => {
                        if flags.contains(AwaitingTxSignaturesFlags::TX_SIGNATURES_SENT) {
                            AwaitingChannelReadyFlags::empty()
                        } else {
                            return Err(ProcessingChannelError::InvalidState(format!(
                                "received ChannelReady message, but we're not ready for ChannelReady, state is currently {:?}",
                                state.state
                            )));
                        }
                    }
                    ChannelState::AwaitingChannelReady(flags) => flags,
                    _ => {
                        return Err(ProcessingChannelError::InvalidState(format!(
                            "received ChannelReady message, but we're not ready for ChannelReady, state is currently {:?}", state.state
                        )));
                    }
                };
                let flags = flags | AwaitingChannelReadyFlags::THEIR_CHANNEL_READY;
                state.update_state(ChannelState::AwaitingChannelReady(flags));
                state.maybe_channel_is_ready(&self.network).await;
                Ok(())
            }
            FiberChannelMessage::UpdateTlcInfo(update_tlc_info) => {
                state.remote_tlc_info = Some(update_tlc_info.into());
                state.update_graph_for_remote_channel_change(&self.network);
                Ok(())
            }
            FiberChannelMessage::AddTlc(add_tlc) => {
                self.handle_add_tlc_peer_message(state, add_tlc)
            }
            FiberChannelMessage::RemoveTlc(remove_tlc) => {
                self.handle_remove_tlc_peer_message(state, remove_tlc)
            }
            FiberChannelMessage::Shutdown(shutdown) => {
                let flags = match state.state {
                    ChannelState::ChannelReady() => ShuttingDownFlags::empty(),
                    ChannelState::ShuttingDown(flags)
                        if flags.contains(ShuttingDownFlags::THEIR_SHUTDOWN_SENT) =>
                    {
                        return Err(ProcessingChannelError::InvalidParameter(
                            "Received Shutdown message, but we're already in ShuttingDown state"
                                .to_string(),
                        ));
                    }
                    ChannelState::ShuttingDown(flags) => flags,
                    _ => {
                        return Err(ProcessingChannelError::InvalidState(format!(
                            "received Shutdown message, but we're not ready for Shutdown, state is currently {:?}",
                            state.state
                        )));
                    }
                };
                let shutdown_info = ShutdownInfo {
                    close_script: shutdown.close_script,
                    fee_rate: shutdown.fee_rate.as_u64(),
                    signature: None,
                };
                state.remote_shutdown_info = Some(shutdown_info);

                let mut flags = flags | ShuttingDownFlags::THEIR_SHUTDOWN_SENT;

                // Only automatically reply shutdown if only their shutdown message is sent.
                // If we are in a state other than only their shutdown is sent,
                // e.g. our shutdown message is also sent, or we are trying to force shutdown,
                // we should not reply.
                let should_we_reply_shutdown =
                    matches!(flags, ShuttingDownFlags::THEIR_SHUTDOWN_SENT);

                if state.check_valid_to_auto_accept_shutdown() && should_we_reply_shutdown {
                    let close_script = state.get_local_shutdown_script();
                    self.network
                        .send_message(NetworkActorMessage::new_command(
                            NetworkActorCommand::SendFiberMessage(FiberMessageWithPeerId::new(
                                state.get_remote_peer_id(),
                                FiberMessage::shutdown(Shutdown {
                                    channel_id: state.get_id(),
                                    close_script: close_script.clone(),
                                    fee_rate: FeeRate::from_u64(0),
                                }),
                            )),
                        ))
                        .expect(ASSUME_NETWORK_ACTOR_ALIVE);
                    let shutdown_info = ShutdownInfo {
                        close_script,
                        fee_rate: 0,
                        signature: None,
                    };
                    state.local_shutdown_info = Some(shutdown_info);
                    flags |= ShuttingDownFlags::OUR_SHUTDOWN_SENT;
                    debug!("Auto accept shutdown ...");
                }
                state.update_state(ChannelState::ShuttingDown(flags));
                state.maybe_transition_to_shutdown(&self.network)?;
                Ok(())
            }
            FiberChannelMessage::ClosingSigned(closing) => {
                let ClosingSigned {
                    partial_signature,
                    channel_id,
                } = closing;

                if channel_id != state.get_id() {
                    return Err(ProcessingChannelError::InvalidParameter(
                        "Channel id mismatch".to_string(),
                    ));
                }

                // Note that we don't check the validity of the signature here.
                // we will check the validity when we're about to build the shutdown tx.
                // This may be or may not be a problem.
                // We do this to simplify the handling of the message.
                // We may change this in the future.
                // We also didn't check the state here.
                if let Some(shutdown_info) = state.remote_shutdown_info.as_mut() {
                    shutdown_info.signature = Some(partial_signature);
                }

                state.maybe_transition_to_shutdown(&self.network)?;
                Ok(())
            }
            FiberChannelMessage::ReestablishChannel(ref reestablish_channel) => {
                state
                    .handle_reestablish_channel_message(reestablish_channel, &self.network)
                    .await?;
                Ok(())
            }
            FiberChannelMessage::TxAbort(_)
            | FiberChannelMessage::TxInitRBF(_)
            | FiberChannelMessage::TxAckRBF(_) => {
                warn!("Received unsupported message: {:?}", &message);
                Ok(())
            }
        }
    }

    async fn get_tlc_error(
        &self,
        state: &mut ChannelActorState,
        error: &ProcessingChannelError,
    ) -> TlcErr {
        let error_code = match error {
            ProcessingChannelError::PeelingOnionPacketError(_) => TlcErrorCode::InvalidOnionPayload,
            ProcessingChannelError::TlcForwardFeeIsTooLow => TlcErrorCode::FeeInsufficient,
            ProcessingChannelError::TlcExpirySoon => TlcErrorCode::ExpiryTooSoon,
            ProcessingChannelError::TlcExpiryTooFar => TlcErrorCode::ExpiryTooFar,
            ProcessingChannelError::FinalInvoiceInvalid(status) => match status {
                CkbInvoiceStatus::Expired => TlcErrorCode::InvoiceExpired,
                CkbInvoiceStatus::Cancelled => TlcErrorCode::InvoiceCancelled,
                _ => TlcErrorCode::IncorrectOrUnknownPaymentDetails,
            },
            ProcessingChannelError::FinalIncorrectPreimage
            | ProcessingChannelError::FinalIncorrectPaymentHash => {
                TlcErrorCode::IncorrectOrUnknownPaymentDetails
            }
            ProcessingChannelError::FinalIncorrectHTLCAmount => {
                TlcErrorCode::FinalIncorrectTlcAmount
            }
            ProcessingChannelError::IncorrectTlcExpiry => TlcErrorCode::IncorrectTlcExpiry,
            ProcessingChannelError::IncorrectFinalTlcExpiry => {
                TlcErrorCode::FinalIncorrectExpiryDelta
            }
            ProcessingChannelError::TlcAmountIsTooLow => TlcErrorCode::AmountBelowMinimum,
            ProcessingChannelError::TlcNumberExceedLimit
            | ProcessingChannelError::TlcAmountExceedLimit
            | ProcessingChannelError::TlcValueInflightExceedLimit => {
                TlcErrorCode::TemporaryChannelFailure
            }
            ProcessingChannelError::WaitingTlcAck => TlcErrorCode::TemporaryChannelFailure,
            ProcessingChannelError::InternalError(_) => TlcErrorCode::TemporaryNodeFailure,
            ProcessingChannelError::InvalidState(_error) => match state.state {
                // we can not revert back up `ChannelReady` after `ShuttingDown`
                ChannelState::Closed(_) | ChannelState::ShuttingDown(_) => {
                    TlcErrorCode::PermanentChannelFailure
                }
                ChannelState::ChannelReady() => {
                    if !state.local_tlc_info.enabled {
                        // channel is disabled
                        TlcErrorCode::TemporaryChannelFailure
                    } else {
                        // we expect `ChannelReady` will be both OK for tlc forwarding,
                        // so here are the unreachable point in normal workflow,
                        // set `TemporaryNodeFailure` for general temporary failure of the processing node here
                        debug_assert!(false, "unreachable point in normal workflow");
                        TlcErrorCode::TemporaryNodeFailure
                    }
                }
                // otherwise, channel maybe not ready
                _ => TlcErrorCode::TemporaryChannelFailure,
            },
            ProcessingChannelError::RepeatedProcessing(_) => TlcErrorCode::TemporaryChannelFailure,
            ProcessingChannelError::SpawnErr(_)
            | ProcessingChannelError::Musig2RoundFinalizeError(_)
            | ProcessingChannelError::Musig2SigningError(_)
            | ProcessingChannelError::Musig2VerifyError(_)
            | ProcessingChannelError::CapacityError(_) => TlcErrorCode::TemporaryNodeFailure,
            ProcessingChannelError::InvalidParameter(_) => {
                TlcErrorCode::IncorrectOrUnknownPaymentDetails
            }
            ProcessingChannelError::TlcForwardingError(_) => {
                unreachable!("TlcForwardingError should be handled before this point")
            }
        };

        let channel_update = if error_code.is_update() {
            state.try_create_channel_update_message(&self.network).await
        } else {
            None
        };
        TlcErr::new_channel_fail(
            error_code,
            state.local_pubkey,
            state.must_get_funding_transaction_outpoint(),
            channel_update,
        )
    }

    async fn handle_commitment_signed_peer_message(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
        commitment_signed: CommitmentSigned,
    ) -> Result<(), ProcessingChannelError> {
        // build commitment tx and verify signature from remote, if passed send ACK for partner
        state.verify_commitment_signed_and_send_ack(commitment_signed.clone(), &self.network)?;
        debug!(
            "handled commitment_signed peer message: {:?}",
            commitment_signed
        );

        let need_commitment_signed = state.tlc_state.update_for_commitment_signed();

        // flush remove tlc for received tlcs after replying ack for peer
        self.apply_settled_remove_tlcs(myself, state, true).await;

        if need_commitment_signed && !state.tlc_state.waiting_ack {
            self.handle_commitment_signed_command(state)?;
        }

        Ok(())
    }

    async fn apply_settled_remove_tlcs(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
        inbound: bool,
    ) {
        let previous_balance = state.get_local_balance();
        let pending_tlcs = if inbound {
            state.tlc_state.received_tlcs.tlcs.iter()
        } else {
            state.tlc_state.offered_tlcs.tlcs.iter()
        };
        let settled_tlcs: Vec<_> = pending_tlcs
            .filter(|tlc| {
                tlc.removed_reason.is_some()
                    && matches!(
                        tlc.status,
                        TlcStatus::Inbound(InboundTlcStatus::RemoveAckConfirmed)
                            | TlcStatus::Outbound(OutboundTlcStatus::RemoveAckConfirmed)
                    )
                    && !state.tlc_state.applied_remove_tlcs.contains(&tlc.tlc_id)
            })
            .map(|tlc| tlc.tlc_id)
            .collect();

        for tlc_id in settled_tlcs {
            self.apply_remove_tlc_operation(myself, state, tlc_id)
                .await
                .expect("expect remove tlc success");
        }

        if state.get_local_balance() != previous_balance {
            state.update_graph_for_local_channel_change(&self.network);
            state.update_graph_for_remote_channel_change(&self.network);
        }
    }

    async fn process_add_tlc_error(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
        payment_hash: Hash256,
        tlc_id: TLCId,
        error: ProcessingChannelErrorWithSharedSecret,
    ) {
        let tlc_err = match error.source {
            // If we already have TlcErr, we can directly use it to send back to the peer.
            ProcessingChannelError::TlcForwardingError(tlc_err) => tlc_err,
            _ => {
                let error_detail = self.get_tlc_error(state, &error.source).await;
                #[cfg(debug_assertions)]
                self.network
                    .clone()
                    .send_message(NetworkActorMessage::new_notification(
                        NetworkServiceEvent::DebugEvent(DebugEvent::AddTlcFailed(
                            state.get_local_peer_id(),
                            payment_hash,
                            error_detail.clone(),
                        )),
                    ))
                    .expect(ASSUME_NETWORK_ACTOR_ALIVE);
                error_detail
            }
        };
        let error_packet = TlcErrPacket::new(
            tlc_err,
            // There's no shared secret stored in the received TLC, use the one found in the peeled onion packet.
            &error.shared_secret,
        );

        self.register_retryable_tlc_remove(
            myself,
            state,
            tlc_id,
            RemoveTlcReason::RemoveTlcFail(error_packet),
        )
        .await;
    }

    async fn update_tlc_status_on_ack(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
    ) {
        let apply_tlcs: Vec<TlcInfo> = state
            .tlc_state
            .get_committed_received_tlcs()
            .into_iter()
            .filter(|tlc| tlc.removed_reason.is_none())
            .filter(|tlc| !state.tlc_state.applied_add_tlcs.contains(&tlc.tlc_id))
            .collect();

        for add_tlc in apply_tlcs {
            assert!(add_tlc.is_received());
            if let Err(error) = self.apply_add_tlc_operation(myself, state, &add_tlc).await {
                self.process_add_tlc_error(
                    myself,
                    state,
                    add_tlc.payment_hash,
                    add_tlc.tlc_id,
                    error,
                )
                .await;
            }
        }

        // flush outbound tlcs
        self.apply_settled_remove_tlcs(myself, state, false).await;
    }

    async fn try_to_relay_remove_tlc(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
        tlc_info: &TlcInfo,
        remove_reason: RemoveTlcReason,
    ) {
        let (previous_channel_id, previous_tlc) =
            tlc_info.previous_tlc.expect("expect previous tlc");
        assert!(tlc_info.is_offered());
        assert!(previous_tlc.is_received());
        assert!(previous_channel_id != state.get_id());

        let remove_reason = remove_reason.clone().backward(&tlc_info.shared_secret);

        self.register_retryable_relay_tlc_remove(
            myself,
            state,
            previous_tlc.into(),
            previous_channel_id,
            remove_reason,
        )
        .await;
    }

    async fn try_to_settle_down_tlc(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
        tlc_id: TLCId,
    ) {
        let tlc_info = state.get_received_tlc(tlc_id).expect("expect tlc");
        let preimage = self.store.get_invoice_preimage(&tlc_info.payment_hash);

        let preimage = if let Some(preimage) = preimage {
            preimage
        } else {
            return;
        };

        let mut remove_reason = RemoveTlcReason::RemoveTlcFulfill(RemoveTlcFulfill {
            payment_preimage: preimage,
        });
        let tlc = tlc_info.clone();
        if let Some(invoice) = self.store.get_invoice(&tlc.payment_hash) {
            let status = self.get_invoice_status(&invoice);
            match status {
                CkbInvoiceStatus::Expired => {
                    remove_reason = RemoveTlcReason::RemoveTlcFail(TlcErrPacket::new(
                        TlcErr::new(TlcErrorCode::InvoiceExpired),
                        &tlc.shared_secret,
                    ));
                }
                CkbInvoiceStatus::Cancelled => {
                    remove_reason = RemoveTlcReason::RemoveTlcFail(TlcErrPacket::new(
                        TlcErr::new(TlcErrorCode::InvoiceCancelled),
                        &tlc.shared_secret,
                    ));
                }
                CkbInvoiceStatus::Paid => {
                    // we have already checked invoice status in apply_add_tlc_operation_with_peeled_onion_packet
                    // this maybe happened when process is killed and restart
                    error!("invoice already paid, ignore");
                }
                _ => {
                    // do nothing
                    // invoice status will be updated to paid after apply remove tlc operation
                }
            }
        }

        self.register_retryable_tlc_remove(myself, state, tlc.tlc_id, remove_reason)
            .await;
    }

    async fn apply_add_tlc_operation(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
        add_tlc: &TlcInfo,
    ) -> Result<(), ProcessingChannelErrorWithSharedSecret> {
        // If needed, shared secret also get be extracted from the encrypted onion packet:
        // - Extract public key from onion_packet[1..34]
        // - Obtain share secret using DH Key Exchange from the public key and the network private key stored in the network actor state.
        if let Some(peeled_onion_packet) = self
            .try_add_tlc_peel_onion_packet(state, add_tlc)
            .await
            .map_err(ProcessingChannelError::without_shared_secret)?
        {
            let shared_secret = peeled_onion_packet.shared_secret;
            self.apply_add_tlc_operation_with_peeled_onion_packet(
                myself,
                state,
                add_tlc,
                peeled_onion_packet,
            )
            .await
            .map_err(move |err| err.with_shared_secret(shared_secret))?;
        }

        if let Some(ref udt_type_script) = state.funding_udt_type_script {
            self.subscribers
                .pending_received_tlcs_subscribers
                .send(TlcNotification {
                    tlc: add_tlc.clone().into(),
                    channel_id: state.get_id(),
                    script: udt_type_script.clone(),
                });
        }

        // we don't need to settle down the tlc if it is not the last hop here,
        // some e2e tests are calling AddTlc manually, so we can not use onion packet to
        // check whether it's the last hop here, maybe need to revisit in future.
        self.try_to_settle_down_tlc(myself, state, add_tlc.tlc_id)
            .await;

        warn!("finished check tlc for peer message: {:?}", &add_tlc.tlc_id);
        Ok(())
    }

    async fn try_add_tlc_peel_onion_packet(
        &self,
        state: &mut ChannelActorState,
        add_tlc: &TlcInfo,
    ) -> Result<Option<PeeledPaymentOnionPacket>, ProcessingChannelError> {
        state.check_tlc_expiry(add_tlc.expiry)?;

        assert!(state.get_received_tlc(add_tlc.tlc_id).is_some());

        OptionFuture::from(
            add_tlc
                .onion_packet
                .clone()
                .map(|onion_packet| self.peel_onion_packet(onion_packet, add_tlc.payment_hash)),
        )
        .await
        .transpose()
    }

    async fn apply_add_tlc_operation_with_peeled_onion_packet(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
        add_tlc: &TlcInfo,
        peeled_onion_packet: PeeledPaymentOnionPacket,
    ) -> Result<(), ProcessingChannelError> {
        let payment_hash = add_tlc.payment_hash;
        let received_amount = add_tlc.amount;
        let forward_amount = peeled_onion_packet.current.amount;

        state.tlc_state.applied_add_tlcs.insert(add_tlc.tlc_id);
        if peeled_onion_packet.is_last() {
            if forward_amount != add_tlc.amount {
                return Err(ProcessingChannelError::FinalIncorrectHTLCAmount);
            }

            if add_tlc.expiry < peeled_onion_packet.current.expiry {
                return Err(ProcessingChannelError::IncorrectFinalTlcExpiry);
            }
            if add_tlc.expiry < now_timestamp_as_millis_u64() + MIN_TLC_EXPIRY_DELTA {
                return Err(ProcessingChannelError::TlcExpirySoon);
            }

            if let Some(invoice) = self.store.get_invoice(&payment_hash) {
                let invoice_status = self.get_invoice_status(&invoice);
                if invoice_status != CkbInvoiceStatus::Open {
                    return Err(ProcessingChannelError::FinalInvoiceInvalid(invoice_status));
                }
            }

            // if this is the last hop, store the preimage.
            // though we will RemoveTlcFulfill the TLC in try_to_settle_down_tlc function,
            // here we can do error check early here for better error handling.
            let preimage = peeled_onion_packet
                .current
                .payment_preimage
                .or_else(|| self.store.get_invoice_preimage(&add_tlc.payment_hash));

            if let Some(preimage) = preimage {
                let filled_payment_hash: Hash256 = add_tlc.hash_algorithm.hash(preimage).into();
                if add_tlc.payment_hash != filled_payment_hash {
                    return Err(ProcessingChannelError::FinalIncorrectPreimage);
                }
                // update invoice status to received only all the error checking passed
                if let Some(_invoice) = self.store.get_invoice(&payment_hash) {
                    self.store
                        .update_invoice_status(&payment_hash, CkbInvoiceStatus::Received)
                        .expect("update invoice status failed");
                }
                self.store
                    .insert_payment_preimage(payment_hash, preimage)
                    .map_err(|_| {
                        ProcessingChannelError::InternalError("insert preimage failed".to_string())
                    })?;
            } else {
                return Err(ProcessingChannelError::FinalIncorrectPaymentHash);
            }
        } else {
            // here we don't need to check current config is public or enabled, because
            // handle_add_tlc_command will check the channel state before forwarding
            // and private channel can also forward TLC to public channel
            if add_tlc.expiry
                < peeled_onion_packet.current.expiry + state.local_tlc_info.tlc_expiry_delta
            {
                return Err(ProcessingChannelError::IncorrectTlcExpiry);
            }

            if received_amount < forward_amount {
                return Err(ProcessingChannelError::InvalidParameter(
                    "received_amount is less than forward_amount".to_string(),
                ));
            }

            // Next forwarding channel will get the forward_fee and check if it's enough.
            let forward_fee = received_amount.saturating_sub(forward_amount);

            // if this is not the last hop, forward TLC to next hop
            self.register_retryable_forward_tlc(
                myself,
                state,
                add_tlc.tlc_id,
                add_tlc.payment_hash,
                peeled_onion_packet.clone(),
                forward_fee,
            )
            .await;
        }
        Ok(())
    }

    fn handle_add_tlc_peer_message(
        &self,
        state: &mut ChannelActorState,
        add_tlc: AddTlc,
    ) -> Result<(), ProcessingChannelError> {
        // TODO: here we only check the error which sender didn't follow agreed rules,
        //       if any error happened here we need go to shutdown procedure

        state.check_for_tlc_update(Some(add_tlc.amount), false, false)?;
        let tlc_info = state.create_inbounding_tlc(add_tlc.clone())?;
        state.check_insert_tlc(&tlc_info)?;
        state.tlc_state.add_received_tlc(tlc_info);
        state.increment_next_received_tlc_id();
        Ok(())
    }

    fn handle_remove_tlc_peer_message(
        &self,
        state: &mut ChannelActorState,
        remove_tlc: RemoveTlc,
    ) -> Result<(), ProcessingChannelError> {
        state.check_for_tlc_update(None, false, false)?;
        // TODO: here if we received a invalid remove tlc, it's maybe a malioucious peer,
        // maybe we need to go through shutdown process for this error
        state
            .check_remove_tlc_with_reason(TLCId::Offered(remove_tlc.tlc_id), &remove_tlc.reason)?;
        let payment_hash = state
            .tlc_state
            .set_offered_tlc_removed(remove_tlc.tlc_id, remove_tlc.reason.clone());
        if let RemoveTlcReason::RemoveTlcFulfill(RemoveTlcFulfill { payment_preimage }) =
            remove_tlc.reason
        {
            // we need to store the preimage if the TLC is fulfilled
            // incase the peer has already shutdown the channel,
            // so we can send setttlement transaction to get money when necessary
            // the preimage must be valid since we have checked it in check_remove_tlc_with_reason
            self.store
                .insert_payment_preimage(payment_hash, payment_preimage)
                .map_err(|_| {
                    ProcessingChannelError::InternalError("insert preimage failed".to_string())
                })?;
        }
        Ok(())
    }

    async fn apply_remove_tlc_operation(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
        tlc_id: TLCId,
    ) -> Result<(), ProcessingChannelError> {
        let channel_id = state.get_id();
        assert!(!state.tlc_state.applied_remove_tlcs.contains(&tlc_id));
        state.tlc_state.applied_remove_tlcs.insert(tlc_id);

        let (tlc_info, remove_reason) = state.remove_tlc_with_reason(tlc_id)?;
        if matches!(remove_reason, RemoveTlcReason::RemoveTlcFulfill(_))
            && self.store.get_invoice(&tlc_info.payment_hash).is_some()
        {
            self.store
                .update_invoice_status(&tlc_info.payment_hash, CkbInvoiceStatus::Paid)
                .expect("update invoice status failed");
        }

        if let (
            Some(ref udt_type_script),
            RemoveTlcReason::RemoveTlcFulfill(RemoveTlcFulfill { payment_preimage }),
        ) = (state.funding_udt_type_script.clone(), &remove_reason)
        {
            let mut tlc_notify_info: TlcNotifyInfo = tlc_info.clone().into();
            tlc_notify_info.payment_preimage = Some(*payment_preimage);
            self.subscribers
                .settled_tlcs_subscribers
                .send(TlcNotification {
                    tlc: tlc_notify_info,
                    channel_id,
                    script: udt_type_script.clone(),
                });
        }
        if tlc_info.previous_tlc.is_none() {
            // only the original sender of the TLC should send `TlcRemoveReceived` event
            // because only the original sender cares about the TLC event to settle the payment
            if tlc_info.is_offered() {
                self.network
                    .send_message(NetworkActorMessage::new_event(
                        NetworkActorEvent::TlcRemoveReceived(
                            tlc_info.payment_hash,
                            remove_reason.clone(),
                        ),
                    ))
                    .expect("myself alive");
            }
        } else {
            // relay RemoveTlc to previous channel if needed
            self.try_to_relay_remove_tlc(myself, state, &tlc_info, remove_reason)
                .await;
        }
        Ok(())
    }

    pub fn handle_commitment_signed_command(
        &self,
        state: &mut ChannelActorState,
    ) -> ProcessingChannelResult {
        let flags = match state.state {
            ChannelState::CollaboratingFundingTx(flags)
                if !flags.contains(CollaboratingFundingTxFlags::COLLABRATION_COMPLETED) =>
            {
                return Err(ProcessingChannelError::InvalidState(format!(
                    "Unable to process commitment_signed command in state {:?}, as collaboration is not completed yet.",
                    &state.state
                )));
            }
            ChannelState::CollaboratingFundingTx(_) => {
                CommitmentSignedFlags::SigningCommitment(SigningCommitmentFlags::empty())
            }
            ChannelState::SigningCommitment(flags)
                if flags.contains(SigningCommitmentFlags::OUR_COMMITMENT_SIGNED_SENT) =>
            {
                return Err(ProcessingChannelError::InvalidState(format!(
                    "Unable to process commitment_signed command in state {:?}, as we have already sent our commitment_signed message.",
                    &state.state
                )));
            }
            ChannelState::SigningCommitment(flags) => {
                CommitmentSignedFlags::SigningCommitment(flags)
            }
            ChannelState::ChannelReady() => CommitmentSignedFlags::ChannelReady(),
            ChannelState::ShuttingDown(flags) => {
                if flags.contains(ShuttingDownFlags::AWAITING_PENDING_TLCS) {
                    CommitmentSignedFlags::PendingShutdown()
                } else {
                    return Err(ProcessingChannelError::InvalidState(format!(
                        "Unable to process commitment_signed message in shutdowning state with flags {:?}",
                        &flags
                    )));
                }
            }
            _ => {
                return Err(ProcessingChannelError::InvalidState(format!(
                    "Unable to send commitment signed message in state {:?}",
                    &state.state
                )));
            }
        };
        state.clean_up_failed_tlcs();
        let (funding_tx_partial_signature, commitment_tx_partial_signature) =
            state.build_and_sign_commitment_tx()?;
        let commitment_signed = CommitmentSigned {
            channel_id: state.get_id(),
            funding_tx_partial_signature,
            commitment_tx_partial_signature,
            next_local_nonce: state.get_next_local_nonce(),
        };

        self.network
            .send_message(NetworkActorMessage::new_command(
                NetworkActorCommand::SendFiberMessage(FiberMessageWithPeerId::new(
                    state.get_remote_peer_id(),
                    FiberMessage::commitment_signed(commitment_signed.clone()),
                )),
            ))
            .expect(ASSUME_NETWORK_ACTOR_ALIVE);

        match flags {
            CommitmentSignedFlags::SigningCommitment(flags) => {
                let flags = flags | SigningCommitmentFlags::OUR_COMMITMENT_SIGNED_SENT;
                state.update_state(ChannelState::SigningCommitment(flags));
                state.maybe_transition_to_tx_signatures(flags, &self.network)?;
            }
            CommitmentSignedFlags::ChannelReady() => {
                state.tlc_state.set_waiting_ack(true);
            }
            CommitmentSignedFlags::PendingShutdown() => {
                state.tlc_state.set_waiting_ack(true);
                state.maybe_transition_to_shutdown(&self.network)?;
            }
        }
        state.update_last_commitment_signed_remote_nonce();
        Ok(())
    }

    pub fn handle_add_tlc_command(
        &self,
        state: &mut ChannelActorState,
        command: AddTlcCommand,
    ) -> Result<u64, ProcessingChannelError> {
        if !state.local_tlc_info.enabled {
            return Err(ProcessingChannelError::InvalidState(format!(
                "TLC forwarding is not enabled for channel {}",
                state.get_id()
            )));
        }

        state.check_for_tlc_update(Some(command.amount), true, true)?;
        state.check_tlc_expiry(command.expiry)?;
        state.check_tlc_forward_amount(
            command.amount,
            command.previous_tlc.map(|x| x.forwarding_fee),
        )?;
        let tlc = state.create_outbounding_tlc(command.clone());
        state.check_insert_tlc(&tlc)?;
        state.tlc_state.add_offered_tlc(tlc.clone());
        state.increment_next_offered_tlc_id();

        let add_tlc = AddTlc {
            channel_id: state.get_id(),
            tlc_id: tlc.tlc_id.into(),
            amount: command.amount,
            payment_hash: command.payment_hash,
            expiry: command.expiry,
            hash_algorithm: command.hash_algorithm,
            onion_packet: command.onion_packet,
        };

        // Send tlc update message to peer.
        let msg = FiberMessageWithPeerId::new(
            state.get_remote_peer_id(),
            FiberMessage::add_tlc(add_tlc.clone()),
        );

        self.network
            .send_message(NetworkActorMessage::new_command(
                NetworkActorCommand::SendFiberMessage(msg),
            ))
            .expect(ASSUME_NETWORK_ACTOR_ALIVE);

        self.handle_commitment_signed_command(state)?;
        Ok(tlc.tlc_id.into())
    }

    pub fn handle_remove_tlc_command(
        &self,
        state: &mut ChannelActorState,
        command: RemoveTlcCommand,
    ) -> ProcessingChannelResult {
        state.check_for_tlc_update(None, true, false)?;
        state.check_remove_tlc_with_reason(TLCId::Received(command.id), &command.reason)?;
        state
            .tlc_state
            .set_received_tlc_removed(command.id, command.reason.clone());
        let msg = FiberMessageWithPeerId::new(
            state.get_remote_peer_id(),
            FiberMessage::remove_tlc(RemoveTlc {
                channel_id: state.get_id(),
                tlc_id: command.id,
                reason: command.reason,
            }),
        );
        self.network
            .send_message(NetworkActorMessage::new_command(
                NetworkActorCommand::SendFiberMessage(msg),
            ))
            .expect(ASSUME_NETWORK_ACTOR_ALIVE);

        state.maybe_transition_to_shutdown(&self.network)?;
        self.handle_commitment_signed_command(state)?;
        Ok(())
    }

    pub fn handle_shutdown_command(
        &self,
        state: &mut ChannelActorState,
        command: ShutdownCommand,
    ) -> ProcessingChannelResult {
        debug!("Handling shutdown command: {:?}", &command);
        if command.force {
            match state.state {
                ChannelState::ChannelReady() => {
                    debug!("Handling force shutdown command in ChannelReady state");
                }
                ChannelState::ShuttingDown(flags) => {
                    debug!(
                        "Handling force shutdown command in ShuttingDown state, flags: {:?}",
                        &flags
                    );
                }
                _ => {
                    return Err(ProcessingChannelError::InvalidState(format!(
                        "Handling force shutdown command invalid state {:?}",
                        &state.state
                    )));
                }
            };

            let transaction = state
                .latest_commitment_transaction
                .clone()
                .expect("latest_commitment_transaction should exist when channel is in ChannelReady of ShuttingDown state");
            self.network
                .send_message(NetworkActorMessage::new_event(
                    NetworkActorEvent::CommitmentTransactionPending(transaction, state.get_id()),
                ))
                .expect(ASSUME_NETWORK_ACTOR_ALIVE);

            state.update_state(ChannelState::ShuttingDown(
                ShuttingDownFlags::WAITING_COMMITMENT_CONFIRMATION,
            ));
            return Ok(());
        }

        let flags = match state.state {
            ChannelState::ChannelReady() => {
                debug!("Handling shutdown command in ChannelReady state");
                ShuttingDownFlags::empty()
            }
            _ => {
                debug!("Handling shutdown command in state {:?}", &state.state);
                return Err(ProcessingChannelError::InvalidState(format!(
                    "Trying to send shutdown message while in invalid state {:?}",
                    &state.state
                )));
            }
        };

        state.check_shutdown_fee_rate(command.fee_rate, &command.close_script)?;
        self.network
            .send_message(NetworkActorMessage::new_command(
                NetworkActorCommand::SendFiberMessage(FiberMessageWithPeerId::new(
                    self.get_remote_peer_id(),
                    FiberMessage::shutdown(Shutdown {
                        channel_id: state.get_id(),
                        close_script: command.close_script.clone(),
                        fee_rate: command.fee_rate,
                    }),
                )),
            ))
            .expect(ASSUME_NETWORK_ACTOR_ALIVE);

        let shutdown_info = ShutdownInfo {
            close_script: command.close_script,
            fee_rate: command.fee_rate.as_u64(),
            signature: None,
        };
        state.local_shutdown_info = Some(shutdown_info);
        state.update_state(ChannelState::ShuttingDown(
            flags | ShuttingDownFlags::OUR_SHUTDOWN_SENT,
        ));
        debug!(
            "Channel state updated to {:?} after processing shutdown command",
            &state.state
        );

        state.maybe_transition_to_shutdown(&self.network)
    }

    pub async fn handle_update_command(
        &self,
        state: &mut ChannelActorState,
        command: UpdateCommand,
    ) -> ProcessingChannelResult {
        if !state.is_public() {
            return Err(ProcessingChannelError::InvalidState(
                "Only public channel can be updated".to_string(),
            ));
        }

        let UpdateCommand {
            enabled,
            tlc_expiry_delta,
            tlc_minimum_value,
            tlc_fee_proportional_millionths,
        } = command;

        let mut updated = false;

        if let Some(enabled) = enabled {
            updated |= state.update_our_enabled(enabled);
        }

        if let Some(delta) = tlc_expiry_delta {
            if delta < MIN_TLC_EXPIRY_DELTA {
                return Err(ProcessingChannelError::InvalidParameter(format!(
                    "TLC expiry delta is too small, expect larger than {}",
                    MIN_TLC_EXPIRY_DELTA
                )));
            }
            updated |= state.update_our_tlc_expiry_delta(delta);
        }

        if let Some(value) = tlc_minimum_value {
            updated |= state.update_our_tlc_min_value(value);
        }

        if let Some(fee) = tlc_fee_proportional_millionths {
            updated |= state.update_our_tlc_fee_proportional_millionths(fee);
        }

        if updated {
            state
                .notify_owned_channel_updated(&self.network, true)
                .await;
        }

        Ok(())
    }

    pub async fn register_retryable_tlc_remove(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
        tlc_id: TLCId,
        reason: RemoveTlcReason,
    ) {
        let remove_tlc = RetryableTlcOperation::RemoveTlc(tlc_id, reason);
        self.register_retryable_tlc_operation(myself, state, remove_tlc)
            .await;
    }

    pub async fn register_retryable_relay_tlc_remove(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
        tlc_id: u64,
        channel_id: Hash256,
        reason: RemoveTlcReason,
    ) {
        let remove_tlc = RetryableTlcOperation::RelayRemoveTlc(channel_id, tlc_id, reason);
        self.register_retryable_tlc_operation(myself, state, remove_tlc)
            .await;
    }

    pub async fn register_retryable_forward_tlc(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
        tlc_id: TLCId,
        payment_hash: Hash256,
        peeled_onion_packet: PeeledPaymentOnionPacket,
        forward_fee: u128,
    ) {
        let forward_tlc = RetryableTlcOperation::ForwardTlc(
            payment_hash,
            tlc_id,
            peeled_onion_packet,
            forward_fee,
            true,
        );
        self.register_retryable_tlc_operation(myself, state, forward_tlc)
            .await;
    }

    async fn register_retryable_tlc_operation(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
        operation: RetryableTlcOperation,
    ) {
        if state.tlc_state.insert_retryable_tlc_operation(operation) {
            myself
                .send_message(ChannelActorMessage::Event(
                    ChannelEvent::CheckTlcRetryOperation,
                ))
                .expect("myself alive");
        }
    }

    fn set_forward_tlc_status(
        &self,
        state: &mut ChannelActorState,
        payment_hash: Hash256,
        try_one_time: bool,
    ) {
        if let Some(RetryableTlcOperation::ForwardTlc(.., ref mut sent)) =
            state.tlc_state.retryable_tlc_operations.iter_mut().find(
                |op| matches!(op, RetryableTlcOperation::ForwardTlc(ph,..) if *ph == payment_hash),
            )
        {
            *sent = try_one_time;
        }
    }

    pub async fn apply_retryable_tlc_operations(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
    ) {
        let mut pending_tlc_ops = state.tlc_state.get_pending_operations();
        pending_tlc_ops.retain_mut(|retryable_operation| {
            match retryable_operation {
                RetryableTlcOperation::RemoveTlc(tlc_id, ref reason) => {
                    match self.handle_remove_tlc_command(
                        state,
                        RemoveTlcCommand {
                            id: u64::from(*tlc_id),
                            reason: reason.clone(),
                        },
                    ) {
                        Ok(_) | Err(ProcessingChannelError::RepeatedProcessing(_)) => false,
                        Err(ProcessingChannelError::WaitingTlcAck) => true,
                        Err(_err) => false,
                    }
                }
                RetryableTlcOperation::RelayRemoveTlc(channel_id, tlc_id, ref reason) => {
                    // send relay remove tlc with network actor to previous hop
                    let (send, _recv) = oneshot::channel::<Result<(), ProcessingChannelError>>();
                    let port = RpcReplyPort::from(send);
                    self.network
                        .send_message(NetworkActorMessage::new_command(
                            NetworkActorCommand::ControlFiberChannel(ChannelCommandWithId {
                                channel_id: *channel_id,
                                command: ChannelCommand::RemoveTlc(
                                    RemoveTlcCommand {
                                        id: (*tlc_id),
                                        reason: reason.clone(),
                                    },
                                    port,
                                ),
                            }),
                        ))
                        .expect(ASSUME_NETWORK_ACTOR_ALIVE);
                    // the previous hop will automatically retry if there is Waiting_Ack error
                    false
                }
                RetryableTlcOperation::ForwardTlc(
                    payment_hash,
                    tlc_id,
                    ref peeled_onion_packet,
                    forward_fee,
                    try_one_time,
                ) => {
                    // there is a potential deadlock for waiting the result from another channel actor
                    // for the scenario these two things happen at the same time:
                    //  1. channel A send forward tlc to channel B
                    //  2. channel B send forward tlc to channel A
                    // we may end up waiting for each other forever
                    //
                    // but we need the result for better error handling
                    // so we introduce the ForwardTlcResult to get the result based on actor message
                    if !*try_one_time {
                        // we need to decide whether to retry it until we get ForwardTlcResult
                        true
                    } else {
                        match self.network.send_message(NetworkActorMessage::Command(
                            NetworkActorCommand::SendPaymentOnionPacket(SendOnionPacketCommand {
                                peeled_onion_packet: peeled_onion_packet.clone(),
                                previous_tlc: Some(PrevTlcInfo::new(
                                    state.get_id(),
                                    u64::from(*tlc_id),
                                    *forward_fee,
                                )),
                                payment_hash: *payment_hash,
                            }),
                        )) {
                            Ok(_) => {
                                // here we just make sure the forward tlc is sent, we don't need to wait for the result
                                // retry it if necessary until we get ForwardTlcResult
                                // self.set_forward_tlc_status(state, *payment_hash, false);
                                *try_one_time = false;
                                true
                            }
                            Err(_err) => {
                                // network actor is dead? we will retry it later
                                false
                            }
                        }
                    }
                }
            }
        });

        state.tlc_state.retryable_tlc_operations = pending_tlc_ops;
        if state.tlc_state.has_pending_operations() {
            myself.send_after(RETRYABLE_TLC_OPS_INTERVAL, || {
                ChannelActorMessage::Event(ChannelEvent::CheckTlcRetryOperation)
            });
        }
    }

    async fn handle_forward_tlc_result(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
        result: ForwardTlcResult,
    ) {
        let pending_ops = state.tlc_state.get_pending_operations();
        if let Some((tlc_op, peeled_onion)) = pending_ops.iter().find_map(|op| match op {
            RetryableTlcOperation::ForwardTlc(payment_hash, _, peel_onion_packet, ..)
                if *payment_hash == result.payment_hash =>
            {
                Some((op, peel_onion_packet))
            }
            _ => None,
        }) {
            if let Some((channel_err, tlc_err)) = result.error_info {
                match channel_err {
                    ProcessingChannelError::WaitingTlcAck => {
                        // if we get WaitingTlcAck error, we will retry it later
                        self.set_forward_tlc_status(state, result.payment_hash, true);
                    }
                    ProcessingChannelError::RepeatedProcessing(_) => {
                        // ignore repeated processing error, we have already handled it
                        state.tlc_state.remove_pending_tlc_operation(tlc_op);
                    }
                    _ => {
                        let error = ProcessingChannelError::TlcForwardingError(tlc_err)
                            .with_shared_secret(peeled_onion.shared_secret);
                        self.process_add_tlc_error(
                            myself,
                            state,
                            result.payment_hash,
                            TLCId::Received(result.tlc_id),
                            error,
                        )
                        .await;
                        state.tlc_state.remove_pending_tlc_operation(tlc_op);
                    }
                }
            } else {
                // if we get success result from AddTlc, we will remove the pending operation
                state.tlc_state.remove_pending_tlc_operation(tlc_op);
            }
        }
    }

    // This is the dual of `handle_tx_collaboration_msg`. Any logic error here is likely
    // to present in the other function as well.
    pub fn handle_tx_collaboration_command(
        &self,
        state: &mut ChannelActorState,
        command: TxCollaborationCommand,
    ) -> Result<(), ProcessingChannelError> {
        debug!("Handling tx collaboration command: {:?}", &command);
        let is_complete_command = matches!(command, TxCollaborationCommand::TxComplete());
        let is_waiting_for_remote = match state.state {
            ChannelState::CollaboratingFundingTx(flags) => {
                flags.contains(CollaboratingFundingTxFlags::AWAITING_REMOTE_TX_COLLABORATION_MSG)
            }
            _ => false,
        };

        // We first exclude below cases that are invalid for tx collaboration,
        // and then process the commands.
        let flags = match state.state {
            ChannelState::NegotiatingFunding(NegotiatingFundingFlags::INIT_SENT)
                if state.is_acceptor =>
            {
                return Err(ProcessingChannelError::InvalidState(
                    "Acceptor tries to start sending tx collaboration message".to_string(),
                ));
            }
            ChannelState::NegotiatingFunding(_) => {
                debug!("Beginning processing tx collaboration command, and transitioning from {:?} to CollaboratingFundingTx state", state.state);
                state.state =
                    ChannelState::CollaboratingFundingTx(CollaboratingFundingTxFlags::empty());
                CollaboratingFundingTxFlags::empty()
            }
            ChannelState::CollaboratingFundingTx(_)
                if !is_complete_command && is_waiting_for_remote =>
            {
                return Err(ProcessingChannelError::InvalidState(format!(
                    "Trying to process command {:?} while in {:?} (should only send non-complete message after received response from peer)",
                    &command, state.state
                )));
            }
            ChannelState::CollaboratingFundingTx(flags) => {
                debug!(
                    "Processing tx collaboration command {:?} for state {:?}",
                    &command, &state.state
                );
                flags
            }
            _ => {
                return Err(ProcessingChannelError::InvalidState(format!(
                    "Invalid tx collaboration command {:?} for state {:?}",
                    &command, state.state
                )));
            }
        };

        // TODO: Note that we may deadlock here if send_tx_collaboration_command does successfully send the message,
        // as in that case both us and the remote are waiting for each other to send the message.
        match command {
            TxCollaborationCommand::TxUpdate(tx_update) => {
                let fiber_message = FiberMessage::tx_update(TxUpdate {
                    channel_id: state.get_id(),
                    tx: tx_update.transaction.clone(),
                });
                self.network
                    .send_message(NetworkActorMessage::new_command(
                        NetworkActorCommand::SendFiberMessage(FiberMessageWithPeerId::new(
                            state.get_remote_peer_id(),
                            fiber_message,
                        )),
                    ))
                    .expect(ASSUME_NETWORK_ACTOR_ALIVE);

                state.update_state(ChannelState::CollaboratingFundingTx(
                    CollaboratingFundingTxFlags::AWAITING_REMOTE_TX_COLLABORATION_MSG,
                ));
                state.funding_tx = Some(tx_update.transaction.clone());
                state.maybe_complete_tx_collaboration(tx_update.transaction, &self.network)?;
            }
            TxCollaborationCommand::TxComplete() => {
                state.check_tx_complete_preconditions()?;
                let commitment_tx_partial_signature = state.build_init_commitment_tx_signature()?;
                let fiber_message = FiberMessage::tx_complete(TxComplete {
                    channel_id: state.get_id(),
                    commitment_tx_partial_signature,
                });
                self.network
                    .send_message(NetworkActorMessage::new_command(
                        NetworkActorCommand::SendFiberMessage(FiberMessageWithPeerId::new(
                            state.get_remote_peer_id(),
                            fiber_message,
                        )),
                    ))
                    .expect(ASSUME_NETWORK_ACTOR_ALIVE);

                state.update_state(ChannelState::CollaboratingFundingTx(
                    flags | CollaboratingFundingTxFlags::OUR_TX_COMPLETE_SENT,
                ));
            }
        }

        Ok(())
    }

    pub async fn handle_command(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
        command: ChannelCommand,
    ) -> Result<(), ProcessingChannelError> {
        match command {
            ChannelCommand::TxCollaborationCommand(tx_collaboration_command) => {
                self.handle_tx_collaboration_command(state, tx_collaboration_command)
            }
            ChannelCommand::CommitmentSigned() => self.handle_commitment_signed_command(state),
            ChannelCommand::AddTlc(command, reply) => {
                let res = self.handle_add_tlc_command(state, command.clone());
                let error_info = if let Err(ref err) = res {
                    Some((err.clone(), self.get_tlc_error(state, err).await))
                } else {
                    None
                };

                self.network
                    .send_message(NetworkActorMessage::new_event(
                        NetworkActorEvent::AddTlcResult(
                            command.payment_hash,
                            error_info,
                            command.previous_tlc,
                        ),
                    ))
                    .expect("network actor alive");

                match res {
                    Ok(tlc_id) => {
                        let _ = reply.send(Ok(AddTlcResponse { tlc_id }));
                        Ok(())
                    }
                    Err(err) => {
                        let tlc_err = self.get_tlc_error(state, &err).await;
                        let _ = reply.send(Err(tlc_err));
                        Err(err)
                    }
                }
            }
            ChannelCommand::RemoveTlc(command, reply) => {
                match self.handle_remove_tlc_command(state, command.clone()) {
                    Ok(_) => {
                        let _ = reply.send(Ok(()));
                        Ok(())
                    }
                    Err(err) => {
                        if matches!(err, ProcessingChannelError::WaitingTlcAck) {
                            self.register_retryable_tlc_remove(
                                myself,
                                state,
                                TLCId::Received(command.id),
                                command.reason,
                            )
                            .await;
                        }
                        let _ = reply.send(Err(err.clone()));
                        Err(err)
                    }
                }
            }
            ChannelCommand::Shutdown(command, reply) => {
                match self.handle_shutdown_command(state, command) {
                    Ok(_) => {
                        debug!("Shutdown command processed successfully");
                        let _ = reply.send(Ok(()));
                        Ok(())
                    }
                    Err(err) => {
                        debug!("Error processing shutdown command: {:?}", &err);
                        let _ = reply.send(Err(err.to_string()));
                        Err(err)
                    }
                }
            }
            ChannelCommand::Update(command, reply) => {
                match self.handle_update_command(state, command).await {
                    Ok(_) => {
                        debug!("Update command processed successfully");
                        let _ = reply.send(Ok(()));
                        Ok(())
                    }
                    Err(err) => {
                        debug!("Error processing update command: {:?}", &err);
                        let _ = reply.send(Err(err.to_string()));
                        Err(err)
                    }
                }
            }
            ChannelCommand::ForwardTlcResult(forward_tlc_res) => {
                self.handle_forward_tlc_result(myself, state, forward_tlc_res)
                    .await;
                Ok(())
            }
            #[cfg(test)]
            ChannelCommand::ReloadState(reload_params) => {
                *state = self
                    .store
                    .get_channel_actor_state(&state.get_id())
                    .expect("load channel state failed");
                let ReloadParams { notify_changes } = reload_params;
                if notify_changes {
                    state
                        .notify_owned_channel_updated(&self.network, false)
                        .await;
                }
                Ok(())
            }
        }
    }

    pub async fn handle_event(
        &self,
        myself: &ActorRef<ChannelActorMessage>,
        state: &mut ChannelActorState,
        event: ChannelEvent,
    ) -> Result<(), ProcessingChannelError> {
        match event {
            ChannelEvent::FundingTransactionConfirmed(block_hash, tx_index, timestamp) => {
                debug!("Funding transaction confirmed");
                let flags = match state.state {
                    ChannelState::AwaitingChannelReady(flags) => flags,
                    ChannelState::AwaitingTxSignatures(f)
                        if f.contains(AwaitingTxSignaturesFlags::TX_SIGNATURES_SENT) =>
                    {
                        AwaitingChannelReadyFlags::empty()
                    }
                    _ => {
                        return Err(ProcessingChannelError::InvalidState(format!(
                            "Expecting funding transaction confirmed event in state AwaitingChannelReady or after TX_SIGNATURES_SENT, but got state {:?}", &state.state)));
                    }
                };
                state.funding_tx_confirmed_at = Some((block_hash, tx_index, timestamp));
                self.network
                    .send_message(NetworkActorMessage::new_command(
                        NetworkActorCommand::SendFiberMessage(FiberMessageWithPeerId::new(
                            state.get_remote_peer_id(),
                            FiberMessage::channel_ready(ChannelReady {
                                channel_id: state.get_id(),
                            }),
                        )),
                    ))
                    .expect(ASSUME_NETWORK_ACTOR_ALIVE);
                let flags = flags | AwaitingChannelReadyFlags::OUR_CHANNEL_READY;
                state.update_state(ChannelState::AwaitingChannelReady(flags));
                state.maybe_channel_is_ready(&self.network).await;
            }
            ChannelEvent::CommitmentTransactionConfirmed => {
                match state.state {
                    ChannelState::ShuttingDown(flags)
                        if flags.contains(ShuttingDownFlags::WAITING_COMMITMENT_CONFIRMATION) => {}
                    _ => {
                        return Err(ProcessingChannelError::InvalidState(format!(
                            "Expecting commitment transaction confirmed event in state ShuttingDown, but got state {:?}", &state.state)
                        ));
                    }
                };
                state.update_state(ChannelState::Closed(CloseFlags::UNCOOPERATIVE));
                debug!("Channel closed with uncooperative close");
            }
            ChannelEvent::CheckTlcRetryOperation => {
                self.apply_retryable_tlc_operations(myself, state).await;
            }
            ChannelEvent::PeerDisconnected => {
                myself.stop(Some("PeerDisconnected".to_string()));
            }
            ChannelEvent::ClosingTransactionConfirmed => {
                // Broadcast the channel update message which disables the channel.
                if state.is_public() {
                    let update = state.generate_disabled_channel_update(&self.network).await;

                    self.network
                        .send_message(NetworkActorMessage::new_command(
                            NetworkActorCommand::BroadcastMessages(vec![
                                BroadcastMessageWithTimestamp::ChannelUpdate(update),
                            ]),
                        ))
                        .expect(ASSUME_NETWORK_ACTOR_ALIVE);
                }
                debug_event!(self.network, "ChannelClosed");
                myself.stop(Some("ChannelClosed".to_string()));
            }
        }
        Ok(())
    }

    fn get_invoice_status(&self, invoice: &CkbInvoice) -> CkbInvoiceStatus {
        match self
            .store
            .get_invoice_status(invoice.payment_hash())
            .expect("no invoice status found")
        {
            CkbInvoiceStatus::Open if invoice.is_expired() => CkbInvoiceStatus::Expired,
            status => status,
        }
    }

    async fn peel_onion_packet(
        &self,
        onion_packet: PaymentOnionPacket,
        payment_hash: Hash256,
    ) -> Result<PeeledPaymentOnionPacket, ProcessingChannelError> {
        call!(self.network, |tx| NetworkActorMessage::Command(
            NetworkActorCommand::PeelPaymentOnionPacket(onion_packet, payment_hash, tx)
        ))
        .expect(ASSUME_NETWORK_ACTOR_ALIVE)
        .map_err(ProcessingChannelError::PeelingOnionPacketError)
    }
}

#[rasync_trait]
impl<S> Actor for ChannelActor<S>
where
    S: ChannelActorStateStore + InvoiceStore + Send + Sync + 'static,
{
    type Msg = ChannelActorMessage;
    type State = ChannelActorState;
    type Arguments = ChannelInitializationParameter;

    async fn pre_start(
        &self,
        _myself: ActorRef<Self::Msg>,
        args: Self::Arguments,
    ) -> Result<Self::State, ActorProcessingErr> {
        // startup the event processing
        match args {
            ChannelInitializationParameter::AcceptChannel(AcceptChannelParameter {
                funding_amount: local_funding_amount,
                reserved_ckb_amount: local_reserved_ckb_amount,
                shutdown_script: local_shutdown_script,
                tlc_info,
                public_channel_info,
                seed,
                open_channel,
                channel_id_sender,
                max_tlc_number_in_flight,
                max_tlc_value_in_flight,
            }) => {
                let peer_id = self.get_remote_peer_id();
                debug!(
                    "Accepting channel {:?} to peer {:?}",
                    &open_channel, &peer_id
                );

                let counterpart_pubkeys = (&open_channel).into();
                let public = open_channel.is_public();
                let OpenChannel {
                    channel_id,
                    chain_hash,
                    commitment_fee_rate,
                    commitment_delay_epoch,
                    funding_fee_rate,
                    funding_udt_type_script,
                    funding_amount,
                    shutdown_script,
                    reserved_ckb_amount,
                    first_per_commitment_point,
                    second_per_commitment_point,
                    next_local_nonce,
                    max_tlc_value_in_flight: remote_max_tlc_value_in_flight,
                    max_tlc_number_in_flight: remote_max_tlc_number_in_flight,
                    channel_announcement_nonce,
                    ..
                } = &open_channel;

                if *chain_hash != get_chain_hash() {
                    return Err(Box::new(ProcessingChannelError::InvalidParameter(format!(
                        "Invalid chain hash {:?}",
                        chain_hash
                    ))));
                }

                // TODO: we may reject the channel opening request here
                // if the peer want to open a public channel, but we don't want to.
                if public && (channel_announcement_nonce.is_none() || public_channel_info.is_none())
                {
                    return Err(Box::new(ProcessingChannelError::InvalidParameter(
                        "Public channel should have channel announcement nonce and public channel info".to_string(),
                    )));
                }

                let mut state = ChannelActorState::new_inbound_channel(
                    *channel_id,
                    public_channel_info,
                    local_funding_amount,
                    local_reserved_ckb_amount,
                    *commitment_fee_rate,
                    *commitment_delay_epoch,
                    *funding_fee_rate,
                    funding_udt_type_script.clone(),
                    &seed,
                    self.get_local_pubkey(),
                    self.get_remote_pubkey(),
                    local_shutdown_script.clone(),
                    shutdown_script.clone(),
                    *funding_amount,
                    *reserved_ckb_amount,
                    counterpart_pubkeys,
                    next_local_nonce.clone(),
                    channel_announcement_nonce.clone(),
                    *first_per_commitment_point,
                    *second_per_commitment_point,
                    *remote_max_tlc_value_in_flight,
                    *remote_max_tlc_number_in_flight,
                    max_tlc_number_in_flight,
                    max_tlc_value_in_flight,
                    tlc_info,
                );
                state.check_accept_channel_parameters()?;

                let commitment_number = INITIAL_COMMITMENT_NUMBER;

                let channel_announcement_nonce = if public {
                    Some(state.get_channel_announcement_musig2_pubnonce())
                } else {
                    None
                };
                let accept_channel = AcceptChannel {
                    channel_id: *channel_id,
                    funding_amount: local_funding_amount,
                    shutdown_script: local_shutdown_script,
                    reserved_ckb_amount: local_reserved_ckb_amount,
                    max_tlc_value_in_flight,
                    max_tlc_number_in_flight,
                    funding_pubkey: state.signer.funding_key.pubkey(),
                    tlc_basepoint: state.signer.tlc_base_key.pubkey(),
                    first_per_commitment_point: state
                        .signer
                        .get_commitment_point(commitment_number),
                    second_per_commitment_point: state
                        .signer
                        .get_commitment_point(commitment_number + 1),
                    channel_announcement_nonce,
                    next_local_nonce: state.get_local_musig2_pubnonce(),
                };

                let command = FiberMessageWithPeerId::new(
                    peer_id,
                    FiberMessage::accept_channel(accept_channel),
                );
                // TODO: maybe we should not use try_send here.
                self.network
                    .send_message(NetworkActorMessage::new_command(
                        NetworkActorCommand::SendFiberMessage(command),
                    ))
                    .expect(ASSUME_NETWORK_ACTOR_ALIVE);

                state.update_state(ChannelState::NegotiatingFunding(
                    NegotiatingFundingFlags::INIT_SENT,
                ));
                if let Some(sender) = channel_id_sender {
                    sender.send(state.get_id()).expect("Receive not dropped");
                }
                Ok(state)
            }
            ChannelInitializationParameter::OpenChannel(OpenChannelParameter {
                funding_amount,
                seed,
                tlc_info,
                public_channel_info,
                funding_udt_type_script,
                shutdown_script,
                channel_id_sender,
                commitment_fee_rate,
                commitment_delay_epoch,
                funding_fee_rate,
                max_tlc_number_in_flight,
                max_tlc_value_in_flight,
            }) => {
                let public = public_channel_info.is_some();
                let peer_id = self.get_remote_peer_id();
                info!("Trying to open a channel to {:?}", &peer_id);

                let commitment_fee_rate =
                    commitment_fee_rate.unwrap_or(DEFAULT_COMMITMENT_FEE_RATE);
                let funding_fee_rate = funding_fee_rate.unwrap_or(DEFAULT_FEE_RATE);

                let (to_local_amount, reserved_ckb_amount) = get_funding_and_reserved_amount(
                    funding_amount,
                    &shutdown_script,
                    &funding_udt_type_script,
                )?;

                let mut channel = ChannelActorState::new_outbound_channel(
                    public_channel_info,
                    &seed,
                    self.get_local_pubkey(),
                    self.get_remote_pubkey(),
                    to_local_amount,
                    reserved_ckb_amount,
                    commitment_fee_rate,
                    commitment_delay_epoch
                        .unwrap_or(EpochNumberWithFraction::new(
                            DEFAULT_COMMITMENT_DELAY_EPOCHS,
                            0,
                            1,
                        ))
                        .full_value(),
                    funding_fee_rate,
                    funding_udt_type_script.clone(),
                    shutdown_script.clone(),
                    max_tlc_value_in_flight,
                    max_tlc_number_in_flight,
                    tlc_info,
                );

                channel.check_open_channel_parameters()?;

                let channel_flags = if public {
                    ChannelFlags::PUBLIC
                } else {
                    ChannelFlags::empty()
                };
                let channel_announcement_nonce = if public {
                    Some(channel.get_channel_announcement_musig2_pubnonce())
                } else {
                    None
                };
                let commitment_number = INITIAL_COMMITMENT_NUMBER;
                let message = FiberMessage::ChannelInitialization(OpenChannel {
                    chain_hash: get_chain_hash(),
                    channel_id: channel.get_id(),
                    funding_udt_type_script,
                    funding_amount: channel.to_local_amount,
                    shutdown_script,
                    reserved_ckb_amount: channel.local_reserved_ckb_amount,
                    funding_fee_rate,
                    commitment_fee_rate,
                    commitment_delay_epoch: channel.commitment_delay_epoch,
                    max_tlc_value_in_flight: channel.local_constraints.max_tlc_value_in_flight,
                    max_tlc_number_in_flight: channel.local_constraints.max_tlc_number_in_flight,
                    channel_flags,
                    first_per_commitment_point: channel
                        .signer
                        .get_commitment_point(commitment_number),
                    second_per_commitment_point: channel
                        .signer
                        .get_commitment_point(commitment_number + 1),
                    funding_pubkey: channel.get_local_channel_public_keys().funding_pubkey,
                    tlc_basepoint: channel.get_local_channel_public_keys().tlc_base_key,
                    next_local_nonce: channel.get_local_musig2_pubnonce(),
                    channel_announcement_nonce,
                });

                debug!(
                    "Created OpenChannel message to {:?}: {:?}",
                    &peer_id, &message
                );
                self.network
                    .send_message(NetworkActorMessage::new_command(
                        NetworkActorCommand::SendFiberMessage(FiberMessageWithPeerId {
                            peer_id: peer_id.clone(),
                            message,
                        }),
                    ))
                    .expect(ASSUME_NETWORK_ACTOR_ALIVE);
                // TODO: note that we can't actually guarantee that this OpenChannel message is sent here.
                // It is even possible that the peer_id is bogus, and we can't send a message to it.
                // We need some book-keeping service to remove all the OUR_INIT_SENT channels.
                channel.update_state(ChannelState::NegotiatingFunding(
                    NegotiatingFundingFlags::OUR_INIT_SENT,
                ));
                debug!(
                    "Channel to peer {:?} with id {:?} created",
                    &peer_id,
                    &channel.get_id()
                );

                channel_id_sender
                    .send(channel.get_id())
                    .expect("Receive not dropped");
                Ok(channel)
            }
            ChannelInitializationParameter::ReestablishChannel(channel_id) => {
                let mut channel = self
                    .store
                    .get_channel_actor_state(&channel_id)
                    .expect("channel should exist");
                channel.reestablishing = true;

                let reestablish_channel = ReestablishChannel {
                    channel_id,
                    local_commitment_number: channel.get_current_commitment_number(true),
                    remote_commitment_number: channel.get_current_commitment_number(false),
                };

                self.network
                    .send_message(NetworkActorMessage::new_command(
                        NetworkActorCommand::SendFiberMessage(FiberMessageWithPeerId::new(
                            self.get_remote_peer_id(),
                            FiberMessage::reestablish_channel(reestablish_channel),
                        )),
                    ))
                    .expect(ASSUME_NETWORK_ACTOR_ALIVE);

                // If the channel is already ready, we should notify the network actor.
                // so that we update the network.outpoint_channel_map
                if matches!(channel.state, ChannelState::ChannelReady()) {
                    self.network
                        .send_message(NetworkActorMessage::new_event(
                            NetworkActorEvent::ChannelReady(
                                channel.get_id(),
                                channel.get_remote_peer_id(),
                                channel.must_get_funding_transaction_outpoint(),
                            ),
                        ))
                        .expect(ASSUME_NETWORK_ACTOR_ALIVE);
                }
                Ok(channel)
            }
        }
    }

    async fn handle(
        &self,
        myself: ActorRef<Self::Msg>,
        message: Self::Msg,
        state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        trace!(
            "Channel actor processing message: id: {:?}, state: {:?}, message: {:?}",
            &state.get_id(),
            &state.state,
            message,
        );

        match message {
            ChannelActorMessage::PeerMessage(message) => {
                if let Err(error) = self
                    .handle_peer_message(&myself, state, message.clone())
                    .await
                {
                    error!(
                        "{:?} Error while processing channel message: {:?} with message: {:?}",
                        state.get_local_peer_id(),
                        error,
                        message
                    );
                    debug_event!(&self.network, &format!("{:?}", error));
                }
            }
            ChannelActorMessage::Command(command) => {
                if let Err(err) = self.handle_command(&myself, state, command).await {
                    error!(
                        "{:?} Error while processing channel command: {:?}",
                        state.get_local_peer_id(),
                        err
                    );
                }
            }
            ChannelActorMessage::Event(e) => {
                if let Err(err) = self.handle_event(&myself, state, e).await {
                    error!("Error while processing channel event: {:?}", err);
                }
            }
        }

        self.store.insert_channel_actor_state(state.clone());
        Ok(())
    }

    async fn post_start(
        &self,
        myself: ActorRef<Self::Msg>,
        state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        if state.tlc_state.has_pending_operations() {
            myself
                .send_message(ChannelActorMessage::Event(
                    ChannelEvent::CheckTlcRetryOperation,
                ))
                .expect("myself alive");
        }

        Ok(())
    }

    async fn post_stop(
        &self,
        _myself: ActorRef<Self::Msg>,
        state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        if let Some(outpoint) = state.get_funding_transaction_outpoint() {
            self.network
                .send_message(NetworkActorMessage::new_event(
                    NetworkActorEvent::OwnedChannelUpdateEvent(
                        super::graph::OwnedChannelUpdateEvent::Down(outpoint),
                    ),
                ))
                .expect(ASSUME_NETWORK_ACTOR_ALIVE);
        }
        Ok(())
    }
}

#[derive(Copy, Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
pub struct CommitmentNumbers {
    pub local: u64,
    pub remote: u64,
}

impl Default for CommitmentNumbers {
    fn default() -> Self {
        Self::new()
    }
}

impl CommitmentNumbers {
    pub fn new() -> Self {
        Self {
            local: INITIAL_COMMITMENT_NUMBER,
            remote: INITIAL_COMMITMENT_NUMBER,
        }
    }

    pub fn get_local(&self) -> u64 {
        self.local
    }

    pub fn get_remote(&self) -> u64 {
        self.remote
    }

    pub fn increment_local(&mut self) {
        self.local += 1;
    }

    pub fn increment_remote(&mut self) {
        self.remote += 1;
    }

    pub fn flip(&self) -> Self {
        Self {
            local: self.remote,
            remote: self.local,
        }
    }
}

#[derive(Copy, Clone, Debug, PartialEq, Eq, Serialize, Deserialize, PartialOrd, Ord, Hash)]
pub enum TLCId {
    Offered(u64),
    Received(u64),
}

impl From<TLCId> for u64 {
    fn from(id: TLCId) -> u64 {
        match id {
            TLCId::Offered(id) => id,
            TLCId::Received(id) => id,
        }
    }
}

impl TLCId {
    pub fn is_offered(&self) -> bool {
        matches!(self, TLCId::Offered(_))
    }

    pub fn is_received(&self) -> bool {
        !self.is_offered()
    }

    pub fn flip(&self) -> Self {
        match self {
            TLCId::Offered(id) => TLCId::Received(*id),
            TLCId::Received(id) => TLCId::Offered(*id),
        }
    }

    pub fn flip_mut(&mut self) {
        *self = self.flip();
    }
}

#[derive(Debug, Clone, Serialize, Deserialize, Eq, PartialEq)]
pub enum OutboundTlcStatus {
    // Offered tlc created and sent to remote party
    LocalAnnounced,
    // Received ACK from remote party for this offered tlc
    Committed,
    // Remote party removed this tlc
    RemoteRemoved,
    // We received another RemoveTlc message from peer when we are waiting for the ack of the last one.
    // So we need another ACK to confirm the removal.
    RemoveWaitPrevAck,
    // We have sent commitment signed to peer and waiting ACK for confirming this RemoveTlc
    RemoveWaitAck,
    // We have received the ACK for the RemoveTlc, it's safe to remove this tlc
    RemoveAckConfirmed,
}

#[derive(Debug, Clone, Serialize, Deserialize, Eq, PartialEq)]
pub enum InboundTlcStatus {
    // Received tlc from remote party, but not committed yet
    RemoteAnnounced,
    // We received another AddTlc peer message when we are waiting for the ack of the last one.
    // So we need another ACK to confirm the addition.
    AnnounceWaitPrevAck,
    // We have sent commitment signed to peer and waiting ACK for confirming this AddTlc
    AnnounceWaitAck,
    // We have received ACK from peer and Committed this tlc
    Committed,
    // We have removed this tlc, but haven't received ACK from peer
    LocalRemoved,
    // We have received the ACK for the RemoveTlc, it's safe to remove this tlc
    RemoveAckConfirmed,
}

#[derive(Debug, Clone, Serialize, Deserialize, Eq, PartialEq)]
pub enum TlcStatus {
    Outbound(OutboundTlcStatus),
    Inbound(InboundTlcStatus),
}

impl TlcStatus {
    pub fn as_outbound_status(&self) -> OutboundTlcStatus {
        match self {
            TlcStatus::Outbound(status) => status.clone(),
            _ => {
                unreachable!("unexpected status")
            }
        }
    }

    pub fn as_inbound_status(&self) -> InboundTlcStatus {
        match self {
            TlcStatus::Inbound(status) => status.clone(),
            _ => {
                unreachable!("unexpected status ")
            }
        }
    }
}

#[derive(Clone, Serialize, Deserialize, Eq, PartialEq)]
pub struct TlcInfo {
    pub channel_id: Hash256,
    pub status: TlcStatus,
    pub tlc_id: TLCId,
    pub amount: u128,
    pub payment_hash: Hash256,
    pub expiry: u64,
    pub hash_algorithm: HashAlgorithm,
    // the onion packet for multi-hop payment
    pub onion_packet: Option<PaymentOnionPacket>,
    /// Shared secret used in forwarding.
    ///
    /// Save it to backward errors. Use all zeros when no shared secrets are available.
    pub shared_secret: [u8; 32],
    pub created_at: CommitmentNumbers,
    pub removed_reason: Option<RemoveTlcReason>,

    /// Note: `previous_tlc` is used to track the tlc chain for a multi-tlc payment,
    ///       we need to know previous when removing tlc backwardly.
    ///
    /// Node A ---------> Node B ------------> Node C ----------> Node D
    ///  tlc_1 <---> (tlc_1) (tlc_2) <---> (tlc_2) (tlc_3) <----> tlc_3
    ///                ^^^^                 ^^^^
    ///
    pub previous_tlc: Option<(Hash256, TLCId)>,
    pub removed_confirmed_at: Option<u64>,
}

// When we are forwarding a TLC, we need to know the previous TLC information.
// This struct keeps the information of the previous TLC.
#[derive(Debug, Copy, Clone)]
pub struct PrevTlcInfo {
    pub(crate) prev_channel_id: Hash256,
    // The TLC is always a received TLC because we are forwarding it.
    pub(crate) prev_tlc_id: u64,
    pub(crate) forwarding_fee: u128,
}

impl PrevTlcInfo {
    pub fn new(prev_channel_id: Hash256, prev_tlc_id: u64, forwarding_fee: u128) -> Self {
        Self {
            prev_channel_id,
            prev_tlc_id,
            forwarding_fee,
        }
    }
}

impl Debug for TlcInfo {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.debug_struct("TlcInfo")
            .field("tlc_id", &self.tlc_id)
            .field("status", &self.status)
            .field("amount", &self.amount)
            .field("removed_reason", &self.removed_reason)
            .field("payment_hash", &self.payment_hash)
            .field("removed_confirmed_at", &self.removed_confirmed_at)
            .finish()
    }
}

impl TlcInfo {
    pub fn log(&self) -> String {
        format!(
            "id: {:?} status: {:?} amount: {:?}",
            &self.tlc_id, self.status, self.amount
        )
    }

    pub fn is_offered(&self) -> bool {
        self.tlc_id.is_offered()
    }

    pub fn is_received(&self) -> bool {
        !self.is_offered()
    }

    pub fn get_commitment_numbers(&self) -> CommitmentNumbers {
        self.created_at
    }

    pub fn flip_mut(&mut self) {
        self.tlc_id.flip_mut();
    }

    pub fn outbound_status(&self) -> OutboundTlcStatus {
        self.status.as_outbound_status()
    }

    pub fn inbound_status(&self) -> InboundTlcStatus {
        self.status.as_inbound_status()
    }

    pub fn is_fail_remove_confirmed(&self) -> bool {
        matches!(self.removed_reason, Some(RemoveTlcReason::RemoveTlcFail(_)))
            && matches!(
                self.status,
                TlcStatus::Outbound(OutboundTlcStatus::RemoveAckConfirmed)
                    | TlcStatus::Outbound(OutboundTlcStatus::RemoveWaitAck)
                    | TlcStatus::Inbound(InboundTlcStatus::RemoveAckConfirmed)
            )
    }

    fn get_hash(&self) -> ShortHash {
        self.payment_hash.as_ref()[..20]
            .try_into()
            .expect("short hash from payment hash")
    }

    /// Get the value for the field `htlc_type` in commitment lock witness.
    /// - Lowest 1 bit: 0 if the tlc is offered by the remote party, 1 otherwise.
    /// - High 7 bits:
    ///     - 0: ckb hash
    ///     - 1: sha256
    pub fn get_htlc_type(&self) -> u8 {
        let offered_flag = if self.is_offered() { 0u8 } else { 1u8 };
        ((self.hash_algorithm as u8) << 1) + offered_flag
    }
}

impl From<TlcInfo> for TlcNotifyInfo {
    fn from(tlc: TlcInfo) -> Self {
        TlcNotifyInfo {
            tlc_id: tlc.tlc_id,
            amount: tlc.amount,
            payment_hash: tlc.payment_hash,
            payment_preimage: None,
        }
    }
}

#[derive(Clone, Serialize, Deserialize, Eq, PartialEq)]
pub enum RetryableTlcOperation {
    RemoveTlc(TLCId, RemoveTlcReason),
    RelayRemoveTlc(Hash256, u64, RemoveTlcReason),
    ForwardTlc(Hash256, TLCId, PeeledPaymentOnionPacket, u128, bool),
}

impl Debug for RetryableTlcOperation {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            RetryableTlcOperation::RemoveTlc(tlc_id, reason) => f
                .debug_tuple("RemoveTlc")
                .field(tlc_id)
                .field(reason)
                .finish(),
            RetryableTlcOperation::RelayRemoveTlc(payment_hash, tlc_id, reason) => f
                .debug_tuple("RelayRemoveTlc")
                .field(payment_hash)
                .field(tlc_id)
                .field(reason)
                .finish(),
            RetryableTlcOperation::ForwardTlc(payment_hash, tlc_id, _, forward_fee, run_once) => f
                .debug_tuple("ForwardTlc")
                .field(payment_hash)
                .field(tlc_id)
                .field(forward_fee)
                .field(run_once)
                .finish(),
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize, Eq, PartialEq, Default)]
pub struct PendingTlcs {
    pub tlcs: Vec<TlcInfo>,
    pub next_tlc_id: u64,
}

impl PendingTlcs {
    pub fn iter_mut(&mut self) -> impl Iterator<Item = &mut TlcInfo> {
        self.tlcs.iter_mut()
    }

    pub fn get_next_id(&self) -> u64 {
        self.next_tlc_id
    }

    pub fn increment_next_id(&mut self) {
        self.next_tlc_id += 1;
    }

    pub fn add_tlc(&mut self, tlc: TlcInfo) {
        self.tlcs.push(tlc);
    }

    pub fn get_committed_tlcs(&self) -> Vec<TlcInfo> {
        self.tlcs
            .iter()
            .filter(|tlc| {
                if tlc.is_offered() {
                    matches!(tlc.outbound_status(), OutboundTlcStatus::Committed)
                } else {
                    matches!(tlc.inbound_status(), InboundTlcStatus::Committed)
                }
            })
            .cloned()
            .collect()
    }

    pub fn get_oldest_failed_tlcs(&self) -> Vec<TLCId> {
        let mut failed_tlcs = self
            .tlcs
            .iter()
            .filter_map(|tlc| {
                if tlc.is_fail_remove_confirmed() {
                    Some((tlc.tlc_id, tlc.removed_confirmed_at.unwrap_or(u64::MAX)))
                } else {
                    None
                }
            })
            .collect::<Vec<_>>();

        if failed_tlcs.len() > 1 {
            failed_tlcs.sort_by_key(|a| a.1);
            failed_tlcs
                .iter()
                .take(failed_tlcs.len() - 1)
                .map(|(tlc_id, _)| *tlc_id)
                .collect()
        } else {
            return Vec::new();
        }
    }
}

#[derive(Default, Clone, Debug, Serialize, Deserialize)]
pub struct TlcState {
    pub offered_tlcs: PendingTlcs,
    pub received_tlcs: PendingTlcs,
    pub retryable_tlc_operations: Vec<RetryableTlcOperation>,
    pub applied_add_tlcs: HashSet<TLCId>,
    pub applied_remove_tlcs: HashSet<TLCId>,
    pub waiting_ack: bool,
}

impl TlcState {
    #[cfg(debug_assertions)]
    pub fn debug(&self) {
        for tlc in self.offered_tlcs.tlcs.iter() {
            debug!("offered_tlc: {:?}", tlc.log());
        }
        for tlc in self.received_tlcs.tlcs.iter() {
            debug!("received_tlc: {:?}", tlc.log());
        }
    }

    pub fn get_mut(&mut self, tlc_id: &TLCId) -> Option<&mut TlcInfo> {
        self.offered_tlcs
            .tlcs
            .iter_mut()
            .find(|tlc| tlc.tlc_id == *tlc_id)
            .or_else(|| {
                self.received_tlcs
                    .tlcs
                    .iter_mut()
                    .find(|tlc| tlc.tlc_id == *tlc_id)
            })
    }

    pub fn get(&self, tlc_id: &TLCId) -> Option<&TlcInfo> {
        if tlc_id.is_offered() {
            self.offered_tlcs
                .tlcs
                .iter()
                .find(|tlc| tlc.tlc_id == *tlc_id)
        } else {
            self.received_tlcs
                .tlcs
                .iter()
                .find(|tlc| tlc.tlc_id == *tlc_id)
        }
    }

    pub fn get_committed_received_tlcs(&self) -> Vec<TlcInfo> {
        self.received_tlcs.get_committed_tlcs()
    }

    pub fn get_next_offering(&self) -> u64 {
        self.offered_tlcs.get_next_id()
    }

    pub fn get_next_received(&self) -> u64 {
        self.received_tlcs.get_next_id()
    }

    pub fn increment_offering(&mut self) {
        self.offered_tlcs.increment_next_id();
    }

    pub fn increment_received(&mut self) {
        self.received_tlcs.increment_next_id();
    }

    pub fn set_waiting_ack(&mut self, waiting_ack: bool) {
        self.waiting_ack = waiting_ack;
    }

    pub fn insert_retryable_tlc_operation(&mut self, operation: RetryableTlcOperation) -> bool {
        if self.retryable_tlc_operations.contains(&operation) {
            return false;
        }
        self.retryable_tlc_operations.push(operation);
        true
    }

    pub fn all_tlcs(&self) -> impl Iterator<Item = &TlcInfo> + '_ {
        self.offered_tlcs
            .tlcs
            .iter()
            .chain(self.received_tlcs.tlcs.iter())
    }

    pub fn all_commited_tlcs(&self) -> impl Iterator<Item = &TlcInfo> + '_ {
        self.offered_tlcs
            .tlcs
            .iter()
            .chain(self.received_tlcs.tlcs.iter())
            .filter(|tlc| {
                if tlc.is_offered() {
                    matches!(tlc.outbound_status(), OutboundTlcStatus::Committed)
                } else {
                    matches!(tlc.inbound_status(), InboundTlcStatus::Committed)
                }
            })
    }

    pub fn apply_remove_tlc(&mut self, tlc_id: TLCId) {
        self.applied_add_tlcs.remove(&tlc_id);
        self.applied_remove_tlcs.remove(&tlc_id);
        if tlc_id.is_offered() {
            self.offered_tlcs.tlcs.retain(|tlc| tlc.tlc_id != tlc_id);
        } else {
            self.received_tlcs.tlcs.retain(|tlc| tlc.tlc_id != tlc_id);
        }
    }

    pub fn get_pending_operations(&self) -> Vec<RetryableTlcOperation> {
        self.retryable_tlc_operations.clone()
    }

    pub fn has_pending_operations(&self) -> bool {
        !self.retryable_tlc_operations.is_empty()
    }

    pub fn remove_pending_tlc_operation(&mut self, retryable_tlc_op: &RetryableTlcOperation) {
        self.retryable_tlc_operations
            .retain(|op| op != retryable_tlc_op);

        // if we already finished the RemoveTlc operation for the tlc,
        // we should also remove the ForwardTlc to avoid any later retry.
        if let RetryableTlcOperation::RemoveTlc(tlc_id, _) = retryable_tlc_op {
            self.retryable_tlc_operations.retain(|op| match op {
                RetryableTlcOperation::ForwardTlc(_, id, ..) => id != tlc_id,
                _ => true,
            });
        }
    }

    pub fn add_offered_tlc(&mut self, tlc: TlcInfo) {
        self.offered_tlcs.add_tlc(tlc);
    }

    pub fn add_received_tlc(&mut self, tlc: TlcInfo) {
        self.received_tlcs.add_tlc(tlc);
    }

    pub fn set_received_tlc_removed(&mut self, tlc_id: u64, reason: RemoveTlcReason) {
        if let Some(tlc) = self.get_mut(&TLCId::Received(tlc_id)) {
            assert_eq!(tlc.inbound_status(), InboundTlcStatus::Committed);
            tlc.removed_reason = Some(reason);
            tlc.status = TlcStatus::Inbound(InboundTlcStatus::LocalRemoved);
        }
    }

    pub fn set_offered_tlc_removed(&mut self, tlc_id: u64, reason: RemoveTlcReason) -> Hash256 {
        let tlc = self.get_mut(&TLCId::Offered(tlc_id)).expect("get tlc");
        assert_eq!(tlc.outbound_status(), OutboundTlcStatus::Committed);
        tlc.removed_reason = Some(reason);
        tlc.status = TlcStatus::Outbound(OutboundTlcStatus::RemoteRemoved);
        tlc.payment_hash
    }

    pub fn commitment_signed_tlcs(&self, for_remote: bool) -> impl Iterator<Item = &TlcInfo> + '_ {
        self.offered_tlcs
            .tlcs
            .iter()
            .filter(move |tlc| match tlc.outbound_status() {
                OutboundTlcStatus::LocalAnnounced => for_remote,
                OutboundTlcStatus::Committed => true,
                OutboundTlcStatus::RemoteRemoved => for_remote,
                OutboundTlcStatus::RemoveWaitPrevAck => for_remote,
                OutboundTlcStatus::RemoveWaitAck => false,
                OutboundTlcStatus::RemoveAckConfirmed => false,
            })
            .chain(
                self.received_tlcs
                    .tlcs
                    .iter()
                    .filter(move |tlc| match tlc.inbound_status() {
                        InboundTlcStatus::RemoteAnnounced => !for_remote,
                        InboundTlcStatus::AnnounceWaitPrevAck => !for_remote,
                        InboundTlcStatus::AnnounceWaitAck => true,
                        InboundTlcStatus::Committed => true,
                        InboundTlcStatus::LocalRemoved => !for_remote,
                        InboundTlcStatus::RemoveAckConfirmed => false,
                    }),
            )
    }

    pub fn update_for_commitment_signed(&mut self) -> bool {
        for tlc in self.offered_tlcs.tlcs.iter_mut() {
            if tlc.outbound_status() == OutboundTlcStatus::RemoteRemoved {
                let status = if self.waiting_ack {
                    OutboundTlcStatus::RemoveWaitPrevAck
                } else {
                    OutboundTlcStatus::RemoveWaitAck
                };
                tlc.status = TlcStatus::Outbound(status);
            }
        }
        for tlc in self.received_tlcs.tlcs.iter_mut() {
            if tlc.inbound_status() == InboundTlcStatus::RemoteAnnounced {
                let status = if self.waiting_ack {
                    InboundTlcStatus::AnnounceWaitPrevAck
                } else {
                    InboundTlcStatus::AnnounceWaitAck
                };
                tlc.status = TlcStatus::Inbound(status)
            }
        }
        self.need_another_commitment_signed()
    }

    pub fn update_for_revoke_and_ack(&mut self, commitment_number: CommitmentNumbers) -> bool {
        self.set_waiting_ack(false);
        for tlc in self.offered_tlcs.tlcs.iter_mut() {
            match tlc.outbound_status() {
                OutboundTlcStatus::LocalAnnounced => {
                    tlc.status = TlcStatus::Outbound(OutboundTlcStatus::Committed);
                }
                OutboundTlcStatus::RemoveWaitPrevAck => {
                    tlc.status = TlcStatus::Outbound(OutboundTlcStatus::RemoveWaitAck);
                }
                OutboundTlcStatus::RemoveWaitAck => {
                    tlc.status = TlcStatus::Outbound(OutboundTlcStatus::RemoveAckConfirmed);
                    tlc.removed_confirmed_at = Some(commitment_number.get_local());
                }
                _ => {}
            }
        }

        for tlc in self.received_tlcs.tlcs.iter_mut() {
            match tlc.inbound_status() {
                InboundTlcStatus::AnnounceWaitPrevAck => {
                    tlc.status = TlcStatus::Inbound(InboundTlcStatus::AnnounceWaitAck);
                }
                InboundTlcStatus::AnnounceWaitAck => {
                    tlc.status = TlcStatus::Inbound(InboundTlcStatus::Committed);
                }
                InboundTlcStatus::LocalRemoved => {
                    tlc.status = TlcStatus::Inbound(InboundTlcStatus::RemoveAckConfirmed);
                    tlc.removed_confirmed_at = Some(commitment_number.get_remote());
                }
                _ => {}
            }
        }
        self.need_another_commitment_signed()
    }

    pub fn need_another_commitment_signed(&self) -> bool {
        self.offered_tlcs.tlcs.iter().any(|tlc| {
            let status = tlc.outbound_status();
            matches!(
                status,
                OutboundTlcStatus::LocalAnnounced
                    | OutboundTlcStatus::RemoteRemoved
                    | OutboundTlcStatus::RemoveWaitPrevAck
                    | OutboundTlcStatus::RemoveWaitAck
            )
        }) || self.received_tlcs.tlcs.iter().any(|tlc| {
            let status = tlc.inbound_status();
            matches!(
                status,
                InboundTlcStatus::RemoteAnnounced
                    | InboundTlcStatus::AnnounceWaitPrevAck
                    | InboundTlcStatus::AnnounceWaitAck
            )
        })
    }
}

#[derive(Debug, Clone, Serialize, Deserialize, Eq, PartialEq, Default)]
pub struct ChannelConstraints {
    // The maximum value can be in pending
    pub max_tlc_value_in_flight: u128,
    // The maximum number of tlcs that we can accept.
    pub max_tlc_number_in_flight: u64,
}

impl ChannelConstraints {
    pub fn new(max_tlc_value_in_flight: u128, max_tlc_number_in_flight: u64) -> Self {
        Self {
            max_tlc_value_in_flight,
            max_tlc_number_in_flight,
        }
    }
}

#[serde_as]
#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]
pub struct RevocationData {
    pub commitment_number: u64,
    pub x_only_aggregated_pubkey: [u8; 32],
    #[serde_as(as = "CompactSignatureAsBytes")]
    pub aggregated_signature: CompactSignature,
    #[serde_as(as = "EntityHex")]
    pub output: CellOutput,
    #[serde_as(as = "EntityHex")]
    pub output_data: Bytes,
}

#[serde_as]
#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]
pub struct SettlementData {
    pub x_only_aggregated_pubkey: [u8; 32],
    #[serde_as(as = "CompactSignatureAsBytes")]
    pub aggregated_signature: CompactSignature,
    #[serde_as(as = "EntityHex")]
    pub to_local_output: CellOutput,
    #[serde_as(as = "EntityHex")]
    pub to_local_output_data: Bytes,
    #[serde_as(as = "EntityHex")]
    pub to_remote_output: CellOutput,
    #[serde_as(as = "EntityHex")]
    pub to_remote_output_data: Bytes,
}

#[serde_as]
#[derive(Clone, Serialize, Deserialize)]
pub struct ChannelActorState {
    pub state: ChannelState,
    // The data below are only relevant if the channel is public.
    pub public_channel_info: Option<PublicChannelInfo>,

    pub local_tlc_info: ChannelTlcInfo,
    pub remote_tlc_info: Option<ChannelTlcInfo>,

    // The local public key used to establish p2p network connection.
    pub local_pubkey: Pubkey,
    // The remote public key used to establish p2p network connection.
    pub remote_pubkey: Pubkey,

    pub id: Hash256,
    #[serde_as(as = "Option<EntityHex>")]
    pub funding_tx: Option<Transaction>,

    pub funding_tx_confirmed_at: Option<(H256, u32, u64)>,

    #[serde_as(as = "Option<EntityHex>")]
    pub funding_udt_type_script: Option<Script>,

    // Is this channel initially inbound?
    // An inbound channel is one where the counterparty is the funder of the channel.
    pub is_acceptor: bool,

    // TODO: consider transaction fee while building the commitment transaction.
    // The invariant here is that the sum of `to_local_amount` and `to_remote_amount`
    // should be equal to the total amount of the channel.
    // The changes of both `to_local_amount` and `to_remote_amount`
    // will always happen after a revoke_and_ack message is sent/received.
    // This means that while calculating the amounts for commitment transactions,
    // processing add_tlc command and messages, we need to take into account that
    // the amounts are not decremented/incremented yet.

    // The amount of CKB/UDT that we own in the channel.
    // This value will only change after we have resolved a tlc.
    pub to_local_amount: u128,
    // The amount of CKB/UDT that the remote owns in the channel.
    // This value will only change after we have resolved a tlc.
    pub to_remote_amount: u128,

    // these two amounts used to keep the minimal ckb amount for the two parties
    // TLC operations will not affect these two amounts, only used to keep the commitment transactions
    // to be valid, so that any party can close the channel at any time.
    // Note: the values are different for the UDT scenario
    pub local_reserved_ckb_amount: u64,
    pub remote_reserved_ckb_amount: u64,

    // The commitment fee rate is used to calculate the fee for the commitment transactions.
    // The side who want to submit the commitment transaction will pay fee
    pub commitment_fee_rate: u64,

    // The delay time for the commitment transaction, this value is set by the initiator of the channel.
    // It must be a relative EpochNumberWithFraction in u64 format.
    pub commitment_delay_epoch: u64,

    // The fee rate used for funding transaction, the initiator may set it as `funding_fee_rate` option,
    // if it's not set, DEFAULT_FEE_RATE will be used as default value, two sides will use the same fee rate
    pub funding_fee_rate: u64,

    // Signer is used to sign the commitment transactions.
    pub signer: InMemorySigner,

    // Cached channel public keys for easier of access.
    pub local_channel_public_keys: ChannelBasePublicKeys,

    // Commitment numbers that are used to derive keys.
    // This value is guaranteed to be 0 when channel is just created.
    pub commitment_numbers: CommitmentNumbers,

    pub local_constraints: ChannelConstraints,
    pub remote_constraints: ChannelConstraints,

    // Below are fields that are only usable after the channel is funded,
    // (or at some point of the state).

    // all the TLC related information
    pub tlc_state: TlcState,

    // The remote and local lock script for close channel, they are setup during the channel establishment.
    #[serde_as(as = "Option<EntityHex>")]
    pub remote_shutdown_script: Option<Script>,
    #[serde_as(as = "EntityHex")]
    pub local_shutdown_script: Script,

    // Basically the latest remote nonce sent by the peer with the CommitmentSigned message,
    // but we will only update this field after we have sent a RevokeAndAck to the peer.
    // With above guarantee, we can be sure the results of the sender obtaining its latest local nonce
    // and the receiver obtaining its latest remote nonce are the same.
    #[serde_as(as = "Option<PubNonceAsBytes>")]
    pub last_committed_remote_nonce: Option<PubNonce>,

    // While handling peer's CommitmentSigned message, we will build a RevokeAndAck message,
    // and reply this message to the peer. The nonce used to build the RevokeAndAck message is
    // an older one sent by the peer. We will read this nonce from the field `last_committed_remote_nonce`
    // The new nonce contained in the CommitmentSigned message
    // will be saved to `last_committed_remote_nonce` field when this process finishes successfully.
    // The problem is in some abnormal cases, the may not be able to successfully send the RevokeAndAck.
    // But we have overwritten the `last_committed_remote_nonce` field with the new nonce.
    // While reestablishing the channel, we need to use the old nonce to build the RevokeAndAck message.
    // This is why we need to save the old nonce in this field.
    #[serde_as(as = "Option<PubNonceAsBytes>")]
    pub last_commitment_signed_remote_nonce: Option<PubNonce>,

    // While building a CommitmentSigned message, we use the latest remote nonce (the `last_committed_remote_nonce` above)
    // to partially sign the commitment transaction. This nonce is also needed for the RevokeAndAck message
    // returned from the peer. We need to save this nonce because the counterparty may send other nonces during
    // the period when our CommitmentSigned is sent and the counterparty's RevokeAndAck is received.
    // This field is used to keep the nonce used by the unconfirmed CommitmentSigned. When we receive a
    // RevokeAndAck from the peer, we will use this nonce to validate the RevokeAndAck message.
    #[serde_as(as = "Option<PubNonceAsBytes>")]
    pub last_revoke_and_ack_remote_nonce: Option<PubNonce>,

    // The latest commitment transaction we're holding,
    // it can be broadcasted to blockchain by us to force close the channel.
    #[serde_as(as = "Option<EntityHex>")]
    pub latest_commitment_transaction: Option<Transaction>,

    // All the commitment point that are sent from the counterparty.
    // We need to save all these points to derive the keys for the commitment transactions.
    // The length of this vector is at most the maximum number of flighting tlcs.
    pub remote_commitment_points: Vec<(u64, Pubkey)>,
    pub remote_channel_public_keys: Option<ChannelBasePublicKeys>,

    // The shutdown info for both local and remote, they are setup by the shutdown command or message.
    pub local_shutdown_info: Option<ShutdownInfo>,
    pub remote_shutdown_info: Option<ShutdownInfo>,

    // A flag to indicate whether the channel is reestablishing, we won't process any messages until the channel is reestablished.
    pub reestablishing: bool,

    pub created_at: SystemTime,
}

#[serde_as]
#[derive(Clone, Serialize, Deserialize, Eq, PartialEq, Debug)]
pub struct ShutdownInfo {
    #[serde_as(as = "EntityHex")]
    pub close_script: Script,
    pub fee_rate: u64,
    pub signature: Option<PartialSignature>,
}

// This struct holds the TLC information for the channel participants.
// We can update this information through the channel update message.
#[serde_as]
#[derive(Default, Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
pub struct ChannelTlcInfo {
    // The timestamp when the following information is updated.
    pub timestamp: u64,

    // Whether this channel is enabled for TLC forwarding or not.
    pub enabled: bool,

    // The fee rate for tlc transfers. We only have these values set when
    // this is a public channel. Both sides may set this value differently.
    // This is a fee that is paid by the sender of the tlc.
    // The detailed calculation for the fee of forwarding tlcs is
    // `fee = round_above(tlc_fee_proportional_millionths * tlc_value / 1,000,000)`.
    pub tlc_fee_proportional_millionths: u128,

    // The expiry delta timestamp, in milliseconds, for the tlc.
    pub tlc_expiry_delta: u64,

    /// The minimal tcl value we can receive in relay tlc
    pub tlc_minimum_value: u128,

    /// The maximal tcl value we can receive in relay tlc
    pub tlc_maximum_value: u128,
}

impl ChannelTlcInfo {
    pub fn new(
        tlc_min_value: u128,
        tlc_expiry_delta: u64,
        tlc_fee_proportional_millionths: u128,
    ) -> Self {
        Self {
            tlc_minimum_value: tlc_min_value,
            tlc_expiry_delta,
            tlc_fee_proportional_millionths,
            enabled: true,
            timestamp: now_timestamp_as_millis_u64(),
            ..Default::default()
        }
    }
}

// This struct holds the channel information that are only relevant when the channel
// is public. The information includes signatures to the channel announcement message,
// our config for the channel that will be published to the network (via ChannelUpdate).
// For ChannelUpdate config, only information on our side are saved here because we have no
// control to the config on the counterparty side. And they will publish
// the config to the network via another ChannelUpdate message.
#[serde_as]
#[derive(Default, Clone, Debug, Serialize, Deserialize)]
pub struct PublicChannelInfo {
    // Channel announcement signatures, may be empty for private channel.
    pub local_channel_announcement_signature: Option<(EcdsaSignature, PartialSignature)>,
    pub remote_channel_announcement_signature: Option<(EcdsaSignature, PartialSignature)>,

    #[serde_as(as = "Option<PubNonceAsBytes>")]
    pub remote_channel_announcement_nonce: Option<PubNonce>,

    pub channel_announcement: Option<ChannelAnnouncement>,
    pub channel_update: Option<ChannelUpdate>,
}

impl PublicChannelInfo {
    pub fn new() -> Self {
        Default::default()
    }
}

#[derive(PartialEq, Eq, Clone, Debug)]
pub struct ClosedChannel {}

#[derive(Debug)]
pub enum ChannelEvent {
    PeerDisconnected,
    FundingTransactionConfirmed(H256, u32, u64),
    CommitmentTransactionConfirmed,
    ClosingTransactionConfirmed,
    CheckTlcRetryOperation,
}

pub type ProcessingChannelResult = Result<(), ProcessingChannelError>;

#[derive(Error, Debug, Clone)]
pub enum ProcessingChannelError {
    #[error("Invalid state: {0}")]
    InvalidState(String),
    #[error("Repeated processing message: {0}")]
    RepeatedProcessing(String),
    #[error("Invalid parameter: {0}")]
    InvalidParameter(String),
    #[error("Internal error: {0}")]
    InternalError(String),
    #[error("Capacity error: {0}")]
    CapacityError(#[from] CapacityError),
    #[error("Failed to spawn actor: {0}")]
    SpawnErr(String),
    #[error("Musig2 RoundFinalizeError: {0}")]
    Musig2RoundFinalizeError(#[from] RoundFinalizeError),
    #[error("Musig2 VerifyError: {0}")]
    Musig2VerifyError(#[from] VerifyError),
    #[error("Musig2 SigningError: {0}")]
    Musig2SigningError(#[from] SigningError),
    #[error("Unable to handle TLC command in waiting TLC ACK state")]
    WaitingTlcAck,
    #[error("Failed to peel onion packet: {0}")]
    PeelingOnionPacketError(String),
    #[error("Forwarding node has tampered with the intended HTLC values or origin node has an obsolete cltv_expiry_delta")]
    IncorrectTlcExpiry,
    #[error("Upstream node set CLTV to less than the CLTV set by the sender")]
    IncorrectFinalTlcExpiry,
    #[error("The amount in the HTLC is not expected")]
    FinalIncorrectHTLCAmount,
    #[error("The payment_hash is not expected for final hop")]
    FinalIncorrectPaymentHash,
    #[error("The payment_hash and preimage does not match for final hop")]
    FinalIncorrectPreimage,
    #[error("The tlc forward fee is tow low")]
    TlcForwardFeeIsTooLow,
    #[error("The invoice status is invalid")]
    FinalInvoiceInvalid(CkbInvoiceStatus),
    #[error("The tlc number exceed limit of this channel")]
    TlcNumberExceedLimit,
    #[error("The tlc flight value exceed limit of this channel")]
    TlcValueInflightExceedLimit,
    #[error("The tlc amount below minimal")]
    TlcAmountIsTooLow,
    #[error("The tlc amount exceed maximal")]
    TlcAmountExceedLimit,
    #[error("The tlc expiry soon")]
    TlcExpirySoon,
    #[error("The tlc expiry too far")]
    TlcExpiryTooFar,
    #[error("Tlc forwarding error")]
    TlcForwardingError(TlcErr),
}

/// ProcessingChannelError which brings the shared secret used in forwarding onion packet.
/// The shared secret is required to obfuscate the error message.
#[derive(Error, Debug)]
#[error("{source}")]
pub struct ProcessingChannelErrorWithSharedSecret {
    pub source: ProcessingChannelError,
    /// Shared secret used in forwarding.
    ///
    /// Save it to backward errors. Use all zeros when no shared secrets are available.
    pub shared_secret: [u8; 32],
}

impl ProcessingChannelError {
    pub fn with_shared_secret(
        self,
        shared_secret: [u8; 32],
    ) -> ProcessingChannelErrorWithSharedSecret {
        ProcessingChannelErrorWithSharedSecret {
            source: self,
            shared_secret,
        }
    }

    pub fn without_shared_secret(self) -> ProcessingChannelErrorWithSharedSecret {
        self.with_shared_secret(NO_SHARED_SECRET)
    }
}

bitflags! {
    #[derive(Copy, Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
    #[serde(transparent)]
    pub struct ChannelFlags: u8 {
        const PUBLIC = 1;
    }

    #[derive(Copy, Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
    #[serde(transparent)]
    pub struct NegotiatingFundingFlags: u32 {
        const OUR_INIT_SENT = 1;
        const THEIR_INIT_SENT = 1 << 1;
        const INIT_SENT = NegotiatingFundingFlags::OUR_INIT_SENT.bits() | NegotiatingFundingFlags::THEIR_INIT_SENT.bits();
    }

    #[derive(Copy, Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
    #[serde(transparent)]
    pub struct CollaboratingFundingTxFlags: u32 {
        const AWAITING_REMOTE_TX_COLLABORATION_MSG = 1;
        const PREPARING_LOCAL_TX_COLLABORATION_MSG = 1 << 1;
        const OUR_TX_COMPLETE_SENT = 1 << 2;
        const THEIR_TX_COMPLETE_SENT = 1 << 3;
        const COLLABRATION_COMPLETED = CollaboratingFundingTxFlags::OUR_TX_COMPLETE_SENT.bits() | CollaboratingFundingTxFlags::THEIR_TX_COMPLETE_SENT.bits();
    }

    #[derive(Copy, Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
    #[serde(transparent)]
    pub struct SigningCommitmentFlags: u32 {
        const OUR_COMMITMENT_SIGNED_SENT = 1;
        const THEIR_COMMITMENT_SIGNED_SENT = 1 << 1;
        const COMMITMENT_SIGNED_SENT = SigningCommitmentFlags::OUR_COMMITMENT_SIGNED_SENT.bits() | SigningCommitmentFlags::THEIR_COMMITMENT_SIGNED_SENT.bits();
    }

    #[derive(Copy, Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
    #[serde(transparent)]
    pub struct AwaitingTxSignaturesFlags: u32 {
        const OUR_TX_SIGNATURES_SENT = 1;
        const THEIR_TX_SIGNATURES_SENT = 1 << 1;
        const TX_SIGNATURES_SENT = AwaitingTxSignaturesFlags::OUR_TX_SIGNATURES_SENT.bits() | AwaitingTxSignaturesFlags::THEIR_TX_SIGNATURES_SENT.bits();
    }

    #[derive(Copy, Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
    #[serde(transparent)]
    pub struct AwaitingChannelReadyFlags: u32 {
        const OUR_CHANNEL_READY = 1;
        const THEIR_CHANNEL_READY = 1 << 1;
        const CHANNEL_READY = AwaitingChannelReadyFlags::OUR_CHANNEL_READY.bits() | AwaitingChannelReadyFlags::THEIR_CHANNEL_READY.bits();
    }

    #[derive(Copy, Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
    #[serde(transparent)]
    pub struct ShuttingDownFlags: u32 {
        /// Indicates that we have sent a `shutdown` message.
        const OUR_SHUTDOWN_SENT = 1;
        /// Indicates that they have sent a `shutdown` message.
        const THEIR_SHUTDOWN_SENT = 1 << 1;
        /// Indicates that both we and they have sent `shutdown` messages,
        /// but some HTLCs are still pending to be resolved.
        const AWAITING_PENDING_TLCS = ShuttingDownFlags::OUR_SHUTDOWN_SENT.bits() | ShuttingDownFlags::THEIR_SHUTDOWN_SENT.bits();
        /// Indicates all pending HTLCs are resolved, and this channel will be dropped.
        const DROPPING_PENDING = 1 << 2;
        /// Indicates we have submitted a commitment transaction, waiting for confirmation
        const WAITING_COMMITMENT_CONFIRMATION = 1 << 3;
    }

    #[derive(Copy, Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
    #[serde(transparent)]
    pub struct CloseFlags: u32 {
        /// Indicates that channel is closed cooperatively.
        const COOPERATIVE = 1;
        /// Indicates that channel is closed uncooperatively, initiated by one party forcely.
        const UNCOOPERATIVE = 1 << 1;
    }
}

// Depending on the state of the channel, we may process the commitment_signed command differently.
// Below are all the channel state flags variants that we may encounter
// in normal commitment_signed processing flow.
#[derive(Debug)]
enum CommitmentSignedFlags {
    SigningCommitment(SigningCommitmentFlags),
    PendingShutdown(),
    ChannelReady(),
}

#[derive(Copy, Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
pub enum ChannelState {
    /// We are negotiating the parameters required for the channel prior to funding it.
    NegotiatingFunding(NegotiatingFundingFlags),
    /// We're collaborating with the other party on the funding transaction.
    CollaboratingFundingTx(CollaboratingFundingTxFlags),
    /// We have collaborated over the funding and are now waiting for CommitmentSigned messages.
    SigningCommitment(SigningCommitmentFlags),
    /// We've received and sent `commitment_signed` and are now waiting for both
    /// party to collaborate on creating a valid funding transaction.
    AwaitingTxSignatures(AwaitingTxSignaturesFlags),
    /// We've received/sent `funding_created` and `funding_signed` and are thus now waiting on the
    /// funding transaction to confirm.
    AwaitingChannelReady(AwaitingChannelReadyFlags),
    /// Both we and our counterparty consider the funding transaction confirmed and the channel is
    /// now operational.
    ChannelReady(),
    /// We've successfully negotiated a `closing_signed` dance. At this point, the `ChannelManager`
    /// is about to drop us, but we store this anyway.
    ShuttingDown(ShuttingDownFlags),
    /// This channel is closed.
    Closed(CloseFlags),
}

impl ChannelState {
    fn is_closed(&self) -> bool {
        matches!(self, ChannelState::Closed(_))
    }
}

fn new_channel_id_from_seed(seed: &[u8]) -> Hash256 {
    blake2b_256(seed).into()
}

fn derive_channel_id_from_tlc_keys(tlc_basepoint1: &Pubkey, tlc_basepoint2: &Pubkey) -> Hash256 {
    let mut preimage = [tlc_basepoint1.0.serialize(), tlc_basepoint2.0.serialize()];
    preimage.sort();
    new_channel_id_from_seed(&preimage.concat())
}

fn derive_temp_channel_id_from_tlc_key(tlc_basepoint: &Pubkey) -> Hash256 {
    let preimage = [tlc_basepoint.0.serialize(), [0; 33]].concat();
    new_channel_id_from_seed(&preimage)
}

pub fn get_commitment_secret(commitment_seed: &[u8; 32], commitment_number: u64) -> [u8; 32] {
    // Note that here, we hold the same assumption to bolts for commitment number,
    // i.e. this number should be in the range [0, 2^48).
    let mut res: [u8; 32] = *commitment_seed;
    for i in 0..48 {
        let bitpos = 47 - i;
        if commitment_number & (1 << bitpos) == (1 << bitpos) {
            res[bitpos / 8] ^= 1 << (bitpos & 7);
            res = blake2b_256(res);
        }
    }
    res
}

pub fn get_commitment_point(commitment_seed: &[u8; 32], commitment_number: u64) -> Pubkey {
    Privkey::from(&get_commitment_secret(commitment_seed, commitment_number)).pubkey()
}

pub(crate) fn get_funding_and_reserved_amount(
    total_amount: u128,
    shutdown_script: &Script,
    udt_type_script: &Option<Script>,
) -> Result<(u128, u64), ProcessingChannelError> {
    let reserved_capacity = reserved_capacity(shutdown_script, udt_type_script)?.as_u64();
    if udt_type_script.is_none() {
        if total_amount < reserved_capacity as u128 {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "The funding amount ({}) should be greater than or equal to {}",
                total_amount, reserved_capacity
            )));
        }
        if total_amount >= u64::MAX as u128 {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "The funding amount ({}) should be less than {}",
                total_amount,
                u64::MAX
            )));
        }
        Ok((total_amount - reserved_capacity as u128, reserved_capacity))
    } else {
        Ok((total_amount, reserved_capacity))
    }
}

pub(crate) fn reserved_capacity(
    shutdown_script: &Script,
    udt_type_script: &Option<Script>,
) -> Result<Capacity, CapacityError> {
    occupied_capacity(shutdown_script, udt_type_script)?
        .safe_add(Capacity::shannons(DEFAULT_MIN_SHUTDOWN_FEE))
}

pub(crate) fn occupied_capacity(
    shutdown_script: &Script,
    udt_type_script: &Option<Script>,
) -> Result<Capacity, CapacityError> {
    let cell_output = CellOutput::new_builder()
        .lock(shutdown_script.clone())
        .type_(udt_type_script.clone().pack())
        .build();

    if udt_type_script.is_some() {
        // 16 bytes for udt data
        cell_output.occupied_capacity(Capacity::bytes(16)?)
    } else {
        cell_output.occupied_capacity(Capacity::bytes(0)?)
    }
}

// Constructors for the channel actor state.
#[allow(clippy::too_many_arguments)]
impl ChannelActorState {
    pub fn is_public(&self) -> bool {
        self.public_channel_info.is_some()
    }

    pub fn is_ready(&self) -> bool {
        matches!(self.state, ChannelState::ChannelReady())
    }

    pub fn is_tlc_forwarding_enabled(&self) -> bool {
        self.local_tlc_info.enabled
    }

    pub async fn try_create_channel_messages(
        &mut self,
        network: &ActorRef<NetworkActorMessage>,
    ) -> Option<(ChannelAnnouncement, ChannelUpdate)> {
        let channel_announcement = self
            .try_create_channel_announcement_message(network)
            .await?;
        let channel_update = self.try_create_channel_update_message(network).await?;
        Some((channel_announcement, channel_update))
    }

    pub async fn try_create_channel_announcement_message(
        &mut self,
        network: &ActorRef<NetworkActorMessage>,
    ) -> Option<ChannelAnnouncement> {
        if !self.is_public() {
            debug!("Ignoring non-public channel announcement");
            return None;
        }

        let mut channel_announcement = match self
            .public_channel_info
            .as_ref()
            .and_then(|state| state.channel_announcement.clone())
        {
            // Skipping creating new signed channel announcement if it exists
            Some(x) if x.is_signed() => return Some(x),
            // We have created a channel announcement, but it's not signed by the other
            // party yet. We should try to complete the signatures next.
            Some(x) => x,
            // We have not created a channel announcement yet.
            None => {
                let channel_outpoint = self.must_get_funding_transaction_outpoint();
                let capacity = self.get_liquid_capacity();
                let (node1_id, node2_id) = if self.local_is_node1() {
                    (self.local_pubkey, self.remote_pubkey)
                } else {
                    (self.remote_pubkey, self.local_pubkey)
                };

                ChannelAnnouncement::new_unsigned(
                    &node1_id,
                    &node2_id,
                    channel_outpoint,
                    &self.get_funding_lock_script_xonly_key(),
                    capacity,
                    self.funding_udt_type_script.clone(),
                )
            }
        };

        let local_nonce = self
            .get_channel_announcement_musig2_secnonce()
            .public_nonce();
        let remote_nonce = self.get_remote_channel_announcement_nonce()?;
        let agg_nonce =
            AggNonce::sum(self.order_things_for_musig2(local_nonce, remote_nonce.clone()));

        let key_agg_ctx = self.get_deterministic_musig2_agg_context();

        let message = channel_announcement.message_to_sign();

        let (local_node_signature, local_partial_signature) = self
            .get_or_create_local_channel_announcement_signature(
                remote_nonce.clone(),
                message,
                network,
            )
            .await;

        let (remote_node_signature, remote_partial_signature) =
            self.get_remote_channel_announcement_signature()?;

        if self.local_is_node1() {
            channel_announcement.node1_signature = Some(local_node_signature);
            channel_announcement.node2_signature = Some(remote_node_signature);
        } else {
            channel_announcement.node1_signature = Some(remote_node_signature);
            channel_announcement.node2_signature = Some(local_node_signature);
        }

        let partial_signatures =
            self.order_things_for_musig2(local_partial_signature, remote_partial_signature);

        let signature =
            aggregate_partial_signatures(&key_agg_ctx, &agg_nonce, partial_signatures, message)
                .expect("aggregate partial signatures");

        channel_announcement.ckb_signature = Some(signature);

        self.public_channel_state_mut().channel_announcement = Some(channel_announcement.clone());

        Some(channel_announcement)
    }

    async fn do_generate_channel_update(
        &mut self,
        network: &ActorRef<NetworkActorMessage>,
        // The function that would change the channel update parameters.
        f: impl FnOnce(&mut ChannelUpdate),
    ) -> ChannelUpdate {
        assert!(self.is_public());
        let mut channel_update = self
            .get_unsigned_channel_update_message()
            .expect("public channel can generate channel update message");
        f(&mut channel_update);
        debug!(
            "Generated channel update message for channel {:?}: {:?}",
            &self.get_id(),
            &channel_update
        );
        let node_signature =
            sign_network_message(network.clone(), channel_update.message_to_sign())
                .await
                .expect(ASSUME_NETWORK_ACTOR_ALIVE);

        channel_update.signature = Some(node_signature);
        self.public_channel_state_mut().channel_update = Some(channel_update.clone());
        channel_update
    }

    async fn generate_channel_update(
        &mut self,
        network: &ActorRef<NetworkActorMessage>,
    ) -> ChannelUpdate {
        self.do_generate_channel_update(network, |_update| {}).await
    }

    fn create_update_tlc_info_message(&mut self) -> UpdateTlcInfo {
        self.local_tlc_info.timestamp = now_timestamp_as_millis_u64();
        UpdateTlcInfo {
            channel_id: self.get_id(),
            timestamp: self.local_tlc_info.timestamp,
            channel_flags: self.get_channel_update_channel_flags(),
            tlc_minimum_value: self.local_tlc_info.tlc_minimum_value,
            tlc_maximum_value: self.local_tlc_info.tlc_maximum_value,
            tlc_fee_proportional_millionths: self.local_tlc_info.tlc_fee_proportional_millionths,
            tlc_expiry_delta: self.local_tlc_info.tlc_expiry_delta,
        }
    }

    async fn generate_disabled_channel_update(
        &mut self,
        network: &ActorRef<NetworkActorMessage>,
    ) -> ChannelUpdate {
        self.do_generate_channel_update(network, |update| {
            update.channel_flags |= ChannelUpdateChannelFlags::DISABLED;
        })
        .await
    }

    // Notify the network, network graph and channel counterparty about the channel update.
    // We do this on channel ready, channel reestablishment, user channel parameters update.
    // Some of the events require us to send an OwnedChannelUpdateEvent::Up to the network actor,
    // (e.g. channel ready and channel reestablishment) and some require us to send a
    // OwnedChannelUpdateEvent::Updated (e.g. user channel parameters update) to the network actor.
    // update_only is used to distinguish between the two cases.
    async fn notify_owned_channel_updated(
        &mut self,
        network: &ActorRef<NetworkActorMessage>,
        update_only: bool,
    ) {
        if update_only {
            self.update_graph_for_local_channel_change(network);
        } else {
            self.update_graph_for_local_channel_ready(network);
        }
        if self.is_public() {
            let channel_update = self.generate_channel_update(network).await;
            network
                .send_message(NetworkActorMessage::new_command(
                    NetworkActorCommand::BroadcastMessages(vec![
                        BroadcastMessageWithTimestamp::ChannelUpdate(channel_update),
                    ]),
                ))
                .expect(ASSUME_NETWORK_ACTOR_ALIVE);
        }
        self.send_update_tlc_info_message(network);
    }

    fn update_graph_for_remote_channel_change(&mut self, network: &ActorRef<NetworkActorMessage>) {
        if let Some(channel_update_info) = self.get_remote_channel_update_info() {
            let channel_outpoint = self.must_get_funding_transaction_outpoint();
            let peer_id = self.get_remote_pubkey();
            network
                .send_message(NetworkActorMessage::new_event(
                    NetworkActorEvent::OwnedChannelUpdateEvent(
                        super::graph::OwnedChannelUpdateEvent::Updated(
                            channel_outpoint,
                            peer_id,
                            channel_update_info,
                        ),
                    ),
                ))
                .expect(ASSUME_NETWORK_ACTOR_ALIVE);
        }
    }

    fn update_graph_for_local_channel_ready(&mut self, network: &ActorRef<NetworkActorMessage>) {
        if let Ok(channel_info) = (&*self).try_into() {
            network
                .send_message(NetworkActorMessage::new_event(
                    NetworkActorEvent::OwnedChannelUpdateEvent(
                        super::graph::OwnedChannelUpdateEvent::Up(channel_info),
                    ),
                ))
                .expect(ASSUME_NETWORK_ACTOR_ALIVE);
        }
    }

    fn update_graph_for_local_channel_change(&mut self, network: &ActorRef<NetworkActorMessage>) {
        let channel_outpoint = self.must_get_funding_transaction_outpoint();
        let peer_id = self.get_local_pubkey();
        let channel_update_info = self.get_local_channel_update_info();
        network
            .send_message(NetworkActorMessage::new_event(
                NetworkActorEvent::OwnedChannelUpdateEvent(
                    super::graph::OwnedChannelUpdateEvent::Updated(
                        channel_outpoint,
                        peer_id,
                        channel_update_info,
                    ),
                ),
            ))
            .expect(ASSUME_NETWORK_ACTOR_ALIVE);
    }

    fn send_update_tlc_info_message(&mut self, network: &ActorRef<NetworkActorMessage>) {
        let update_tlc_info = self.create_update_tlc_info_message();
        network
            .send_message(NetworkActorMessage::new_command(
                NetworkActorCommand::SendFiberMessage(FiberMessageWithPeerId {
                    peer_id: self.get_remote_peer_id(),
                    message: FiberMessage::ChannelNormalOperation(
                        FiberChannelMessage::UpdateTlcInfo(update_tlc_info),
                    ),
                }),
            ))
            .expect(ASSUME_NETWORK_ACTOR_ALIVE);
    }

    async fn try_create_channel_update_message(
        &mut self,
        network: &ActorRef<NetworkActorMessage>,
    ) -> Option<ChannelUpdate> {
        if !self.is_public() {
            debug!("Ignoring non-public channel update");
            return None;
        }

        if let Some(x) = self
            .public_channel_info
            .as_ref()
            .and_then(|state| state.channel_update.clone())
        {
            return Some(x);
        };

        Some(self.generate_channel_update(network).await)
    }

    fn get_channel_update_channel_flags(&self) -> ChannelUpdateChannelFlags {
        if self.is_tlc_forwarding_enabled() {
            ChannelUpdateChannelFlags::empty()
        } else {
            ChannelUpdateChannelFlags::DISABLED
        }
    }

    pub fn get_unsigned_channel_update_message(&self) -> Option<ChannelUpdate> {
        let message_flags = if self.local_is_node1() {
            ChannelUpdateMessageFlags::UPDATE_OF_NODE1
        } else {
            ChannelUpdateMessageFlags::UPDATE_OF_NODE2
        };

        self.is_public().then_some(ChannelUpdate::new_unsigned(
            self.must_get_funding_transaction_outpoint(),
            now_timestamp_as_millis_u64(),
            message_flags,
            self.get_channel_update_channel_flags(),
            self.local_tlc_info.tlc_expiry_delta,
            self.local_tlc_info.tlc_minimum_value,
            self.local_tlc_info.tlc_fee_proportional_millionths,
        ))
    }

    pub fn new_inbound_channel(
        temp_channel_id: Hash256,
        public_channel_info: Option<PublicChannelInfo>,
        local_value: u128,
        local_reserved_ckb_amount: u64,
        commitment_fee_rate: u64,
        commitment_delay_epoch: u64,
        funding_fee_rate: u64,
        funding_udt_type_script: Option<Script>,
        seed: &[u8],
        local_pubkey: Pubkey,
        remote_pubkey: Pubkey,
        local_shutdown_script: Script,
        remote_shutdown_script: Script,
        remote_value: u128,
        remote_reserved_ckb_amount: u64,
        remote_pubkeys: ChannelBasePublicKeys,
        remote_nonce: PubNonce,
        remote_channel_announcement_nonce: Option<PubNonce>,
        first_commitment_point: Pubkey,
        second_commitment_point: Pubkey,
        remote_max_tlc_value_in_flight: u128,
        remote_max_tlc_number_in_flight: u64,
        local_max_tlc_number_in_flight: u64,
        local_max_tlc_value_in_flight: u128,
        local_tlc_info: ChannelTlcInfo,
    ) -> Self {
        let signer = InMemorySigner::generate_from_seed(seed);
        let local_base_pubkeys = signer.get_base_public_keys();

        let channel_id = derive_channel_id_from_tlc_keys(
            &local_base_pubkeys.tlc_base_key,
            &remote_pubkeys.tlc_base_key,
        );

        debug!(
            "Generated channel id ({:?}) for temporary channel {:?}",
            &channel_id, &temp_channel_id,
        );

        let mut state = Self {
            state: ChannelState::NegotiatingFunding(NegotiatingFundingFlags::THEIR_INIT_SENT),
            public_channel_info,
            local_tlc_info,
            remote_tlc_info: None,
            local_pubkey,
            remote_pubkey,
            funding_tx: None,
            funding_tx_confirmed_at: None,
            is_acceptor: true,
            funding_udt_type_script,
            to_local_amount: local_value,
            to_remote_amount: remote_value,
            commitment_fee_rate,
            commitment_delay_epoch,
            funding_fee_rate,
            id: channel_id,
            tlc_state: Default::default(),
            local_shutdown_script,
            local_channel_public_keys: local_base_pubkeys,
            signer,
            remote_channel_public_keys: Some(remote_pubkeys),
            commitment_numbers: Default::default(),
            remote_shutdown_script: Some(remote_shutdown_script),
            last_commitment_signed_remote_nonce: None,
            last_revoke_and_ack_remote_nonce: None,
            last_committed_remote_nonce: Some(remote_nonce),
            remote_commitment_points: vec![
                (0, first_commitment_point),
                (1, second_commitment_point),
            ],
            local_shutdown_info: None,
            remote_shutdown_info: None,
            local_reserved_ckb_amount,
            remote_reserved_ckb_amount,
            local_constraints: ChannelConstraints::new(
                local_max_tlc_value_in_flight,
                local_max_tlc_number_in_flight,
            ),
            remote_constraints: ChannelConstraints::new(
                remote_max_tlc_value_in_flight,
                remote_max_tlc_number_in_flight,
            ),
            latest_commitment_transaction: None,
            reestablishing: false,
            created_at: SystemTime::now(),
        };
        if let Some(nonce) = remote_channel_announcement_nonce {
            state.update_remote_channel_announcement_nonce(&nonce);
        }
        state
    }

    #[allow(clippy::too_many_arguments)]
    pub fn new_outbound_channel(
        public_channel_info: Option<PublicChannelInfo>,
        seed: &[u8],
        local_pubkey: Pubkey,
        remote_pubkey: Pubkey,
        to_local_amount: u128,
        local_reserved_ckb_amount: u64,
        commitment_fee_rate: u64,
        commitment_delay_epoch: u64,
        funding_fee_rate: u64,
        funding_udt_type_script: Option<Script>,
        shutdown_script: Script,
        local_max_tlc_value_in_flight: u128,
        local_max_tlc_number_in_flight: u64,
        local_tlc_info: ChannelTlcInfo,
    ) -> Self {
        let signer = InMemorySigner::generate_from_seed(seed);
        let local_pubkeys = signer.get_base_public_keys();
        let temp_channel_id = derive_temp_channel_id_from_tlc_key(&local_pubkeys.tlc_base_key);
        Self {
            state: ChannelState::NegotiatingFunding(NegotiatingFundingFlags::empty()),
            public_channel_info,
            local_tlc_info,
            remote_tlc_info: None,
            local_pubkey,
            remote_pubkey,
            funding_tx: None,
            funding_tx_confirmed_at: None,
            funding_udt_type_script,
            is_acceptor: false,
            to_local_amount,
            to_remote_amount: 0,
            commitment_fee_rate,
            commitment_delay_epoch,
            funding_fee_rate,
            id: temp_channel_id,
            tlc_state: Default::default(),
            signer,
            local_channel_public_keys: local_pubkeys,
            local_constraints: ChannelConstraints::new(
                local_max_tlc_value_in_flight,
                local_max_tlc_number_in_flight,
            ),
            // these values will update after accept channel peer message handled
            remote_constraints: ChannelConstraints::default(),
            remote_channel_public_keys: None,
            last_commitment_signed_remote_nonce: None,
            last_revoke_and_ack_remote_nonce: None,
            last_committed_remote_nonce: None,
            commitment_numbers: Default::default(),
            remote_commitment_points: vec![],
            local_shutdown_script: shutdown_script,
            remote_shutdown_script: None,
            local_shutdown_info: None,
            remote_shutdown_info: None,
            local_reserved_ckb_amount,
            remote_reserved_ckb_amount: 0,
            latest_commitment_transaction: None,
            reestablishing: false,
            created_at: SystemTime::now(),
        }
    }

    // TODO: this fn is duplicated with NetworkActorState::check_open_channel_parameters, but is not easy to refactor, just keep it for now.
    fn check_open_channel_parameters(&self) -> ProcessingChannelResult {
        let udt_type_script = &self.funding_udt_type_script;

        // reserved_ckb_amount
        let occupied_capacity =
            occupied_capacity(&self.local_shutdown_script, udt_type_script)?.as_u64();
        if self.local_reserved_ckb_amount < occupied_capacity {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Reserved CKB amount {} is less than {}",
                self.local_reserved_ckb_amount, occupied_capacity,
            )));
        }

        // funding_fee_rate
        if self.funding_fee_rate < DEFAULT_FEE_RATE {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Funding fee rate is less than {}",
                DEFAULT_FEE_RATE,
            )));
        }

        // commitment_fee_rate
        if self.commitment_fee_rate < DEFAULT_COMMITMENT_FEE_RATE {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Commitment fee rate is less than {}",
                DEFAULT_COMMITMENT_FEE_RATE,
            )));
        }
        let commitment_fee = calculate_commitment_tx_fee(self.commitment_fee_rate, udt_type_script);
        let reserved_fee = self.local_reserved_ckb_amount - occupied_capacity;
        if commitment_fee * 2 > reserved_fee {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Commitment fee {} which caculated by commitment fee rate {} is larger than half of reserved fee {}",
                commitment_fee, self.commitment_fee_rate, reserved_fee
            )));
        }

        // commitment_delay_epoch
        let epoch = EpochNumberWithFraction::from_full_value_unchecked(self.commitment_delay_epoch);
        if !epoch.is_well_formed() {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Commitment delay epoch {} is not a valid value",
                self.commitment_delay_epoch,
            )));
        }

        let min = EpochNumberWithFraction::new(MIN_COMMITMENT_DELAY_EPOCHS, 0, 1);
        if epoch < min {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Commitment delay epoch {} is less than the minimal value {}",
                epoch, min
            )));
        }

        let max = EpochNumberWithFraction::new(MAX_COMMITMENT_DELAY_EPOCHS, 0, 1);
        if epoch > max {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Commitment delay epoch {} is greater than the maximal value {}",
                epoch, max
            )));
        }

        // max_tlc_number_in_flight
        if self.local_constraints.max_tlc_number_in_flight > SYS_MAX_TLC_NUMBER_IN_FLIGHT {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Local max TLC number in flight {} is greater than the system maximal value {}",
                self.local_constraints.max_tlc_number_in_flight, SYS_MAX_TLC_NUMBER_IN_FLIGHT
            )));
        }

        Ok(())
    }

    fn check_accept_channel_parameters(&self) -> Result<(), ProcessingChannelError> {
        if self.remote_constraints.max_tlc_number_in_flight > MAX_TLC_NUMBER_IN_FLIGHT {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Remote max TLC number in flight {} is greater than the system maximal value {}",
                self.remote_constraints.max_tlc_number_in_flight, MAX_TLC_NUMBER_IN_FLIGHT
            )));
        }

        let udt_type_script = &self.funding_udt_type_script;

        // reserved_ckb_amount
        let occupied_capacity =
            occupied_capacity(&self.get_remote_shutdown_script(), udt_type_script)?.as_u64();
        if self.remote_reserved_ckb_amount < occupied_capacity {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Reserved CKB amount {} is less than {}",
                self.remote_reserved_ckb_amount, occupied_capacity,
            )));
        }

        // commitment_fee_rate
        let commitment_fee = calculate_commitment_tx_fee(self.commitment_fee_rate, udt_type_script);
        let reserved_fee = self.remote_reserved_ckb_amount - occupied_capacity;
        if commitment_fee * 2 > reserved_fee {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Commitment fee {} which caculated by commitment fee rate {} is larger than half of reserved fee {}",
                commitment_fee, self.commitment_fee_rate, reserved_fee
            )));
        }

        Ok(())
    }

    fn check_shutdown_fee_rate(
        &self,
        fee_rate: FeeRate,
        close_script: &Script,
    ) -> ProcessingChannelResult {
        if fee_rate.as_u64() < self.commitment_fee_rate {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Fee rate {} is less than commitment fee rate {}",
                fee_rate, self.commitment_fee_rate
            )));
        }

        let fee = calculate_shutdown_tx_fee(
            fee_rate.as_u64(),
            &self.funding_udt_type_script,
            (self.get_remote_shutdown_script(), close_script.clone()),
        );

        let occupied_capacity =
            occupied_capacity(close_script, &self.funding_udt_type_script)?.as_u64();
        let available_max_fee = if self.funding_udt_type_script.is_none() {
            (self.to_local_amount as u64 + self.local_reserved_ckb_amount)
                .saturating_sub(occupied_capacity)
        } else {
            self.local_reserved_ckb_amount
                .saturating_sub(occupied_capacity)
        };

        if fee > available_max_fee {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Local balance is not enough to pay the fee, expect fee {} <= available_max_fee {}",
                fee, available_max_fee
            )));
        }
        Ok(())
    }

    pub fn get_local_balance(&self) -> u128 {
        self.to_local_amount
    }

    pub fn get_remote_balance(&self) -> u128 {
        self.to_remote_amount
    }

    pub fn get_offered_tlc_balance(&self, exclude_failed_tls: bool) -> u128 {
        self.get_all_offer_tlcs()
            .filter(|tlc| !(exclude_failed_tls && tlc.is_fail_remove_confirmed()))
            .map(|tlc| tlc.amount)
            .sum::<u128>()
    }

    pub fn get_received_tlc_balance(&self, exclude_failed_tls: bool) -> u128 {
        self.get_all_received_tlcs()
            .filter(|tlc| !(exclude_failed_tls && tlc.is_fail_remove_confirmed()))
            .map(|tlc| tlc.amount)
            .sum::<u128>()
    }

    pub fn get_created_at_in_millis(&self) -> u64 {
        self.created_at
            .duration_since(UNIX_EPOCH)
            .expect("Duration since unix epoch")
            .as_millis() as u64
    }

    pub fn is_closed(&self) -> bool {
        self.state.is_closed()
    }

    pub(crate) fn update_state(&mut self, new_state: ChannelState) {
        debug!(
            "Updating channel state from {:?} to {:?}",
            &self.state, &new_state
        );
        self.state = new_state;
    }

    pub(crate) fn local_is_node1(&self) -> bool {
        self.local_pubkey < self.remote_pubkey
    }

    async fn get_or_create_local_channel_announcement_signature(
        &mut self,
        remote_nonce: PubNonce,
        message: [u8; 32],
        network: &ActorRef<NetworkActorMessage>,
    ) -> (EcdsaSignature, PartialSignature) {
        if let Some(local_channel_announcement_signature) = self
            .public_channel_info
            .as_ref()
            .and_then(|channel_info| channel_info.local_channel_announcement_signature.clone())
        {
            return local_channel_announcement_signature;
        }

        let local_secnonce = self.get_channel_announcement_musig2_secnonce();
        let local_nonce = local_secnonce.public_nonce();
        let agg_nonce = AggNonce::sum(self.order_things_for_musig2(local_nonce, remote_nonce));
        let key_agg_ctx = self.get_deterministic_musig2_agg_context();
        let channel_id = self.get_id();
        let peer_id = self.get_remote_peer_id();
        let channel_outpoint = self.must_get_funding_transaction_outpoint();

        let partial_signature: PartialSignature = sign_partial(
            &key_agg_ctx,
            &self.signer.funding_key,
            local_secnonce,
            &agg_nonce,
            message,
        )
        .expect("Partial sign channel announcement");

        let node_signature = sign_network_message(network.clone(), message)
            .await
            .expect(ASSUME_NETWORK_ACTOR_ALIVE);
        network
            .send_message(NetworkActorMessage::new_command(
                NetworkActorCommand::SendFiberMessage(FiberMessageWithPeerId::new(
                    peer_id,
                    FiberMessage::announcement_signatures(AnnouncementSignatures {
                        channel_id,
                        channel_outpoint,
                        partial_signature,
                        node_signature: node_signature.clone(),
                    }),
                )),
            ))
            .expect(ASSUME_NETWORK_ACTOR_ALIVE);
        let result = (node_signature, partial_signature);
        self.public_channel_state_mut()
            .local_channel_announcement_signature = Some(result.clone());
        result
    }

    fn public_channel_state_mut(&mut self) -> &mut PublicChannelInfo {
        self.public_channel_info
            .as_mut()
            .expect("public channel info exists")
    }

    fn get_remote_channel_announcement_nonce(&self) -> Option<PubNonce> {
        self.public_channel_info
            .as_ref()
            .and_then(|state| state.remote_channel_announcement_nonce.clone())
    }

    fn update_remote_channel_announcement_nonce(&mut self, nonce: &PubNonce) {
        assert!(self.is_public());
        self.public_channel_state_mut()
            .remote_channel_announcement_nonce = Some(nonce.clone());
    }

    fn get_remote_channel_announcement_signature(
        &self,
    ) -> Option<(EcdsaSignature, PartialSignature)> {
        self.public_channel_info
            .as_ref()
            .and_then(|state| state.remote_channel_announcement_signature.clone())
    }

    fn update_remote_channel_announcement_signature(
        &mut self,
        ecdsa_signature: EcdsaSignature,
        partial_signatures: PartialSignature,
    ) {
        assert!(self.is_public());
        self.public_channel_info
            .as_mut()
            .expect("public channel info exists")
            .remote_channel_announcement_signature = Some((ecdsa_signature, partial_signatures));
    }

    fn update_our_tlc_fee_proportional_millionths(&mut self, fee: u128) -> bool {
        if self.local_tlc_info.tlc_fee_proportional_millionths == fee {
            return false;
        }
        self.local_tlc_info.tlc_fee_proportional_millionths = fee;
        true
    }

    fn update_our_tlc_min_value(&mut self, value: u128) -> bool {
        if self.local_tlc_info.tlc_minimum_value == value {
            return false;
        }
        self.local_tlc_info.tlc_minimum_value = value;
        true
    }

    fn update_our_enabled(&mut self, enabled: bool) -> bool {
        if self.local_tlc_info.enabled == enabled {
            return false;
        }
        self.local_tlc_info.enabled = enabled;
        true
    }

    fn update_our_tlc_expiry_delta(&mut self, value: u64) -> bool {
        if self.local_tlc_info.tlc_expiry_delta == value {
            return false;
        }
        self.local_tlc_info.tlc_expiry_delta = value;
        true
    }

    fn get_total_reserved_ckb_amount(&self) -> u64 {
        self.local_reserved_ckb_amount + self.remote_reserved_ckb_amount
    }

    fn get_total_ckb_amount(&self) -> u64 {
        self.to_local_amount as u64
            + self.to_remote_amount as u64
            + self.get_total_reserved_ckb_amount()
    }

    fn get_total_udt_amount(&self) -> u128 {
        self.to_local_amount + self.to_remote_amount
    }

    // Get the total liquid capacity of the channel, which will exclude the reserved ckb amount.
    // This is the capacity used for gossiping channel information.
    pub(crate) fn get_liquid_capacity(&self) -> u128 {
        if self.funding_udt_type_script.is_some() {
            self.get_total_udt_amount()
        } else {
            self.to_local_amount + self.to_remote_amount
        }
    }

    // Send RevokeAndAck message to the counterparty, and update the
    // channel state accordingly.
    fn send_revoke_and_ack_message(
        &mut self,
        network: &ActorRef<NetworkActorMessage>,
    ) -> ProcessingChannelResult {
        let sign_ctx = self.get_sign_context(false);
        let x_only_aggregated_pubkey = sign_ctx.common_ctx.x_only_aggregated_pubkey();

        let revocation_partial_signature = {
            let commitment_tx_fee = calculate_commitment_tx_fee(
                self.commitment_fee_rate,
                &self.funding_udt_type_script,
            );
            let lock_script = self.get_remote_shutdown_script();
            let (output, output_data) = if let Some(udt_type_script) = &self.funding_udt_type_script
            {
                let capacity = self.get_total_reserved_ckb_amount() - commitment_tx_fee;
                let output = CellOutput::new_builder()
                    .lock(lock_script)
                    .type_(Some(udt_type_script.clone()).pack())
                    .capacity(capacity.pack())
                    .build();

                let output_data = self.get_total_udt_amount().to_le_bytes().pack();
                (output, output_data)
            } else {
                let capacity = self.get_total_ckb_amount() - commitment_tx_fee;
                let output = CellOutput::new_builder()
                    .lock(lock_script.clone())
                    .capacity(capacity.pack())
                    .build();
                let output_data = Bytes::default();
                (output, output_data)
            };

            let commitment_number = self.get_remote_commitment_number() - 1;
            let commitment_lock_script_args = [
                &blake2b_256(x_only_aggregated_pubkey)[0..20],
                self.get_delay_epoch_as_lock_args_bytes().as_slice(),
                commitment_number.to_be_bytes().as_slice(),
            ]
            .concat();

            let message = blake2b_256(
                [
                    output.as_slice(),
                    output_data.as_slice(),
                    commitment_lock_script_args.as_slice(),
                ]
                .concat(),
            );
            let our_signature = sign_ctx.sign(message.as_slice()).expect("valid signature");
            our_signature
        };

        let commitment_tx_partial_signature = {
            let (
                [to_local_output, to_remote_output],
                [to_local_output_data, to_remote_output_data],
            ) = self.build_settlement_transaction_outputs(false);
            let commitment_lock_script_args = [
                &blake2b_256(x_only_aggregated_pubkey)[0..20],
                self.get_delay_epoch_as_lock_args_bytes().as_slice(),
                self.get_remote_commitment_number().to_be_bytes().as_slice(),
            ]
            .concat();

            let message = blake2b_256(
                [
                    to_local_output.as_slice(),
                    to_local_output_data.as_slice(),
                    to_remote_output.as_slice(),
                    to_remote_output_data.as_slice(),
                    commitment_lock_script_args.as_slice(),
                ]
                .concat(),
            );
            sign_ctx.sign(message.as_slice())?
        };

        // Note that we must update channel state here to update commitment number,
        // so that next step will obtain the correct commitment point.
        self.increment_remote_commitment_number();
        let point = self.get_current_local_commitment_point();

        network
            .send_message(NetworkActorMessage::new_command(
                NetworkActorCommand::SendFiberMessage(FiberMessageWithPeerId::new(
                    self.get_remote_peer_id(),
                    FiberMessage::revoke_and_ack(RevokeAndAck {
                        channel_id: self.get_id(),
                        revocation_partial_signature,
                        commitment_tx_partial_signature,
                        next_per_commitment_point: point,
                    }),
                )),
            ))
            .expect(ASSUME_NETWORK_ACTOR_ALIVE);
        self.update_last_revoke_and_ack_remote_nonce();
        Ok(())
    }

    pub fn get_id(&self) -> Hash256 {
        self.id
    }

    pub fn get_local_pubkey(&self) -> Pubkey {
        self.local_pubkey
    }

    pub fn get_local_peer_id(&self) -> PeerId {
        self.local_pubkey.tentacle_peer_id()
    }

    pub fn get_local_channel_update_info(&self) -> ChannelUpdateInfo {
        let balance = self.get_local_balance();
        let mut info = ChannelUpdateInfo::from(&self.local_tlc_info);
        info.outbound_liquidity = Some(balance);
        info
    }

    pub fn get_remote_pubkey(&self) -> Pubkey {
        self.remote_pubkey
    }

    pub fn get_remote_peer_id(&self) -> PeerId {
        self.remote_pubkey.tentacle_peer_id()
    }

    pub fn get_remote_channel_update_info(&self) -> Option<ChannelUpdateInfo> {
        let balance = self.get_remote_balance();
        self.remote_tlc_info.as_ref().map(|tlc_info| {
            let mut info = ChannelUpdateInfo::from(tlc_info);
            info.outbound_liquidity = Some(balance);
            info
        })
    }

    pub fn get_next_local_secnonce(&self) -> SecNonce {
        self.signer
            .derive_musig2_nonce(self.get_next_commitment_number(true))
    }

    pub fn get_next_local_nonce(&self) -> PubNonce {
        self.get_next_local_secnonce().public_nonce()
    }

    fn get_last_committed_remote_nonce(&self) -> PubNonce {
        self.last_committed_remote_nonce
            .as_ref()
            .expect("always have peer's last committed nonce in normal channel operations")
            .clone()
    }

    fn get_last_commitment_signed_remote_nonce(&self) -> Option<PubNonce> {
        self.last_commitment_signed_remote_nonce.clone()
    }

    fn commit_remote_nonce(&mut self, nonce: PubNonce) {
        self.last_committed_remote_nonce = Some(nonce);
    }

    fn update_last_commitment_signed_remote_nonce(&mut self) {
        let nonce = self.get_last_committed_remote_nonce();
        self.last_commitment_signed_remote_nonce = Some(nonce);
    }

    fn update_last_revoke_and_ack_remote_nonce(&mut self) {
        let nonce = self.get_last_committed_remote_nonce();
        self.last_revoke_and_ack_remote_nonce = Some(nonce);
    }

    pub fn get_current_commitment_numbers(&self) -> CommitmentNumbers {
        self.commitment_numbers
    }

    pub fn get_local_commitment_number(&self) -> u64 {
        self.commitment_numbers.get_local()
    }

    pub fn get_remote_commitment_number(&self) -> u64 {
        self.commitment_numbers.get_remote()
    }

    fn set_remote_commitment_number(&mut self, number: u64) {
        self.commitment_numbers.remote = number;
    }

    pub fn increment_local_commitment_number(&mut self) {
        self.commitment_numbers.increment_local();
    }

    pub fn increment_remote_commitment_number(&mut self) {
        self.commitment_numbers.increment_remote();
    }

    pub fn get_current_commitment_number(&self, for_remote: bool) -> u64 {
        if for_remote {
            self.get_local_commitment_number()
        } else {
            self.get_remote_commitment_number()
        }
    }

    pub fn get_next_commitment_number(&self, for_remote: bool) -> u64 {
        self.get_current_commitment_number(for_remote) + 1
    }

    pub fn get_next_offering_tlc_id(&self) -> TLCId {
        TLCId::Offered(self.tlc_state.get_next_offering())
    }

    pub fn get_next_received_tlc_id(&self) -> TLCId {
        TLCId::Received(self.tlc_state.get_next_received())
    }

    pub fn increment_next_offered_tlc_id(&mut self) {
        self.tlc_state.increment_offering();
    }

    pub fn increment_next_received_tlc_id(&mut self) {
        self.tlc_state.increment_received();
    }

    pub fn get_offered_tlc(&self, tlc_id: TLCId) -> Option<&TlcInfo> {
        self.tlc_state.get(&tlc_id)
    }

    pub fn get_received_tlc(&self, tlc_id: TLCId) -> Option<&TlcInfo> {
        self.tlc_state.get(&tlc_id)
    }

    pub fn check_insert_tlc(&mut self, tlc: &TlcInfo) -> Result<(), ProcessingChannelError> {
        let next_tlc_id = if tlc.is_offered() {
            self.get_next_offering_tlc_id()
        } else {
            self.get_next_received_tlc_id()
        };
        if tlc.tlc_id != next_tlc_id {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Received tlc id {:?} is not the expected next id {:?}",
                tlc.tlc_id, next_tlc_id
            )));
        }
        let payment_hash = tlc.payment_hash;
        let mut tlc_infos = self
            .tlc_state
            .all_tlcs()
            .filter(|tlc| tlc.payment_hash == payment_hash)
            .peekable();

        if tlc_infos.peek().is_some() {
            if tlc_infos.all(|t| t.is_fail_remove_confirmed()) {
                // If all the tlcs with the same payment hash are confirmed to be failed,
                // then it's safe to insert the new tlc, the old tlcs will be removed later.
            } else {
                return Err(ProcessingChannelError::RepeatedProcessing(format!(
                    "Trying to insert tlc with duplicate payment hash {:?}",
                    payment_hash
                )));
            }
        }
        if tlc.is_offered() {
            let sent_tlc_value = self.get_offered_tlc_balance(false);
            debug_assert!(self.to_local_amount >= sent_tlc_value);
            if sent_tlc_value + tlc.amount > self.to_local_amount {
                return Err(ProcessingChannelError::TlcAmountExceedLimit);
            }
        } else {
            let received_tlc_value = self.get_received_tlc_balance(false);
            debug_assert!(self.to_remote_amount >= received_tlc_value);
            if received_tlc_value + tlc.amount > self.to_remote_amount {
                debug!(
                    "Adding tlc {:?} with amount {} exceeds remote balance {}",
                    tlc.tlc_id,
                    tlc.amount,
                    self.to_remote_amount - received_tlc_value
                );
                return Err(ProcessingChannelError::TlcAmountExceedLimit);
            }
        }
        Ok(())
    }

    // Remove a tlc with a reason. If the tlc is removed, then the channel
    // balance will be updated accordingly. Otherwise, it is guaranteed that
    // the channel state is not updated.
    pub fn remove_tlc_with_reason(
        &mut self,
        tlc_id: TLCId,
    ) -> Result<(TlcInfo, RemoveTlcReason), ProcessingChannelError> {
        let current = self.tlc_state.get_mut(&tlc_id).expect("TLC exists").clone();
        let reason = current
            .removed_reason
            .clone()
            .expect("expect removed_reason exist");
        assert!(matches!(
            current.status,
            TlcStatus::Inbound(InboundTlcStatus::RemoveAckConfirmed)
                | TlcStatus::Outbound(OutboundTlcStatus::RemoveAckConfirmed)
        ));

        if let RemoveTlcReason::RemoveTlcFulfill(fulfill) = &reason {
            let filled_payment_hash: Hash256 =
                current.hash_algorithm.hash(fulfill.payment_preimage).into();
            if current.payment_hash != filled_payment_hash {
                return Err(ProcessingChannelError::FinalIncorrectPreimage);
            }

            // update balance according to the tlc
            let (mut to_local_amount, mut to_remote_amount) =
                (self.to_local_amount, self.to_remote_amount);
            if current.is_offered() {
                to_local_amount -= current.amount;
                to_remote_amount += current.amount;
            } else {
                to_local_amount += current.amount;
                to_remote_amount -= current.amount;
            }

            self.to_local_amount = to_local_amount;
            self.to_remote_amount = to_remote_amount;

            debug!("Updated local balance to {} and remote balance to {} by removing tlc {:?} with reason {:?}",
                            to_local_amount, to_remote_amount, tlc_id, reason);
            self.tlc_state.apply_remove_tlc(tlc_id);
        }
        debug!(
            "Removed tlc payment_hash {:?} with reason {:?}",
            current.payment_hash, reason
        );

        Ok((current.clone(), reason))
    }

    pub fn clean_up_failed_tlcs(&mut self) {
        // Remove the oldest failed tlcs from the channel state turns out to be very tricky
        // Because the different parties may have different views on the failed tlcs,
        // so we need to be very careful here.

        // The basic idea is to remove the oldest failed tlcs that are confirmed by both parties.
        // And we need to calculate the oldest failed tlcs independently from two directions,
        // Because we may have tlc operations from both directions at the same time, order matters.
        // see #475 for more details.
        let failed_offered_tlcs = self.tlc_state.offered_tlcs.get_oldest_failed_tlcs();
        let failed_received_tlcs = self.tlc_state.received_tlcs.get_oldest_failed_tlcs();

        for tlc_id in failed_offered_tlcs
            .iter()
            .chain(failed_received_tlcs.iter())
        {
            debug_assert!(self.tlc_state.applied_remove_tlcs.contains(tlc_id));
            self.tlc_state.apply_remove_tlc(*tlc_id);
        }
    }

    pub fn get_local_channel_public_keys(&self) -> &ChannelBasePublicKeys {
        &self.local_channel_public_keys
    }

    pub fn get_remote_channel_public_keys(&self) -> &ChannelBasePublicKeys {
        self.remote_channel_public_keys
            .as_ref()
            .expect("remote channel public keys exist")
    }

    pub fn must_get_funding_transaction(&self) -> &Transaction {
        self.funding_tx
            .as_ref()
            .expect("Funding transaction is present")
    }

    pub fn get_funding_transaction_outpoint(&self) -> Option<OutPoint> {
        self.funding_tx.as_ref().map(|tx| {
            // By convention, the funding tx output for the channel is the first output.
            OutPoint::new(tx.calc_tx_hash(), 0)
        })
    }

    pub fn must_get_funding_transaction_outpoint(&self) -> OutPoint {
        self.get_funding_transaction_outpoint()
            .expect("Funding transaction outpoint is present")
    }

    pub fn must_get_funding_transaction_timestamp(&self) -> u64 {
        self.funding_tx_confirmed_at
            .as_ref()
            .expect("Funding transaction confirmed at present")
            .2
    }

    pub fn get_local_shutdown_script(&self) -> Script {
        self.local_shutdown_script.clone()
    }

    pub fn get_remote_shutdown_script(&self) -> Script {
        self.remote_shutdown_script
            .as_ref()
            .expect("remote_shutdown_script should be set in current state")
            .clone()
    }

    fn get_local_commitment_point(&self, commitment_number: u64) -> Pubkey {
        self.signer.get_commitment_point(commitment_number)
    }

    /// Get the counterparty commitment point for the given commitment number.
    fn get_remote_commitment_point(&self, commitment_number: u64) -> Pubkey {
        self.remote_commitment_points
            .iter()
            .find_map(|(number, point)| {
                if *number == commitment_number {
                    Some(*point)
                } else {
                    None
                }
            })
            .expect("remote commitment point should exist")
    }

    fn get_current_local_commitment_point(&self) -> Pubkey {
        self.get_local_commitment_point(self.get_remote_commitment_number())
    }

    pub fn get_funding_lock_script_xonly_key(&self) -> XOnlyPublicKey {
        let pubkey: secp256k1::PublicKey = self
            .get_deterministic_musig2_agg_context()
            .aggregated_pubkey();
        pubkey.into()
    }

    pub fn get_funding_lock_script_xonly(&self) -> [u8; 32] {
        self.get_deterministic_musig2_agg_context()
            .aggregated_pubkey::<Point>()
            .serialize_xonly()
    }

    pub fn get_funding_lock_script(&self) -> Script {
        let aggregated_pubkey = self.get_funding_lock_script_xonly();
        let pubkey_hash = blake2b_256(aggregated_pubkey);
        get_script_by_contract(Contract::FundingLock, &pubkey_hash[0..20])
    }

    pub fn get_funding_request(&self) -> FundingRequest {
        FundingRequest {
            script: self.get_funding_lock_script(),
            udt_type_script: self.funding_udt_type_script.clone(),
            local_amount: self.to_local_amount,
            funding_fee_rate: self.funding_fee_rate,
            remote_amount: self.to_remote_amount,
            local_reserved_ckb_amount: self.local_reserved_ckb_amount,
            remote_reserved_ckb_amount: self.remote_reserved_ckb_amount,
        }
    }

    pub fn get_deterministic_musig2_agg_context(&self) -> KeyAggContext {
        let local_pubkey = self.get_local_channel_public_keys().funding_pubkey;
        let remote_pubkey = self.get_remote_channel_public_keys().funding_pubkey;
        let keys = self.order_things_for_musig2(local_pubkey, remote_pubkey);
        KeyAggContext::new(keys).expect("Valid pubkeys")
    }

    pub fn get_channel_announcement_musig2_secnonce(&self) -> SecNonce {
        let seckey = blake2b_hash_with_salt(
            self.signer.musig2_base_nonce.as_ref(),
            b"channel_announcement".as_slice(),
        );
        SecNonce::build(seckey).build()
    }

    pub fn get_channel_announcement_musig2_pubnonce(&self) -> PubNonce {
        self.get_channel_announcement_musig2_secnonce()
            .public_nonce()
    }

    pub fn get_local_musig2_secnonce(&self) -> SecNonce {
        self.signer
            .derive_musig2_nonce(self.get_local_commitment_number())
    }

    pub fn get_local_musig2_pubnonce(&self) -> PubNonce {
        self.get_local_musig2_secnonce().public_nonce()
    }

    pub fn get_deterministic_musig2_agg_pubnonce(
        &self,
        local_nonce: PubNonce,
        remote_nonce: PubNonce,
    ) -> AggNonce {
        let nonces = self.order_things_for_musig2(local_nonce, remote_nonce);
        AggNonce::sum(nonces)
    }

    fn get_active_received_tlcs(&self, for_remote: bool) -> Vec<TlcInfo> {
        self.tlc_state
            .commitment_signed_tlcs(for_remote)
            .filter(|tlc| tlc.is_received())
            .cloned()
            .collect()
    }

    fn get_active_offered_tlcs(&self, for_remote: bool) -> Vec<TlcInfo> {
        self.tlc_state
            .commitment_signed_tlcs(for_remote)
            .filter(|tlc| tlc.is_offered())
            .cloned()
            .collect()
    }

    pub fn get_all_received_tlcs(&self) -> impl Iterator<Item = &TlcInfo> {
        self.tlc_state.all_tlcs().filter(|tlc| tlc.is_received())
    }

    pub fn get_all_offer_tlcs(&self) -> impl Iterator<Item = &TlcInfo> {
        self.tlc_state.all_tlcs().filter(|tlc| tlc.is_offered())
    }

    // Get the pubkeys for the tlc. Tlc pubkeys are the pubkeys held by each party
    // while this tlc was created (pubkeys are derived from the commitment number
    // when this tlc was created). The pubkeys returned here are sorted.
    // The offerer who offered this tlc will have the first pubkey, and the receiver
    // will have the second pubkey.
    // This tlc must have valid local_committed_at and remote_committed_at fields.
    pub fn get_tlc_pubkeys(&self, tlc: &TlcInfo) -> (Pubkey, Pubkey) {
        let is_offered = tlc.is_offered();
        let CommitmentNumbers {
            local: local_commitment_number,
            remote: remote_commitment_number,
        } = tlc.get_commitment_numbers();
        debug!(
            "Local commitment number: {}, remote commitment number: {}",
            local_commitment_number, remote_commitment_number
        );
        let local_pubkey = derive_tlc_pubkey(
            &self.get_local_channel_public_keys().tlc_base_key,
            &self.get_local_commitment_point(remote_commitment_number),
        );
        let remote_pubkey = derive_tlc_pubkey(
            &self.get_remote_channel_public_keys().tlc_base_key,
            &self.get_remote_commitment_point(local_commitment_number),
        );

        if is_offered {
            (local_pubkey, remote_pubkey)
        } else {
            (remote_pubkey, local_pubkey)
        }
    }

    fn get_active_received_tlc_with_pubkeys(
        &self,
        for_remote: bool,
    ) -> Vec<(TlcInfo, Pubkey, Pubkey)> {
        self.get_active_received_tlcs(for_remote)
            .into_iter()
            .map(move |tlc| {
                let (k1, k2) = self.get_tlc_pubkeys(&tlc);
                (tlc, k1, k2)
            })
            .collect()
    }

    fn get_active_offered_tlc_with_pubkeys(
        &self,
        for_remote: bool,
    ) -> Vec<(TlcInfo, Pubkey, Pubkey)> {
        self.get_active_offered_tlcs(for_remote)
            .into_iter()
            .map(move |tlc| {
                let (k1, k2) = self.get_tlc_pubkeys(&tlc);
                (tlc, k1, k2)
            })
            .collect()
    }

    fn get_active_htlcs(&self, for_remote: bool) -> Vec<u8> {
        // Build a sorted array of TLC so that both party can generate the same commitment transaction.
        let tlcs = {
            let (mut received_tlcs, mut offered_tlcs) = (
                self.get_active_received_tlc_with_pubkeys(for_remote),
                self.get_active_offered_tlc_with_pubkeys(for_remote),
            );
            let (mut a, mut b) = if for_remote {
                (received_tlcs, offered_tlcs)
            } else {
                for (tlc, _, _) in received_tlcs.iter_mut().chain(offered_tlcs.iter_mut()) {
                    // Need to flip these fields for the counterparty.
                    tlc.flip_mut();
                }
                (offered_tlcs, received_tlcs)
            };
            a.sort_by(|x, y| u64::from(x.0.tlc_id).cmp(&u64::from(y.0.tlc_id)));
            b.sort_by(|x, y| u64::from(x.0.tlc_id).cmp(&u64::from(y.0.tlc_id)));
            [a, b].concat()
        };

        if tlcs.is_empty() {
            Vec::new()
        } else {
            let mut result = vec![tlcs.len() as u8];
            for (tlc, local, remote) in tlcs {
                result.extend_from_slice(&tlc.get_htlc_type().to_le_bytes());
                result.extend_from_slice(&tlc.amount.to_le_bytes());
                result.extend_from_slice(&tlc.get_hash());
                result.extend_from_slice(&local.serialize());
                result.extend_from_slice(&remote.serialize());
                result.extend_from_slice(
                    &Since::new(SinceType::Timestamp, tlc.expiry, false)
                        .value()
                        .to_le_bytes(),
                );
            }
            result
        }
    }

    fn any_tlc_pending(&self) -> bool {
        self.tlc_state
            .all_tlcs()
            .any(|tlc| tlc.removed_reason.is_none())
    }

    pub fn get_local_funding_pubkey(&self) -> &Pubkey {
        &self.get_local_channel_public_keys().funding_pubkey
    }

    pub fn get_remote_funding_pubkey(&self) -> &Pubkey {
        &self.get_remote_channel_public_keys().funding_pubkey
    }

    fn check_valid_to_auto_accept_shutdown(&self) -> bool {
        let Some(remote_fee_rate) = self.remote_shutdown_info.as_ref().map(|i| i.fee_rate) else {
            return false;
        };
        if remote_fee_rate < self.commitment_fee_rate {
            return false;
        }
        let fee = calculate_shutdown_tx_fee(
            remote_fee_rate,
            &self.funding_udt_type_script,
            (
                self.get_remote_shutdown_script(),
                self.get_local_shutdown_script(),
            ),
        );
        let occupied_capacity = match occupied_capacity(
            &self.get_remote_shutdown_script(),
            &self.funding_udt_type_script,
        ) {
            Ok(capacity) => capacity.as_u64(),
            Err(_) => return false,
        };
        let remote_available_max_fee = if self.funding_udt_type_script.is_none() {
            (self.to_remote_amount as u64 + self.remote_reserved_ckb_amount)
                .saturating_sub(occupied_capacity)
        } else {
            self.remote_reserved_ckb_amount
                .saturating_sub(occupied_capacity)
        };
        return fee <= remote_available_max_fee;
    }

    fn check_tlc_expiry(&self, expiry: u64) -> ProcessingChannelResult {
        let current_time = now_timestamp_as_millis_u64();
        if current_time >= expiry {
            debug!(
                "TLC expiry {} is already passed, current time: {}",
                expiry, current_time
            );
            return Err(ProcessingChannelError::TlcExpirySoon);
        }
        if expiry >= current_time + MAX_PAYMENT_TLC_EXPIRY_LIMIT {
            debug!(
                "TLC expiry {} is too far in the future, current time: {}",
                expiry, current_time
            );
            return Err(ProcessingChannelError::TlcExpiryTooFar);
        }
        Ok(())
    }

    fn check_tlc_forward_amount(
        &self,
        forward_amount: u128,
        forward_fee: Option<u128>,
    ) -> ProcessingChannelResult {
        if self.local_tlc_info.tlc_minimum_value != 0
            && forward_amount < self.local_tlc_info.tlc_minimum_value
        {
            return Err(ProcessingChannelError::TlcAmountIsTooLow);
        }
        if self.local_tlc_info.tlc_maximum_value != 0
            && forward_amount > self.local_tlc_info.tlc_minimum_value
        {
            return Err(ProcessingChannelError::TlcAmountExceedLimit);
        }
        let forward_fee = match forward_fee {
            Some(fee) => fee,
            None => {
                // We are not forwarding the tlc, so no need to check the fee.
                return Ok(());
            }
        };
        let fee_rate = self.local_tlc_info.tlc_fee_proportional_millionths;
        let expected_fee = calculate_tlc_forward_fee(forward_amount, fee_rate);
        match expected_fee {
            Ok(expected_fee) if forward_fee >= expected_fee => Ok(()),
            Ok(fee) => {
                error!(
                    "too low forward_fee: {}, expected_fee: {}",
                    forward_fee, fee
                );
                Err(ProcessingChannelError::TlcForwardFeeIsTooLow)
            }
            Err(e) => {
                error!("calculate_tlc_forward_fee error: {:?}", e);
                Err(ProcessingChannelError::TlcForwardFeeIsTooLow)
            }
        }
    }

    // Check whether the reason is valid for removing the tlc.
    fn check_remove_tlc_with_reason(
        &self,
        tlc_id: TLCId,
        reason: &RemoveTlcReason,
    ) -> ProcessingChannelResult {
        if let Some(tlc) = self.tlc_state.get(&tlc_id) {
            if tlc.removed_reason.is_some() {
                return Err(ProcessingChannelError::RepeatedProcessing(
                    "TLC is already removed".to_string(),
                ));
            }
            if (tlc.is_offered() && tlc.outbound_status() != OutboundTlcStatus::Committed)
                || (tlc.is_received() && tlc.inbound_status() != InboundTlcStatus::Committed)
            {
                return Err(ProcessingChannelError::InvalidState(
                    "TLC is not in Committed status".to_string(),
                ));
            }
            if let RemoveTlcReason::RemoveTlcFulfill(fulfill) = reason {
                let filled_payment_hash: Hash256 =
                    tlc.hash_algorithm.hash(fulfill.payment_preimage).into();
                if tlc.payment_hash != filled_payment_hash {
                    // actually this branch should never be reached in normal case
                    // `FinalIncorrectPreimage` will be returned in `apply_add_tlc_operation_with_peeled_onion_packet`
                    // when the preimage is incorrect
                    return Err(ProcessingChannelError::FinalIncorrectPreimage);
                }
            }
            Ok(())
        } else {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Trying to remove non-existing tlc with id {:?}",
                tlc_id
            )));
        }
    }

    fn check_for_tlc_update(
        &self,
        add_tlc_amount: Option<u128>,
        is_tlc_command_message: bool,
        is_sent: bool,
    ) -> ProcessingChannelResult {
        if is_tlc_command_message && self.tlc_state.waiting_ack {
            return Err(ProcessingChannelError::WaitingTlcAck);
        }
        match self.state {
            ChannelState::ChannelReady() => {}
            ChannelState::ShuttingDown(_) if add_tlc_amount.is_none() => {}
            _ => {
                return Err(ProcessingChannelError::InvalidState(format!(
                    "Invalid state {:?} for {} tlc",
                    self.state,
                    if add_tlc_amount.is_some() {
                        "adding"
                    } else {
                        "removing"
                    }
                )))
            }
        }

        if let Some(add_amount) = add_tlc_amount {
            self.check_tlc_limits(add_amount, is_sent)?;
        }
        Ok(())
    }

    fn check_tlc_limits(
        &self,
        add_amount: u128,
        is_sent: bool,
    ) -> Result<(), ProcessingChannelError> {
        if add_amount == 0 {
            return Err(ProcessingChannelError::TlcAmountIsTooLow);
        }
        if is_sent {
            let active_offered_tls_number = self.get_all_offer_tlcs().count() as u64 + 1;
            if active_offered_tls_number > self.local_constraints.max_tlc_number_in_flight {
                return Err(ProcessingChannelError::TlcNumberExceedLimit);
            }

            let active_offered_amount = self
                .get_all_offer_tlcs()
                .fold(0_u128, |sum, tlc| sum + tlc.amount)
                + add_amount;
            if active_offered_amount > self.local_constraints.max_tlc_value_in_flight {
                return Err(ProcessingChannelError::TlcValueInflightExceedLimit);
            }
        } else {
            let active_received_tls_number = self.get_all_received_tlcs().count() as u64 + 1;
            if active_received_tls_number > self.remote_constraints.max_tlc_number_in_flight {
                return Err(ProcessingChannelError::TlcNumberExceedLimit);
            }

            let active_received_amount = self
                .get_all_received_tlcs()
                .fold(0_u128, |sum, tlc| sum + tlc.amount)
                + add_amount;
            if active_received_amount > self.remote_constraints.max_tlc_value_in_flight {
                return Err(ProcessingChannelError::TlcValueInflightExceedLimit);
            }
        }

        Ok(())
    }

    fn create_outbounding_tlc(&self, command: AddTlcCommand) -> TlcInfo {
        let tlc_id = self.get_next_offering_tlc_id();
        assert!(
            self.get_offered_tlc(tlc_id).is_none(),
            "Must not have the same id in pending offered tlcs"
        );

        TlcInfo {
            channel_id: self.get_id(),
            status: TlcStatus::Outbound(OutboundTlcStatus::LocalAnnounced),
            tlc_id,
            amount: command.amount,
            payment_hash: command.payment_hash,
            expiry: command.expiry,
            hash_algorithm: command.hash_algorithm,
            created_at: self.get_current_commitment_numbers(),
            removed_reason: None,
            onion_packet: command.onion_packet,
            shared_secret: command.shared_secret,
            previous_tlc: command.previous_tlc.map(|prev_tlc| {
                (
                    prev_tlc.prev_channel_id,
                    TLCId::Received(prev_tlc.prev_tlc_id),
                )
            }),
            removed_confirmed_at: None,
        }
    }

    fn create_inbounding_tlc(&self, message: AddTlc) -> Result<TlcInfo, ProcessingChannelError> {
        let tlc_info = TlcInfo {
            tlc_id: TLCId::Received(message.tlc_id),
            status: TlcStatus::Inbound(InboundTlcStatus::RemoteAnnounced),
            channel_id: self.get_id(),
            amount: message.amount,
            payment_hash: message.payment_hash,
            expiry: message.expiry,
            hash_algorithm: message.hash_algorithm,
            // will be set when apply AddTlc operations after the signature is checked
            onion_packet: message.onion_packet,
            // No need to save shared secret for inbound TLC.
            shared_secret: NO_SHARED_SECRET,
            created_at: self.get_current_commitment_numbers(),
            removed_reason: None,
            previous_tlc: None,
            removed_confirmed_at: None,
        };
        Ok(tlc_info)
    }

    fn aggregate_partial_signatures_to_consume_funding_cell(
        &self,
        common_ctx: &Musig2CommonContext,
        our_partial_signature: PartialSignature,
        their_partial_signature: PartialSignature,
        tx: &TransactionView,
    ) -> Result<TransactionView, ProcessingChannelError> {
        let signature = common_ctx.aggregate_partial_signatures_for_msg(
            our_partial_signature,
            their_partial_signature,
            tx.hash().as_slice(),
        )?;

        let witness =
            create_witness_for_funding_cell(self.get_funding_lock_script_xonly(), signature);
        Ok(tx
            .as_advanced_builder()
            .set_witnesses(vec![witness.pack()])
            .build())
    }

    fn complete_partially_signed_tx(
        &self,
        psct: &PartiallySignedCommitmentTransaction,
    ) -> Result<(TransactionView, SettlementData), ProcessingChannelError> {
        let completed_commitment_tx = {
            let deterministic_sign_ctx = self.get_deterministic_sign_context();

            let our_funding_tx_partial_signature =
                deterministic_sign_ctx.sign(psct.commitment_tx.hash().as_slice())?;

            self.aggregate_partial_signatures_to_consume_funding_cell(
                &deterministic_sign_ctx.common_ctx,
                our_funding_tx_partial_signature,
                psct.funding_tx_partial_signature,
                &psct.commitment_tx,
            )?
        };

        let settlement_data = {
            let sign_ctx = self.get_sign_context(false);
            let x_only_aggregated_pubkey = sign_ctx.common_ctx.x_only_aggregated_pubkey();

            let settlement_tx = &psct.settlement_tx;
            let commitment_tx = &psct.commitment_tx;
            let to_local_output = settlement_tx
                .outputs()
                .get(0)
                .expect("get output 0 of settlement tx");
            let to_local_output_data = settlement_tx
                .outputs_data()
                .get(0)
                .expect("get output 0 data of settlement tx");
            let to_remote_output = settlement_tx
                .outputs()
                .get(1)
                .expect("get output 1 of settlement tx");
            let to_remote_output_data = settlement_tx
                .outputs_data()
                .get(1)
                .expect("get output 1 data of settlement tx");
            let args = commitment_tx
                .outputs()
                .get(0)
                .expect("get output 0 of commitment tx")
                .lock()
                .args()
                .raw_data();
            let message = blake2b_256(
                [
                    to_local_output.as_slice(),
                    to_local_output_data.as_slice(),
                    to_remote_output.as_slice(),
                    to_remote_output_data.as_slice(),
                    &args[0..36],
                ]
                .concat(),
            );
            let aggregated_signature = sign_ctx
                .sign_and_aggregate(message.as_slice(), psct.commitment_tx_partial_signature)?;

            SettlementData {
                x_only_aggregated_pubkey,
                aggregated_signature,
                to_local_output,
                to_local_output_data,
                to_remote_output,
                to_remote_output_data,
            }
        };

        Ok((completed_commitment_tx, settlement_data))
    }

    fn maybe_transition_to_shutdown(
        &mut self,
        network: &ActorRef<NetworkActorMessage>,
    ) -> ProcessingChannelResult {
        // This function will also be called when we resolve all pending tlcs.
        // If we are not in the ShuttingDown state, we should not do anything.
        let flags = match self.state {
            ChannelState::ShuttingDown(flags) => flags,
            _ => {
                return Ok(());
            }
        };

        if !flags.contains(ShuttingDownFlags::AWAITING_PENDING_TLCS) || self.any_tlc_pending() {
            debug!(
                "Will not shutdown the channel because we require all tlcs resolved and both parties sent the Shutdown message, current state: {:?}, pending tlcs: {:?}",
                &self.state,
                &self.tlc_state.all_commited_tlcs().collect::<Vec<_>>()
            );
            return Ok(());
        }

        debug!("All pending tlcs are resolved, transitioning to Shutdown state");
        self.update_state(ChannelState::ShuttingDown(
            flags | ShuttingDownFlags::DROPPING_PENDING,
        ));

        if self.local_shutdown_info.is_some() && self.remote_shutdown_info.is_some() {
            let shutdown_tx = self.build_shutdown_tx()?;
            let deterministic_sign_ctx = self.get_deterministic_sign_context();

            let local_shutdown_info = self
                .local_shutdown_info
                .as_mut()
                .expect("local shudown info exists");
            let remote_shutdown_info = self
                .remote_shutdown_info
                .as_ref()
                .expect("remote shudown info exists");
            let shutdown_scripts = (
                local_shutdown_info.close_script.clone(),
                remote_shutdown_info.close_script.clone(),
            );
            let local_shutdown_signature = match local_shutdown_info.signature {
                Some(signature) => signature,
                None => {
                    let signature = deterministic_sign_ctx.sign(shutdown_tx.hash().as_slice())?;
                    local_shutdown_info.signature = Some(signature);

                    network
                        .send_message(NetworkActorMessage::new_command(
                            NetworkActorCommand::SendFiberMessage(FiberMessageWithPeerId::new(
                                self.get_remote_peer_id(),
                                FiberMessage::closing_signed(ClosingSigned {
                                    partial_signature: signature,
                                    channel_id: self.get_id(),
                                }),
                            )),
                        ))
                        .expect(ASSUME_NETWORK_ACTOR_ALIVE);
                    signature
                }
            };

            if let Some(remote_shutdown_signature) = remote_shutdown_info.signature {
                let tx: TransactionView = self
                    .aggregate_partial_signatures_to_consume_funding_cell(
                        &deterministic_sign_ctx.common_ctx,
                        local_shutdown_signature,
                        remote_shutdown_signature,
                        &shutdown_tx,
                    )?;
                assert_eq!(
                    tx.data().serialized_size_in_block(),
                    shutdown_tx_size(&self.funding_udt_type_script, shutdown_scripts)
                );

                self.update_state(ChannelState::Closed(CloseFlags::COOPERATIVE));

                network
                    .send_message(NetworkActorMessage::new_event(
                        NetworkActorEvent::ClosingTransactionPending(
                            self.get_id(),
                            self.get_remote_peer_id(),
                            tx,
                        ),
                    ))
                    .expect(ASSUME_NETWORK_ACTOR_ALIVE);
            } else {
                debug!("We have sent our shutdown signature, waiting for counterparty's signature");
            }
        } else {
            debug!("Not ready to shutdown the channel, waiting for both parties to send the Shutdown message");
        }

        Ok(())
    }

    fn handle_accept_channel_message(
        &mut self,
        accept_channel: AcceptChannel,
    ) -> ProcessingChannelResult {
        if self.state != ChannelState::NegotiatingFunding(NegotiatingFundingFlags::OUR_INIT_SENT) {
            return Err(ProcessingChannelError::InvalidState(format!(
                "accepting a channel while in state {:?}, expecting NegotiatingFundingFlags::OUR_INIT_SENT",
                self.state
            )));
        }

        self.update_state(ChannelState::NegotiatingFunding(
            NegotiatingFundingFlags::INIT_SENT,
        ));

        self.to_remote_amount = accept_channel.funding_amount;
        self.remote_reserved_ckb_amount = accept_channel.reserved_ckb_amount;

        self.commit_remote_nonce(accept_channel.next_local_nonce.clone());
        let remote_pubkeys = (&accept_channel).into();
        self.remote_channel_public_keys = Some(remote_pubkeys);
        self.remote_commitment_points = vec![
            (0, accept_channel.first_per_commitment_point),
            (1, accept_channel.second_per_commitment_point),
        ];
        self.remote_shutdown_script = Some(accept_channel.shutdown_script.clone());

        self.remote_constraints = ChannelConstraints::new(
            accept_channel.max_tlc_value_in_flight,
            accept_channel.max_tlc_number_in_flight,
        );

        self.check_accept_channel_parameters()?;

        match accept_channel.channel_announcement_nonce {
            Some(ref nonce) if self.is_public() => {
                debug!("Updating remote channel announcement nonce: {:?}", nonce);
                self.update_remote_channel_announcement_nonce(nonce);
            }
            None if !self.is_public() => {}
            _ => {
                return Err(ProcessingChannelError::InvalidParameter(format!(
                    "Must/Mustn't send announcement nonce if channel is public/private, nonce {:?}, channel is public: {}",
                    &accept_channel.channel_announcement_nonce, self.is_public()
                )));
            }
        }
        debug!(
            "Successfully processed AcceptChannel message {:?}",
            &accept_channel
        );
        Ok(())
    }

    // This is the dual of `handle_tx_collaboration_command`. Any logic error here is likely
    // to present in the other function as well.
    fn handle_tx_collaboration_msg(
        &mut self,
        msg: TxCollaborationMsg,
        network: &ActorRef<NetworkActorMessage>,
    ) -> ProcessingChannelResult {
        debug!("Processing tx collaboration message: {:?}", &msg);
        let is_complete_message = matches!(msg, TxCollaborationMsg::TxComplete(_));
        let is_waiting_for_remote = match self.state {
            ChannelState::CollaboratingFundingTx(flags) => {
                flags.contains(CollaboratingFundingTxFlags::AWAITING_REMOTE_TX_COLLABORATION_MSG)
            }
            _ => false,
        };
        let flags = match self.state {
            // Starting transaction collaboration
            ChannelState::NegotiatingFunding(NegotiatingFundingFlags::INIT_SENT)
                if !self.is_acceptor =>
            {
                return Err(ProcessingChannelError::InvalidState(
                    "Initiator received a tx collaboration message".to_string(),
                ));
            }
            ChannelState::NegotiatingFunding(_) => {
                debug!("Started negotiating funding tx collaboration, and transitioning from {:?} to CollaboratingFundingTx state", self.state);
                self.state =
                    ChannelState::CollaboratingFundingTx(CollaboratingFundingTxFlags::empty());
                CollaboratingFundingTxFlags::empty()
            }
            ChannelState::CollaboratingFundingTx(_)
                if !is_complete_message && !is_waiting_for_remote =>
            {
                return Err(ProcessingChannelError::InvalidState(format!(
                    "Trying to process message {:?} while in {:?} (should only receive non-complete message after sent response from peer)",
                    &msg, self.state
                )));
            }
            ChannelState::CollaboratingFundingTx(flags) => {
                if flags.contains(CollaboratingFundingTxFlags::THEIR_TX_COMPLETE_SENT) {
                    return Err(ProcessingChannelError::InvalidState(format!(
                        "Received a tx collaboration message {:?}, but we are already in the state {:?} where the remote has sent a complete message",
                        &msg, &self.state
                    )));
                }
                debug!(
                    "Processing tx collaboration message {:?} for state {:?}",
                    &msg, &self.state
                );
                flags
            }
            _ => {
                return Err(ProcessingChannelError::InvalidState(format!(
                    "Invalid tx collaboration message {:?} for state {:?}",
                    &msg, &self.state
                )));
            }
        };
        match msg {
            TxCollaborationMsg::TxUpdate(msg) => {
                // TODO check if the tx is valid.
                self.funding_tx = Some(msg.tx.clone());
                if self.is_tx_final(&msg.tx)? {
                    self.maybe_complete_tx_collaboration(msg.tx, network)?;
                } else {
                    network
                        .send_message(NetworkActorMessage::new_command(
                            NetworkActorCommand::UpdateChannelFunding(
                                self.get_id(),
                                msg.tx,
                                self.get_funding_request(),
                            ),
                        ))
                        .expect(ASSUME_NETWORK_ACTOR_ALIVE);
                    self.update_state(ChannelState::CollaboratingFundingTx(
                        CollaboratingFundingTxFlags::PREPARING_LOCAL_TX_COLLABORATION_MSG,
                    ));
                }
            }
            TxCollaborationMsg::TxComplete(tx_complete) => {
                self.check_tx_complete_preconditions()?;
                let settlement_data = self.check_init_commitment_tx_signature(
                    tx_complete.commitment_tx_partial_signature,
                )?;
                network
                    .send_message(NetworkActorMessage::new_notification(
                        NetworkServiceEvent::RemoteTxComplete(
                            self.get_remote_peer_id(),
                            self.get_id(),
                            self.get_funding_lock_script(),
                            settlement_data,
                        ),
                    ))
                    .expect(ASSUME_NETWORK_ACTOR_ALIVE);
                let flags = flags | CollaboratingFundingTxFlags::THEIR_TX_COMPLETE_SENT;
                self.update_state(ChannelState::CollaboratingFundingTx(flags));
            }
        }
        Ok(())
    }

    fn verify_commitment_signed_and_send_ack(
        &mut self,
        commitment_signed: CommitmentSigned,
        network: &ActorRef<NetworkActorMessage>,
    ) -> ProcessingChannelResult {
        let flags = match self.state {
            ChannelState::CollaboratingFundingTx(flags)
                if !flags.contains(CollaboratingFundingTxFlags::COLLABRATION_COMPLETED) =>
            {
                return Err(ProcessingChannelError::InvalidState(format!(
                    "Unable to process commitment_signed message in state {:?}, as collaboration is not completed yet.",
                    &self.state
                )));
            }
            ChannelState::CollaboratingFundingTx(_) => {
                CommitmentSignedFlags::SigningCommitment(SigningCommitmentFlags::empty())
            }
            ChannelState::SigningCommitment(flags)
                if flags.contains(SigningCommitmentFlags::THEIR_COMMITMENT_SIGNED_SENT) =>
            {
                return Err(ProcessingChannelError::InvalidState(format!(
                    "Unable to process commitment_signed message in state {:?}, as we have already received our commitment_signed message.",
                    &self.state
                )));
            }
            ChannelState::SigningCommitment(flags) => {
                CommitmentSignedFlags::SigningCommitment(flags)
            }
            ChannelState::ChannelReady() => CommitmentSignedFlags::ChannelReady(),
            ChannelState::ShuttingDown(flags) => {
                if flags.contains(ShuttingDownFlags::AWAITING_PENDING_TLCS) {
                    debug!(
                        "Signing commitment transactions while shutdown is pending, current state {:?}",
                        &self.state
                    );
                    CommitmentSignedFlags::PendingShutdown()
                } else {
                    return Err(ProcessingChannelError::InvalidState(format!(
                        "Unable to process commitment_signed message in shutdowning state with flags {:?}",
                        &flags
                    )));
                }
            }
            _ => {
                return Err(ProcessingChannelError::InvalidState(format!(
                    "Unable to send commitment signed message in state {:?}",
                    &self.state
                )));
            }
        };

        self.clean_up_failed_tlcs();
        let (commitment_tx, settlement_data) = self.verify_and_complete_tx(
            commitment_signed.funding_tx_partial_signature,
            commitment_signed.commitment_tx_partial_signature,
        )?;

        // Notify outside observers.
        network
            .send_message(NetworkActorMessage::new_notification(
                NetworkServiceEvent::RemoteCommitmentSigned(
                    self.get_remote_peer_id(),
                    self.get_id(),
                    commitment_tx.clone(),
                    settlement_data,
                ),
            ))
            .expect(ASSUME_NETWORK_ACTOR_ALIVE);

        match flags {
            CommitmentSignedFlags::SigningCommitment(flags) => {
                let flags = flags | SigningCommitmentFlags::THEIR_COMMITMENT_SIGNED_SENT;
                self.update_state(ChannelState::SigningCommitment(flags));
                self.maybe_transition_to_tx_signatures(flags, network)?;
            }
            CommitmentSignedFlags::ChannelReady() | CommitmentSignedFlags::PendingShutdown() => {
                self.send_revoke_and_ack_message(network)?;
                match flags {
                    CommitmentSignedFlags::ChannelReady() => {}
                    CommitmentSignedFlags::PendingShutdown() => {
                        // TODO: Handle error in the below function call.
                        // We've already updated our state, we should never fail here.
                        self.maybe_transition_to_shutdown(network)?;
                    }
                    _ => {
                        unreachable!(
                            "Invalid flags for commitment signed message, should have handled {:?}",
                            flags
                        );
                    }
                }
            }
        }
        self.commit_remote_nonce(commitment_signed.next_local_nonce);
        self.latest_commitment_transaction = Some(commitment_tx.data());
        Ok(())
    }

    fn maybe_transition_to_tx_signatures(
        &mut self,
        flags: SigningCommitmentFlags,
        network: &ActorRef<NetworkActorMessage>,
    ) -> ProcessingChannelResult {
        if flags.contains(SigningCommitmentFlags::COMMITMENT_SIGNED_SENT) {
            debug!("Commitment signed message sent by both sides, tranitioning to AwaitingTxSignatures state");
            self.update_state(ChannelState::AwaitingTxSignatures(
                AwaitingTxSignaturesFlags::empty(),
            ));
            if self.should_local_send_tx_signatures_first() {
                debug!("It is our turn to send tx_signatures, so we will do it now.");
                self.handle_tx_signatures(network, None)?;
            }
        }
        Ok(())
    }

    // TODO: currently witnesses in the tx_signatures molecule message are a list of bytes.
    // It is unclear how can we compose two partial sets witnesses into a complete
    // set of witnesses.
    fn handle_tx_signatures(
        &mut self,
        network: &ActorRef<NetworkActorMessage>,
        // If partial_witnesses is given, then it is the counterparty that send a message
        // to us, and we must combine them to make a full list of witnesses.
        // Otherwise, we are the one who is to start send the tx_signatures.
        // We can just create a partial set of witnesses, and sent them to the peer.
        partial_witnesses: Option<Vec<Vec<u8>>>,
    ) -> ProcessingChannelResult {
        let flags = match self.state {
            ChannelState::AwaitingTxSignatures(flags)
                if flags.contains(AwaitingTxSignaturesFlags::THEIR_TX_SIGNATURES_SENT)
                    && partial_witnesses.is_some() =>
            {
                return Err(ProcessingChannelError::RepeatedProcessing(format!(
                    "tx_signatures partial witnesses {:?}",
                    partial_witnesses
                )));
            }
            ChannelState::AwaitingTxSignatures(flags)
                if flags.contains(AwaitingTxSignaturesFlags::OUR_TX_SIGNATURES_SENT)
                    && partial_witnesses.is_none() =>
            {
                return Err(ProcessingChannelError::RepeatedProcessing(
                    "We have already sent our tx_signatures".to_string(),
                ));
            }
            ChannelState::SigningCommitment(flags)
                if flags.contains(SigningCommitmentFlags::COMMITMENT_SIGNED_SENT) =>
            {
                AwaitingTxSignaturesFlags::empty()
            }
            ChannelState::AwaitingTxSignatures(flags) => flags,
            _ => {
                return Err(ProcessingChannelError::InvalidState(format!(
                    "Unable to build and sign funding tx in state {:?}",
                    &self.state
                )));
            }
        };

        let flags = if partial_witnesses.is_some() {
            flags | AwaitingTxSignaturesFlags::THEIR_TX_SIGNATURES_SENT
        } else {
            flags | AwaitingTxSignaturesFlags::OUR_TX_SIGNATURES_SENT
        };
        self.update_state(ChannelState::AwaitingTxSignatures(flags));

        let funding_tx = self
            .funding_tx
            .clone()
            .ok_or(ProcessingChannelError::InvalidState(
                "Funding transaction is not present".to_string(),
            ))?;

        network
            .send_message(NetworkActorMessage::new_command(
                NetworkActorCommand::SignTx(
                    self.get_remote_peer_id(),
                    self.get_id(),
                    funding_tx,
                    partial_witnesses,
                ),
            ))
            .expect(ASSUME_NETWORK_ACTOR_ALIVE);
        let flags = flags | AwaitingTxSignaturesFlags::OUR_TX_SIGNATURES_SENT;
        self.update_state(ChannelState::AwaitingTxSignatures(flags));

        Ok(())
    }

    async fn maybe_public_channel_is_ready(&mut self, network: &ActorRef<NetworkActorMessage>) {
        debug!("Trying to create channel announcement message for public channel");
        if let Some((channel_announcement, channel_update)) =
            self.try_create_channel_messages(network).await
        {
            debug!(
                "Channel announcement/update message for {:?} created, public channel is ready",
                self.get_id(),
            );
            self.on_channel_ready(network).await;

            debug!(
                "Broadcasting channel announcement {:?} and channel update {:?}",
                &channel_announcement, &channel_update
            );
            network
                .send_message(NetworkActorMessage::new_command(
                    NetworkActorCommand::BroadcastMessages(vec![
                        BroadcastMessageWithTimestamp::ChannelAnnouncement(
                            self.must_get_funding_transaction_timestamp(),
                            channel_announcement,
                        ),
                        BroadcastMessageWithTimestamp::ChannelUpdate(channel_update),
                    ]),
                ))
                .expect(ASSUME_NETWORK_ACTOR_ALIVE);

            // Note that there is a racing condition here. The peer may have not finished
            // generating the channel update message yet. In order to reliably query the
            // peer for the channel update message, we may to retry the query a few times.
            let peer_id = self.get_remote_peer_id();
            let queries = if self.local_is_node1() {
                vec![
                    BroadcastMessageQuery {
                        channel_outpoint: self.must_get_funding_transaction_outpoint(),
                        flags: BroadcastMessageQueryFlags::ChannelUpdateOfNode2,
                    },
                    BroadcastMessageQuery {
                        channel_outpoint: self.must_get_funding_transaction_outpoint(),
                        flags: BroadcastMessageQueryFlags::NodeAnnouncementNode2,
                    },
                ]
            } else {
                vec![
                    BroadcastMessageQuery {
                        channel_outpoint: self.must_get_funding_transaction_outpoint(),
                        flags: BroadcastMessageQueryFlags::ChannelUpdateOfNode1,
                    },
                    BroadcastMessageQuery {
                        channel_outpoint: self.must_get_funding_transaction_outpoint(),
                        flags: BroadcastMessageQueryFlags::NodeAnnouncementNode1,
                    },
                ]
            };
            debug!(
                "Querying for channel update and node announcement messages from {:?}",
                &peer_id
            );
            network
                .send_message(NetworkActorMessage::new_command(
                    NetworkActorCommand::QueryBroadcastMessages(peer_id, queries),
                ))
                .expect(ASSUME_NETWORK_ACTOR_ALIVE);
        }
    }

    async fn maybe_channel_is_ready(&mut self, network: &ActorRef<NetworkActorMessage>) {
        match self.state {
            ChannelState::AwaitingChannelReady(flags) => {
                if flags.contains(AwaitingChannelReadyFlags::CHANNEL_READY) {
                    if !self.is_public() {
                        self.on_channel_ready(network).await;
                    } else {
                        self.maybe_public_channel_is_ready(network).await;
                    }
                }
            }
            _ => {
                panic!(
                    "Invalid state {:?} for maybe_on_channel_ready (expected AwaitingChannelReady)",
                    &self.state
                );
            }
        }
    }

    async fn on_channel_ready(&mut self, network: &ActorRef<NetworkActorMessage>) {
        self.update_state(ChannelState::ChannelReady());
        self.increment_local_commitment_number();
        self.increment_remote_commitment_number();
        let peer_id = self.get_remote_peer_id();
        self.notify_owned_channel_updated(network, false).await;
        network
            .send_message(NetworkActorMessage::new_event(
                NetworkActorEvent::ChannelReady(
                    self.get_id(),
                    peer_id.clone(),
                    self.must_get_funding_transaction_outpoint(),
                ),
            ))
            .expect(ASSUME_NETWORK_ACTOR_ALIVE);
    }

    fn append_remote_commitment_point(&mut self, commitment_point: Pubkey) {
        self.remote_commitment_points
            .push((self.get_local_commitment_number(), commitment_point));

        // shrink the remote commitment points list
        // TODO: use all_tlcs as filter instead of select the minimal commitment number
        let len = self.remote_commitment_points.len();
        if len > (self.local_constraints.max_tlc_number_in_flight + 1) as usize {
            let min_remote_commitment = self
                .tlc_state
                .all_tlcs()
                .map(|x| x.created_at.remote.min(x.created_at.local))
                .min()
                .unwrap_or_default();
            self.remote_commitment_points
                .retain(|(num, _)| *num >= min_remote_commitment);
        }
    }

    fn handle_revoke_and_ack_peer_message(
        &mut self,
        network: &ActorRef<NetworkActorMessage>,
        revoke_and_ack: RevokeAndAck,
    ) -> Result<bool, ProcessingChannelError> {
        if !self.tlc_state.waiting_ack {
            return Err(ProcessingChannelError::InvalidState(
                "unexpected RevokeAndAck message".to_string(),
            ));
        }
        let RevokeAndAck {
            channel_id: _,
            revocation_partial_signature,
            commitment_tx_partial_signature,
            next_per_commitment_point,
        } = revoke_and_ack;

        let sign_ctx = self.get_sign_context_for_revoke_and_ack_message()?;
        let x_only_aggregated_pubkey = sign_ctx.common_ctx.x_only_aggregated_pubkey();

        let revocation_data = {
            let commitment_tx_fee = calculate_commitment_tx_fee(
                self.commitment_fee_rate,
                &self.funding_udt_type_script,
            );
            let lock_script = self.get_local_shutdown_script();
            let (output, output_data) = if let Some(udt_type_script) = &self.funding_udt_type_script
            {
                let capacity = self.get_total_reserved_ckb_amount() - commitment_tx_fee;
                let output = CellOutput::new_builder()
                    .lock(lock_script.clone())
                    .type_(Some(udt_type_script.clone()).pack())
                    .capacity(capacity.pack())
                    .build();

                let output_data = self.get_total_udt_amount().to_le_bytes().pack();
                (output, output_data)
            } else {
                let capacity = self.get_total_ckb_amount() - commitment_tx_fee;
                let output = CellOutput::new_builder()
                    .lock(lock_script.clone())
                    .capacity(capacity.pack())
                    .build();
                let output_data = Bytes::default();
                (output, output_data)
            };

            let commitment_number = self.get_local_commitment_number() - 1;
            let commitment_lock_script_args = [
                &blake2b_256(x_only_aggregated_pubkey)[0..20],
                self.get_delay_epoch_as_lock_args_bytes().as_slice(),
                commitment_number.to_be_bytes().as_slice(),
            ]
            .concat();

            let message = blake2b_256(
                [
                    output.as_slice(),
                    output_data.as_slice(),
                    commitment_lock_script_args.as_slice(),
                ]
                .concat(),
            );

            let aggregated_signature =
                sign_ctx.sign_and_aggregate(message.as_slice(), revocation_partial_signature)?;
            RevocationData {
                commitment_number,
                x_only_aggregated_pubkey,
                aggregated_signature,
                output,
                output_data,
            }
        };

        let settlement_data = {
            let (
                [to_local_output, to_remote_output],
                [to_local_output_data, to_remote_output_data],
            ) = self.build_settlement_transaction_outputs(true);
            let commitment_lock_script_args = [
                &blake2b_256(x_only_aggregated_pubkey)[0..20],
                self.get_delay_epoch_as_lock_args_bytes().as_slice(),
                self.get_local_commitment_number().to_be_bytes().as_slice(),
            ]
            .concat();
            let message = blake2b_256(
                [
                    to_local_output.as_slice(),
                    to_local_output_data.as_slice(),
                    to_remote_output.as_slice(),
                    to_remote_output_data.as_slice(),
                    commitment_lock_script_args.as_slice(),
                ]
                .concat(),
            );

            let aggregated_signature =
                sign_ctx.sign_and_aggregate(message.as_slice(), commitment_tx_partial_signature)?;

            SettlementData {
                x_only_aggregated_pubkey,
                aggregated_signature,
                to_local_output,
                to_local_output_data,
                to_remote_output,
                to_remote_output_data,
            }
        };

        self.increment_local_commitment_number();
        self.append_remote_commitment_point(next_per_commitment_point);

        let need_commitment_signed = self
            .tlc_state
            .update_for_revoke_and_ack(self.commitment_numbers);
        network
            .send_message(NetworkActorMessage::new_notification(
                NetworkServiceEvent::RevokeAndAckReceived(
                    self.get_remote_peer_id(),
                    self.get_id(),
                    revocation_data,
                    settlement_data,
                ),
            ))
            .expect(ASSUME_NETWORK_ACTOR_ALIVE);
        Ok(need_commitment_signed)
    }

    async fn handle_reestablish_channel_message(
        &mut self,
        reestablish_channel: &ReestablishChannel,
        network: &ActorRef<NetworkActorMessage>,
    ) -> ProcessingChannelResult {
        debug!(
            "Handling reestablish channel message: {:?}, our commitment_numbers {:?} in channel state {:?}",
            reestablish_channel, self.commitment_numbers, self.state
        );
        self.reestablishing = false;
        match self.state {
            ChannelState::NegotiatingFunding(_flags) => {
                // TODO: in current implementation, we don't store the channel when we are in NegotiatingFunding state.
                // This is an unreachable state for reestablish channel message. we may need to handle this case in the future.
            }
            ChannelState::ChannelReady() => {
                let expected_local_commitment_number = self.get_local_commitment_number();
                let acutal_local_commitment_number = reestablish_channel.remote_commitment_number;
                if acutal_local_commitment_number == expected_local_commitment_number {
                    // resend AddTlc, RemoveTlc and CommitmentSigned messages if needed
                    let mut need_resend_commitment_signed = false;
                    for info in self.tlc_state.all_tlcs() {
                        if info.is_offered()
                            && matches!(info.outbound_status(), OutboundTlcStatus::LocalAnnounced)
                        {
                            // resend AddTlc message
                            network
                                .send_message(NetworkActorMessage::new_command(
                                    NetworkActorCommand::SendFiberMessage(
                                        FiberMessageWithPeerId::new(
                                            self.get_remote_peer_id(),
                                            FiberMessage::add_tlc(AddTlc {
                                                channel_id: self.get_id(),
                                                tlc_id: info.tlc_id.into(),
                                                amount: info.amount,
                                                payment_hash: info.payment_hash,
                                                expiry: info.expiry,
                                                hash_algorithm: info.hash_algorithm,
                                                onion_packet: info.onion_packet.clone(),
                                            }),
                                        ),
                                    ),
                                ))
                                .expect(ASSUME_NETWORK_ACTOR_ALIVE);
                            need_resend_commitment_signed = true;
                            debug_event!(network, "resend add tlc");
                        } else if let Some(remove_reason) = &info.removed_reason {
                            if info.is_received()
                                && matches!(info.inbound_status(), InboundTlcStatus::LocalRemoved)
                            {
                                // resend RemoveTlc message
                                network
                                    .send_message(NetworkActorMessage::new_command(
                                        NetworkActorCommand::SendFiberMessage(
                                            FiberMessageWithPeerId::new(
                                                self.get_remote_peer_id(),
                                                FiberMessage::remove_tlc(RemoveTlc {
                                                    channel_id: self.get_id(),
                                                    tlc_id: info.tlc_id.into(),
                                                    reason: remove_reason.clone(),
                                                }),
                                            ),
                                        ),
                                    ))
                                    .expect(ASSUME_NETWORK_ACTOR_ALIVE);

                                need_resend_commitment_signed = true;
                                debug_event!(network, "resend remove tlc");
                            }
                        }
                    }
                    // previous waiting_ack maybe true, reset it after reestablish the channel
                    // if we need to resend CommitmentSigned message, it will be set to proper status again
                    self.tlc_state.set_waiting_ack(false);
                    debug!(
                        "Resend AddTlc and RemoveTlc messages if needed: {}",
                        need_resend_commitment_signed
                    );
                    if need_resend_commitment_signed
                        || self.tlc_state.need_another_commitment_signed()
                    {
                        debug!("Resend CommitmentSigned message");
                        network
                            .send_message(NetworkActorMessage::new_command(
                                NetworkActorCommand::ControlFiberChannel(ChannelCommandWithId {
                                    channel_id: self.get_id(),
                                    command: ChannelCommand::CommitmentSigned(),
                                }),
                            ))
                            .expect(ASSUME_NETWORK_ACTOR_ALIVE);
                    }
                } else if acutal_local_commitment_number == expected_local_commitment_number + 1 {
                    // wait for remote to resend the RevokeAndAck message, do nothing here
                    warn!("wait for remote to resend the RevokeAndAck message, do nothing here");
                } else {
                    // unreachable state, just log an error for potential bugs
                    error!(
                        "Reestablish channel message with invalid local commitment number: expected {}, actual {}",
                        expected_local_commitment_number, acutal_local_commitment_number
                    );
                }

                let expected_remote_commitment_number = self.get_remote_commitment_number();
                let acutal_remote_commitment_number = reestablish_channel.local_commitment_number;
                if expected_remote_commitment_number == acutal_remote_commitment_number {
                    // synced with remote, do nothing
                } else if expected_remote_commitment_number == acutal_remote_commitment_number + 1 {
                    // Resetting our remote commitment number to the actual remote commitment number
                    // and resend the RevokeAndAck message.
                    self.set_remote_commitment_number(acutal_remote_commitment_number);
                    // Resetting the remote nonce to build the RevokeAndAck message
                    let last_commited_nonce = self.get_last_committed_remote_nonce();
                    let used_nonce = self
                        .last_revoke_and_ack_remote_nonce
                        .as_ref()
                        .expect("must have set last_revoke_and_ack_remote_nonce")
                        .clone();
                    self.commit_remote_nonce(used_nonce);
                    self.send_revoke_and_ack_message(network)?;
                    // Now we can reset the remote nonce to the "real" last committed nonce
                    self.commit_remote_nonce(last_commited_nonce);
                    let need_commitment_signed = self.tlc_state.update_for_commitment_signed();
                    if need_commitment_signed {
                        network
                            .send_message(NetworkActorMessage::new_command(
                                NetworkActorCommand::ControlFiberChannel(ChannelCommandWithId {
                                    channel_id: self.get_id(),
                                    command: ChannelCommand::CommitmentSigned(),
                                }),
                            ))
                            .expect(ASSUME_NETWORK_ACTOR_ALIVE);
                    }
                } else {
                    // unreachable state, just log an error for potential bugs
                    error!(
                        "Reestablish channel message with invalid remote commitment number: expected {}, actual {}",
                        expected_remote_commitment_number, acutal_remote_commitment_number
                    );
                }

                self.notify_owned_channel_updated(network, false).await;

                debug_event!(network, "Reestablished channel in ChannelReady");
            }
            _ => {
                // TODO: @quake we need to handle other states.
                warn!(
                    "Unhandled reestablish channel message in state {:?}",
                    &self.state
                );
            }
        }
        Ok(())
    }

    fn is_tx_final(&self, tx: &Transaction) -> Result<bool, ProcessingChannelError> {
        // TODO: check if the tx is valid
        let tx = tx.clone().into_view();

        let first_output = tx
            .outputs()
            .get(0)
            .ok_or(ProcessingChannelError::InvalidParameter(
                "Funding transaction should have at least one output".to_string(),
            ))?;

        if first_output.lock() != self.get_funding_lock_script() {
            return Err(ProcessingChannelError::InvalidState(
                "Invalid funding transation lock script".to_string(),
            ));
        }

        let current_capacity: u64 = first_output.capacity().unpack();

        // make sure both parties have paid the reserved ckb amount
        if current_capacity <= self.local_reserved_ckb_amount
            || current_capacity <= self.remote_reserved_ckb_amount
        {
            return Ok(false);
        }

        if self.funding_udt_type_script.is_some() {
            let (_output, data) =
                tx.output_with_data(0)
                    .ok_or(ProcessingChannelError::InvalidParameter(
                        "Funding transaction should have at least one output".to_string(),
                    ))?;
            assert!(data.as_ref().len() >= 16);
            let mut amount_bytes = [0u8; 16];
            amount_bytes.copy_from_slice(&data.as_ref()[0..16]);
            let udt_amount = u128::from_le_bytes(amount_bytes);
            debug!(
                "udt_amount: {}, to_remote_amount: {}, to_local_amount: {}",
                udt_amount, self.to_remote_amount, self.to_local_amount
            );
            debug!("current_capacity: {}, remote_reserved_ckb_amount: {}, local_reserved_ckb_amount: {}",
                current_capacity, self.remote_reserved_ckb_amount, self.local_reserved_ckb_amount);
            let is_udt_amount_ok = udt_amount == self.get_total_udt_amount();
            return Ok(is_udt_amount_ok);
        } else {
            let is_complete = current_capacity == self.get_total_ckb_amount();
            Ok(is_complete)
        }
    }

    fn maybe_complete_tx_collaboration(
        &mut self,
        tx: Transaction,
        network: &ActorRef<NetworkActorMessage>,
    ) -> ProcessingChannelResult {
        let is_complete = self.is_tx_final(&tx)?;

        debug!(
            "Checking if funding transaction {:?} is complete: {}",
            &tx, is_complete
        );

        if is_complete {
            // We need to send a SendFiberMessage command here (instead of a ControlFiberChannel),
            // to guarantee that the TxComplete message immediately is sent to the network actor.
            // Otherwise, it is possible that when the network actor is processing ControlFiberChannel,
            // it receives another SendFiberMessage command, and that message (e.g. CommitmentSigned)
            // is processed first, thus breaking the order of messages.
            let commitment_tx_partial_signature = self.build_init_commitment_tx_signature()?;
            network
                .send_message(NetworkActorMessage::new_command(
                    NetworkActorCommand::SendFiberMessage(FiberMessageWithPeerId::new(
                        self.get_remote_peer_id(),
                        FiberMessage::tx_complete(TxComplete {
                            channel_id: self.get_id(),
                            commitment_tx_partial_signature,
                        }),
                    )),
                ))
                .expect(ASSUME_NETWORK_ACTOR_ALIVE);
            let old_flags = match self.state {
                ChannelState::CollaboratingFundingTx(flags) => flags,
                _ => {
                    panic!(
                        "Expect to be in CollaboratingFundingTx state while running update_funding_tx, current state {:?}", &self.state,
                    );
                }
            };
            self.update_state(ChannelState::CollaboratingFundingTx(
                old_flags | CollaboratingFundingTxFlags::OUR_TX_COMPLETE_SENT,
            ));
        }
        Ok(())
    }

    fn build_init_commitment_tx_signature(&self) -> Result<PartialSignature, SigningError> {
        let sign_ctx = self.get_sign_context(false);
        let x_only_aggregated_pubkey = sign_ctx.common_ctx.x_only_aggregated_pubkey();
        let ([to_local_output, to_remote_output], [to_local_output_data, to_remote_output_data]) =
            self.build_settlement_transaction_outputs(false);
        let version = 0u64;
        let commitment_lock_script_args = [
            &blake2b_256(x_only_aggregated_pubkey)[0..20],
            self.get_delay_epoch_as_lock_args_bytes().as_slice(),
            version.to_be_bytes().as_slice(),
        ]
        .concat();
        let message = blake2b_256(
            [
                to_local_output.as_slice(),
                to_local_output_data.as_slice(),
                to_remote_output.as_slice(),
                to_remote_output_data.as_slice(),
                commitment_lock_script_args.as_slice(),
            ]
            .concat(),
        );

        let signature = sign_ctx.sign(message.as_slice());
        signature
    }

    fn check_init_commitment_tx_signature(
        &self,
        signature: PartialSignature,
    ) -> Result<SettlementData, ProcessingChannelError> {
        let sign_ctx = self.get_sign_context(true);
        let x_only_aggregated_pubkey = sign_ctx.common_ctx.x_only_aggregated_pubkey();

        let ([to_local_output, to_remote_output], [to_local_output_data, to_remote_output_data]) =
            self.build_settlement_transaction_outputs(true);
        let version = 0u64;
        let commitment_lock_script_args = [
            &blake2b_256(x_only_aggregated_pubkey)[0..20],
            self.get_delay_epoch_as_lock_args_bytes().as_slice(),
            version.to_be_bytes().as_slice(),
        ]
        .concat();
        let message = blake2b_256(
            [
                to_local_output.as_slice(),
                to_local_output_data.as_slice(),
                to_remote_output.as_slice(),
                to_remote_output_data.as_slice(),
                commitment_lock_script_args.as_slice(),
            ]
            .concat(),
        );

        let settlement_data = {
            let aggregated_signature =
                sign_ctx.sign_and_aggregate(message.as_slice(), signature)?;

            SettlementData {
                x_only_aggregated_pubkey,
                aggregated_signature,
                to_local_output,
                to_local_output_data,
                to_remote_output,
                to_remote_output_data,
            }
        };
        Ok(settlement_data)
    }

    // TODO: More checks to the funding tx.
    fn check_tx_complete_preconditions(&mut self) -> ProcessingChannelResult {
        match self.funding_tx.as_ref() {
            None => {
                return Err(ProcessingChannelError::InvalidState(
                    "Received TxComplete message without a funding transaction".to_string(),
                ));
            }
            Some(tx) => {
                debug!(
                    "Received TxComplete message, funding tx is present {:?}",
                    tx
                );
                let check = self.is_tx_final(tx);
                if !check.is_ok_and(|ok| ok) {
                    return Err(ProcessingChannelError::InvalidState(
                        "Received TxComplete message, but funding tx is not final".to_string(),
                    ));
                }
            }
        }
        Ok(())
    }

    fn fill_in_channel_id(&mut self) {
        let local = &self.get_local_channel_public_keys().tlc_base_key;
        let remote = &self.get_remote_channel_public_keys().tlc_base_key;
        let channel_id = derive_channel_id_from_tlc_keys(local, remote);
        debug!("Channel Id changed from {:?} to {:?}", self.id, channel_id,);
        self.id = channel_id;
    }

    // Whose pubkey should go first in musig2?
    // We define a definitive order for the pubkeys in musig2 to makes it easier
    // to aggregate musig2 signatures.
    fn should_local_go_first_in_musig2(&self) -> bool {
        let local_pubkey = self.get_local_channel_public_keys().funding_pubkey;
        let remote_pubkey = self.get_remote_channel_public_keys().funding_pubkey;
        local_pubkey <= remote_pubkey
    }

    // Order some items (like pubkey and nonce) from local and remote in musig2.
    fn order_things_for_musig2<T>(&self, local: T, remote: T) -> [T; 2] {
        if self.should_local_go_first_in_musig2() {
            [local, remote]
        } else {
            [remote, local]
        }
    }

    fn get_deterministic_common_context(&self) -> Musig2CommonContext {
        let local_first = self.should_local_go_first_in_musig2();
        let key_agg_ctx = self.get_deterministic_musig2_agg_context();
        let remote_nonce = self.get_last_committed_remote_nonce();
        let local_nonce = self.get_local_musig2_pubnonce();
        let agg_nonce = AggNonce::sum(if local_first {
            [local_nonce, remote_nonce]
        } else {
            [remote_nonce, local_nonce]
        });
        Musig2CommonContext {
            local_first,
            key_agg_ctx,
            agg_nonce,
        }
    }

    // A deterministic `Musig2VerifyContext` is a verifying context that has the same basic configuration
    // for both parties. This is mostly used by us to verify transactions to consume the funding cell,
    // which uses a deterministic aggregated pubkey for both parties.
    fn get_deterministic_verify_context(&self) -> Musig2VerifyContext {
        let common_ctx = self.get_deterministic_common_context();
        Musig2VerifyContext {
            common_ctx,
            pubkey: *self.get_remote_funding_pubkey(),
            pubnonce: self.get_last_committed_remote_nonce(),
        }
    }

    fn get_verify_context(&self) -> Musig2VerifyContext {
        // We are always verifying a commitment transaction that is broadcast by us,
        // so we can always pass false to get_musig2_common_ctx.
        let common_ctx = self.get_musig2_common_ctx(false);

        Musig2VerifyContext {
            common_ctx,
            pubkey: *self.get_remote_funding_pubkey(),
            pubnonce: self.get_last_committed_remote_nonce(),
        }
    }

    // A deterministic `Musig2SignContext` is a signing context that has the same basic configuration
    // for both parties. This is mostly used by us to sign transactions to consume the funding cell,
    // which uses a deterministic aggregated pubkey for both parties.
    fn get_deterministic_sign_context(&self) -> Musig2SignContext {
        let common_ctx = self.get_deterministic_common_context();
        Musig2SignContext {
            common_ctx,
            seckey: self.signer.funding_key.clone(),
            secnonce: self.get_local_musig2_secnonce(),
        }
    }

    // This function is used to construct a `Musig2SignContext` with which we can easily sign
    // and aggregate partial signatures. The parameter for_remote is used to indicate the direction
    // of commitment transation (just like the same parameter used in building commitment transactions).
    // This is also due to the fact commitment transactions are asymmetrical (A's broadcastable commitment
    // transactions are different from B's broadcastable commitment transactions), sometimes we need to
    // construct different `Musig2SignContext` depending on the direction of commitment transaction.
    // For example, the `Musig2SignContext`s used by A to construct `CommitmentSigned` and `RevokeAndAck`
    // messages to B are different. A needs to build a commitment transaction that is broadcast by B
    // to construct a `CommitmentSigned` message, but when constructing `RevokeAndAck` A needs to
    // build an old commitment transaction that is broadcast by himself. This is the reason why
    // we need a `for_remote` parameter. It serves the same function as `for_remote` in functions
    // like `build_commitment_and_settlement_tx`.
    fn get_sign_context(&self, for_remote: bool) -> Musig2SignContext {
        let common_ctx = self.get_musig2_common_ctx(for_remote);

        Musig2SignContext {
            common_ctx,
            seckey: self.signer.funding_key.clone(),
            secnonce: self.get_local_musig2_secnonce(),
        }
    }

    // As explained in the documentation of `last_used_remote_nonce` field, we need to
    // use a saved remote nonce because the latest remote nonce may be different from the
    // one we used while sending CommitmentSigned message.
    fn get_sign_context_for_revoke_and_ack_message(
        &self,
    ) -> Result<Musig2SignContext, ProcessingChannelError> {
        let common_ctx = {
            let local_pubkey = self.get_local_channel_public_keys().funding_pubkey;
            let remote_pubkey = self.get_remote_channel_public_keys().funding_pubkey;
            let pubkeys = [local_pubkey, remote_pubkey];
            let key_agg_ctx = KeyAggContext::new(pubkeys).expect("Valid pubkeys");
            let remote_nonce =
                self.get_last_commitment_signed_remote_nonce()
                    .ok_or(ProcessingChannelError::InvalidState(
                        "No last used remote nonce found, has the peer sent a RevokeAndAck without us sending CommitmentSigned"
                            .to_string(),
                    ))?;
            let local_nonce = self.get_local_musig2_pubnonce();
            let agg_nonce = AggNonce::sum([local_nonce, remote_nonce]);
            Musig2CommonContext {
                local_first: true,
                key_agg_ctx,
                agg_nonce,
            }
        };

        Ok(Musig2SignContext {
            common_ctx,
            seckey: self.signer.funding_key.clone(),
            secnonce: self.get_local_musig2_secnonce(),
        })
    }

    // Should the local send tx_signatures first?
    // In order to avoid deadlock, we need to define an order for sending tx_signatures.
    // Currently the order of sending tx_signatures is defined as follows:
    // If the amount to self is less than the amount to remote, then we should send,
    // else if the amount to self is equal to the amount to remote and we have
    // smaller funding_pubkey, then we should send first. Otherwise, we should wait
    // the counterparty to send tx_signatures first.
    fn should_local_send_tx_signatures_first(&self) -> bool {
        self.to_local_amount < self.to_remote_amount
            || self.to_local_amount == self.to_remote_amount
                && self.should_local_go_first_in_musig2()
    }

    fn build_shutdown_tx(&self) -> Result<TransactionView, ProcessingChannelError> {
        let local_shutdown_info = self
            .local_shutdown_info
            .as_ref()
            .expect("local shutdown info exists");
        let remote_shutdown_info = self
            .remote_shutdown_info
            .as_ref()
            .expect("remote shutdown info exists");

        let local_shutdown_script = local_shutdown_info.close_script.clone();
        let remote_shutdown_script = remote_shutdown_info.close_script.clone();
        let local_shutdown_fee = calculate_shutdown_tx_fee(
            local_shutdown_info.fee_rate,
            &self.funding_udt_type_script,
            (
                remote_shutdown_script.clone(),
                local_shutdown_script.clone(),
            ),
        );
        let remote_shutdown_fee = calculate_shutdown_tx_fee(
            remote_shutdown_info.fee_rate,
            &self.funding_udt_type_script,
            (
                local_shutdown_script.clone(),
                remote_shutdown_script.clone(),
            ),
        );

        debug!(
            "build_shutdown_tx local_shutdown_fee: local {}, remote {}",
            local_shutdown_fee, remote_shutdown_fee
        );

        let cell_deps = get_cell_deps(vec![Contract::FundingLock], &self.funding_udt_type_script);
        let tx_builder = TransactionBuilder::default().cell_deps(cell_deps).input(
            CellInput::new_builder()
                .previous_output(self.must_get_funding_transaction_outpoint())
                .build(),
        );

        if let Some(type_script) = &self.funding_udt_type_script {
            debug!(
                "shutdown UDT local_amount: {}, remote_amount: {}",
                self.to_local_amount, self.to_remote_amount
            );

            let local_capacity: u64 = self.local_reserved_ckb_amount - local_shutdown_fee;
            debug!(
                "shutdown_tx local_capacity: {} - {} = {}",
                self.local_reserved_ckb_amount, local_shutdown_fee, local_capacity
            );
            let to_local_output = CellOutput::new_builder()
                .lock(local_shutdown_script)
                .type_(Some(type_script.clone()).pack())
                .capacity(local_capacity.pack())
                .build();
            let to_local_output_data = self.to_local_amount.to_le_bytes().pack();

            let remote_capacity: u64 = self.remote_reserved_ckb_amount - remote_shutdown_fee;
            debug!(
                "shutdown_tx remote_capacity: {} - {} = {}",
                self.remote_reserved_ckb_amount, remote_shutdown_fee, remote_capacity
            );
            let to_remote_output = CellOutput::new_builder()
                .lock(remote_shutdown_script)
                .type_(Some(type_script.clone()).pack())
                .capacity(remote_capacity.pack())
                .build();
            let to_remote_output_data = self.to_remote_amount.to_le_bytes().pack();

            let outputs = self.order_things_for_musig2(to_local_output, to_remote_output);
            let outputs_data =
                self.order_things_for_musig2(to_local_output_data, to_remote_output_data);
            let tx = tx_builder
                .set_outputs(outputs.to_vec())
                .set_outputs_data(outputs_data.to_vec())
                .build();
            Ok(tx)
        } else {
            debug!(
                "Final balance partition before shutting down: local {} (fee {}), remote {} (fee {})",
                self.to_local_amount, local_shutdown_fee,
                self.to_remote_amount, remote_shutdown_fee
            );
            let local_value =
                self.to_local_amount as u64 + self.local_reserved_ckb_amount - local_shutdown_fee;
            let remote_value = self.to_remote_amount as u64 + self.remote_reserved_ckb_amount
                - remote_shutdown_fee;
            debug!(
                "Building shutdown transaction with values: local {}, remote {}",
                local_value, remote_value
            );
            let to_local_output = CellOutput::new_builder()
                .capacity(local_value.pack())
                .lock(local_shutdown_script)
                .build();
            let to_remote_output = CellOutput::new_builder()
                .capacity(remote_value.pack())
                .lock(remote_shutdown_script)
                .build();
            let outputs = self.order_things_for_musig2(to_local_output, to_remote_output);
            let tx = tx_builder
                .set_outputs(outputs.to_vec())
                .set_outputs_data(vec![Default::default(), Default::default()])
                .build();
            Ok(tx)
        }
    }

    // The parameter `for_remote` here specifies whether we are building the commitment transaction
    // for the local party or the remote party. If `for_remote` is false, then we are building a
    // commitment transaction which can be broadcasted by ourself (with valid partial
    // signature from the other party), else we are building a commitment transaction
    // for the remote party (we build this commitment transaction
    // normally because we want to send a partial signature to remote).
    // The function returns a tuple, the first element is the commitment transaction itself,
    // and the second element is the message to be signed by the each party,
    // so as to consume the funding cell. The last element is the witnesses for the
    // commitment transaction.
    fn build_commitment_and_settlement_tx(
        &self,
        for_remote: bool,
    ) -> (TransactionView, TransactionView) {
        let commitment_tx = {
            let funding_out_point = self.must_get_funding_transaction_outpoint();
            let cell_deps =
                get_cell_deps(vec![Contract::FundingLock], &self.funding_udt_type_script);
            let (output, output_data) = self.build_commitment_transaction_output(for_remote);

            TransactionBuilder::default()
                .cell_deps(cell_deps)
                .input(
                    CellInput::new_builder()
                        .previous_output(funding_out_point.clone())
                        .build(),
                )
                .output(output)
                .output_data(output_data)
                .build()
        };

        let settlement_tx = {
            let commtimtent_out_point = OutPoint::new(commitment_tx.hash(), 0);
            let cell_deps = get_cell_deps(
                vec![Contract::CommitmentLock],
                &self.funding_udt_type_script,
            );
            let (outputs, outputs_data) = self.build_settlement_transaction_outputs(for_remote);

            TransactionBuilder::default()
                .cell_deps(cell_deps)
                .input(
                    CellInput::new_builder()
                        .previous_output(commtimtent_out_point.clone())
                        .build(),
                )
                .set_outputs(outputs.to_vec())
                .set_outputs_data(outputs_data.to_vec())
                .build()
        };

        (commitment_tx, settlement_tx)
    }

    fn build_commitment_transaction_output(&self, for_remote: bool) -> (CellOutput, Bytes) {
        let x_only_aggregated_pubkey = self.get_commitment_lock_script_xonly(for_remote);
        let version = self.get_current_commitment_number(for_remote);
        let htlcs = self.get_active_htlcs(for_remote);

        let mut commitment_lock_script_args = [
            &blake2b_256(x_only_aggregated_pubkey)[0..20],
            self.get_delay_epoch_as_lock_args_bytes().as_slice(),
            version.to_be_bytes().as_slice(),
        ]
        .concat();
        if !htlcs.is_empty() {
            commitment_lock_script_args.extend_from_slice(&blake2b_256(&htlcs)[0..20]);
        }

        let commitment_lock_script =
            get_script_by_contract(Contract::CommitmentLock, &commitment_lock_script_args);

        let commitment_tx_fee =
            calculate_commitment_tx_fee(self.commitment_fee_rate, &self.funding_udt_type_script);

        if let Some(udt_type_script) = &self.funding_udt_type_script {
            let capacity = self.local_reserved_ckb_amount + self.remote_reserved_ckb_amount
                - commitment_tx_fee;
            let output = CellOutput::new_builder()
                .lock(commitment_lock_script)
                .type_(Some(udt_type_script.clone()).pack())
                .capacity(capacity.pack())
                .build();

            let output_data = self.get_total_udt_amount().to_le_bytes().pack();
            (output, output_data)
        } else {
            let capacity = self.get_total_ckb_amount() - commitment_tx_fee;
            let output = CellOutput::new_builder()
                .lock(commitment_lock_script)
                .capacity(capacity.pack())
                .build();
            let output_data = Bytes::default();
            (output, output_data)
        }
    }

    // For different directions of commitment transactions, we put pubkeys and nonces
    // in different order. It is a coincidency that in the current code when we are building
    // a commitment transaction for the remote, we will put our pubkey/nonce first.
    // That is to say, `for_remote` is equivalent to this function's parameter `local_first`.
    // But, the name local_first is more descriptive in the context of ordering musig2-related
    // stuff.
    fn get_musig2_common_ctx(&self, local_first: bool) -> Musig2CommonContext {
        let local_pubkey = self.get_local_channel_public_keys().funding_pubkey;
        let remote_pubkey = self.get_remote_channel_public_keys().funding_pubkey;
        let pubkeys = if local_first {
            [local_pubkey, remote_pubkey]
        } else {
            [remote_pubkey, local_pubkey]
        };
        let key_agg_ctx = KeyAggContext::new(pubkeys).expect("Valid pubkeys");
        let remote_nonce = self.get_last_committed_remote_nonce();
        let local_nonce = self.get_local_musig2_pubnonce();

        let agg_nonce = AggNonce::sum(if local_first {
            [local_nonce, remote_nonce]
        } else {
            [remote_nonce, local_nonce]
        });
        Musig2CommonContext {
            local_first,
            key_agg_ctx,
            agg_nonce,
        }
    }

    fn get_commitment_lock_script_xonly(&self, for_remote: bool) -> [u8; 32] {
        self.get_musig2_common_ctx(for_remote)
            .key_agg_ctx
            .aggregated_pubkey::<Point>()
            .serialize_xonly()
    }

    fn build_settlement_transaction_outputs(
        &self,
        for_remote: bool,
    ) -> ([CellOutput; 2], [Bytes; 2]) {
        let pending_tlcs = self
            .tlc_state
            .offered_tlcs
            .tlcs
            .iter()
            .filter(move |tlc| match tlc.outbound_status() {
                OutboundTlcStatus::LocalAnnounced => for_remote,
                OutboundTlcStatus::Committed => true,
                OutboundTlcStatus::RemoteRemoved => true,
                OutboundTlcStatus::RemoveWaitPrevAck => true,
                OutboundTlcStatus::RemoveWaitAck => true,
                OutboundTlcStatus::RemoveAckConfirmed => true,
            })
            .chain(self.tlc_state.received_tlcs.tlcs.iter().filter(move |tlc| {
                match tlc.inbound_status() {
                    InboundTlcStatus::RemoteAnnounced => !for_remote,
                    InboundTlcStatus::AnnounceWaitPrevAck => !for_remote,
                    InboundTlcStatus::AnnounceWaitAck => true,
                    InboundTlcStatus::Committed => true,
                    InboundTlcStatus::LocalRemoved => true,
                    InboundTlcStatus::RemoveAckConfirmed => true,
                }
            }));

        let mut offered_pending = 0;
        let mut offered_fullfilled = 0;
        let mut received_pending = 0;
        let mut received_fullfilled = 0;
        for info in pending_tlcs {
            if info.is_offered() {
                if (info.outbound_status() == OutboundTlcStatus::RemoveWaitAck
                    || info.outbound_status() == OutboundTlcStatus::RemoveAckConfirmed
                    || (info.outbound_status() == OutboundTlcStatus::RemoteRemoved && !for_remote))
                    && info
                        .removed_reason
                        .as_ref()
                        .map(|r| matches!(r, RemoveTlcReason::RemoveTlcFulfill(_)))
                        .unwrap_or_default()
                {
                    offered_fullfilled += info.amount;
                } else {
                    offered_pending += info.amount;
                }
            } else if (info.inbound_status() == InboundTlcStatus::RemoveAckConfirmed
                || (info.inbound_status() == InboundTlcStatus::LocalRemoved && for_remote))
                && info
                    .removed_reason
                    .as_ref()
                    .map(|r| matches!(r, RemoveTlcReason::RemoveTlcFulfill(_)))
                    .unwrap_or_default()
            {
                received_fullfilled += info.amount;
            } else {
                received_pending += info.amount;
            }
        }

        let to_local_value =
            self.to_local_amount + received_fullfilled - offered_pending - offered_fullfilled;
        let to_remote_value =
            self.to_remote_amount + offered_fullfilled - received_pending - received_fullfilled;

        let commitment_tx_fee =
            calculate_commitment_tx_fee(self.commitment_fee_rate, &self.funding_udt_type_script);

        let to_local_output_script = self.get_local_shutdown_script();
        let to_remote_output_script = self.get_remote_shutdown_script();

        // to simplify the fee calculation, we assume that the fee is double paid by both parties
        if let Some(udt_type_script) = &self.funding_udt_type_script {
            let to_local_output = CellOutput::new_builder()
                .lock(to_local_output_script)
                .type_(Some(udt_type_script.clone()).pack())
                .capacity((self.local_reserved_ckb_amount - commitment_tx_fee).pack())
                .build();
            let to_local_output_data = to_local_value.to_le_bytes().pack();

            let to_remote_output = CellOutput::new_builder()
                .lock(to_remote_output_script)
                .type_(Some(udt_type_script.clone()).pack())
                .capacity((self.remote_reserved_ckb_amount - commitment_tx_fee).pack())
                .build();
            let to_remote_output_data = to_remote_value.to_le_bytes().pack();
            if for_remote {
                (
                    [to_local_output, to_remote_output],
                    [to_local_output_data, to_remote_output_data],
                )
            } else {
                (
                    [to_remote_output, to_local_output],
                    [to_remote_output_data, to_local_output_data],
                )
            }
        } else {
            let to_local_output = CellOutput::new_builder()
                .lock(to_local_output_script)
                .capacity(
                    (to_local_value as u64 + self.local_reserved_ckb_amount - commitment_tx_fee)
                        .pack(),
                )
                .build();
            let to_local_output_data = Bytes::default();

            let to_remote_output = CellOutput::new_builder()
                .lock(to_remote_output_script)
                .capacity(
                    (to_remote_value as u64 + self.remote_reserved_ckb_amount - commitment_tx_fee)
                        .pack(),
                )
                .build();
            let to_remote_output_data = Bytes::default();

            if for_remote {
                (
                    [to_local_output, to_remote_output],
                    [to_local_output_data, to_remote_output_data],
                )
            } else {
                (
                    [to_remote_output, to_local_output],
                    [to_remote_output_data, to_local_output_data],
                )
            }
        }
    }

    pub fn build_and_verify_commitment_tx(
        &self,
        funding_tx_partial_signature: PartialSignature,
        commitment_tx_partial_signature: PartialSignature,
    ) -> Result<PartiallySignedCommitmentTransaction, ProcessingChannelError> {
        let (commitment_tx, settlement_tx) = self.build_commitment_and_settlement_tx(false);

        let deterministic_verify_ctx = self.get_deterministic_verify_context();
        deterministic_verify_ctx.verify(
            funding_tx_partial_signature,
            commitment_tx.hash().as_slice(),
        )?;

        let to_local_output = settlement_tx
            .outputs()
            .get(0)
            .expect("get output 0 of settlement tx");
        let to_local_output_data = settlement_tx
            .outputs_data()
            .get(0)
            .expect("get output 0 data of settlement tx");
        let to_remote_output = settlement_tx
            .outputs()
            .get(1)
            .expect("get output 1 of settlement tx");
        let to_remote_output_data = settlement_tx
            .outputs_data()
            .get(1)
            .expect("get output 1 data of settlement tx");
        let args = commitment_tx
            .outputs()
            .get(0)
            .expect("get output 0 of commitment tx")
            .lock()
            .args()
            .raw_data();
        let message = blake2b_256(
            [
                to_local_output.as_slice(),
                to_local_output_data.as_slice(),
                to_remote_output.as_slice(),
                to_remote_output_data.as_slice(),
                &args[0..36],
            ]
            .concat(),
        );
        let verify_ctx = self.get_verify_context();
        verify_ctx.verify(commitment_tx_partial_signature, message.as_slice())?;

        Ok(PartiallySignedCommitmentTransaction {
            version: self.get_current_commitment_number(false),
            commitment_tx,
            settlement_tx,
            funding_tx_partial_signature,
            commitment_tx_partial_signature,
        })
    }

    fn build_and_sign_commitment_tx(
        &self,
    ) -> Result<(PartialSignature, PartialSignature), ProcessingChannelError> {
        let (commitment_tx, settlement_tx) = self.build_commitment_and_settlement_tx(true);

        let deterministic_sign_ctx = self.get_deterministic_sign_context();
        let funding_tx_partial_signature =
            deterministic_sign_ctx.sign(commitment_tx.hash().as_slice())?;

        let to_local_output = settlement_tx
            .outputs()
            .get(0)
            .expect("get output 0 of settlement tx");
        let to_local_output_data = settlement_tx
            .outputs_data()
            .get(0)
            .expect("get output 0 data of settlement tx");
        let to_remote_output = settlement_tx
            .outputs()
            .get(1)
            .expect("get output 1 of settlement tx");
        let to_remote_output_data = settlement_tx
            .outputs_data()
            .get(1)
            .expect("get output 1 data of settlement tx");
        let args = commitment_tx
            .outputs()
            .get(0)
            .expect("get output 0 of commitment tx")
            .lock()
            .args()
            .raw_data();
        let message = blake2b_256(
            [
                to_local_output.as_slice(),
                to_local_output_data.as_slice(),
                to_remote_output.as_slice(),
                to_remote_output_data.as_slice(),
                &args[0..36],
            ]
            .concat(),
        );

        let sign_ctx = self.get_sign_context(true);
        let commitment_tx_partial_signature = sign_ctx.sign(message.as_slice())?;

        Ok((
            funding_tx_partial_signature,
            commitment_tx_partial_signature,
        ))
    }

    /// Verify the partial signature from the peer and create a complete transaction
    /// with valid witnesses.
    fn verify_and_complete_tx(
        &self,
        funding_tx_partial_signature: PartialSignature,
        commitment_tx_partial_signature: PartialSignature,
    ) -> Result<(TransactionView, SettlementData), ProcessingChannelError> {
        let tx = self.build_and_verify_commitment_tx(
            funding_tx_partial_signature,
            commitment_tx_partial_signature,
        )?;
        self.complete_partially_signed_tx(&tx)
    }

    fn get_delay_epoch_as_lock_args_bytes(&self) -> [u8; 8] {
        let since = Since::new(
            SinceType::EpochNumberWithFraction,
            self.commitment_delay_epoch,
            true,
        );
        since.value().to_le_bytes()
    }
}

pub trait ChannelActorStateStore {
    fn get_channel_actor_state(&self, id: &Hash256) -> Option<ChannelActorState>;
    fn insert_channel_actor_state(&self, state: ChannelActorState);
    fn delete_channel_actor_state(&self, id: &Hash256);
    fn get_channel_ids_by_peer(&self, peer_id: &PeerId) -> Vec<Hash256>;
    fn get_active_channel_ids_by_peer(&self, peer_id: &PeerId) -> Vec<Hash256> {
        self.get_channel_ids_by_peer(peer_id)
            .into_iter()
            .filter(
                |id| matches!(self.get_channel_actor_state(id), Some(state) if !state.is_closed()),
            )
            .collect()
    }
    fn get_channel_states(&self, peer_id: Option<PeerId>) -> Vec<(PeerId, Hash256, ChannelState)>;
    fn get_active_channel_states(
        &self,
        peer_id: Option<PeerId>,
    ) -> Vec<(PeerId, Hash256, ChannelState)> {
        self.get_channel_states(peer_id)
            .into_iter()
            .filter(|(_, _, state)| !state.is_closed())
            .collect()
    }
    fn get_channel_state_by_outpoint(&self, id: &OutPoint) -> Option<ChannelActorState>;
}

/// A wrapper on CommitmentTransaction that has a partial signature along with
/// the ckb transaction.
#[derive(Clone, Debug)]
pub struct PartiallySignedCommitmentTransaction {
    // The version number of the commitment transaction.
    pub version: u64,
    // The commitment transaction.
    pub commitment_tx: TransactionView,
    // The settlement transaction.
    pub settlement_tx: TransactionView,
    // The partial signature to unlock the funding transaction.
    pub funding_tx_partial_signature: PartialSignature,
    // The partial signature to unlock the commitment transaction.
    pub commitment_tx_partial_signature: PartialSignature,
}

pub fn create_witness_for_funding_cell(
    lock_key_xonly: [u8; 32],
    signature: CompactSignature,
) -> [u8; FUNDING_CELL_WITNESS_LEN] {
    let mut witness = Vec::with_capacity(FUNDING_CELL_WITNESS_LEN);

    // for xudt compatibility issue,
    // refer to: https://github.com/nervosnetwork/fiber-scripts/pull/5
    let empty_witness_args = [16, 0, 0, 0, 16, 0, 0, 0, 16, 0, 0, 0, 16, 0, 0, 0];
    witness.extend_from_slice(&empty_witness_args);
    witness.extend_from_slice(lock_key_xonly.as_slice());
    witness.extend_from_slice(signature.serialize().as_slice());
    witness
        .try_into()
        .expect("Witness length should be correct")
}

pub fn create_witness_for_commitment_cell(
    lock_key_xonly: [u8; 32],
    signature: CompactSignature,
) -> [u8; COMMITMENT_CELL_WITNESS_LEN] {
    let mut witness = Vec::with_capacity(COMMITMENT_CELL_WITNESS_LEN);
    // for xudt compatibility issue,
    // refer to: https://github.com/nervosnetwork/fiber-scripts/pull/5
    let empty_witness_args = [16, 0, 0, 0, 16, 0, 0, 0, 16, 0, 0, 0, 16, 0, 0, 0];
    witness.extend_from_slice(&empty_witness_args);
    witness.extend_from_slice(&[0xFE]);
    witness.extend_from_slice(lock_key_xonly.as_slice());
    witness.extend_from_slice(signature.serialize().as_slice());
    witness
        .try_into()
        .expect("Witness length should be correct")
}

// The common musig2 configuration that is used both by signing and verifying.
#[derive(Debug)]
struct Musig2CommonContext {
    // This parameter is also saved to the context because it is useful for
    // aggregating partial signatures.
    local_first: bool,
    key_agg_ctx: KeyAggContext,
    agg_nonce: AggNonce,
}

impl Musig2CommonContext {
    fn aggregate_partial_signatures_for_msg(
        &self,
        local_signature: PartialSignature,
        remote_signature: PartialSignature,
        message: &[u8],
    ) -> Result<CompactSignature, VerifyError> {
        let partial_signatures = if self.local_first {
            [local_signature, remote_signature]
        } else {
            [remote_signature, local_signature]
        };
        aggregate_partial_signatures(
            &self.key_agg_ctx,
            &self.agg_nonce,
            partial_signatures,
            message,
        )
    }

    pub fn x_only_aggregated_pubkey(&self) -> [u8; 32] {
        self.key_agg_ctx
            .aggregated_pubkey::<Point>()
            .serialize_xonly()
    }
}

struct Musig2VerifyContext {
    common_ctx: Musig2CommonContext,
    pubkey: Pubkey,
    pubnonce: PubNonce,
}

impl Musig2VerifyContext {
    fn verify(&self, signature: PartialSignature, message: &[u8]) -> Result<(), VerifyError> {
        verify_partial(
            &self.common_ctx.key_agg_ctx,
            signature,
            &self.common_ctx.agg_nonce,
            self.pubkey,
            &self.pubnonce,
            message,
        )
    }
}

struct Musig2SignContext {
    common_ctx: Musig2CommonContext,
    seckey: Privkey,
    secnonce: SecNonce,
}

impl Musig2SignContext {
    fn sign(&self, message: &[u8]) -> Result<PartialSignature, SigningError> {
        sign_partial(
            &self.common_ctx.key_agg_ctx,
            self.seckey.clone(),
            self.secnonce.clone(),
            &self.common_ctx.agg_nonce,
            message,
        )
    }

    fn sign_and_aggregate(
        &self,
        message: &[u8],
        remote_signature: PartialSignature,
    ) -> Result<CompactSignature, RoundFinalizeError> {
        let local_signature = self.sign(message)?;
        Ok(self.common_ctx.aggregate_partial_signatures_for_msg(
            local_signature,
            remote_signature,
            message,
        )?)
    }
}

/// One counterparty's public keys which do not change over the life of a channel.
#[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
pub struct ChannelBasePublicKeys {
    /// The public key which is used to sign all commitment transactions, as it appears in the
    /// on-chain channel lock-in 2-of-2 multisig output.
    pub funding_pubkey: Pubkey,
    /// The base point which is used (with derive_public_key) to derive a per-commitment public key
    /// which is used to encumber HTLC-in-flight outputs.
    pub tlc_base_key: Pubkey,
}

impl From<&OpenChannel> for ChannelBasePublicKeys {
    fn from(value: &OpenChannel) -> Self {
        ChannelBasePublicKeys {
            funding_pubkey: value.funding_pubkey,
            tlc_base_key: value.tlc_basepoint,
        }
    }
}

impl From<&AcceptChannel> for ChannelBasePublicKeys {
    fn from(value: &AcceptChannel) -> Self {
        ChannelBasePublicKeys {
            funding_pubkey: value.funding_pubkey,
            tlc_base_key: value.tlc_basepoint,
        }
    }
}

type ShortHash = [u8; 20];

pub fn get_tweak_by_commitment_point(commitment_point: &Pubkey) -> [u8; 32] {
    let mut hasher = new_blake2b();
    hasher.update(&commitment_point.serialize());
    let mut result = [0u8; 32];
    hasher.finalize(&mut result);
    result
}

pub(crate) fn derive_private_key(secret: &Privkey, commitment_point: &Pubkey) -> Privkey {
    secret.tweak(get_tweak_by_commitment_point(commitment_point))
}

fn derive_public_key(base_key: &Pubkey, commitment_point: &Pubkey) -> Pubkey {
    base_key.tweak(get_tweak_by_commitment_point(commitment_point))
}

pub fn derive_payment_pubkey(base_key: &Pubkey, commitment_point: &Pubkey) -> Pubkey {
    derive_public_key(base_key, commitment_point)
}

pub fn derive_delayed_payment_pubkey(base_key: &Pubkey, commitment_point: &Pubkey) -> Pubkey {
    derive_public_key(base_key, commitment_point)
}

pub fn derive_tlc_pubkey(base_key: &Pubkey, commitment_point: &Pubkey) -> Pubkey {
    derive_public_key(base_key, commitment_point)
}

/// A simple implementation of [`WriteableEcdsaChannelSigner`] that just keeps the private keys in memory.
///
/// This implementation performs no policy checks and is insufficient by itself as
/// a secure external signer.
#[derive(Clone, Eq, PartialEq, Serialize, Deserialize)]
pub struct InMemorySigner {
    /// Holder secret key in the 2-of-2 multisig script of a channel. This key also backs the
    /// holder's anchor output in a commitment transaction, if one is present.
    pub funding_key: Privkey,
    /// Holder HTLC secret key used in commitment transaction HTLC outputs.
    pub tlc_base_key: Privkey,
    /// SecNonce used to generate valid signature in musig.
    // TODO: use rust's ownership to make sure musig_nonce is used once.
    pub musig2_base_nonce: Privkey,
    /// Seed to derive above keys (per commitment).
    pub commitment_seed: [u8; 32],
}

impl InMemorySigner {
    pub fn generate_from_seed(params: &[u8]) -> Self {
        let seed = ckb_hash::blake2b_256(params);

        let commitment_seed = {
            let mut hasher = new_blake2b();
            hasher.update(&seed);
            hasher.update(&b"commitment seed"[..]);
            let mut result = [0u8; 32];
            hasher.finalize(&mut result);
            result
        };

        let key_derive = |seed: &[u8], info: &[u8]| {
            let result = blake2b_hash_with_salt(seed, info);
            Privkey::from_slice(&result)
        };

        let funding_key = key_derive(&seed, b"funding key");
        let tlc_base_key = key_derive(funding_key.as_ref(), b"HTLC base key");
        let musig2_base_nonce = key_derive(tlc_base_key.as_ref(), b"musig nocne");

        Self {
            funding_key,
            tlc_base_key,
            musig2_base_nonce,
            commitment_seed,
        }
    }

    fn get_base_public_keys(&self) -> ChannelBasePublicKeys {
        ChannelBasePublicKeys {
            funding_pubkey: self.funding_key.pubkey(),
            tlc_base_key: self.tlc_base_key.pubkey(),
        }
    }

    pub fn get_commitment_point(&self, commitment_number: u64) -> Pubkey {
        get_commitment_point(&self.commitment_seed, commitment_number)
    }

    pub fn get_commitment_secret(&self, commitment_number: u64) -> [u8; 32] {
        get_commitment_secret(&self.commitment_seed, commitment_number)
    }

    pub fn derive_tlc_key(&self, new_commitment_number: u64) -> Privkey {
        let per_commitment_point = self.get_commitment_point(new_commitment_number);
        derive_private_key(&self.tlc_base_key, &per_commitment_point)
    }

    // TODO: Verify that this is a secure way to derive the nonce.
    pub fn derive_musig2_nonce(&self, commitment_number: u64) -> SecNonce {
        let commitment_point = self.get_commitment_point(commitment_number);
        let seckey = derive_private_key(&self.musig2_base_nonce, &commitment_point);
        SecNonce::build(seckey.as_ref()).build()
    }
}


================================================
File: src/fiber/config.rs
================================================
use crate::{ckb::contracts::Contract, Result};
use ckb_jsonrpc_types::{CellDep, Script};
use clap_serde_derive::{
    clap::{self},
    ClapSerde,
};
#[cfg(not(test))]
use once_cell::sync::OnceCell;
use serde::{Deserialize, Deserializer, Serialize, Serializer};
use std::{fs, path::PathBuf, str::FromStr};
use tentacle::secio::{PublicKey, SecioKeyPair};

pub const CKB_SHANNONS: u64 = 100_000_000; // 1 CKB = 10 ^ 8 shannons
pub const DEFAULT_MIN_SHUTDOWN_FEE: u64 = CKB_SHANNONS; // 1 CKB prepared for shutdown transaction fee

/// By default, listen to any tcp port allocated by the kernel.
pub const DEFAULT_LISTENING_ADDR: &str = "/ip4/0.0.0.0/tcp/0";

const MIN_OCCUPIED_CAPACITY: u64 = 61 * CKB_SHANNONS; // 61 CKB for occupied capacity

/// Default ckb funding amount when auto accepting an open channel request.
pub const DEFAULT_AUTO_ACCEPT_CHANNEL_CKB_FUNDING_AMOUNT: u64 =
    MIN_OCCUPIED_CAPACITY + DEFAULT_MIN_SHUTDOWN_FEE;

/// Default minimum ckb funding amount for auto accepting an open channel request.
pub const DEFAULT_OPEN_CHANNEL_AUTO_ACCEPT_MIN_CKB_FUNDING_AMOUNT: u64 = 100 * CKB_SHANNONS;

/// The expiry delta to forward a tlc, in milliseconds, default to 1 day.
pub const DEFAULT_TLC_EXPIRY_DELTA: u64 = 24 * 60 * 60 * 1000;

/// The minimal expiry delta to forward a tlc, in milliseconds. 15 minutes.
pub const MIN_TLC_EXPIRY_DELTA: u64 = 15 * 60 * 1000; // 15 minutes

/// The maximum expiry delta for a payment, in milliseconds. 2 weeks
pub const MAX_PAYMENT_TLC_EXPIRY_LIMIT: u64 = 14 * 24 * 60 * 60 * 1000; // 2 weeks

/// The minimal value of a tlc. 0 means no minimal value.
pub const DEFAULT_TLC_MIN_VALUE: u128 = 0;

/// The maximal value of a tlc. 0 means no maximal value.
pub const DEFAULT_TLC_MAX_VALUE: u128 = 0;

/// The fee for forwarding peer tlcs. Proportional to the amount of the forwarded tlc. The unit is millionths of the amount. 1000 means 0.1%.
pub const DEFAULT_TLC_FEE_PROPORTIONAL_MILLIONTHS: u128 = 1000;

/// Whether to automatically announce the node on startup. false means not announcing.
pub const DEFAULT_AUTO_ANNOUNCE_NODE: bool = true;

/// The interval to reannounce NodeAnnouncement, in seconds.
pub const DEFAULT_ANNOUNCE_NODE_INTERVAL_SECONDS: u64 = 3600;

/// The interval to maintain the gossip network, in milli-seconds.
pub const DEFAULT_GOSSIP_NETWORK_MAINTENANCE_INTERVAL_MS: u64 = 1000 * 60;

/// Maximal number of inbound connections.
pub const DEFAULT_MAX_INBOUND_PEERS: usize = 16;

/// Minimal number of outbound connections.
pub const DEFAULT_MIN_OUTBOUND_PEERS: usize = 8;

/// The interval to maintain the gossip network, in milli-seconds.
pub const DEFAULT_GOSSIP_STORE_MAINTENANCE_INTERVAL_MS: u64 = 20 * 1000;

/// Whether to sync the network graph from the network. true means syncing.
pub const DEFAULT_SYNC_NETWORK_GRAPH: bool = true;

// See comment in `LdkConfig` for why do we need to specify both name and long,
// and prefix them with `ckb-`/`CKB_`.
#[derive(ClapSerde, Debug, Clone)]
pub struct FiberConfig {
    /// ckb base directory
    #[arg(
        name = "FIBER_BASE_DIR",
        long = "fiber-base-dir",
        env,
        help = "base directory for fiber [default: $BASE_DIR/fiber]"
    )]
    pub(crate) base_dir: Option<PathBuf>,

    /// listening address for fiber network [default: "/ip4/0.0.0.0/tcp/0" (random tcp port)]
    #[arg(name = "FIBER_LISTENING_ADDR", long = "fiber-listening-addr", env)]
    pub(crate) listening_addr: Option<String>,

    /// whether to announce listening address [default: false]
    #[arg(
        name = "FIBER_ANNOUNCE_LISTENING_ADDR",
        long = "fiber-announce-listening-addr",
        env
    )]
    pub(crate) announce_listening_addr: Option<bool>,

    /// whether to announce or process private address, this should be set to false unless you are running a private network or testing [default: false]
    #[arg(
        name = "FIBER_ANNOUNCE_PRIVATE_ADDR",
        long = "fiber-announce-private-addr",
        env
    )]
    pub(crate) announce_private_addr: Option<bool>,

    /// addresses to be announced to fiber network (separated by `,`)
    #[arg(name = "FIBER_ANNOUNCED_ADDRS", long = "fiber-announced-addrs", env, value_parser, num_args = 0.., value_delimiter = ',')]
    pub(crate) announced_addrs: Vec<String>,

    /// bootstrap node addresses to be connected at startup (separated by `,`)
    #[arg(name = "FIBER_BOOTNODE_ADDRS", long = "fiber-bootnode-addrs", env, value_parser, num_args = 0.., value_delimiter = ',')]
    pub bootnode_addrs: Vec<String>,

    /// node name to be announced to fiber network
    #[arg(
        name = "FIBER_ANNOUNCED_NODE_NAME",
        long = "fiber-announced-node-name",
        env
    )]
    pub(crate) announced_node_name: Option<AnnouncedNodeName>,

    /// chain spec file path, can be "mainnet", "testnet", or a file path to a custom chain spec
    #[arg(name = "FIBER_CHAIN", long = "fiber-chain", env)]
    pub chain: String,

    /// lock script configurations related to fiber network
    #[arg(name = "FIBER_SCRIPTS", long = "fiber-scripts", env, value_parser, num_args = 0.., value_delimiter = ',')]
    pub scripts: Vec<FiberScript>,

    /// minimum ckb funding amount for auto accepting an open channel requests, unit: shannons [default: 10000000000 shannons]
    #[arg(
        name = "FIBER_OPEN_CHANNEL_AUTO_ACCEPT_MIN_CKB_FUNDING_AMOUNT",
        long = "fiber-open-channel-auto-accept-min-ckb-funding-amount",
        env,
        help = "minimum ckb funding amount for auto accepting an open channel requests, unit: shannons [default: 10000000000 shannons]"
    )]
    pub open_channel_auto_accept_min_ckb_funding_amount: Option<u64>,
    /// whether to accept open channel requests with ckb funding amount automatically, unit: shannons [default: 6200000000 shannons], if this is set to zero, it means to disable auto accept
    #[arg(
        name = "FIBER_AUTO_ACCEPT_CHANNEL_CKB_FUNDING_AMOUNT",
        long = "fiber-auto-accept-channel-ckb-funding-amount",
        env,
        help = "whether to accept open channel requests with ckb funding amount automatically, unit: shannons [default: 6200000000 shannons], if this is set to zero, it means to disable auto accept"
    )]
    pub auto_accept_channel_ckb_funding_amount: Option<u64>,

    /// The expiry delta to forward a tlc, in milliseconds. [default: 86400000 (1 day)]
    #[arg(
        name = "FIBER_TLC_EXPIRY_DELTA",
        long = "fiber-tlc-expiry-delta",
        env,
        help = "The expiry delta to forward a tlc, in milliseconds. [default: 86400000 (1 day)]"
    )]
    pub tlc_expiry_delta: Option<u64>,

    /// The minimal value of a tlc. [default: 0 (no minimal value)]
    #[arg(
        name = "FIBER_TLC_MIN_VALUE",
        long = "fiber-tlc-min-value",
        env,
        help = "The minimal value of a tlc. [default: 0 (no minimal value)]"
    )]
    pub tlc_min_value: Option<u128>,
    /// The maximal value of a tlc. [default: 0 (no maximal value)]
    #[arg(
        name = "FIBER_TLC_MAX_VALUE",
        long = "fiber-tlc-max-value",
        env,
        help = "The maximal value of a tlc. [default: 0 (no maximal value)]"
    )]
    pub tlc_max_value: Option<u128>,

    /// The fee for forwarding peer tlcs. Proportional to the amount of the forwarded tlc. The unit is millionths of the amount. [default: 1000 (0.1%)]
    #[arg(
        name = "FIBER_TLC_FEE_PROPORTIONAL_MILLIONTHS",
        long = "fiber-tlc-fee-proportional-millionths",
        env,
        help = "The fee for forwarding peer tlcs. Proportional to the amount of the forwarded tlc. The unit is millionths of the amount. [default: 1000 (0.1%)]"
    )]
    pub tlc_fee_proportional_millionths: Option<u128>,

    /// Whether to automatically announce the node on startup. [default: true]
    #[arg(
        name = "FIBER_AUTO_ANNOUNCE_NODE",
        long = "fiber-auto-announce-node",
        env,
        help = "Whether to automatically announce the node on startup. [default: true]"
    )]
    pub auto_announce_node: Option<bool>,

    // TODO: the more sensible default value for this option is a reasonable interval like one day
    // if this node has public channels, otherwise don't reannounce (or announce) at all.
    /// The interval to reannounce NodeAnnouncement, in seconds. 0 means never reannounce. [default: 3600 (1 hour)]
    #[arg(
        name = "FIBER_ANNOUNCE_NODE_INTERVAL_SECONDS",
        long = "fiber-announce-node-interval-seconds",
        env,
        help = "The interval to reannounce NodeAnnouncement, in seconds. 0 means never reannounce. [default: 3600 (1 hour)]"
    )]
    pub(crate) announce_node_interval_seconds: Option<u64>,

    /// Gossip network maintenance interval, in milli-seconds. [default: 60000]
    /// This is the interval to maintain the gossip network, including connecting to more peers, etc.
    #[arg(
        name = "FIBER_GOSSIP_NETWORK_MAINTENANCE_INTERVAL_MS",
        long = "fiber-gossip-network-maintenance-interval-ms",
        env,
        help = "Gossip network maintenance interval, in milli-seconds. [default: 60000]"
    )]
    pub(crate) gossip_network_maintenance_interval_ms: Option<u64>,

    /// Maximal number of inbound connections. The node will disconnect inbound connections
    /// when the number of inbound connection exceeds this number. [default: 16]
    #[arg(
        name = "FIBER_MAX_INBOUND_PEERS",
        long = "fiber-max-inbound-peers",
        env,
        help = "Maximal number of inbound connections. The node will disconnect inbound connections when the number of inbound connection exceeds this number. [default: 16]"
    )]
    pub(crate) max_inbound_peers: Option<usize>,

    /// Minimal number of outbound connections. The node will try to connect to more peers
    /// when the number of outbound connection is less than this number. [default: 8]
    #[arg(
        name = "FIBER_MIN_OUTBOUND_PEERS",
        long = "fiber-min-outbound-peers",
        env,
        help = "Minimal number of outbound connections. The node will try to connect to more peers when the number of outbound connection is less than this number. [default: 8]"
    )]
    pub(crate) min_outbound_peers: Option<usize>,

    /// Gossip store maintenance interval, in milli-seconds. [default: 20000]
    /// This is the interval to maintain the gossip store, including saving messages whose complete dependencies
    /// are available, etc.
    #[arg(
        name = "FIBER_GOSSIP_STORE_MAINTENANCE_INTERVAL_MS",
        long = "fiber-gossip-store-maintenance-interval-ms",
        env,
        help = "Gossip store maintenance interval, in milli-seconds. [default: 20000]"
    )]
    pub(crate) gossip_store_maintenance_interval_ms: Option<u64>,

    /// Gossip network num targeted active syncing peers. [default: None]
    /// This is the number of peers to target for active syncing. This is the number of peers that we will
    /// send GetBroadcastMessages message to obtain the gossip messages that we missed during the time we
    /// were offiline. A larger number means more peers to receive updates from, but also more bandwidth usage.
    /// If None, it will use the default value.
    #[arg(
        name = "FIBER_GOSSIP_NETWORK_NUM_TARGETED_ACTIVE_SYNCING_PEERS",
        long = "fiber-gossip-network-num-targeted-active-syncing-peers",
        env,
        help = "Gossip network num targeted active syncing peers. [default: None]"
    )]
    pub(crate) gossip_network_num_targeted_active_syncing_peers: Option<usize>,

    /// Gossip network num targeted outbound passive syncing peers. [default: None]
    /// This is the number of peers to target for outbound passive syncing. This is the number of outbound peers
    /// that we will send BroadcastMessageFilter to receive updates from them. A larger number means more
    /// peers to receive updates from, but also more bandwidth usage. We only count the outbound peers here,
    /// because outbound peers are less likely to be malicious, and we want to receive updates from them.
    /// If None, it will use the default value.
    #[arg(
        name = "FIBER_GOSSIP_NETWORK_NUM_TARGETED_OUTBOUND_PASSIVE_SYNCING_PEERS",
        long = "fiber-gossip-network-num-targeted-outbound-passive-syncing-peers",
        env,
        help = "Gossip network num targeted outbound passive syncing peers. [default: None]"
    )]
    pub(crate) gossip_network_num_targeted_outbound_passive_syncing_peers: Option<usize>,

    /// Whether to sync the network graph from the network. [default: true]
    #[arg(
        name = "FIBER_SYNC_NETWORK_GRAPH",
        long = "fiber-sync-network-graph",
        env,
        help = "Whether to sync the network graph from the network. [default: true]"
    )]
    pub(crate) sync_network_graph: Option<bool>,

    /// The interval to check watchtower, in seconds. 0 means never check. [default: 60 (1 minute)]
    #[arg(
        name = "FIBER_WATCHTOWER_CHECK_INTERVAL_SECONDS",
        long = "fiber-watchtower-check-interval-seconds",
        env,
        help = "The interval to check watchtower, in seconds. 0 means never check. [default: 60 (1 minute)]"
    )]
    pub watchtower_check_interval_seconds: Option<u64>,
}

/// Must be a valid utf-8 string of length maximal length 32 bytes.
/// If the length is less than 32 bytes, it will be padded with 0.
/// If the length is more than 32 bytes, it should be truncated.
#[derive(Eq, PartialEq, Copy, Clone, Default, Hash)]
pub struct AnnouncedNodeName(pub [u8; 32]);

impl AnnouncedNodeName {
    pub fn as_bytes(&self) -> &[u8; 32] {
        &self.0
    }

    pub fn from_slice(slice: &[u8]) -> std::result::Result<Self, String> {
        if slice.len() > 32 {
            return Err("Node Alias can not be longer than 32 bytes".to_string());
        }
        let mut bytes = [0; 32];
        bytes[..slice.len()].copy_from_slice(slice);
        Ok(Self(bytes))
    }

    pub fn from_string(value: &str) -> std::result::Result<Self, String> {
        let str_bytes = value.as_bytes();
        Self::from_slice(str_bytes)
    }

    pub fn as_str(&self) -> &str {
        let end = self.0.iter().position(|&b| b == 0).unwrap_or(self.0.len());
        if end == 0 {
            return "";
        }
        std::str::from_utf8(&self.0[..end]).expect("valid utf8 string")
    }
}

impl std::fmt::Display for AnnouncedNodeName {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        write!(f, "{}", self.as_str())
    }
}

impl std::fmt::Debug for AnnouncedNodeName {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        write!(f, "AnnouncedNodeName({})", self)
    }
}

impl<'s> From<&'s str> for AnnouncedNodeName {
    fn from(value: &'s str) -> Self {
        Self::from_string(value).expect("Valid announced node name")
    }
}

impl serde::Serialize for AnnouncedNodeName {
    fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        serializer.serialize_str(std::str::from_utf8(&self.0).expect("valid utf8 string"))
    }
}

impl<'de> serde::Deserialize<'de> for AnnouncedNodeName {
    fn deserialize<D>(deserializer: D) -> std::result::Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        let s = String::deserialize(deserializer)?;
        Self::from_string(&s).map_err(serde::de::Error::custom)
    }
}

#[cfg(not(test))]
static FIBER_SECRET_KEY: OnceCell<super::KeyPair> = OnceCell::new();

impl FiberConfig {
    pub fn base_dir(&self) -> &PathBuf {
        self.base_dir.as_ref().expect("have set base dir")
    }

    pub fn create_base_dir(&self) -> Result<()> {
        if !self.base_dir().exists() {
            fs::create_dir_all(self.base_dir()).map_err(Into::into)
        } else {
            Ok(())
        }
    }

    fn inner_read_or_generate_secret_key(&self) -> Result<super::KeyPair> {
        self.create_base_dir()?;
        super::key::KeyPair::read_or_generate(&self.base_dir().join("sk")).map_err(Into::into)
    }

    // `OnceCell` will make all actors in UI tests use the same secret key.
    // which is not what we want. So we disable it in tests.
    #[cfg(test)]
    pub fn read_or_generate_secret_key(&self) -> Result<super::KeyPair> {
        self.inner_read_or_generate_secret_key()
    }

    #[cfg(not(test))]
    pub fn read_or_generate_secret_key(&self) -> Result<super::KeyPair> {
        FIBER_SECRET_KEY
            .get_or_try_init(|| self.inner_read_or_generate_secret_key())
            .cloned()
    }

    pub fn store_path(&self) -> PathBuf {
        let path = self.base_dir().join("store");
        if !path.exists() {
            fs::create_dir_all(&path).expect("create store directory");
        }
        path
    }

    pub fn listening_addr(&self) -> &str {
        self.listening_addr
            .as_deref()
            .unwrap_or(DEFAULT_LISTENING_ADDR)
    }

    pub fn announce_listening_addr(&self) -> bool {
        self.announce_listening_addr.unwrap_or(false)
    }

    pub fn announce_private_addr(&self) -> bool {
        self.announce_private_addr.unwrap_or(false)
    }

    pub fn open_channel_auto_accept_min_ckb_funding_amount(&self) -> u64 {
        self.open_channel_auto_accept_min_ckb_funding_amount
            .unwrap_or(DEFAULT_OPEN_CHANNEL_AUTO_ACCEPT_MIN_CKB_FUNDING_AMOUNT)
    }

    pub fn auto_accept_channel_ckb_funding_amount(&self) -> u64 {
        self.auto_accept_channel_ckb_funding_amount
            .unwrap_or(DEFAULT_AUTO_ACCEPT_CHANNEL_CKB_FUNDING_AMOUNT)
    }

    pub fn tlc_expiry_delta(&self) -> u64 {
        self.tlc_expiry_delta.unwrap_or(DEFAULT_TLC_EXPIRY_DELTA)
    }

    pub fn tlc_min_value(&self) -> u128 {
        self.tlc_min_value.unwrap_or(DEFAULT_TLC_MIN_VALUE)
    }

    pub fn tlc_max_value(&self) -> u128 {
        self.tlc_max_value.unwrap_or(DEFAULT_TLC_MAX_VALUE)
    }

    pub fn tlc_fee_proportional_millionths(&self) -> u128 {
        self.tlc_fee_proportional_millionths
            .unwrap_or(DEFAULT_TLC_FEE_PROPORTIONAL_MILLIONTHS)
    }

    pub fn auto_announce_node(&self) -> bool {
        self.auto_announce_node
            .unwrap_or(DEFAULT_AUTO_ANNOUNCE_NODE)
    }

    pub fn announce_node_interval_seconds(&self) -> u64 {
        self.announce_node_interval_seconds
            .unwrap_or(DEFAULT_ANNOUNCE_NODE_INTERVAL_SECONDS)
    }

    pub fn public_key(&self) -> PublicKey {
        let secio_kp: SecioKeyPair = self
            .read_or_generate_secret_key()
            .expect("read or generate secret key")
            .into();
        secio_kp.public_key()
    }

    pub fn gossip_network_maintenance_interval_ms(&self) -> u64 {
        self.gossip_network_maintenance_interval_ms
            .unwrap_or(DEFAULT_GOSSIP_NETWORK_MAINTENANCE_INTERVAL_MS)
    }

    pub fn max_inbound_peers(&self) -> usize {
        self.max_inbound_peers.unwrap_or(DEFAULT_MAX_INBOUND_PEERS)
    }

    pub fn min_outbound_peers(&self) -> usize {
        self.min_outbound_peers
            .unwrap_or(DEFAULT_MIN_OUTBOUND_PEERS)
    }

    pub fn gossip_store_maintenance_interval_ms(&self) -> u64 {
        self.gossip_store_maintenance_interval_ms
            .unwrap_or(DEFAULT_GOSSIP_STORE_MAINTENANCE_INTERVAL_MS)
    }

    pub fn sync_network_graph(&self) -> bool {
        self.sync_network_graph
            .unwrap_or(DEFAULT_SYNC_NETWORK_GRAPH)
    }
}

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct FiberScript {
    pub name: Contract,
    pub script: Script,
    pub cell_deps: Vec<CellDep>,
}

impl FromStr for FiberScript {
    type Err = serde_json::Error;

    fn from_str(s: &str) -> std::result::Result<Self, Self::Err> {
        serde_json::from_str(s)
    }
}


================================================
File: src/fiber/fee.rs
================================================
use super::channel::FUNDING_CELL_WITNESS_LEN;
use crate::ckb::contracts::{get_cell_deps, get_script_by_contract, Contract};
use ckb_types::core::TransactionBuilder;
use ckb_types::packed::{Bytes, Script};
use ckb_types::prelude::Builder;
use ckb_types::{
    core::FeeRate,
    packed::{CellInput, CellOutput},
    prelude::Pack,
};
use molecule::prelude::Entity;

fn commitment_tx_size(udt_type_script: &Option<Script>) -> usize {
    // when there is pending htlcs, the commitment lock args will be 56 bytes, otherwise 46 bytes.
    // to simplify the calculation, we use hardcoded 56 bytes here.
    let commitment_lock_script = get_script_by_contract(Contract::CommitmentLock, &[0u8; 56]);
    let cell_deps = get_cell_deps(vec![Contract::FundingLock], udt_type_script);

    let (output, output_data) = if let Some(type_script) = udt_type_script {
        let output = CellOutput::new_builder()
            .lock(commitment_lock_script)
            .type_(Some(type_script.clone()).pack())
            .capacity(0.pack())
            .build();
        let output_data = (0_u128).to_le_bytes().pack();
        (output, output_data)
    } else {
        let output = CellOutput::new_builder()
            .capacity(0.pack())
            .lock(commitment_lock_script)
            .build();
        (output, Bytes::default())
    };

    let mock_commitment_tx = TransactionBuilder::default()
        .cell_deps(cell_deps)
        .input(CellInput::default())
        .output(output)
        .output_data(output_data)
        .set_witnesses(vec![[0; FUNDING_CELL_WITNESS_LEN].pack()])
        .build();
    mock_commitment_tx.data().serialized_size_in_block()
}

pub(crate) fn shutdown_tx_size(
    udt_type_script: &Option<Script>,
    shutdown_scripts: (Script, Script),
) -> usize {
    let (script_a, script_b) = shutdown_scripts;
    let cell_deps = get_cell_deps(vec![Contract::FundingLock], udt_type_script);

    let (outputs, outputs_data) = if let Some(type_script) = udt_type_script {
        let output_a = CellOutput::new_builder()
            .lock(script_a)
            .type_(Some(type_script.clone()).pack())
            .capacity(0.pack())
            .build();
        let output_b = CellOutput::new_builder()
            .lock(script_b)
            .type_(Some(type_script.clone()).pack())
            .capacity(0.pack())
            .build();
        let dummy_output_data = (0_u128).to_le_bytes().pack();

        let outputs = [output_a, output_b];
        let outputs_data = [dummy_output_data.clone(), dummy_output_data];
        (outputs, outputs_data.to_vec())
    } else {
        let output_a = CellOutput::new_builder()
            .capacity(0.pack())
            .lock(script_a)
            .build();
        let output_b = CellOutput::new_builder()
            .capacity(0.pack())
            .lock(script_b)
            .build();
        let outputs = [output_a, output_b];
        (outputs, vec![Bytes::default(); 2])
    };

    let mock_shutdown_tx = TransactionBuilder::default()
        .cell_deps(cell_deps)
        .input(CellInput::default())
        .set_outputs(outputs.to_vec())
        .set_outputs_data(outputs_data.to_vec())
        .set_witnesses(vec![[0; FUNDING_CELL_WITNESS_LEN].pack()])
        .build();
    mock_shutdown_tx.data().serialized_size_in_block()
}

pub(crate) fn calculate_commitment_tx_fee(fee_rate: u64, udt_type_script: &Option<Script>) -> u64 {
    let fee_rate: FeeRate = FeeRate::from_u64(fee_rate);
    let tx_size = commitment_tx_size(udt_type_script) as u64;
    fee_rate.fee(tx_size).as_u64()
}

pub(crate) fn calculate_shutdown_tx_fee(
    fee_rate: u64,
    udt_type_script: &Option<Script>,
    shutdown_scripts: (Script, Script),
) -> u64 {
    let fee_rate: FeeRate = FeeRate::from_u64(fee_rate);
    let tx_size = shutdown_tx_size(udt_type_script, shutdown_scripts) as u64;
    fee_rate.fee(tx_size).as_u64()
}

pub(crate) fn calculate_tlc_forward_fee(
    amount: u128,
    fee_proportational_millionths: u128,
) -> Result<u128, String> {
    let fee = fee_proportational_millionths
        .checked_mul(amount)
        .ok_or_else(|| {
            format!(
                "fee_proportational_millionths {} * amount {} overflow",
                fee_proportational_millionths, amount
            )
        })?;
    let base_fee = fee / 1_000_000;
    let remainder = fee % 1_000_000;
    if remainder > 0 {
        Ok(base_fee + 1)
    } else {
        Ok(base_fee)
    }
}


================================================
File: src/fiber/gossip.rs
================================================
use std::{
    collections::{HashMap, HashSet},
    marker::PhantomData,
    sync::Arc,
    time::Duration,
};

use ckb_hash::blake2b_256;
use ckb_jsonrpc_types::{Status, TransactionView, TxStatus};
use ckb_types::{packed::OutPoint, H256};
use ractor::{
    async_trait as rasync_trait, call, call_t,
    concurrency::{timeout, JoinHandle},
    Actor, ActorCell, ActorProcessingErr, ActorRef, ActorRuntime, MessagingErr, OutputPort,
    RpcReplyPort, SupervisionEvent,
};
use secp256k1::Message;
use tentacle::{
    async_trait as tasync_trait,
    builder::MetaBuilder,
    bytes::Bytes,
    context::{ProtocolContext, ProtocolContextMutRef, SessionContext},
    secio::PeerId,
    service::{ProtocolHandle, ProtocolMeta, ServiceAsyncControl, SessionType},
    traits::ServiceProtocol,
    utils::{is_reachable, multiaddr_to_socketaddr},
    SessionId,
};
use tokio::sync::oneshot;
use tracing::{debug, error, info, trace, warn};

use crate::{
    ckb::{CkbChainMessage, GetBlockTimestampRequest, TraceTxRequest, TraceTxResponse},
    fiber::{network::DEFAULT_CHAIN_ACTOR_TIMEOUT, types::secp256k1_instance},
    now_timestamp_as_millis_u64, unwrap_or_return, Error,
};

use super::{
    network::{check_chain_hash, get_chain_hash, GossipMessageWithPeerId, GOSSIP_PROTOCOL_ID},
    types::{
        BroadcastMessage, BroadcastMessageID, BroadcastMessageQuery, BroadcastMessageQueryFlags,
        BroadcastMessageWithTimestamp, BroadcastMessagesFilter, BroadcastMessagesFilterResult,
        ChannelAnnouncement, ChannelOnchainInfo, ChannelUpdate, Cursor, GetBroadcastMessages,
        GetBroadcastMessagesResult, GossipMessage, NodeAnnouncement, Pubkey,
        QueryBroadcastMessages, QueryBroadcastMessagesResult,
    },
};

// The maximum duration drift between the broadcast message timestamp and latest cursor in store.
pub(crate) const MAX_MISSING_BROADCAST_MESSAGE_TIMESTAMP_DRIFT: Duration =
    Duration::from_secs(60 * 60 * 2);

const MAX_BROADCAST_MESSAGE_TIMESTAMP_DRIFT: Duration = Duration::from_secs(60);
const MAX_BROADCAST_MESSAGE_TIMESTAMP_DRIFT_MILLIS: u64 =
    MAX_BROADCAST_MESSAGE_TIMESTAMP_DRIFT.as_millis() as u64;

const MAX_NUM_OF_BROADCAST_MESSAGES: u16 = 1000;
pub(crate) const DEFAULT_NUM_OF_BROADCAST_MESSAGE: u16 = 100;

const MAX_NUM_OF_ACTIVE_SYNCING_PEERS: usize = 3;
const MIN_NUM_OF_PASSIVE_SYNCING_PEERS: usize = 3;

const NUM_SIMULTANEOUS_GET_REQUESTS: usize = 1;
const GET_REQUEST_TIMEOUT: Duration = Duration::from_secs(20);

fn max_acceptable_gossip_message_timestamp() -> u64 {
    now_timestamp_as_millis_u64() + MAX_BROADCAST_MESSAGE_TIMESTAMP_DRIFT_MILLIS
}

pub trait GossipMessageStore {
    /// The implementors should guarantee that the returned messages are sorted by timestamp in the ascending order.
    fn get_broadcast_messages_iter(
        &self,
        after_cursor: &Cursor,
    ) -> impl IntoIterator<Item = BroadcastMessageWithTimestamp>;

    fn get_broadcast_messages(
        &self,
        after_cursor: &Cursor,
        count: Option<u16>,
    ) -> Vec<BroadcastMessageWithTimestamp> {
        self.get_broadcast_messages_iter(after_cursor)
            .into_iter()
            .take(count.unwrap_or(DEFAULT_NUM_OF_BROADCAST_MESSAGE) as usize)
            .collect()
    }

    fn query_broadcast_messages<I: IntoIterator<Item = BroadcastMessageQuery>>(
        &self,
        queries: I,
    ) -> (Vec<BroadcastMessageWithTimestamp>, Vec<u16>) {
        let mut results = Vec::new();
        let mut missing = Vec::new();
        for (index, query) in queries.into_iter().enumerate() {
            if let Some(message) = self.query_broadcast_message(query) {
                results.push(message);
            } else {
                missing.push(index as u16);
            }
        }
        (results, missing)
    }

    fn query_broadcast_message(
        &self,
        query: BroadcastMessageQuery,
    ) -> Option<BroadcastMessageWithTimestamp> {
        match query.flags {
            BroadcastMessageQueryFlags::ChannelAnnouncement => self
                .get_latest_channel_announcement(&query.channel_outpoint)
                .map(|(timestamp, channel_announcement)| {
                    BroadcastMessageWithTimestamp::ChannelAnnouncement(
                        timestamp,
                        channel_announcement,
                    )
                }),
            BroadcastMessageQueryFlags::ChannelUpdateOfNode1 => self
                .get_latest_channel_update(&query.channel_outpoint, true)
                .map(BroadcastMessageWithTimestamp::ChannelUpdate),
            BroadcastMessageQueryFlags::ChannelUpdateOfNode2 => self
                .get_latest_channel_update(&query.channel_outpoint, false)
                .map(BroadcastMessageWithTimestamp::ChannelUpdate),

            BroadcastMessageQueryFlags::NodeAnnouncementNode1
            | BroadcastMessageQueryFlags::NodeAnnouncementNode2 => self
                .get_latest_channel_announcement(&query.channel_outpoint)
                .and_then(|(_, channel_announcement)| {
                    let node = if query.flags == BroadcastMessageQueryFlags::NodeAnnouncementNode1 {
                        &channel_announcement.node1_id
                    } else {
                        &channel_announcement.node2_id
                    };
                    self.get_latest_node_announcement(node)
                        .map(BroadcastMessageWithTimestamp::NodeAnnouncement)
                }),
        }
    }

    fn get_broadcast_message_with_cursor(
        &self,
        cursor: &Cursor,
    ) -> Option<BroadcastMessageWithTimestamp>;

    fn get_latest_broadcast_message_cursor(&self) -> Option<Cursor>;

    fn get_latest_channel_announcement_timestamp(&self, outpoint: &OutPoint) -> Option<u64>;

    fn get_latest_channel_update_timestamp(
        &self,
        outpoint: &OutPoint,
        is_node1: bool,
    ) -> Option<u64>;

    fn get_latest_node_announcement_timestamp(&self, pk: &Pubkey) -> Option<u64>;

    fn get_latest_channel_announcement(
        &self,
        outpoint: &OutPoint,
    ) -> Option<(u64, ChannelAnnouncement)> {
        self.get_latest_channel_announcement_timestamp(outpoint)
            .and_then(|timestamp| {
                 self.get_broadcast_message_with_cursor(&Cursor::new(
                    timestamp,
                    BroadcastMessageID::ChannelAnnouncement(outpoint.clone()),
                )).map(|message| match message {
                    BroadcastMessageWithTimestamp::ChannelAnnouncement(
                        _,
                        channel_announcement,
                    ) => (timestamp, channel_announcement),
                    _ => panic!(
                        "get_latest_channel_announcement returned non-ChannelAnnouncement message from db: channel outpoint {:?}, message {:?}", outpoint, message
                    ),
                })
            })
    }

    fn get_latest_channel_update(
        &self,
        outpoint: &OutPoint,
        is_node1: bool,
    ) -> Option<ChannelUpdate> {
        self.get_latest_channel_update_timestamp(outpoint, is_node1)
            .and_then(|timestamp| {
                 self.get_broadcast_message_with_cursor(&Cursor::new(
                    timestamp,
                    BroadcastMessageID::ChannelUpdate(outpoint.clone()),
                )).map(|message| match message {
                    BroadcastMessageWithTimestamp::ChannelUpdate(channel_update) => channel_update,
                    _ => panic!("get_latest_channel_update returned non-ChannelUpdate message from db: channel outpoint {:?}, is_node1 {:?}, message {:?}", outpoint, is_node1, message),
                })
            })
    }

    fn get_latest_node_announcement(&self, pk: &Pubkey) -> Option<NodeAnnouncement> {
        self.get_latest_node_announcement_timestamp(pk).and_then(|timestamp| {
            self.get_broadcast_message_with_cursor(&Cursor::new(
                timestamp,
                BroadcastMessageID::NodeAnnouncement(*pk),
            )).map(|message|
                    match message {
                    BroadcastMessageWithTimestamp::NodeAnnouncement(node_announcement) => node_announcement,
                    _ => panic!("get_lastest_node_announcement returned non-NodeAnnouncement message from db: pk {:?}, message {:?}", pk, message),
                    }
                )
            }
        )
    }

    fn save_channel_announcement(&self, timestamp: u64, channel_announcement: ChannelAnnouncement);

    fn save_channel_update(&self, channel_update: ChannelUpdate);

    fn save_node_announcement(&self, node_announcement: NodeAnnouncement);
}

// A batch of gossip messages has been added to the store since the last time
// we pulled new messages/messages are pushed to us.
#[derive(Clone, Debug)]
pub struct GossipMessageUpdates {
    pub messages: Vec<BroadcastMessageWithTimestamp>,
}

impl GossipMessageUpdates {
    pub fn new(messages: Vec<BroadcastMessageWithTimestamp>) -> Self {
        Self { messages }
    }

    fn is_empty(&self) -> bool {
        self.messages.is_empty()
    }

    pub fn create_broadcast_messages_filter_result(&self) -> Option<BroadcastMessagesFilterResult> {
        (!self.is_empty()).then_some(BroadcastMessagesFilterResult {
            messages: self.messages.iter().map(|m| m.clone().into()).collect(),
        })
    }
}

/// New messages will be added to the store every now and then.
/// These messages are not guaranteed to be saved to the store in order.
/// This trait provides a way to subscribe to the updates of the gossip message store.
/// The subscriber will receive a batch of messages that are added to the store since the last time
/// we sent messages to the subscriber.
#[rasync_trait]
pub trait SubscribableGossipMessageStore {
    type Subscription;
    type Error: std::error::Error;

    /// Initialize a subscription for gossip message updates, the receiver will receive a batch of
    /// messages that are added to the store since the last time we sent messages to the receiver.
    /// These messages are first processed by the converter. When it is unideal to send messages to
    /// the receiver the converter should return a None, otherwise it can return some message of type
    /// TReceiverMsg, which would then be sent to the receiver actor.
    /// The cursor here specifies the starting point of the subscription.
    /// If there are already some messages in the store that are newer than the cursor, the receiver
    /// will receive these messages immediately after the subscription is created.
    /// Note that the messages are not guaranteed to be sent in ascending order of timestamp,
    /// or in the order of logic dependency (e.g. ChannelAnnouncement is sent before ChannelUpdate).
    /// But we guarantee that the dependencies of the messages will eventually be sent out.
    /// Or if an message is sent to the receiver, all its dependencies are already saved to the store.
    /// We only make this weak guarantee because it simplifies the implementation a lot.
    /// The above weak guarantee is enough for two of the use cases of this subscription:
    /// 1. Sending newer gossip messages to peers via BroadcastMessageFilterResult.
    /// 2. Updating graph data structures (e.g. ChannelManager) with the latest gossip messages.
    /// For the first use case, all the messages are cached first, so we won't directly save a
    /// message without unmet dependencies to the store. For the second use case, we can always
    /// read their dependencies from the store.
    async fn subscribe<
        TReceiverMsg: ractor::Message,
        F: Fn(GossipMessageUpdates) -> Option<TReceiverMsg> + Send + 'static,
    >(
        &self,
        cursor: Cursor,
        receiver: ActorRef<TReceiverMsg>,
        converter: F,
    ) -> Result<Self::Subscription, Self::Error>;

    /// Update the subscription to the gossip message store updates. The subscription parameter is the
    /// return value of the subscribe function. The new cursor will be used to determine the
    /// starting point of the next batch of messages that will be sent to the receiver.
    async fn update_subscription(
        &self,
        subscription: &Self::Subscription,
        cursor: Cursor,
    ) -> Result<(), Self::Error>;

    // Unsubscribe from the gossip message store updates. The subscription parameter is the return value
    // of the subscribe function. After this function is called, the receiver will no longer
    // receive messages from the store.
    async fn unsubscribe(&self, subscription: &Self::Subscription) -> Result<(), Self::Error>;
}

#[derive(Debug)]
pub enum GossipActorMessage {
    // Network events to be processed by this actor.
    PeerConnected(PeerId, Pubkey, SessionContext),
    PeerDisconnected(PeerId, SessionContext),

    // Current implementation will take a few connected peers and send BroadcastMessageFilter to them.
    // It is almost certain that we will send the filter to the peers that we connected to first.
    // This message will be used to rotate the list of peers that we send the filter to,
    // which will make the network more robust.
    RotateOutboundPassiveSyncingPeers,

    // The function of TickNetworkMaintenance is to maintain the network state.
    // Currently it will do the following things:
    // 1. Check if we have sufficient number of peers to receive broadcasts. If not, send more BroadcastMessageFilter.
    // 2. Check if there are any pending broadcast message queries. If so, broadcast them to the network.
    TickNetworkMaintenance,

    // The active syncing process is finished for a peer.
    ActiveSyncingFinished(PeerId, Cursor),

    // A malicious peer is found. We should disconnect from the peer.
    MaliciousPeerFound(PeerId),

    // Process BroadcastMessage from the network. This is mostly used to save a broadcast message
    // not received from gossip message protocol to the store. Examples of such messages are
    // our own node announcement messages, channel updates from the onion error packets, etc.
    ProcessBroadcastMessage(BroadcastMessage),
    // Query some broadcast messages from a peer.
    QueryBroadcastMessages(PeerId, Vec<BroadcastMessageQuery>),
    // Try to broadcast BroadcastMessage created by us to the network.
    // We will save and broadcast the messages. Note that we don't check the dependencies of
    // these messages because we assume that the messages created by us are always valid.
    TryBroadcastMessages(Vec<BroadcastMessageWithTimestamp>),
    // Send gossip message to a peer.
    SendGossipMessage(GossipMessageWithPeerId),
    // Received GossipMessage from a peer
    GossipMessageReceived(GossipMessageWithPeerId),
}

pub(crate) struct GossipActor<S> {
    _phantom: std::marker::PhantomData<S>,
}

impl<S> GossipActor<S> {
    fn new() -> Self {
        Self {
            _phantom: Default::default(),
        }
    }
}

#[derive(Debug, Default)]
struct SyncingPeerState {
    failed_times: usize,
}

pub struct GossipSyncingActorState<S> {
    peer_id: PeerId,
    gossip_actor: ActorRef<GossipActorMessage>,
    chain_actor: ActorRef<CkbChainMessage>,
    store: ExtendedGossipMessageStore<S>,
    // The problem of using the cursor from the store is that a malicious peer may only
    // send large cursor to us, which may cause us to miss some messages.
    // So we decide to keep a cursor for each peer.
    // Of course, using different cursor for different peers will waste
    // some bandwidth by requesting the same messages from different peers.
    cursor: Cursor,
    peer_state: SyncingPeerState,
    request_id: u64,
    inflight_requests:
        HashMap<u64, JoinHandle<Result<(), MessagingErr<GossipSyncingActorMessage>>>>,
}

impl<S> GossipSyncingActorState<S> {
    fn new(
        peer_id: PeerId,
        gossip_actor: ActorRef<GossipActorMessage>,
        chain_actor: ActorRef<CkbChainMessage>,
        store: ExtendedGossipMessageStore<S>,
        cursor: Cursor,
    ) -> Self {
        Self {
            peer_id,
            gossip_actor,
            chain_actor,
            store,
            cursor,
            peer_state: Default::default(),
            inflight_requests: Default::default(),
            request_id: 0,
        }
    }

    fn get_cursor(&self) -> &Cursor {
        &self.cursor
    }

    fn get_and_increment_request_id(&mut self) -> u64 {
        let id = self.request_id;
        self.request_id += 1;
        id
    }
}

pub(crate) struct GossipSyncingActor<S> {
    _phantom: std::marker::PhantomData<S>,
}

impl<S> GossipSyncingActor<S> {
    fn new() -> Self {
        Self {
            _phantom: Default::default(),
        }
    }
}

pub(crate) enum GossipSyncingActorMessage {
    // A GetBroadcastMessages request to the syncing peer has timed out.
    RequestTimeout(u64),
    // A GetBroadcastMessagesResult response from the syncing peer.
    ResponseReceived(GetBroadcastMessagesResult),
    // Initiate a new GetBroadcastMessages request.
    // Mostly triggered by a timeout or a response received.
    NewGetRequest(),
}

#[rasync_trait]
impl<S> Actor for GossipSyncingActor<S>
where
    S: GossipMessageStore + Clone + Send + Sync + 'static,
{
    type Msg = GossipSyncingActorMessage;
    type State = GossipSyncingActorState<S>;
    type Arguments = (
        PeerId,
        ActorRef<GossipActorMessage>,
        ActorRef<CkbChainMessage>,
        ExtendedGossipMessageStore<S>,
        Cursor,
    );

    async fn pre_start(
        &self,
        myself: ActorRef<Self::Msg>,
        (peer_id, gossip_actor, chain_actor, store, cursor): Self::Arguments,
    ) -> Result<Self::State, ActorProcessingErr> {
        myself
            .send_message(GossipSyncingActorMessage::NewGetRequest())
            .expect("gossip syncing actor alive");
        Ok(GossipSyncingActorState::new(
            peer_id,
            gossip_actor,
            chain_actor,
            store,
            cursor,
        ))
    }

    async fn handle(
        &self,
        myself: ActorRef<Self::Msg>,
        message: Self::Msg,
        state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        match message {
            GossipSyncingActorMessage::RequestTimeout(request_id) => {
                state.inflight_requests.remove(&request_id);
                // TODO: When the peer failed for too many times, we should consider disconnecting from the peer.
                state.peer_state.failed_times += 1;
                myself
                    .send_message(GossipSyncingActorMessage::NewGetRequest())
                    .expect("gossip syncing actor alive");
            }
            GossipSyncingActorMessage::ResponseReceived(result) => {
                trace!(
                    "Received GetBroadcastMessages response from peer {:?}: {:?}",
                    &state.peer_id,
                    result
                );
                if let Some(handle) = state.inflight_requests.remove(&result.id) {
                    // Stop the timeout notification.
                    handle.abort();
                    let messages = result.messages;
                    // If we are receiving an empty response, then the syncing process is finished.
                    match messages.last() {
                        Some(last_message) => {
                            // We need the message timestamp to construct a valid cursor.
                            match get_message_cursor(
                                last_message,
                                &state.store.store,
                                &state.chain_actor,
                            )
                            .await
                            {
                                Ok(cursor) => {
                                    state.cursor = cursor;
                                }
                                Err(error) => {
                                    warn!(
                                        "Failed to verify the last message in the response: message {:?}, peer {:?}",
                                        error, &state.peer_id
                                    );
                                    myself.stop(Some(
                                        "Failed to verify the last message in the response"
                                            .to_string(),
                                    ));
                                    state
                                        .gossip_actor
                                        .send_message(GossipActorMessage::MaliciousPeerFound(
                                            state.peer_id.clone(),
                                        ))
                                        .expect("gossip actor alive");
                                    return Ok(());
                                }
                            }
                        }
                        None => {
                            state
                                .gossip_actor
                                .send_message(GossipActorMessage::ActiveSyncingFinished(
                                    state.peer_id.clone(),
                                    state.cursor.clone(),
                                ))
                                .expect("gossip actor alive");
                            myself.stop(Some("Active syncing finished".to_string()));
                            return Ok(());
                        }
                    }

                    let _ = state
                        .store
                        .actor
                        .send_message(ExtendedGossipMessageStoreMessage::SaveMessages(messages))
                        .expect("store actor alive");
                    myself
                        .send_message(GossipSyncingActorMessage::NewGetRequest())
                        .expect("gossip syncing actor alive");
                } else {
                    warn!(
                        "Received GetBroadcastMessages response from peer {:?} with unknown request id: {:?}",
                        state.peer_id, result
                    );
                }
            }
            GossipSyncingActorMessage::NewGetRequest() => {
                let latest_cursor = state.get_cursor().clone();
                let request_id = state.get_and_increment_request_id();
                trace!(
                    "Sending GetBroadcastMessages request to peers: request_id {}, latest_cursor {:?}",
                    request_id, latest_cursor
                );
                let request = GossipMessage::GetBroadcastMessages(GetBroadcastMessages {
                    id: request_id,
                    chain_hash: get_chain_hash(),
                    after_cursor: latest_cursor,
                    count: DEFAULT_NUM_OF_BROADCAST_MESSAGE,
                });
                // Send a new GetBroadcastMessages request to the newly-connected peer.
                // If we have less than NUM_SIMULTANEOUS_GET_REQUESTS requests inflight.
                if state.inflight_requests.len() > NUM_SIMULTANEOUS_GET_REQUESTS {
                    return Ok(());
                }
                state
                    .gossip_actor
                    .send_message(GossipActorMessage::SendGossipMessage(
                        GossipMessageWithPeerId {
                            peer_id: state.peer_id.clone(),
                            message: request,
                        },
                    ))
                    .expect("gossip actor alive");
                // Send a timeout message to myself after 20 seconds, which will then send another GetRequest.
                let handle = myself.send_after(GET_REQUEST_TIMEOUT, move || {
                    GossipSyncingActorMessage::RequestTimeout(request_id)
                });
                // If the request with the same request_id is completed before the timeout,
                // we will use this handle to cancel the timeout notification.
                state.inflight_requests.insert(request_id, handle);
            }
        }
        Ok(())
    }
}

#[derive(Debug)]
struct PeerFilterProcessor {
    // It is sometimes useful to get the filter from the processor (e.g.
    // when we need to actively send a message to the peer).
    filter: Cursor,
    // The actor which watches the store updates and sends corresponding messages to the peer.
    actor: ActorRef<PeerFilterProcessorMessage>,
}

impl PeerFilterProcessor {
    async fn new<S>(
        store: S,
        peer: PeerId,
        filter: Cursor,
        gossip_actor: ActorRef<GossipActorMessage>,
    ) -> Self
    where
        S: SubscribableGossipMessageStore + Clone + Send + Sync + 'static,
        S::Subscription: Send,
    {
        let supervisor = gossip_actor.get_cell();
        let (actor, _) = Actor::spawn_linked(
            Some(format!(
                "peer filter actor for peer {:?} supervised by {:?}",
                &peer,
                gossip_actor.get_id(),
            )),
            PeerFilterActor {
                store,
                peer,
                gossip_actor,
            },
            filter.clone(),
            supervisor,
        )
        .await
        .expect("start peer filter processor actor");
        Self { filter, actor }
    }

    fn update_filter(&mut self, filter: &Cursor) {
        self.filter = filter.clone();
        self.actor
            .send_message(PeerFilterProcessorMessage::UpdateFilter(filter.clone()))
            .expect("peer filter processor actor alive");
    }
}

struct PeerFilterActor<S> {
    store: S,
    peer: PeerId,
    gossip_actor: ActorRef<GossipActorMessage>,
}

enum PeerFilterProcessorMessage {
    NewStoreUpdates(GossipMessageUpdates),
    UpdateFilter(Cursor),
}

#[rasync_trait]
impl<S> Actor for PeerFilterActor<S>
where
    S: SubscribableGossipMessageStore + Clone + Send + Sync + 'static,
    S::Subscription: Send,
{
    type Msg = PeerFilterProcessorMessage;
    type State = S::Subscription;
    type Arguments = Cursor;

    async fn pre_start(
        &self,
        myself: ActorRef<Self::Msg>,
        filter_cursor: Cursor,
    ) -> Result<Self::State, ActorProcessingErr> {
        let subscription = self
            .store
            .subscribe(filter_cursor, myself, |m| {
                Some(PeerFilterProcessorMessage::NewStoreUpdates(m))
            })
            .await
            .expect("subscribe store updates");
        Ok(subscription)
    }

    async fn handle(
        &self,
        _myself: ActorRef<Self::Msg>,
        message: Self::Msg,
        subscription: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        match message {
            PeerFilterProcessorMessage::NewStoreUpdates(updates) => {
                if let Some(result) = updates.create_broadcast_messages_filter_result() {
                    self.gossip_actor
                        .send_message(GossipActorMessage::SendGossipMessage(
                            GossipMessageWithPeerId {
                                peer_id: self.peer.clone(),
                                message: GossipMessage::BroadcastMessagesFilterResult(result),
                            },
                        ))
                        .expect("gossip actor alive");
                }
            }
            PeerFilterProcessorMessage::UpdateFilter(cursor) => {
                self.store
                    .update_subscription(subscription, cursor)
                    .await
                    .expect("update subscription");
            }
        }
        Ok(())
    }

    async fn post_stop(
        &self,
        _myself: ActorRef<Self::Msg>,
        subscription: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        let _ = self.store.unsubscribe(subscription).await;
        Ok(())
    }
}

// The PeerSyncStatus is used to track the syncing status with a peer.
// Typically, on startup, we will actively obtain the latest messages from the peer.
// After the peer returns a empty response for broadcast messages, we deem that we
// are now in sync with the peer. We will then find if we have been in sync with
// enough number of peers. If not, continue above process.
// After we have been in sync with enough number of peers, we will send a
// BroadcastMessageFilter to enough number of peers to passively receive
// updates.
#[derive(Debug)]
#[allow(dead_code)]
enum PeerSyncStatus {
    // We are not syncing with the peer.
    NotSyncing(),
    // We are actively sending GetBroadcastMessages to the peer.
    // The actor here is responsible to get syncing process running.
    ActiveGet(ActorRef<GossipSyncingActorMessage>),
    // We are only passively receiving messages from the peer.
    // The cursor here is the filter that we sent to the peer.
    PassiveFilter(Cursor),
    // We have finished syncing with the peer. The cursor here is the latest cursor
    // that we have received from the peer. The u64 here is the timestamp
    // of the finishing syncing time.
    FinishedActiveSyncing(u64, Cursor),
}

impl PeerSyncStatus {
    fn is_passive_syncing(&self) -> bool {
        matches!(self, PeerSyncStatus::PassiveFilter(_))
    }

    fn is_active_syncing(&self) -> bool {
        matches!(self, PeerSyncStatus::ActiveGet(_))
    }

    fn is_finished_active_syncing(&self) -> bool {
        matches!(self, PeerSyncStatus::FinishedActiveSyncing(_, _))
    }

    fn can_start_active_syncing(&self) -> bool {
        !self.is_active_syncing()
            && !self.is_passive_syncing()
            && !self.is_finished_active_syncing()
    }

    fn can_start_passive_syncing(&self) -> bool {
        !self.is_passive_syncing() && !self.is_active_syncing()
    }
}

impl Default for PeerSyncStatus {
    fn default() -> Self {
        Self::NotSyncing()
    }
}

#[derive(Debug)]
struct PeerState {
    session_id: SessionId,
    session_type: SessionType,
    // The filter is a cursor that the peer sent to us. We will only send messages to the peer
    // that are newer than the cursor. If the peer has not sent us a filter, we will not actively
    // send messages to the peer. If the peer sends us a new filter, we will update this field,
    // and send all the messages after the cursor to the peer immediately.
    filter_processor: Option<PeerFilterProcessor>,
    // The status of the peer syncing.
    sync_status: PeerSyncStatus,
}

impl Drop for PeerState {
    fn drop(&mut self) {
        if let Some(filter_processor) = self.filter_processor.take() {
            filter_processor
                .actor
                .stop(Some("peer state dropped".to_string()));
        }
        if let PeerSyncStatus::ActiveGet(actor) = &self.sync_status {
            actor.stop(Some("peer state dropped".to_string()));
        }
    }
}

impl PeerState {
    fn new(session_id: SessionId, session_type: SessionType) -> Self {
        Self {
            session_id,
            session_type,
            filter_processor: Default::default(),
            sync_status: Default::default(),
        }
    }

    fn change_sync_status(&mut self, new_status: PeerSyncStatus) {
        self.sync_status = new_status;
    }
}

// This ExtendedGossipMessageStore is used to store the gossip messages and their dependencies.
// It enhances the GossipMessageStore trait with the ability to check the dependencies of the messages,
// and occasionally send out messages that are saved out of order (a message with smaller timestamp
// was saved before a message with larger timestamp).
#[derive(Clone)]
pub struct ExtendedGossipMessageStore<S> {
    // It is possible to re-implement all the store functions by message-passing to the actor.
    // But it is tedious to do so. So we just store the store here.
    // We need to get/save broadcast messages from/to the store. We can use this field directly.
    // Be careful while saving messages to the store. We should send SaveMessage message to the actor
    // because we must ask the actor do some bookkeeping work (e.g. check if the dependencies of
    // the message are already saved).
    pub(crate) store: S,
    // The actor that is responsible for book-keep the messages to be saved to the store,
    // and send messages to the subscribers.
    pub(crate) actor: ActorRef<ExtendedGossipMessageStoreMessage>,
}

impl<S> ExtendedGossipMessageStore<S> {
    fn get_store(&self) -> &S {
        &self.store
    }
}

impl<S> ExtendedGossipMessageStore<S>
where
    S: GossipMessageStore + Send + Sync + Clone + 'static,
{
    async fn new(
        maintenance_interval: Duration,
        announce_private_addr: bool,
        store: S,
        chain_actor: ActorRef<CkbChainMessage>,
        supervisor: ActorCell,
    ) -> Self {
        let (actor, _) = Actor::spawn_linked(
            Some(format!(
                "gossip message store actor supervised by {:?}",
                supervisor.get_id()
            )),
            ExtendedGossipMessageStoreActor::new(),
            (
                maintenance_interval,
                announce_private_addr,
                store.clone(),
                chain_actor,
            ),
            supervisor,
        )
        .await
        .expect("start gossip message actor store");

        Self { store, actor }
    }
}

#[rasync_trait]
impl<S: GossipMessageStore + Sync> SubscribableGossipMessageStore
    for ExtendedGossipMessageStore<S>
{
    type Subscription = u64;
    type Error = Error;

    async fn subscribe<
        TReceiverMsg: ractor::Message,
        F: Fn(GossipMessageUpdates) -> Option<TReceiverMsg> + Send + 'static,
    >(
        &self,
        cursor: Cursor,
        receiver: ActorRef<TReceiverMsg>,
        converter: F,
    ) -> Result<Self::Subscription, Self::Error> {
        match call!(
            &self.actor,
            ExtendedGossipMessageStoreMessage::NewSubscription,
            cursor
        ) {
            Ok((subscription, tx, output_port)) => {
                output_port.subscribe(receiver, converter);
                // It is sometimes possible that some messages are sent to the output_port even
                // before we subscribe to it (in this case we will miss these messages).
                // So we use a channel to notify that we have already subscribed to the output_port,
                // and messages can now be sent to the output_port.
                tx.send(()).expect("notify new subscription ready");
                Ok(subscription)
            }
            Err(e) => Err(Error::InternalError(anyhow::anyhow!(e.to_string()))),
        }
    }

    async fn update_subscription(
        &self,
        subscription: &Self::Subscription,
        cursor: Cursor,
    ) -> Result<(), Self::Error> {
        const DEFAULT_TIMEOUT: u64 = Duration::from_secs(5).as_millis() as u64;
        call_t!(
            &self.actor,
            ExtendedGossipMessageStoreMessage::UpdateSubscription,
            DEFAULT_TIMEOUT,
            *subscription,
            Some(cursor)
        )
        .map_err(|e| Error::InternalError(anyhow::anyhow!(e.to_string())))
    }

    async fn unsubscribe(&self, subscription: &Self::Subscription) -> Result<(), Self::Error> {
        const DEFAULT_TIMEOUT: u64 = Duration::from_secs(5).as_millis() as u64;
        call_t!(
            &self.actor,
            ExtendedGossipMessageStoreMessage::UpdateSubscription,
            DEFAULT_TIMEOUT,
            *subscription,
            None
        )
        .map_err(|e| Error::InternalError(anyhow::anyhow!(e.to_string())))
    }
}

struct BroadcastMessageOutput {
    // The filter that a subscriber has set.
    filter: Cursor,
    // A port that from which the subscriber will receive messages and from which we will send messages to the subscriber.
    output_port: Arc<OutputPort<GossipMessageUpdates>>,
}

impl BroadcastMessageOutput {
    fn new(filter: Cursor, output_port: Arc<OutputPort<GossipMessageUpdates>>) -> Self {
        Self {
            filter,
            output_port,
        }
    }
}

// This is the error type for processing the gossip messages.
// Sometimes we can't be very sure of if a gossip message is valid on a first sight.
// For example, a ChannelUpdate message may be signed with a different node's key,
// but we won't be able to find this out until we have the corresponding ChannelAnnouncement.
#[derive(Debug, Clone, thiserror::Error)]
pub enum GossipMessageProcessingError {
    #[error("The message timestamp is too far in the future: expected to before {1}, has {0}")]
    MessageTooNew(u64, u64),
    #[error("Failed to process the message: {0}")]
    ProcessingError(String),
    #[error("A newer message is already saved: {0:?}")]
    NewerMessageSaved(BroadcastMessageWithTimestamp),
}

pub struct ExtendedGossipMessageStoreState<S> {
    announce_private_addr: bool,
    store: S,
    chain_actor: ActorRef<CkbChainMessage>,
    next_id: u64,
    output_ports: HashMap<u64, BroadcastMessageOutput>,
    messages_to_be_saved: HashSet<BroadcastMessage>,
}

impl<S: GossipMessageStore> ExtendedGossipMessageStoreState<S> {
    fn new(announce_private_addr: bool, store: S, chain_actor: ActorRef<CkbChainMessage>) -> Self {
        Self {
            announce_private_addr,
            store,
            chain_actor,
            next_id: Default::default(),
            output_ports: Default::default(),
            messages_to_be_saved: Default::default(),
        }
    }

    // Obtaining all the messages whose transitive dependencies are already available,
    // check their validity and then save valid messages to store and
    // return the list of saved messages that can be sent to the subscribers.
    async fn prune_messages_to_be_saved(&mut self) -> Vec<BroadcastMessageWithTimestamp> {
        // Note that we have to call has_dependencies_available before changing messages_to_be_saved,
        // as the function will check the dependencies of the message in the current messages_to_be_saved.
        let (complete_messages, incomplete_messages) = self
            .messages_to_be_saved
            .clone()
            .into_iter()
            .partition(|m| self.has_dependencies_available(m));
        self.messages_to_be_saved = incomplete_messages;

        let mut sorted_messages = complete_messages.into_iter().collect::<Vec<_>>();
        sorted_messages.sort_unstable();
        trace!(
            "Saving complete messages to the store: {:?}",
            &sorted_messages
        );

        let mut verified_sorted_messages = Vec::with_capacity(sorted_messages.len());
        for message in sorted_messages {
            match verify_and_save_broadcast_message(&message, &self.store, &self.chain_actor).await
            {
                Ok(message) => {
                    verified_sorted_messages.push(message);
                }
                Err(error) => {
                    trace!(
                        "Failed to verify and save message {:?}: {:?}",
                        message,
                        error
                    );
                }
            }
        }

        verified_sorted_messages
    }

    fn store_messages(&mut self, messages: &[BroadcastMessageWithTimestamp]) {
        for message in messages {
            match message {
                BroadcastMessageWithTimestamp::ChannelAnnouncement(
                    timestamp,
                    channel_announcement,
                ) => {
                    self.store
                        .save_channel_announcement(*timestamp, channel_announcement.clone());
                }
                BroadcastMessageWithTimestamp::ChannelUpdate(channel_update) => {
                    self.store.save_channel_update(channel_update.clone());
                }
                BroadcastMessageWithTimestamp::NodeAnnouncement(node_announcement) => {
                    self.store.save_node_announcement(node_announcement.clone());
                }
            }
        }
    }

    fn broadcast_messages(&mut self, messages: &[BroadcastMessageWithTimestamp]) {
        if messages.is_empty() {
            return;
        }

        for (id, subscription) in self.output_ports.iter() {
            let messages_to_send = messages
                .iter()
                .filter(|m| m.cursor() > subscription.filter)
                .cloned()
                .collect::<Vec<_>>();
            trace!(
                "Sending complete messages in memory to subscription #{}: number of messages = {}",
                id,
                messages_to_send.len()
            );
            for chunk in messages_to_send.chunks(MAX_NUM_OF_BROADCAST_MESSAGES as usize) {
                subscription
                    .output_port
                    .send(GossipMessageUpdates::new(chunk.to_vec()));
            }
        }
    }

    fn store_and_broadcast_messages(&mut self, messages: &[BroadcastMessageWithTimestamp]) {
        self.store_messages(messages);
        self.broadcast_messages(messages);
    }

    fn get_channel_annnouncement(&self, outpoint: &OutPoint) -> Option<ChannelAnnouncement> {
        self.store
            .get_latest_channel_announcement(outpoint)
            .map(|(_, m)| m)
            .or_else(|| self.get_channel_annnouncement_in_memory(outpoint))
    }

    fn get_channel_annnouncement_in_memory(
        &self,
        outpoint: &OutPoint,
    ) -> Option<ChannelAnnouncement> {
        self.messages_to_be_saved.iter().find_map(|m| match m {
            BroadcastMessage::ChannelAnnouncement(channel_announcement)
                if &channel_announcement.channel_outpoint == outpoint =>
            {
                Some(channel_announcement.clone())
            }
            _ => None,
        })
    }

    async fn insert_message_to_be_saved_list(
        &mut self,
        message: &BroadcastMessage,
    ) -> Result<(), GossipMessageProcessingError> {
        if let Some(existing_message) = get_existing_newer_broadcast_message(message, &self.store) {
            if &BroadcastMessage::from(existing_message.clone()) != message {
                return Err(GossipMessageProcessingError::NewerMessageSaved(
                    existing_message,
                ));
            } else {
                return Ok(());
            }
        }

        if self.messages_to_be_saved.contains(message) {
            return Ok(());
        }

        if let Some(timestamp) = message.timestamp() {
            let max_acceptable_gossip_message_timestamp = max_acceptable_gossip_message_timestamp();
            if timestamp > max_acceptable_gossip_message_timestamp {
                return Err(GossipMessageProcessingError::MessageTooNew(
                    timestamp,
                    max_acceptable_gossip_message_timestamp,
                ));
            }
        }

        if !self.announce_private_addr {
            if let BroadcastMessage::NodeAnnouncement(node_announcement) = &message {
                if !node_announcement.addresses.iter().any(|addr| {
                    multiaddr_to_socketaddr(addr)
                        .map(|socket_addr| is_reachable(socket_addr.ip()))
                        .unwrap_or_default()
                }) {
                    return Err(GossipMessageProcessingError::ProcessingError(
                        "private address node announcement".to_string(),
                    ));
                }
            }
        }

        trace!("New gossip message saved to memory: {:?}", message);
        self.messages_to_be_saved.insert(message.clone());
        Ok(())
    }

    fn has_dependencies_available(&self, message: &BroadcastMessage) -> bool {
        match message {
            BroadcastMessage::ChannelUpdate(channel_update) => self
                .get_channel_annnouncement(&channel_update.channel_outpoint)
                .is_some(),
            _ => true,
        }
    }
}

// An extended gossip message store actor that can handle more complex operations than a normal gossip message store.
// Major features are added to this actor:
// 1). It can stash lagged messages (messages arrived at this node out of order) as as to
// send them to the subscribers eventually.
// 2). It can manage the dependencies of the messages and save them to the store in the correct order,
// which means that the messages in the store is always consistent.
// 3). Used in ExtendedGossipMessageStore, we can subscribe to the updates of the store, which means that
// it is possible to get a consistent view of the store without loading all the messages from the store.
struct ExtendedGossipMessageStoreActor<S> {
    phantom: PhantomData<S>,
}

impl<S: GossipMessageStore> ExtendedGossipMessageStoreActor<S> {
    fn new() -> Self {
        Self {
            phantom: Default::default(),
        }
    }
}

#[rasync_trait]
impl<S: GossipMessageStore + Send + Sync + 'static> Actor for ExtendedGossipMessageStoreActor<S> {
    type Msg = ExtendedGossipMessageStoreMessage;
    type State = ExtendedGossipMessageStoreState<S>;
    type Arguments = (Duration, bool, S, ActorRef<CkbChainMessage>);

    async fn pre_start(
        &self,
        myself: ActorRef<Self::Msg>,
        (
            gossip_store_maintenance_interval,
            announce_private_addr,
            store,
            chain_actor,
        ): Self::Arguments,
    ) -> Result<Self::State, ActorProcessingErr> {
        myself.send_interval(gossip_store_maintenance_interval, || {
            ExtendedGossipMessageStoreMessage::Tick
        });
        Ok(ExtendedGossipMessageStoreState::new(
            announce_private_addr,
            store,
            chain_actor,
        ))
    }

    async fn handle(
        &self,
        myself: ActorRef<Self::Msg>,
        message: Self::Msg,
        state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        match message {
            ExtendedGossipMessageStoreMessage::NewSubscription(cursor, reply) => {
                trace!(
                    "Creating subscription to the store updates with cursor {:?}",
                    cursor
                );
                let id = state.next_id;
                state.next_id += 1;
                let (tx, rx) = oneshot::channel();
                let output_port = Arc::new(OutputPort::default());
                if let Err(error) = reply.send((id, tx, Arc::clone(&output_port))) {
                    error!(
                        "Failed to send reply to new subscription (has the caller exited?): {:?}",
                        error
                    );
                    return Ok(());
                }
                rx.await.expect("receive notification");
                trace!(
                    "Loading messages from store for subscriber {}: subscription cursor {:?}",
                    id,
                    cursor
                );
                // Since the handling of LoadMessagesFromStore interleaves with the handling of Tick,
                // we may send the messages in an order that is different from both the dependency order
                // and the timestamp order. This means that we may send a ChannelUpdate while handling
                // Tick and later we will send the corresponding ChannelAnnouncement.
                // So the downstream consumer need to either cache some of the messages and wait for the
                // dependent messages to arrive or read the messages from the store directly.
                myself
                    .send_message(ExtendedGossipMessageStoreMessage::LoadMessagesFromStore(
                        id,
                        cursor.clone(),
                    ))
                    .expect("myself alive");
                state.output_ports.insert(
                    id,
                    BroadcastMessageOutput::new(cursor, Arc::clone(&output_port)),
                );
            }

            ExtendedGossipMessageStoreMessage::UpdateSubscription(id, cursor, reply) => {
                trace!(
                    "Updating subscription to store updates for #{} with cursor {:?}",
                    id,
                    cursor
                );

                match cursor {
                    Some(cursor) => {
                        if let Some(outpout) = state.output_ports.get_mut(&id) {
                            outpout.filter = cursor;
                        }
                    }
                    _ => {
                        state.output_ports.remove(&id);
                    }
                }
                let _ = reply.send(());
            }

            ExtendedGossipMessageStoreMessage::LoadMessagesFromStore(id, cursor) => {
                let subscription = match state.output_ports.get_mut(&id) {
                    Some(output) => output,
                    // Subscriber has already unsubscribed, early return.
                    None => return Ok(()),
                };
                let messages = state
                    .store
                    .get_broadcast_messages(&cursor, Some(DEFAULT_NUM_OF_BROADCAST_MESSAGE))
                    .into_iter()
                    .collect::<Vec<_>>();
                trace!(
                    "Loaded messages for subscription #{} with cursor {:?} (number of messages {:?})",
                    id,
                    cursor,
                    messages.len()
                );
                match messages.last() {
                    Some(m) => {
                        myself
                            .send_message(ExtendedGossipMessageStoreMessage::LoadMessagesFromStore(
                                id,
                                m.cursor(),
                            ))
                            .expect("actor alive");
                        subscription
                            .output_port
                            .send(GossipMessageUpdates::new(messages));
                    }
                    None => {
                        // We have finished initial loading.
                    }
                }
            }

            ExtendedGossipMessageStoreMessage::SaveMessages(messages) => {
                for message in messages {
                    if let Err(error) = state.insert_message_to_be_saved_list(&message).await {
                        trace!("Failed to save message: {:?}, error: {:?}", message, error);
                    }
                }
            }

            ExtendedGossipMessageStoreMessage::SaveAndBroadcastMessages(messages) => {
                state.store_and_broadcast_messages(&messages);
            }

            ExtendedGossipMessageStoreMessage::Tick => {
                trace!(
                    "Gossip store maintenance ticked: #subscriptions = {},  #messages_to_be_saved = {}",
                    state.output_ports.len(),
                    state.messages_to_be_saved.len(),
                );

                // These are the messages that have complete dependencies and can be sent to the subscribers.
                let complete_messages = state.prune_messages_to_be_saved().await;
                state.broadcast_messages(&complete_messages);
            }
        }
        Ok(())
    }
}

pub enum ExtendedGossipMessageStoreMessage {
    // A new subscription for gossip message updates. We will send a batch of messages to the subscriber
    // via the returned output port.
    NewSubscription(
        Cursor,
        RpcReplyPort<(
            u64,
            oneshot::Sender<()>, // A channel to notify the subscriber that the subscription is ready.
            Arc<OutputPort<GossipMessageUpdates>>,
        )>,
    ),
    // Update the subscription. If this Option is None, the subscription will be cancelled.
    // Otherwise the new cursor will be used to filter the messages that are sent to the subscriber.
    UpdateSubscription(u64, Option<Cursor>, RpcReplyPort<()>),
    // Save new broadcast messages to the store. The messages will be first saved to the memory,
    // then if all the dependencies are met, they are periodically saved to the store and sent to the subscribers.
    SaveMessages(Vec<BroadcastMessage>),
    // Save new messages to the store, and broadcast them to the subscribers immediately.
    // These messages will not be saved to the memory and wait for the dependencies to be met.
    // We normally use this variant to send our own messages to the subscribers.
    SaveAndBroadcastMessages(Vec<BroadcastMessageWithTimestamp>),
    // Send broadcast messages after the cursor to the subscriber specified in the u64 id.
    // This is normally called immediately after a new subscription is created. This is the time when
    // we need to send existing messages to the subscriber.
    LoadMessagesFromStore(u64, Cursor),
    // A tick message that is sent periodically to check if there are any messages that are saved out of order.
    // If there are, we will send them to the subscribers.
    Tick,
}

pub(crate) struct GossipActorState<S> {
    store: ExtendedGossipMessageStore<S>,
    control: ServiceAsyncControl,
    // The number of active syncing peers that we have finished syncing with.
    // Together with the number of current active syncing peers, this is
    // used to determine if we should start a new active syncing peer.
    num_finished_active_syncing_peers: usize,
    // The number of targeted active syncing peers that we want to have.
    // Currently we will only start this many active syncing peers.
    num_targeted_active_syncing_peers: usize,
    // The number of outbound passive syncing peers that we want to have.
    // We only count outbound peers because the purpose of this number is to avoid eclipse attacks.
    // By maintaining a certain number of outbound passive syncing peers, we can ensure that we are
    // not isolated from the network.
    num_targeted_outbound_passive_syncing_peers: usize,
    next_request_id: u64,
    myself: ActorRef<GossipActorMessage>,
    chain_actor: ActorRef<CkbChainMessage>,
    // There are some messages missing from our store, and we need to query them from peers.
    // These messages include channel updates and node announcements related to channel announcements,
    // and channel announcements related to channel updates.
    pending_queries: Vec<BroadcastMessageQuery>,
    peer_states: HashMap<PeerId, PeerState>,
}

impl<S> GossipActorState<S>
where
    S: GossipMessageStore + Clone + Send + Sync + 'static,
{
    fn is_ready_for_passive_syncing(&self) -> bool {
        self.num_finished_active_syncing_peers > 0
    }

    fn num_of_active_syncing_peers(&self) -> usize {
        self.peer_states
            .values()
            .filter(|state| state.sync_status.is_active_syncing())
            .count()
    }

    fn num_of_passive_syncing_peers(&self) -> usize {
        self.passive_syncing_peers().len()
    }

    fn num_of_outbound_passive_syncing_peers(&self) -> usize {
        self.outbound_passive_syncing_peers().len()
    }

    fn outbound_passive_syncing_peers(&self) -> Vec<PeerId> {
        self.peer_states
            .iter()
            .filter_map(|(peer_id, state)| {
                (state.sync_status.is_passive_syncing() && state.session_type.is_outbound())
                    .then_some(peer_id.clone())
            })
            .collect()
    }

    fn passive_syncing_peers(&self) -> Vec<PeerId> {
        self.peer_states
            .iter()
            .filter_map(|(peer_id, state)| {
                state
                    .sync_status
                    .is_passive_syncing()
                    .then_some(peer_id.clone())
            })
            .collect()
    }

    fn peers_to_start_active_syncing(&self) -> Vec<PeerId> {
        match self.num_targeted_active_syncing_peers.checked_sub(
            self.num_finished_active_syncing_peers + self.num_of_active_syncing_peers(),
        ) {
            None => vec![],
            Some(num) => self
                .peer_states
                .iter()
                .filter(|(_, state)| state.sync_status.can_start_active_syncing())
                .take(num)
                .map(|(peer_id, _)| peer_id)
                .cloned()
                .collect(),
        }
    }

    fn new_outbound_peers_to_start_passive_syncing(&self) -> Vec<PeerId> {
        if !self.is_ready_for_passive_syncing() {
            return vec![];
        }
        match self
            .num_targeted_outbound_passive_syncing_peers
            .checked_sub(self.num_of_outbound_passive_syncing_peers())
        {
            None => vec![],
            Some(num) => self
                .peer_states
                .iter()
                .filter(|(_, state)| {
                    state.session_type.is_outbound()
                        && state.sync_status.can_start_passive_syncing()
                })
                .take(num)
                .map(|(peer_id, _)| peer_id)
                .cloned()
                .collect(),
        }
    }

    fn peers_to_start_passive_syncing(&self) -> Vec<PeerId> {
        [
            self.peers_to_start_mutual_passive_syncing().as_slice(),
            self.new_outbound_peers_to_start_passive_syncing()
                .as_slice(),
        ]
        .concat()
    }

    fn peers_to_start_mutual_passive_syncing(&self) -> Vec<PeerId> {
        if !self.is_ready_for_passive_syncing() {
            return vec![];
        }
        self.peer_states
            .iter()
            .filter(|(_, state)| {
                // A peer that has subscribed to us is a good candidate for passive syncing.
                // By mutual subscription, we can ensure that both us and the peer have the same set of messages.
                state.filter_processor.is_some() && state.sync_status.can_start_passive_syncing()
            })
            .map(|(peer_id, _)| peer_id.clone())
            .collect::<Vec<_>>()
    }

    async fn start_new_active_syncer(&mut self, peer_id: &PeerId) {
        let safe_cursor = self.get_safe_cursor_to_start_syncing();
        let sync_actor = Actor::spawn_linked(
            Some(format!(
                "gossip syncing actor to peer {:?} supervised by {:?}",
                peer_id,
                self.myself.get_id()
            )),
            GossipSyncingActor::new(),
            (
                peer_id.clone(),
                self.myself.clone(),
                self.chain_actor.clone(),
                self.store.clone(),
                safe_cursor,
            ),
            self.myself.get_cell(),
        )
        .await
        .expect("start gossip syncing actor");

        self.peer_states
            .get_mut(peer_id)
            .expect("get peer state")
            .change_sync_status(PeerSyncStatus::ActiveGet(sync_actor.0));
    }

    async fn start_passive_syncer(&mut self, peer_id: &PeerId) {
        let cursor = self.get_safe_cursor_to_start_syncing();
        let filter = BroadcastMessagesFilter {
            chain_hash: get_chain_hash(),
            after_cursor: cursor.clone(),
        };

        match self.send_broadcast_message_filter(peer_id, filter).await {
            Ok(_) => {
                self.peer_states
                    .get_mut(peer_id)
                    .expect("get peer state")
                    .change_sync_status(PeerSyncStatus::PassiveFilter(cursor));
            }
            Err(e) => {
                error!(
                    "Failed to send BroadcastMessagesFilter to peer {:?}: {:?}",
                    peer_id, e
                );
            }
        }
    }

    async fn stop_passive_syncer(&mut self, peer_id: &PeerId) {
        let filter = BroadcastMessagesFilter {
            chain_hash: get_chain_hash(),
            after_cursor: Cursor::max(),
        };
        match self.peer_states.get(peer_id) {
            Some(peer) if peer.sync_status.is_passive_syncing() => {
                match self.send_broadcast_message_filter(peer_id, filter).await {
                    Ok(_) => {
                        self.peer_states
                            .get_mut(peer_id)
                            .expect("get peer state")
                            .change_sync_status(PeerSyncStatus::NotSyncing());
                    }
                    Err(e) => {
                        error!(
                            "Failed to send BroadcastMessagesFilter to peer {:?}: {:?}",
                            peer_id, e
                        );
                    }
                }
            }
            _ => {}
        }
    }

    async fn send_broadcast_message_filter(
        &self,
        peer_id: &PeerId,
        filter: BroadcastMessagesFilter,
    ) -> crate::Result<()> {
        let message = GossipMessage::BroadcastMessagesFilter(filter);
        self.send_message_to_peer(peer_id, message).await?;
        Ok(())
    }

    fn is_peer_connected(&self, peer_id: &PeerId) -> bool {
        self.peer_states.contains_key(peer_id)
    }

    fn get_store(&self) -> &S {
        self.store.get_store()
    }

    fn get_peer_session(&self, peer_id: &PeerId) -> Option<SessionId> {
        self.peer_states.get(peer_id).map(|s| s.session_id)
    }

    fn get_latest_cursor(&self) -> Cursor {
        self.get_store()
            .get_latest_broadcast_message_cursor()
            .unwrap_or_default()
    }

    fn get_safe_cursor_to_start_syncing(&self) -> Cursor {
        self.get_latest_cursor()
            .go_back_for_some_time(MAX_MISSING_BROADCAST_MESSAGE_TIMESTAMP_DRIFT)
    }

    async fn try_to_verify_and_save_broadcast_message(&mut self, message: BroadcastMessage) {
        // If there is any messages related to this message that we haven't obtained yet, we will
        // add them to pending_queries, which would be processed later.
        // TODO: It is possible the message here comes from a malicious peer. We should check bookkeep
        // the origin of the message and check if queries constructed here go nowhere.
        let queries = get_dependent_message_queries(&message, self.get_store());
        self.pending_queries.extend(queries);

        self.store
            .actor
            .send_message(ExtendedGossipMessageStoreMessage::SaveMessages(vec![
                message,
            ]))
            .expect("store actor alive");
    }

    async fn send_message_to_session(
        &self,
        session_id: SessionId,
        message: GossipMessage,
    ) -> crate::Result<()> {
        send_message_to_session(&self.control, session_id, message).await?;
        Ok(())
    }

    async fn send_message_to_peer(
        &self,
        peer_id: &PeerId,
        message: GossipMessage,
    ) -> crate::Result<()> {
        match self.get_peer_session(peer_id) {
            Some(session_id) => self.send_message_to_session(session_id, message).await,
            None => Err(Error::PeerNotFound(peer_id.clone())),
        }
    }

    fn get_and_increment_request_id(&mut self) -> u64 {
        let id = self.next_request_id;
        self.next_request_id += 1;
        id
    }
}

async fn send_message_to_session(
    control: &ServiceAsyncControl,
    session_id: SessionId,
    message: GossipMessage,
) -> crate::Result<()> {
    control
        .send_message_to(session_id, GOSSIP_PROTOCOL_ID, message.to_molecule_bytes())
        .await?;
    Ok(())
}

pub(crate) struct GossipProtocolHandle {
    actor: ActorRef<GossipActorMessage>,
    sender: Option<oneshot::Sender<ServiceAsyncControl>>,
}

fn get_dependent_message_queries<S: GossipMessageStore>(
    message: &BroadcastMessage,
    store: &S,
) -> Vec<BroadcastMessageQuery> {
    let mut queries = Vec::new();
    match message {
        BroadcastMessage::ChannelAnnouncement(channel_announcement) => {
            let outpoint = &channel_announcement.channel_outpoint;
            if store
                .get_latest_node_announcement_timestamp(&channel_announcement.node1_id)
                .is_none()
            {
                queries.push(BroadcastMessageQuery {
                    flags: BroadcastMessageQueryFlags::NodeAnnouncementNode1,
                    channel_outpoint: outpoint.clone(),
                });
            }
            if store
                .get_latest_node_announcement_timestamp(&channel_announcement.node2_id)
                .is_none()
            {
                queries.push(BroadcastMessageQuery {
                    flags: BroadcastMessageQueryFlags::NodeAnnouncementNode2,
                    channel_outpoint: outpoint.clone(),
                });
            }
        }
        BroadcastMessage::ChannelUpdate(channel_update) => {
            // Check if we need to obtain related channel announcement message.
            let outpoint = &channel_update.channel_outpoint;
            if store
                .get_latest_channel_announcement_timestamp(outpoint)
                .is_none()
            {
                queries.push(BroadcastMessageQuery {
                    flags: BroadcastMessageQueryFlags::ChannelAnnouncement,
                    channel_outpoint: outpoint.clone(),
                });
            }
        }
        BroadcastMessage::NodeAnnouncement(_node_announcement) => {}
    }
    queries
}

async fn get_message_cursor<S: GossipMessageStore>(
    message: &BroadcastMessage,
    store: &S,
    chain: &ActorRef<CkbChainMessage>,
) -> Result<Cursor, Error> {
    match message {
        BroadcastMessage::ChannelAnnouncement(channel_announcement) => {
            let timestamp =
                get_channel_timestamp(&channel_announcement.channel_outpoint, store, chain).await?;
            Ok(Cursor::new(
                timestamp,
                BroadcastMessageID::ChannelAnnouncement(
                    channel_announcement.channel_outpoint.clone(),
                ),
            ))
        }
        BroadcastMessage::ChannelUpdate(channel_update) => Ok(Cursor::new(
            channel_update.timestamp,
            BroadcastMessageID::ChannelUpdate(channel_update.channel_outpoint.clone()),
        )),
        BroadcastMessage::NodeAnnouncement(node_announcement) => Ok(Cursor::new(
            node_announcement.timestamp,
            BroadcastMessageID::NodeAnnouncement(node_announcement.node_id),
        )),
    }
}

fn get_existing_broadcast_message<S: GossipMessageStore>(
    message: &BroadcastMessage,
    store: &S,
) -> Option<BroadcastMessageWithTimestamp> {
    match message {
        BroadcastMessage::ChannelAnnouncement(channel_announcement) => store
            .get_latest_channel_announcement(&channel_announcement.channel_outpoint)
            .map(|(timestamp, channel_announcement)| {
                BroadcastMessageWithTimestamp::ChannelAnnouncement(timestamp, channel_announcement)
            }),
        BroadcastMessage::ChannelUpdate(channel_update) => store
            .get_latest_channel_update(
                &channel_update.channel_outpoint,
                channel_update.is_update_of_node_1(),
            )
            .map(|store_channel_update| {
                BroadcastMessageWithTimestamp::ChannelUpdate(store_channel_update)
            }),
        BroadcastMessage::NodeAnnouncement(node_announcement) => store
            .get_latest_node_announcement(&node_announcement.node_id)
            .map(|store_node_announcement| {
                BroadcastMessageWithTimestamp::NodeAnnouncement(store_node_announcement)
            }),
    }
}

fn get_existing_newer_broadcast_message<S: GossipMessageStore>(
    message: &BroadcastMessage,
    store: &S,
) -> Option<BroadcastMessageWithTimestamp> {
    get_existing_broadcast_message(message, store).and_then(|existing_message| {
        match message.cursor() {
            Some(cursor) if cursor > existing_message.cursor() => None,
            _ => Some(existing_message),
        }
    })
}

// Verify and save broadcast messages to the store.
// Note that we can't relialy verify a message until we have all the messages that it depends on.
// So this function should be called by the dependency order of the messages.
// E.g. channel updates depends on channel announcements to obtain the node public keys,
// so we should call this method to save and verify channel announcements before channel updates.
async fn verify_and_save_broadcast_message<S: GossipMessageStore>(
    message: &BroadcastMessage,
    store: &S,
    chain: &ActorRef<CkbChainMessage>,
) -> Result<BroadcastMessageWithTimestamp, Error> {
    let timestamp = match message {
        BroadcastMessage::ChannelAnnouncement(channel_announcement) => {
            let on_chain_info =
                get_channel_on_chain_info(channel_announcement.out_point(), chain).await?;
            if !verify_channel_announcement(channel_announcement, &on_chain_info, store).await? {
                store.save_channel_announcement(
                    on_chain_info.timestamp,
                    channel_announcement.clone(),
                );
            }
            on_chain_info.timestamp
        }
        BroadcastMessage::ChannelUpdate(channel_update) => {
            if !verify_channel_update(channel_update, store)? {
                store.save_channel_update(channel_update.clone());
            }
            channel_update.timestamp
        }
        BroadcastMessage::NodeAnnouncement(node_announcement) => {
            if !verify_node_announcement(node_announcement, store)? {
                store.save_node_announcement(node_announcement.clone());
            }
            node_announcement.timestamp
        }
    };
    Ok((message.clone(), timestamp).into())
}

async fn get_channel_tx(
    outpoint: &OutPoint,
    chain: &ActorRef<CkbChainMessage>,
) -> Result<(TransactionView, H256), Error> {
    match call_t!(
        chain,
        CkbChainMessage::TraceTx,
        DEFAULT_CHAIN_ACTOR_TIMEOUT,
        TraceTxRequest {
            tx_hash: outpoint.tx_hash(),
            confirmations: 2,
        }
    ) {
        Ok(TraceTxResponse {
            tx: Some(tx),
            status:
                TxStatus {
                    status: Status::Committed,
                    block_hash: Some(block_hash),
                    ..
                },
        }) => Ok((tx, block_hash)),
        err => Err(Error::InvalidParameter(format!(
            "Channel announcement transaction {:?} not found or not confirmed, result is: {:?}",
            &outpoint.tx_hash(),
            err
        ))),
    }
}

async fn get_channel_timestamp<S: GossipMessageStore>(
    outpoint: &OutPoint,
    store: &S,
    chain: &ActorRef<CkbChainMessage>,
) -> Result<u64, Error> {
    if let Some((timestamp, _)) = store.get_latest_channel_announcement(outpoint) {
        return Ok(timestamp);
    }

    let on_chain_info = get_channel_on_chain_info(outpoint, chain).await?;

    Ok(on_chain_info.timestamp)
}

async fn get_channel_on_chain_info(
    outpoint: &OutPoint,
    chain: &ActorRef<CkbChainMessage>,
) -> Result<ChannelOnchainInfo, Error> {
    let (tx, block_hash) = get_channel_tx(outpoint, chain).await?;
    let first_output = match tx.inner.outputs.first() {
        None => {
            return Err(Error::InvalidParameter(format!(
                "On-chain transaction found but no output: {:?}",
                &outpoint
            )));
        }
        Some(output) => output.clone(),
    };

    let timestamp: u64 = match call_t!(
        chain,
        CkbChainMessage::GetBlockTimestamp,
        DEFAULT_CHAIN_ACTOR_TIMEOUT,
        GetBlockTimestampRequest::from_block_hash(block_hash.clone())
    ) {
        Ok(Ok(Some(timestamp))) => timestamp,
        Ok(Ok(None)) => {
            return Err(Error::InternalError(anyhow::anyhow!(
                "Unable to find block {:?} for channel outpoint {:?}",
                &block_hash,
                &outpoint
            )));
        }
        Ok(Err(err)) => {
            return Err(Error::CkbRpcError(err));
        }
        Err(err) => {
            return Err(Error::InternalError(anyhow::Error::new(err).context(
                format!(
                    "Error while trying to obtain block {:?} for channel outpoint {:?}",
                    block_hash, &outpoint
                ),
            )));
        }
    };

    Ok(ChannelOnchainInfo {
        timestamp,
        first_output,
    })
}

// Verify the channel announcement message. If any error occurs, return the error.
// Otherwise, return the timestamp of the channel announcement and a bool value indicating if the
// the channel announcement is already saved to the store. If it is already saved, the bool value
// is true, otherwise it is false.
async fn verify_channel_announcement<S: GossipMessageStore>(
    channel_announcement: &ChannelAnnouncement,
    on_chain_info: &ChannelOnchainInfo,
    store: &S,
) -> Result<bool, Error> {
    if let Some((_, announcement)) =
        store.get_latest_channel_announcement(&channel_announcement.channel_outpoint)
    {
        if announcement == *channel_announcement {
            return Ok(true);
        } else {
            return Err(Error::InvalidParameter(format!(
                "Channel announcement message already exists but mismatched: {:?}, existing: {:?}",
                &channel_announcement, &announcement
            )));
        }
    }
    let message = channel_announcement.message_to_sign();
    if channel_announcement.node1_id == channel_announcement.node2_id {
        return Err(Error::InvalidParameter(format!(
            "Channel announcement node had a channel with itself: {:?}",
            &channel_announcement
        )));
    }
    let (node1_signature, node2_signature, ckb_signature) = match (
        &channel_announcement.node1_signature,
        &channel_announcement.node2_signature,
        &channel_announcement.ckb_signature,
    ) {
        (Some(node1_signature), Some(node2_signature), Some(ckb_signature)) => {
            (node1_signature, node2_signature, ckb_signature)
        }
        _ => {
            return Err(Error::InvalidParameter(format!(
                "Channel announcement message signature verification failed, some signatures are missing: {:?}",
                &channel_announcement
            )));
        }
    };

    if !node1_signature.verify(&channel_announcement.node1_id, &message) {
        return Err(Error::InvalidParameter(format!(
            "Channel announcement message signature verification failed for node 1: {:?}, message: {:?}, signature: {:?}, pubkey: {:?}",
            &channel_announcement,
            &message,
            &node1_signature,
            &channel_announcement.node1_id
        )));
    }

    if !node2_signature.verify(&channel_announcement.node2_id, &message) {
        return Err(Error::InvalidParameter(format!(
            "Channel announcement message signature verification failed for node 2: {:?}, message: {:?}, signature: {:?}, pubkey: {:?}",
            &channel_announcement,
            &message,
            &node2_signature,
            &channel_announcement.node2_id
        )));
    }

    let pubkey = channel_announcement.ckb_key.serialize();
    let pubkey_hash = &blake2b_256(pubkey.as_slice())[0..20];

    let output = &on_chain_info.first_output;
    if output.lock.args.as_bytes() != pubkey_hash {
        return Err(Error::InvalidParameter(format!(
                    "On-chain transaction found but pubkey hash mismatched: on chain hash {:?}, pub key ({:?}) hash {:?}",
                    &output.lock.args.as_bytes(),
                    hex::encode(pubkey),
                    &pubkey_hash
                )));
    }
    let capacity: u128 = u64::from(output.capacity).into();
    match channel_announcement.udt_type_script {
        Some(_) => {
            // TODO: verify the capacity of the UDT
        }
        None => {
            if channel_announcement.capacity > capacity {
                return Err(Error::InvalidParameter(format!(
                            "On-chain transaction found but capacity mismatched: on chain capacity {:?} smaller than annoucned channel capacity {:?}",
                            &output.capacity, &channel_announcement.capacity
                        )));
            }
        }
    }

    if let Err(err) = secp256k1_instance().verify_schnorr(
        ckb_signature,
        &Message::from_digest(message),
        &channel_announcement.ckb_key,
    ) {
        return Err(Error::InvalidParameter(format!(
            "Channel announcement message signature verification failed for ckb: {:?}, message: {:?}, signature: {:?}, pubkey: {:?}, error: {:?}",
            &channel_announcement,
            &message,
            &ckb_signature,
            &channel_announcement.ckb_key,
            &err
        )));
    }

    Ok(false)
}

// Verify the signature of the channel update message. If there is any error, an error will be returned.
// Else if the channel update is already saved to the store, true will be returned.
// Otherwise false will be returned. The caller may use this value to determine if the channel update
// message should be saved to the store.
fn verify_channel_update<S: GossipMessageStore>(
    channel_update: &ChannelUpdate,
    store: &S,
) -> Result<bool, Error> {
    if let Some(BroadcastMessageWithTimestamp::ChannelUpdate(existing)) =
        store.get_broadcast_message_with_cursor(&channel_update.cursor())
    {
        if existing == *channel_update {
            return Ok(true);
        } else {
            return Err(Error::InvalidParameter(format!(
                "Channel update message already exists but mismatched: {:?}, existing: {:?}",
                &channel_update, &existing
            )));
        }
    }
    let message = channel_update.message_to_sign();

    let signature = match channel_update.signature {
        Some(ref signature) => signature,
        None => {
            return Err(Error::InvalidParameter(format!(
                "Channel update message signature verification failed (signature not found): {:?}",
                &channel_update
            )));
        }
    };
    match store.get_latest_channel_announcement(&channel_update.channel_outpoint) {
        Some((_, channel_announcement)) => {
            let pubkey = if channel_update.is_update_of_node_1() {
                channel_announcement.node1_id
            } else {
                channel_announcement.node2_id
            };
            if !signature.verify(&pubkey, &message) {
                return Err(Error::InvalidParameter(format!(
                    "Channel update message signature verification failed (invalid signature): {:?}",
                    &channel_update
                )));
            }
            Ok(false)
        }
        None => {
            // It is possible that the channel update message is received before the channel announcement message.
            // In this case, we should temporarily store the channel update message and verify it later
            // when the channel announcement message is received.
            return Err(Error::InvalidParameter(format!(
                "Channel announcement message not found for channel update message: {:?}",
                &channel_update.channel_outpoint
            )));
        }
    }
}

// Verify the signature of the node announcement message. If there is any error, an error will be returned.
// Else if the node announcement is already saved to the store, true will be returned.
// Otherwise false will be returned. The caller may use this value to determine if the node announcement
// message should be saved to the store.
fn verify_node_announcement<S: GossipMessageStore>(
    node_announcement: &NodeAnnouncement,
    store: &S,
) -> Result<bool, Error> {
    if let Some(BroadcastMessageWithTimestamp::NodeAnnouncement(announcement)) =
        store.get_broadcast_message_with_cursor(&node_announcement.cursor())
    {
        if announcement == *node_announcement {
            return Ok(true);
        } else {
            return Err(Error::InvalidParameter(format!(
                "Node announcement message already exists but mismatched: {:?}, existing: {:?}",
                &node_announcement, &announcement
            )));
        }
    }
    if !node_announcement.verify() {
        Err(Error::InvalidParameter(
            "Node announcement message signature verification failed".to_string(),
        ))
    } else {
        Ok(false)
    }
}

#[allow(clippy::too_many_arguments)]
impl GossipProtocolHandle {
    pub(crate) async fn new<S>(
        name: Option<String>,
        gossip_network_maintenance_interval: Duration,
        gossip_store_maintenance_interval: Duration,
        announce_private_addr: bool,
        num_targeted_active_syncing_peers: Option<usize>,
        num_targeted_outbound_passive_syncing_peers: Option<usize>,
        store: S,
        chain_actor: ActorRef<CkbChainMessage>,
        supervisor: ActorCell,
    ) -> (Self, ExtendedGossipMessageStore<S>)
    where
        S: GossipMessageStore + Clone + Send + Sync + 'static,
    {
        let (network_control_sender, network_control_receiver) = oneshot::channel();
        let (store_sender, store_receiver) = oneshot::channel();

        let (actor, _handle) = ActorRuntime::spawn_linked_instant(
            name,
            GossipActor::new(),
            (
                network_control_receiver,
                store_sender,
                gossip_network_maintenance_interval,
                gossip_store_maintenance_interval,
                announce_private_addr,
                num_targeted_active_syncing_peers.unwrap_or(MAX_NUM_OF_ACTIVE_SYNCING_PEERS),
                num_targeted_outbound_passive_syncing_peers
                    .unwrap_or(MIN_NUM_OF_PASSIVE_SYNCING_PEERS),
                store,
                chain_actor,
            ),
            supervisor,
        )
        .expect("start gossip actor");
        let store = store_receiver.await.expect("receive store");
        (
            Self {
                actor,
                sender: Some(network_control_sender),
            },
            store,
        )
    }

    pub(crate) fn actor(&self) -> &ActorRef<GossipActorMessage> {
        &self.actor
    }

    pub(crate) fn create_meta(self) -> ProtocolMeta {
        MetaBuilder::new()
            .id(GOSSIP_PROTOCOL_ID)
            .service_handle(move || {
                let handle = Box::new(self);
                ProtocolHandle::Callback(handle)
            })
            .build()
    }
}

#[rasync_trait]
impl<S> Actor for GossipActor<S>
where
    S: GossipMessageStore + Clone + Send + Sync + 'static,
{
    type Msg = GossipActorMessage;
    type State = GossipActorState<S>;
    type Arguments = (
        oneshot::Receiver<ServiceAsyncControl>,
        oneshot::Sender<ExtendedGossipMessageStore<S>>,
        Duration,
        Duration,
        bool,
        usize,
        usize,
        S,
        ActorRef<CkbChainMessage>,
    );

    async fn pre_start(
        &self,
        myself: ActorRef<Self::Msg>,
        (
            rx,
            tx,
            network_maintenance_interval,
            store_maintenance_interval,
            announce_private_addr,
            num_targeted_active_syncing_peers,
            num_targeted_outbound_passive_syncing_peers,
            store,
            chain_actor,
        ): Self::Arguments,
    ) -> Result<Self::State, ActorProcessingErr> {
        let store = ExtendedGossipMessageStore::new(
            store_maintenance_interval,
            announce_private_addr,
            store,
            chain_actor.clone(),
            myself.get_cell(),
        )
        .await;
        if tx.send(store.clone()).is_err() {
            panic!("failed to send store to the caller");
        }
        let control = timeout(Duration::from_secs(1), rx)
            .await
            .expect("received control timely")
            .expect("receive control");
        debug!("Gossip actor received service control");

        myself.send_interval(network_maintenance_interval, || {
            GossipActorMessage::TickNetworkMaintenance
        });
        let state = Self::State {
            store,
            control,
            num_targeted_active_syncing_peers,
            num_targeted_outbound_passive_syncing_peers,
            myself,
            chain_actor,
            next_request_id: Default::default(),
            pending_queries: Default::default(),
            num_finished_active_syncing_peers: Default::default(),
            peer_states: Default::default(),
        };
        Ok(state)
    }

    async fn handle_supervisor_evt(
        &self,
        _myself: ActorRef<Self::Msg>,
        message: SupervisionEvent,
        _state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        match message {
            SupervisionEvent::ActorTerminated(who, _, _) => {
                debug!("{:?} terminated", who);
            }
            SupervisionEvent::ActorFailed(who, err) => {
                panic!("Actor unexpectedly panicked (id: {:?}): {:?}", who, err);
            }
            _ => {}
        }
        Ok(())
    }

    async fn handle(
        &self,
        myself: ActorRef<Self::Msg>,
        message: Self::Msg,
        state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        match message {
            GossipActorMessage::PeerConnected(peer_id, _pubkey, session) => {
                if state.is_peer_connected(&peer_id) {
                    return Ok(());
                }
                state
                    .peer_states
                    .insert(peer_id.clone(), PeerState::new(session.id, session.ty));
            }
            GossipActorMessage::PeerDisconnected(peer_id, _session) => {
                state.peer_states.remove(&peer_id);
            }
            GossipActorMessage::ProcessBroadcastMessage(message) => {
                state
                    .try_to_verify_and_save_broadcast_message(message.clone())
                    .await;
            }
            GossipActorMessage::QueryBroadcastMessages(peer, queries) => {
                let id = state.get_and_increment_request_id();
                if let Err(e) = state
                    .send_message_to_peer(
                        &peer,
                        GossipMessage::QueryBroadcastMessages(QueryBroadcastMessages {
                            id,
                            chain_hash: get_chain_hash(),
                            queries,
                        }),
                    )
                    .await
                {
                    error!(
                        "Failed to send query broadcast messages to peer {:?}: {:?}",
                        &peer, e
                    );
                }
            }
            GossipActorMessage::TryBroadcastMessages(messages) => {
                state
                    .store
                    .actor
                    .send_message(ExtendedGossipMessageStoreMessage::SaveAndBroadcastMessages(
                        messages,
                    ))
                    .expect("store actor alive");
            }
            GossipActorMessage::RotateOutboundPassiveSyncingPeers => {
                if !state.is_ready_for_passive_syncing() {
                    return Ok(());
                }

                let current_peers = state
                    .outbound_passive_syncing_peers()
                    .into_iter()
                    .collect::<HashSet<_>>();
                let new_peers = state
                    .peer_states
                    .iter()
                    .filter_map(|(peer, state)| {
                        (state.session_type.is_outbound()
                            && (state.sync_status.can_start_passive_syncing()
                                || state.sync_status.is_passive_syncing()))
                        .then_some(peer.clone())
                    })
                    .take(state.num_targeted_outbound_passive_syncing_peers)
                    .collect::<HashSet<_>>();
                debug!(
                    "Rotating passive syncing peers: current {:?}, new {:?}",
                    &current_peers, &new_peers
                );
                for peers in new_peers.difference(&current_peers) {
                    state.start_passive_syncer(peers).await;
                }
                for peers in current_peers.difference(&new_peers) {
                    state.stop_passive_syncer(peers).await;
                }
            }

            GossipActorMessage::TickNetworkMaintenance => {
                trace!(
                    "Gossip network maintenance ticked, current state: num of peers: {}, num of finished syncing peers: {}, num of active syncing peers: {}, num of passive syncing peers: {}, num of pending queries: {}",
                    state.peer_states.len(),
                    state.num_finished_active_syncing_peers,
                    state.num_of_active_syncing_peers(),
                    state.num_of_passive_syncing_peers(),
                    state.pending_queries.len(),
                );
                for peer in state.peers_to_start_active_syncing() {
                    state.start_new_active_syncer(&peer).await;
                }

                for peer in state.peers_to_start_passive_syncing() {
                    state.start_passive_syncer(&peer).await;
                }

                // Query missing messages from peers.
                let pending_queries = std::mem::take(&mut state.pending_queries);
                for chunk in pending_queries.chunks(MAX_NUM_OF_BROADCAST_MESSAGES as usize) {
                    let queries = chunk.to_vec();
                    let id = state.get_and_increment_request_id();
                    for peer_state in state
                        .peer_states
                        .values()
                        .take(NUM_SIMULTANEOUS_GET_REQUESTS)
                    {
                        let message =
                            GossipMessage::QueryBroadcastMessages(QueryBroadcastMessages {
                                id,
                                chain_hash: get_chain_hash(),
                                queries: queries.clone(),
                            });
                        if let Err(e) =
                            send_message_to_session(&state.control, peer_state.session_id, message)
                                .await
                        {
                            error!(
                                "Failed to send query broadcast messages to peer {:?}: {:?}",
                                &peer_state.session_id, e
                            );
                        }
                    }
                }
            }

            GossipActorMessage::ActiveSyncingFinished(peer_id, cursor) => {
                state.num_finished_active_syncing_peers += 1;
                if let Some(peer_state) = state.peer_states.get_mut(&peer_id) {
                    peer_state.change_sync_status(PeerSyncStatus::FinishedActiveSyncing(
                        now_timestamp_as_millis_u64(),
                        cursor,
                    ));
                }
            }

            GossipActorMessage::MaliciousPeerFound(peer_id) => {
                warn!("Malicious peer found: {:?}", &peer_id);
            }

            GossipActorMessage::SendGossipMessage(GossipMessageWithPeerId { peer_id, message }) => {
                if let Err(error) = state.send_message_to_peer(&peer_id, message).await {
                    error!(
                        "Failed to send gossip message to peer {:?}: {:?}",
                        &peer_id, error
                    );
                }
            }

            GossipActorMessage::GossipMessageReceived(GossipMessageWithPeerId {
                peer_id,
                message,
            }) => {
                match message {
                    GossipMessage::BroadcastMessagesFilter(BroadcastMessagesFilter {
                        chain_hash,
                        after_cursor,
                    }) => {
                        if let Err(e) = check_chain_hash(&chain_hash) {
                            error!("Failed to check chain hash: {:?}", e);
                            return Ok(());
                        }
                        if after_cursor.is_max() {
                            info!(
                                "Received BroadcastMessagesFilter with max cursor from peer, stopping filter processor to {:?}",
                                &peer_id
                            );
                            state.peer_states.remove(&peer_id);
                            return Ok(());
                        }
                        match state.peer_states.get_mut(&peer_id) {
                            Some(peer_state) => {
                                match peer_state.filter_processor.as_mut() {
                                    Some(filter_processor) => {
                                        filter_processor.update_filter(&after_cursor);
                                        return Ok(());
                                    }
                                    _ => {
                                        peer_state.filter_processor = Some(
                                            PeerFilterProcessor::new(
                                                state.store.clone(),
                                                peer_id.clone(),
                                                after_cursor.clone(),
                                                myself,
                                            )
                                            .await,
                                        );
                                    }
                                };
                                // Also start passive syncer to peer so that we have less silos.
                                if peer_state.sync_status.can_start_passive_syncing() {
                                    state.start_passive_syncer(&peer_id).await;
                                }
                            }
                            None => {
                                warn!(
                                    "Received BroadcastMessagesFilter from unknown peer: {:?}",
                                    &peer_id
                                );
                                return Ok(());
                            }
                        };
                    }
                    GossipMessage::BroadcastMessagesFilterResult(
                        BroadcastMessagesFilterResult { messages },
                    ) => {
                        for message in messages {
                            state
                                .try_to_verify_and_save_broadcast_message(message)
                                .await;
                        }
                    }
                    GossipMessage::GetBroadcastMessages(get_broadcast_messages) => {
                        if let Err(e) = check_chain_hash(&get_broadcast_messages.chain_hash) {
                            error!("Failed to check chain hash: {:?}", e);
                            return Ok(());
                        }
                        if get_broadcast_messages.count > MAX_NUM_OF_BROADCAST_MESSAGES {
                            warn!(
                                "Received GetBroadcastMessages with too many messages: {:?}",
                                get_broadcast_messages.count
                            );
                            return Ok(());
                        }
                        let id = get_broadcast_messages.id;
                        let messages = state.get_store().get_broadcast_messages(
                            &get_broadcast_messages.after_cursor,
                            Some(get_broadcast_messages.count),
                        );
                        let result =
                            GossipMessage::GetBroadcastMessagesResult(GetBroadcastMessagesResult {
                                id,
                                messages: messages.into_iter().map(|m| m.into()).collect(),
                            });
                        if let Err(error) = state.send_message_to_peer(&peer_id, result).await {
                            error!(
                                "Failed to send GetBroadcastMessagesResult to peer {:?}: {:?}",
                                &peer_id, error
                            );
                        }
                    }
                    GossipMessage::GetBroadcastMessagesResult(result) => {
                        let peer_state = state.peer_states.get(&peer_id);
                        if let Some(PeerState {
                            sync_status: PeerSyncStatus::ActiveGet(actor),
                            ..
                        }) = peer_state
                        {
                            let _ = actor
                                .send_message(GossipSyncingActorMessage::ResponseReceived(result));
                        } else {
                            warn!(
                                "Received GetBroadcastMessagesResult from peer {:?} in state {:?}",
                                &peer_id, &peer_state
                            );
                        }
                    }
                    GossipMessage::QueryBroadcastMessages(QueryBroadcastMessages {
                        id,
                        chain_hash,
                        queries,
                    }) => {
                        if let Err(e) = check_chain_hash(&chain_hash) {
                            error!("Failed to check chain hash: {:?}", e);
                            return Ok(());
                        }
                        if queries.len() > MAX_NUM_OF_BROADCAST_MESSAGES as usize {
                            warn!(
                                "Received QueryBroadcastMessages with too many queries: {:?}",
                                queries.len()
                            );
                            return Ok(());
                        }
                        let (results, missing_queries) =
                            state.get_store().query_broadcast_messages(queries);
                        let result = GossipMessage::QueryBroadcastMessagesResult(
                            QueryBroadcastMessagesResult {
                                id,
                                messages: results.into_iter().map(|m| m.into()).collect(),
                                missing_queries,
                            },
                        );
                        if let Err(error) = state.send_message_to_peer(&peer_id, result).await {
                            error!(
                                "Failed to send QueryBroadcastMessagesResult to peer {:?}: {:?}",
                                &peer_id, error
                            );
                        }
                    }
                    GossipMessage::QueryBroadcastMessagesResult(QueryBroadcastMessagesResult {
                        id: _id,
                        messages,
                        missing_queries,
                    }) => {
                        let _is_finished = missing_queries.is_empty();
                        for message in messages {
                            state
                                .try_to_verify_and_save_broadcast_message(message)
                                .await;
                        }
                        // TODO: mark requests corresponding to id as finished
                        // TODO: if not finished, send another QueryBroadcastMessages to other peers.
                        // Must be careful since some queries may be initiated by malformed messages
                        // from malicious peers.
                    }
                }
            }
        }

        Ok(())
    }
}

#[tasync_trait]
impl ServiceProtocol for GossipProtocolHandle {
    async fn init(&mut self, context: &mut ProtocolContext) {
        let sender = self
            .sender
            .take()
            .expect("service control sender set and init called once");
        if sender.send(context.control().clone()).is_err() {
            panic!("Failed to send service control");
        }
    }

    async fn connected(&mut self, context: ProtocolContextMutRef<'_>, version: &str) {
        trace!(
            "proto id [{}] open on session [{}], address: [{}], type: [{:?}], version: {}",
            context.proto_id,
            context.session.id,
            context.session.address,
            context.session.ty,
            version
        );

        if let Some(remote_pubkey) = context.session.remote_pubkey.clone() {
            let remote_peer_id = PeerId::from_public_key(&remote_pubkey);
            let _ = self.actor.send_message(GossipActorMessage::PeerConnected(
                remote_peer_id,
                remote_pubkey.into(),
                context.session.clone(),
            ));
        } else {
            warn!("Peer connected without remote pubkey {:?}", context.session);
        }
    }

    async fn disconnected(&mut self, context: ProtocolContextMutRef<'_>) {
        trace!(
            "proto id [{}] close on session [{}], address: [{}], type: [{:?}]",
            context.proto_id,
            context.session.id,
            &context.session.address,
            &context.session.ty
        );

        match context.session.remote_pubkey.as_ref() {
            Some(remote_pubkey) => {
                let remote_peer_id = PeerId::from_public_key(remote_pubkey);
                let _ = self
                    .actor
                    .send_message(GossipActorMessage::PeerDisconnected(
                        remote_peer_id,
                        context.session.clone(),
                    ));
            }
            None => {
                unreachable!("Received message without remote pubkey");
            }
        }
    }

    async fn received(&mut self, context: ProtocolContextMutRef<'_>, data: Bytes) {
        let message = unwrap_or_return!(GossipMessage::from_molecule_slice(&data), "parse message");
        match context.session.remote_pubkey.as_ref() {
            Some(pubkey) => {
                let peer_id = PeerId::from_public_key(pubkey);
                let _ = self
                    .actor
                    .send_message(GossipActorMessage::GossipMessageReceived(
                        GossipMessageWithPeerId { peer_id, message },
                    ));
            }
            None => {
                unreachable!("Received message without remote pubkey");
            }
        }
    }

    async fn notify(&mut self, _context: &mut ProtocolContext, _token: u64) {}
}


================================================
File: src/fiber/graph.rs
================================================
use super::channel::{ChannelActorState, ChannelActorStateStore, ChannelTlcInfo};
use super::config::AnnouncedNodeName;
use super::gossip::GossipMessageStore;
use super::history::{Direction, InternalResult, PaymentHistory, TimedResult};
use super::network::{get_chain_hash, HopHint, SendPaymentData, SendPaymentResponse};
use super::path::NodeHeap;
use super::types::{
    BroadcastMessageID, BroadcastMessageWithTimestamp, ChannelAnnouncement, ChannelUpdate, Hash256,
    NodeAnnouncement,
};
use super::types::{Cursor, Pubkey, TlcErr};
use crate::ckb::config::UdtCfgInfos;
use crate::fiber::fee::calculate_tlc_forward_fee;
use crate::fiber::path::NodeHeapElement;
use crate::fiber::serde_utils::EntityHex;
use crate::fiber::types::PaymentHopData;
use crate::invoice::CkbInvoice;
use crate::now_timestamp_as_millis_u64;
use ckb_types::packed::{OutPoint, Script};
use rand::seq::SliceRandom;
use rand::thread_rng;
use serde::{Deserialize, Serialize};
use serde_with::serde_as;
use std::collections::{HashMap, HashSet};
use tentacle::multiaddr::MultiAddr;
use tentacle::secio::PeerId;
use tentacle::utils::{is_reachable, multiaddr_to_socketaddr};
use thiserror::Error;
use tracing::log::error;
use tracing::{debug, info, trace};

const DEFAULT_MIN_PROBABILITY: f64 = 0.01;

#[serde_as]
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
/// Details about a node in the network, known from the network announcement.
pub struct NodeInfo {
    pub node_id: Pubkey,
    // The timestamp set by the owner for the node announcement.
    pub timestamp: u64,
    // Tentatively using 64 bits for features. May change the type later while developing.
    // rust-lightning uses a Vec<u8> here.
    pub features: u64,
    // The name of the node. This is a human-readable string that is meant to be used for labelling nodes in the UI.
    pub node_name: AnnouncedNodeName,
    // All the reachable addresses.
    pub addresses: Vec<MultiAddr>,
    // If the other party funding more than this amount, we will automatically accept the channel.
    pub auto_accept_min_ckb_funding_amount: u64,
    // UDT config info
    pub udt_cfg_infos: UdtCfgInfos,
}

impl NodeInfo {
    pub fn cursor(&self) -> Cursor {
        Cursor::new(
            self.timestamp,
            BroadcastMessageID::NodeAnnouncement(self.node_id),
        )
    }
}

impl From<NodeAnnouncement> for NodeInfo {
    fn from(value: NodeAnnouncement) -> Self {
        Self {
            node_id: value.node_id,
            timestamp: value.timestamp,
            features: value.features,
            node_name: value.node_name,
            addresses: value.addresses,
            auto_accept_min_ckb_funding_amount: value.auto_accept_min_ckb_funding_amount,
            udt_cfg_infos: value.udt_cfg_infos,
        }
    }
}

#[derive(Clone, Debug, PartialEq)]
pub struct ChannelInfo {
    pub channel_outpoint: OutPoint,
    // The timestamp in the block header of the block that includes the funding transaction of the channel.
    pub timestamp: u64,

    pub features: u64,
    pub node1: Pubkey,
    pub node2: Pubkey,
    // The total capacity of the channel.
    pub capacity: u128,
    // UDT script
    pub udt_type_script: Option<Script>,
    pub update_of_node1: Option<ChannelUpdateInfo>,
    pub update_of_node2: Option<ChannelUpdateInfo>,
}

impl ChannelInfo {
    pub fn cursor(&self) -> Cursor {
        Cursor::new(
            self.timestamp,
            BroadcastMessageID::ChannelAnnouncement(self.channel_outpoint.clone()),
        )
    }

    pub fn out_point(&self) -> &OutPoint {
        &self.channel_outpoint
    }

    pub fn capacity(&self) -> u128 {
        self.capacity
    }

    pub fn node1(&self) -> Pubkey {
        self.node1
    }

    pub fn node2(&self) -> Pubkey {
        self.node2
    }

    pub fn node1_peerid(&self) -> PeerId {
        self.node1.tentacle_peer_id()
    }

    pub fn node2_peerid(&self) -> PeerId {
        self.node2.tentacle_peer_id()
    }

    pub fn udt_type_script(&self) -> &Option<Script> {
        &self.udt_type_script
    }

    // Whether this channel is explicitly disabled in either direction.
    // TODO: we currently deem a channel as disabled if one direction is disabled.
    // Is it possible that one direction is disabled while the other is not?
    pub fn is_explicitly_disabled(&self) -> bool {
        match (&self.update_of_node2, &self.update_of_node1) {
            (Some(update1), _) if !update1.enabled => true,
            (_, Some(update2)) if !update2.enabled => true,
            _ => false,
        }
    }

    pub fn channel_last_update_time(&self) -> Option<u64> {
        self.update_of_node2
            .as_ref()
            .map(|n| n.timestamp)
            .max(self.update_of_node1.as_ref().map(|n| n.timestamp))
    }

    #[cfg(test)]
    pub fn get_channel_update_of(&self, node: Pubkey) -> Option<&ChannelUpdateInfo> {
        if self.node1() == node {
            self.update_of_node1.as_ref()
        } else if self.node2() == node {
            self.update_of_node2.as_ref()
        } else {
            None
        }
    }
}

impl TryFrom<&ChannelActorState> for ChannelInfo {
    type Error = String;

    fn try_from(state: &ChannelActorState) -> Result<Self, Self::Error> {
        if !state.is_ready() {
            return Err("Channel is not ready".to_string());
        }

        let timestamp = state.must_get_funding_transaction_timestamp();
        let channel_outpoint = state.must_get_funding_transaction_outpoint();
        let capacity = state.get_liquid_capacity();
        let udt_type_script = state.funding_udt_type_script.clone();

        let (node1, node2, update_of_node1, update_of_node2) = if state.local_is_node1() {
            (
                state.local_pubkey,
                state.remote_pubkey,
                Some(state.get_local_channel_update_info()),
                state.get_remote_channel_update_info(),
            )
        } else {
            (
                state.remote_pubkey,
                state.local_pubkey,
                state.get_remote_channel_update_info(),
                Some(state.get_local_channel_update_info()),
            )
        };
        Ok(Self {
            channel_outpoint,
            timestamp,
            features: 0,
            node1,
            node2,
            capacity,
            udt_type_script,
            update_of_node1,
            update_of_node2,
        })
    }
}

impl From<(u64, ChannelAnnouncement)> for ChannelInfo {
    fn from((timestamp, channel_announcement): (u64, ChannelAnnouncement)) -> Self {
        Self {
            channel_outpoint: channel_announcement.channel_outpoint,
            timestamp,
            features: channel_announcement.features,
            node1: channel_announcement.node1_id,
            node2: channel_announcement.node2_id,
            capacity: channel_announcement.capacity,
            udt_type_script: channel_announcement.udt_type_script,
            update_of_node2: None,
            update_of_node1: None,
        }
    }
}

#[derive(Copy, Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
pub struct ChannelUpdateInfo {
    // The timestamp is the time when the channel update was received by the node.
    pub timestamp: u64,
    /// Whether the channel can be currently used for payments (in this one direction).
    pub enabled: bool,
    /// The exact amount of balance that we can send to the other party via the channel.
    pub outbound_liquidity: Option<u128>,
    /// The difference in htlc expiry values that you must have when routing through this channel (in milliseconds).
    pub tlc_expiry_delta: u64,
    /// The minimum value, which must be relayed to the next hop via the channel
    pub tlc_minimum_value: u128,
    pub fee_rate: u64,
}

impl From<&ChannelTlcInfo> for ChannelUpdateInfo {
    fn from(info: &ChannelTlcInfo) -> Self {
        Self {
            timestamp: info.timestamp,
            enabled: info.enabled,
            outbound_liquidity: None,
            tlc_expiry_delta: info.tlc_expiry_delta,
            tlc_minimum_value: info.tlc_minimum_value,
            fee_rate: info.tlc_fee_proportional_millionths as u64,
        }
    }
}

impl From<ChannelTlcInfo> for ChannelUpdateInfo {
    fn from(info: ChannelTlcInfo) -> Self {
        Self::from(&info)
    }
}

impl From<ChannelUpdate> for ChannelUpdateInfo {
    fn from(update: ChannelUpdate) -> Self {
        Self::from(&update)
    }
}

impl From<&ChannelUpdate> for ChannelUpdateInfo {
    fn from(update: &ChannelUpdate) -> Self {
        Self {
            timestamp: update.timestamp,
            enabled: !update.is_disabled(),
            outbound_liquidity: None,
            tlc_expiry_delta: update.tlc_expiry_delta,
            tlc_minimum_value: update.tlc_minimum_value,
            fee_rate: update.tlc_fee_proportional_millionths as u64,
        }
    }
}

/// Update for our own channel has been made. We can use those events to update our graph.
/// The events only contain the information that is relevant for our own channels.
/// Other channel update events should be processed by gossip messages.
#[derive(Debug)]
pub enum OwnedChannelUpdateEvent {
    /// The channel is back online and can be used for routing payments.
    /// This normally means the peer is now reachable.
    Up(ChannelInfo),
    /// The channel is down and should not be used for routing payments.
    /// This normally means the peer is not reachable.
    Down(OutPoint),
    /// One direction of the channel is updated (e.g. new balance, new fee rate).
    Updated(OutPoint, Pubkey, ChannelUpdateInfo),
}

#[derive(Clone, Debug)]
pub struct NetworkGraph<S> {
    // Whether to always process gossip messages for our own channels.
    // See comments in should_process_gossip_message_for_channel for why we need this.
    // TLDR: Most of the tests do not need this. Only tests in src/fiber/tests/graph.rs need this.
    // We will only set this to true for tests in src/fiber/tests/graph.rs.
    #[cfg(test)]
    pub always_process_gossip_message: bool,
    // The pubkey of the node that is running this instance of the network graph.
    source: Pubkey,
    // All the channels in the network.
    pub(crate) channels: HashMap<OutPoint, ChannelInfo>,
    // All the nodes in the network.
    nodes: HashMap<Pubkey, NodeInfo>,
    // The latest cursor we read from the GossipMessageStore. When we need to refresh our view of the
    // the network, we need to load all the messages starting from this cursor.
    latest_cursor: Cursor,
    // A store is both a persistent storage from which we can fetch all the network messages.
    // and a state store where we can store our local state (e.g. when a node has been unresponsive
    // for a few rounds, we need to mark it as failed, this information needs to be persisted).
    // The formal use of the store is defined as a GossipMessageStore, while the latter is defined
    // as a NetworkGraphStateStore.
    store: S,
    history: PaymentHistory<S>,
    // Whether to process announcement of private address
    announce_private_addr: bool,
}

#[derive(Error, Debug)]
pub enum PathFindError {
    #[error("Graph error: {0}")]
    Amount(String),
    #[error("PathFind error: {0}")]
    PathFind(String),
    #[error("Graph other error: {0}")]
    Other(String),
}

// An edge along the payment path from the source to the target.
// This represents a TLC transfer from one node to another.
#[derive(Clone, Debug, Eq, PartialEq)]
pub struct PathEdge {
    pub(crate) target: Pubkey,
    pub(crate) channel_outpoint: OutPoint,
    // The amount that the source node will transfer to the target node.
    // We have already added up all the fees along the path, so this amount can be used directly for the TLC.
    pub(crate) amount_received: u128,
    // The expiry for the TLC that the source node sends to the target node.
    // We have already added up all the expiry deltas along the path,
    // the only thing missing is current time. So the expiry is the current time plus the expiry delta.
    pub(crate) incoming_tlc_expiry: u64,
}

impl<S> NetworkGraph<S>
where
    S: NetworkGraphStateStore
        + ChannelActorStateStore
        + GossipMessageStore
        + Clone
        + Send
        + Sync
        + 'static,
{
    pub fn new(store: S, source: Pubkey, announce_private_addr: bool) -> Self {
        let mut network_graph = Self {
            #[cfg(test)]
            always_process_gossip_message: false,
            source,
            channels: HashMap::new(),
            nodes: HashMap::new(),
            latest_cursor: Cursor::default(),
            store: store.clone(),
            history: PaymentHistory::new(source, None, store),
            announce_private_addr,
        };
        network_graph.load_from_store();
        network_graph
    }

    pub fn get_latest_cursor(&self) -> &Cursor {
        &self.latest_cursor
    }

    fn update_lastest_cursor(&mut self, cursor: Cursor) {
        if cursor > self.latest_cursor {
            self.latest_cursor = cursor;
        }
    }

    // Update the network graph with the messages received from the network.
    // Returns true if the network graph has been updated.
    pub(crate) fn update_for_messages(
        &mut self,
        messages: Vec<BroadcastMessageWithTimestamp>,
    ) -> bool {
        if messages.is_empty() {
            return false;
        }
        debug!("Updating network graph with {} messages", messages.len());
        for message in messages {
            self.update_lastest_cursor(message.cursor());
            if message.chain_hash() != get_chain_hash() {
                tracing::warn!(
                    "Chain hash mismatch: having {:?}, expecting {:?}, full message {:?}",
                    message.chain_hash(),
                    get_chain_hash(),
                    &message
                );
                continue;
            }
            match message {
                BroadcastMessageWithTimestamp::ChannelAnnouncement(
                    timestamp,
                    channel_announcement,
                ) => {
                    self.process_channel_announcement(timestamp, channel_announcement);
                }
                BroadcastMessageWithTimestamp::ChannelUpdate(channel_update) => {
                    self.process_channel_update(channel_update);
                }
                BroadcastMessageWithTimestamp::NodeAnnouncement(node_announcement) => {
                    self.process_node_announcement(node_announcement);
                }
            }
        }
        return true;
    }

    // Process the events that are relevant for our own channels, and update the graph accordingly.
    pub(crate) fn process_owned_channel_update_event(&mut self, event: OwnedChannelUpdateEvent) {
        match event {
            OwnedChannelUpdateEvent::Up(channel_info) => {
                // Normally the channel_info passed here is the latest channel info,
                // so we can just overwrite the old channel info.
                self.channels
                    .insert(channel_info.channel_outpoint.clone(), channel_info);
            }
            OwnedChannelUpdateEvent::Down(channel_outpoint) => {
                self.channels.remove(&channel_outpoint);
            }
            OwnedChannelUpdateEvent::Updated(channel_outpoint, node, channel_update) => {
                if let Some(channel) = self.channels.get_mut(&channel_outpoint) {
                    if node == channel.node2() {
                        channel.update_of_node2 = Some(channel_update);
                    }
                    if node == channel.node1() {
                        channel.update_of_node1 = Some(channel_update);
                    }
                }
            }
        }
    }

    // Load all the broadcast messages starting from latest_cursor from the store.
    // Process them and set nodes and channels accordingly.
    pub(crate) fn load_from_store(&mut self) {
        loop {
            let messages = self.store.get_broadcast_messages(&self.latest_cursor, None);
            if messages.is_empty() {
                break;
            }
            self.update_for_messages(messages);
        }
    }

    // Completely reload from store. Because messages with larger timestamp
    // can be added to the store earlier than messages with smaller timestamp,
    // It is possible in regular load_from_store may skip some messages.
    // We use this method to reset the cursor and load all messages from start.
    #[cfg(test)]
    pub(crate) fn reload_from_store(&mut self) {
        self.reset();
        self.load_from_store();
    }

    fn load_channel_updates_from_store(&self, channel_info: &mut ChannelInfo) {
        let channel_update_of_node1 = self
            .store
            .get_latest_channel_update(&channel_info.channel_outpoint, true)
            .map(Into::into);
        let channel_update_of_node2 = self
            .store
            .get_latest_channel_update(&channel_info.channel_outpoint, false)
            .map(Into::into);
        channel_info.update_of_node1 = channel_update_of_node1;
        channel_info.update_of_node2 = channel_update_of_node2;
    }

    fn load_channel_info_mut(&mut self, channel_outpoint: &OutPoint) -> Option<&mut ChannelInfo> {
        if !self.channels.contains_key(channel_outpoint) {
            if let Some((timestamp, channel_announcement)) =
                self.store.get_latest_channel_announcement(channel_outpoint)
            {
                debug!(
                    "Loading channel announcement: timestamp {}, channel announcement {:?}",
                    timestamp, &channel_announcement
                );
                self.process_channel_announcement(timestamp, channel_announcement);
            }
        }
        self.channels.get_mut(channel_outpoint)
    }

    // We don't need to process our own channel announcement with gossip messages.
    // They are processed by passing OwnedChannelUpdateEvents to the graph.
    // These are real-time events with more detailed information (e.g. balance).
    // We don't want to overwrite their detailed information here.
    // But tests in src/fiber/tests/graph.rs need to process gossip messages
    // to update the network graph. Many of the tests are messages from the graph.source.
    // If we ignore these messages, the graph won't be updated. And many tests will fail.
    fn should_process_gossip_message_for_nodes(&self, node1: &Pubkey, node2: &Pubkey) -> bool {
        #[cfg(test)]
        if self.always_process_gossip_message {
            return true;
        }
        !(&self.source == node1 || &self.source == node2)
    }

    fn process_channel_announcement(
        &mut self,
        timestamp: u64,
        channel_announcement: ChannelAnnouncement,
    ) -> Option<Cursor> {
        if !self.should_process_gossip_message_for_nodes(
            &channel_announcement.node1_id,
            &channel_announcement.node2_id,
        ) {
            return None;
        }

        match self.channels.get(&channel_announcement.channel_outpoint) {
            Some(_channel) => {
                trace!(
                    "Channel already exists, ignoring: {:?}",
                    &channel_announcement
                );
                return None;
            }
            None => {
                let cursor = Cursor::new(
                    timestamp,
                    BroadcastMessageID::ChannelAnnouncement(
                        channel_announcement.channel_outpoint.clone(),
                    ),
                );
                trace!(
                    "Inserting new channel announcement: {:?}",
                    &channel_announcement
                );
                let channel_info = ChannelInfo::from((timestamp, channel_announcement));
                // The history needs to know the mapping between nodes and channels.
                // So that when a node is marked as failed, the history can mark all the channels
                // associated with the node as failed. Here we tell the history about
                // the mapping between nodes and channels.
                self.history
                    .add_node_channel_map(channel_info.node1, channel_info.out_point().clone());
                self.history
                    .add_node_channel_map(channel_info.node2, channel_info.out_point().clone());
                self.channels
                    .insert(channel_info.channel_outpoint.clone(), channel_info);
                return Some(cursor);
            }
        }
    }

    fn process_channel_update(&mut self, channel_update: ChannelUpdate) -> Option<Cursor> {
        match self.get_channel(&channel_update.channel_outpoint) {
            Some(channel)
                if !self
                    .should_process_gossip_message_for_nodes(&channel.node1, &channel.node2) =>
            {
                return None;
            }
            _ => {}
        }
        let channel = self.load_channel_info_mut(&channel_update.channel_outpoint)?;
        let update_info = if channel_update.is_update_of_node_1() {
            &mut channel.update_of_node1
        } else {
            &mut channel.update_of_node2
        };

        match update_info {
            Some(old_update) if old_update.timestamp > channel_update.timestamp => {
                trace!(
                    "Ignoring outdated channel update {:?} for channel {:?}",
                    &channel_update,
                    &channel
                );
                return None;
            }
            _ => {
                let cursor = Cursor::new(
                    channel_update.timestamp,
                    BroadcastMessageID::ChannelUpdate(channel_update.channel_outpoint.clone()),
                );
                trace!(
                    "Saving new channel update to the graph: {:?}",
                    &channel_update
                );
                *update_info = Some(ChannelUpdateInfo::from(channel_update));
                return Some(cursor);
            }
        }
    }

    fn process_node_announcement(
        &mut self,
        mut node_announcement: NodeAnnouncement,
    ) -> Option<Cursor> {
        if !self.announce_private_addr {
            node_announcement.addresses.retain(|addr| {
                multiaddr_to_socketaddr(addr)
                    .map(|socket_addr| is_reachable(socket_addr.ip()))
                    .unwrap_or_default()
            });

            if node_announcement.addresses.is_empty() {
                return None;
            }
        }
        let node_info = NodeInfo::from(node_announcement);
        match self.nodes.get(&node_info.node_id) {
            Some(old_node) if old_node.timestamp > node_info.timestamp => {
                trace!(
                    "Ignoring outdated node announcement {:?} for node {:?}",
                    &node_info,
                    &old_node
                );
                return None;
            }
            _ => {
                let cursor = Cursor::new(
                    node_info.timestamp,
                    BroadcastMessageID::NodeAnnouncement(node_info.node_id),
                );
                trace!("Saving new node info to the graph: {:?}", &node_info);
                self.nodes.insert(node_info.node_id, node_info);
                return Some(cursor);
            }
        }
    }

    pub(crate) fn num_of_nodes(&self) -> usize {
        self.nodes.len()
    }

    pub(crate) fn sample_n_peers_to_connect(&self, n: usize) -> HashMap<PeerId, Vec<MultiAddr>> {
        // TODO: we may need to shuffle the nodes before selecting the first n nodes,
        // to avoid some malicious nodes from being always selected.
        self.nodes
            .iter()
            .filter(|(k, _)| **k != self.source)
            .take(n)
            .map(|(k, v)| (k.tentacle_peer_id(), v.addresses.clone()))
            .collect()
    }

    pub fn nodes(&self) -> impl Iterator<Item = &NodeInfo> {
        self.nodes.values()
    }

    pub fn get_nodes_with_params(&self, limit: usize, after: Option<Cursor>) -> Vec<NodeInfo> {
        let cursor = after.unwrap_or_default();
        self.store
            .get_broadcast_messages_iter(&cursor)
            .into_iter()
            .filter_map(|message| match message {
                BroadcastMessageWithTimestamp::NodeAnnouncement(node_announcement) => {
                    Some(NodeInfo::from(node_announcement))
                }
                _ => None,
            })
            .take(limit)
            .collect()
    }

    pub fn get_node(&self, node_id: &Pubkey) -> Option<&NodeInfo> {
        self.nodes.get(node_id)
    }

    pub fn channels(&self) -> impl Iterator<Item = &ChannelInfo> {
        self.channels.values()
    }

    pub fn get_channel(&self, outpoint: &OutPoint) -> Option<&ChannelInfo> {
        self.channels.get(outpoint)
    }

    pub fn get_channels_with_params(
        &self,
        limit: usize,
        after: Option<Cursor>,
    ) -> Vec<ChannelInfo> {
        let cursor = after.unwrap_or_default();
        self.store
            .get_broadcast_messages_iter(&cursor)
            .into_iter()
            .filter_map(|message| match message {
                BroadcastMessageWithTimestamp::ChannelAnnouncement(
                    timestamp,
                    channel_announcement,
                ) => {
                    let mut channel_info = ChannelInfo::from((timestamp, channel_announcement));
                    self.load_channel_updates_from_store(&mut channel_info);
                    if channel_info.is_explicitly_disabled() {
                        None
                    } else {
                        Some(channel_info)
                    }
                }
                _ => None,
            })
            .take(limit)
            .collect()
    }

    pub fn get_channels_by_peer(&self, node_id: Pubkey) -> impl Iterator<Item = &ChannelInfo> {
        self.channels
            .values()
            .filter(move |channel| channel.node1() == node_id || channel.node2() == node_id)
    }

    pub fn get_mut_channels_by_peer(
        &mut self,
        node_id: Pubkey,
    ) -> impl Iterator<Item = &mut ChannelInfo> {
        self.channels
            .values_mut()
            .filter(move |channel| channel.node1() == node_id || channel.node2() == node_id)
    }

    pub fn get_node_inbounds(
        &self,
        node_id: Pubkey,
    ) -> impl Iterator<Item = (Pubkey, Pubkey, &ChannelInfo, &ChannelUpdateInfo)> {
        let mut channels: Vec<_> = self
            .channels
            .values()
            .filter_map(move |channel| {
                match channel.update_of_node1.as_ref() {
                    Some(info) if node_id == channel.node2() && info.enabled => {
                        return Some((channel.node1(), channel.node2(), channel, info));
                    }
                    _ => {}
                }
                match channel.update_of_node2.as_ref() {
                    Some(info) if node_id == channel.node1() && info.enabled => {
                        return Some((channel.node2(), channel.node1(), channel, info));
                    }
                    _ => {}
                }
                None
            })
            .collect();

        // Iterating over HashMap's values is not guaranteed to be in order,
        // which may introduce randomness in the path finding.
        // We will first sort the channels by outbound_liquidity, then capacity, and at last update time.
        // This is because the weight algorithm in find_path does not considering outbound_liquidity and capacity,
        // so the channel with larger outbound_liquidity/capacity maybe have the same weight with the channel
        // with smaller outbound_liquidity/capacity, even though the former have better chance to success.
        channels.sort_by(
            |(_, _, a_channel_info, a_channel_update_info),
             (_, _, b_channel_info, b_channel_update_info)| {
                b_channel_update_info
                    .outbound_liquidity
                    .cmp(&a_channel_update_info.outbound_liquidity)
                    .then(
                        b_channel_info
                            .capacity()
                            .cmp(&a_channel_info.capacity())
                            .then(
                                b_channel_info
                                    .channel_last_update_time()
                                    .cmp(&a_channel_info.channel_last_update_time()),
                            ),
                    )
            },
        );
        channels.into_iter()
    }

    pub fn get_source_pubkey(&self) -> Pubkey {
        self.source
    }

    pub(crate) fn mark_channel_failed(&mut self, channel_outpoint: &OutPoint) {
        if let Some(channel) = self.channels.get_mut(channel_outpoint) {
            if let Some(info) = channel.update_of_node2.as_mut() {
                info.enabled = false;
            }
            if let Some(info) = channel.update_of_node1.as_mut() {
                info.enabled = false;
            }
        }
    }

    pub(crate) fn mark_node_failed(&mut self, node_id: Pubkey) {
        for channel in self.get_mut_channels_by_peer(node_id) {
            if channel.node1() == node_id {
                if let Some(info) = channel.update_of_node2.as_mut() {
                    info.enabled = false;
                }
            } else if let Some(info) = channel.update_of_node1.as_mut() {
                info.enabled = false;
            }
        }
    }

    pub(crate) fn record_payment_success(&mut self, mut payment_session: PaymentSession) {
        let session_route = &payment_session.route.nodes;
        let mut result = InternalResult::default();
        result.succeed_range_pairs(session_route, 0, session_route.len() - 1);
        self.history.apply_internal_result(result);
        payment_session.set_success_status();
        self.store.insert_payment_session(payment_session);
    }

    pub(crate) fn record_payment_fail(
        &mut self,
        payment_session: &PaymentSession,
        tlc_err: TlcErr,
    ) -> bool {
        let mut internal_result = InternalResult::default();
        let nodes = &payment_session.route.nodes;
        let need_to_retry = internal_result.record_payment_fail(nodes, tlc_err);
        self.history.apply_internal_result(internal_result);
        return need_to_retry && payment_session.can_retry();
    }

    #[cfg(test)]
    pub fn reset(&mut self) {
        self.latest_cursor = Cursor::default();
        self.channels.clear();
        self.nodes.clear();
        self.history.reset();
    }

    #[cfg(test)]
    pub fn set_source(&mut self, source: Pubkey) {
        self.source = source;
    }

    /// Returns a list of `PaymentHopData` for all nodes in the route,
    /// including the origin and the target node.
    pub fn build_route(
        &self,
        payment_data: SendPaymentData,
    ) -> Result<Vec<PaymentHopData>, PathFindError> {
        let source = self.get_source_pubkey();
        let target = payment_data.target_pubkey;
        let amount = payment_data.amount;
        let preimage = payment_data.preimage;
        let payment_hash = payment_data.payment_hash;
        let udt_type_script = payment_data.udt_type_script;
        let final_tlc_expiry_delta = payment_data.final_tlc_expiry_delta;
        let invoice = payment_data
            .invoice
            .map(|x| x.parse::<CkbInvoice>().expect("parse CKB invoice"));
        let hash_algorithm = invoice
            .as_ref()
            .and_then(|x| x.hash_algorithm().copied())
            .unwrap_or_default();

        info!(
            "build_route source: {:?} target: {:?} amount: {:?}, payment_hash: {:?}",
            source, target, amount, payment_hash
        );

        let allow_self_payment = payment_data.allow_self_payment;
        if source == target && !allow_self_payment {
            return Err(PathFindError::PathFind(
                "allow_self_payment is not enable, can not pay to self".to_string(),
            ));
        }

        let route = self.find_path(
            source,
            target,
            amount,
            payment_data.max_fee_amount,
            udt_type_script,
            final_tlc_expiry_delta,
            payment_data.tlc_expiry_limit,
            allow_self_payment,
            payment_data.hop_hints,
        )?;
        assert!(!route.is_empty());

        let route_len = route.len();
        let now = now_timestamp_as_millis_u64();
        let mut hops_data = Vec::with_capacity(route.len() + 1);

        for r in route {
            hops_data.push(PaymentHopData {
                amount: r.amount_received,
                next_hop: Some(r.target),
                hash_algorithm,
                expiry: now + r.incoming_tlc_expiry,
                funding_tx_hash: r.channel_outpoint.tx_hash().into(),
                payment_preimage: None,
            });
        }
        hops_data.push(PaymentHopData {
            amount,
            next_hop: None,
            hash_algorithm,
            expiry: now + final_tlc_expiry_delta,
            funding_tx_hash: Default::default(),
            payment_preimage: preimage,
        });

        // assert there is no duplicate node in the route
        assert_eq!(
            hops_data
                .iter()
                .filter_map(|x| x.next_hop)
                .collect::<HashSet<_>>()
                .len(),
            route_len
        );

        Ok(hops_data)
    }

    // the algorithm works from target-to-source to find the shortest path
    #[allow(clippy::too_many_arguments)]
    pub fn find_path(
        &self,
        source: Pubkey,
        target: Pubkey,
        amount: u128,
        max_fee_amount: Option<u128>,
        udt_type_script: Option<Script>,
        final_tlc_expiry_delta: u64,
        tlc_expiry_limit: u64,
        allow_self: bool,
        hop_hints: Vec<HopHint>,
    ) -> Result<Vec<PathEdge>, PathFindError> {
        let started_time = std::time::Instant::now();
        let nodes_len = self.nodes.len();
        let route_to_self = source == target;

        let mut result = vec![];
        let mut nodes_visited = 0;
        let mut edges_expanded = 0;
        let mut nodes_heap = NodeHeap::new(nodes_len);
        let mut distances = HashMap::<Pubkey, NodeHeapElement>::new();

        if amount == 0 {
            return Err(PathFindError::Amount(
                "amount must be greater than 0".to_string(),
            ));
        }

        if source == target && !allow_self {
            return Err(PathFindError::PathFind(
                "allow_self_payment is not enable, can not pay self".to_string(),
            ));
        }

        let hop_hint_map: HashMap<(Pubkey, bool), OutPoint> = hop_hints
            .into_iter()
            .map(|hint| {
                (
                    (hint.pubkey, hint.inbound),
                    OutPoint::new(hint.channel_funding_tx.into(), 0),
                )
            })
            .collect::<HashMap<_, _>>();

        let mut target = target;
        let mut expiry = final_tlc_expiry_delta;
        let mut amount = amount;
        let mut last_edge = None;

        if route_to_self {
            let (edge, t, e, f) = self.adjust_target_for_route_self(
                &hop_hint_map,
                amount,
                final_tlc_expiry_delta,
                source,
                target,
            )?;
            assert_ne!(target, t);
            target = t;
            expiry += e;
            amount += f;
            last_edge = Some(edge);
        }
        assert_ne!(source, target);
        // initialize the target node
        nodes_heap.push(NodeHeapElement {
            node_id: target,
            weight: 0,
            distance: 0,
            amount_to_send: amount,
            fee_charged: 0,
            probability: 1.0,
            next_hop: None,
            incoming_tlc_expiry: expiry,
        });

        while let Some(cur_hop) = nodes_heap.pop() {
            nodes_visited += 1;

            for (from, to, channel_info, channel_update) in self.get_node_inbounds(cur_hop.node_id)
            {
                let is_initial = from == source;

                assert_eq!(to, cur_hop.node_id);
                if &udt_type_script != channel_info.udt_type_script() {
                    continue;
                }

                if let Some(channel) = hop_hint_map.get(&(from, false)) {
                    if channel != channel_info.out_point() {
                        continue;
                    }
                }
                if let Some(channel) = hop_hint_map.get(&(to, true)) {
                    if channel != channel_info.out_point() {
                        continue;
                    }
                }

                if let Some(last_edge) = &last_edge {
                    if &last_edge.channel_outpoint == channel_info.out_point() {
                        continue;
                    }
                }

                edges_expanded += 1;

                let next_hop_received_amount = cur_hop.amount_to_send;
                if next_hop_received_amount > channel_info.capacity() {
                    debug!(
                        "next_hop_received_amount: {} > channel_info.capacity {}",
                        next_hop_received_amount,
                        channel_info.capacity()
                    );
                    continue;
                }

                let fee = if is_initial {
                    0
                } else {
                    calculate_tlc_forward_fee(
                        next_hop_received_amount,
                        channel_update.fee_rate as u128,
                    )
                    .map_err(|err| {
                        PathFindError::PathFind(format!(
                            "calculate_tlc_forward_fee error: {:?}",
                            err
                        ))
                    })?
                };
                let amount_to_send = next_hop_received_amount + fee;

                // if the amount to send is greater than the amount we have, skip this edge
                if let Some(max_fee_amount) = max_fee_amount {
                    if amount_to_send > amount + max_fee_amount {
                        debug!(
                            "amount_to_send: {:?} is greater than sum_amount sum_amount: {:?}",
                            amount_to_send,
                            amount + max_fee_amount
                        );
                        continue;
                    }
                }
                // check to make sure the current hop can send the amount
                // if `tlc_maximum_value` equals 0, it means there is no limit
                if amount_to_send > channel_info.capacity() {
                    continue;
                }
                // We should use next_hop_received_amount because that is the amount to be
                // sent over the channel.
                if next_hop_received_amount < channel_update.tlc_minimum_value {
                    continue;
                }

                // If we already know the balance of the channel, check if we can send the amount.
                if let Some(balance) = channel_update.outbound_liquidity {
                    if amount_to_send > balance {
                        continue;
                    }
                }

                let expiry_delta = if is_initial {
                    0
                } else {
                    channel_update.tlc_expiry_delta
                };

                let incoming_tlc_expiry = cur_hop.incoming_tlc_expiry + expiry_delta;
                if incoming_tlc_expiry > tlc_expiry_limit {
                    continue;
                }

                let probability = cur_hop.probability
                    * self.history.eval_probability(
                        from,
                        to,
                        channel_info.out_point(),
                        amount_to_send,
                        channel_info.capacity(),
                    );

                debug!(
                    "probability: {} for channel_outpoint: {:?} from: {:?} => to: {:?}",
                    probability,
                    channel_info.out_point(),
                    from,
                    to
                );
                if probability < DEFAULT_MIN_PROBABILITY {
                    debug!("probability is too low: {:?}", probability);
                    continue;
                }
                let agg_weight =
                    self.edge_weight(amount_to_send, fee, channel_update.tlc_expiry_delta);
                let weight = cur_hop.weight + agg_weight;
                let distance = self.calculate_distance_based_probability(probability, weight);

                if let Some(node) = distances.get(&from) {
                    if distance >= node.distance {
                        continue;
                    }
                }
                let node = NodeHeapElement {
                    node_id: from,
                    weight,
                    distance,
                    amount_to_send,
                    incoming_tlc_expiry,
                    fee_charged: fee,
                    probability,
                    next_hop: Some(PathEdge {
                        target: to,
                        channel_outpoint: channel_info.out_point().clone(),
                        // The amount_received is the amount that next hop is going to receive.
                        // That is exactly next_hop_received_amount.
                        amount_received: next_hop_received_amount,
                        // We need to use cur_hop.incoming_tlc_expiry instead of incoming_tlc_expiry here
                        // because we need the expiry for the AddTlc packet sent from source to target.
                        // cur_hop.incoming_tlc_expiry is the expiry time for the TLC that is going to be received by the target,
                        // while incoming_tlc_expiry is the expiry time for the TLC that is going to be received by the source.
                        incoming_tlc_expiry: cur_hop.incoming_tlc_expiry,
                    }),
                };
                distances.insert(node.node_id, node.clone());
                nodes_heap.push_or_fix(node);
            }
        }

        let mut current = source;
        while let Some(elem) = distances.remove(&current) {
            let edge = elem.next_hop.expect("next_hop is none");
            current = edge.target;
            result.push(edge);
            if current == target {
                break;
            }
        }

        if result.is_empty() || current != target {
            return Err(PathFindError::PathFind("no path found".to_string()));
        }
        if let Some(edge) = last_edge {
            result.push(edge)
        }

        info!(
            "get_route: nodes visited: {}, edges expanded: {}, time: {:?} \nresult: {:?}",
            nodes_visited,
            edges_expanded,
            started_time.elapsed(),
            result
        );
        Ok(result)
    }

    fn adjust_target_for_route_self(
        &self,
        hop_hint_map: &HashMap<(Pubkey, bool), OutPoint>,
        amount: u128,
        expiry: u64,
        source: Pubkey,
        target: Pubkey,
    ) -> Result<(PathEdge, Pubkey, u64, u128), PathFindError> {
        let direct_channels: Vec<(Pubkey, Pubkey, &ChannelInfo, &ChannelUpdateInfo)> = self
            .get_node_inbounds(source)
            .filter(|(_, _, channel_info, _)| {
                if let Some(channel) = hop_hint_map.get(&(source, true)) {
                    // if there is a hop hint for node -> source,
                    // try to use this channel as the last candidate hop for route self
                    // and we event don't check the direct balance of channel,
                    // hop hint's priority is higher than direct balance
                    return channel == channel_info.out_point();
                }
                if let Some(channel) = hop_hint_map.get(&(source, false)) {
                    // if there is a hop hint for source -> node,
                    // then we can not set this node as the last candidate hop for route self
                    // so skip this channel
                    if channel == channel_info.out_point() {
                        return false;
                    }
                }
                if let Some(state) = self
                    .store
                    .get_channel_state_by_outpoint(channel_info.out_point())
                {
                    let balance = state.to_remote_amount;
                    return balance >= amount;
                }
                // normal code path will not reach here, we must can get balance for direct channels
                // anyway, check the capacity here for safety
                return channel_info.capacity() >= amount;
            })
            .collect();

        // a proper hop hint for route self will limit the direct_channels to only one
        // if there are multiple channels, we will randomly select a channel from the source node for route to self
        // so that the following part of algorithm will always trying to find a path without cycle
        if let Some(&(from, to, channel_info, channel_update)) =
            direct_channels.choose(&mut thread_rng())
        {
            assert_ne!(target, from);
            let last_edge = PathEdge {
                target: to,
                channel_outpoint: channel_info.out_point().clone(),
                amount_received: amount,
                incoming_tlc_expiry: expiry,
            };
            let fee = calculate_tlc_forward_fee(amount, channel_update.fee_rate as u128).map_err(
                |err| {
                    PathFindError::PathFind(format!("calculate_tlc_forward_fee error: {:?}", err))
                },
            )?;
            Ok((last_edge, from, channel_update.tlc_expiry_delta, fee))
        } else {
            return Err(PathFindError::PathFind(
                "no direct channel found for source node".to_string(),
            ));
        }
    }

    fn edge_weight(&self, amount: u128, fee: u128, htlc_expiry_delta: u64) -> u128 {
        let risk_factor: u128 = 15;
        let time_lock_penalty = amount * htlc_expiry_delta as u128 * (risk_factor / 1000000000);
        fee + time_lock_penalty
    }

    fn calculate_distance_based_probability(&self, probability: f64, weight: u128) -> u128 {
        assert!(probability > 0.0);
        // FIXME: set this to configurable parameters
        let weight = weight as f64;
        let time_pref = 0.5_f64;
        let default_attemp_cost = 0.1_f64;
        let penalty = default_attemp_cost * (1.0 / (0.5 - time_pref / 2.0) - 1.0);
        weight as u128 + (penalty / probability) as u128
    }
}

pub trait NetworkGraphStateStore {
    fn get_payment_session(&self, payment_hash: Hash256) -> Option<PaymentSession>;
    fn insert_payment_session(&self, session: PaymentSession);
    fn insert_payment_history_result(
        &mut self,
        channel_outpoint: OutPoint,
        direction: Direction,
        result: TimedResult,
    );
    fn get_payment_history_results(&self) -> Vec<(OutPoint, Direction, TimedResult)>;
}

/// The status of a payment, will update as the payment progresses.
#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
pub enum PaymentSessionStatus {
    /// initial status, payment session is created, no HTLC is sent
    Created,
    /// the first hop AddTlc is sent successfully and waiting for the response
    Inflight,
    /// related HTLC is successfully settled
    Success,
    /// related HTLC is failed
    Failed,
}

/// The node and channel information in a payment route hop
#[serde_as]
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct SessionRouteNode {
    /// the public key of the node
    pub pubkey: Pubkey,
    /// the amount for this hop
    pub amount: u128,
    /// the channel outpoint for this hop
    #[serde_as(as = "EntityHex")]
    pub channel_outpoint: OutPoint,
}

/// The router is a list of nodes that the payment will go through.
/// We store in the payment session and then will use it to track the payment history.
/// The router is a list of nodes that the payment will go through.
/// For example:
///    A(amount, channel) -> B -> C -> D means A will send `amount` with `channel` to B.
#[derive(Clone, Debug, Serialize, Deserialize, Default)]
pub struct SessionRoute {
    /// the nodes in the route
    pub nodes: Vec<SessionRouteNode>,
}

impl SessionRoute {
    // Create a new route from the source to the target with the given payment hops.
    // The payment hops are the hops that the payment will go through.
    // for a payment route A -> B -> C -> D
    // the `payment_hops` is [B, C, D], which is a convinent way for onion routing.
    // here we need to create a session route with source, which is A -> B -> C -> D
    pub fn new(source: Pubkey, target: Pubkey, payment_hops: &[PaymentHopData]) -> Self {
        let nodes = std::iter::once(source)
            .chain(
                payment_hops
                    .iter()
                    .map(|hop| hop.next_hop.unwrap_or(target)),
            )
            .zip(payment_hops)
            .map(|(pubkey, hop)| SessionRouteNode {
                pubkey,
                channel_outpoint: OutPoint::new(
                    if hop.funding_tx_hash != Hash256::default() {
                        hop.funding_tx_hash.into()
                    } else {
                        Hash256::default().into()
                    },
                    0,
                ),
                amount: hop.amount,
            })
            .collect();
        Self { nodes }
    }

    pub fn fee(&self) -> u128 {
        let first_amount = self.nodes.first().map_or(0, |s| s.amount);
        let last_amount = self.nodes.last().map_or(0, |s| s.amount);
        assert!(first_amount >= last_amount);
        first_amount - last_amount
    }
}

#[serde_as]
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct PaymentSession {
    pub request: SendPaymentData,
    pub retried_times: u32,
    pub last_error: Option<String>,
    pub try_limit: u32,
    pub status: PaymentSessionStatus,
    pub created_at: u64,
    pub last_updated_at: u64,
    pub route: SessionRoute,
    // Session key for onion packet. Save it for decoding the error packet.
    pub session_key: [u8; 32],
}

impl PaymentSession {
    pub fn new(request: SendPaymentData, try_limit: u32) -> Self {
        let now = now_timestamp_as_millis_u64();
        Self {
            request,
            retried_times: 0,
            last_error: None,
            try_limit,
            status: PaymentSessionStatus::Created,
            created_at: now,
            last_updated_at: now,
            route: SessionRoute::default(),
            session_key: Default::default(),
        }
    }

    pub fn payment_hash(&self) -> Hash256 {
        self.request.payment_hash
    }

    fn set_status(&mut self, status: PaymentSessionStatus) {
        self.status = status;
        self.last_updated_at = now_timestamp_as_millis_u64();
    }

    pub fn set_inflight_status(&mut self) {
        self.set_status(PaymentSessionStatus::Inflight);
    }

    pub fn set_success_status(&mut self) {
        self.set_status(PaymentSessionStatus::Success);
        self.last_error = None;
    }

    pub fn set_failed_status(&mut self, error: &str) {
        self.set_status(PaymentSessionStatus::Failed);
        self.last_error = Some(error.to_string());
    }

    pub fn can_retry(&self) -> bool {
        self.retried_times < self.try_limit
    }

    pub fn fee(&self) -> u128 {
        self.route.fee()
    }

    pub fn hops_public_keys(&self) -> Vec<Pubkey> {
        // Skip the first node, which is the sender.
        self.route.nodes.iter().skip(1).map(|x| x.pubkey).collect()
    }
}

impl From<PaymentSession> for SendPaymentResponse {
    fn from(session: PaymentSession) -> Self {
        let fee = session.fee();
        Self {
            payment_hash: session.request.payment_hash,
            status: session.status,
            failed_error: session.last_error,
            created_at: session.created_at,
            last_updated_at: session.last_updated_at,
            fee,
            #[cfg(debug_assertions)]
            router: session.route,
        }
    }
}


================================================
File: src/fiber/hash_algorithm.rs
================================================
use bitcoin::hashes::{sha256::Hash as Sha256, Hash as _};
use ckb_hash::blake2b_256;
use ckb_types::packed;
use serde::{Deserialize, Serialize};
use thiserror::Error;

/// HashAlgorithm is the hash algorithm used in the hash lock.
#[repr(u8)]
#[derive(Copy, Clone, Debug, PartialEq, Eq, Serialize, Deserialize, Default, Hash)]
#[serde(rename_all = "snake_case")]
pub enum HashAlgorithm {
    /// The default hash algorithm, CkbHash
    #[default]
    CkbHash = 0,
    /// The sha256 hash algorithm
    Sha256 = 1,
}

impl HashAlgorithm {
    pub fn hash<T: AsRef<[u8]>>(&self, s: T) -> [u8; 32] {
        match self {
            HashAlgorithm::CkbHash => blake2b_256(s),
            HashAlgorithm::Sha256 => sha256(s),
        }
    }

    pub fn supported_algorithms() -> Vec<HashAlgorithm> {
        vec![HashAlgorithm::CkbHash, HashAlgorithm::Sha256]
    }
}

/// The error type wrap various ser/de errors.
#[derive(Error, Debug)]
#[error("Unknown Hash Algorithm: {0}")]
pub struct UnknownHashAlgorithmError(pub u8);

impl TryFrom<u8> for HashAlgorithm {
    type Error = UnknownHashAlgorithmError;

    fn try_from(value: u8) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(HashAlgorithm::CkbHash),
            1 => Ok(HashAlgorithm::Sha256),
            _ => Err(UnknownHashAlgorithmError(value)),
        }
    }
}

impl TryFrom<packed::Byte> for HashAlgorithm {
    type Error = UnknownHashAlgorithmError;

    fn try_from(value: packed::Byte) -> Result<Self, Self::Error> {
        let value: u8 = value.into();
        value.try_into()
    }
}

pub fn sha256<T: AsRef<[u8]>>(s: T) -> [u8; 32] {
    Sha256::hash(s.as_ref()).to_byte_array()
}


================================================
File: src/fiber/history.rs
================================================
// The probability calculation is based on lnd's implementation,
// https://github.com/lightningnetwork/lnd/blob/b7c59b36a74975c4e710a02ea42959053735402e/routing/probability_bimodal.go
// we only use direct channel probability now.

use super::{
    graph::{NetworkGraphStateStore, SessionRouteNode},
    types::{Pubkey, TlcErr},
};
use crate::{fiber::types::TlcErrorCode, now_timestamp_as_millis_u64};
use ckb_types::packed::OutPoint;
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet};
use tracing::{debug, error};

#[derive(Debug, Copy, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct TimedResult {
    pub fail_time: u64,
    pub fail_amount: u128,
    pub success_time: u64,
    pub success_amount: u128,
}

const DEFAULT_MIN_FAIL_RELAX_INTERVAL: u64 = 60 * 1000;

// FIXME: this is a magic number from lnd, it's used to scale the amount to calculate the probability
// lnd use 300_000_000 mili satoshis, we use shannons as the unit in fiber
// we need to find a better way to set this value for UDT
const DEFAULT_BIMODAL_SCALE_SHANNONS: f64 = 800_000_000.0;
pub(crate) const DEFAULT_BIMODAL_DECAY_TIME: u64 = 6 * 60 * 60 * 1000; // 6 hours

// The direction of the channel,
// Forward means from node_a to node_b
// Backward means from node_b to node_a
#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash, Serialize, Deserialize)]
pub enum Direction {
    Forward,
    Backward,
}

#[derive(Debug, Copy, Clone, PartialEq, Eq)]
pub(crate) struct InternalPairResult {
    pub(crate) success: bool,
    pub(crate) time: u64,
    pub(crate) amount: u128,
}

#[derive(Debug, Clone, PartialEq, Eq, Default)]
pub(crate) struct InternalResult {
    pub pairs: HashMap<(OutPoint, Direction), InternalPairResult>,
    pub nodes_to_channel_map: HashMap<Pubkey, HashSet<OutPoint>>,
    pub fail_node: Option<Pubkey>,
}

pub(crate) fn output_direction(node1: Pubkey, node2: Pubkey) -> (Direction, Direction) {
    if node1 < node2 {
        (Direction::Forward, Direction::Backward)
    } else {
        (Direction::Backward, Direction::Forward)
    }
}

impl InternalResult {
    pub fn add(
        &mut self,
        node_1: Pubkey,
        node_2: Pubkey,
        channel: OutPoint,
        time: u64,
        amount: u128,
        success: bool,
    ) {
        let (direction, _) = output_direction(node_1, node_2);
        self.add_node_channel_map(node_1, channel.clone());
        self.add_node_channel_map(node_2, channel.clone());
        self.pairs.insert(
            (channel, direction),
            InternalPairResult {
                success,
                time,
                amount,
            },
        );
    }

    fn add_node_channel_map(&mut self, node: Pubkey, channel: OutPoint) {
        self.nodes_to_channel_map
            .entry(node)
            .or_default()
            .insert(channel);
    }

    pub fn add_fail_pair(&mut self, from: Pubkey, target: Pubkey, channel: OutPoint) {
        self.add(
            from,
            target,
            channel.clone(),
            now_timestamp_as_millis_u64(),
            0,
            false,
        );
        self.add(
            target,
            from,
            channel,
            now_timestamp_as_millis_u64(),
            0,
            false,
        )
    }

    pub fn add_fail_pair_balanced(
        &mut self,
        from: Pubkey,
        target: Pubkey,
        channel: OutPoint,
        amount: u128,
    ) {
        self.add(
            from,
            target,
            channel,
            now_timestamp_as_millis_u64(),
            amount,
            false,
        );
    }

    pub fn fail_node(&mut self, nodes: &[SessionRouteNode], index: usize) {
        self.fail_node = Some(nodes[index].pubkey);
        if index > 0 {
            self.fail_pair(nodes, index);
        }
        if index + 1 < nodes.len() {
            self.fail_pair(nodes, index + 1);
        }
    }

    pub fn fail_pair(&mut self, route: &[SessionRouteNode], index: usize) {
        if index > 0 {
            let a = route[index - 1].pubkey;
            let b = route[index].pubkey;
            let channel = route[index - 1].channel_outpoint.clone();
            self.add_fail_pair(a, b, channel);
        }
    }

    pub fn fail_pair_balanced(&mut self, nodes: &[SessionRouteNode], index: usize) {
        if index > 0 {
            let a = nodes[index - 1].pubkey;
            let b = nodes[index].pubkey;
            let amount = nodes[index].amount;
            let channel = nodes[index - 1].channel_outpoint.clone();
            self.add_fail_pair_balanced(a, b, channel, amount);
        }
    }

    pub fn succeed_range_pairs(&mut self, nodes: &[SessionRouteNode], start: usize, end: usize) {
        for i in start..end {
            self.add(
                nodes[i].pubkey,
                nodes[i + 1].pubkey,
                nodes[i].channel_outpoint.clone(),
                now_timestamp_as_millis_u64(),
                nodes[i].amount,
                true,
            );
        }
    }
    pub fn fail_range_pairs(&mut self, nodes: &[SessionRouteNode], start: usize, end: usize) {
        for index in start.max(1)..=end {
            self.fail_pair(nodes, index);
        }
    }

    pub fn record_payment_fail(&mut self, nodes: &[SessionRouteNode], tlc_err: TlcErr) -> bool {
        let mut need_to_retry = true;

        let error_index = nodes
            .iter()
            .position(|s| Some(s.pubkey) == tlc_err.error_node_id());

        let Some(index) = error_index else {
            error!("Error index not found in the route: {:?}", tlc_err);
            // if the error node is not in the route,
            // and we can not penalize the source node (which is ourself)
            // it's better to stop the payment session
            return false;
        };

        let len = nodes.len();
        assert!(len >= 2);
        let error_code = tlc_err.error_code;
        if index == 0 {
            // we get error from the source node
            match error_code {
                TlcErrorCode::InvalidOnionVersion
                | TlcErrorCode::InvalidOnionHmac
                | TlcErrorCode::InvalidOnionKey
                | TlcErrorCode::InvalidOnionPayload => need_to_retry = false,
                TlcErrorCode::IncorrectOrUnknownPaymentDetails
                | TlcErrorCode::InvoiceExpired
                | TlcErrorCode::InvoiceCancelled
                | TlcErrorCode::ExpiryTooFar => {
                    need_to_retry = false;
                }
                TlcErrorCode::TemporaryChannelFailure => {
                    self.fail_pair_balanced(nodes, index + 1);
                }
                _ => {
                    // we can not penalize our own node, the whole payment session need to retry
                }
            }
        } else if index == len - 1 {
            match error_code {
                TlcErrorCode::FinalIncorrectExpiryDelta | TlcErrorCode::FinalIncorrectTlcAmount => {
                    if len == 2 {
                        need_to_retry = false;
                        self.fail_node(nodes, len - 1);
                    } else {
                        // maybe the previous hop is malicious
                        self.fail_pair(nodes, index - 1);
                        self.succeed_range_pairs(nodes, 0, index - 2);
                    }
                }
                TlcErrorCode::IncorrectOrUnknownPaymentDetails
                | TlcErrorCode::InvoiceExpired
                | TlcErrorCode::InvoiceCancelled => {
                    need_to_retry = false;
                    self.succeed_range_pairs(nodes, 0, len - 1);
                }
                TlcErrorCode::ExpiryTooSoon | TlcErrorCode::ExpiryTooFar => {
                    need_to_retry = false;
                }
                _ => {
                    self.fail_node(nodes, len - 1);
                    if len > 1 {
                        self.succeed_range_pairs(nodes, 0, len - 2);
                    }
                }
            }
        } else {
            match error_code {
                TlcErrorCode::InvalidOnionVersion
                | TlcErrorCode::InvalidOnionHmac
                | TlcErrorCode::InvalidOnionKey => {
                    self.fail_pair(nodes, index);
                }
                TlcErrorCode::InvalidOnionPayload => {
                    self.fail_node(nodes, index);
                    if index > 1 {
                        self.succeed_range_pairs(nodes, 0, index - 1);
                    }
                }
                TlcErrorCode::UnknownNextPeer => {
                    self.fail_pair(nodes, index + 1);
                }
                TlcErrorCode::PermanentChannelFailure => {
                    self.fail_pair(nodes, index + 1);
                }
                TlcErrorCode::FeeInsufficient => {
                    need_to_retry = true;
                    self.fail_pair_balanced(nodes, index + 1);
                    if index > 1 {
                        self.succeed_range_pairs(nodes, 0, index);
                    }
                }
                TlcErrorCode::IncorrectTlcExpiry => {
                    need_to_retry = false;
                    if index == 1 {
                        self.fail_node(nodes, 1);
                    } else {
                        self.fail_pair(nodes, index - 1);
                        if index > 1 {
                            self.succeed_range_pairs(nodes, 0, index - 2);
                        }
                    }
                }
                TlcErrorCode::TemporaryChannelFailure => {
                    self.fail_pair_balanced(nodes, index + 1);
                    self.succeed_range_pairs(nodes, 0, index);
                }
                TlcErrorCode::ExpiryTooSoon => {
                    if index == 1 {
                        self.fail_node(nodes, 1);
                    } else {
                        self.fail_range_pairs(nodes, 0, index - 1);
                    }
                }
                TlcErrorCode::IncorrectOrUnknownPaymentDetails
                | TlcErrorCode::InvoiceExpired
                | TlcErrorCode::InvoiceCancelled
                | TlcErrorCode::FinalIncorrectExpiryDelta
                | TlcErrorCode::FinalIncorrectTlcAmount => {
                    error!("middle hop does not expect to report this error");
                    need_to_retry = false;
                }
                _ => {
                    self.fail_node(nodes, index);
                }
            }
        }
        need_to_retry
    }
}

#[derive(Debug, Clone)]
pub(crate) struct PaymentHistory<S> {
    pub inner: HashMap<(OutPoint, Direction), TimedResult>,
    pub nodes_to_channel_map: HashMap<Pubkey, HashSet<OutPoint>>,
    // The minimum interval between two failed payments in milliseconds
    pub min_fail_relax_interval: u64,
    pub bimodal_scale_msat: f64,
    // this filed is used to check whether from is the source Node
    // will be used after enabling the direct channel related logic
    #[allow(dead_code)]
    pub source: Pubkey,
    store: S,
}

impl<S> PaymentHistory<S>
where
    S: NetworkGraphStateStore + Clone + Send + Sync + 'static,
{
    pub(crate) fn new(source: Pubkey, min_fail_relax_interval: Option<u64>, store: S) -> Self {
        let mut s = PaymentHistory {
            source,
            inner: HashMap::new(),
            nodes_to_channel_map: HashMap::new(),
            min_fail_relax_interval: min_fail_relax_interval
                .unwrap_or(DEFAULT_MIN_FAIL_RELAX_INTERVAL),
            bimodal_scale_msat: DEFAULT_BIMODAL_SCALE_SHANNONS,
            store,
        };
        s.load_from_store();
        s
    }

    #[cfg(test)]
    pub(crate) fn reset(&mut self) {
        self.inner.clear();
        self.nodes_to_channel_map.clear();
    }

    pub(crate) fn add_result(
        &mut self,
        channel: OutPoint,
        direction: Direction,
        result: TimedResult,
    ) {
        self.inner.insert((channel.clone(), direction), result);
        self.save_result(channel, direction, result);
    }

    fn save_result(&mut self, channel: OutPoint, direction: Direction, result: TimedResult) {
        self.store
            .insert_payment_history_result(channel, direction, result);
    }

    pub(crate) fn add_node_channel_map(&mut self, node: Pubkey, channel: OutPoint) {
        self.nodes_to_channel_map
            .entry(node)
            .or_default()
            .insert(channel);
    }

    pub(crate) fn load_from_store(&mut self) {
        let results = self.store.get_payment_history_results();
        for (channel, direction, result) in results.into_iter() {
            self.inner.insert((channel, direction), result);
        }
    }

    pub(crate) fn apply_pair_result(
        &mut self,
        channel: OutPoint,
        direction: Direction,
        amount: u128,
        success: bool,
        time: u64,
    ) {
        let min_fail_relax_interval = self.min_fail_relax_interval;
        let result = if let Some(current) = self.get_mut_result(channel.clone(), direction) {
            if success {
                current.success_time = time;
                if amount > current.success_amount {
                    current.success_amount = amount;
                }
                if current.fail_time != 0 && amount >= current.fail_amount {
                    current.fail_amount = amount + 1;
                }
            } else {
                if amount > current.fail_amount
                    && current.fail_time != 0
                    && time.saturating_sub(current.fail_time) < min_fail_relax_interval
                {
                    return;
                }
                current.fail_amount = amount;
                current.fail_time = time;
                if amount == 0 {
                    current.success_amount = 0;
                } else if amount <= current.success_amount {
                    current.success_amount = amount.saturating_sub(1);
                }
            }
            // make sure success_amount is less than or equal to fail_amount,
            // so that we can calculate the probability in a amount range.
            assert!(current.fail_time == 0 || current.success_amount <= current.fail_amount);
            *current
        } else {
            TimedResult {
                fail_time: if success { 0 } else { time },
                fail_amount: if success { 0 } else { amount },
                success_time: if success { time } else { 0 },
                success_amount: if success { amount } else { 0 },
            }
        };
        self.add_result(channel, direction, result);
    }

    pub(crate) fn apply_internal_result(&mut self, result: InternalResult) {
        let InternalResult {
            pairs,
            fail_node,
            nodes_to_channel_map,
        } = result;
        for ((channel, direction), pair_result) in pairs.into_iter() {
            self.apply_pair_result(
                channel,
                direction,
                pair_result.amount,
                pair_result.success,
                pair_result.time,
            );
        }
        for (node, channels) in nodes_to_channel_map.into_iter() {
            self.nodes_to_channel_map
                .entry(node)
                .or_default()
                .extend(channels);
        }
        if let Some(fail_node) = fail_node {
            let channels = self
                .nodes_to_channel_map
                .get(&fail_node)
                .expect("channels not found");
            let pairs: Vec<(OutPoint, Direction)> = self
                .inner
                .iter()
                .flat_map(|((outpoint, direction), _)| {
                    if channels.contains(outpoint) {
                        Some((outpoint.clone(), *direction))
                    } else {
                        None
                    }
                })
                .collect();

            for (channel, direction) in pairs.into_iter() {
                self.apply_pair_result(channel, direction, 0, false, now_timestamp_as_millis_u64());
            }
        }
    }

    pub(crate) fn get_result(
        &self,
        channel: &OutPoint,
        direction: Direction,
    ) -> Option<&TimedResult> {
        self.inner.get(&(channel.clone(), direction))
    }

    pub(crate) fn get_mut_result(
        &mut self,
        channel: OutPoint,
        direction: Direction,
    ) -> Option<&mut TimedResult> {
        self.inner.get_mut(&(channel, direction))
    }

    pub(crate) fn eval_probability(
        &self,
        from: Pubkey,
        target: Pubkey,
        channel: &OutPoint,
        amount: u128,
        capacity: u128,
    ) -> f64 {
        let mut success_amount = 0;
        let mut fail_amount = capacity;
        let (direction, _) = output_direction(from, target);
        if let Some(result) = self.get_result(channel, direction) {
            if result.fail_time != 0 {
                fail_amount = self.cannot_send(result.fail_amount, result.fail_time, capacity);
            }
            if result.success_time != 0 {
                success_amount = self.can_send(result.success_amount, result.success_time);
            }
        } else {
            // if we don't have the history, we assume the probability is 1.0
            return 1.0;
        }
        let ret = self.get_channel_probability(capacity, success_amount, fail_amount, amount);
        assert!((0.0..=1.0).contains(&ret));
        ret
    }

    // The factor approaches 0 for success_time a long time in the past,
    // is 1 when the success_time is now.
    fn time_factor(&self, time: u64) -> f64 {
        let time_ago = now_timestamp_as_millis_u64() - time;
        // if time_ago is less than 1 second, we treat it as 0, this makes the factor 1
        // this is to avoid the factor is too small when the time is very close to now,
        // this will make the probability calculation more stable
        let time_ago = if time_ago < 1000 { 0 } else { time_ago };
        let exponent = -(time_ago as f64) / (DEFAULT_BIMODAL_DECAY_TIME as f64);

        exponent.exp()
    }

    pub(crate) fn cannot_send(&self, fail_amount: u128, time: u64, capacity: u128) -> u128 {
        let mut fail_amount = fail_amount;

        if fail_amount > capacity {
            fail_amount = capacity;
        }

        let factor = self.time_factor(time);

        capacity - (factor * (capacity - fail_amount) as f64) as u128
    }

    pub(crate) fn can_send(&self, amount: u128, time: u64) -> u128 {
        let factor = self.time_factor(time);

        (amount as f64 * factor) as u128
    }

    // Get the probability of a payment success through a direct channel,
    // suppose we know the accurate balance for direct channels, so we don't need to use `get_channel_probability`
    // for the direct channel, this function is used disable the direct channel for a time preiod if it's failed
    // currently we may mark the channel failed on graph level, so this function is not used now.
    // FIXME: reconsider this after we already got the accurate balance of direct channels
    //        related issue: https://github.com/nervosnetwork/fiber/issues/257
    #[allow(dead_code)]
    pub(crate) fn get_direct_probability(&self, channel: &OutPoint, direction: Direction) -> f64 {
        let mut prob = 1.0;
        if let Some(result) = self.get_result(channel, direction) {
            if result.fail_time != 0 {
                let time_ago = now_timestamp_as_millis_u64() - result.fail_time;
                let exponent = -(time_ago as f64) / (DEFAULT_BIMODAL_DECAY_TIME as f64);
                prob -= exponent.exp();
            }
        }
        prob
    }

    // Get the probability of a payment success through a channel
    // The probability is calculated based on the history of the channel
    // Suppose the range of amount:
    // ---------------------- success_amount ++++++++++++++++++++++++ fail_amount xxxxxxxxxxxxxxxxxxxxxx
    //        must be succeed       |        may be succeed           |       must be failed
    // The probability is calculated as:
    // 1. If the amount is less than or equal to success_amount, return 1.0
    // 2. If the amount is greater than fail_amount, return 0.0
    // 3. Otherwise, calculate the probability based on the time and capacity of the channel
    pub(crate) fn get_channel_probability(
        &self,
        capacity: u128,
        success_amount: u128,
        fail_amount: u128,
        amount: u128,
    ) -> f64 {
        if amount > capacity || amount == 0 || capacity == 0 {
            return 0.0;
        }

        let fail_amount = fail_amount.min(capacity);
        let success_amount = success_amount.min(capacity);

        if fail_amount == success_amount {
            // if the graph has latest information
            // we don't continue to calculate the probability
            if amount < capacity {
                return 1.0;
            }
            return 0.0;
        }

        if fail_amount < success_amount {
            // suppose a malioucious node report wrong information
            // here we return 0.0 to avoid to choose this channel
            error!(
                "fail_amount: {} < success_amount: {}",
                fail_amount, success_amount
            );
            return 0.0;
        }

        if amount >= fail_amount {
            return 0.0;
        }

        // safely convert amount, success_amount, fail_amount to f64
        let amount = amount as f64;
        let success_amount = success_amount as f64;
        let fail_amount = fail_amount as f64;

        // f128 is only on nightly, so we use f64 here, we may lose some precision
        // but it's acceptable since all the values are cast to f64
        let mut prob = self.integral_probability(capacity as f64, amount, fail_amount);
        if prob.is_nan() {
            error!(
                "probability is NaN: capacity: {} amount: {} fail_amount: {}",
                capacity, amount, fail_amount
            );
            return 0.0;
        }
        let re_norm = self.integral_probability(capacity as f64, success_amount, fail_amount);
        if re_norm == 0.0 {
            return 0.0;
        }
        prob /= re_norm;
        prob = prob.clamp(0.0, 1.0);
        return prob;
    }

    fn primitive(&self, c: f64, x: f64) -> f64 {
        let s = self.bimodal_scale_msat;

        // The indefinite integral of P(x) is given by
        // Int P(x) dx = H(x) = s * (-e(-x/s) + e((x-c)/s)),
        // and its norm from 0 to c can be computed from it,
        // norm = [H(x)]_0^c = s * (-e(-c/s) + 1 -(1 + e(-c/s))).
        let ecs = (-c / s).exp();
        let exs = (-x / s).exp();

        // It would be possible to split the next term and reuse the factors
        // from before, but this can lead to numerical issues with large
        // numbers.
        let excs = ((x - c) / s).exp();

        // norm can only become zero, if c is zero, which we sorted out before
        // calling this method.
        let norm = -2.0 * ecs + 2.0;

        // We end up with the primitive function of the normalized P(x).
        (-exs + excs) / norm
    }

    fn integral_probability(&self, capacity: f64, lower: f64, upper: f64) -> f64 {
        if lower < 0.0 || lower > upper {
            debug!(
                "probability integral limits nonsensical: capacity: {} lower: {} upper: {}",
                capacity, lower, upper
            );
            return 0.0;
        }

        self.primitive(capacity, upper) - self.primitive(capacity, lower)
    }
}


================================================
File: src/fiber/key.rs
================================================
use ckb_hash::new_blake2b;
use std::{fs, path::Path};
use tracing::warn;

// TODO: we need to securely erase the key.
// We wrap the key in a struct to obtain create a function to obtain secret entropy from this key.
// Unfortunately, SecioKeyPair does not allow us to obtain the secret key from the key pair.
#[derive(Clone)]
pub struct KeyPair([u8; 32]);

use tentacle::secio::SecioKeyPair;

use rand::{thread_rng, Rng};
use std::io::{Error, ErrorKind, Read, Write};

use super::types::Privkey;

impl KeyPair {
    pub fn generate_random_key() -> Self {
        loop {
            let mut key: [u8; 32] = [0; 32];
            thread_rng().fill(&mut key);
            if Self::try_from(key.as_slice()).is_ok() {
                return Self(key);
            }
        }
    }

    pub fn read_or_generate(path: &Path) -> Result<Self, Error> {
        match Self::read_from_file(path)? {
            Some(key) => Ok(key),
            None => {
                let key = Self::generate_random_key();
                key.write_to_file(path)?;
                Ok(Self::read_from_file(path)?.expect("key created from previous step"))
            }
        }
    }

    pub fn write_to_file(&self, path: &Path) -> Result<(), Error> {
        fs::OpenOptions::new()
            .create(true)
            .truncate(true)
            .write(true)
            .open(path)
            .and_then(|mut file| {
                file.write_all(self.as_ref())?;
                #[cfg(unix)]
                {
                    use std::os::unix::fs::PermissionsExt;
                    file.set_permissions(fs::Permissions::from_mode(0o400))
                }
                #[cfg(not(unix))]
                {
                    let mut permissions = file.metadata()?.permissions();
                    permissions.set_readonly(true);
                    file.set_permissions(permissions)
                }
            })
    }

    pub fn read_from_file(path: &Path) -> Result<Option<Self>, Error> {
        read_secret_key(path)
    }
}

impl AsRef<[u8]> for KeyPair {
    fn as_ref(&self) -> &[u8] {
        &self.0
    }
}

impl From<KeyPair> for SecioKeyPair {
    fn from(val: KeyPair) -> Self {
        SecioKeyPair::secp256k1_raw_key(val.0).expect("key must have been validated")
    }
}

impl TryFrom<&[u8]> for KeyPair {
    type Error = Error;

    fn try_from(value: &[u8]) -> Result<Self, Self::Error> {
        if value.len() < 32 {
            return Err(Error::new(
                ErrorKind::InvalidData,
                "invalid secret key length",
            ));
        }
        let mut key = [0u8; 32];
        key.copy_from_slice(value);
        if SecioKeyPair::secp256k1_raw_key(key).is_err() {
            return Err(Error::new(
                ErrorKind::InvalidData,
                "invalid secret key data",
            ));
        }
        Ok(Self(key))
    }
}

impl From<KeyPair> for Privkey {
    fn from(val: KeyPair) -> Self {
        Privkey::from(val.0)
    }
}

pub(crate) fn read_secret_key(path: &Path) -> Result<Option<KeyPair>, Error> {
    let mut file = match fs::File::open(path) {
        Ok(file) => file,
        Err(_) => return Ok(None),
    };
    let warn = |m: bool, d: &str| {
        if m {
            warn!(
                "Your network secret file's permission is not {}, path: {:?}. \
                Please fix it as soon as possible",
                d, path
            )
        }
    };
    #[cfg(unix)]
    {
        use std::os::unix::fs::PermissionsExt;
        warn(
            file.metadata()?.permissions().mode() & 0o177 != 0,
            "less than 0o600",
        );
    }
    #[cfg(not(unix))]
    {
        warn(!file.metadata()?.permissions().readonly(), "readonly");
    }
    let mut buf = Vec::new();
    file.read_to_end(&mut buf).and_then(|_read_size| {
        KeyPair::try_from(buf.as_slice())
            .map(Some)
            .map_err(|_| Error::new(ErrorKind::InvalidData, "invalid secret key data"))
    })
}

pub(crate) fn blake2b_hash_with_salt(data: &[u8], salt: &[u8]) -> [u8; 32] {
    let mut hasher = new_blake2b();
    hasher.update(salt);
    hasher.update(data);
    let mut result = [0u8; 32];
    hasher.finalize(&mut result);
    result
}


================================================
File: src/fiber/mod.rs
================================================
pub mod config;
pub use config::FiberConfig;
pub mod network;

pub use network::start_network;
pub use network::{
    NetworkActor, NetworkActorCommand, NetworkActorEvent, NetworkActorMessage, NetworkServiceEvent,
};
pub mod graph;
pub mod history;

mod fee;
mod key;
mod path;

pub use key::KeyPair;
pub mod channel;
pub mod gen;
pub mod hash_algorithm;
pub mod serde_utils;
pub mod types;

pub(crate) mod gossip;

#[cfg(test)]
pub mod tests;

pub(crate) const ASSUME_NETWORK_ACTOR_ALIVE: &str = "network actor must be alive";


================================================
File: src/fiber/network.rs
================================================
use ckb_hash::blake2b_256;
use ckb_jsonrpc_types::{Status, TxStatus};
use ckb_types::core::{EpochNumberWithFraction, TransactionView};
use ckb_types::packed::{Byte32, OutPoint, Script, Transaction};
use ckb_types::prelude::{IntoTransactionView, Pack, Unpack};
use ckb_types::H256;
use once_cell::sync::OnceCell;
use ractor::concurrency::Duration;
use ractor::{
    async_trait as rasync_trait, call, call_t, Actor, ActorCell, ActorProcessingErr, ActorRef,
    RactorErr, RpcReplyPort, SupervisionEvent,
};
use rand::Rng;
use secp256k1::Secp256k1;
use serde::{Deserialize, Serialize};
use serde_with::{serde_as, DisplayFromStr};
use std::borrow::Cow;
use std::collections::hash_map::Entry;
use std::collections::{HashMap, HashSet};
use std::str::FromStr;
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Arc;
use std::time::SystemTime;
use tentacle::multiaddr::{MultiAddr, Protocol};
use tentacle::service::SessionType;
use tentacle::utils::{extract_peer_id, is_reachable, multiaddr_to_socketaddr};
use tentacle::{
    async_trait,
    builder::{MetaBuilder, ServiceBuilder},
    bytes::Bytes,
    context::SessionContext,
    context::{ProtocolContext, ProtocolContextMutRef, ServiceContext},
    multiaddr::Multiaddr,
    secio::PeerId,
    secio::SecioKeyPair,
    service::{
        ProtocolHandle, ProtocolMeta, ServiceAsyncControl, ServiceError, ServiceEvent,
        TargetProtocol,
    },
    traits::{ServiceHandle, ServiceProtocol},
    ProtocolId, SessionId,
};
use tokio::sync::{mpsc, oneshot, RwLock};
use tokio_util::task::TaskTracker;
use tracing::{debug, error, info, trace, warn};

use super::channel::{
    get_funding_and_reserved_amount, occupied_capacity, AcceptChannelParameter, ChannelActor,
    ChannelActorMessage, ChannelActorStateStore, ChannelCommand, ChannelCommandWithId,
    ChannelEvent, ChannelInitializationParameter, ChannelState, ChannelSubscribers, ChannelTlcInfo,
    OpenChannelParameter, PrevTlcInfo, ProcessingChannelError, ProcessingChannelResult,
    PublicChannelInfo, RevocationData, SettlementData, ShuttingDownFlags,
    DEFAULT_COMMITMENT_FEE_RATE, DEFAULT_FEE_RATE, DEFAULT_MAX_TLC_VALUE_IN_FLIGHT,
    MAX_COMMITMENT_DELAY_EPOCHS, MAX_TLC_NUMBER_IN_FLIGHT, MIN_COMMITMENT_DELAY_EPOCHS,
    SYS_MAX_TLC_NUMBER_IN_FLIGHT,
};
use super::config::{AnnouncedNodeName, MIN_TLC_EXPIRY_DELTA};
use super::fee::calculate_commitment_tx_fee;
use super::gossip::{GossipActorMessage, GossipMessageStore, GossipMessageUpdates};
use super::graph::{NetworkGraph, NetworkGraphStateStore, OwnedChannelUpdateEvent, SessionRoute};
use super::key::blake2b_hash_with_salt;
use super::types::{
    BroadcastMessage, BroadcastMessageQuery, BroadcastMessageWithTimestamp, EcdsaSignature,
    FiberMessage, ForwardTlcResult, GossipMessage, Hash256, NodeAnnouncement, OpenChannel,
    PaymentHopData, Privkey, Pubkey, RemoveTlcReason, TlcErr, TlcErrData, TlcErrorCode,
};
use super::{FiberConfig, ASSUME_NETWORK_ACTOR_ALIVE};

use crate::ckb::config::UdtCfgInfos;
use crate::ckb::contracts::{check_udt_script, get_udt_whitelist, is_udt_type_auto_accept};
use crate::ckb::{
    CkbChainMessage, FundingRequest, FundingTx, GetBlockTimestampRequest, TraceTxRequest,
    TraceTxResponse,
};
use crate::fiber::channel::{
    AddTlcCommand, AddTlcResponse, TxCollaborationCommand, TxUpdateCommand,
};
use crate::fiber::config::{DEFAULT_TLC_EXPIRY_DELTA, MAX_PAYMENT_TLC_EXPIRY_LIMIT};
use crate::fiber::gossip::{GossipProtocolHandle, SubscribableGossipMessageStore};
use crate::fiber::graph::{PaymentSession, PaymentSessionStatus};
use crate::fiber::serde_utils::EntityHex;
use crate::fiber::types::{
    FiberChannelMessage, PaymentOnionPacket, PeeledPaymentOnionPacket, TxSignatures,
};
use crate::fiber::KeyPair;
use crate::invoice::{CkbInvoice, InvoiceStore};
use crate::{now_timestamp_as_millis_u64, unwrap_or_return, Error};

pub const FIBER_PROTOCOL_ID: ProtocolId = ProtocolId::new(42);

pub const GOSSIP_PROTOCOL_ID: ProtocolId = ProtocolId::new(43);

pub const DEFAULT_CHAIN_ACTOR_TIMEOUT: u64 = 300000;

// tx index is not returned on older ckb version, using dummy tx index instead.
// Waiting for https://github.com/nervosnetwork/ckb/pull/4583/ to be released.
const DUMMY_FUNDING_TX_INDEX: u32 = 0;

// This is a temporary way to document that we assume the chain actor is always alive.
// We may later relax this assumption. At the moment, if the chain actor fails, we
// should panic with this message, and later we may find all references to this message
// to make sure that we handle the case where the chain actor is not alive.
const ASSUME_CHAIN_ACTOR_ALWAYS_ALIVE_FOR_NOW: &str =
    "We currently assume that chain actor is always alive, but it failed. This is a known issue.";

const ASSUME_NETWORK_MYSELF_ALIVE: &str = "network actor myself alive";

// The duration for which we will try to maintain the number of peers in connection.
const MAINTAINING_CONNECTIONS_INTERVAL: Duration = Duration::from_secs(3600);

// While creating a network graph from the gossip messages, we will load current gossip messages
// in the store and process them. We will load all current messages and get the latest cursor.
// The problem is that we can't guarantee that the messages are in order, that is to say it is
// possible that messages with smaller cursor may arrive at the store from the time we create
// the graph. So we have to subscribe to gossip messages with a cursor slightly smaller than
// current latest cursor. This parameter is the difference between the cursor we use to subscribe
// and the latest cursor.
const MAX_GRAPH_MISSING_BROADCAST_MESSAGE_TIMESTAMP_DRIFT: Duration =
    Duration::from_secs(60 * 60 * 2);

static CHAIN_HASH_INSTANCE: OnceCell<Hash256> = OnceCell::new();

pub fn init_chain_hash(chain_hash: Hash256) {
    CHAIN_HASH_INSTANCE
        .set(chain_hash)
        .expect("init_chain_hash should only be called once");
}

pub(crate) fn get_chain_hash() -> Hash256 {
    CHAIN_HASH_INSTANCE.get().cloned().unwrap_or_default()
}

pub(crate) fn check_chain_hash(chain_hash: &Hash256) -> Result<(), Error> {
    if chain_hash == &get_chain_hash() {
        Ok(())
    } else {
        Err(Error::InvalidChainHash(*chain_hash, get_chain_hash()))
    }
}

#[derive(Debug)]
pub struct OpenChannelResponse {
    pub channel_id: Hash256,
}

#[derive(Debug)]
pub struct AcceptChannelResponse {
    pub old_channel_id: Hash256,
    pub new_channel_id: Hash256,
}

#[derive(Debug)]
pub struct SendPaymentResponse {
    pub payment_hash: Hash256,
    pub status: PaymentSessionStatus,
    pub created_at: u64,
    pub last_updated_at: u64,
    pub failed_error: Option<String>,
    pub fee: u128,
    #[cfg(debug_assertions)]
    pub router: SessionRoute,
}

/// What kind of local information should be broadcasted to the network.
#[derive(Debug)]
pub enum LocalInfoKind {
    NodeAnnouncement,
}

#[derive(Debug, Clone)]
pub struct NodeInfoResponse {
    pub node_name: Option<AnnouncedNodeName>,
    pub node_id: Pubkey,
    pub addresses: Vec<MultiAddr>,
    pub chain_hash: Hash256,
    pub open_channel_auto_accept_min_ckb_funding_amount: u64,
    pub auto_accept_channel_ckb_funding_amount: u64,
    pub tlc_expiry_delta: u64,
    pub tlc_min_value: u128,
    pub tlc_max_value: u128,
    pub tlc_fee_proportional_millionths: u128,
    pub channel_count: u32,
    pub pending_channel_count: u32,
    pub peers_count: u32,
    pub udt_cfg_infos: UdtCfgInfos,
}

/// The struct here is used both internally and as an API to the outside world.
/// If we want to send a reply to the caller, we need to wrap the message with
/// a RpcReplyPort. Since outsider users have no knowledge of RpcReplyPort, we
/// need to hide it from the API. So in case a reply is needed, we need to put
/// an optional RpcReplyPort in the of the definition of this message.
#[derive(Debug)]
pub enum NetworkActorCommand {
    /// Network commands
    // Connect to a peer, and optionally also save the peer to the peer store.
    ConnectPeer(Multiaddr),
    DisconnectPeer(PeerId),
    // Save the address of a peer to the peer store, the address here must be a valid
    // multiaddr with the peer id.
    SavePeerAddress(Multiaddr),
    // We need to maintain a certain number of peers connections to keep the network running.
    MaintainConnections,
    // For internal use and debugging only. Most of the messages requires some
    // changes to local state. Even if we can send a message to a peer, some
    // part of the local state is not changed.
    SendFiberMessage(FiberMessageWithPeerId),
    // Open a channel to a peer.
    OpenChannel(
        OpenChannelCommand,
        RpcReplyPort<Result<OpenChannelResponse, String>>,
    ),
    // Accept a channel to a peer.
    AcceptChannel(
        AcceptChannelCommand,
        RpcReplyPort<Result<AcceptChannelResponse, String>>,
    ),
    // Send a command to a channel.
    ControlFiberChannel(ChannelCommandWithId),
    // The first parameter is the peeled onion in binary via `PeeledOnionPacket::serialize`. `PeeledOnionPacket::current`
    // is for the current node.
    SendPaymentOnionPacket(SendOnionPacketCommand),
    PeelPaymentOnionPacket(
        PaymentOnionPacket, // onion_packet
        Hash256,            // payment_hash
        RpcReplyPort<Result<PeeledPaymentOnionPacket, String>>,
    ),
    UpdateChannelFunding(Hash256, Transaction, FundingRequest),
    SignTx(PeerId, Hash256, Transaction, Option<Vec<Vec<u8>>>),
    // Process a broadcast message from the network.
    ProcessBroadcastMessage(BroadcastMessage),
    // Query broadcast messages from a peer. Some messages may have been missed
    // we use this to query them.
    QueryBroadcastMessages(PeerId, Vec<BroadcastMessageQuery>),
    // Broadcast our BroadcastMessage to the network.
    BroadcastMessages(Vec<BroadcastMessageWithTimestamp>),
    // Broadcast local information to the network.
    BroadcastLocalInfo(LocalInfoKind),
    SignMessage([u8; 32], RpcReplyPort<EcdsaSignature>),
    // Payment related commands
    SendPayment(
        SendPaymentCommand,
        RpcReplyPort<Result<SendPaymentResponse, String>>,
    ),
    // Get Payment Session for query payment status and errors
    GetPayment(Hash256, RpcReplyPort<Result<SendPaymentResponse, String>>),

    // Send a message to the gossip actor.
    GossipActorMessage(GossipActorMessage),

    NodeInfo((), RpcReplyPort<Result<NodeInfoResponse, String>>),
}

pub async fn sign_network_message(
    network: ActorRef<NetworkActorMessage>,
    message: [u8; 32],
) -> std::result::Result<EcdsaSignature, RactorErr<NetworkActorMessage>> {
    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::SignMessage(message, rpc_reply))
    };

    call!(network, message)
}

#[derive(Debug)]
pub struct OpenChannelCommand {
    pub peer_id: PeerId,
    pub funding_amount: u128,
    pub public: bool,
    pub shutdown_script: Option<Script>,
    pub funding_udt_type_script: Option<Script>,
    pub commitment_fee_rate: Option<u64>,
    pub commitment_delay_epoch: Option<EpochNumberWithFraction>,
    pub funding_fee_rate: Option<u64>,
    pub tlc_expiry_delta: Option<u64>,
    pub tlc_min_value: Option<u128>,
    pub tlc_fee_proportional_millionths: Option<u128>,
    pub max_tlc_value_in_flight: Option<u128>,
    pub max_tlc_number_in_flight: Option<u64>,
}

#[serde_as]
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct SendPaymentCommand {
    // the identifier of the payment target
    pub target_pubkey: Option<Pubkey>,
    // the amount of the payment
    pub amount: Option<u128>,
    // The hash to use within the payment's HTLC
    pub payment_hash: Option<Hash256>,
    // the encoded invoice to send to the recipient
    pub invoice: Option<String>,
    // the TLC expiry delta that should be used to set the timelock for the final hop
    pub final_tlc_expiry_delta: Option<u64>,
    // the TLC expiry for whole payment, in milliseconds
    pub tlc_expiry_limit: Option<u64>,
    // the payment timeout in seconds, if the payment is not completed within this time, it will be cancelled
    pub timeout: Option<u64>,
    // the maximum fee amounts in shannons that the sender is willing to pay, default is 1000 shannons CKB.
    pub max_fee_amount: Option<u128>,
    // max parts for the payment, only used for multi-part payments
    pub max_parts: Option<u64>,
    // keysend payment, default is false
    pub keysend: Option<bool>,
    // udt type script
    #[serde_as(as = "Option<EntityHex>")]
    pub udt_type_script: Option<Script>,
    // allow self payment, default is false
    pub allow_self_payment: bool,
    // the hop hint which may help the find path algorithm to find the path
    pub hop_hints: Option<Vec<HopHint>>,
    // dry_run only used for checking, default is false
    pub dry_run: bool,
}

#[serde_as]
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct HopHint {
    /// The public key of the node
    pub pubkey: Pubkey,
    /// The funding transaction hash of the channel outpoint
    pub channel_funding_tx: Hash256,
    /// inbound or outbound for the channel
    pub inbound: bool,
}

#[serde_as]
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct SendPaymentData {
    pub target_pubkey: Pubkey,
    pub amount: u128,
    pub payment_hash: Hash256,
    pub invoice: Option<String>,
    pub final_tlc_expiry_delta: u64,
    pub tlc_expiry_limit: u64,
    pub timeout: Option<u64>,
    pub max_fee_amount: Option<u128>,
    pub max_parts: Option<u64>,
    pub keysend: bool,
    #[serde_as(as = "Option<EntityHex>")]
    pub udt_type_script: Option<Script>,
    pub preimage: Option<Hash256>,
    pub allow_self_payment: bool,
    pub hop_hints: Vec<HopHint>,
    pub dry_run: bool,
}

impl SendPaymentData {
    pub fn new(command: SendPaymentCommand) -> Result<SendPaymentData, String> {
        let invoice = command
            .invoice
            .as_ref()
            .map(|invoice| invoice.parse::<CkbInvoice>())
            .transpose()
            .map_err(|_| "invoice is invalid".to_string())?;

        if let Some(invoice) = invoice.clone() {
            if invoice.is_expired() {
                return Err("invoice is expired".to_string());
            }
        }

        fn validate_field<T: PartialEq + Clone>(
            field: Option<T>,
            invoice_field: Option<T>,
            field_name: &str,
        ) -> Result<T, String> {
            match (field, invoice_field) {
                (Some(f), Some(i)) => {
                    if f != i {
                        return Err(format!("{} does not match the invoice", field_name));
                    }
                    Ok(f)
                }
                (Some(f), None) => Ok(f),
                (None, Some(i)) => Ok(i),
                (None, None) => Err(format!("{} is missing", field_name)),
            }
        }

        let target = validate_field(
            command.target_pubkey,
            invoice
                .as_ref()
                .and_then(|i| i.payee_pub_key().cloned().map(Pubkey::from)),
            "target_pubkey",
        )?;

        let amount = validate_field(
            command.amount,
            invoice.as_ref().and_then(|i| i.amount()),
            "amount",
        )?;

        let udt_type_script = match validate_field(
            command.udt_type_script.clone(),
            invoice.as_ref().and_then(|i| i.udt_type_script().cloned()),
            "udt_type_script",
        ) {
            Ok(script) => Some(script),
            Err(e) if e == "udt_type_script is missing" => None,
            Err(e) => return Err(e),
        };

        // check htlc expiry delta and limit are both valid if it is set
        let final_tlc_expiry_delta = command
            .final_tlc_expiry_delta
            .or_else(|| {
                invoice
                    .as_ref()
                    .and_then(|i| i.final_tlc_minimum_expiry_delta().copied())
            })
            .unwrap_or(DEFAULT_TLC_EXPIRY_DELTA);
        if !(MIN_TLC_EXPIRY_DELTA..=MAX_PAYMENT_TLC_EXPIRY_LIMIT).contains(&final_tlc_expiry_delta)
        {
            return Err(format!(
                "invalid final_tlc_expiry_delta, expect between {} and {}",
                MIN_TLC_EXPIRY_DELTA, MAX_PAYMENT_TLC_EXPIRY_LIMIT
            ));
        }

        let tlc_expiry_limit = command
            .tlc_expiry_limit
            .unwrap_or(MAX_PAYMENT_TLC_EXPIRY_LIMIT);

        if tlc_expiry_limit < final_tlc_expiry_delta || tlc_expiry_limit < MIN_TLC_EXPIRY_DELTA {
            return Err("tlc_expiry_limit is too small".to_string());
        }
        if tlc_expiry_limit > MAX_PAYMENT_TLC_EXPIRY_LIMIT {
            return Err(format!(
                "tlc_expiry_limit is too large, expect it to less than {}",
                MAX_PAYMENT_TLC_EXPIRY_LIMIT
            ));
        }

        let keysend = command.keysend.unwrap_or(false);
        let (payment_hash, preimage) = if !keysend {
            (
                validate_field(
                    command.payment_hash,
                    invoice.as_ref().map(|i| *i.payment_hash()),
                    "payment_hash",
                )?,
                None,
            )
        } else {
            if invoice.is_some() {
                return Err("keysend payment should not have invoice".to_string());
            }
            if command.payment_hash.is_some() {
                return Err("keysend payment should not have payment_hash".to_string());
            }
            // generate a random preimage for keysend payment
            let mut rng = rand::thread_rng();
            let mut result = [0u8; 32];
            rng.fill(&mut result[..]);
            let preimage: Hash256 = result.into();
            // use the default payment hash algorithm here for keysend payment
            let payment_hash: Hash256 = blake2b_256(preimage).into();
            (payment_hash, Some(preimage))
        };

        if udt_type_script.is_none() && amount >= u64::MAX as u128 {
            return Err(format!(
                "The payment amount ({}) should be less than {}",
                amount,
                u64::MAX
            ));
        }

        let hop_hints = command.hop_hints.unwrap_or_default();

        Ok(SendPaymentData {
            target_pubkey: target,
            amount,
            payment_hash,
            invoice: command.invoice,
            final_tlc_expiry_delta,
            tlc_expiry_limit,
            timeout: command.timeout,
            max_fee_amount: command.max_fee_amount,
            max_parts: command.max_parts,
            keysend,
            udt_type_script,
            preimage,
            allow_self_payment: command.allow_self_payment,
            hop_hints,
            dry_run: command.dry_run,
        })
    }
}

#[derive(Debug)]
pub struct AcceptChannelCommand {
    pub temp_channel_id: Hash256,
    pub funding_amount: u128,
    pub shutdown_script: Option<Script>,
    pub max_tlc_value_in_flight: Option<u128>,
    pub max_tlc_number_in_flight: Option<u64>,
    pub min_tlc_value: Option<u128>,
    pub tlc_fee_proportional_millionths: Option<u128>,
    pub tlc_expiry_delta: Option<u64>,
}

#[derive(Debug, Clone)]
pub struct SendOnionPacketCommand {
    pub peeled_onion_packet: PeeledPaymentOnionPacket,
    // We are currently forwarding a previous tlc. The previous tlc's channel id, tlc id
    // and the fee paid are included here.
    pub previous_tlc: Option<PrevTlcInfo>,
    pub payment_hash: Hash256,
}

impl NetworkActorMessage {
    pub fn new_event(event: NetworkActorEvent) -> Self {
        Self::Event(event)
    }

    pub fn new_command(command: NetworkActorCommand) -> Self {
        Self::Command(command)
    }

    pub fn new_notification(service_event: NetworkServiceEvent) -> Self {
        Self::Notification(service_event)
    }
}

#[cfg(debug_assertions)]
#[derive(Clone, Debug)]
pub enum DebugEvent {
    // A AddTlc peer message processed with failure
    AddTlcFailed(PeerId, Hash256, TlcErr),
    // Common event with string
    Common(String),
}

#[macro_export]
macro_rules! debug_event {
    ($network:expr, $debug_event:expr) => {
        #[cfg(debug_assertions)]
        $network
            .send_message(NetworkActorMessage::new_notification(
                NetworkServiceEvent::DebugEvent(DebugEvent::Common($debug_event.to_string())),
            ))
            .expect(ASSUME_NETWORK_ACTOR_ALIVE);
    };
}

#[derive(Clone, Debug)]
pub enum NetworkServiceEvent {
    NetworkStarted(PeerId, MultiAddr, Vec<Multiaddr>),
    NetworkStopped(PeerId),
    PeerConnected(PeerId, Multiaddr),
    PeerDisConnected(PeerId, Multiaddr),
    // An incoming/outgoing channel is created.
    ChannelCreated(PeerId, Hash256),
    // A outgoing channel is pending to be accepted.
    ChannelPendingToBeAccepted(PeerId, Hash256),
    // A funding tx is completed. The watch tower may use this to monitor the channel.
    RemoteTxComplete(PeerId, Hash256, Script, SettlementData),
    // The channel is ready to use (with funding transaction confirmed
    // and both parties sent ChannelReady messages).
    ChannelReady(PeerId, Hash256, OutPoint),
    ChannelClosed(PeerId, Hash256, Byte32),
    // A RevokeAndAck is received from the peer. Other data relevant to this
    // RevokeAndAck message are also assembled here. The watch tower may use this.
    RevokeAndAckReceived(
        PeerId,  /* Peer Id */
        Hash256, /* Channel Id */
        RevocationData,
        SettlementData,
    ),
    // The other party has signed a valid commitment transaction,
    // and we successfully assemble the partial signature from other party
    // to create a complete commitment transaction and a settlement transaction.
    RemoteCommitmentSigned(PeerId, Hash256, TransactionView, SettlementData),
    // Some other debug event for assertion.
    #[cfg(debug_assertions)]
    DebugEvent(DebugEvent),
}

/// Events that can be sent to the network actor. Except for NetworkServiceEvent,
/// all events are processed by the network actor.
#[derive(Debug)]
pub enum NetworkActorEvent {
    /// Network events to be processed by this actor.
    PeerConnected(PeerId, Pubkey, SessionContext),
    PeerDisconnected(PeerId, SessionContext),
    FiberMessage(PeerId, FiberMessage),

    // Some gossip messages have been updated in the gossip message store.
    // Normally we need to propagate these messages to the network graph.
    GossipMessageUpdates(GossipMessageUpdates),
    // Mock that a gossip message is received, used for testing.
    #[cfg(test)]
    GossipMessage(PeerId, GossipMessage),

    /// Channel related events.

    /// A channel has been accepted.
    /// The two Hash256 are respectively newly agreed channel id and temp channel id,
    /// The two u128 are respectively local and remote funding amount,
    /// and the script is the lock script of the agreed funding cell.
    ChannelAccepted(
        PeerId,
        Hash256,
        Hash256,
        u128,
        u128,
        Script,
        Option<Script>,
        u64,
        u64,
        u64,
    ),
    /// A channel is ready to use.
    ChannelReady(Hash256, PeerId, OutPoint),
    /// A channel is already closed.
    ClosingTransactionPending(Hash256, PeerId, TransactionView),

    /// Both parties are now able to broadcast a valid funding transaction.
    FundingTransactionPending(Transaction, OutPoint, Hash256),

    /// A funding transaction has been confirmed. The transaction was included in the
    /// block with the given transaction index, and the timestamp in the block header.
    FundingTransactionConfirmed(OutPoint, H256, u32, u64),

    /// A funding transaction has failed.
    FundingTransactionFailed(OutPoint),

    /// Channel is going to be closed forcely, and the closing transaction is ready to be broadcasted.
    CommitmentTransactionPending(Transaction, Hash256),

    /// A commitment transaction is broacasted successfully.
    CommitmentTransactionConfirmed(Hash256, Hash256),

    /// A commitment transaction is failed to be broacasted.
    CommitmentTransactionFailed(Hash256, Byte32),

    /// A closing transaction has been confirmed.
    ClosingTransactionConfirmed(PeerId, Hash256, Byte32),

    /// A closing transaction has failed (either because of invalid transaction or timeout)
    ClosingTransactionFailed(PeerId, Hash256, Byte32),

    // A tlc remove message is received. (payment_hash, remove_tlc)
    TlcRemoveReceived(Hash256, RemoveTlcReason),

    // A payment need to retry
    RetrySendPayment(Hash256),

    // AddTlc result from peer (payment_hash, (process_channel_error, tlc_err), (previous_channel_id, previous_tlc_id))
    AddTlcResult(
        Hash256,
        Option<(ProcessingChannelError, TlcErr)>,
        Option<PrevTlcInfo>,
    ),

    // An owned channel is updated.
    OwnedChannelUpdateEvent(OwnedChannelUpdateEvent),
}

#[derive(Debug)]
pub enum NetworkActorMessage {
    Command(NetworkActorCommand),
    Event(NetworkActorEvent),
    Notification(NetworkServiceEvent),
}

#[derive(Debug)]
pub struct FiberMessageWithPeerId {
    pub peer_id: PeerId,
    pub message: FiberMessage,
}

impl FiberMessageWithPeerId {
    pub fn new(peer_id: PeerId, message: FiberMessage) -> Self {
        Self { peer_id, message }
    }
}

#[derive(Debug)]
pub struct GossipMessageWithPeerId {
    pub peer_id: PeerId,
    pub message: GossipMessage,
}

impl GossipMessageWithPeerId {
    pub fn new(peer_id: PeerId, message: GossipMessage) -> Self {
        Self { peer_id, message }
    }
}

pub struct NetworkActor<S> {
    // An event emitter to notify outside observers.
    event_sender: mpsc::Sender<NetworkServiceEvent>,
    chain_actor: ActorRef<CkbChainMessage>,
    store: S,
    network_graph: Arc<RwLock<NetworkGraph<S>>>,
}

impl<S> NetworkActor<S>
where
    S: NetworkActorStateStore
        + ChannelActorStateStore
        + NetworkGraphStateStore
        + GossipMessageStore
        + InvoiceStore
        + Clone
        + Send
        + Sync
        + 'static,
{
    pub fn new(
        event_sender: mpsc::Sender<NetworkServiceEvent>,
        chain_actor: ActorRef<CkbChainMessage>,
        store: S,
        network_graph: Arc<RwLock<NetworkGraph<S>>>,
    ) -> Self {
        Self {
            event_sender,
            chain_actor,
            store: store.clone(),
            network_graph,
        }
    }

    pub async fn handle_peer_message(
        &self,
        state: &mut NetworkActorState<S>,
        peer_id: PeerId,
        message: FiberMessage,
    ) -> crate::Result<()> {
        match message {
            // We should process OpenChannel message here because there is no channel corresponding
            // to the channel id in the message yet.
            FiberMessage::ChannelInitialization(open_channel) => {
                let temp_channel_id = open_channel.channel_id;
                match state
                    .on_open_channel_msg(peer_id, open_channel.clone())
                    .await
                {
                    Ok(()) => {
                        let auto_accept = if let Some(udt_type_script) =
                            open_channel.funding_udt_type_script.as_ref()
                        {
                            is_udt_type_auto_accept(udt_type_script, open_channel.funding_amount)
                        } else {
                            state.auto_accept_channel_ckb_funding_amount > 0
                                && open_channel.funding_amount
                                    >= state.open_channel_auto_accept_min_ckb_funding_amount as u128
                        };
                        if auto_accept {
                            let accept_channel = AcceptChannelCommand {
                                temp_channel_id,
                                funding_amount: if open_channel.funding_udt_type_script.is_some() {
                                    0
                                } else {
                                    state.auto_accept_channel_ckb_funding_amount as u128
                                },
                                shutdown_script: None,
                                max_tlc_number_in_flight: None,
                                max_tlc_value_in_flight: None,
                                min_tlc_value: None,
                                tlc_fee_proportional_millionths: None,
                                tlc_expiry_delta: None,
                            };
                            state.create_inbound_channel(accept_channel).await?;
                        }
                    }
                    Err(err) => {
                        error!("Failed to process OpenChannel message: {}", err);
                    }
                }
            }
            FiberMessage::ChannelNormalOperation(m) => {
                let channel_id = m.get_channel_id();
                state
                    .send_message_to_channel_actor(
                        channel_id,
                        Some(&peer_id),
                        ChannelActorMessage::PeerMessage(m),
                    )
                    .await;
            }
        };
        Ok(())
    }

    // We normally don't need to manually call this to update graph from store data,
    // because network actor will automatically update the graph when it receives
    // updates. But in some standalone tests, we may need to manually update the graph.
    async fn update_graph(&self) {
        let mut graph = self.network_graph.write().await;
        graph.load_from_store();
    }

    pub async fn handle_event(
        &self,
        myself: ActorRef<NetworkActorMessage>,
        state: &mut NetworkActorState<S>,
        event: NetworkActorEvent,
    ) -> crate::Result<()> {
        match event {
            NetworkActorEvent::PeerConnected(id, pubkey, session) => {
                state.on_peer_connected(&id, pubkey, &session).await;
                // Notify outside observers.
                myself
                    .send_message(NetworkActorMessage::new_notification(
                        NetworkServiceEvent::PeerConnected(id, session.address),
                    ))
                    .expect(ASSUME_NETWORK_MYSELF_ALIVE);
            }
            NetworkActorEvent::PeerDisconnected(id, session) => {
                state.on_peer_disconnected(&id);
                // Notify outside observers.
                myself
                    .send_message(NetworkActorMessage::new_notification(
                        NetworkServiceEvent::PeerDisConnected(id, session.address),
                    ))
                    .expect(ASSUME_NETWORK_MYSELF_ALIVE);
            }
            NetworkActorEvent::ChannelAccepted(
                peer_id,
                new,
                old,
                local,
                remote,
                script,
                udt_funding_script,
                local_reserved_ckb_amount,
                remote_reserved_ckb_amount,
                funding_fee_rate,
            ) => {
                assert_ne!(new, old, "new and old channel id must be different");
                if let Some(session) = state.get_peer_session(&peer_id) {
                    if let Some(channel) = state.channels.remove(&old) {
                        debug!("Channel accepted: {:?} -> {:?}", old, new);
                        state.channels.insert(new, channel);
                        if let Some(set) = state.session_channels_map.get_mut(&session) {
                            set.remove(&old);
                            set.insert(new);
                        };

                        debug!("Starting funding channel");
                        // TODO: Here we implies the one who receives AcceptChannel message
                        //  (i.e. the channel initiator) will send TxUpdate message first.
                        myself
                            .send_message(NetworkActorMessage::new_command(
                                NetworkActorCommand::UpdateChannelFunding(
                                    new,
                                    Default::default(),
                                    FundingRequest {
                                        script,
                                        udt_type_script: udt_funding_script,
                                        local_amount: local,
                                        funding_fee_rate,
                                        remote_amount: remote,
                                        local_reserved_ckb_amount,
                                        remote_reserved_ckb_amount,
                                    },
                                ),
                            ))
                            .expect(ASSUME_NETWORK_MYSELF_ALIVE);
                    }
                }
            }
            NetworkActorEvent::ChannelReady(channel_id, peer_id, channel_outpoint) => {
                info!(
                    "Channel ({:?}) to peer {:?} is now ready",
                    channel_id, peer_id
                );

                // FIXME(yukang): need to make sure ChannelReady is sent after the channel is reestablished
                state
                    .outpoint_channel_map
                    .insert(channel_outpoint.clone(), channel_id);

                // Notify outside observers.
                myself
                    .send_message(NetworkActorMessage::new_notification(
                        NetworkServiceEvent::ChannelReady(peer_id, channel_id, channel_outpoint),
                    ))
                    .expect(ASSUME_NETWORK_MYSELF_ALIVE);
            }
            NetworkActorEvent::FiberMessage(peer_id, message) => {
                self.handle_peer_message(state, peer_id, message).await?
            }
            NetworkActorEvent::FundingTransactionPending(transaction, outpoint, channel_id) => {
                state
                    .on_funding_transaction_pending(transaction, outpoint.clone(), channel_id)
                    .await;
            }
            NetworkActorEvent::FundingTransactionConfirmed(
                outpoint,
                block_hash,
                tx_index,
                timestamp,
            ) => {
                state
                    .on_funding_transaction_confirmed(outpoint, block_hash, tx_index, timestamp)
                    .await;
            }
            NetworkActorEvent::CommitmentTransactionPending(transaction, channel_id) => {
                state
                    .on_commitment_transaction_pending(transaction, channel_id)
                    .await;
            }
            NetworkActorEvent::CommitmentTransactionConfirmed(tx_hash, channel_id) => {
                state
                    .on_commitment_transaction_confirmed(tx_hash, channel_id)
                    .await;
            }
            NetworkActorEvent::CommitmentTransactionFailed(tx_hash, channel_id) => {
                error!(
                    "Commitment transaction failed for channel {:?}, tx hash: {:?}",
                    channel_id, tx_hash
                );
            }
            NetworkActorEvent::FundingTransactionFailed(outpoint) => {
                error!("Funding transaction failed: {:?}", outpoint);
            }
            NetworkActorEvent::ClosingTransactionPending(channel_id, peer_id, tx) => {
                state
                    .on_closing_transaction_pending(channel_id, peer_id.clone(), tx.clone())
                    .await;
            }
            NetworkActorEvent::ClosingTransactionConfirmed(peer_id, channel_id, tx_hash) => {
                state
                    .on_closing_transaction_confirmed(&peer_id, &channel_id, tx_hash)
                    .await;
            }
            NetworkActorEvent::ClosingTransactionFailed(peer_id, tx_hash, channel_id) => {
                error!(
                    "Closing transaction failed for channel {:?}, tx hash: {:?}, peer id: {:?}",
                    &channel_id, &tx_hash, &peer_id
                );
            }
            NetworkActorEvent::TlcRemoveReceived(payment_hash, remove_tlc_reason) => {
                // When a node is restarted, RemoveTLC will also be resent if necessary
                self.on_remove_tlc_event(myself, state, payment_hash, remove_tlc_reason)
                    .await;
            }
            NetworkActorEvent::RetrySendPayment(payment_hash) => {
                let _ = self.try_payment_session(myself, state, payment_hash).await;
            }
            NetworkActorEvent::AddTlcResult(payment_hash, error_info, previous_tlc) => {
                self.on_add_tlc_result_event(myself, state, payment_hash, error_info, previous_tlc)
                    .await;
            }
            #[cfg(test)]
            NetworkActorEvent::GossipMessage(peer_id, message) => {
                let _ = state
                    .gossip_actor
                    .send_message(GossipActorMessage::GossipMessageReceived(
                        GossipMessageWithPeerId { peer_id, message },
                    ));
            }
            NetworkActorEvent::GossipMessageUpdates(gossip_message_updates) => {
                let mut graph = self.network_graph.write().await;
                graph.update_for_messages(gossip_message_updates.messages);
            }
            NetworkActorEvent::OwnedChannelUpdateEvent(owned_channel_update_event) => {
                let mut graph = self.network_graph.write().await;
                debug!(
                    "Received owned channel update event: {:?}",
                    owned_channel_update_event
                );
                let is_down =
                    matches!(owned_channel_update_event, OwnedChannelUpdateEvent::Down(_));
                graph.process_owned_channel_update_event(owned_channel_update_event);
                if is_down {
                    debug!("Owned channel is down");
                }
            }
        }
        Ok(())
    }

    pub async fn handle_command(
        &self,
        myself: ActorRef<NetworkActorMessage>,
        state: &mut NetworkActorState<S>,
        command: NetworkActorCommand,
    ) -> crate::Result<()> {
        match command {
            NetworkActorCommand::SendFiberMessage(FiberMessageWithPeerId { peer_id, message }) => {
                state.send_fiber_message_to_peer(&peer_id, message).await?;
            }

            NetworkActorCommand::ConnectPeer(addr) => {
                // TODO: It is more than just dialing a peer. We need to exchange capabilities of the peer,
                // e.g. whether the peer support some specific feature.

                if let Some(peer_id) = extract_peer_id(&addr) {
                    if state.is_connected(&peer_id) {
                        debug!("Peer {:?} already connected, ignoring...", peer_id);
                        return Ok(());
                    }
                    if state.peer_id == peer_id {
                        debug!("Trying to connect to self {:?}, ignoring...", addr);
                        return Ok(());
                    }
                } else {
                    error!("Failed to extract peer id from address: {:?}", addr);
                    return Ok(());
                }

                state
                    .control
                    .dial(addr.clone(), TargetProtocol::All)
                    .await?
                // TODO: note that the dial function does not return error immediately even if dial fails.
                // Tentacle sends an event by calling handle_error function instead, which
                // may receive errors like DialerError.
            }

            NetworkActorCommand::DisconnectPeer(peer_id) => {
                if let Some(session) = state.get_peer_session(&peer_id) {
                    state.control.disconnect(session).await?;
                }
            }

            NetworkActorCommand::SavePeerAddress(addr) => match extract_peer_id(&addr) {
                Some(peer) => {
                    debug!("Saved peer id {:?} with address {:?}", &peer, &addr);
                    state.save_peer_address(peer, addr);
                }
                None => {
                    error!("Failed to save address to peer store: unable to extract peer id from address {:?}", &addr);
                }
            },

            NetworkActorCommand::MaintainConnections => {
                let mut inbound_peer_sessions = state.inbound_peer_sessions();
                let num_inbound_peers = inbound_peer_sessions.len();
                let num_outbound_peers = state.num_of_outbound_peers();

                debug!("Maintaining network connections ticked: current num inbound peers {}, current num outbound peers {}", num_inbound_peers, num_outbound_peers);

                if num_inbound_peers > state.max_inbound_peers {
                    debug!(
                        "Already connected to {} inbound peers, only wants {} peers, disconnecting some",
                        num_inbound_peers, state.max_inbound_peers
                    );
                    inbound_peer_sessions.retain(|k| !state.session_channels_map.contains_key(k));
                    let sessions_to_disconnect = if inbound_peer_sessions.len()
                        < num_inbound_peers - state.max_inbound_peers
                    {
                        warn!(
                            "Wants to disconnect more {} inbound peers, but all peers except {:?} have channels, will not disconnect any peer with channels",
                            num_inbound_peers - state.max_inbound_peers, &inbound_peer_sessions
                        );
                        &inbound_peer_sessions[..]
                    } else {
                        &inbound_peer_sessions[..num_inbound_peers - state.max_inbound_peers]
                    };
                    debug!(
                        "Disconnecting inbound peer sessions {:?}",
                        sessions_to_disconnect
                    );
                    for session in sessions_to_disconnect {
                        if let Err(err) = state.control.disconnect(*session).await {
                            error!("Failed to disconnect session: {}", err);
                        }
                    }
                }

                if num_outbound_peers >= state.min_outbound_peers {
                    debug!(
                        "Already connected to {} outbound peers, wants a minimal of {} peers, skipping connecting to more peers",
                        num_outbound_peers, state.min_outbound_peers
                    );
                    return Ok(());
                }

                let peers_to_connect = {
                    let graph = self.network_graph.read().await;
                    let n_peers_to_connect = state.min_outbound_peers - num_outbound_peers;
                    let n_graph_nodes = graph.num_of_nodes();
                    let n_saved_peers = state.state_to_be_persisted.num_of_saved_nodes();
                    let n_all_saved_peers = n_graph_nodes + n_saved_peers;
                    if n_all_saved_peers == 0 {
                        return Ok(());
                    }
                    let n_saved_peers_to_connect =
                        n_peers_to_connect * n_saved_peers / n_all_saved_peers;
                    let n_graph_nodes_to_connect = n_peers_to_connect - n_saved_peers_to_connect;

                    let saved_peers_to_connect = state
                        .state_to_be_persisted
                        .sample_n_peers_to_connect(n_saved_peers_to_connect);
                    trace!(
                        "Randomly selected peers from saved addresses to connect: {:?}",
                        &saved_peers_to_connect
                    );
                    let graph_nodes_to_connect =
                        graph.sample_n_peers_to_connect(n_graph_nodes_to_connect);
                    trace!(
                        "Randomly selected peers from network graph to connect: {:?}",
                        &graph_nodes_to_connect
                    );
                    saved_peers_to_connect
                        .into_iter()
                        .chain(graph_nodes_to_connect.into_iter())
                };
                for (peer_id, addresses) in peers_to_connect {
                    if let Some(session) = state.get_peer_session(&peer_id) {
                        debug!(
                            "Randomly selected peer {:?} already connected with session id {:?}, skipping connection",
                            peer_id, session
                        );
                        continue;
                    }
                    for addr in addresses {
                        state
                            .network
                            .send_message(NetworkActorMessage::new_command(
                                NetworkActorCommand::ConnectPeer(addr.clone()),
                            ))
                            .expect(ASSUME_NETWORK_MYSELF_ALIVE);
                    }
                }
            }

            NetworkActorCommand::OpenChannel(open_channel, reply) => {
                match state.create_outbound_channel(open_channel).await {
                    Ok((_, channel_id)) => {
                        let _ = reply.send(Ok(OpenChannelResponse { channel_id }));
                    }
                    Err(err) => {
                        error!("Failed to create channel: {}", err);
                        let _ = reply.send(Err(err.to_string()));
                    }
                }
            }
            NetworkActorCommand::AcceptChannel(accept_channel, reply) => {
                match state.create_inbound_channel(accept_channel).await {
                    Ok((_, old_channel_id, new_channel_id)) => {
                        let _ = reply.send(Ok(AcceptChannelResponse {
                            old_channel_id,
                            new_channel_id,
                        }));
                    }
                    Err(err) => {
                        error!("Failed to accept channel: {}", err);
                        let _ = reply.send(Err(err.to_string()));
                    }
                }
            }

            NetworkActorCommand::ControlFiberChannel(c) => {
                state
                    .send_command_to_channel(c.channel_id, c.command)
                    .await?
            }

            NetworkActorCommand::SendPaymentOnionPacket(command) => {
                let res = self
                    .handle_send_onion_packet_command(state, command.clone())
                    .await;
                if let Err(err) = res {
                    self.on_add_tlc_result_event(
                        myself,
                        state,
                        command.payment_hash,
                        Some((ProcessingChannelError::TlcForwardingError(err.clone()), err)),
                        command.previous_tlc,
                    )
                    .await;
                }
            }
            NetworkActorCommand::PeelPaymentOnionPacket(onion_packet, payment_hash, reply) => {
                let response = onion_packet
                    .peel(
                        &state.private_key,
                        Some(payment_hash.as_ref()),
                        &Secp256k1::new(),
                    )
                    .map_err(|err| err.to_string());

                let _ = reply.send(response);
            }

            NetworkActorCommand::UpdateChannelFunding(channel_id, transaction, request) => {
                let old_tx = transaction.into_view();
                let mut tx = FundingTx::new();
                tx.update_for_self(old_tx)?;
                let tx = match call_t!(
                    self.chain_actor.clone(),
                    CkbChainMessage::Fund,
                    DEFAULT_CHAIN_ACTOR_TIMEOUT,
                    tx,
                    request
                ) {
                    Ok(Ok(tx)) => match tx.into_inner() {
                        Some(tx) => tx,
                        _ => {
                            error!("Obtained empty funding tx");
                            return Ok(());
                        }
                    },
                    Ok(Err(err)) => {
                        // FIXME(yukang): we need to handle this error properly
                        error!("Failed to fund channel: {}", err);
                        return Ok(());
                    }
                    Err(err) => {
                        error!("Failed to call chain actor: {}", err);
                        return Ok(());
                    }
                };
                debug!("Funding transaction updated on our part: {:?}", tx);
                state
                    .send_command_to_channel(
                        channel_id,
                        ChannelCommand::TxCollaborationCommand(TxCollaborationCommand::TxUpdate(
                            TxUpdateCommand {
                                transaction: tx.data(),
                            },
                        )),
                    )
                    .await?
            }
            NetworkActorCommand::SignTx(
                ref peer_id,
                ref channel_id,
                funding_tx,
                partial_witnesses,
            ) => {
                let msg = match partial_witnesses {
                    Some(partial_witnesses) => {
                        debug!(
                            "Received SignTx request with for transaction {:?} and partial witnesses {:?}",
                            &funding_tx,
                            partial_witnesses
                                .iter()
                                .map(hex::encode)
                                .collect::<Vec<_>>()
                        );
                        let funding_tx = funding_tx
                            .into_view()
                            .as_advanced_builder()
                            .set_witnesses(
                                partial_witnesses.into_iter().map(|x| x.pack()).collect(),
                            )
                            .build();

                        let mut funding_tx = call_t!(
                            self.chain_actor,
                            CkbChainMessage::Sign,
                            DEFAULT_CHAIN_ACTOR_TIMEOUT,
                            funding_tx.into()
                        )
                        .expect(ASSUME_CHAIN_ACTOR_ALWAYS_ALIVE_FOR_NOW)
                        .expect("Signing succeeded");
                        debug!("Funding transaction signed: {:?}", &funding_tx);

                        // Since we have received a valid tx_signatures message, we're now sure that
                        // we can broadcast a valid transaction to the network, i.e. we can wait for
                        // the funding transaction to be confirmed.
                        let funding_tx = funding_tx.take().expect("take tx");
                        let witnesses = funding_tx.witnesses();
                        let outpoint = funding_tx
                            .output_pts_iter()
                            .next()
                            .expect("funding tx output exists");

                        myself
                            .send_message(NetworkActorMessage::new_event(
                                NetworkActorEvent::FundingTransactionPending(
                                    funding_tx.data(),
                                    outpoint,
                                    *channel_id,
                                ),
                            ))
                            .expect("network actor alive");
                        debug!("Fully signed funding tx {:?}", &funding_tx);

                        FiberMessageWithPeerId {
                            peer_id: peer_id.clone(),
                            message: FiberMessage::ChannelNormalOperation(
                                FiberChannelMessage::TxSignatures(TxSignatures {
                                    channel_id: *channel_id,
                                    witnesses: witnesses.into_iter().map(|x| x.unpack()).collect(),
                                }),
                            ),
                        }
                    }
                    None => {
                        debug!(
                            "Received SignTx request with for transaction {:?} without partial witnesses, so start signing it now",
                            &funding_tx,
                        );
                        let mut funding_tx = call_t!(
                            self.chain_actor,
                            CkbChainMessage::Sign,
                            DEFAULT_CHAIN_ACTOR_TIMEOUT,
                            funding_tx.into()
                        )
                        .expect(ASSUME_CHAIN_ACTOR_ALWAYS_ALIVE_FOR_NOW)?;
                        debug!("Funding transaction signed: {:?}", &funding_tx);
                        let funding_tx = funding_tx.take().expect("take tx");
                        let witnesses = funding_tx.witnesses();

                        debug!("Partially signed funding tx {:?}", &funding_tx);
                        FiberMessageWithPeerId {
                            peer_id: peer_id.clone(),
                            message: FiberMessage::ChannelNormalOperation(
                                FiberChannelMessage::TxSignatures(TxSignatures {
                                    channel_id: *channel_id,
                                    witnesses: witnesses.into_iter().map(|x| x.unpack()).collect(),
                                }),
                            ),
                        }
                    }
                };
                myself
                    .send_message(NetworkActorMessage::new_command(
                        NetworkActorCommand::SendFiberMessage(msg),
                    ))
                    .expect("network actor alive");
            }
            NetworkActorCommand::ProcessBroadcastMessage(message) => {
                let _ = state
                    .gossip_actor
                    .send_message(GossipActorMessage::ProcessBroadcastMessage(message));
            }
            NetworkActorCommand::QueryBroadcastMessages(peer, queries) => {
                let _ = state
                    .gossip_actor
                    .send_message(GossipActorMessage::QueryBroadcastMessages(peer, queries));
            }
            NetworkActorCommand::BroadcastMessages(message) => {
                let _ = state
                    .gossip_actor
                    .send_message(GossipActorMessage::TryBroadcastMessages(message));
            }
            NetworkActorCommand::SignMessage(message, reply) => {
                debug!(
                    "Signing message with node private key: message {:?}, public key {:?}",
                    message,
                    state.get_public_key()
                );
                let signature = state.private_key.sign(message);
                let _ = reply.send(signature);
            }
            NetworkActorCommand::SendPayment(payment_request, reply) => {
                match self.on_send_payment(myself, state, payment_request).await {
                    Ok(payment) => {
                        let _ = reply.send(Ok(payment));
                    }
                    Err(e) => {
                        error!("Failed to send payment: {:?}", e);
                        let _ = reply.send(Err(e.to_string()));
                    }
                }
            }
            NetworkActorCommand::GetPayment(payment_hash, reply) => {
                match self.on_get_payment(&payment_hash) {
                    Ok(payment) => {
                        let _ = reply.send(Ok(payment));
                    }
                    Err(e) => {
                        let _ = reply.send(Err(e.to_string()));
                    }
                }
            }
            NetworkActorCommand::BroadcastLocalInfo(kind) => match kind {
                LocalInfoKind::NodeAnnouncement => {
                    let message = state.get_or_create_new_node_announcement_message();
                    myself
                        .send_message(NetworkActorMessage::new_command(
                            NetworkActorCommand::BroadcastMessages(vec![
                                BroadcastMessageWithTimestamp::NodeAnnouncement(message),
                            ]),
                        ))
                        .expect(ASSUME_NETWORK_MYSELF_ALIVE);
                }
            },
            NetworkActorCommand::GossipActorMessage(message) => {
                let _ = state.gossip_actor.send_message(message);
            }
            NetworkActorCommand::NodeInfo(_, rpc) => {
                let response = NodeInfoResponse {
                    node_name: state.node_name,
                    node_id: state.get_public_key(),
                    addresses: state.announced_addrs.clone(),
                    chain_hash: get_chain_hash(),
                    open_channel_auto_accept_min_ckb_funding_amount: state
                        .open_channel_auto_accept_min_ckb_funding_amount,
                    auto_accept_channel_ckb_funding_amount: state
                        .auto_accept_channel_ckb_funding_amount,
                    tlc_expiry_delta: state.tlc_expiry_delta,
                    tlc_min_value: state.tlc_min_value,
                    tlc_max_value: state.tlc_max_value,
                    tlc_fee_proportional_millionths: state.tlc_fee_proportional_millionths,
                    channel_count: state.channels.len() as u32,
                    pending_channel_count: state.pending_channels.len() as u32,
                    peers_count: state.peer_session_map.len() as u32,
                    udt_cfg_infos: get_udt_whitelist(),
                };
                let _ = rpc.send(Ok(response));
            }
        };
        Ok(())
    }

    async fn handle_send_onion_packet_command(
        &self,
        state: &mut NetworkActorState<S>,
        command: SendOnionPacketCommand,
    ) -> Result<(), TlcErr> {
        let SendOnionPacketCommand {
            peeled_onion_packet,
            previous_tlc,
            payment_hash,
        } = command;

        let info = peeled_onion_packet.current.clone();
        let shared_secret = peeled_onion_packet.shared_secret;
        let channel_outpoint = OutPoint::new(info.funding_tx_hash.into(), 0);
        let channel_id = match state.outpoint_channel_map.get(&channel_outpoint) {
            Some(channel_id) => channel_id,
            None => {
                error!(
                        "Channel id not found in outpoint_channel_map with {:?}, are we connected to the peer?",
                        channel_outpoint
                    );
                let tlc_err = TlcErr::new_channel_fail(
                    TlcErrorCode::UnknownNextPeer,
                    state.get_public_key(),
                    channel_outpoint.clone(),
                    None,
                );
                return Err(tlc_err);
            }
        };
        let (send, _recv) = oneshot::channel::<Result<AddTlcResponse, TlcErr>>();
        // explicitly don't wait for the response, we will handle the result in AddTlcResult
        let rpc_reply = RpcReplyPort::from(send);
        let command = ChannelCommand::AddTlc(
            AddTlcCommand {
                amount: info.amount,
                payment_hash,
                expiry: info.expiry,
                hash_algorithm: info.hash_algorithm,
                onion_packet: peeled_onion_packet.next.clone(),
                shared_secret,
                previous_tlc,
            },
            rpc_reply,
        );

        // we have already checked the channel_id is valid,
        match state.send_command_to_channel(*channel_id, command).await {
            Ok(_) => {
                return Ok(());
            }
            Err(err) => {
                error!(
                    "Failed to send onion packet to channel: {:?} with err: {:?}",
                    channel_id, err
                );
                let tlc_error = self.get_tlc_error(state, &err, &channel_outpoint);
                return Err(tlc_error);
            }
        }
    }

    fn get_tlc_error(
        &self,
        state: &mut NetworkActorState<S>,
        error: &Error,
        channel_outpoint: &OutPoint,
    ) -> TlcErr {
        let node_id = state.get_public_key();
        match error {
            Error::ChannelNotFound(_) | Error::PeerNotFound(_) => TlcErr::new_channel_fail(
                TlcErrorCode::UnknownNextPeer,
                node_id,
                channel_outpoint.clone(),
                None,
            ),
            Error::ChannelError(_) => TlcErr::new_channel_fail(
                TlcErrorCode::TemporaryChannelFailure,
                node_id,
                channel_outpoint.clone(),
                None,
            ),
            _ => {
                error!(
                    "Failed to send onion packet to channel: {:?} with err: {:?}",
                    channel_outpoint, error
                );
                TlcErr::new_node_fail(TlcErrorCode::TemporaryNodeFailure, state.get_public_key())
            }
        }
    }

    async fn on_remove_tlc_event(
        &self,
        myself: ActorRef<NetworkActorMessage>,
        state: &mut NetworkActorState<S>,
        payment_hash: Hash256,
        reason: RemoveTlcReason,
    ) {
        if let Some(mut payment_session) = self.store.get_payment_session(payment_hash) {
            if payment_session.status == PaymentSessionStatus::Inflight {
                match reason {
                    RemoveTlcReason::RemoveTlcFulfill(_) => {
                        self.network_graph
                            .write()
                            .await
                            .record_payment_success(payment_session);
                    }
                    RemoveTlcReason::RemoveTlcFail(reason) => {
                        let error_detail = reason
                            .decode(
                                &payment_session.session_key,
                                payment_session.hops_public_keys(),
                            )
                            .unwrap_or_else(|| {
                                debug_event!(myself, "InvalidOnionError");
                                TlcErr::new(TlcErrorCode::InvalidOnionError)
                            });

                        self.update_graph_with_tlc_fail(&state.network, &error_detail)
                            .await;
                        let need_to_retry = self
                            .network_graph
                            .write()
                            .await
                            .record_payment_fail(&payment_session, error_detail.clone());
                        if need_to_retry {
                            // If this is the first hop error, like the WaitingTlcAck error,
                            // we will just retry later, return Ok here for letting endpoint user
                            // know payment session is created successfully
                            self.register_payment_retry(myself, payment_hash);
                        } else {
                            self.set_payment_fail_with_error(
                                &mut payment_session,
                                error_detail.error_code.as_ref(),
                            );
                        }
                    }
                }
            }
        }
    }

    async fn update_graph_with_tlc_fail(
        &self,
        network: &ActorRef<NetworkActorMessage>,
        tcl_error_detail: &TlcErr,
    ) {
        let error_code = tcl_error_detail.error_code();
        // https://github.com/lightning/bolts/blob/master/04-onion-routing.md#rationale-6
        // we now still update the graph, maybe we need to remove it later?
        if error_code.is_update() {
            if let Some(TlcErrData::ChannelFailed {
                channel_update: Some(channel_update),
                ..
            }) = &tcl_error_detail.extra_data
            {
                network
                    .send_message(NetworkActorMessage::new_command(
                        NetworkActorCommand::BroadcastMessages(vec![
                            BroadcastMessageWithTimestamp::ChannelUpdate(channel_update.clone()),
                        ]),
                    ))
                    .expect(ASSUME_NETWORK_MYSELF_ALIVE);
            }
        }
        match tcl_error_detail.error_code() {
            TlcErrorCode::PermanentChannelFailure
            | TlcErrorCode::ChannelDisabled
            | TlcErrorCode::UnknownNextPeer => {
                let channel_outpoint = tcl_error_detail
                    .error_channel_outpoint()
                    .expect("expect channel outpoint");
                debug!("mark channel failed: {:?}", channel_outpoint);
                let mut graph = self.network_graph.write().await;
                graph.mark_channel_failed(&channel_outpoint);
            }
            TlcErrorCode::PermanentNodeFailure => {
                let node_id = tcl_error_detail.error_node_id().expect("expect node id");
                let mut graph = self.network_graph.write().await;
                graph.mark_node_failed(node_id);
            }
            _ => {}
        }
    }

    fn on_get_payment(&self, payment_hash: &Hash256) -> Result<SendPaymentResponse, Error> {
        match self.store.get_payment_session(*payment_hash) {
            Some(payment_session) => Ok(payment_session.into()),
            None => Err(Error::InvalidParameter(format!(
                "Payment session not found: {:?}",
                payment_hash
            ))),
        }
    }

    async fn build_payment_route(
        &self,
        payment_session: &mut PaymentSession,
        payment_data: &SendPaymentData,
    ) -> Result<Vec<PaymentHopData>, Error> {
        let graph = self.network_graph.read().await;
        match graph.build_route(payment_data.clone()) {
            Err(e) => {
                let error = format!("Failed to build route, {}", e);
                self.set_payment_fail_with_error(payment_session, &error);
                return Err(Error::SendPaymentError(error));
            }
            Ok(hops) => {
                assert_ne!(hops[0].funding_tx_hash, Hash256::default());
                return Ok(hops);
            }
        };
    }

    async fn send_payment_onion_packet(
        &self,
        state: &mut NetworkActorState<S>,
        payment_session: &mut PaymentSession,
        payment_data: &SendPaymentData,
        hops: Vec<PaymentHopData>,
    ) -> Result<PaymentSession, Error> {
        let session_key = Privkey::from_slice(KeyPair::generate_random_key().as_ref());
        assert_ne!(hops[0].funding_tx_hash, Hash256::default());

        payment_session
            .session_key
            .copy_from_slice(session_key.as_ref());
        payment_session.route =
            SessionRoute::new(state.get_public_key(), payment_data.target_pubkey, &hops);

        let peeled_onion_packet = match PeeledPaymentOnionPacket::create(
            session_key,
            hops,
            Some(payment_data.payment_hash.as_ref().to_vec()),
            &Secp256k1::signing_only(),
        ) {
            Ok(packet) => packet,
            Err(e) => {
                let err = format!(
                    "Failed to create onion packet: {:?}, error: {:?}",
                    payment_data.payment_hash, e
                );
                self.set_payment_fail_with_error(payment_session, &err);
                return Err(Error::SendPaymentFirstHopError(err, false));
            }
        };

        match self
            .handle_send_onion_packet_command(
                state,
                SendOnionPacketCommand {
                    peeled_onion_packet,
                    previous_tlc: None,
                    payment_hash: payment_data.payment_hash,
                },
            )
            .await
        {
            Err(error_detail) => {
                self.update_graph_with_tlc_fail(&state.network, &error_detail)
                    .await;
                let need_to_retry = self
                    .network_graph
                    .write()
                    .await
                    .record_payment_fail(payment_session, error_detail.clone());
                let err = format!(
                    "Failed to send onion packet with error {}",
                    error_detail.error_code_as_str()
                );
                if !need_to_retry {
                    // only update the payment session status when we don't need to retry
                    // otherwise the endpoint user may get confused in the internal state changes
                    self.set_payment_fail_with_error(payment_session, &err);
                }
                return Err(Error::SendPaymentFirstHopError(err, need_to_retry));
            }
            Ok(_) => {
                self.store.insert_payment_session(payment_session.clone());
                return Ok(payment_session.clone());
            }
        }
    }

    async fn on_add_tlc_result_event(
        &self,
        myself: ActorRef<NetworkActorMessage>,
        state: &mut NetworkActorState<S>,
        payment_hash: Hash256,
        error_info: Option<(ProcessingChannelError, TlcErr)>,
        previous_tlc: Option<PrevTlcInfo>,
    ) {
        if let Some(PrevTlcInfo {
            prev_channel_id: channel_id,
            prev_tlc_id: tlc_id,
            ..
        }) = previous_tlc
        {
            myself
                .send_message(NetworkActorMessage::new_command(
                    NetworkActorCommand::ControlFiberChannel(ChannelCommandWithId {
                        channel_id,
                        command: ChannelCommand::ForwardTlcResult(ForwardTlcResult {
                            payment_hash,
                            channel_id,
                            tlc_id,
                            error_info: error_info.clone(),
                        }),
                    }),
                ))
                .expect("network actor alive");
            return;
        }

        let Some(mut payment_session) = self.store.get_payment_session(payment_hash) else {
            return;
        };

        if error_info.is_none() {
            // Change the status from Created into Inflight
            payment_session.set_inflight_status();
            self.store.insert_payment_session(payment_session.clone());
            return;
        }

        let (channel_error, tlc_err) = error_info.unwrap();
        if matches!(channel_error, ProcessingChannelError::RepeatedProcessing(_)) {
            return;
        }

        let need_to_retry = if matches!(channel_error, ProcessingChannelError::WaitingTlcAck) {
            payment_session.last_error = Some("WaitingTlcAck".to_string());
            self.store.insert_payment_session(payment_session.clone());
            true
        } else {
            self.network_graph
                .write()
                .await
                .record_payment_fail(&payment_session, tlc_err.clone())
        };
        if need_to_retry {
            let _ = self.try_payment_session(myself, state, payment_hash).await;
        } else {
            let error = format!(
                "Failed to send payment session: {:?}, retried times: {}",
                payment_session.payment_hash(),
                payment_session.retried_times
            );
            self.set_payment_fail_with_error(&mut payment_session, &error);
        }
    }

    fn set_payment_fail_with_error(&self, payment_session: &mut PaymentSession, error: &str) {
        payment_session.set_failed_status(error);
        self.store.insert_payment_session(payment_session.clone());
    }

    async fn try_payment_session(
        &self,
        myself: ActorRef<NetworkActorMessage>,
        state: &mut NetworkActorState<S>,
        payment_hash: Hash256,
    ) -> Result<PaymentSession, Error> {
        self.update_graph().await;
        let Some(mut payment_session) = self.store.get_payment_session(payment_hash) else {
            return Err(Error::InvalidParameter(payment_hash.to_string()));
        };

        assert!(payment_session.status != PaymentSessionStatus::Failed);

        debug!(
            "try_payment_session: {:?} times: {:?}",
            payment_session.payment_hash(),
            payment_session.retried_times
        );

        let payment_data = payment_session.request.clone();
        if payment_session.can_retry() {
            if payment_session.last_error != Some("WaitingTlcAck".to_string()) {
                payment_session.retried_times += 1;
            }

            let hops_info = self
                .build_payment_route(&mut payment_session, &payment_data)
                .await?;

            match self
                .send_payment_onion_packet(state, &mut payment_session, &payment_data, hops_info)
                .await
            {
                Ok(payment_session) => return Ok(payment_session),
                Err(err) => {
                    let need_retry = matches!(err, Error::SendPaymentFirstHopError(_, true));
                    if need_retry {
                        // If this is the first hop error, such as the WaitingTlcAck error,
                        // we will just retry later, return Ok here for letting endpoint user
                        // know payment session is created successfully
                        self.register_payment_retry(myself, payment_hash);
                        return Ok(payment_session);
                    } else {
                        return Err(err);
                    }
                }
            }
        } else {
            let error = payment_session.last_error.clone().unwrap_or_else(|| {
                format!(
                    "Failed to send payment session: {:?}, retried times: {}",
                    payment_data.payment_hash, payment_session.retried_times
                )
            });
            return Err(Error::SendPaymentError(error));
        }
    }

    fn register_payment_retry(&self, myself: ActorRef<NetworkActorMessage>, payment_hash: Hash256) {
        myself.send_after(Duration::from_millis(500), move || {
            NetworkActorMessage::new_event(NetworkActorEvent::RetrySendPayment(payment_hash))
        });
    }

    async fn on_send_payment(
        &self,
        myself: ActorRef<NetworkActorMessage>,
        state: &mut NetworkActorState<S>,
        payment_request: SendPaymentCommand,
    ) -> Result<SendPaymentResponse, Error> {
        let payment_data = SendPaymentData::new(payment_request.clone()).map_err(|e| {
            error!("Failed to validate payment request: {:?}", e);
            Error::InvalidParameter(format!("Failed to validate payment request: {:?}", e))
        })?;

        // for dry run, we only build the route and return the hops info,
        // will not store the payment session and send the onion packet
        if payment_data.dry_run {
            let mut payment_session = PaymentSession::new(payment_data.clone(), 0);
            let hops = self
                .build_payment_route(&mut payment_session, &payment_data)
                .await?;
            payment_session.route =
                SessionRoute::new(state.get_public_key(), payment_data.target_pubkey, &hops);
            return Ok(payment_session.into());
        }

        // initialize the payment session in db and begin the payment process lifecycle
        if let Some(payment_session) = self.store.get_payment_session(payment_data.payment_hash) {
            // we only allow retrying payment session with status failed
            debug!("Payment session already exists: {:?}", payment_session);
            if payment_session.status != PaymentSessionStatus::Failed {
                return Err(Error::InvalidParameter(format!(
                    "Payment session already exists: {} with payment session status: {:?}",
                    payment_data.payment_hash, payment_session.status
                )));
            }
        }

        let payment_session = PaymentSession::new(payment_data, 5);
        self.store.insert_payment_session(payment_session.clone());
        let session = self
            .try_payment_session(myself, state, payment_session.payment_hash())
            .await?;
        return Ok(session.into());
    }
}

pub struct NetworkActorState<S> {
    store: S,
    state_to_be_persisted: PersistentNetworkActorState,
    // The name of the node to be announced to the network, may be empty.
    node_name: Option<AnnouncedNodeName>,
    peer_id: PeerId,
    announced_addrs: Vec<Multiaddr>,
    auto_announce: bool,
    last_node_announcement_message: Option<NodeAnnouncement>,
    // We need to keep private key here in order to sign node announcement messages.
    private_key: Privkey,
    // This is the entropy used to generate various random values.
    // Must be kept secret.
    // TODO: Maybe we should abstract this into a separate trait.
    entropy: [u8; 32],
    // The default lock script to be used when closing a channel, may be overridden by the shutdown command.
    default_shutdown_script: Script,
    network: ActorRef<NetworkActorMessage>,
    // This immutable attribute is placed here because we need to create it in
    // the pre_start function.
    control: ServiceAsyncControl,
    peer_session_map: HashMap<PeerId, (SessionId, SessionType)>,
    session_channels_map: HashMap<SessionId, HashSet<Hash256>>,
    channels: HashMap<Hash256, ActorRef<ChannelActorMessage>>,
    // Outpoint to channel id mapping, only contains channels with state of Ready.
    // We need to remove the channel from this map when the channel is closed or peer disconnected.
    outpoint_channel_map: HashMap<OutPoint, Hash256>,
    // Channels in this hashmap are pending for acceptance. The user needs to
    // issue an AcceptChannelCommand with the amount of funding to accept the channel.
    to_be_accepted_channels: HashMap<Hash256, (PeerId, OpenChannel)>,
    // Channels in this hashmap are pending for funding transaction confirmation.
    pending_channels: HashMap<OutPoint, Hash256>,
    // Used to broadcast and query network info.
    chain_actor: ActorRef<CkbChainMessage>,
    // If the other party funding more than this amount, we will automatically accept the channel.
    open_channel_auto_accept_min_ckb_funding_amount: u64,
    // Tha default amount of CKB to be funded when auto accepting a channel.
    auto_accept_channel_ckb_funding_amount: u64,
    // The default expiry delta to forward tlcs.
    tlc_expiry_delta: u64,
    // The default tlc min and max value of tlcs to be accepted.
    tlc_min_value: u128,
    tlc_max_value: u128,
    // The default tlc fee proportional millionths to be used when auto accepting a channel.
    tlc_fee_proportional_millionths: u128,
    // The gossip messages actor to process and send gossip messages.
    gossip_actor: ActorRef<GossipActorMessage>,
    channel_subscribers: ChannelSubscribers,
    max_inbound_peers: usize,
    min_outbound_peers: usize,
}

#[serde_as]
#[derive(Default, Clone, Serialize, Deserialize)]
pub struct PersistentNetworkActorState {
    // This map is used to store the public key of the peer.
    #[serde_as(as = "Vec<(DisplayFromStr, _)>")]
    peer_pubkey_map: HashMap<PeerId, Pubkey>,
    // These addresses are saved by the user (e.g. the user sends a ConnectPeer rpc to the node),
    // we will then save these addresses to the peer store.
    #[serde_as(as = "Vec<(DisplayFromStr, _)>")]
    saved_peer_addresses: HashMap<PeerId, Vec<Multiaddr>>,
}

impl PersistentNetworkActorState {
    pub fn new() -> Self {
        Default::default()
    }

    fn get_peer_addresses(&self, peer_id: &PeerId) -> Vec<Multiaddr> {
        self.saved_peer_addresses
            .get(peer_id)
            .cloned()
            .unwrap_or_default()
    }

    /// Save a single peer address to the peer store. If this address for the peer does not exist,
    /// then return false, otherwise return true.
    fn save_peer_address(&mut self, peer_id: PeerId, addr: Multiaddr) -> bool {
        match self.saved_peer_addresses.entry(peer_id) {
            Entry::Occupied(mut entry) => {
                if entry.get().contains(&addr) {
                    false
                } else {
                    entry.get_mut().push(addr);
                    true
                }
            }
            Entry::Vacant(entry) => {
                entry.insert(vec![addr]);
                true
            }
        }
    }

    fn get_peer_pubkey(&self, peer_id: &PeerId) -> Option<Pubkey> {
        self.peer_pubkey_map.get(peer_id).copied()
    }

    // Save a single peer pubkey to the peer store. Returns true if the new pubkey is different from the old one,
    // or there does not exist a old pubkey.
    fn save_peer_pubkey(&mut self, peer_id: PeerId, pubkey: Pubkey) -> bool {
        match self.peer_pubkey_map.insert(peer_id, pubkey) {
            Some(old_pubkey) => old_pubkey != pubkey,
            None => true,
        }
    }

    fn num_of_saved_nodes(&self) -> usize {
        self.saved_peer_addresses.len()
    }

    pub(crate) fn sample_n_peers_to_connect(&self, n: usize) -> HashMap<PeerId, Vec<Multiaddr>> {
        // TODO: we may need to shuffle the nodes before selecting the first n nodes,
        // to avoid some malicious nodes from being always selected.
        self.saved_peer_addresses
            .iter()
            .take(n)
            .map(|(k, v)| (k.clone(), v.clone()))
            .collect()
    }
}

pub trait NetworkActorStateStore {
    fn get_network_actor_state(&self, id: &PeerId) -> Option<PersistentNetworkActorState>;
    fn insert_network_actor_state(&self, id: &PeerId, state: PersistentNetworkActorState);
}

static CHANNEL_ACTOR_NAME_PREFIX: AtomicU64 = AtomicU64::new(0u64);

// ractor requires that the actor name is unique, so we add a prefix to the actor name.
fn generate_channel_actor_name(local_peer_id: &PeerId, remote_peer_id: &PeerId) -> String {
    format!(
        "Channel-{} {} <-> {}",
        CHANNEL_ACTOR_NAME_PREFIX.fetch_add(1, Ordering::AcqRel),
        local_peer_id,
        remote_peer_id
    )
}

impl<S> NetworkActorState<S>
where
    S: NetworkActorStateStore
        + ChannelActorStateStore
        + NetworkGraphStateStore
        + GossipMessageStore
        + InvoiceStore
        + Clone
        + Send
        + Sync
        + 'static,
{
    pub fn get_or_create_new_node_announcement_message(&mut self) -> NodeAnnouncement {
        let now = now_timestamp_as_millis_u64();
        match self.last_node_announcement_message {
            // If the last node announcement message is still relatively new, we don't need to create a new one.
            // Because otherwise the receiving node may be confused by the multiple announcements,
            // and falsely believe we updated the node announcement, and then forward this message to other nodes.
            // This is undesirable because we don't want to flood the network with the same message.
            // On the other hand, if the message is too old, we need to create a new one.
            Some(ref message) if now - message.timestamp < 3600 * 1000 => {
                debug!("Returning old node announcement message as it is still valid");
            }
            _ => {
                let node_name = self.node_name.unwrap_or_default();
                let addresses = self.announced_addrs.clone();
                let announcement = NodeAnnouncement::new(
                    node_name,
                    addresses,
                    &self.private_key,
                    now,
                    self.open_channel_auto_accept_min_ckb_funding_amount,
                );
                debug!(
                    "Created new node announcement message: {:?}, previous {:?}",
                    &announcement, self.last_node_announcement_message
                );
                self.last_node_announcement_message = Some(announcement);
            }
        }
        self.last_node_announcement_message
            .clone()
            .expect("last node announcement message is present")
    }

    pub fn get_public_key(&self) -> Pubkey {
        self.private_key.pubkey()
    }

    pub fn generate_channel_seed(&mut self) -> [u8; 32] {
        let channel_user_id = self.channels.len();
        let seed = channel_user_id
            .to_be_bytes()
            .into_iter()
            .chain(self.entropy.iter().cloned())
            .collect::<Vec<u8>>();
        let result = blake2b_hash_with_salt(&seed, b"FIBER_CHANNEL_SEED");
        self.entropy = blake2b_hash_with_salt(&result, b"FIBER_NETWORK_ENTROPY_UPDATE");
        result
    }

    pub async fn create_outbound_channel(
        &mut self,
        open_channel: OpenChannelCommand,
    ) -> Result<(ActorRef<ChannelActorMessage>, Hash256), ProcessingChannelError> {
        let store = self.store.clone();
        let network = self.network.clone();
        let OpenChannelCommand {
            peer_id,
            funding_amount,
            public,
            shutdown_script,
            funding_udt_type_script,
            commitment_fee_rate,
            commitment_delay_epoch,
            funding_fee_rate,
            tlc_expiry_delta,
            tlc_min_value,
            tlc_fee_proportional_millionths,
            max_tlc_value_in_flight,
            max_tlc_number_in_flight,
        } = open_channel;
        let remote_pubkey =
            self.get_peer_pubkey(&peer_id)
                .ok_or(ProcessingChannelError::InvalidParameter(format!(
                    "Peer {:?} pubkey not found",
                    &peer_id
                )))?;
        if let Some(udt_type_script) = funding_udt_type_script.as_ref() {
            if !check_udt_script(udt_type_script) {
                return Err(ProcessingChannelError::InvalidParameter(
                    "Invalid UDT type script".to_string(),
                ));
            }
        }

        if let Some(_delta) = tlc_expiry_delta.filter(|&d| d < MIN_TLC_EXPIRY_DELTA) {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "TLC expiry delta is too small, expect larger than {}",
                MIN_TLC_EXPIRY_DELTA
            )));
        }

        let shutdown_script =
            shutdown_script.unwrap_or_else(|| self.default_shutdown_script.clone());

        let seed = self.generate_channel_seed();
        let (tx, rx) = oneshot::channel::<Hash256>();
        let channel = Actor::spawn_linked(
            Some(generate_channel_actor_name(&self.peer_id, &peer_id)),
            ChannelActor::new(
                self.get_public_key(),
                remote_pubkey,
                network.clone(),
                store,
                self.channel_subscribers.clone(),
            ),
            ChannelInitializationParameter::OpenChannel(OpenChannelParameter {
                funding_amount,
                seed,
                tlc_info: ChannelTlcInfo::new(
                    tlc_min_value.unwrap_or(self.tlc_min_value),
                    tlc_expiry_delta.unwrap_or(self.tlc_expiry_delta),
                    tlc_fee_proportional_millionths.unwrap_or(self.tlc_fee_proportional_millionths),
                ),
                public_channel_info: public.then_some(PublicChannelInfo::new()),
                funding_udt_type_script,
                shutdown_script,
                channel_id_sender: tx,
                commitment_fee_rate,
                commitment_delay_epoch,
                funding_fee_rate,
                max_tlc_value_in_flight: max_tlc_value_in_flight
                    .unwrap_or(DEFAULT_MAX_TLC_VALUE_IN_FLIGHT),
                max_tlc_number_in_flight: max_tlc_number_in_flight
                    .unwrap_or(MAX_TLC_NUMBER_IN_FLIGHT),
            }),
            network.clone().get_cell(),
        )
        .await
        .map_err(|e| ProcessingChannelError::SpawnErr(e.to_string()))?
        .0;
        let temp_channel_id = rx.await.expect("msg received");
        self.on_channel_created(temp_channel_id, &peer_id, channel.clone());
        Ok((channel, temp_channel_id))
    }

    pub async fn create_inbound_channel(
        &mut self,
        accept_channel: AcceptChannelCommand,
    ) -> Result<(ActorRef<ChannelActorMessage>, Hash256, Hash256), ProcessingChannelError> {
        let store = self.store.clone();
        let AcceptChannelCommand {
            temp_channel_id,
            funding_amount,
            shutdown_script,
            max_tlc_number_in_flight,
            max_tlc_value_in_flight,
            min_tlc_value,
            tlc_fee_proportional_millionths,
            tlc_expiry_delta,
        } = accept_channel;

        let (peer_id, open_channel) = self
            .to_be_accepted_channels
            .remove(&temp_channel_id)
            .ok_or(ProcessingChannelError::InvalidParameter(format!(
                "No channel with temp id {:?} found",
                &temp_channel_id
            )))?;

        let remote_pubkey =
            self.get_peer_pubkey(&peer_id)
                .ok_or(ProcessingChannelError::InvalidParameter(format!(
                    "Peer {:?} pubkey not found",
                    &peer_id
                )))?;

        let shutdown_script =
            shutdown_script.unwrap_or_else(|| self.default_shutdown_script.clone());
        let (funding_amount, reserved_ckb_amount) = get_funding_and_reserved_amount(
            funding_amount,
            &shutdown_script,
            &open_channel.funding_udt_type_script,
        )?;

        let network = self.network.clone();
        let id = open_channel.channel_id;
        if let Some(channel) = self.channels.get(&id) {
            warn!("A channel of id {:?} is already created, returning it", &id);
            return Ok((channel.clone(), temp_channel_id, id));
        }

        let seed = self.generate_channel_seed();
        let (tx, rx) = oneshot::channel::<Hash256>();
        let channel = Actor::spawn_linked(
            Some(generate_channel_actor_name(&self.peer_id, &peer_id)),
            ChannelActor::new(
                self.get_public_key(),
                remote_pubkey,
                network.clone(),
                store,
                self.channel_subscribers.clone(),
            ),
            ChannelInitializationParameter::AcceptChannel(AcceptChannelParameter {
                funding_amount,
                reserved_ckb_amount,
                tlc_info: ChannelTlcInfo::new(
                    min_tlc_value.unwrap_or(self.tlc_min_value),
                    tlc_expiry_delta.unwrap_or(self.tlc_expiry_delta),
                    tlc_fee_proportional_millionths.unwrap_or(self.tlc_fee_proportional_millionths),
                ),
                public_channel_info: open_channel.is_public().then_some(PublicChannelInfo::new()),
                seed,
                open_channel,
                shutdown_script,
                channel_id_sender: Some(tx),
                max_tlc_number_in_flight: max_tlc_number_in_flight
                    .unwrap_or(MAX_TLC_NUMBER_IN_FLIGHT),
                max_tlc_value_in_flight: max_tlc_value_in_flight.unwrap_or(u128::MAX),
            }),
            network.clone().get_cell(),
        )
        .await
        .map_err(|e| ProcessingChannelError::SpawnErr(e.to_string()))?
        .0;
        let new_id = rx.await.expect("msg received");
        self.on_channel_created(new_id, &peer_id, channel.clone());
        Ok((channel, temp_channel_id, new_id))
    }

    // This function send the transaction to the network and then trace the transaction status.
    // Either the sending or the tracing may fail, in which case the callback will be called with
    // the error.
    async fn broadcast_tx_with_callback<F>(&self, transaction: TransactionView, callback: F)
    where
        F: Send + 'static + FnOnce(Result<TraceTxResponse, RactorErr<CkbChainMessage>>),
    {
        let chain = self.chain_actor.clone();
        // Spawn a new task to avoid blocking current actor message processing.
        ractor::concurrency::tokio_primitives::spawn(async move {
            debug!("Trying to broadcast transaction {:?}", &transaction);
            let result = match call_t!(
                &chain,
                CkbChainMessage::SendTx,
                DEFAULT_CHAIN_ACTOR_TIMEOUT,
                transaction.clone()
            )
            .expect(ASSUME_CHAIN_ACTOR_ALWAYS_ALIVE_FOR_NOW)
            {
                Err(err) => {
                    error!("Failed to send transaction to the network: {:?}", &err);
                    // TODO: the caller of this function will deem the failure returned here as permanent.
                    // But SendTx may only fail temporarily. We need to handle this case.
                    Ok(TraceTxResponse {
                        tx: None,
                        status: TxStatus {
                            status: Status::Rejected,
                            block_number: None,
                            block_hash: None,
                            tx_index: None,
                            reason: Some(format!("Sending transaction failed: {:?}", &err)),
                        },
                    })
                }
                Ok(_) => {
                    let tx_hash = transaction.hash();
                    // TODO: make number of confirmation to transaction configurable.
                    const NUM_CONFIRMATIONS: u64 = 4;
                    let request = TraceTxRequest {
                        tx_hash: tx_hash.clone(),
                        confirmations: NUM_CONFIRMATIONS,
                    };
                    debug!(
                        "Transaction sent to the network, waiting for it to be confirmed: {:?}",
                        &request.tx_hash
                    );
                    call_t!(
                        chain,
                        CkbChainMessage::TraceTx,
                        DEFAULT_CHAIN_ACTOR_TIMEOUT,
                        request.clone()
                    )
                }
            };

            callback(result);
        });
    }

    fn get_peer_session(&self, peer_id: &PeerId) -> Option<SessionId> {
        self.peer_session_map.get(peer_id).map(|s| s.0)
    }

    fn inbound_peer_sessions(&self) -> Vec<SessionId> {
        self.peer_session_map
            .values()
            .filter_map(|s| (s.1 == SessionType::Inbound).then_some(s.0))
            .collect()
    }

    fn num_of_outbound_peers(&self) -> usize {
        self.peer_session_map
            .values()
            .filter(|s| s.1 == SessionType::Outbound)
            .count()
    }

    fn is_connected(&self, peer_id: &PeerId) -> bool {
        self.peer_session_map.contains_key(peer_id)
    }

    pub fn get_n_peer_peer_ids(&self, n: usize, excluding: HashSet<PeerId>) -> Vec<PeerId> {
        self.peer_session_map
            .keys()
            .skip_while(|x| excluding.contains(x))
            .take(n)
            .cloned()
            .collect()
    }

    pub fn get_n_peer_sessions(&self, n: usize) -> Vec<SessionId> {
        self.peer_session_map
            .values()
            .take(n)
            .map(|s| s.0)
            .collect()
    }

    fn get_peer_pubkey(&self, peer_id: &PeerId) -> Option<Pubkey> {
        self.state_to_be_persisted.get_peer_pubkey(peer_id)
    }

    // TODO: this fn is duplicated with ChannelActorState::check_open_channel_parameters, but is not easy to refactor, just keep it for now.
    fn check_open_channel_parameters(
        &self,
        open_channel: &OpenChannel,
    ) -> Result<(), ProcessingChannelError> {
        let udt_type_script = &open_channel.funding_udt_type_script;

        // reserved_ckb_amount
        let occupied_capacity =
            occupied_capacity(&open_channel.shutdown_script, udt_type_script)?.as_u64();
        if open_channel.reserved_ckb_amount < occupied_capacity {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Reserved CKB amount {} is less than {}",
                open_channel.reserved_ckb_amount, occupied_capacity,
            )));
        }

        // funding_fee_rate
        if open_channel.funding_fee_rate < DEFAULT_FEE_RATE {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Funding fee rate is less than {}",
                DEFAULT_FEE_RATE,
            )));
        }

        // commitment_fee_rate
        if open_channel.commitment_fee_rate < DEFAULT_COMMITMENT_FEE_RATE {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Commitment fee rate is less than {}",
                DEFAULT_COMMITMENT_FEE_RATE,
            )));
        }
        let commitment_fee =
            calculate_commitment_tx_fee(open_channel.commitment_fee_rate, udt_type_script);
        let reserved_fee = open_channel.reserved_ckb_amount - occupied_capacity;
        if commitment_fee * 2 > reserved_fee {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Commitment fee {} which caculated by commitment fee rate {} is larger than half of reserved fee {}",
                commitment_fee, open_channel.commitment_fee_rate, reserved_fee
            )));
        }

        // commitment_delay_epoch
        let epoch =
            EpochNumberWithFraction::from_full_value_unchecked(open_channel.commitment_delay_epoch);
        if !epoch.is_well_formed() {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Commitment delay epoch {} is not a valid value",
                open_channel.commitment_delay_epoch,
            )));
        }

        let min = EpochNumberWithFraction::new(MIN_COMMITMENT_DELAY_EPOCHS, 0, 1);
        if epoch < min {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Commitment delay epoch {} is less than the minimal value {}",
                epoch, min
            )));
        }

        let max = EpochNumberWithFraction::new(MAX_COMMITMENT_DELAY_EPOCHS, 0, 1);
        if epoch > max {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Commitment delay epoch {} is greater than the maximal value {}",
                epoch, max
            )));
        }

        // max_tlc_number_in_flight
        if open_channel.max_tlc_number_in_flight > SYS_MAX_TLC_NUMBER_IN_FLIGHT {
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "Max TLC number in flight {} is greater than the system maximal value {}",
                open_channel.max_tlc_number_in_flight, SYS_MAX_TLC_NUMBER_IN_FLIGHT
            )));
        }

        Ok(())
    }

    async fn send_fiber_message_to_session(
        &self,
        session_id: SessionId,
        message: FiberMessage,
    ) -> crate::Result<()> {
        self.control
            .send_message_to(session_id, FIBER_PROTOCOL_ID, message.to_molecule_bytes())
            .await?;
        Ok(())
    }

    async fn send_fiber_message_to_peer(
        &self,
        peer_id: &PeerId,
        message: FiberMessage,
    ) -> crate::Result<()> {
        match self.get_peer_session(peer_id) {
            Some(session) => self.send_fiber_message_to_session(session, message).await,
            None => Err(Error::PeerNotFound(peer_id.clone())),
        }
    }

    async fn send_command_to_channel(
        &self,
        channel_id: Hash256,
        command: ChannelCommand,
    ) -> crate::Result<()> {
        match command {
            // Need to handle the force shutdown command specially because the ChannelActor may not exist when remote peer is disconnected.
            ChannelCommand::Shutdown(shutdown, rpc_reply) if shutdown.force => {
                if let Some(actor) = self.channels.get(&channel_id) {
                    actor.send_message(ChannelActorMessage::Command(ChannelCommand::Shutdown(
                        shutdown, rpc_reply,
                    )))?;
                    Ok(())
                } else {
                    match self.store.get_channel_actor_state(&channel_id) {
                        Some(mut state) => {
                            match state.state {
                                ChannelState::ChannelReady() => {
                                    debug!("Handling force shutdown command in ChannelReady state");
                                }
                                ChannelState::ShuttingDown(flags) => {
                                    debug!("Handling force shutdown command in ShuttingDown state, flags: {:?}", &flags);
                                }
                                _ => {
                                    let error = Error::ChannelError(
                                        ProcessingChannelError::InvalidState(format!(
                                            "Handling force shutdown command invalid state {:?}",
                                            &state.state
                                        )),
                                    );

                                    let _ = rpc_reply.send(Err(error.to_string()));
                                    return Err(error);
                                }
                            };

                            let transaction = state
                                .latest_commitment_transaction
                                .clone()
                                .expect("latest_commitment_transaction should exist when channel is in ChannelReady of ShuttingDown state");
                            self.network
                                .send_message(NetworkActorMessage::new_event(
                                    NetworkActorEvent::CommitmentTransactionPending(
                                        transaction,
                                        channel_id,
                                    ),
                                ))
                                .expect(ASSUME_NETWORK_ACTOR_ALIVE);

                            state.update_state(ChannelState::ShuttingDown(
                                ShuttingDownFlags::WAITING_COMMITMENT_CONFIRMATION,
                            ));
                            self.store.insert_channel_actor_state(state);

                            let _ = rpc_reply.send(Ok(()));
                            Ok(())
                        }
                        None => Err(Error::ChannelNotFound(channel_id)),
                    }
                }
            }
            _ => match self.channels.get(&channel_id) {
                Some(actor) => {
                    actor.send_message(ChannelActorMessage::Command(command))?;
                    Ok(())
                }
                None => Err(Error::ChannelNotFound(channel_id)),
            },
        }
    }

    async fn reestablish_channel(
        &mut self,
        peer_id: &PeerId,
        channel_id: Hash256,
    ) -> Result<ActorRef<ChannelActorMessage>, Error> {
        if let Some(actor) = self.channels.get(&channel_id) {
            debug!(
                "Channel {:x} already exists, skipping reestablishment",
                &channel_id
            );
            return Ok(actor.clone());
        }
        let remote_pubkey =
            self.get_peer_pubkey(peer_id)
                .ok_or(ProcessingChannelError::InvalidState(format!(
                    "Peer {:?}'s pubkey not found, this should never happen",
                    &peer_id
                )))?;

        debug!("Reestablishing channel {:x}", &channel_id);
        let (channel, _) = Actor::spawn_linked(
            Some(generate_channel_actor_name(&self.peer_id, peer_id)),
            ChannelActor::new(
                self.get_public_key(),
                remote_pubkey,
                self.network.clone(),
                self.store.clone(),
                self.channel_subscribers.clone(),
            ),
            ChannelInitializationParameter::ReestablishChannel(channel_id),
            self.network.get_cell(),
        )
        .await?;
        info!("channel {:x} reestablished successfully", &channel_id);
        self.on_channel_created(channel_id, peer_id, channel.clone());
        Ok(channel)
    }

    async fn on_peer_connected(
        &mut self,
        remote_peer_id: &PeerId,
        remote_pubkey: Pubkey,
        session: &SessionContext,
    ) {
        let store = self.store.clone();
        self.peer_session_map
            .insert(remote_peer_id.clone(), (session.id, session.ty));
        if self
            .state_to_be_persisted
            .save_peer_pubkey(remote_peer_id.clone(), remote_pubkey)
        {
            self.persist_state();
        }

        if self.auto_announce {
            let message = self.get_or_create_new_node_announcement_message();
            debug!(
                "Auto announcing our node to peer {:?} (message: {:?})",
                remote_peer_id, &message
            );
            let _ = self.network.send_message(NetworkActorMessage::new_command(
                NetworkActorCommand::BroadcastMessages(vec![
                    BroadcastMessageWithTimestamp::NodeAnnouncement(message),
                ]),
            ));
        } else {
            debug!(
                "Auto announcing is disabled, skipping node announcement to peer {:?}",
                remote_peer_id
            );
        }

        for channel_id in store.get_active_channel_ids_by_peer(remote_peer_id) {
            if let Err(e) = self.reestablish_channel(remote_peer_id, channel_id).await {
                error!("Failed to reestablish channel {:x}: {:?}", &channel_id, &e);
            }
        }
    }

    fn remove_channel(&mut self, channel_id: &Hash256) -> Option<ActorRef<ChannelActorMessage>> {
        self.channels
            .remove(channel_id)
            .inspect(|_| self.outpoint_channel_map.retain(|_, v| v != channel_id))
    }

    fn on_peer_disconnected(&mut self, id: &PeerId) {
        if let Some(session) = self.peer_session_map.remove(id) {
            if let Some(channel_ids) = self.session_channels_map.remove(&session.0) {
                for channel_id in channel_ids {
                    if let Some(channel) = self.remove_channel(&channel_id) {
                        let _ = channel.send_message(ChannelActorMessage::Event(
                            ChannelEvent::PeerDisconnected,
                        ));
                    }
                }
            }
        }
    }

    pub(crate) fn get_peer_addresses(&self, peer_id: &PeerId) -> HashSet<Multiaddr> {
        self.get_peer_pubkey(peer_id)
            .and_then(|pk| self.store.get_latest_node_announcement(&pk))
            .map(|a| a.addresses)
            .unwrap_or_default()
            .into_iter()
            .chain(self.state_to_be_persisted.get_peer_addresses(peer_id))
            .collect()
    }

    pub(crate) fn save_peer_address(&mut self, peer_id: PeerId, address: Multiaddr) -> bool {
        if self
            .state_to_be_persisted
            .save_peer_address(peer_id, address)
        {
            self.persist_state();
            true
        } else {
            false
        }
    }

    fn persist_state(&self) {
        self.store
            .insert_network_actor_state(&self.peer_id, self.state_to_be_persisted.clone());
    }

    fn on_channel_created(
        &mut self,
        id: Hash256,
        peer_id: &PeerId,
        actor: ActorRef<ChannelActorMessage>,
    ) {
        if let Some(session) = self.get_peer_session(peer_id) {
            self.channels.insert(id, actor.clone());
            self.session_channels_map
                .entry(session)
                .or_default()
                .insert(id);
        }
        debug!("Channel {:x} created", &id);
        // Notify outside observers.
        self.network
            .send_message(NetworkActorMessage::new_notification(
                NetworkServiceEvent::ChannelCreated(peer_id.clone(), id),
            ))
            .expect(ASSUME_NETWORK_MYSELF_ALIVE);
    }

    async fn on_closing_transaction_pending(
        &mut self,
        channel_id: Hash256,
        peer_id: PeerId,
        transaction: TransactionView,
    ) {
        let tx_hash: Byte32 = transaction.hash();
        info!(
            "Channel ({:?}) to peer {:?} is closed. Broadcasting closing transaction ({:?}) now.",
            &channel_id, &peer_id, &tx_hash
        );
        let network: ActorRef<NetworkActorMessage> = self.network.clone();
        self.broadcast_tx_with_callback(transaction, move |result| {
            let message = match result {
                Ok(TraceTxResponse {
                    status:
                        TxStatus {
                            status: Status::Committed,
                            ..
                        },
                    ..
                }) => {
                    info!("Cloisng transaction {:?} confirmed", &tx_hash);
                    NetworkActorEvent::ClosingTransactionConfirmed(peer_id, channel_id, tx_hash)
                }
                Ok(status) => {
                    error!(
                        "Closing transaction {:?} failed to be confirmed with final status {:?}",
                        &tx_hash, &status
                    );
                    NetworkActorEvent::ClosingTransactionFailed(peer_id, channel_id, tx_hash)
                }
                Err(err) => {
                    error!("Failed to trace transaction {:?}: {:?}", &tx_hash, &err);
                    NetworkActorEvent::ClosingTransactionFailed(peer_id, channel_id, tx_hash)
                }
            };
            network
                .send_message(NetworkActorMessage::new_event(message))
                .expect(ASSUME_NETWORK_MYSELF_ALIVE);
        })
        .await;
    }

    async fn on_closing_transaction_confirmed(
        &mut self,
        peer_id: &PeerId,
        channel_id: &Hash256,
        tx_hash: Byte32,
    ) {
        self.send_message_to_channel_actor(
            *channel_id,
            None,
            ChannelActorMessage::Event(ChannelEvent::ClosingTransactionConfirmed),
        )
        .await;
        self.remove_channel(channel_id);
        if let Some(session) = self.get_peer_session(peer_id) {
            if let Some(set) = self.session_channels_map.get_mut(&session) {
                set.remove(channel_id);
            }
        }
        // Notify outside observers.
        self.network
            .send_message(NetworkActorMessage::new_notification(
                NetworkServiceEvent::ChannelClosed(peer_id.clone(), *channel_id, tx_hash),
            ))
            .expect(ASSUME_NETWORK_MYSELF_ALIVE);
    }

    pub async fn on_open_channel_msg(
        &mut self,
        peer_id: PeerId,
        open_channel: OpenChannel,
    ) -> ProcessingChannelResult {
        self.check_open_channel_parameters(&open_channel)?;

        if let Some(udt_type_script) = &open_channel.funding_udt_type_script {
            if !check_udt_script(udt_type_script) {
                return Err(ProcessingChannelError::InvalidParameter(format!(
                    "Invalid UDT type script: {:?}",
                    udt_type_script
                )));
            }
        }

        let id = open_channel.channel_id;
        if let Some(channel) = self.to_be_accepted_channels.get(&id) {
            warn!(
                "A channel from {:?} of id {:?} is already awaiting to be accepted: {:?}",
                &peer_id, &id, channel
            );
            return Err(ProcessingChannelError::InvalidParameter(format!(
                "A channel from {:?} of id {:?} is already awaiting to be accepted",
                &peer_id, &id,
            )));
        }
        debug!(
            "Channel from {:?} of id {:?} is now awaiting to be accepted: {:?}",
            &peer_id, &id, &open_channel
        );
        self.to_be_accepted_channels
            .insert(id, (peer_id.clone(), open_channel));
        // Notify outside observers.
        self.network
            .clone()
            .send_message(NetworkActorMessage::new_notification(
                NetworkServiceEvent::ChannelPendingToBeAccepted(peer_id, id),
            ))
            .expect(ASSUME_NETWORK_MYSELF_ALIVE);
        Ok(())
    }

    async fn on_funding_transaction_pending(
        &mut self,
        transaction: Transaction,
        outpoint: OutPoint,
        channel_id: Hash256,
    ) {
        // Just a sanity check to ensure that no two channels are associated with the same outpoint.
        if let Some(old) = self.pending_channels.remove(&outpoint) {
            if old != channel_id {
                panic!("Trying to associate a new channel id {:?} with the same outpoint {:?} when old channel id is {:?}. Rejecting.", channel_id, outpoint, old);
            }
        }
        self.pending_channels.insert(outpoint.clone(), channel_id);
        // TODO: try to broadcast the transaction to the network.
        let transaction = transaction.into_view();
        let tx_hash: Byte32 = transaction.hash();
        debug!(
            "Funding transaction (outpoint {:?}) for channel {:?} is now ready. Broadcast it {:?} now.",
            &outpoint, &channel_id, &tx_hash
        );
        let network = self.network.clone();
        let chain = self.chain_actor.clone();
        self.broadcast_tx_with_callback(transaction, move |result| {
            match result {
                Ok(TraceTxResponse {
                    status:
                        TxStatus {
                            status: Status::Committed,
                            block_hash: Some(block_hash),
                            ..
                        },
                    ..
                }) => {
                    tokio::spawn( async move  {
                        match call!(
                            chain,
                            |reply| CkbChainMessage::GetBlockTimestamp(
                                GetBlockTimestampRequest::from_block_hash(block_hash.clone()), reply
                            )
                        ) {
                            Ok(Ok(Some(timestamp))) => {
                                info!("Funding transaction {:?} confirmed", &tx_hash);
                                // Notify outside observers.
                                network.send_message(NetworkActorMessage::new_event(
                                    NetworkActorEvent::FundingTransactionConfirmed(
                                        outpoint.clone(),
                                        block_hash.clone(),
                                        DUMMY_FUNDING_TX_INDEX,
                                        timestamp,
                                    )
                                ))
                                .expect(ASSUME_NETWORK_MYSELF_ALIVE);
                                return;
                            },
                            Ok(Ok(None)) => {
                                error!(
                                    "Failed to get block timestamp for block hash {:?}: block not found",
                                    &block_hash
                                );
                            }
                            Ok(Err(err)) => {
                                error!(
                                    "Failed to get block timestamp for block hash {:?}: {:?}",
                                    &block_hash, &err
                                );
                            }
                            Err(err) => {
                                error!(
                                    "Failed to get block timestamp for block hash {:?}: {:?}",
                                    &block_hash, &err
                                );
                            }
                        }
                    });
                }
                Ok(status) => {
                    error!(
                        "Funding transaction {:?} failed to be confirmed with final status {:?}",
                        &tx_hash, &status
                    );
                    // Notify outside observers.
                    network
                        .send_message(NetworkActorMessage::new_event(NetworkActorEvent::FundingTransactionFailed(outpoint)
                    ))
                        .expect(ASSUME_NETWORK_MYSELF_ALIVE);
                }
                Err(err) => {
                    error!("Failed to trace transaction {:?}: {:?}", &tx_hash, &err);
                    // Notify outside observers.
                    network
                        .send_message(NetworkActorMessage::new_event(NetworkActorEvent::FundingTransactionFailed(outpoint)
                    ))
                        .expect(ASSUME_NETWORK_MYSELF_ALIVE);
                }
            };
        })
        .await;
    }

    async fn on_commitment_transaction_pending(
        &mut self,
        transaction: Transaction,
        channel_id: Hash256,
    ) {
        let transaction = transaction.into_view();
        let tx_hash: Byte32 = transaction.hash();
        debug!(
            "Commitment transaction for channel {:?} is now ready. Broadcast it {:?} now.",
            &channel_id, &tx_hash
        );

        let network = self.network.clone();
        self.broadcast_tx_with_callback(transaction, move |result| {
            let message = match result {
                Ok(TraceTxResponse {
                    status:
                        TxStatus {
                            status: Status::Committed,
                            ..
                        },
                    ..
                }) => {
                    info!("Commitment transaction {:?} confirmed", tx_hash,);
                    NetworkActorEvent::CommitmentTransactionConfirmed(tx_hash.into(), channel_id)
                }
                Ok(status) => {
                    error!(
                        "Commitment transaction {:?} failed to be confirmed with final status {:?}",
                        &tx_hash, &status
                    );
                    NetworkActorEvent::CommitmentTransactionFailed(channel_id, tx_hash)
                }
                Err(err) => {
                    error!(
                        "Failed to trace commitment transaction {:?}: {:?}",
                        &tx_hash, &err
                    );
                    NetworkActorEvent::CommitmentTransactionFailed(channel_id, tx_hash)
                }
            };
            network
                .send_message(NetworkActorMessage::new_event(message))
                .expect(ASSUME_NETWORK_MYSELF_ALIVE);
        })
        .await;
    }

    async fn on_funding_transaction_confirmed(
        &mut self,
        outpoint: OutPoint,
        block_hash: H256,
        tx_index: u32,
        timestamp: u64,
    ) {
        debug!("Funding transaction is confirmed: {:?}", &outpoint);
        let channel_id = match self.pending_channels.remove(&outpoint) {
            Some(channel_id) => channel_id,
            None => {
                warn!(
                    "Funding transaction confirmed for outpoint {:?} but no channel found",
                    &outpoint
                );
                return;
            }
        };
        self.send_message_to_channel_actor(
            channel_id,
            None,
            ChannelActorMessage::Event(ChannelEvent::FundingTransactionConfirmed(
                block_hash, tx_index, timestamp,
            )),
        )
        .await;
    }

    async fn on_commitment_transaction_confirmed(&mut self, tx_hash: Hash256, channel_id: Hash256) {
        debug!("Commitment transaction is confirmed: {:?}", tx_hash);
        self.send_message_to_channel_actor(
            channel_id,
            None,
            ChannelActorMessage::Event(ChannelEvent::CommitmentTransactionConfirmed),
        )
        .await;
    }

    async fn send_message_to_channel_actor(
        &mut self,
        channel_id: Hash256,
        // Sometimes we need to know the peer id in order to send the message to the channel actor.
        peer_id: Option<&PeerId>,
        message: ChannelActorMessage,
    ) {
        match self.channels.get(&channel_id) {
            None => match (message, peer_id) {
                // There is some chance that the peer send a message related to a channel that is not created yet,
                // e.g. when we just started trying to reestablish channel, we may have
                // no reference to that channel yet.
                // We should stash the message and process it later.
                // TODO: ban the adversary who constantly send messages related to non-existing channels.
                (
                    ChannelActorMessage::PeerMessage(FiberChannelMessage::ReestablishChannel(r)),
                    Some(remote_peer_id),
                ) if self.store.get_channel_actor_state(&channel_id).is_some() => {
                    debug!("Received a ReestablishChannel message for channel {:?} which has persisted state, but no corresponding channel actor, starting it now", &channel_id);
                    match self.reestablish_channel(remote_peer_id, channel_id).await {
                        Ok(actor) => {
                            actor
                                .send_message(ChannelActorMessage::PeerMessage(
                                    FiberChannelMessage::ReestablishChannel(r),
                                ))
                                .expect("channel actor alive");
                        }
                        Err(e) => {
                            error!("Failed to reestablish channel {:x}: {:?}", &channel_id, &e);
                        }
                    }
                }
                (message, _) => {
                    error!(
                            "Failed to send message to channel actor: channel {:?} not found, message: {:?}",
                            &channel_id, &message,
                        );
                }
            },
            Some(actor) => {
                actor.send_message(message).expect("channel actor alive");
            }
        }
    }
}

pub struct NetworkActorStartArguments {
    pub config: FiberConfig,
    pub tracker: TaskTracker,
    pub channel_subscribers: ChannelSubscribers,
    pub default_shutdown_script: Script,
}

#[rasync_trait]
impl<S> Actor for NetworkActor<S>
where
    S: NetworkActorStateStore
        + ChannelActorStateStore
        + NetworkGraphStateStore
        + GossipMessageStore
        + InvoiceStore
        + Clone
        + Send
        + Sync
        + 'static,
{
    type Msg = NetworkActorMessage;
    type State = NetworkActorState<S>;
    type Arguments = NetworkActorStartArguments;

    async fn pre_start(
        &self,
        myself: ActorRef<Self::Msg>,
        args: Self::Arguments,
    ) -> Result<Self::State, ActorProcessingErr> {
        let NetworkActorStartArguments {
            config,
            tracker,
            channel_subscribers,
            default_shutdown_script,
        } = args;
        let now = SystemTime::now()
            .duration_since(SystemTime::UNIX_EPOCH)
            .expect("SystemTime::now() should after UNIX_EPOCH");
        let kp = config
            .read_or_generate_secret_key()
            .expect("read or generate secret key");
        let private_key = <[u8; 32]>::try_from(kp.as_ref())
            .expect("valid length for key")
            .into();
        let entropy = blake2b_hash_with_salt(
            [kp.as_ref(), now.as_nanos().to_le_bytes().as_ref()]
                .concat()
                .as_slice(),
            b"FIBER_NETWORK_ENTROPY",
        );
        let secio_kp = SecioKeyPair::from(kp);
        let secio_pk = secio_kp.public_key();
        let my_peer_id: PeerId = PeerId::from(secio_pk);
        let handle = MyServiceHandle::new(myself.clone());
        let fiber_handle = FiberProtocolHandle::from(&handle);
        let (gossip_handle, store_update_subscriber) = GossipProtocolHandle::new(
            Some(format!("gossip actor {:?}", my_peer_id)),
            Duration::from_millis(config.gossip_network_maintenance_interval_ms()),
            Duration::from_millis(config.gossip_store_maintenance_interval_ms()),
            config.announce_private_addr(),
            config.gossip_network_num_targeted_active_syncing_peers,
            config.gossip_network_num_targeted_outbound_passive_syncing_peers,
            self.store.clone(),
            self.chain_actor.clone(),
            myself.get_cell(),
        )
        .await;
        let graph = self.network_graph.read().await;
        let graph_subscribing_cursor = graph
            .get_latest_cursor()
            .go_back_for_some_time(MAX_GRAPH_MISSING_BROADCAST_MESSAGE_TIMESTAMP_DRIFT);

        store_update_subscriber
            .subscribe(graph_subscribing_cursor, myself.clone(), |m| {
                Some(NetworkActorMessage::new_event(
                    NetworkActorEvent::GossipMessageUpdates(m),
                ))
            })
            .await
            .expect("subscribe to gossip store updates");
        let gossip_actor = gossip_handle.actor().clone();
        let mut service = ServiceBuilder::default()
            .insert_protocol(fiber_handle.create_meta())
            .insert_protocol(gossip_handle.create_meta())
            .handshake_type(secio_kp.into())
            .build(handle);
        let mut listening_addr = service
            .listen(
                MultiAddr::from_str(config.listening_addr())
                    .expect("valid tentacle listening address"),
            )
            .await
            .expect("listen tentacle");

        listening_addr.push(Protocol::P2P(Cow::Owned(my_peer_id.clone().into_bytes())));
        let mut announced_addrs = Vec::with_capacity(config.announced_addrs.len() + 1);
        if config.announce_listening_addr() {
            announced_addrs.push(listening_addr.clone());
        }
        for announced_addr in &config.announced_addrs {
            let mut multiaddr =
                MultiAddr::from_str(announced_addr.as_str()).expect("valid announced listen addr");
            match multiaddr.pop() {
                Some(Protocol::P2P(c)) => {
                    // If the announced listen addr has a peer id, it must match our peer id.
                    if c.as_ref() != my_peer_id.as_bytes() {
                        panic!("Announced listen addr is using invalid peer id: announced addr {}, actual peer id {:?}", announced_addr, my_peer_id);
                    }
                }
                Some(component) => {
                    // Push this unrecognized component back to the multiaddr.
                    multiaddr.push(component);
                }
                None => {
                    // Should never happen
                }
            }
            // Push our peer id to the multiaddr.
            multiaddr.push(Protocol::P2P(Cow::Owned(my_peer_id.clone().into_bytes())));
            announced_addrs.push(multiaddr);
        }

        if !config.announce_private_addr.unwrap_or_default() {
            announced_addrs.retain(|addr| {
                multiaddr_to_socketaddr(addr)
                    .map(|socket_addr| is_reachable(socket_addr.ip()))
                    .unwrap_or_default()
            });
        }

        info!(
            "Started listening tentacle on {:?}, peer id {:?}, announced addresses {:?}",
            &listening_addr, &my_peer_id, &announced_addrs
        );

        let control = service.control().to_owned();

        myself
            .send_message(NetworkActorMessage::new_notification(
                NetworkServiceEvent::NetworkStarted(
                    my_peer_id.clone(),
                    listening_addr.clone(),
                    announced_addrs.clone(),
                ),
            ))
            .expect(ASSUME_NETWORK_MYSELF_ALIVE);

        tracker.spawn(async move {
            service.run().await;
            debug!("Tentacle service stopped");
        });

        let mut state_to_be_persisted = self
            .store
            .get_network_actor_state(&my_peer_id)
            .unwrap_or_default();

        for bootnode in &config.bootnode_addrs {
            let addr = Multiaddr::from_str(bootnode.as_str()).expect("valid bootnode");
            let peer_id = extract_peer_id(&addr).expect("valid peer id");
            state_to_be_persisted.save_peer_address(peer_id, addr);
        }

        let chain_actor = self.chain_actor.clone();

        let mut state = NetworkActorState {
            store: self.store.clone(),
            state_to_be_persisted,
            node_name: config.announced_node_name,
            peer_id: my_peer_id,
            announced_addrs,
            auto_announce: config.auto_announce_node(),
            last_node_announcement_message: None,
            private_key,
            entropy,
            default_shutdown_script,
            network: myself.clone(),
            control,
            peer_session_map: Default::default(),
            session_channels_map: Default::default(),
            channels: Default::default(),
            outpoint_channel_map: Default::default(),
            to_be_accepted_channels: Default::default(),
            pending_channels: Default::default(),
            chain_actor,
            open_channel_auto_accept_min_ckb_funding_amount: config
                .open_channel_auto_accept_min_ckb_funding_amount(),
            auto_accept_channel_ckb_funding_amount: config.auto_accept_channel_ckb_funding_amount(),
            tlc_expiry_delta: config.tlc_expiry_delta(),
            tlc_min_value: config.tlc_min_value(),
            tlc_max_value: config.tlc_max_value(),
            tlc_fee_proportional_millionths: config.tlc_fee_proportional_millionths(),
            gossip_actor,
            channel_subscribers,
            max_inbound_peers: config.max_inbound_peers(),
            min_outbound_peers: config.min_outbound_peers(),
        };

        // Save our own NodeInfo to the network graph.
        let node_announcement = state.get_or_create_new_node_announcement_message();
        myself.send_message(NetworkActorMessage::new_command(
            NetworkActorCommand::ProcessBroadcastMessage(BroadcastMessage::NodeAnnouncement(
                node_announcement.clone(),
            )),
        ))?;

        let announce_node_interval_seconds = config.announce_node_interval_seconds();
        if announce_node_interval_seconds > 0 {
            myself.send_interval(Duration::from_secs(announce_node_interval_seconds), || {
                NetworkActorMessage::new_command(NetworkActorCommand::BroadcastLocalInfo(
                    LocalInfoKind::NodeAnnouncement,
                ))
            });
        }

        // Save bootnodes to the network actor state.
        state.persist_state();

        Ok(state)
    }

    async fn post_start(
        &self,
        myself: ActorRef<Self::Msg>,
        state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        debug!("Trying to connect to peers with mutual channels");
        for (peer_id, channel_id, channel_state) in self.store.get_channel_states(None) {
            let addresses = state.get_peer_addresses(&peer_id);

            debug!(
                "Reconnecting channel {:x} peers {:?} in state {:?} with addresses {:?}",
                &channel_id, &peer_id, &channel_state, &addresses
            );
            for addr in addresses {
                myself
                    .send_message(NetworkActorMessage::new_command(
                        NetworkActorCommand::ConnectPeer(addr),
                    ))
                    .expect(ASSUME_NETWORK_MYSELF_ALIVE);
            }
        }

        myself
            .send_message(NetworkActorMessage::new_command(
                NetworkActorCommand::MaintainConnections,
            ))
            .expect(ASSUME_NETWORK_MYSELF_ALIVE);
        myself.send_interval(MAINTAINING_CONNECTIONS_INTERVAL, || {
            NetworkActorMessage::new_command(NetworkActorCommand::MaintainConnections)
        });
        Ok(())
    }

    async fn handle(
        &self,
        myself: ActorRef<Self::Msg>,
        message: Self::Msg,
        state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        match message {
            NetworkActorMessage::Event(event) => {
                if let Err(err) = self.handle_event(myself, state, event).await {
                    error!("Failed to handle fiber network event: {}", err);
                }
            }
            NetworkActorMessage::Command(command) => {
                if let Err(err) = self.handle_command(myself, state, command).await {
                    error!("Failed to handle fiber network command: {}", err);
                }
            }
            NetworkActorMessage::Notification(event) => {
                if let Err(err) = self.event_sender.send(event).await {
                    error!("Failed to notify outside observers: {}", err);
                }
            }
        }
        Ok(())
    }

    async fn post_stop(
        &self,
        _myself: ActorRef<Self::Msg>,
        state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        if let Err(err) = state.control.close().await {
            error!("Failed to close tentacle service: {}", err);
        }
        debug!("Saving network actor state for {:?}", state.peer_id);
        state.persist_state();
        debug!("Network service for {:?} shutdown", state.peer_id);
        // The event receiver may have been closed already.
        // We ignore the error here.
        let _ = self
            .event_sender
            .send(NetworkServiceEvent::NetworkStopped(state.peer_id.clone()))
            .await;
        Ok(())
    }

    async fn handle_supervisor_evt(
        &self,
        _myself: ActorRef<Self::Msg>,
        message: SupervisionEvent,
        _state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        match message {
            SupervisionEvent::ActorTerminated(who, _, _) => {
                debug!("Actor {:?} terminated", who);
            }
            SupervisionEvent::ActorFailed(who, err) => {
                panic!("Actor unexpectedly panicked (id: {:?}): {:?}", who, err);
            }
            _ => {}
        }
        Ok(())
    }
}

#[derive(Clone, Debug)]
struct FiberProtocolHandle {
    actor: ActorRef<NetworkActorMessage>,
}

impl FiberProtocolHandle {
    fn create_meta(self) -> ProtocolMeta {
        MetaBuilder::new()
            .id(FIBER_PROTOCOL_ID)
            .service_handle(move || {
                let handle = Box::new(self);
                ProtocolHandle::Callback(handle)
            })
            .build()
    }
}

#[async_trait]
impl ServiceProtocol for FiberProtocolHandle {
    async fn init(&mut self, _context: &mut ProtocolContext) {}

    async fn connected(&mut self, context: ProtocolContextMutRef<'_>, _version: &str) {
        let _session = context.session;
        if let Some(remote_pubkey) = context.session.remote_pubkey.clone() {
            let remote_peer_id = PeerId::from_public_key(&remote_pubkey);
            try_send_actor_message(
                &self.actor,
                NetworkActorMessage::new_event(NetworkActorEvent::PeerConnected(
                    remote_peer_id,
                    remote_pubkey.into(),
                    context.session.clone(),
                )),
            );
        } else {
            warn!("Peer connected without remote pubkey {:?}", context.session);
        }
    }

    async fn disconnected(&mut self, context: ProtocolContextMutRef<'_>) {
        match context.session.remote_pubkey.as_ref() {
            Some(pubkey) => {
                let peer_id = PeerId::from_public_key(pubkey);
                try_send_actor_message(
                    &self.actor,
                    NetworkActorMessage::new_event(NetworkActorEvent::PeerDisconnected(
                        peer_id,
                        context.session.clone(),
                    )),
                );
            }
            None => {
                unreachable!("Received message without remote pubkey");
            }
        }
    }

    async fn received(&mut self, context: ProtocolContextMutRef<'_>, data: Bytes) {
        let msg = unwrap_or_return!(FiberMessage::from_molecule_slice(&data), "parse message");
        match context.session.remote_pubkey.as_ref() {
            Some(pubkey) => {
                let peer_id = PeerId::from_public_key(pubkey);
                try_send_actor_message(
                    &self.actor,
                    NetworkActorMessage::new_event(NetworkActorEvent::FiberMessage(peer_id, msg)),
                );
            }
            None => {
                unreachable!("Received message without remote pubkey");
            }
        }
    }

    async fn notify(&mut self, _context: &mut ProtocolContext, _token: u64) {}
}

#[derive(Clone, Debug)]
struct MyServiceHandle {
    actor: ActorRef<NetworkActorMessage>,
}

impl MyServiceHandle {
    fn new(actor: ActorRef<NetworkActorMessage>) -> Self {
        MyServiceHandle { actor }
    }
}

impl From<&MyServiceHandle> for FiberProtocolHandle {
    fn from(handle: &MyServiceHandle) -> Self {
        FiberProtocolHandle {
            actor: handle.actor.clone(),
        }
    }
}

#[async_trait]
impl ServiceHandle for MyServiceHandle {
    async fn handle_error(&mut self, _context: &mut ServiceContext, error: ServiceError) {
        trace!("Service error: {:?}", error);
        // TODO
        // ServiceError::DialerError => remove address from peer store
        // ServiceError::ProtocolError => ban peer
    }
    async fn handle_event(&mut self, _context: &mut ServiceContext, event: ServiceEvent) {
        trace!("Service event: {:?}", event);
    }
}

// If we are closing the whole network service, we may have already stopped the network actor.
// In that case the send_message will fail.
// Ideally, we should close tentacle network service first, then stop the network actor.
// But ractor provides only api for `post_stop` instead of `pre_stop`.
fn try_send_actor_message(actor: &ActorRef<NetworkActorMessage>, message: NetworkActorMessage) {
    let _ = actor.send_message(message);
}

#[allow(clippy::too_many_arguments)]
pub async fn start_network<
    S: NetworkActorStateStore
        + ChannelActorStateStore
        + NetworkGraphStateStore
        + GossipMessageStore
        + InvoiceStore
        + Clone
        + Send
        + Sync
        + 'static,
>(
    config: FiberConfig,
    chain_actor: ActorRef<CkbChainMessage>,
    event_sender: mpsc::Sender<NetworkServiceEvent>,
    tracker: TaskTracker,
    root_actor: ActorCell,
    store: S,
    channel_subscribers: ChannelSubscribers,
    network_graph: Arc<RwLock<NetworkGraph<S>>>,
    default_shutdown_script: Script,
) -> ActorRef<NetworkActorMessage> {
    let my_pubkey = config.public_key();
    let my_peer_id = PeerId::from_public_key(&my_pubkey);

    let (actor, _handle) = Actor::spawn_linked(
        Some(format!("Network {}", my_peer_id)),
        NetworkActor::new(event_sender, chain_actor, store, network_graph),
        NetworkActorStartArguments {
            config,
            tracker,
            channel_subscribers,
            default_shutdown_script,
        },
        root_actor,
    )
    .await
    .expect("Failed to start network actor");

    actor
}


================================================
File: src/fiber/path.rs
================================================
use super::graph::PathEdge;
use super::types::Pubkey;
use std::cmp::Ordering;
use std::collections::BinaryHeap;

#[derive(Clone, Debug)]
pub(crate) struct NodeHeapElement {
    // node_id is the vertex itself.
    // This can be used to explore all the outgoing edges (channels) emanating from a node.
    pub node_id: Pubkey,

    // The cost from this node to destination node.
    pub weight: u128,

    // The distance from source node to this node.
    pub distance: u128,

    // The amount to send to next node.
    pub amount_to_send: u128,

    // The fee charged by this node.
    pub fee_charged: u128,

    // The probability of this node.
    pub probability: f64,

    // The expected aboslute expiry timestamp (in milliseconds) for the incoming HTLC of this Node
    pub incoming_tlc_expiry: u64,

    // next_hop is the edge this route comes from, we also include the fee rate and tlc expiry delta.
    pub next_hop: Option<PathEdge>,
}

impl Ord for NodeHeapElement {
    fn cmp(&self, other: &Self) -> Ordering {
        if self.distance == other.distance {
            // Use partial_cmp and unwrap_or to handle NaN values
            self.probability
                .partial_cmp(&other.probability)
                .unwrap_or(Ordering::Equal)
        } else {
            other.distance.cmp(&self.distance)
        }
    }
}

impl PartialOrd for NodeHeapElement {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

// Implement PartialEq for custom comparison
impl PartialEq for NodeHeapElement {
    fn eq(&self, other: &Self) -> bool {
        self.node_id == other.node_id
            && self.weight == other.weight
            && self.distance == other.distance
            && self.amount_to_send == other.amount_to_send
            && self.fee_charged == other.fee_charged
            && self.probability == other.probability
            && self.incoming_tlc_expiry == other.incoming_tlc_expiry
            && self.next_hop == other.next_hop
    }
}

// Implement Eq for custom comparison
impl Eq for NodeHeapElement {}

pub(crate) struct NodeHeap {
    inner: BinaryHeap<NodeHeapElement>,
}

impl NodeHeap {
    pub fn new(num: usize) -> Self {
        Self {
            inner: BinaryHeap::with_capacity(num),
        }
    }

    pub fn push(&mut self, element: NodeHeapElement) {
        self.inner.push(element);
    }

    pub fn pop(&mut self) -> Option<NodeHeapElement> {
        self.inner.pop()
    }

    #[allow(dead_code)]
    pub fn is_empty(&self) -> bool {
        self.inner.is_empty()
    }

    #[allow(dead_code)]
    pub fn peek(&self) -> Option<&NodeHeapElement> {
        self.inner.peek()
    }

    pub fn push_or_fix(&mut self, element: NodeHeapElement) {
        // Remove the element with the same node_id if it exists
        self.inner.retain(|e| e.node_id != element.node_id);
        // Push the new element
        self.inner.push(element);
    }
}


================================================
File: src/fiber/serde_utils.rs
================================================
use molecule::prelude::Entity;
use musig2::{BinaryEncoding, CompactSignature, PubNonce, SCHNORR_SIGNATURE_SIZE};
use serde::{de::Error, Deserialize, Deserializer, Serializer};
use serde_with::{serde_conv, DeserializeAs, SerializeAs};

pub fn from_hex<'de, D, E>(deserializer: D) -> Result<E, D::Error>
where
    D: Deserializer<'de>,
    E: TryFrom<Vec<u8>>,
    E::Error: core::fmt::Debug,
{
    String::deserialize(deserializer)
        .and_then(|string| {
            if string.len() < 2 || &string[..2].to_lowercase() != "0x" {
                return Err(Error::custom(format!(
                    "hex string does not start with 0x: {}",
                    &string
                )));
            };
            hex::decode(&string[2..]).map_err(|err| {
                Error::custom(format!(
                    "failed to decode hex string {}: {:?}",
                    &string, err
                ))
            })
        })
        .and_then(|vec| {
            vec.try_into().map_err(|err| {
                Error::custom(format!("failed to convert vector into type: {:?}", err))
            })
        })
}

pub fn to_hex<E, S>(e: E, serializer: S) -> Result<S::Ok, S::Error>
where
    E: AsRef<[u8]>,
    S: Serializer,
{
    serializer.serialize_str(&format!("0x{}", &hex::encode(e.as_ref())))
}

pub struct SliceHex;

impl<T> SerializeAs<T> for SliceHex
where
    T: AsRef<[u8]>,
{
    fn serialize_as<S>(source: &T, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        to_hex(source, serializer)
    }
}

impl<'de, T> DeserializeAs<'de, T> for SliceHex
where
    T: TryFrom<Vec<u8>>,
    T::Error: core::fmt::Debug,
{
    fn deserialize_as<D>(deserializer: D) -> Result<T, D::Error>
    where
        D: Deserializer<'de>,
    {
        from_hex(deserializer)
    }
}

pub struct EntityHex;

impl<T> SerializeAs<T> for EntityHex
where
    T: Entity,
{
    fn serialize_as<S>(source: &T, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        to_hex(source.as_slice(), serializer)
    }
}

impl<'de, T> DeserializeAs<'de, T> for EntityHex
where
    T: Entity,
{
    fn deserialize_as<D>(deserializer: D) -> Result<T, D::Error>
    where
        D: Deserializer<'de>,
    {
        let v: Vec<u8> = from_hex(deserializer)?;
        T::from_slice(&v).map_err(Error::custom)
    }
}

macro_rules! uint_as_hex {
    ($name:ident, $ty:ty) => {
        serde_conv!(
            pub $name,
            $ty,
            |u: &$ty| format!("0x{:x}", u),
            |hex: &str| -> Result<$ty, String> {
                let bytes = hex.as_bytes();
                if bytes.len() < 3 || &bytes[..2] != b"0x" {
                    return Err(format!("uint hex string does not start with 0x: {}", hex));
                }
                if bytes.len() > 3 && &bytes[2..3] == b"0" {
                    return Err(format!("uint hex string starts with redundant leading zeros: {}", hex));
                };
                <$ty>::from_str_radix(&hex[2..], 16)
                    .map_err(|err| format!("failed to parse uint hex {}: {:?}", hex, err))
            }
        );
    };
}

uint_as_hex!(U128Hex, u128);
uint_as_hex!(U64Hex, u64);
uint_as_hex!(U32Hex, u32);
uint_as_hex!(U16Hex, u16);

pub struct CompactSignatureAsBytes;

impl SerializeAs<CompactSignature> for CompactSignatureAsBytes {
    fn serialize_as<S>(signature: &CompactSignature, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        serializer.serialize_bytes(&signature.to_bytes())
    }
}

impl<'de> DeserializeAs<'de, CompactSignature> for CompactSignatureAsBytes {
    fn deserialize_as<D>(deserializer: D) -> Result<CompactSignature, D::Error>
    where
        D: Deserializer<'de>,
    {
        let bytes: Vec<u8> = Deserialize::deserialize(deserializer)?;
        if bytes.len() != SCHNORR_SIGNATURE_SIZE {
            return Err(serde::de::Error::custom("expected 64 bytes"));
        }
        CompactSignature::from_bytes(&bytes).map_err(serde::de::Error::custom)
    }
}

pub struct PubNonceAsBytes;

impl SerializeAs<PubNonce> for PubNonceAsBytes {
    fn serialize_as<S>(nonce: &PubNonce, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        serializer.serialize_bytes(&nonce.to_bytes())
    }
}

impl<'de> DeserializeAs<'de, PubNonce> for PubNonceAsBytes {
    fn deserialize_as<D>(deserializer: D) -> Result<PubNonce, D::Error>
    where
        D: Deserializer<'de>,
    {
        let bytes: Vec<u8> = Deserialize::deserialize(deserializer)?;
        if bytes.len() != 66 {
            return Err(serde::de::Error::custom("expected 66 bytes"));
        }
        PubNonce::from_bytes(&bytes).map_err(serde::de::Error::custom)
    }
}


================================================
File: src/fiber/types.rs
================================================
use super::channel::{ChannelFlags, ChannelTlcInfo, ProcessingChannelError};
use super::config::AnnouncedNodeName;
use super::gen::fiber::{
    self as molecule_fiber, ChannelUpdateOpt, PaymentPreimageOpt, PubNonce as Byte66, PubkeyOpt,
    TlcErrDataOpt, UdtCellDeps, Uint128Opt,
};
use super::gen::gossip::{self as molecule_gossip};
use super::hash_algorithm::{HashAlgorithm, UnknownHashAlgorithmError};
use super::network::get_chain_hash;
use super::r#gen::fiber::PubNonceOpt;
use super::serde_utils::{EntityHex, SliceHex};
use crate::ckb::config::{UdtArgInfo, UdtCellDep, UdtCfgInfos, UdtScript};
use crate::ckb::contracts::get_udt_whitelist;
use ckb_jsonrpc_types::CellOutput;
use num_enum::IntoPrimitive;
use num_enum::TryFromPrimitive;
use std::convert::TryFrom;
use std::fmt::Debug;

use anyhow::anyhow;
use ckb_types::{
    core::FeeRate,
    packed::{Byte32 as MByte32, BytesVec, OutPoint, Script, Transaction},
    prelude::{Pack, Unpack},
};
use core::fmt::{self, Formatter};
use fiber_sphinx::{OnionErrorPacket, SphinxError};
use molecule::prelude::{Builder, Byte, Entity};
use musig2::errors::DecodeError;
use musig2::secp::{Point, Scalar};
use musig2::{BinaryEncoding, PartialSignature, PubNonce};
use once_cell::sync::OnceCell;
use ractor::concurrency::Duration;
use secp256k1::{
    ecdsa::Signature as Secp256k1Signature, schnorr::Signature as SchnorrSignature, All, PublicKey,
    Secp256k1, SecretKey, Signing,
};
use secp256k1::{Verification, XOnlyPublicKey};
use serde::{Deserialize, Serialize};
use serde_with::serde_as;
use std::cmp::Ordering;
use std::fmt::Display;
use std::marker::PhantomData;
use std::str::FromStr;
use strum::{AsRefStr, EnumString};
use tentacle::multiaddr::MultiAddr;
use tentacle::secio::PeerId;
use thiserror::Error;
use tracing::{error, trace};

pub fn secp256k1_instance() -> &'static Secp256k1<All> {
    static INSTANCE: OnceCell<Secp256k1<All>> = OnceCell::new();
    INSTANCE.get_or_init(Secp256k1::new)
}

bitflags::bitflags! {
    #[derive(Copy, Clone, Debug, PartialEq, Eq, Hash, Serialize, Deserialize)]
    #[serde(transparent)]
    pub struct ChannelUpdateChannelFlags: u32 {
        const DISABLED = 1;
    }
    #[derive(Copy, Clone, Debug, PartialEq, Eq, Hash, Serialize, Deserialize)]
    #[serde(transparent)]
    pub struct ChannelUpdateMessageFlags: u32 {
        const UPDATE_OF_NODE1 = 0;
        const UPDATE_OF_NODE2 = 1;
    }
}

impl From<&Byte66> for PubNonce {
    fn from(value: &Byte66) -> Self {
        PubNonce::from_bytes(value.as_slice()).expect("PubNonce from Byte66")
    }
}

impl From<&PubNonce> for Byte66 {
    fn from(value: &PubNonce) -> Self {
        Byte66::from_slice(&value.to_bytes()).expect("valid pubnonce serialized to 66 bytes")
    }
}

#[derive(Debug, Clone, Eq, PartialEq, Serialize, Deserialize)]
pub struct Privkey(pub SecretKey);

impl From<Privkey> for Scalar {
    fn from(pk: Privkey) -> Self {
        pk.0.into()
    }
}

impl From<&Privkey> for Scalar {
    fn from(pk: &Privkey) -> Self {
        pk.0.into()
    }
}

impl From<[u8; 32]> for Privkey {
    fn from(k: [u8; 32]) -> Self {
        Privkey(SecretKey::from_slice(&k).expect("Invalid secret key"))
    }
}

impl From<Scalar> for Privkey {
    fn from(scalar: Scalar) -> Self {
        scalar.serialize().into()
    }
}

impl From<Hash256> for Privkey {
    fn from(hash: Hash256) -> Self {
        let mut bytes = [0u8; 32];
        bytes.copy_from_slice(hash.as_ref());
        Privkey::from_slice(&bytes)
    }
}

impl From<Privkey> for SecretKey {
    fn from(pk: Privkey) -> Self {
        pk.0
    }
}

impl From<SecretKey> for Privkey {
    fn from(sk: SecretKey) -> Self {
        Self(sk)
    }
}

impl From<&[u8; 32]> for Privkey {
    fn from(k: &[u8; 32]) -> Self {
        Self::from_slice(k)
    }
}

impl AsRef<[u8; 32]> for Privkey {
    /// Gets a reference to the underlying array.
    ///
    /// # Side channel attacks
    ///
    /// Using ordering functions (`PartialOrd`/`Ord`) on a reference to secret keys leaks data
    /// because the implementations are not constant time. Doing so will make your code vulnerable
    /// to side channel attacks. [`SecretKey::eq`] is implemented using a constant time algorithm,
    /// please consider using it to do comparisons of secret keys.
    #[inline]
    fn as_ref(&self) -> &[u8; 32] {
        self.0.as_ref()
    }
}

/// A 256-bit hash digest, used as identifier of channnel, payment, transaction hash etc.
#[serde_as]
#[derive(Copy, Clone, Serialize, Deserialize, Hash, Eq, PartialEq, Default)]
pub struct Hash256(#[serde_as(as = "SliceHex")] [u8; 32]);

impl From<[u8; 32]> for Hash256 {
    fn from(value: [u8; 32]) -> Self {
        Self(value)
    }
}

impl AsRef<[u8]> for Hash256 {
    fn as_ref(&self) -> &[u8] {
        &self.0
    }
}

impl From<&Hash256> for MByte32 {
    fn from(hash: &Hash256) -> Self {
        MByte32::from_slice(hash.0.as_ref()).expect("Byte32 from Hash256")
    }
}

impl From<Hash256> for MByte32 {
    fn from(hash: Hash256) -> Self {
        (&hash).into()
    }
}

impl From<&MByte32> for Hash256 {
    fn from(value: &MByte32) -> Self {
        Hash256(value.as_slice().try_into().expect("Hash256 from Byte32"))
    }
}

impl From<MByte32> for Hash256 {
    fn from(value: MByte32) -> Self {
        (&value).into()
    }
}

fn u8_32_as_byte_32(value: &[u8; 32]) -> MByte32 {
    MByte32::from_slice(value.as_slice()).expect("[u8; 32] to Byte32")
}

impl ::core::fmt::LowerHex for Hash256 {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex::encode(self.0))
    }
}

impl ::core::fmt::Debug for Hash256 {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "Hash256({:#x})", self)
    }
}

impl ::core::fmt::Display for Hash256 {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        let raw_data = hex::encode(self.0);
        write!(f, "Hash256(0x{})", raw_data)
    }
}

impl FromStr for Hash256 {
    type Err = anyhow::Error;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        let s = s.trim_start_matches("0x");
        let bytes = hex::decode(s)?;
        if bytes.len() != 32 {
            return Err(anyhow!("Invalid hash length"));
        }
        let mut data = [0u8; 32];
        data.copy_from_slice(&bytes);
        Ok(Hash256(data))
    }
}

impl Privkey {
    pub fn from_slice(key: &[u8]) -> Self {
        SecretKey::from_slice(key)
            .expect("Invalid secret key")
            .into()
    }

    pub fn pubkey(&self) -> Pubkey {
        Pubkey::from(self.0.public_key(secp256k1_instance()))
    }

    pub fn tweak<I: Into<[u8; 32]>>(&self, scalar: I) -> Self {
        let scalar = scalar.into();
        let scalar = Scalar::from_slice(&scalar)
            .expect(format!("Value {:?} must be within secp256k1 scalar range. If you generated this value from hash function, then your hash function is busted.", &scalar).as_str());
        let sk = Scalar::from(self);
        (scalar + sk)
            .not_zero()
            .expect("valid secp256k1 scalar addition")
            .into()
    }

    pub fn sign(&self, message: [u8; 32]) -> EcdsaSignature {
        let message = secp256k1::Message::from_digest(message);
        secp256k1_instance().sign_ecdsa(&message, &self.0).into()
    }

    pub fn x_only_pub_key(&self) -> XOnlyPublicKey {
        let secp256k1_instance = secp256k1_instance();
        let secret_key = self.0;
        let keypair = secp256k1::Keypair::from_secret_key(secp256k1_instance, &secret_key);
        XOnlyPublicKey::from_keypair(&keypair).0
    }

    pub fn sign_schnorr(&self, message: [u8; 32]) -> SchnorrSignature {
        let secp256k1_instance = secp256k1_instance();
        let secret_key = self.0;
        let keypair = secp256k1::Keypair::from_secret_key(secp256k1_instance, &secret_key);
        let message = secp256k1::Message::from_digest(message);
        let sig = secp256k1_instance.sign_schnorr(&message, &keypair);
        trace!(
            "Schnorr signing message {:?} with private key {:?} (pub key {:?}), Signature: {:?}",
            message,
            keypair.secret_key(),
            keypair.public_key(),
            &sig
        );
        sig
    }
}

/// The public key for a Node
#[derive(Copy, Clone, Debug, PartialOrd, Ord, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct Pubkey(pub PublicKey);

impl From<Pubkey> for Point {
    fn from(val: Pubkey) -> Self {
        PublicKey::from(val).into()
    }
}

impl From<&Pubkey> for Point {
    fn from(val: &Pubkey) -> Self {
        (*val).into()
    }
}

impl From<&Pubkey> for PublicKey {
    fn from(val: &Pubkey) -> Self {
        val.0
    }
}

impl From<Pubkey> for PublicKey {
    fn from(pk: Pubkey) -> Self {
        pk.0
    }
}

impl From<PublicKey> for Pubkey {
    fn from(pk: PublicKey) -> Pubkey {
        Pubkey(pk)
    }
}

impl From<Point> for Pubkey {
    fn from(point: Point) -> Self {
        PublicKey::from(point).into()
    }
}

impl From<tentacle::secio::PublicKey> for Pubkey {
    fn from(pk: tentacle::secio::PublicKey) -> Self {
        secp256k1::PublicKey::from_slice(pk.inner_ref())
            .expect("valid tentacle pubkey can be converted to secp pubkey")
            .into()
    }
}

impl From<Pubkey> for tentacle::secio::PublicKey {
    fn from(pk: Pubkey) -> Self {
        tentacle::secio::PublicKey::from_raw_key(pk.serialize().to_vec())
    }
}

const PUBKEY_SIZE: usize = 33;
impl Pubkey {
    pub const fn serialization_len() -> usize {
        PUBKEY_SIZE
    }

    pub fn serialize(&self) -> [u8; PUBKEY_SIZE] {
        PublicKey::from(self).serialize()
    }

    pub fn from_slice(slice: &[u8]) -> Result<Self, secp256k1::Error> {
        PublicKey::from_slice(slice).map(Into::into)
    }

    pub fn tweak<I: Into<[u8; 32]>>(&self, scalar: I) -> Self {
        let scalar = scalar.into();
        let scalar = Scalar::from_slice(&scalar)
            .expect(format!("Value {:?} must be within secp256k1 scalar range. If you generated this value from hash function, then your hash function is busted.", &scalar).as_str());
        let result = Point::from(self) + scalar.base_point_mul();
        PublicKey::from(result.not_inf().expect("valid public key")).into()
    }

    pub fn tentacle_peer_id(&self) -> PeerId {
        let pubkey = (*self).into();
        PeerId::from_public_key(&pubkey)
    }
}

#[derive(Clone, PartialOrd, Ord, PartialEq, Eq, Hash, Serialize, Deserialize, Debug)]
pub struct EcdsaSignature(pub Secp256k1Signature);

impl EcdsaSignature {
    pub fn verify(&self, pubkey: &Pubkey, message: &[u8; 32]) -> bool {
        let message = secp256k1::Message::from_digest(*message);
        secp256k1_instance()
            .verify_ecdsa(&message, &self.0, &pubkey.0)
            .is_ok()
    }
}

impl From<EcdsaSignature> for Secp256k1Signature {
    fn from(sig: EcdsaSignature) -> Self {
        sig.0
    }
}

impl From<Secp256k1Signature> for EcdsaSignature {
    fn from(sig: Secp256k1Signature) -> Self {
        Self(sig)
    }
}

/// The error type wrap various ser/de errors.
#[derive(Error, Debug)]
pub enum Error {
    /// Invalid pubkey/signature format
    #[error("Secp error: {0}")]
    Secp(#[from] secp256k1::Error),
    #[error("Molecule error: {0}")]
    Molecule(#[from] molecule::error::VerificationError),
    #[error("Tentacle multiaddr error: {0}")]
    TentacleMultiAddr(#[from] tentacle::multiaddr::Error),
    #[error("Musig2 error: {0}")]
    Musig2(String),
    #[error("Invalid onion packet")]
    OnionPacket(#[from] OnionPacketError),
    #[error("Error: {0}")]
    AnyHow(#[from] anyhow::Error),
}

#[derive(Error, Debug)]
pub enum OnionPacketError {
    #[error("Try to peel the last hop")]
    PeelingLastHop,

    #[error("Fail to deserialize the hop data")]
    InvalidHopData,

    #[error("Sphinx protocol error")]
    Sphinx(#[from] SphinxError),
}

impl From<Pubkey> for molecule_fiber::Pubkey {
    fn from(pk: Pubkey) -> molecule_fiber::Pubkey {
        molecule_fiber::Pubkey::new_builder()
            .set(
                pk.0.serialize()
                    .into_iter()
                    .map(Into::into)
                    .collect::<Vec<Byte>>()
                    .try_into()
                    .expect("Public serialized to corrent length"),
            )
            .build()
    }
}

impl TryFrom<molecule_fiber::Pubkey> for Pubkey {
    type Error = Error;

    fn try_from(pubkey: molecule_fiber::Pubkey) -> Result<Self, Self::Error> {
        let pubkey = pubkey.as_slice();
        Ok(Self::from_slice(pubkey)?)
    }
}

impl From<EcdsaSignature> for molecule_fiber::EcdsaSignature {
    fn from(signature: EcdsaSignature) -> molecule_fiber::EcdsaSignature {
        molecule_fiber::EcdsaSignature::new_builder()
            .set(
                signature
                    .0
                    .serialize_compact()
                    .into_iter()
                    .map(Into::into)
                    .collect::<Vec<Byte>>()
                    .try_into()
                    .expect("Signature serialized to corrent length"),
            )
            .build()
    }
}

impl TryFrom<molecule_fiber::EcdsaSignature> for EcdsaSignature {
    type Error = Error;

    fn try_from(signature: molecule_fiber::EcdsaSignature) -> Result<Self, Self::Error> {
        let signature = signature.raw_data();
        Secp256k1Signature::from_compact(&signature)
            .map(Into::into)
            .map_err(Into::into)
    }
}

impl From<XOnlyPublicKey> for molecule_gossip::SchnorrXOnlyPubkey {
    fn from(pk: XOnlyPublicKey) -> molecule_gossip::SchnorrXOnlyPubkey {
        molecule_gossip::SchnorrXOnlyPubkey::new_builder()
            .set(
                pk.serialize()
                    .into_iter()
                    .map(Into::into)
                    .collect::<Vec<Byte>>()
                    .try_into()
                    .expect("Public serialized to corrent length"),
            )
            .build()
    }
}

impl TryFrom<molecule_gossip::SchnorrXOnlyPubkey> for XOnlyPublicKey {
    type Error = Error;

    fn try_from(pubkey: molecule_gossip::SchnorrXOnlyPubkey) -> Result<Self, Self::Error> {
        let pubkey = pubkey.as_slice();
        XOnlyPublicKey::from_slice(pubkey).map_err(Into::into)
    }
}

impl From<SchnorrSignature> for molecule_gossip::SchnorrSignature {
    fn from(signature: SchnorrSignature) -> molecule_gossip::SchnorrSignature {
        molecule_gossip::SchnorrSignature::new_builder()
            .set(
                signature
                    .serialize()
                    .into_iter()
                    .map(Into::into)
                    .collect::<Vec<Byte>>()
                    .try_into()
                    .expect("Signature serialized to corrent length"),
            )
            .build()
    }
}

impl TryFrom<molecule_gossip::SchnorrSignature> for SchnorrSignature {
    type Error = Error;

    fn try_from(signature: molecule_gossip::SchnorrSignature) -> Result<Self, Self::Error> {
        let signature = signature.as_slice();
        SchnorrSignature::from_slice(signature)
            .map(Into::into)
            .map_err(Into::into)
    }
}

impl TryFrom<Byte66> for PubNonce {
    type Error = DecodeError<Self>;

    fn try_from(value: Byte66) -> Result<Self, Self::Error> {
        PubNonce::from_bytes(value.as_slice())
    }
}

#[derive(Clone, Debug)]
pub struct OpenChannel {
    pub chain_hash: Hash256,
    pub channel_id: Hash256,
    pub funding_udt_type_script: Option<Script>,
    pub funding_amount: u128,
    pub shutdown_script: Script,
    pub reserved_ckb_amount: u64,
    pub funding_fee_rate: u64,
    pub commitment_fee_rate: u64,
    pub commitment_delay_epoch: u64,
    pub max_tlc_value_in_flight: u128,
    pub max_tlc_number_in_flight: u64,
    pub funding_pubkey: Pubkey,
    pub tlc_basepoint: Pubkey,
    pub first_per_commitment_point: Pubkey,
    pub second_per_commitment_point: Pubkey,
    pub channel_announcement_nonce: Option<PubNonce>,
    pub next_local_nonce: PubNonce,
    pub channel_flags: ChannelFlags,
}

impl OpenChannel {
    pub fn all_ckb_amount(&self) -> u64 {
        if self.funding_udt_type_script.is_none() {
            self.funding_amount as u64 + self.reserved_ckb_amount
        } else {
            self.reserved_ckb_amount
        }
    }

    pub fn is_public(&self) -> bool {
        self.channel_flags.contains(ChannelFlags::PUBLIC)
    }
}

impl From<OpenChannel> for molecule_fiber::OpenChannel {
    fn from(open_channel: OpenChannel) -> Self {
        molecule_fiber::OpenChannel::new_builder()
            .chain_hash(open_channel.chain_hash.into())
            .channel_id(open_channel.channel_id.into())
            .funding_udt_type_script(open_channel.funding_udt_type_script.pack())
            .funding_amount(open_channel.funding_amount.pack())
            .reserved_ckb_amount(open_channel.reserved_ckb_amount.pack())
            .funding_fee_rate(open_channel.funding_fee_rate.pack())
            .commitment_fee_rate(open_channel.commitment_fee_rate.pack())
            .commitment_delay_epoch(open_channel.commitment_delay_epoch.pack())
            .max_tlc_value_in_flight(open_channel.max_tlc_value_in_flight.pack())
            .max_tlc_number_in_flight(open_channel.max_tlc_number_in_flight.pack())
            .shutdown_script(open_channel.shutdown_script)
            .funding_pubkey(open_channel.funding_pubkey.into())
            .tlc_basepoint(open_channel.tlc_basepoint.into())
            .first_per_commitment_point(open_channel.first_per_commitment_point.into())
            .second_per_commitment_point(open_channel.second_per_commitment_point.into())
            .next_local_nonce((&open_channel.next_local_nonce).into())
            .channel_annoucement_nonce(
                PubNonceOpt::new_builder()
                    .set(open_channel.channel_announcement_nonce.map(|x| (&x).into()))
                    .build(),
            )
            .channel_flags(open_channel.channel_flags.bits().into())
            .build()
    }
}

impl TryFrom<molecule_fiber::OpenChannel> for OpenChannel {
    type Error = Error;

    fn try_from(open_channel: molecule_fiber::OpenChannel) -> Result<Self, Self::Error> {
        Ok(OpenChannel {
            chain_hash: open_channel.chain_hash().into(),
            channel_id: open_channel.channel_id().into(),
            funding_udt_type_script: open_channel.funding_udt_type_script().to_opt(),
            funding_amount: open_channel.funding_amount().unpack(),
            reserved_ckb_amount: open_channel.reserved_ckb_amount().unpack(),
            shutdown_script: open_channel.shutdown_script(),
            funding_fee_rate: open_channel.funding_fee_rate().unpack(),
            commitment_fee_rate: open_channel.commitment_fee_rate().unpack(),
            commitment_delay_epoch: open_channel.commitment_delay_epoch().unpack(),
            max_tlc_value_in_flight: open_channel.max_tlc_value_in_flight().unpack(),
            max_tlc_number_in_flight: open_channel.max_tlc_number_in_flight().unpack(),
            funding_pubkey: open_channel.funding_pubkey().try_into()?,
            tlc_basepoint: open_channel.tlc_basepoint().try_into()?,
            first_per_commitment_point: open_channel.first_per_commitment_point().try_into()?,
            second_per_commitment_point: open_channel.second_per_commitment_point().try_into()?,
            next_local_nonce: open_channel
                .next_local_nonce()
                .try_into()
                .map_err(|err| Error::Musig2(format!("{err}")))?,
            channel_announcement_nonce: open_channel
                .channel_annoucement_nonce()
                .to_opt()
                .map(TryInto::try_into)
                .transpose()
                .map_err(|err| Error::Musig2(format!("{err}")))?,
            channel_flags: ChannelFlags::from_bits(open_channel.channel_flags().into()).ok_or(
                anyhow!("Invalid channel flags: {}", open_channel.channel_flags()),
            )?,
        })
    }
}

#[derive(Debug, Clone)]
pub struct AcceptChannel {
    pub channel_id: Hash256,
    pub funding_amount: u128,
    pub reserved_ckb_amount: u64,
    pub max_tlc_value_in_flight: u128,
    pub max_tlc_number_in_flight: u64,
    pub funding_pubkey: Pubkey,
    pub shutdown_script: Script,
    pub tlc_basepoint: Pubkey,
    pub first_per_commitment_point: Pubkey,
    pub second_per_commitment_point: Pubkey,
    pub channel_announcement_nonce: Option<PubNonce>,
    pub next_local_nonce: PubNonce,
}

impl From<AcceptChannel> for molecule_fiber::AcceptChannel {
    fn from(accept_channel: AcceptChannel) -> Self {
        molecule_fiber::AcceptChannel::new_builder()
            .channel_id(accept_channel.channel_id.into())
            .funding_amount(accept_channel.funding_amount.pack())
            .reserved_ckb_amount(accept_channel.reserved_ckb_amount.pack())
            .max_tlc_value_in_flight(accept_channel.max_tlc_value_in_flight.pack())
            .max_tlc_number_in_flight(accept_channel.max_tlc_number_in_flight.pack())
            .shutdown_script(accept_channel.shutdown_script)
            .funding_pubkey(accept_channel.funding_pubkey.into())
            .tlc_basepoint(accept_channel.tlc_basepoint.into())
            .first_per_commitment_point(accept_channel.first_per_commitment_point.into())
            .second_per_commitment_point(accept_channel.second_per_commitment_point.into())
            .channel_annoucement_nonce(
                PubNonceOpt::new_builder()
                    .set(
                        accept_channel
                            .channel_announcement_nonce
                            .map(|x| (&x).into()),
                    )
                    .build(),
            )
            .next_local_nonce((&accept_channel.next_local_nonce).into())
            .build()
    }
}

impl TryFrom<molecule_fiber::AcceptChannel> for AcceptChannel {
    type Error = Error;

    fn try_from(accept_channel: molecule_fiber::AcceptChannel) -> Result<Self, Self::Error> {
        Ok(AcceptChannel {
            channel_id: accept_channel.channel_id().into(),
            funding_amount: accept_channel.funding_amount().unpack(),
            shutdown_script: accept_channel.shutdown_script(),
            reserved_ckb_amount: accept_channel.reserved_ckb_amount().unpack(),
            max_tlc_value_in_flight: accept_channel.max_tlc_value_in_flight().unpack(),
            max_tlc_number_in_flight: accept_channel.max_tlc_number_in_flight().unpack(),
            funding_pubkey: accept_channel.funding_pubkey().try_into()?,
            tlc_basepoint: accept_channel.tlc_basepoint().try_into()?,
            first_per_commitment_point: accept_channel.first_per_commitment_point().try_into()?,
            second_per_commitment_point: accept_channel.second_per_commitment_point().try_into()?,
            channel_announcement_nonce: accept_channel
                .channel_annoucement_nonce()
                .to_opt()
                .map(TryInto::try_into)
                .transpose()
                .map_err(|err| Error::Musig2(format!("{err}")))?,
            next_local_nonce: accept_channel
                .next_local_nonce()
                .try_into()
                .map_err(|err| Error::Musig2(format!("{err}")))?,
        })
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CommitmentSigned {
    pub channel_id: Hash256,
    pub funding_tx_partial_signature: PartialSignature,
    pub commitment_tx_partial_signature: PartialSignature,
    pub next_local_nonce: PubNonce,
}

fn partial_signature_to_molecule(partial_signature: PartialSignature) -> MByte32 {
    MByte32::from_slice(partial_signature.serialize().as_ref()).expect("[Byte; 32] from [u8; 32]")
}

impl From<CommitmentSigned> for molecule_fiber::CommitmentSigned {
    fn from(commitment_signed: CommitmentSigned) -> Self {
        molecule_fiber::CommitmentSigned::new_builder()
            .channel_id(commitment_signed.channel_id.into())
            .funding_tx_partial_signature(partial_signature_to_molecule(
                commitment_signed.funding_tx_partial_signature,
            ))
            .commitment_tx_partial_signature(partial_signature_to_molecule(
                commitment_signed.commitment_tx_partial_signature,
            ))
            .next_local_nonce((&commitment_signed.next_local_nonce).into())
            .build()
    }
}

impl TryFrom<molecule_fiber::CommitmentSigned> for CommitmentSigned {
    type Error = Error;

    fn try_from(commitment_signed: molecule_fiber::CommitmentSigned) -> Result<Self, Self::Error> {
        Ok(CommitmentSigned {
            channel_id: commitment_signed.channel_id().into(),
            funding_tx_partial_signature: PartialSignature::from_slice(
                commitment_signed.funding_tx_partial_signature().as_slice(),
            )
            .map_err(|e| anyhow!(e))?,
            commitment_tx_partial_signature: PartialSignature::from_slice(
                commitment_signed
                    .commitment_tx_partial_signature()
                    .as_slice(),
            )
            .map_err(|e| anyhow!(e))?,
            next_local_nonce: commitment_signed
                .next_local_nonce()
                .try_into()
                .map_err(|e| anyhow!(format!("{e:?}")))?,
        })
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TxSignatures {
    pub channel_id: Hash256,
    pub witnesses: Vec<Vec<u8>>,
}

impl From<TxSignatures> for molecule_fiber::TxSignatures {
    fn from(tx_signatures: TxSignatures) -> Self {
        molecule_fiber::TxSignatures::new_builder()
            .channel_id(tx_signatures.channel_id.into())
            .witnesses(
                BytesVec::new_builder()
                    .set(
                        tx_signatures
                            .witnesses
                            .into_iter()
                            .map(|witness| witness.pack())
                            .collect(),
                    )
                    .build(),
            )
            .build()
    }
}

impl TryFrom<molecule_fiber::TxSignatures> for TxSignatures {
    type Error = Error;

    fn try_from(tx_signatures: molecule_fiber::TxSignatures) -> Result<Self, Self::Error> {
        Ok(TxSignatures {
            channel_id: tx_signatures.channel_id().into(),
            witnesses: tx_signatures
                .witnesses()
                .into_iter()
                .map(|witness| witness.unpack())
                .collect(),
        })
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChannelReady {
    pub channel_id: Hash256,
}

impl From<ChannelReady> for molecule_fiber::ChannelReady {
    fn from(channel_ready: ChannelReady) -> Self {
        molecule_fiber::ChannelReady::new_builder()
            .channel_id(channel_ready.channel_id.into())
            .build()
    }
}

impl TryFrom<molecule_fiber::ChannelReady> for ChannelReady {
    type Error = Error;

    fn try_from(channel_ready: molecule_fiber::ChannelReady) -> Result<Self, Self::Error> {
        Ok(ChannelReady {
            channel_id: channel_ready.channel_id().into(),
        })
    }
}

#[derive(Debug, Clone)]
pub enum TxCollaborationMsg {
    TxUpdate(TxUpdate),
    TxComplete(TxComplete),
}

#[derive(Debug, Clone)]
pub struct TxUpdate {
    pub channel_id: Hash256,
    pub tx: Transaction,
}

impl From<TxUpdate> for molecule_fiber::TxUpdate {
    fn from(tx_update: TxUpdate) -> Self {
        molecule_fiber::TxUpdate::new_builder()
            .channel_id(tx_update.channel_id.into())
            .tx(tx_update.tx)
            .build()
    }
}

impl TryFrom<molecule_fiber::TxUpdate> for TxUpdate {
    type Error = Error;

    fn try_from(tx_update: molecule_fiber::TxUpdate) -> Result<Self, Self::Error> {
        Ok(TxUpdate {
            channel_id: tx_update.channel_id().into(),
            tx: tx_update.tx(),
        })
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TxComplete {
    pub channel_id: Hash256,
    pub commitment_tx_partial_signature: PartialSignature,
}

impl From<TxComplete> for molecule_fiber::TxComplete {
    fn from(tx_complete: TxComplete) -> Self {
        molecule_fiber::TxComplete::new_builder()
            .channel_id(tx_complete.channel_id.into())
            .commitment_tx_partial_signature(partial_signature_to_molecule(
                tx_complete.commitment_tx_partial_signature,
            ))
            .build()
    }
}

impl TryFrom<molecule_fiber::TxComplete> for TxComplete {
    type Error = Error;

    fn try_from(tx_complete: molecule_fiber::TxComplete) -> Result<Self, Self::Error> {
        Ok(TxComplete {
            channel_id: tx_complete.channel_id().into(),
            commitment_tx_partial_signature: PartialSignature::from_slice(
                tx_complete.commitment_tx_partial_signature().as_slice(),
            )
            .map_err(|e| anyhow!(e))?,
        })
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TxAbort {
    pub channel_id: Hash256,
    pub message: Vec<u8>,
}

impl From<TxAbort> for molecule_fiber::TxAbort {
    fn from(tx_abort: TxAbort) -> Self {
        molecule_fiber::TxAbort::new_builder()
            .channel_id(tx_abort.channel_id.into())
            .message(tx_abort.message.pack())
            .build()
    }
}

impl TryFrom<molecule_fiber::TxAbort> for TxAbort {
    type Error = Error;

    fn try_from(tx_abort: molecule_fiber::TxAbort) -> Result<Self, Self::Error> {
        Ok(TxAbort {
            channel_id: tx_abort.channel_id().into(),
            message: tx_abort.message().unpack(),
        })
    }
}

#[derive(Debug, Clone)]
pub struct TxInitRBF {
    pub channel_id: Hash256,
    pub fee_rate: u64,
}

impl From<TxInitRBF> for molecule_fiber::TxInitRBF {
    fn from(tx_init_rbf: TxInitRBF) -> Self {
        molecule_fiber::TxInitRBF::new_builder()
            .channel_id(tx_init_rbf.channel_id.into())
            .fee_rate(tx_init_rbf.fee_rate.pack())
            .build()
    }
}

impl TryFrom<molecule_fiber::TxInitRBF> for TxInitRBF {
    type Error = Error;

    fn try_from(tx_init_rbf: molecule_fiber::TxInitRBF) -> Result<Self, Self::Error> {
        Ok(TxInitRBF {
            channel_id: tx_init_rbf.channel_id().into(),
            fee_rate: tx_init_rbf.fee_rate().unpack(),
        })
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TxAckRBF {
    pub channel_id: Hash256,
}

impl From<TxAckRBF> for molecule_fiber::TxAckRBF {
    fn from(tx_ack_rbf: TxAckRBF) -> Self {
        molecule_fiber::TxAckRBF::new_builder()
            .channel_id(tx_ack_rbf.channel_id.into())
            .build()
    }
}

impl TryFrom<molecule_fiber::TxAckRBF> for TxAckRBF {
    type Error = Error;

    fn try_from(tx_ack_rbf: molecule_fiber::TxAckRBF) -> Result<Self, Self::Error> {
        Ok(TxAckRBF {
            channel_id: tx_ack_rbf.channel_id().into(),
        })
    }
}

#[derive(Debug, Clone)]
pub struct Shutdown {
    pub channel_id: Hash256,
    pub close_script: Script,
    pub fee_rate: FeeRate,
}

impl From<Shutdown> for molecule_fiber::Shutdown {
    fn from(shutdown: Shutdown) -> Self {
        molecule_fiber::Shutdown::new_builder()
            .channel_id(shutdown.channel_id.into())
            .close_script(shutdown.close_script)
            .fee_rate(shutdown.fee_rate.as_u64().pack())
            .build()
    }
}

impl TryFrom<molecule_fiber::Shutdown> for Shutdown {
    type Error = Error;

    fn try_from(shutdown: molecule_fiber::Shutdown) -> Result<Self, Self::Error> {
        Ok(Shutdown {
            channel_id: shutdown.channel_id().into(),
            close_script: shutdown.close_script(),
            fee_rate: FeeRate::from_u64(shutdown.fee_rate().unpack()),
        })
    }
}

#[derive(Debug, Clone)]
pub struct ClosingSigned {
    pub channel_id: Hash256,
    pub partial_signature: PartialSignature,
}

impl From<ClosingSigned> for molecule_fiber::ClosingSigned {
    fn from(closing_signed: ClosingSigned) -> Self {
        molecule_fiber::ClosingSigned::new_builder()
            .channel_id(closing_signed.channel_id.into())
            .partial_signature(partial_signature_to_molecule(
                closing_signed.partial_signature,
            ))
            .build()
    }
}

impl TryFrom<molecule_fiber::ClosingSigned> for ClosingSigned {
    type Error = Error;

    fn try_from(closing_signed: molecule_fiber::ClosingSigned) -> Result<Self, Self::Error> {
        Ok(ClosingSigned {
            channel_id: closing_signed.channel_id().into(),
            partial_signature: PartialSignature::from_slice(
                closing_signed.partial_signature().as_slice(),
            )
            .map_err(|e| anyhow!(e))?,
        })
    }
}

#[derive(Debug, Clone, Eq, PartialEq, Serialize, Deserialize)]
pub struct UpdateTlcInfo {
    pub channel_id: Hash256,
    pub timestamp: u64,
    pub channel_flags: ChannelUpdateChannelFlags,
    pub tlc_expiry_delta: u64,
    pub tlc_minimum_value: u128,
    pub tlc_maximum_value: u128,
    pub tlc_fee_proportional_millionths: u128,
}

impl From<UpdateTlcInfo> for molecule_fiber::UpdateTlcInfo {
    fn from(update_tlc_info: UpdateTlcInfo) -> Self {
        molecule_fiber::UpdateTlcInfo::new_builder()
            .channel_id(update_tlc_info.channel_id.into())
            .timestamp(update_tlc_info.timestamp.pack())
            .channel_flags(update_tlc_info.channel_flags.bits().pack())
            .tlc_expiry_delta(update_tlc_info.tlc_expiry_delta.pack())
            .tlc_minimum_value(update_tlc_info.tlc_minimum_value.pack())
            .tlc_maximum_value(update_tlc_info.tlc_maximum_value.pack())
            .tlc_fee_proportional_millionths(update_tlc_info.tlc_fee_proportional_millionths.pack())
            .build()
    }
}

impl From<molecule_fiber::UpdateTlcInfo> for UpdateTlcInfo {
    fn from(update_tlc_info: molecule_fiber::UpdateTlcInfo) -> Self {
        UpdateTlcInfo {
            channel_id: update_tlc_info.channel_id().into(),
            timestamp: update_tlc_info.timestamp().unpack(),
            channel_flags: ChannelUpdateChannelFlags::from_bits_truncate(
                update_tlc_info.channel_flags().unpack(),
            ),
            tlc_expiry_delta: update_tlc_info.tlc_expiry_delta().unpack(),
            tlc_minimum_value: update_tlc_info.tlc_minimum_value().unpack(),
            tlc_maximum_value: update_tlc_info.tlc_maximum_value().unpack(),
            tlc_fee_proportional_millionths: update_tlc_info
                .tlc_fee_proportional_millionths()
                .unpack(),
        }
    }
}

impl From<UpdateTlcInfo> for ChannelTlcInfo {
    fn from(update_tlc_info: UpdateTlcInfo) -> Self {
        ChannelTlcInfo {
            timestamp: update_tlc_info.timestamp,
            enabled: !update_tlc_info
                .channel_flags
                .contains(ChannelUpdateChannelFlags::DISABLED),
            tlc_expiry_delta: update_tlc_info.tlc_expiry_delta,
            tlc_minimum_value: update_tlc_info.tlc_minimum_value,
            tlc_maximum_value: update_tlc_info.tlc_maximum_value,
            tlc_fee_proportional_millionths: update_tlc_info.tlc_fee_proportional_millionths,
        }
    }
}

#[derive(Debug, Clone, Eq, PartialEq, Serialize, Deserialize)]
pub struct AddTlc {
    pub channel_id: Hash256,
    pub tlc_id: u64,
    pub amount: u128,
    pub payment_hash: Hash256,
    pub expiry: u64,
    pub hash_algorithm: HashAlgorithm,
    pub onion_packet: Option<PaymentOnionPacket>,
}

impl From<AddTlc> for molecule_fiber::AddTlc {
    fn from(add_tlc: AddTlc) -> Self {
        molecule_fiber::AddTlc::new_builder()
            .channel_id(add_tlc.channel_id.into())
            .tlc_id(add_tlc.tlc_id.pack())
            .amount(add_tlc.amount.pack())
            .payment_hash(add_tlc.payment_hash.into())
            .expiry(add_tlc.expiry.pack())
            .hash_algorithm(Byte::new(add_tlc.hash_algorithm as u8))
            .onion_packet(
                add_tlc
                    .onion_packet
                    .map(|p| p.into_bytes())
                    .unwrap_or_default()
                    .pack(),
            )
            .build()
    }
}

impl TryFrom<molecule_fiber::AddTlc> for AddTlc {
    type Error = Error;

    fn try_from(add_tlc: molecule_fiber::AddTlc) -> Result<Self, Self::Error> {
        let onion_packet_bytes: Vec<u8> = add_tlc.onion_packet().unpack();
        let onion_packet =
            (!onion_packet_bytes.is_empty()).then(|| PaymentOnionPacket::new(onion_packet_bytes));
        Ok(AddTlc {
            onion_packet,
            channel_id: add_tlc.channel_id().into(),
            tlc_id: add_tlc.tlc_id().unpack(),
            amount: add_tlc.amount().unpack(),
            payment_hash: add_tlc.payment_hash().into(),
            expiry: add_tlc.expiry().unpack(),
            hash_algorithm: add_tlc
                .hash_algorithm()
                .try_into()
                .map_err(|err: UnknownHashAlgorithmError| Error::AnyHow(err.into()))?,
        })
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RevokeAndAck {
    pub channel_id: Hash256,
    pub revocation_partial_signature: PartialSignature,
    pub commitment_tx_partial_signature: PartialSignature,
    pub next_per_commitment_point: Pubkey,
}

impl From<RevokeAndAck> for molecule_fiber::RevokeAndAck {
    fn from(revoke_and_ack: RevokeAndAck) -> Self {
        molecule_fiber::RevokeAndAck::new_builder()
            .channel_id(revoke_and_ack.channel_id.into())
            .revocation_partial_signature(partial_signature_to_molecule(
                revoke_and_ack.revocation_partial_signature,
            ))
            .commitment_tx_partial_signature(partial_signature_to_molecule(
                revoke_and_ack.commitment_tx_partial_signature,
            ))
            .next_per_commitment_point(revoke_and_ack.next_per_commitment_point.into())
            .build()
    }
}

impl TryFrom<molecule_fiber::RevokeAndAck> for RevokeAndAck {
    type Error = Error;

    fn try_from(revoke_and_ack: molecule_fiber::RevokeAndAck) -> Result<Self, Self::Error> {
        Ok(RevokeAndAck {
            channel_id: revoke_and_ack.channel_id().into(),
            revocation_partial_signature: PartialSignature::from_slice(
                revoke_and_ack.revocation_partial_signature().as_slice(),
            )
            .map_err(|e| anyhow!(e))?,
            commitment_tx_partial_signature: PartialSignature::from_slice(
                revoke_and_ack.commitment_tx_partial_signature().as_slice(),
            )
            .map_err(|e| anyhow!(e))?,
            next_per_commitment_point: revoke_and_ack.next_per_commitment_point().try_into()?,
        })
    }
}

#[derive(Debug, Copy, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct RemoveTlcFulfill {
    pub payment_preimage: Hash256,
}

impl From<RemoveTlcFulfill> for molecule_fiber::RemoveTlcFulfill {
    fn from(remove_tlc_fulfill: RemoveTlcFulfill) -> Self {
        molecule_fiber::RemoveTlcFulfill::new_builder()
            .payment_preimage(remove_tlc_fulfill.payment_preimage.into())
            .build()
    }
}

impl TryFrom<molecule_fiber::RemoveTlcFulfill> for RemoveTlcFulfill {
    type Error = Error;

    fn try_from(remove_tlc_fulfill: molecule_fiber::RemoveTlcFulfill) -> Result<Self, Self::Error> {
        Ok(RemoveTlcFulfill {
            payment_preimage: remove_tlc_fulfill.payment_preimage().into(),
        })
    }
}

#[serde_as]
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum TlcErrData {
    ChannelFailed {
        #[serde_as(as = "EntityHex")]
        channel_outpoint: OutPoint,
        channel_update: Option<ChannelUpdate>,
        node_id: Pubkey,
    },
    NodeFailed {
        node_id: Pubkey,
    },
}

#[serde_as]
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct TlcErr {
    pub error_code: TlcErrorCode,
    pub extra_data: Option<TlcErrData>,
}

impl Display for TlcErr {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.error_code_as_str())
    }
}

impl TlcErr {
    pub fn new(error_code: TlcErrorCode) -> Self {
        TlcErr {
            error_code,
            extra_data: None,
        }
    }

    pub fn new_node_fail(error_code: TlcErrorCode, node_id: Pubkey) -> Self {
        TlcErr {
            error_code,
            extra_data: Some(TlcErrData::NodeFailed { node_id }),
        }
    }

    pub fn new_channel_fail(
        error_code: TlcErrorCode,
        node_id: Pubkey,
        channel_outpoint: OutPoint,
        channel_update: Option<ChannelUpdate>,
    ) -> Self {
        TlcErr {
            error_code,
            extra_data: Some(TlcErrData::ChannelFailed {
                node_id,
                channel_outpoint,
                channel_update,
            }),
        }
    }

    pub fn error_node_id(&self) -> Option<Pubkey> {
        match &self.extra_data {
            Some(TlcErrData::NodeFailed { node_id }) => Some(*node_id),
            Some(TlcErrData::ChannelFailed { node_id, .. }) => Some(*node_id),
            _ => None,
        }
    }

    pub fn error_channel_outpoint(&self) -> Option<OutPoint> {
        match &self.extra_data {
            Some(TlcErrData::ChannelFailed {
                channel_outpoint, ..
            }) => Some(channel_outpoint.clone()),
            _ => None,
        }
    }

    pub fn error_code(&self) -> TlcErrorCode {
        self.error_code
    }

    pub fn error_code_as_str(&self) -> String {
        let error_code: TlcErrorCode = self.error_code;
        error_code.as_ref().to_string()
    }

    pub fn error_code_as_u16(&self) -> u16 {
        self.error_code.into()
    }

    pub fn set_extra_data(&mut self, extra_data: TlcErrData) {
        self.extra_data = Some(extra_data);
    }

    fn serialize(&self) -> Vec<u8> {
        molecule_fiber::TlcErr::from(self.clone())
            .as_slice()
            .to_vec()
    }

    fn deserialize(data: &[u8]) -> Option<Self> {
        molecule_fiber::TlcErr::from_slice(data)
            .map(TlcErr::from)
            .ok()
    }
}

impl TryFrom<TlcErrData> for molecule_fiber::TlcErrData {
    type Error = Error;

    fn try_from(tlc_err_data: TlcErrData) -> Result<Self, Self::Error> {
        match tlc_err_data {
            TlcErrData::ChannelFailed {
                channel_outpoint,
                channel_update,
                node_id,
            } => Ok(molecule_fiber::ChannelFailed::new_builder()
                .channel_outpoint(channel_outpoint)
                .channel_update(
                    ChannelUpdateOpt::new_builder()
                        .set(channel_update.map(|x| x.into()))
                        .build(),
                )
                .node_id(node_id.into())
                .build()
                .into()),
            TlcErrData::NodeFailed { node_id } => Ok(molecule_fiber::NodeFailed::new_builder()
                .node_id(node_id.into())
                .build()
                .into()),
        }
    }
}

impl TryFrom<molecule_fiber::TlcErrData> for TlcErrData {
    type Error = Error;

    fn try_from(tlc_err_data: molecule_fiber::TlcErrData) -> Result<Self, Self::Error> {
        match tlc_err_data.to_enum() {
            molecule_fiber::TlcErrDataUnion::ChannelFailed(channel_failed) => {
                Ok(TlcErrData::ChannelFailed {
                    channel_outpoint: channel_failed.channel_outpoint(),
                    channel_update: channel_failed
                        .channel_update()
                        .to_opt()
                        .map(|x| x.try_into().unwrap()),
                    node_id: channel_failed.node_id().try_into()?,
                })
            }
            molecule_fiber::TlcErrDataUnion::NodeFailed(node_failed) => {
                Ok(TlcErrData::NodeFailed {
                    node_id: node_failed.node_id().try_into()?,
                })
            }
        }
    }
}

impl From<TlcErr> for molecule_fiber::TlcErr {
    fn from(tlc_err: TlcErr) -> Self {
        molecule_fiber::TlcErr::new_builder()
            .error_code(tlc_err.error_code_as_u16().into())
            .extra_data(
                TlcErrDataOpt::new_builder()
                    .set(tlc_err.extra_data.map(|data| data.try_into().unwrap()))
                    .build(),
            )
            .build()
    }
}

impl From<molecule_fiber::TlcErr> for TlcErr {
    fn from(tlc_err: molecule_fiber::TlcErr) -> Self {
        TlcErr {
            error_code: {
                let code: u16 = tlc_err.error_code().into();
                TlcErrorCode::try_from(code).expect("tlc_errror_code failed")
            },
            extra_data: tlc_err
                .extra_data()
                .to_opt()
                .map(|data| data.try_into().unwrap()),
        }
    }
}

// This is the onion packet we need to encode and send back to the sender,
// currently it's the raw TlcErr serialized data from the TlcErr struct,
// sender should decode it and then decide what to do with the error.
// Note: this supposed to be only accessible by the sender, and it's not reliable since it
//       is not placed on-chain due to the possibility of hop failure.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct TlcErrPacket {
    // TODO: replace this with the real onion packet
    pub onion_packet: Vec<u8>,
}

pub const NO_SHARED_SECRET: [u8; 32] = [0u8; 32];
const NO_ERROR_PACKET_HMAC: [u8; 32] = [0u8; 32];

/// Always decrypting 27 times so the erroring node cannot learn its relative position in the route
/// by performing a timing analysis if the sender were to retry the same route multiple times.
const ERROR_DECODING_PASSES: usize = 27;

impl TlcErrPacket {
    /// Erring node creates the error packet using the shared secret used in forwarding onion packet.
    /// Use all zeros for the origin node.
    pub fn new(tlc_fail: TlcErr, shared_secret: &[u8; 32]) -> Self {
        let payload = tlc_fail.serialize();

        let onion_packet = if shared_secret != &NO_SHARED_SECRET {
            OnionErrorPacket::create(shared_secret, payload)
        } else {
            OnionErrorPacket::concat(NO_ERROR_PACKET_HMAC, payload)
        }
        .into_bytes();
        TlcErrPacket { onion_packet }
    }

    pub fn is_plaintext(&self) -> bool {
        self.onion_packet.len() >= 32 && self.onion_packet[0..32] == NO_ERROR_PACKET_HMAC
    }

    /// Intermediate node backwards the error to the previous hop using the shared secret used in forwarding
    /// the onion packet.
    pub fn backward(self, shared_secret: &[u8; 32]) -> Self {
        if !self.is_plaintext() {
            let onion_packet = OnionErrorPacket::from_bytes(self.onion_packet)
                .xor_cipher_stream(shared_secret)
                .into_bytes();
            TlcErrPacket { onion_packet }
        } else {
            // If it is not encrypted, just send back as it is.
            self
        }
    }

    pub fn decode(&self, session_key: &[u8; 32], hops_public_keys: Vec<Pubkey>) -> Option<TlcErr> {
        if self.is_plaintext() {
            let error = TlcErr::deserialize(&self.onion_packet[32..]);
            if error.is_some() {
                return error;
            }
        }

        let hops_public_keys: Vec<PublicKey> = hops_public_keys.iter().map(|k| k.0).collect();
        let session_key = SecretKey::from_slice(session_key).inspect_err(|err|
            error!(target: "fnn::fiber::types::TlcErrPacket", "decode session_key error={} key={}", err, hex::encode(session_key))
        ).ok()?;
        OnionErrorPacket::from_bytes(self.onion_packet.clone())
            .parse(hops_public_keys, session_key, TlcErr::deserialize)
            .map(|(error, hop_index)| {
                for _ in hop_index..ERROR_DECODING_PASSES {
                    OnionErrorPacket::from_bytes(self.onion_packet.clone())
                        .xor_cipher_stream(&NO_SHARED_SECRET);
                }
                error
            })
    }
}

impl From<TlcErrPacket> for molecule_fiber::TlcErrPacket {
    fn from(remove_tlc_fail: TlcErrPacket) -> Self {
        molecule_fiber::TlcErrPacket::new_builder()
            .onion_packet(remove_tlc_fail.onion_packet.pack())
            .build()
    }
}

impl TryFrom<molecule_fiber::TlcErrPacket> for TlcErrPacket {
    type Error = Error;

    fn try_from(remove_tlc_fail: molecule_fiber::TlcErrPacket) -> Result<Self, Self::Error> {
        Ok(TlcErrPacket {
            onion_packet: remove_tlc_fail.onion_packet().unpack(),
        })
    }
}

impl std::fmt::Display for TlcErrPacket {
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        write!(f, "TlcErrPacket")
    }
}

// The onion packet is invalid
const BADONION: u16 = 0x8000;
// Permanent errors (otherwise transient)
const PERM: u16 = 0x4000;
// Node releated errors (otherwise channels)
const NODE: u16 = 0x2000;
// Channel forwarding parameter was violated
const UPDATE: u16 = 0x1000;

#[repr(u16)]
#[derive(
    Debug,
    Copy,
    Clone,
    Serialize,
    Deserialize,
    PartialEq,
    Eq,
    AsRefStr,
    EnumString,
    TryFromPrimitive,
    IntoPrimitive,
)]
pub enum TlcErrorCode {
    TemporaryNodeFailure = NODE | 2,
    PermanentNodeFailure = PERM | NODE | 2,
    // unused right now
    RequiredNodeFeatureMissing = PERM | NODE | 3,
    // unused right now, maybe need to add onion version in future?
    InvalidOnionVersion = BADONION | PERM | 4,
    InvalidOnionHmac = BADONION | PERM | 5,
    InvalidOnionKey = BADONION | PERM | 6,
    TemporaryChannelFailure = UPDATE | 7,
    // used for shutting down the channel
    PermanentChannelFailure = PERM | 8,
    RequiredChannelFeatureMissing = PERM | 9,
    UnknownNextPeer = PERM | 10,
    AmountBelowMinimum = UPDATE | 11,
    FeeInsufficient = UPDATE | 12,
    IncorrectTlcExpiry = UPDATE | 13,
    ExpiryTooSoon = PERM | 14,
    IncorrectOrUnknownPaymentDetails = PERM | 15,
    InvoiceExpired = PERM | 16,
    InvoiceCancelled = PERM | 17,
    FinalIncorrectExpiryDelta = 18,
    FinalIncorrectTlcAmount = 19,
    ChannelDisabled = UPDATE | 20,
    ExpiryTooFar = PERM | 21,
    InvalidOnionPayload = PERM | 22,
    InvalidOnionError = BADONION | PERM | 25,
}

impl TlcErrorCode {
    pub fn is_node(&self) -> bool {
        *self as u16 & NODE != 0
    }

    pub fn is_bad_onion(&self) -> bool {
        *self as u16 & BADONION != 0
    }

    pub fn is_perm(&self) -> bool {
        *self as u16 & PERM != 0
    }

    pub fn is_update(&self) -> bool {
        *self as u16 & UPDATE != 0
    }

    pub fn payment_failed(&self) -> bool {
        matches!(
            self,
            TlcErrorCode::IncorrectOrUnknownPaymentDetails
                | TlcErrorCode::FinalIncorrectExpiryDelta
                | TlcErrorCode::FinalIncorrectTlcAmount
                | TlcErrorCode::InvoiceExpired
                | TlcErrorCode::InvoiceCancelled
                | TlcErrorCode::ExpiryTooFar
                | TlcErrorCode::ExpiryTooSoon
        )
    }
}

#[derive(Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum RemoveTlcReason {
    RemoveTlcFulfill(RemoveTlcFulfill),
    RemoveTlcFail(TlcErrPacket),
}

impl Debug for RemoveTlcReason {
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        match self {
            RemoveTlcReason::RemoveTlcFulfill(_fulfill) => {
                write!(f, "RemoveTlcFulfill")
            }
            RemoveTlcReason::RemoveTlcFail(_fail) => {
                write!(f, "RemoveTlcFail")
            }
        }
    }
}

impl RemoveTlcReason {
    /// Intermediate node backwards the error to the previous hop using the shared secret used in forwarding
    /// the onion packet.
    pub fn backward(self, shared_secret: &[u8; 32]) -> Self {
        match self {
            RemoveTlcReason::RemoveTlcFulfill(remove_tlc_fulfill) => {
                RemoveTlcReason::RemoveTlcFulfill(remove_tlc_fulfill)
            }
            RemoveTlcReason::RemoveTlcFail(remove_tlc_fail) => {
                RemoveTlcReason::RemoveTlcFail(remove_tlc_fail.backward(shared_secret))
            }
        }
    }
}

impl From<RemoveTlcReason> for molecule_fiber::RemoveTlcReasonUnion {
    fn from(remove_tlc_reason: RemoveTlcReason) -> Self {
        match remove_tlc_reason {
            RemoveTlcReason::RemoveTlcFulfill(remove_tlc_fulfill) => {
                molecule_fiber::RemoveTlcReasonUnion::RemoveTlcFulfill(remove_tlc_fulfill.into())
            }
            RemoveTlcReason::RemoveTlcFail(remove_tlc_fail) => {
                molecule_fiber::RemoveTlcReasonUnion::TlcErrPacket(remove_tlc_fail.into())
            }
        }
    }
}

impl From<RemoveTlcReason> for molecule_fiber::RemoveTlcReason {
    fn from(remove_tlc_reason: RemoveTlcReason) -> Self {
        molecule_fiber::RemoveTlcReason::new_builder()
            .set(remove_tlc_reason)
            .build()
    }
}

impl TryFrom<molecule_fiber::RemoveTlcReason> for RemoveTlcReason {
    type Error = Error;

    fn try_from(remove_tlc_reason: molecule_fiber::RemoveTlcReason) -> Result<Self, Self::Error> {
        match remove_tlc_reason.to_enum() {
            molecule_fiber::RemoveTlcReasonUnion::RemoveTlcFulfill(remove_tlc_fulfill) => Ok(
                RemoveTlcReason::RemoveTlcFulfill(remove_tlc_fulfill.try_into()?),
            ),
            molecule_fiber::RemoveTlcReasonUnion::TlcErrPacket(remove_tlc_fail) => {
                Ok(RemoveTlcReason::RemoveTlcFail(remove_tlc_fail.try_into()?))
            }
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct RemoveTlc {
    pub channel_id: Hash256,
    pub tlc_id: u64,
    pub reason: RemoveTlcReason,
}

impl From<RemoveTlc> for molecule_fiber::RemoveTlc {
    fn from(remove_tlc: RemoveTlc) -> Self {
        molecule_fiber::RemoveTlc::new_builder()
            .channel_id(remove_tlc.channel_id.into())
            .tlc_id(remove_tlc.tlc_id.pack())
            .reason(
                molecule_fiber::RemoveTlcReason::new_builder()
                    .set(remove_tlc.reason)
                    .build(),
            )
            .build()
    }
}

impl TryFrom<molecule_fiber::RemoveTlc> for RemoveTlc {
    type Error = Error;

    fn try_from(remove_tlc: molecule_fiber::RemoveTlc) -> Result<Self, Self::Error> {
        Ok(RemoveTlc {
            channel_id: remove_tlc.channel_id().into(),
            tlc_id: remove_tlc.tlc_id().unpack(),
            reason: remove_tlc.reason().try_into()?,
        })
    }
}

#[derive(Debug, Clone)]
pub struct ReestablishChannel {
    pub channel_id: Hash256,
    pub local_commitment_number: u64,
    pub remote_commitment_number: u64,
}

impl From<ReestablishChannel> for molecule_fiber::ReestablishChannel {
    fn from(reestablish_channel: ReestablishChannel) -> Self {
        molecule_fiber::ReestablishChannel::new_builder()
            .channel_id(reestablish_channel.channel_id.into())
            .local_commitment_number(reestablish_channel.local_commitment_number.pack())
            .remote_commitment_number(reestablish_channel.remote_commitment_number.pack())
            .build()
    }
}

impl TryFrom<molecule_fiber::ReestablishChannel> for ReestablishChannel {
    type Error = Error;

    fn try_from(
        reestablish_channel: molecule_fiber::ReestablishChannel,
    ) -> Result<Self, Self::Error> {
        Ok(ReestablishChannel {
            channel_id: reestablish_channel.channel_id().into(),
            local_commitment_number: reestablish_channel.local_commitment_number().unpack(),
            remote_commitment_number: reestablish_channel.remote_commitment_number().unpack(),
        })
    }
}

#[derive(Debug, Clone)]
pub struct AnnouncementSignatures {
    pub channel_id: Hash256,
    pub channel_outpoint: OutPoint,
    pub node_signature: EcdsaSignature,
    pub partial_signature: PartialSignature,
}

impl From<AnnouncementSignatures> for molecule_fiber::AnnouncementSignatures {
    fn from(announcement_signatures: AnnouncementSignatures) -> Self {
        molecule_fiber::AnnouncementSignatures::new_builder()
            .channel_id(announcement_signatures.channel_id.into())
            .channel_outpoint(announcement_signatures.channel_outpoint)
            .node_signature(announcement_signatures.node_signature.into())
            .partial_signature(partial_signature_to_molecule(
                announcement_signatures.partial_signature,
            ))
            .build()
    }
}

impl TryFrom<molecule_fiber::AnnouncementSignatures> for AnnouncementSignatures {
    type Error = Error;

    fn try_from(
        announcement_signatures: molecule_fiber::AnnouncementSignatures,
    ) -> Result<Self, Self::Error> {
        Ok(AnnouncementSignatures {
            channel_id: announcement_signatures.channel_id().into(),
            channel_outpoint: announcement_signatures.channel_outpoint(),
            node_signature: announcement_signatures.node_signature().try_into()?,
            partial_signature: PartialSignature::from_slice(
                announcement_signatures.partial_signature().as_slice(),
            )
            .map_err(|e| anyhow!(e))?,
        })
    }
}

#[derive(Debug, Clone)]
pub struct ForwardTlcResult {
    pub channel_id: Hash256,
    pub payment_hash: Hash256,
    pub tlc_id: u64,
    pub error_info: Option<(ProcessingChannelError, TlcErr)>,
}

#[derive(Debug, Clone, Serialize, Deserialize, Eq, PartialEq, Hash)]
pub struct NodeAnnouncement {
    // Signature to this message, may be empty the message is not signed yet.
    pub signature: Option<EcdsaSignature>,
    // Tentatively using 64 bits for features. May change the type later while developing.
    // rust-lightning uses a Vec<u8> here.
    pub features: u64,
    // Timestamp for current NodeAnnouncement. Later updates should have larger timestamp.
    pub timestamp: u64,
    pub node_id: Pubkey,
    // Must be a valid utf-8 string of length maximal length 32 bytes.
    // If the length is less than 32 bytes, it will be padded with 0.
    // If the length is more than 32 bytes, it should be truncated.
    pub node_name: AnnouncedNodeName,
    // All the reachable addresses.
    pub addresses: Vec<MultiAddr>,
    // chain_hash
    pub chain_hash: Hash256,
    // If the other party funding more than this amount, we will automatically accept the channel.
    pub auto_accept_min_ckb_funding_amount: u64,
    // UDT config info
    pub udt_cfg_infos: UdtCfgInfos,
}

impl NodeAnnouncement {
    pub fn new_unsigned(
        node_name: AnnouncedNodeName,
        addresses: Vec<MultiAddr>,
        node_id: Pubkey,
        timestamp: u64,
        auto_accept_min_ckb_funding_amount: u64,
    ) -> Self {
        Self {
            signature: None,
            features: Default::default(),
            timestamp,
            node_id,
            node_name,
            chain_hash: get_chain_hash(),
            addresses,
            auto_accept_min_ckb_funding_amount,
            udt_cfg_infos: get_udt_whitelist(),
        }
    }

    pub fn new(
        node_name: AnnouncedNodeName,
        addresses: Vec<MultiAddr>,
        private_key: &Privkey,
        timestamp: u64,
        auto_accept_min_ckb_funding_amount: u64,
    ) -> NodeAnnouncement {
        let mut unsigned = NodeAnnouncement::new_unsigned(
            node_name,
            addresses,
            private_key.pubkey(),
            timestamp,
            auto_accept_min_ckb_funding_amount,
        );
        unsigned.signature = Some(private_key.sign(unsigned.message_to_sign()));
        unsigned
    }

    pub fn message_to_sign(&self) -> [u8; 32] {
        let unsigned_announcement = NodeAnnouncement {
            signature: None,
            features: self.features,
            timestamp: self.timestamp,
            node_id: self.node_id,
            node_name: self.node_name,
            chain_hash: self.chain_hash,
            addresses: self.addresses.clone(),
            auto_accept_min_ckb_funding_amount: self.auto_accept_min_ckb_funding_amount,
            udt_cfg_infos: self.udt_cfg_infos.clone(),
        };
        deterministically_hash(&molecule_gossip::NodeAnnouncement::from(
            unsigned_announcement,
        ))
    }

    pub fn peer_id(&self) -> PeerId {
        PeerId::from_public_key(&self.node_id.into())
    }

    pub fn cursor(&self) -> Cursor {
        Cursor::new(
            self.timestamp,
            BroadcastMessageID::NodeAnnouncement(self.node_id),
        )
    }

    pub fn verify(&self) -> bool {
        let message = self.message_to_sign();
        match self.signature {
            Some(ref signature) => signature.verify(&self.node_id, &message),
            _ => false,
        }
    }
}

impl From<UdtCellDep> for molecule_fiber::UdtCellDep {
    fn from(udt_cell_dep: UdtCellDep) -> Self {
        molecule_fiber::UdtCellDep::new_builder()
            .dep_type(udt_cell_dep.dep_type.into())
            .tx_hash(udt_cell_dep.tx_hash.pack())
            .index(udt_cell_dep.index.pack())
            .build()
    }
}

impl From<molecule_fiber::UdtCellDep> for UdtCellDep {
    fn from(udt_cell_dep: molecule_fiber::UdtCellDep) -> Self {
        UdtCellDep {
            dep_type: udt_cell_dep
                .dep_type()
                .try_into()
                .expect("invalid dep type"),
            tx_hash: udt_cell_dep.tx_hash().unpack(),
            index: udt_cell_dep.index().unpack(),
        }
    }
}

impl From<UdtScript> for molecule_fiber::UdtScript {
    fn from(udt_script: UdtScript) -> Self {
        molecule_fiber::UdtScript::new_builder()
            .code_hash(udt_script.code_hash.pack())
            .hash_type(udt_script.hash_type.into())
            .args(udt_script.args.pack())
            .build()
    }
}

impl From<molecule_fiber::UdtScript> for UdtScript {
    fn from(udt_script: molecule_fiber::UdtScript) -> Self {
        UdtScript {
            code_hash: udt_script.code_hash().unpack(),
            hash_type: udt_script
                .hash_type()
                .try_into()
                .expect("invalid hash type"),
            args: String::from_utf8(udt_script.args().unpack()).expect("invalid utf8"),
        }
    }
}

impl From<UdtArgInfo> for molecule_fiber::UdtArgInfo {
    fn from(udt_arg_info: UdtArgInfo) -> Self {
        molecule_fiber::UdtArgInfo::new_builder()
            .name(udt_arg_info.name.pack())
            .script(udt_arg_info.script.into())
            .auto_accept_amount(
                Uint128Opt::new_builder()
                    .set(udt_arg_info.auto_accept_amount.map(|x| x.pack()))
                    .build(),
            )
            .cell_deps(
                UdtCellDeps::new_builder()
                    .set(
                        udt_arg_info
                            .cell_deps
                            .into_iter()
                            .map(|cell_dep| cell_dep.into())
                            .collect(),
                    )
                    .build(),
            )
            .build()
    }
}

impl From<molecule_fiber::UdtArgInfo> for UdtArgInfo {
    fn from(udt_arg_info: molecule_fiber::UdtArgInfo) -> Self {
        UdtArgInfo {
            name: String::from_utf8(udt_arg_info.name().unpack()).expect("invalid name"),
            script: udt_arg_info.script().into(),
            auto_accept_amount: udt_arg_info
                .auto_accept_amount()
                .to_opt()
                .map(|x| x.unpack()),
            cell_deps: udt_arg_info
                .cell_deps()
                .into_iter()
                .map(|cell_dep| cell_dep.into())
                .collect(),
        }
    }
}

impl From<UdtCfgInfos> for molecule_fiber::UdtCfgInfos {
    fn from(udt_arg_info: UdtCfgInfos) -> Self {
        molecule_fiber::UdtCfgInfos::new_builder()
            .set(
                udt_arg_info
                    .0
                    .into_iter()
                    .map(|udt_arg_info| udt_arg_info.into())
                    .collect(),
            )
            .build()
    }
}

impl From<molecule_fiber::UdtCfgInfos> for UdtCfgInfos {
    fn from(udt_arg_infos: molecule_fiber::UdtCfgInfos) -> Self {
        UdtCfgInfos(
            udt_arg_infos
                .into_iter()
                .map(|udt_arg_info| udt_arg_info.into())
                .collect(),
        )
    }
}

impl From<NodeAnnouncement> for molecule_gossip::NodeAnnouncement {
    fn from(node_announcement: NodeAnnouncement) -> Self {
        let builder = molecule_gossip::NodeAnnouncement::new_builder()
            .features(node_announcement.features.pack())
            .timestamp(node_announcement.timestamp.pack())
            .node_id(node_announcement.node_id.into())
            .node_name(u8_32_as_byte_32(&node_announcement.node_name.0))
            .chain_hash(node_announcement.chain_hash.into())
            .auto_accept_min_ckb_funding_amount(
                node_announcement.auto_accept_min_ckb_funding_amount.pack(),
            )
            .udt_cfg_infos(node_announcement.udt_cfg_infos.into())
            .address(
                BytesVec::new_builder()
                    .set(
                        node_announcement
                            .addresses
                            .into_iter()
                            .map(|address| address.to_vec().pack())
                            .collect(),
                    )
                    .build(),
            );

        let builder = if let Some(signature) = node_announcement.signature {
            builder.signature(signature.into())
        } else {
            builder
        };

        builder.build()
    }
}

impl TryFrom<molecule_gossip::NodeAnnouncement> for NodeAnnouncement {
    type Error = Error;

    fn try_from(node_announcement: molecule_gossip::NodeAnnouncement) -> Result<Self, Self::Error> {
        Ok(NodeAnnouncement {
            signature: Some(node_announcement.signature().try_into()?),
            features: node_announcement.features().unpack(),
            timestamp: node_announcement.timestamp().unpack(),
            node_id: node_announcement.node_id().try_into()?,
            chain_hash: node_announcement.chain_hash().into(),
            auto_accept_min_ckb_funding_amount: node_announcement
                .auto_accept_min_ckb_funding_amount()
                .unpack(),
            node_name: AnnouncedNodeName::from_slice(node_announcement.node_name().as_slice())
                .map_err(|e| Error::AnyHow(anyhow!("Invalid node_name: {}", e)))?,
            udt_cfg_infos: node_announcement.udt_cfg_infos().into(),
            addresses: node_announcement
                .address()
                .into_iter()
                .map(|address| MultiAddr::try_from(address.raw_data()))
                .collect::<Result<Vec<_>, _>>()?,
        })
    }
}

#[serde_as]
#[derive(Debug, Clone, Eq, PartialEq, Serialize, Deserialize, Hash)]
pub struct ChannelAnnouncement {
    pub node1_signature: Option<EcdsaSignature>,
    pub node2_signature: Option<EcdsaSignature>,
    // Signature signed by the funding transaction output public key.
    pub ckb_signature: Option<SchnorrSignature>,
    // Tentatively using 64 bits for features. May change the type later while developing.
    // rust-lightning uses a Vec<u8> here.
    pub features: u64,
    pub chain_hash: Hash256,
    #[serde_as(as = "EntityHex")]
    pub channel_outpoint: OutPoint,
    pub node1_id: Pubkey,
    pub node2_id: Pubkey,
    // The aggregated public key of the funding transaction output.
    pub ckb_key: XOnlyPublicKey,
    // The total capacity of the channel.
    pub capacity: u128,
    // UDT script
    #[serde_as(as = "Option<EntityHex>")]
    pub udt_type_script: Option<Script>,
}

impl ChannelAnnouncement {
    pub fn new_unsigned(
        node1_pubkey: &Pubkey,
        node2_pubkey: &Pubkey,
        channel_outpoint: OutPoint,
        ckb_pubkey: &XOnlyPublicKey,
        capacity: u128,
        udt_type_script: Option<Script>,
    ) -> Self {
        Self {
            node1_signature: None,
            node2_signature: None,
            ckb_signature: None,
            features: Default::default(),
            chain_hash: get_chain_hash(),
            channel_outpoint,
            node1_id: *node1_pubkey,
            node2_id: *node2_pubkey,
            ckb_key: *ckb_pubkey,
            capacity,
            udt_type_script,
        }
    }

    pub fn is_signed(&self) -> bool {
        self.node1_signature.is_some()
            && self.node2_signature.is_some()
            && self.ckb_signature.is_some()
    }

    pub fn message_to_sign(&self) -> [u8; 32] {
        let unsigned_announcement = Self {
            node1_signature: None,
            node2_signature: None,
            ckb_signature: None,
            features: self.features,
            chain_hash: self.chain_hash,
            channel_outpoint: self.channel_outpoint.clone(),
            node1_id: self.node1_id,
            node2_id: self.node2_id,
            ckb_key: self.ckb_key,
            capacity: self.capacity,
            udt_type_script: self.udt_type_script.clone(),
        };
        deterministically_hash(&molecule_gossip::ChannelAnnouncement::from(
            unsigned_announcement,
        ))
    }

    pub fn out_point(&self) -> &OutPoint {
        &self.channel_outpoint
    }
}

impl From<ChannelAnnouncement> for molecule_gossip::ChannelAnnouncement {
    fn from(channel_announcement: ChannelAnnouncement) -> Self {
        let builder = molecule_gossip::ChannelAnnouncement::new_builder()
            .features(channel_announcement.features.pack())
            .chain_hash(channel_announcement.chain_hash.into())
            .channel_outpoint(channel_announcement.channel_outpoint)
            .node1_id(channel_announcement.node1_id.into())
            .node2_id(channel_announcement.node2_id.into())
            .capacity(channel_announcement.capacity.pack())
            .udt_type_script(channel_announcement.udt_type_script.pack())
            .ckb_key(channel_announcement.ckb_key.into());

        let builder = if let Some(signature) = channel_announcement.node1_signature {
            builder.node1_signature(signature.into())
        } else {
            builder
        };

        let builder = if let Some(signature) = channel_announcement.node2_signature {
            builder.node2_signature(signature.into())
        } else {
            builder
        };

        let builder = if let Some(signature) = channel_announcement.ckb_signature {
            builder.ckb_signature(signature.into())
        } else {
            builder
        };

        builder.build()
    }
}

impl TryFrom<molecule_gossip::ChannelAnnouncement> for ChannelAnnouncement {
    type Error = Error;

    fn try_from(
        channel_announcement: molecule_gossip::ChannelAnnouncement,
    ) -> Result<Self, Self::Error> {
        Ok(ChannelAnnouncement {
            node1_signature: Some(channel_announcement.node1_signature().try_into()?),
            node2_signature: Some(channel_announcement.node2_signature().try_into()?),
            ckb_signature: Some(channel_announcement.ckb_signature().try_into()?),
            features: channel_announcement.features().unpack(),
            capacity: channel_announcement.capacity().unpack(),
            chain_hash: channel_announcement.chain_hash().into(),
            channel_outpoint: channel_announcement.channel_outpoint(),
            udt_type_script: channel_announcement.udt_type_script().to_opt(),
            node1_id: channel_announcement.node1_id().try_into()?,
            node2_id: channel_announcement.node2_id().try_into()?,
            ckb_key: channel_announcement.ckb_key().try_into()?,
        })
    }
}

#[serde_as]
#[derive(Debug, Clone, Eq, PartialEq, Serialize, Deserialize, Hash)]
pub struct ChannelUpdate {
    // Signature of the node that wants to update the channel information.
    pub signature: Option<EcdsaSignature>,
    pub chain_hash: Hash256,
    #[serde_as(as = "EntityHex")]
    pub channel_outpoint: OutPoint,
    pub timestamp: u64,
    // Currently only the first bit is used to indicate the direction of the channel.
    // If it is 0, it means this channel message is from node 1 (thus applies to tlcs
    // sent from node 2 to node 1). Otherwise, it is from node 2.
    pub message_flags: ChannelUpdateMessageFlags,
    // Currently only the first bit is used to indicate if the channel is disabled.
    // If the first bit is set, the channel is disabled.
    pub channel_flags: ChannelUpdateChannelFlags,
    pub tlc_expiry_delta: u64,
    pub tlc_minimum_value: u128,
    pub tlc_fee_proportional_millionths: u128,
}

impl ChannelUpdate {
    pub fn new_unsigned(
        channel_outpoint: OutPoint,
        timestamp: u64,
        message_flags: ChannelUpdateMessageFlags,
        channel_flags: ChannelUpdateChannelFlags,
        tlc_expiry_delta: u64,
        tlc_minimum_value: u128,
        tlc_fee_proportional_millionths: u128,
    ) -> Self {
        // To avoid having the same timestamp for both channel updates, we will use an even
        // timestamp number for node1 and an odd timestamp number for node2.
        let timestamp = if message_flags.contains(ChannelUpdateMessageFlags::UPDATE_OF_NODE2) {
            timestamp | 1u64
        } else {
            timestamp & !1u64
        };
        Self {
            signature: None,
            chain_hash: get_chain_hash(),
            channel_outpoint,
            timestamp,
            message_flags,
            channel_flags,
            tlc_expiry_delta,
            tlc_minimum_value,
            tlc_fee_proportional_millionths,
        }
    }

    pub fn message_to_sign(&self) -> [u8; 32] {
        let unsigned_update = ChannelUpdate {
            signature: None,
            chain_hash: self.chain_hash,
            channel_outpoint: self.channel_outpoint.clone(),
            timestamp: self.timestamp,
            message_flags: self.message_flags,
            channel_flags: self.channel_flags,
            tlc_expiry_delta: self.tlc_expiry_delta,
            tlc_minimum_value: self.tlc_minimum_value,
            tlc_fee_proportional_millionths: self.tlc_fee_proportional_millionths,
        };
        deterministically_hash(&molecule_fiber::ChannelUpdate::from(unsigned_update))
    }

    pub fn is_update_of_node_1(&self) -> bool {
        !self.is_update_of_node_2()
    }

    pub fn is_update_of_node_2(&self) -> bool {
        self.message_flags
            .contains(ChannelUpdateMessageFlags::UPDATE_OF_NODE2)
    }

    pub fn is_disabled(&self) -> bool {
        self.channel_flags
            .contains(ChannelUpdateChannelFlags::DISABLED)
    }

    pub fn cursor(&self) -> Cursor {
        Cursor::new(
            self.timestamp,
            BroadcastMessageID::ChannelUpdate(self.channel_outpoint.clone()),
        )
    }
}

impl From<ChannelUpdate> for molecule_fiber::ChannelUpdate {
    fn from(channel_update: ChannelUpdate) -> Self {
        let builder = molecule_fiber::ChannelUpdate::new_builder()
            .chain_hash(channel_update.chain_hash.into())
            .channel_outpoint(channel_update.channel_outpoint)
            .timestamp(channel_update.timestamp.pack())
            .message_flags(channel_update.message_flags.bits().pack())
            .channel_flags(channel_update.channel_flags.bits().pack())
            .tlc_expiry_delta(channel_update.tlc_expiry_delta.pack())
            .tlc_minimum_value(channel_update.tlc_minimum_value.pack())
            .tlc_fee_proportional_millionths(channel_update.tlc_fee_proportional_millionths.pack());

        let builder = if let Some(signature) = channel_update.signature {
            builder.signature(signature.into())
        } else {
            builder
        };

        builder.build()
    }
}

impl TryFrom<molecule_fiber::ChannelUpdate> for ChannelUpdate {
    type Error = Error;

    fn try_from(channel_update: molecule_fiber::ChannelUpdate) -> Result<Self, Self::Error> {
        Ok(ChannelUpdate {
            signature: Some(channel_update.signature().try_into()?),
            chain_hash: channel_update.chain_hash().into(),
            channel_outpoint: channel_update.channel_outpoint(),
            timestamp: channel_update.timestamp().unpack(),
            message_flags: ChannelUpdateMessageFlags::from_bits_truncate(
                channel_update.message_flags().unpack(),
            ),
            channel_flags: ChannelUpdateChannelFlags::from_bits_truncate(
                channel_update.channel_flags().unpack(),
            ),
            tlc_expiry_delta: channel_update.tlc_expiry_delta().unpack(),
            tlc_minimum_value: channel_update.tlc_minimum_value().unpack(),
            tlc_fee_proportional_millionths: channel_update
                .tlc_fee_proportional_millionths()
                .unpack(),
        })
    }
}

#[derive(Debug, Clone)]
pub enum FiberQueryInformation {
    GetBroadcastMessages(GetBroadcastMessages),
    GetBroadcastMessagesResult(GetBroadcastMessagesResult),
}

#[derive(Debug, Clone)]
pub enum FiberMessage {
    ChannelInitialization(OpenChannel),
    ChannelNormalOperation(FiberChannelMessage),
}

impl FiberMessage {
    pub fn open_channel(open_channel: OpenChannel) -> Self {
        FiberMessage::ChannelInitialization(open_channel)
    }

    pub fn accept_channel(accept_channel: AcceptChannel) -> Self {
        FiberMessage::ChannelNormalOperation(FiberChannelMessage::AcceptChannel(accept_channel))
    }

    pub fn commitment_signed(commitment_signed: CommitmentSigned) -> Self {
        FiberMessage::ChannelNormalOperation(FiberChannelMessage::CommitmentSigned(
            commitment_signed,
        ))
    }

    pub fn tx_signatures(tx_signatures: TxSignatures) -> Self {
        FiberMessage::ChannelNormalOperation(FiberChannelMessage::TxSignatures(tx_signatures))
    }

    pub fn channel_ready(channel_ready: ChannelReady) -> Self {
        FiberMessage::ChannelNormalOperation(FiberChannelMessage::ChannelReady(channel_ready))
    }

    pub fn tx_update(tx_update: TxUpdate) -> Self {
        FiberMessage::ChannelNormalOperation(FiberChannelMessage::TxUpdate(tx_update))
    }

    pub fn tx_complete(tx_complete: TxComplete) -> Self {
        FiberMessage::ChannelNormalOperation(FiberChannelMessage::TxComplete(tx_complete))
    }

    pub fn tx_abort(tx_abort: TxAbort) -> Self {
        FiberMessage::ChannelNormalOperation(FiberChannelMessage::TxAbort(tx_abort))
    }

    pub fn tx_init_rbf(tx_init_rbf: TxInitRBF) -> Self {
        FiberMessage::ChannelNormalOperation(FiberChannelMessage::TxInitRBF(tx_init_rbf))
    }

    pub fn tx_ack_rbf(tx_ack_rbf: TxAckRBF) -> Self {
        FiberMessage::ChannelNormalOperation(FiberChannelMessage::TxAckRBF(tx_ack_rbf))
    }

    pub fn shutdown(shutdown: Shutdown) -> Self {
        FiberMessage::ChannelNormalOperation(FiberChannelMessage::Shutdown(shutdown))
    }

    pub fn closing_signed(closing_signed: ClosingSigned) -> Self {
        FiberMessage::ChannelNormalOperation(FiberChannelMessage::ClosingSigned(closing_signed))
    }

    pub fn add_tlc(add_tlc: AddTlc) -> Self {
        FiberMessage::ChannelNormalOperation(FiberChannelMessage::AddTlc(add_tlc))
    }

    pub fn revoke_and_ack(revoke_and_ack: RevokeAndAck) -> Self {
        FiberMessage::ChannelNormalOperation(FiberChannelMessage::RevokeAndAck(revoke_and_ack))
    }

    pub fn remove_tlc(remove_tlc: RemoveTlc) -> Self {
        FiberMessage::ChannelNormalOperation(FiberChannelMessage::RemoveTlc(remove_tlc))
    }

    pub fn reestablish_channel(reestablish_channel: ReestablishChannel) -> Self {
        FiberMessage::ChannelNormalOperation(FiberChannelMessage::ReestablishChannel(
            reestablish_channel,
        ))
    }

    pub fn announcement_signatures(announcement_signatures: AnnouncementSignatures) -> Self {
        FiberMessage::ChannelNormalOperation(FiberChannelMessage::AnnouncementSignatures(
            announcement_signatures,
        ))
    }
}

#[derive(Debug, Clone)]
pub enum FiberChannelMessage {
    AcceptChannel(AcceptChannel),
    CommitmentSigned(CommitmentSigned),
    TxSignatures(TxSignatures),
    ChannelReady(ChannelReady),
    TxUpdate(TxUpdate),
    TxComplete(TxComplete),
    TxAbort(TxAbort),
    TxInitRBF(TxInitRBF),
    TxAckRBF(TxAckRBF),
    Shutdown(Shutdown),
    ClosingSigned(ClosingSigned),
    UpdateTlcInfo(UpdateTlcInfo),
    AddTlc(AddTlc),
    RevokeAndAck(RevokeAndAck),
    RemoveTlc(RemoveTlc),
    ReestablishChannel(ReestablishChannel),
    AnnouncementSignatures(AnnouncementSignatures),
}

impl Display for FiberChannelMessage {
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        match self {
            FiberChannelMessage::AcceptChannel(_) => write!(f, "AcceptChannel"),
            FiberChannelMessage::CommitmentSigned(_) => write!(f, "CommitmentSigned"),
            FiberChannelMessage::TxSignatures(_) => write!(f, "TxSignatures"),
            FiberChannelMessage::ChannelReady(_) => write!(f, "ChannelReady"),
            FiberChannelMessage::TxUpdate(_) => write!(f, "TxUpdate"),
            FiberChannelMessage::TxComplete(_) => write!(f, "TxComplete"),
            FiberChannelMessage::TxAbort(_) => write!(f, "TxAbort"),
            FiberChannelMessage::TxInitRBF(_) => write!(f, "TxInitRBF"),
            FiberChannelMessage::TxAckRBF(_) => write!(f, "TxAckRBF"),
            FiberChannelMessage::Shutdown(_) => write!(f, "Shutdown"),
            FiberChannelMessage::ClosingSigned(_) => write!(f, "ClosingSigned"),
            FiberChannelMessage::UpdateTlcInfo(_) => write!(f, "UpdateTlcInfo"),
            FiberChannelMessage::AddTlc(_) => write!(f, "AddTlc"),
            FiberChannelMessage::RevokeAndAck(_) => write!(f, "RevokeAndAck"),
            FiberChannelMessage::RemoveTlc(_) => write!(f, "RemoveTlc"),
            FiberChannelMessage::ReestablishChannel(_) => write!(f, "ReestablishChannel"),
            FiberChannelMessage::AnnouncementSignatures(_) => write!(f, "AnnouncementSignatures"),
        }
    }
}

impl FiberChannelMessage {
    pub fn get_channel_id(&self) -> Hash256 {
        match self {
            FiberChannelMessage::AcceptChannel(accept_channel) => accept_channel.channel_id,
            FiberChannelMessage::CommitmentSigned(commitment_signed) => {
                commitment_signed.channel_id
            }
            FiberChannelMessage::TxSignatures(tx_signatures) => tx_signatures.channel_id,
            FiberChannelMessage::ChannelReady(channel_ready) => channel_ready.channel_id,
            FiberChannelMessage::TxUpdate(tx_update) => tx_update.channel_id,
            FiberChannelMessage::TxComplete(tx_complete) => tx_complete.channel_id,
            FiberChannelMessage::TxAbort(tx_abort) => tx_abort.channel_id,
            FiberChannelMessage::TxInitRBF(tx_init_rbf) => tx_init_rbf.channel_id,
            FiberChannelMessage::TxAckRBF(tx_ack_rbf) => tx_ack_rbf.channel_id,
            FiberChannelMessage::Shutdown(shutdown) => shutdown.channel_id,
            FiberChannelMessage::ClosingSigned(closing_signed) => closing_signed.channel_id,
            FiberChannelMessage::UpdateTlcInfo(update_tlc_info) => update_tlc_info.channel_id,
            FiberChannelMessage::AddTlc(add_tlc) => add_tlc.channel_id,
            FiberChannelMessage::RevokeAndAck(revoke_and_ack) => revoke_and_ack.channel_id,
            FiberChannelMessage::RemoveTlc(remove_tlc) => remove_tlc.channel_id,
            FiberChannelMessage::ReestablishChannel(reestablish_channel) => {
                reestablish_channel.channel_id
            }
            FiberChannelMessage::AnnouncementSignatures(annoucement_signatures) => {
                annoucement_signatures.channel_id
            }
        }
    }
}

#[derive(Debug, Clone)]
pub enum GossipMessage {
    BroadcastMessagesFilter(BroadcastMessagesFilter),
    BroadcastMessagesFilterResult(BroadcastMessagesFilterResult),
    GetBroadcastMessages(GetBroadcastMessages),
    GetBroadcastMessagesResult(GetBroadcastMessagesResult),
    QueryBroadcastMessages(QueryBroadcastMessages),
    QueryBroadcastMessagesResult(QueryBroadcastMessagesResult),
}

impl GossipMessage {
    pub fn to_molecule_bytes(self) -> molecule::bytes::Bytes {
        molecule_gossip::GossipMessage::from(self).as_bytes()
    }

    pub fn from_molecule_slice(data: &[u8]) -> Result<Self, Error> {
        molecule_gossip::GossipMessage::from_slice(data)
            .map_err(Into::into)
            .and_then(TryInto::try_into)
    }
}

impl From<GossipMessage> for molecule_gossip::GossipMessageUnion {
    fn from(gossip_message: GossipMessage) -> Self {
        match gossip_message {
            GossipMessage::BroadcastMessagesFilter(broadcast_messages_filter) => {
                molecule_gossip::GossipMessageUnion::BroadcastMessagesFilter(
                    broadcast_messages_filter.into(),
                )
            }
            GossipMessage::BroadcastMessagesFilterResult(broadcast_messages_filter_result) => {
                molecule_gossip::GossipMessageUnion::BroadcastMessagesFilterResult(
                    broadcast_messages_filter_result.into(),
                )
            }
            GossipMessage::GetBroadcastMessages(get_broadcast_messages) => {
                molecule_gossip::GossipMessageUnion::GetBroadcastMessages(
                    get_broadcast_messages.into(),
                )
            }
            GossipMessage::GetBroadcastMessagesResult(get_broadcast_messages_result) => {
                molecule_gossip::GossipMessageUnion::GetBroadcastMessagesResult(
                    get_broadcast_messages_result.into(),
                )
            }
            GossipMessage::QueryBroadcastMessages(query_broadcast_messages) => {
                molecule_gossip::GossipMessageUnion::QueryBroadcastMessages(
                    query_broadcast_messages.into(),
                )
            }
            GossipMessage::QueryBroadcastMessagesResult(query_broadcast_messages_result) => {
                molecule_gossip::GossipMessageUnion::QueryBroadcastMessagesResult(
                    query_broadcast_messages_result.into(),
                )
            }
        }
    }
}

impl From<GossipMessage> for molecule_gossip::GossipMessage {
    fn from(gossip_message: GossipMessage) -> Self {
        molecule_gossip::GossipMessage::new_builder()
            .set(gossip_message)
            .build()
    }
}

impl TryFrom<molecule_gossip::GossipMessageUnion> for GossipMessage {
    type Error = Error;

    fn try_from(gossip_message: molecule_gossip::GossipMessageUnion) -> Result<Self, Self::Error> {
        match gossip_message {
            molecule_gossip::GossipMessageUnion::BroadcastMessagesFilter(
                broadcast_messages_filter,
            ) => Ok(GossipMessage::BroadcastMessagesFilter(
                broadcast_messages_filter.try_into()?,
            )),
            molecule_gossip::GossipMessageUnion::BroadcastMessagesFilterResult(
                broadcast_messages_result,
            ) => Ok(GossipMessage::BroadcastMessagesFilterResult(
                broadcast_messages_result.try_into()?,
            )),
            molecule_gossip::GossipMessageUnion::GetBroadcastMessages(get_broadcast_messages) => {
                Ok(GossipMessage::GetBroadcastMessages(
                    get_broadcast_messages.try_into()?,
                ))
            }
            molecule_gossip::GossipMessageUnion::GetBroadcastMessagesResult(
                broadcast_messages_result,
            ) => Ok(GossipMessage::GetBroadcastMessagesResult(
                broadcast_messages_result.try_into()?,
            )),
            molecule_gossip::GossipMessageUnion::QueryBroadcastMessages(
                query_broadcast_messages,
            ) => Ok(GossipMessage::QueryBroadcastMessages(
                query_broadcast_messages.try_into()?,
            )),
            molecule_gossip::GossipMessageUnion::QueryBroadcastMessagesResult(
                broadcast_messages_result,
            ) => Ok(GossipMessage::QueryBroadcastMessagesResult(
                broadcast_messages_result.try_into()?,
            )),
        }
    }
}

impl TryFrom<molecule_gossip::GossipMessage> for GossipMessage {
    type Error = Error;
    fn try_from(value: molecule_gossip::GossipMessage) -> Result<Self, Self::Error> {
        value.to_enum().try_into()
    }
}

#[derive(Debug, Clone, Serialize, Deserialize, Eq, PartialEq, Hash)]
pub enum BroadcastMessage {
    NodeAnnouncement(NodeAnnouncement),
    ChannelAnnouncement(ChannelAnnouncement),
    ChannelUpdate(ChannelUpdate),
}

impl BroadcastMessage {
    pub fn create_broadcast_messages_filter_result(&self) -> GossipMessage {
        GossipMessage::BroadcastMessagesFilterResult(BroadcastMessagesFilterResult {
            messages: vec![self.clone()],
        })
    }

    pub fn cursor(&self) -> Option<Cursor> {
        match self {
            BroadcastMessage::ChannelAnnouncement(_) => None,
            BroadcastMessage::ChannelUpdate(channel_update) => Some(channel_update.cursor()),
            BroadcastMessage::NodeAnnouncement(node_announcement) => {
                Some(node_announcement.cursor())
            }
        }
    }

    pub(crate) fn message_id(&self) -> BroadcastMessageID {
        match self {
            BroadcastMessage::NodeAnnouncement(node_announcement) => {
                BroadcastMessageID::NodeAnnouncement(node_announcement.node_id)
            }
            BroadcastMessage::ChannelAnnouncement(channel_announcement) => {
                BroadcastMessageID::ChannelAnnouncement(
                    channel_announcement.channel_outpoint.clone(),
                )
            }
            BroadcastMessage::ChannelUpdate(channel_update) => {
                BroadcastMessageID::ChannelUpdate(channel_update.channel_outpoint.clone())
            }
        }
    }

    pub(crate) fn timestamp(&self) -> Option<u64> {
        match self {
            BroadcastMessage::NodeAnnouncement(node_announcement) => {
                Some(node_announcement.timestamp)
            }
            BroadcastMessage::ChannelAnnouncement(_) => None,
            BroadcastMessage::ChannelUpdate(channel_update) => Some(channel_update.timestamp),
        }
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct ChannelOnchainInfo {
    pub timestamp: u64,
    pub first_output: CellOutput,
}

// Augment the broadcast message with timestamp so that we can easily obtain the cursor of the message.
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub enum BroadcastMessageWithTimestamp {
    NodeAnnouncement(NodeAnnouncement),
    ChannelAnnouncement(u64, ChannelAnnouncement),
    ChannelUpdate(ChannelUpdate),
}

impl BroadcastMessageWithTimestamp {
    pub fn chain_hash(&self) -> Hash256 {
        match self {
            BroadcastMessageWithTimestamp::NodeAnnouncement(node_announcement) => {
                node_announcement.chain_hash
            }
            BroadcastMessageWithTimestamp::ChannelAnnouncement(_, channel_announcement) => {
                channel_announcement.chain_hash
            }
            BroadcastMessageWithTimestamp::ChannelUpdate(channel_update) => {
                channel_update.chain_hash
            }
        }
    }

    pub fn cursor(&self) -> Cursor {
        match self {
            BroadcastMessageWithTimestamp::NodeAnnouncement(node_announcement) => Cursor::new(
                node_announcement.timestamp,
                BroadcastMessageID::NodeAnnouncement(node_announcement.node_id),
            ),
            BroadcastMessageWithTimestamp::ChannelAnnouncement(timestamp, channel_announcement) => {
                Cursor::new(
                    *timestamp,
                    BroadcastMessageID::ChannelAnnouncement(
                        channel_announcement.channel_outpoint.clone(),
                    ),
                )
            }
            BroadcastMessageWithTimestamp::ChannelUpdate(channel_update) => Cursor::new(
                channel_update.timestamp,
                BroadcastMessageID::ChannelUpdate(channel_update.channel_outpoint.clone()),
            ),
        }
    }

    pub fn timestamp(&self) -> u64 {
        match self {
            BroadcastMessageWithTimestamp::NodeAnnouncement(node_announcement) => {
                node_announcement.timestamp
            }
            BroadcastMessageWithTimestamp::ChannelAnnouncement(timestamp, _) => *timestamp,
            BroadcastMessageWithTimestamp::ChannelUpdate(channel_update) => {
                channel_update.timestamp
            }
        }
    }

    pub fn message_id(&self) -> BroadcastMessageID {
        match self {
            BroadcastMessageWithTimestamp::NodeAnnouncement(node_announcement) => {
                BroadcastMessageID::NodeAnnouncement(node_announcement.node_id)
            }
            BroadcastMessageWithTimestamp::ChannelAnnouncement(_, channel_announcement) => {
                BroadcastMessageID::ChannelAnnouncement(
                    channel_announcement.channel_outpoint.clone(),
                )
            }
            BroadcastMessageWithTimestamp::ChannelUpdate(channel_update) => {
                BroadcastMessageID::ChannelUpdate(channel_update.channel_outpoint.clone())
            }
        }
    }

    pub fn create_broadcast_messages_filter_result(&self) -> BroadcastMessagesFilterResult {
        BroadcastMessagesFilterResult {
            messages: vec![BroadcastMessage::from(self.clone())],
        }
    }
}

impl Ord for BroadcastMessage {
    fn cmp(&self, other: &Self) -> Ordering {
        self.message_id()
            .cmp(&other.message_id())
            .then(self.timestamp().cmp(&other.timestamp()))
    }
}

impl PartialOrd for BroadcastMessage {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

impl From<(BroadcastMessage, Option<ChannelOnchainInfo>)> for BroadcastMessageWithTimestamp {
    fn from(
        (broadcast_message, channel_onchain_info): (BroadcastMessage, Option<ChannelOnchainInfo>),
    ) -> Self {
        match broadcast_message {
            BroadcastMessage::NodeAnnouncement(node_announcement) => {
                BroadcastMessageWithTimestamp::NodeAnnouncement(node_announcement)
            }
            BroadcastMessage::ChannelAnnouncement(channel_announcement) => {
                let timestamp = channel_onchain_info
                    .expect("Channel onchain info is required for channel announcement")
                    .timestamp;
                BroadcastMessageWithTimestamp::ChannelAnnouncement(timestamp, channel_announcement)
            }
            BroadcastMessage::ChannelUpdate(channel_update) => {
                BroadcastMessageWithTimestamp::ChannelUpdate(channel_update)
            }
        }
    }
}

impl From<BroadcastMessageWithTimestamp> for BroadcastMessage {
    fn from(broadcast_message_with_timestamp: BroadcastMessageWithTimestamp) -> Self {
        match broadcast_message_with_timestamp {
            BroadcastMessageWithTimestamp::NodeAnnouncement(node_announcement) => {
                BroadcastMessage::NodeAnnouncement(node_announcement)
            }
            BroadcastMessageWithTimestamp::ChannelAnnouncement(_, channel_announcement) => {
                BroadcastMessage::ChannelAnnouncement(channel_announcement)
            }
            BroadcastMessageWithTimestamp::ChannelUpdate(channel_update) => {
                BroadcastMessage::ChannelUpdate(channel_update)
            }
        }
    }
}

impl From<(BroadcastMessage, u64)> for BroadcastMessageWithTimestamp {
    fn from((broadcast_message, timestamp): (BroadcastMessage, u64)) -> Self {
        match broadcast_message {
            BroadcastMessage::NodeAnnouncement(node_announcement) => {
                debug_assert_eq!(timestamp, node_announcement.timestamp);
                BroadcastMessageWithTimestamp::NodeAnnouncement(node_announcement)
            }
            BroadcastMessage::ChannelAnnouncement(channel_announcement) => {
                BroadcastMessageWithTimestamp::ChannelAnnouncement(timestamp, channel_announcement)
            }
            BroadcastMessage::ChannelUpdate(channel_update) => {
                debug_assert_eq!(timestamp, channel_update.timestamp);
                BroadcastMessageWithTimestamp::ChannelUpdate(channel_update)
            }
        }
    }
}

impl From<BroadcastMessage> for molecule_gossip::BroadcastMessageUnion {
    fn from(fiber_broadcast_message: BroadcastMessage) -> Self {
        match fiber_broadcast_message {
            BroadcastMessage::NodeAnnouncement(node_announcement) => {
                molecule_gossip::BroadcastMessageUnion::NodeAnnouncement(node_announcement.into())
            }
            BroadcastMessage::ChannelAnnouncement(channel_announcement) => {
                molecule_gossip::BroadcastMessageUnion::ChannelAnnouncement(
                    channel_announcement.into(),
                )
            }
            BroadcastMessage::ChannelUpdate(channel_update) => {
                molecule_gossip::BroadcastMessageUnion::ChannelUpdate(channel_update.into())
            }
        }
    }
}

impl TryFrom<molecule_gossip::BroadcastMessageUnion> for BroadcastMessage {
    type Error = Error;

    fn try_from(
        fiber_broadcast_message: molecule_gossip::BroadcastMessageUnion,
    ) -> Result<Self, Self::Error> {
        match fiber_broadcast_message {
            molecule_gossip::BroadcastMessageUnion::NodeAnnouncement(node_announcement) => Ok(
                BroadcastMessage::NodeAnnouncement(node_announcement.try_into()?),
            ),
            molecule_gossip::BroadcastMessageUnion::ChannelAnnouncement(channel_announcement) => {
                Ok(BroadcastMessage::ChannelAnnouncement(
                    channel_announcement.try_into()?,
                ))
            }
            molecule_gossip::BroadcastMessageUnion::ChannelUpdate(channel_update) => {
                Ok(BroadcastMessage::ChannelUpdate(channel_update.try_into()?))
            }
        }
    }
}

impl From<BroadcastMessage> for molecule_gossip::BroadcastMessage {
    fn from(fiber_broadcast_message: BroadcastMessage) -> Self {
        molecule_gossip::BroadcastMessage::new_builder()
            .set(fiber_broadcast_message)
            .build()
    }
}

impl TryFrom<molecule_gossip::BroadcastMessage> for BroadcastMessage {
    type Error = Error;

    fn try_from(
        fiber_broadcast_message: molecule_gossip::BroadcastMessage,
    ) -> Result<Self, Self::Error> {
        fiber_broadcast_message.to_enum().try_into()
    }
}

/// Note that currently we only allow querying for one type of broadcast message at a time.
#[derive(Debug, Copy, Clone, Eq, PartialEq)]
pub enum BroadcastMessageQueryFlags {
    ChannelAnnouncement,
    ChannelUpdateOfNode1,
    ChannelUpdateOfNode2,
    NodeAnnouncementNode1,
    NodeAnnouncementNode2,
}

impl From<BroadcastMessageQueryFlags> for u8 {
    fn from(value: BroadcastMessageQueryFlags) -> u8 {
        match value {
            // The numbers are chosen to be powers of 2 so that they can be combined using bitwise OR.
            // But we disallow querying for multiple types of broadcast messages at a time for now.
            BroadcastMessageQueryFlags::ChannelAnnouncement => 0,
            BroadcastMessageQueryFlags::ChannelUpdateOfNode1 => 1,
            BroadcastMessageQueryFlags::ChannelUpdateOfNode2 => 2,
            BroadcastMessageQueryFlags::NodeAnnouncementNode1 => 4,
            BroadcastMessageQueryFlags::NodeAnnouncementNode2 => 8,
        }
    }
}

impl TryFrom<u8> for BroadcastMessageQueryFlags {
    type Error = Error;

    fn try_from(value: u8) -> Result<Self, Self::Error> {
        match value {
            0 => Ok(BroadcastMessageQueryFlags::ChannelAnnouncement),
            1 => Ok(BroadcastMessageQueryFlags::ChannelUpdateOfNode1),
            2 => Ok(BroadcastMessageQueryFlags::ChannelUpdateOfNode2),
            4 => Ok(BroadcastMessageQueryFlags::NodeAnnouncementNode1),
            8 => Ok(BroadcastMessageQueryFlags::NodeAnnouncementNode2),
            _ => Err(Error::AnyHow(anyhow!(
                "Invalid broadcast message query flags: {}",
                value
            ))),
        }
    }
}

#[derive(Debug, Clone)]
pub struct BroadcastMessageQuery {
    pub channel_outpoint: OutPoint,
    pub flags: BroadcastMessageQueryFlags,
}

impl From<BroadcastMessageQuery> for molecule_gossip::BroadcastMessageQuery {
    fn from(broadcast_message_query: BroadcastMessageQuery) -> Self {
        molecule_gossip::BroadcastMessageQuery::new_builder()
            .channel_outpoint(broadcast_message_query.channel_outpoint)
            .flags(u8::from(broadcast_message_query.flags).into())
            .build()
    }
}

impl TryFrom<molecule_gossip::BroadcastMessageQuery> for BroadcastMessageQuery {
    type Error = Error;

    fn try_from(
        broadcast_message_query: molecule_gossip::BroadcastMessageQuery,
    ) -> Result<Self, Self::Error> {
        Ok(BroadcastMessageQuery {
            channel_outpoint: broadcast_message_query.channel_outpoint(),
            flags: u8::from(broadcast_message_query.flags()).try_into()?,
        })
    }
}

#[derive(Debug, Clone, Eq, PartialEq, Hash)]
pub enum BroadcastMessageID {
    ChannelAnnouncement(OutPoint),
    ChannelUpdate(OutPoint),
    NodeAnnouncement(Pubkey),
}

// We need to implement Ord for BroadcastMessageID to make sure that a ChannelUpdate message is always ordered after ChannelAnnouncement,
// so that we can use it as the sorting key in fn prune_messages_to_be_saved to simplify the logic.
impl Ord for BroadcastMessageID {
    fn cmp(&self, other: &Self) -> Ordering {
        match (self, other) {
            (
                BroadcastMessageID::ChannelAnnouncement(outpoint1),
                BroadcastMessageID::ChannelAnnouncement(outpoint2),
            ) => outpoint1.cmp(outpoint2),
            (
                BroadcastMessageID::ChannelUpdate(outpoint1),
                BroadcastMessageID::ChannelUpdate(outpoint2),
            ) => outpoint1.cmp(outpoint2),
            (
                BroadcastMessageID::NodeAnnouncement(pubkey1),
                BroadcastMessageID::NodeAnnouncement(pubkey2),
            ) => pubkey1.cmp(pubkey2),
            (BroadcastMessageID::NodeAnnouncement(_), _) => Ordering::Less,
            (BroadcastMessageID::ChannelUpdate(_), _) => Ordering::Greater,
            (
                BroadcastMessageID::ChannelAnnouncement(_),
                BroadcastMessageID::NodeAnnouncement(_),
            ) => Ordering::Greater,
            (BroadcastMessageID::ChannelAnnouncement(_), BroadcastMessageID::ChannelUpdate(_)) => {
                Ordering::Less
            }
        }
    }
}

impl PartialOrd for BroadcastMessageID {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

// 1 byte for message type, 36 bytes for message id
const MESSAGE_ID_SIZE: usize = 1 + 36;
// 8 bytes for timestamp, MESSAGE_ID_SIZE bytes for message id
pub(crate) const CURSOR_SIZE: usize = 8 + MESSAGE_ID_SIZE;

impl BroadcastMessageID {
    pub(crate) fn to_bytes(&self) -> [u8; MESSAGE_ID_SIZE] {
        let mut result = [0u8; MESSAGE_ID_SIZE];
        match self {
            BroadcastMessageID::ChannelAnnouncement(channel_outpoint) => {
                result[0] = 0;
                result[1..].copy_from_slice(&channel_outpoint.as_bytes());
            }
            BroadcastMessageID::ChannelUpdate(channel_outpoint) => {
                result[0] = 1;
                result[1..].copy_from_slice(&channel_outpoint.as_bytes());
            }
            BroadcastMessageID::NodeAnnouncement(node_id) => {
                result[0] = 2;
                let node_id = node_id.serialize();
                result[1..1 + node_id.len()].copy_from_slice(&node_id);
            }
        };
        result
    }

    pub(crate) fn from_bytes(bytes: &[u8]) -> Result<Self, Error> {
        if bytes.len() != MESSAGE_ID_SIZE {
            return Err(Error::AnyHow(anyhow!(
                "Invalid message id size: {}",
                bytes.len()
            )));
        }
        match bytes[0] {
            0 => Ok(BroadcastMessageID::ChannelAnnouncement(
                OutPoint::from_slice(&bytes[1..])?,
            )),
            1 => Ok(BroadcastMessageID::ChannelUpdate(OutPoint::from_slice(
                &bytes[1..],
            )?)),
            2 => Ok(BroadcastMessageID::NodeAnnouncement(Pubkey::from_slice(
                &bytes[1..1 + Pubkey::serialization_len()],
            )?)),
            _ => Err(Error::AnyHow(anyhow!(
                "Invalid message id type: {}",
                bytes[0]
            ))),
        }
    }
}

#[derive(Debug, Clone, Eq, PartialEq, Hash)]
pub struct Cursor {
    pub(crate) timestamp: u64,
    pub(crate) message_id: BroadcastMessageID,
}

impl Cursor {
    pub fn new(timestamp: u64, message_id: BroadcastMessageID) -> Self {
        Self {
            timestamp,
            message_id,
        }
    }

    /// Create a new cursor which is the same as the current cursor but with a smaller timestamp.
    /// This is useful when we want to query messages back from this cursor for a certain duration.
    /// For example, sometimes we aren't particularly sure about whether we have already seen all messages before
    /// the latest cursor in our broadcast message store, because it is possible that we that messages are not
    /// saved in strictly increasing order of their timestamps. In this case, we can go back for some time
    /// (e.g. one week) to make sure we don't miss any messages.
    pub fn go_back_for_some_time(&self, duration: Duration) -> Self {
        let current_timestamp = self.timestamp;
        let duration_millis = duration.as_millis() as u64;
        if current_timestamp > duration_millis {
            Self {
                timestamp: current_timestamp - duration_millis,
                message_id: self.message_id.clone(),
            }
        } else {
            Default::default()
        }
    }

    pub fn to_bytes(&self) -> [u8; 45] {
        self.timestamp
            .to_be_bytes()
            .into_iter()
            .chain(self.message_id.to_bytes())
            .collect::<Vec<_>>()
            .try_into()
            .expect("Must serialize cursor to 45 bytes")
    }

    pub fn from_bytes(bytes: &[u8]) -> Result<Self, Error> {
        if bytes.len() != CURSOR_SIZE {
            return Err(Error::AnyHow(anyhow!(
                "Invalid cursor size: {}, want {}",
                bytes.len(),
                CURSOR_SIZE
            )));
        }
        let timestamp = u64::from_be_bytes(bytes[..8].try_into().expect("Cursor timestamp to u64"));
        let message_id = BroadcastMessageID::from_bytes(&bytes[8..])?;
        Ok(Cursor {
            timestamp,
            message_id,
        })
    }

    // A dummy cursor with the maximum timestamp and a dummy message id. This is useful when
    // we want to create a cursor after which none of the messages should be included.
    pub fn max() -> Self {
        Self {
            timestamp: u64::MAX,
            message_id: BroadcastMessageID::ChannelAnnouncement(OutPoint::default()),
        }
    }

    pub fn is_max(&self) -> bool {
        self.timestamp == u64::MAX
    }
}

impl Ord for Cursor {
    fn cmp(&self, other: &Self) -> Ordering {
        self.to_bytes().cmp(&other.to_bytes())
    }
}

impl PartialOrd for Cursor {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

impl Default for Cursor {
    fn default() -> Self {
        molecule_gossip::Cursor::new_builder()
            .set([Byte::new(0); CURSOR_SIZE])
            .build()
            .try_into()
            .expect("Default cursor")
    }
}

impl From<Cursor> for molecule_gossip::Cursor {
    fn from(cursor: Cursor) -> Self {
        let serialized = cursor
            .timestamp
            .to_be_bytes()
            .into_iter()
            .chain(cursor.message_id.to_bytes())
            .map(Byte::new)
            .collect::<Vec<_>>()
            .try_into()
            .expect("Must serialize cursor to 45 bytes");

        molecule_gossip::Cursor::new_builder()
            .set(serialized)
            .build()
    }
}

impl TryFrom<molecule_gossip::Cursor> for Cursor {
    type Error = Error;

    fn try_from(cursor: molecule_gossip::Cursor) -> Result<Self, Self::Error> {
        let slice = cursor.as_slice();
        if slice.len() != CURSOR_SIZE {
            return Err(Error::AnyHow(anyhow!(
                "Invalid cursor size: {}, want {}",
                slice.len(),
                CURSOR_SIZE
            )));
        }
        let timestamp = u64::from_be_bytes(slice[..8].try_into().expect("Cursor timestamp to u64"));
        let message_id = BroadcastMessageID::from_bytes(&slice[8..])?;
        Ok(Cursor {
            timestamp,
            message_id,
        })
    }
}

impl From<u16> for molecule_fiber::Uint16 {
    fn from(count: u16) -> Self {
        let le_bytes = count.to_le_bytes();
        Self::new_builder()
            .set(
                le_bytes
                    .into_iter()
                    .map(Byte::new)
                    .collect::<Vec<_>>()
                    .try_into()
                    .expect("Uint16 from u16"),
            )
            .build()
    }
}

impl From<molecule_fiber::Uint16> for u16 {
    fn from(count: molecule_fiber::Uint16) -> Self {
        let le_bytes = count.as_slice().try_into().expect("Uint16 to u16");
        u16::from_le_bytes(le_bytes)
    }
}

#[derive(Debug, Clone)]
pub struct BroadcastMessagesFilter {
    pub chain_hash: Hash256,
    pub after_cursor: Cursor,
}

impl From<BroadcastMessagesFilter> for molecule_gossip::BroadcastMessagesFilter {
    fn from(broadcast_messages_filter: BroadcastMessagesFilter) -> Self {
        molecule_gossip::BroadcastMessagesFilter::new_builder()
            .chain_hash(broadcast_messages_filter.chain_hash.into())
            .after_cursor(broadcast_messages_filter.after_cursor.into())
            .build()
    }
}

impl TryFrom<molecule_gossip::BroadcastMessagesFilter> for BroadcastMessagesFilter {
    type Error = Error;

    fn try_from(
        broadcast_messages_filter: molecule_gossip::BroadcastMessagesFilter,
    ) -> Result<Self, Self::Error> {
        Ok(BroadcastMessagesFilter {
            chain_hash: broadcast_messages_filter.chain_hash().into(),
            after_cursor: broadcast_messages_filter.after_cursor().try_into()?,
        })
    }
}

#[derive(Debug, Clone)]
pub struct BroadcastMessagesFilterResult {
    pub messages: Vec<BroadcastMessage>,
}

impl BroadcastMessagesFilterResult {
    pub fn new(messages: Vec<BroadcastMessage>) -> Self {
        Self { messages }
    }
}

impl From<BroadcastMessagesFilterResult> for molecule_gossip::BroadcastMessagesFilterResult {
    fn from(broadcast_messages_filter_result: BroadcastMessagesFilterResult) -> Self {
        molecule_gossip::BroadcastMessagesFilterResult::new_builder()
            .messages(
                molecule_gossip::BroadcastMessages::new_builder()
                    .set(
                        broadcast_messages_filter_result
                            .messages
                            .into_iter()
                            .map(|message| message.into())
                            .collect(),
                    )
                    .build(),
            )
            .build()
    }
}

impl TryFrom<molecule_gossip::BroadcastMessagesFilterResult> for BroadcastMessagesFilterResult {
    type Error = Error;

    fn try_from(
        broadcast_messages_filter_result: molecule_gossip::BroadcastMessagesFilterResult,
    ) -> Result<Self, Self::Error> {
        Ok(BroadcastMessagesFilterResult {
            messages: broadcast_messages_filter_result
                .messages()
                .into_iter()
                .map(|message| message.try_into())
                .collect::<Result<Vec<BroadcastMessage>, Error>>()?,
        })
    }
}

#[derive(Debug, Clone)]
pub struct GetBroadcastMessages {
    pub id: u64,
    pub chain_hash: Hash256,
    pub after_cursor: Cursor,
    pub count: u16,
}

impl From<GetBroadcastMessages> for molecule_gossip::GetBroadcastMessages {
    fn from(get_broadcast_messages: GetBroadcastMessages) -> Self {
        molecule_gossip::GetBroadcastMessages::new_builder()
            .id(get_broadcast_messages.id.pack())
            .chain_hash(get_broadcast_messages.chain_hash.into())
            .after_cursor(get_broadcast_messages.after_cursor.into())
            .count(get_broadcast_messages.count.into())
            .build()
    }
}

impl TryFrom<molecule_gossip::GetBroadcastMessages> for GetBroadcastMessages {
    type Error = Error;

    fn try_from(
        get_broadcast_messages: molecule_gossip::GetBroadcastMessages,
    ) -> Result<Self, Self::Error> {
        Ok(GetBroadcastMessages {
            id: get_broadcast_messages.id().unpack(),
            chain_hash: get_broadcast_messages.chain_hash().into(),
            after_cursor: get_broadcast_messages.after_cursor().try_into()?,
            count: get_broadcast_messages.count().into(),
        })
    }
}

#[derive(Debug, Clone)]
pub struct GetBroadcastMessagesResult {
    pub id: u64,
    pub messages: Vec<BroadcastMessage>,
}

impl From<GetBroadcastMessagesResult> for molecule_gossip::GetBroadcastMessagesResult {
    fn from(get_broadcast_messages_result: GetBroadcastMessagesResult) -> Self {
        molecule_gossip::GetBroadcastMessagesResult::new_builder()
            .id(get_broadcast_messages_result.id.pack())
            .messages(
                molecule_gossip::BroadcastMessages::new_builder()
                    .set(
                        get_broadcast_messages_result
                            .messages
                            .into_iter()
                            .map(|message| message.into())
                            .collect(),
                    )
                    .build(),
            )
            .build()
    }
}

impl TryFrom<molecule_gossip::GetBroadcastMessagesResult> for GetBroadcastMessagesResult {
    type Error = Error;

    fn try_from(
        get_broadcast_messages_result: molecule_gossip::GetBroadcastMessagesResult,
    ) -> Result<Self, Self::Error> {
        Ok(GetBroadcastMessagesResult {
            id: get_broadcast_messages_result.id().unpack(),
            messages: get_broadcast_messages_result
                .messages()
                .into_iter()
                .map(|message| message.try_into())
                .collect::<Result<Vec<BroadcastMessage>, Error>>()?,
        })
    }
}

#[derive(Debug, Clone)]
pub struct QueryBroadcastMessages {
    pub id: u64,
    pub chain_hash: Hash256,
    pub queries: Vec<BroadcastMessageQuery>,
}

impl From<QueryBroadcastMessages> for molecule_gossip::QueryBroadcastMessages {
    fn from(query_broadcast_messages: QueryBroadcastMessages) -> Self {
        molecule_gossip::QueryBroadcastMessages::new_builder()
            .id(query_broadcast_messages.id.pack())
            .chain_hash(query_broadcast_messages.chain_hash.into())
            .queries(
                molecule_gossip::BroadcastMessageQueries::new_builder()
                    .set(
                        query_broadcast_messages
                            .queries
                            .into_iter()
                            .map(|query| query.into())
                            .collect(),
                    )
                    .build(),
            )
            .build()
    }
}

impl TryFrom<molecule_gossip::QueryBroadcastMessages> for QueryBroadcastMessages {
    type Error = Error;

    fn try_from(
        query_broadcast_messages: molecule_gossip::QueryBroadcastMessages,
    ) -> Result<Self, Self::Error> {
        Ok(QueryBroadcastMessages {
            id: query_broadcast_messages.id().unpack(),
            chain_hash: query_broadcast_messages.chain_hash().into(),
            queries: query_broadcast_messages
                .queries()
                .into_iter()
                .map(|query| query.try_into())
                .collect::<Result<Vec<_>, Error>>()?,
        })
    }
}

#[derive(Debug, Clone)]
pub struct QueryBroadcastMessagesResult {
    pub id: u64,
    pub messages: Vec<BroadcastMessage>,
    pub missing_queries: Vec<u16>,
}

impl From<QueryBroadcastMessagesResult> for molecule_gossip::QueryBroadcastMessagesResult {
    fn from(query_broadcast_messages_result: QueryBroadcastMessagesResult) -> Self {
        molecule_gossip::QueryBroadcastMessagesResult::new_builder()
            .id(query_broadcast_messages_result.id.pack())
            .messages(
                molecule_gossip::BroadcastMessages::new_builder()
                    .set(
                        query_broadcast_messages_result
                            .messages
                            .into_iter()
                            .map(|message| message.into())
                            .collect(),
                    )
                    .build(),
            )
            .missing_queries(
                query_broadcast_messages_result
                    .missing_queries
                    .into_iter()
                    .map(|x| x.into())
                    .collect(),
            )
            .build()
    }
}

impl TryFrom<molecule_gossip::QueryBroadcastMessagesResult> for QueryBroadcastMessagesResult {
    type Error = Error;

    fn try_from(
        query_broadcast_messages_result: molecule_gossip::QueryBroadcastMessagesResult,
    ) -> Result<Self, Self::Error> {
        Ok(QueryBroadcastMessagesResult {
            id: query_broadcast_messages_result.id().unpack(),
            messages: query_broadcast_messages_result
                .messages()
                .into_iter()
                .map(|message| message.try_into())
                .collect::<Result<Vec<BroadcastMessage>, Error>>()?,
            missing_queries: query_broadcast_messages_result
                .missing_queries()
                .into_iter()
                .map(u16::from)
                .collect(),
        })
    }
}

impl From<FiberMessage> for molecule_fiber::FiberMessageUnion {
    fn from(fiber_message: FiberMessage) -> Self {
        match fiber_message {
            FiberMessage::ChannelInitialization(open_channel) => {
                molecule_fiber::FiberMessageUnion::OpenChannel(open_channel.into())
            }
            FiberMessage::ChannelNormalOperation(m) => match m {
                FiberChannelMessage::AcceptChannel(accept_channel) => {
                    molecule_fiber::FiberMessageUnion::AcceptChannel(accept_channel.into())
                }
                FiberChannelMessage::CommitmentSigned(commitment_signed) => {
                    molecule_fiber::FiberMessageUnion::CommitmentSigned(commitment_signed.into())
                }
                FiberChannelMessage::TxSignatures(tx_signatures) => {
                    molecule_fiber::FiberMessageUnion::TxSignatures(tx_signatures.into())
                }
                FiberChannelMessage::ChannelReady(channel_ready) => {
                    molecule_fiber::FiberMessageUnion::ChannelReady(channel_ready.into())
                }
                FiberChannelMessage::TxUpdate(tx_update) => {
                    molecule_fiber::FiberMessageUnion::TxUpdate(tx_update.into())
                }
                FiberChannelMessage::TxComplete(tx_complete) => {
                    molecule_fiber::FiberMessageUnion::TxComplete(tx_complete.into())
                }
                FiberChannelMessage::TxAbort(tx_abort) => {
                    molecule_fiber::FiberMessageUnion::TxAbort(tx_abort.into())
                }
                FiberChannelMessage::TxInitRBF(tx_init_rbf) => {
                    molecule_fiber::FiberMessageUnion::TxInitRBF(tx_init_rbf.into())
                }
                FiberChannelMessage::TxAckRBF(tx_ack_rbf) => {
                    molecule_fiber::FiberMessageUnion::TxAckRBF(tx_ack_rbf.into())
                }
                FiberChannelMessage::Shutdown(shutdown) => {
                    molecule_fiber::FiberMessageUnion::Shutdown(shutdown.into())
                }
                FiberChannelMessage::ClosingSigned(closing_signed) => {
                    molecule_fiber::FiberMessageUnion::ClosingSigned(closing_signed.into())
                }
                FiberChannelMessage::UpdateTlcInfo(update_tlc_info) => {
                    molecule_fiber::FiberMessageUnion::UpdateTlcInfo(update_tlc_info.into())
                }
                FiberChannelMessage::AddTlc(add_tlc) => {
                    molecule_fiber::FiberMessageUnion::AddTlc(add_tlc.into())
                }
                FiberChannelMessage::RemoveTlc(remove_tlc) => {
                    molecule_fiber::FiberMessageUnion::RemoveTlc(remove_tlc.into())
                }
                FiberChannelMessage::RevokeAndAck(revoke_and_ack) => {
                    molecule_fiber::FiberMessageUnion::RevokeAndAck(revoke_and_ack.into())
                }
                FiberChannelMessage::ReestablishChannel(reestablish_channel) => {
                    molecule_fiber::FiberMessageUnion::ReestablishChannel(
                        reestablish_channel.into(),
                    )
                }
                FiberChannelMessage::AnnouncementSignatures(announcement_signatures) => {
                    molecule_fiber::FiberMessageUnion::AnnouncementSignatures(
                        announcement_signatures.into(),
                    )
                }
            },
        }
    }
}

impl TryFrom<molecule_fiber::FiberMessageUnion> for FiberMessage {
    type Error = Error;

    fn try_from(fiber_message: molecule_fiber::FiberMessageUnion) -> Result<Self, Self::Error> {
        Ok(match fiber_message {
            molecule_fiber::FiberMessageUnion::OpenChannel(open_channel) => {
                FiberMessage::ChannelInitialization(open_channel.try_into()?)
            }
            molecule_fiber::FiberMessageUnion::AcceptChannel(accept_channel) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::AcceptChannel(
                    accept_channel.try_into()?,
                ))
            }
            molecule_fiber::FiberMessageUnion::CommitmentSigned(commitment_signed) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::CommitmentSigned(
                    commitment_signed.try_into()?,
                ))
            }
            molecule_fiber::FiberMessageUnion::TxSignatures(tx_signatures) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::TxSignatures(
                    tx_signatures.try_into()?,
                ))
            }
            molecule_fiber::FiberMessageUnion::ChannelReady(channel_ready) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::ChannelReady(
                    channel_ready.try_into()?,
                ))
            }
            molecule_fiber::FiberMessageUnion::TxUpdate(tx_update) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::TxUpdate(
                    tx_update.try_into()?,
                ))
            }
            molecule_fiber::FiberMessageUnion::TxComplete(tx_complete) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::TxComplete(
                    tx_complete.try_into()?,
                ))
            }
            molecule_fiber::FiberMessageUnion::TxAbort(tx_abort) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::TxAbort(
                    tx_abort.try_into()?,
                ))
            }
            molecule_fiber::FiberMessageUnion::TxInitRBF(tx_init_rbf) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::TxInitRBF(
                    tx_init_rbf.try_into()?,
                ))
            }
            molecule_fiber::FiberMessageUnion::TxAckRBF(tx_ack_rbf) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::TxAckRBF(
                    tx_ack_rbf.try_into()?,
                ))
            }
            molecule_fiber::FiberMessageUnion::Shutdown(shutdown) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::Shutdown(
                    shutdown.try_into()?,
                ))
            }
            molecule_fiber::FiberMessageUnion::ClosingSigned(closing_signed) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::ClosingSigned(
                    closing_signed.try_into()?,
                ))
            }
            molecule_fiber::FiberMessageUnion::UpdateTlcInfo(update_tlc_info) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::UpdateTlcInfo(
                    update_tlc_info.into(),
                ))
            }
            molecule_fiber::FiberMessageUnion::AddTlc(add_tlc) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::AddTlc(
                    add_tlc.try_into()?,
                ))
            }
            molecule_fiber::FiberMessageUnion::RemoveTlc(remove_tlc) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::RemoveTlc(
                    remove_tlc.try_into()?,
                ))
            }
            molecule_fiber::FiberMessageUnion::RevokeAndAck(revoke_and_ack) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::RevokeAndAck(
                    revoke_and_ack.try_into()?,
                ))
            }
            molecule_fiber::FiberMessageUnion::ReestablishChannel(reestablish_channel) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::ReestablishChannel(
                    reestablish_channel.try_into()?,
                ))
            }
            molecule_fiber::FiberMessageUnion::AnnouncementSignatures(announcement_signatures) => {
                FiberMessage::ChannelNormalOperation(FiberChannelMessage::AnnouncementSignatures(
                    announcement_signatures.try_into()?,
                ))
            }
        })
    }
}

impl From<FiberMessage> for molecule_fiber::FiberMessage {
    fn from(fiber_message: FiberMessage) -> Self {
        molecule_fiber::FiberMessage::new_builder()
            .set(fiber_message)
            .build()
    }
}

impl TryFrom<molecule_fiber::FiberMessage> for FiberMessage {
    type Error = Error;

    fn try_from(fiber_message: molecule_fiber::FiberMessage) -> Result<Self, Self::Error> {
        fiber_message.to_enum().try_into()
    }
}

macro_rules! impl_traits {
    ($t:ident) => {
        impl $t {
            pub fn to_molecule_bytes(self) -> molecule::bytes::Bytes {
                molecule_fiber::$t::from(self).as_bytes()
            }
        }

        impl $t {
            pub fn from_molecule_slice(data: &[u8]) -> Result<Self, Error> {
                molecule_fiber::$t::from_slice(data)
                    .map_err(Into::into)
                    .and_then(TryInto::try_into)
            }
        }
    };
}

impl_traits!(FiberMessage);

pub(crate) fn deterministically_hash<T: Entity>(v: &T) -> [u8; 32] {
    ckb_hash::blake2b_256(v.as_slice())
}

#[serde_as]
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct PaymentHopData {
    pub amount: u128,
    pub expiry: u64,
    // this is only specified in the last hop in the keysend mode
    pub payment_preimage: Option<Hash256>,
    pub hash_algorithm: HashAlgorithm,
    pub funding_tx_hash: Hash256,
    pub next_hop: Option<Pubkey>,
}

/// Trait for hop data
pub trait HopData: Sized {
    const PACKET_DATA_LEN: usize;
    fn next_hop(&self) -> Option<Pubkey>;
    fn assoc_data(&self) -> Option<Vec<u8>>;
    fn serialize(&self) -> Vec<u8>;
    fn deserialize(data: &[u8]) -> Option<Self>;
}

impl HopData for PaymentHopData {
    const PACKET_DATA_LEN: usize = 6500;

    fn next_hop(&self) -> Option<Pubkey> {
        self.next_hop
    }

    fn assoc_data(&self) -> Option<Vec<u8>> {
        None
    }

    fn serialize(&self) -> Vec<u8> {
        molecule_fiber::PaymentHopData::from(self.clone())
            .as_bytes()
            .to_vec()
    }

    fn deserialize(data: &[u8]) -> Option<Self> {
        molecule_fiber::PaymentHopData::from_slice(data)
            .ok()
            .map(|x| x.into())
    }
}

impl From<PaymentHopData> for molecule_fiber::PaymentHopData {
    fn from(payment_hop_data: PaymentHopData) -> Self {
        molecule_fiber::PaymentHopData::new_builder()
            .amount(payment_hop_data.amount.pack())
            .expiry(payment_hop_data.expiry.pack())
            .payment_preimage(
                PaymentPreimageOpt::new_builder()
                    .set(payment_hop_data.payment_preimage.map(|x| x.into()))
                    .build(),
            )
            .hash_algorithm(Byte::new(payment_hop_data.hash_algorithm as u8))
            .funding_tx_hash(payment_hop_data.funding_tx_hash.into())
            .next_hop(
                PubkeyOpt::new_builder()
                    .set(payment_hop_data.next_hop.map(|x| x.into()))
                    .build(),
            )
            .build()
    }
}

impl From<molecule_fiber::PaymentHopData> for PaymentHopData {
    fn from(payment_hop_data: molecule_fiber::PaymentHopData) -> Self {
        PaymentHopData {
            amount: payment_hop_data.amount().unpack(),
            expiry: payment_hop_data.expiry().unpack(),
            payment_preimage: payment_hop_data
                .payment_preimage()
                .to_opt()
                .map(|x| x.into()),
            hash_algorithm: payment_hop_data
                .hash_algorithm()
                .try_into()
                .expect("valid hash algorithm"),
            funding_tx_hash: payment_hop_data.funding_tx_hash().into(),
            next_hop: payment_hop_data
                .next_hop()
                .to_opt()
                .map(|x| x.try_into().expect("invalid pubkey")),
        }
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct OnionPacket<T> {
    _phantom: PhantomData<T>,
    // The encrypted packet
    data: Vec<u8>,
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct PeeledOnionPacket<T> {
    // The decrypted hop data for the current hop
    pub current: T,
    // The shared secret for `current` used for returning error. Set to all zeros for the origin node
    // who has no shared secret.
    pub shared_secret: [u8; 32],
    // The packet for the next hop
    pub next: Option<OnionPacket<T>>,
}

pub type PaymentOnionPacket = OnionPacket<PaymentHopData>;
pub type PeeledPaymentOnionPacket = PeeledOnionPacket<PaymentHopData>;

impl<T> OnionPacket<T> {
    pub fn new(data: Vec<u8>) -> Self {
        OnionPacket {
            _phantom: PhantomData,
            data,
        }
    }

    pub fn into_sphinx_onion_packet(self) -> Result<fiber_sphinx::OnionPacket, Error> {
        fiber_sphinx::OnionPacket::from_bytes(self.data)
            .map_err(|err| Error::OnionPacket(err.into()))
    }

    pub fn into_bytes(self) -> Vec<u8> {
        self.data
    }

    pub fn as_bytes(&self) -> &[u8] {
        &self.data
    }
}

impl<T: HopData> OnionPacket<T> {
    /// Peels the next layer of the onion packet using the privkey of the current node.
    ///
    /// Returns errors when:
    /// - This is the packet for the last hop.
    /// - Fail to peel the packet using the given private key.
    pub fn peel<C: Verification>(
        self,
        privkey: &Privkey,
        assoc_data: Option<&[u8]>,
        secp_ctx: &Secp256k1<C>,
    ) -> Result<PeeledOnionPacket<T>, Error> {
        let sphinx_packet = self.into_sphinx_onion_packet()?;
        let shared_secret = sphinx_packet.shared_secret(&privkey.0);

        let (new_current, new_next) = sphinx_packet
            .peel(&privkey.0, assoc_data, secp_ctx, get_hop_data_len)
            .map_err(|err| Error::OnionPacket(err.into()))?;

        let current = unpack_hop_data(&new_current)
            .ok_or_else(|| Error::OnionPacket(OnionPacketError::InvalidHopData))?;
        // All zeros hmac indicates the last hop
        let next = new_next
            .hmac
            .iter()
            .any(|b| *b != 0)
            .then(|| OnionPacket::new(new_next.into_bytes()));

        Ok(PeeledOnionPacket {
            current,
            next,
            shared_secret,
        })
    }
}

impl<T: HopData> PeeledOnionPacket<T> {
    /// - `hops_info`: the first is the instruction for the origin node itself.
    ///                Remaining elements are for each node to receive the packet.
    pub fn create<C: Signing>(
        session_key: Privkey,
        mut hops_infos: Vec<T>,
        assoc_data: Option<Vec<u8>>,
        secp_ctx: &Secp256k1<C>,
    ) -> Result<Self, Error> {
        if hops_infos.is_empty() {
            return Err(Error::OnionPacket(SphinxError::HopsIsEmpty.into()));
        }

        let hops_path: Vec<PublicKey> = hops_infos
            .iter()
            .map(HopData::next_hop)
            .take_while(Option::is_some)
            .map(|opt| opt.expect("must be some").into())
            .collect();

        // Add length as the header
        let hops_data = hops_infos.iter().skip(1).map(pack_hop_data).collect();

        let current = hops_infos.swap_remove(0);
        let assoc_data = if assoc_data.is_some() {
            assoc_data
        } else {
            current.assoc_data()
        };

        let next = if !hops_path.is_empty() {
            Some(OnionPacket::new(
                fiber_sphinx::OnionPacket::create(
                    session_key.into(),
                    hops_path,
                    hops_data,
                    assoc_data,
                    T::PACKET_DATA_LEN,
                    secp_ctx,
                )
                .map_err(|err| Error::OnionPacket(err.into()))?
                .into_bytes(),
            ))
        } else {
            None
        };

        Ok(PeeledOnionPacket {
            current,
            next,
            // Use all zeros for the sender
            shared_secret: NO_SHARED_SECRET,
        })
    }

    /// Returns true if this is the peeled packet for the last destination.
    pub fn is_last(&self) -> bool {
        self.next.is_none()
    }

    /// Peels the next layer of the onion packet using the privkey of the current node.
    ///
    /// Returns errors when:
    /// - This is the packet for the last hop.
    /// - Fail to peel the packet using the given private key.
    pub fn peel<C: Verification>(
        self,
        privkey: &Privkey,
        secp_ctx: &Secp256k1<C>,
    ) -> Result<Self, Error> {
        let next = self
            .next
            .ok_or_else(|| Error::OnionPacket(OnionPacketError::PeelingLastHop))?;

        next.peel(privkey, self.current.assoc_data().as_deref(), secp_ctx)
    }

    pub fn serialize(&self) -> Vec<u8> {
        let mut res = pack_hop_data(&self.current);
        res.extend(self.shared_secret);
        if let Some(ref next) = self.next {
            res.extend(&next.data[..]);
        }
        res
    }

    pub fn deserialize(data: &[u8]) -> Result<Self, Error> {
        let mut read_bytes = get_hop_data_len(data)
            .ok_or_else(|| Error::OnionPacket(OnionPacketError::InvalidHopData))?;
        let current = unpack_hop_data(data)
            .ok_or_else(|| Error::OnionPacket(OnionPacketError::InvalidHopData))?;

        // Ensure backward compatibility
        let mut shared_secret = NO_SHARED_SECRET;
        if data.len() >= read_bytes + 32 && data.len() != read_bytes + T::PACKET_DATA_LEN {
            shared_secret.copy_from_slice(&data[read_bytes..read_bytes + 32]);
            read_bytes += 32;
        }

        let next = if read_bytes < data.len() {
            Some(OnionPacket::new(data[read_bytes..].to_vec()))
        } else {
            None
        };
        Ok(Self {
            current,
            shared_secret,
            next,
        })
    }
}

const HOP_DATA_HEAD_LEN: usize = std::mem::size_of::<u64>();

/// TODO: when JSON is replaced, this function may return `data` directly.
fn pack_hop_data<T: HopData>(hop_data: &T) -> Vec<u8> {
    let mut serialized = hop_data.serialize();
    // A temporary solution to prepend the length as the header
    let mut packed = (serialized.len() as u64).to_be_bytes().to_vec();
    packed.append(&mut serialized);
    packed
}

/// TODO: when JSON is replaced, this function may return `data` directly.
fn unpack_hop_data<T: HopData>(buf: &[u8]) -> Option<T> {
    let len = get_hop_data_len(buf)?;
    if buf.len() < len {
        return None;
    }
    T::deserialize(&buf[HOP_DATA_HEAD_LEN..len])
}

/// TODO: when JSON is replaced, this function may return `data` directly.
fn get_hop_data_len(buf: &[u8]) -> Option<usize> {
    if buf.len() < HOP_DATA_HEAD_LEN {
        return None;
    }
    Some(
        u64::from_be_bytes(
            buf[0..HOP_DATA_HEAD_LEN]
                .try_into()
                .expect("u64 from slice"),
        ) as usize
            + HOP_DATA_HEAD_LEN,
    )
}


================================================
File: src/fiber/gen/fiber.rs
================================================
// Generated by Molecule 0.8.0

use super::blockchain::*;
use molecule::prelude::*;
#[derive(Clone)]
pub struct Uint16(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for Uint16 {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for Uint16 {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for Uint16 {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl ::core::default::Default for Uint16 {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        Uint16::new_unchecked(v)
    }
}
impl Uint16 {
    const DEFAULT_VALUE: [u8; 2] = [0, 0];
    pub const TOTAL_SIZE: usize = 2;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 2;
    pub fn nth0(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(0..1))
    }
    pub fn nth1(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(1..2))
    }
    pub fn raw_data(&self) -> molecule::bytes::Bytes {
        self.as_bytes()
    }
    pub fn as_reader<'r>(&'r self) -> Uint16Reader<'r> {
        Uint16Reader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for Uint16 {
    type Builder = Uint16Builder;
    const NAME: &'static str = "Uint16";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        Uint16(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        Uint16Reader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        Uint16Reader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set([self.nth0(), self.nth1()])
    }
}
#[derive(Clone, Copy)]
pub struct Uint16Reader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for Uint16Reader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for Uint16Reader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for Uint16Reader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl<'r> Uint16Reader<'r> {
    pub const TOTAL_SIZE: usize = 2;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 2;
    pub fn nth0(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[0..1])
    }
    pub fn nth1(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[1..2])
    }
    pub fn raw_data(&self) -> &'r [u8] {
        self.as_slice()
    }
}
impl<'r> molecule::prelude::Reader<'r> for Uint16Reader<'r> {
    type Entity = Uint16;
    const NAME: &'static str = "Uint16Reader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        Uint16Reader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone)]
pub struct Uint16Builder(pub(crate) [Byte; 2]);
impl ::core::fmt::Debug for Uint16Builder {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:?})", Self::NAME, &self.0[..])
    }
}
impl ::core::default::Default for Uint16Builder {
    fn default() -> Self {
        Uint16Builder([Byte::default(), Byte::default()])
    }
}
impl Uint16Builder {
    pub const TOTAL_SIZE: usize = 2;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 2;
    pub fn set(mut self, v: [Byte; 2]) -> Self {
        self.0 = v;
        self
    }
    pub fn nth0(mut self, v: Byte) -> Self {
        self.0[0] = v;
        self
    }
    pub fn nth1(mut self, v: Byte) -> Self {
        self.0[1] = v;
        self
    }
}
impl molecule::prelude::Builder for Uint16Builder {
    type Entity = Uint16;
    const NAME: &'static str = "Uint16Builder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.0[0].as_slice())?;
        writer.write_all(self.0[1].as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        Uint16::new_unchecked(inner.into())
    }
}
impl From<[Byte; 2usize]> for Uint16 {
    fn from(value: [Byte; 2usize]) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl ::core::convert::TryFrom<&[Byte]> for Uint16 {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[Byte]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(Self::new_builder()
            .set(<&[Byte; 2usize]>::try_from(value)?.clone())
            .build())
    }
}
impl From<Uint16> for [Byte; 2usize] {
    #[track_caller]
    fn from(value: Uint16) -> Self {
        [value.nth0(), value.nth1()]
    }
}
impl From<[u8; 2usize]> for Uint16 {
    fn from(value: [u8; 2usize]) -> Self {
        Uint16Reader::new_unchecked(&value).to_entity()
    }
}
impl ::core::convert::TryFrom<&[u8]> for Uint16 {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[u8]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(<[u8; 2usize]>::try_from(value)?.into())
    }
}
impl From<Uint16> for [u8; 2usize] {
    #[track_caller]
    fn from(value: Uint16) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<Uint16Reader<'a>> for &'a [u8; 2usize] {
    #[track_caller]
    fn from(value: Uint16Reader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<&'a Uint16Reader<'a>> for &'a [u8; 2usize] {
    #[track_caller]
    fn from(value: &'a Uint16Reader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
#[derive(Clone)]
pub struct EcdsaSignature(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for EcdsaSignature {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for EcdsaSignature {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for EcdsaSignature {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl ::core::default::Default for EcdsaSignature {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        EcdsaSignature::new_unchecked(v)
    }
}
impl EcdsaSignature {
    const DEFAULT_VALUE: [u8; 64] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0,
    ];
    pub const TOTAL_SIZE: usize = 64;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 64;
    pub fn nth0(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(0..1))
    }
    pub fn nth1(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(1..2))
    }
    pub fn nth2(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(2..3))
    }
    pub fn nth3(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(3..4))
    }
    pub fn nth4(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(4..5))
    }
    pub fn nth5(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(5..6))
    }
    pub fn nth6(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(6..7))
    }
    pub fn nth7(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(7..8))
    }
    pub fn nth8(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(8..9))
    }
    pub fn nth9(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(9..10))
    }
    pub fn nth10(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(10..11))
    }
    pub fn nth11(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(11..12))
    }
    pub fn nth12(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(12..13))
    }
    pub fn nth13(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(13..14))
    }
    pub fn nth14(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(14..15))
    }
    pub fn nth15(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(15..16))
    }
    pub fn nth16(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(16..17))
    }
    pub fn nth17(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(17..18))
    }
    pub fn nth18(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(18..19))
    }
    pub fn nth19(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(19..20))
    }
    pub fn nth20(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(20..21))
    }
    pub fn nth21(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(21..22))
    }
    pub fn nth22(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(22..23))
    }
    pub fn nth23(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(23..24))
    }
    pub fn nth24(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(24..25))
    }
    pub fn nth25(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(25..26))
    }
    pub fn nth26(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(26..27))
    }
    pub fn nth27(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(27..28))
    }
    pub fn nth28(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(28..29))
    }
    pub fn nth29(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(29..30))
    }
    pub fn nth30(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(30..31))
    }
    pub fn nth31(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(31..32))
    }
    pub fn nth32(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(32..33))
    }
    pub fn nth33(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(33..34))
    }
    pub fn nth34(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(34..35))
    }
    pub fn nth35(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(35..36))
    }
    pub fn nth36(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(36..37))
    }
    pub fn nth37(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(37..38))
    }
    pub fn nth38(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(38..39))
    }
    pub fn nth39(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(39..40))
    }
    pub fn nth40(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(40..41))
    }
    pub fn nth41(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(41..42))
    }
    pub fn nth42(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(42..43))
    }
    pub fn nth43(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(43..44))
    }
    pub fn nth44(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(44..45))
    }
    pub fn nth45(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(45..46))
    }
    pub fn nth46(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(46..47))
    }
    pub fn nth47(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(47..48))
    }
    pub fn nth48(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(48..49))
    }
    pub fn nth49(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(49..50))
    }
    pub fn nth50(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(50..51))
    }
    pub fn nth51(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(51..52))
    }
    pub fn nth52(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(52..53))
    }
    pub fn nth53(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(53..54))
    }
    pub fn nth54(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(54..55))
    }
    pub fn nth55(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(55..56))
    }
    pub fn nth56(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(56..57))
    }
    pub fn nth57(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(57..58))
    }
    pub fn nth58(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(58..59))
    }
    pub fn nth59(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(59..60))
    }
    pub fn nth60(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(60..61))
    }
    pub fn nth61(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(61..62))
    }
    pub fn nth62(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(62..63))
    }
    pub fn nth63(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(63..64))
    }
    pub fn raw_data(&self) -> molecule::bytes::Bytes {
        self.as_bytes()
    }
    pub fn as_reader<'r>(&'r self) -> EcdsaSignatureReader<'r> {
        EcdsaSignatureReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for EcdsaSignature {
    type Builder = EcdsaSignatureBuilder;
    const NAME: &'static str = "EcdsaSignature";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        EcdsaSignature(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        EcdsaSignatureReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        EcdsaSignatureReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set([
            self.nth0(),
            self.nth1(),
            self.nth2(),
            self.nth3(),
            self.nth4(),
            self.nth5(),
            self.nth6(),
            self.nth7(),
            self.nth8(),
            self.nth9(),
            self.nth10(),
            self.nth11(),
            self.nth12(),
            self.nth13(),
            self.nth14(),
            self.nth15(),
            self.nth16(),
            self.nth17(),
            self.nth18(),
            self.nth19(),
            self.nth20(),
            self.nth21(),
            self.nth22(),
            self.nth23(),
            self.nth24(),
            self.nth25(),
            self.nth26(),
            self.nth27(),
            self.nth28(),
            self.nth29(),
            self.nth30(),
            self.nth31(),
            self.nth32(),
            self.nth33(),
            self.nth34(),
            self.nth35(),
            self.nth36(),
            self.nth37(),
            self.nth38(),
            self.nth39(),
            self.nth40(),
            self.nth41(),
            self.nth42(),
            self.nth43(),
            self.nth44(),
            self.nth45(),
            self.nth46(),
            self.nth47(),
            self.nth48(),
            self.nth49(),
            self.nth50(),
            self.nth51(),
            self.nth52(),
            self.nth53(),
            self.nth54(),
            self.nth55(),
            self.nth56(),
            self.nth57(),
            self.nth58(),
            self.nth59(),
            self.nth60(),
            self.nth61(),
            self.nth62(),
            self.nth63(),
        ])
    }
}
#[derive(Clone, Copy)]
pub struct EcdsaSignatureReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for EcdsaSignatureReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for EcdsaSignatureReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for EcdsaSignatureReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl<'r> EcdsaSignatureReader<'r> {
    pub const TOTAL_SIZE: usize = 64;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 64;
    pub fn nth0(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[0..1])
    }
    pub fn nth1(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[1..2])
    }
    pub fn nth2(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[2..3])
    }
    pub fn nth3(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[3..4])
    }
    pub fn nth4(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[4..5])
    }
    pub fn nth5(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[5..6])
    }
    pub fn nth6(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[6..7])
    }
    pub fn nth7(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[7..8])
    }
    pub fn nth8(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[8..9])
    }
    pub fn nth9(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[9..10])
    }
    pub fn nth10(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[10..11])
    }
    pub fn nth11(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[11..12])
    }
    pub fn nth12(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[12..13])
    }
    pub fn nth13(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[13..14])
    }
    pub fn nth14(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[14..15])
    }
    pub fn nth15(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[15..16])
    }
    pub fn nth16(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[16..17])
    }
    pub fn nth17(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[17..18])
    }
    pub fn nth18(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[18..19])
    }
    pub fn nth19(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[19..20])
    }
    pub fn nth20(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[20..21])
    }
    pub fn nth21(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[21..22])
    }
    pub fn nth22(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[22..23])
    }
    pub fn nth23(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[23..24])
    }
    pub fn nth24(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[24..25])
    }
    pub fn nth25(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[25..26])
    }
    pub fn nth26(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[26..27])
    }
    pub fn nth27(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[27..28])
    }
    pub fn nth28(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[28..29])
    }
    pub fn nth29(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[29..30])
    }
    pub fn nth30(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[30..31])
    }
    pub fn nth31(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[31..32])
    }
    pub fn nth32(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[32..33])
    }
    pub fn nth33(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[33..34])
    }
    pub fn nth34(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[34..35])
    }
    pub fn nth35(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[35..36])
    }
    pub fn nth36(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[36..37])
    }
    pub fn nth37(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[37..38])
    }
    pub fn nth38(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[38..39])
    }
    pub fn nth39(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[39..40])
    }
    pub fn nth40(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[40..41])
    }
    pub fn nth41(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[41..42])
    }
    pub fn nth42(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[42..43])
    }
    pub fn nth43(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[43..44])
    }
    pub fn nth44(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[44..45])
    }
    pub fn nth45(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[45..46])
    }
    pub fn nth46(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[46..47])
    }
    pub fn nth47(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[47..48])
    }
    pub fn nth48(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[48..49])
    }
    pub fn nth49(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[49..50])
    }
    pub fn nth50(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[50..51])
    }
    pub fn nth51(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[51..52])
    }
    pub fn nth52(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[52..53])
    }
    pub fn nth53(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[53..54])
    }
    pub fn nth54(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[54..55])
    }
    pub fn nth55(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[55..56])
    }
    pub fn nth56(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[56..57])
    }
    pub fn nth57(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[57..58])
    }
    pub fn nth58(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[58..59])
    }
    pub fn nth59(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[59..60])
    }
    pub fn nth60(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[60..61])
    }
    pub fn nth61(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[61..62])
    }
    pub fn nth62(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[62..63])
    }
    pub fn nth63(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[63..64])
    }
    pub fn raw_data(&self) -> &'r [u8] {
        self.as_slice()
    }
}
impl<'r> molecule::prelude::Reader<'r> for EcdsaSignatureReader<'r> {
    type Entity = EcdsaSignature;
    const NAME: &'static str = "EcdsaSignatureReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        EcdsaSignatureReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone)]
pub struct EcdsaSignatureBuilder(pub(crate) [Byte; 64]);
impl ::core::fmt::Debug for EcdsaSignatureBuilder {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:?})", Self::NAME, &self.0[..])
    }
}
impl ::core::default::Default for EcdsaSignatureBuilder {
    fn default() -> Self {
        EcdsaSignatureBuilder([
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
        ])
    }
}
impl EcdsaSignatureBuilder {
    pub const TOTAL_SIZE: usize = 64;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 64;
    pub fn set(mut self, v: [Byte; 64]) -> Self {
        self.0 = v;
        self
    }
    pub fn nth0(mut self, v: Byte) -> Self {
        self.0[0] = v;
        self
    }
    pub fn nth1(mut self, v: Byte) -> Self {
        self.0[1] = v;
        self
    }
    pub fn nth2(mut self, v: Byte) -> Self {
        self.0[2] = v;
        self
    }
    pub fn nth3(mut self, v: Byte) -> Self {
        self.0[3] = v;
        self
    }
    pub fn nth4(mut self, v: Byte) -> Self {
        self.0[4] = v;
        self
    }
    pub fn nth5(mut self, v: Byte) -> Self {
        self.0[5] = v;
        self
    }
    pub fn nth6(mut self, v: Byte) -> Self {
        self.0[6] = v;
        self
    }
    pub fn nth7(mut self, v: Byte) -> Self {
        self.0[7] = v;
        self
    }
    pub fn nth8(mut self, v: Byte) -> Self {
        self.0[8] = v;
        self
    }
    pub fn nth9(mut self, v: Byte) -> Self {
        self.0[9] = v;
        self
    }
    pub fn nth10(mut self, v: Byte) -> Self {
        self.0[10] = v;
        self
    }
    pub fn nth11(mut self, v: Byte) -> Self {
        self.0[11] = v;
        self
    }
    pub fn nth12(mut self, v: Byte) -> Self {
        self.0[12] = v;
        self
    }
    pub fn nth13(mut self, v: Byte) -> Self {
        self.0[13] = v;
        self
    }
    pub fn nth14(mut self, v: Byte) -> Self {
        self.0[14] = v;
        self
    }
    pub fn nth15(mut self, v: Byte) -> Self {
        self.0[15] = v;
        self
    }
    pub fn nth16(mut self, v: Byte) -> Self {
        self.0[16] = v;
        self
    }
    pub fn nth17(mut self, v: Byte) -> Self {
        self.0[17] = v;
        self
    }
    pub fn nth18(mut self, v: Byte) -> Self {
        self.0[18] = v;
        self
    }
    pub fn nth19(mut self, v: Byte) -> Self {
        self.0[19] = v;
        self
    }
    pub fn nth20(mut self, v: Byte) -> Self {
        self.0[20] = v;
        self
    }
    pub fn nth21(mut self, v: Byte) -> Self {
        self.0[21] = v;
        self
    }
    pub fn nth22(mut self, v: Byte) -> Self {
        self.0[22] = v;
        self
    }
    pub fn nth23(mut self, v: Byte) -> Self {
        self.0[23] = v;
        self
    }
    pub fn nth24(mut self, v: Byte) -> Self {
        self.0[24] = v;
        self
    }
    pub fn nth25(mut self, v: Byte) -> Self {
        self.0[25] = v;
        self
    }
    pub fn nth26(mut self, v: Byte) -> Self {
        self.0[26] = v;
        self
    }
    pub fn nth27(mut self, v: Byte) -> Self {
        self.0[27] = v;
        self
    }
    pub fn nth28(mut self, v: Byte) -> Self {
        self.0[28] = v;
        self
    }
    pub fn nth29(mut self, v: Byte) -> Self {
        self.0[29] = v;
        self
    }
    pub fn nth30(mut self, v: Byte) -> Self {
        self.0[30] = v;
        self
    }
    pub fn nth31(mut self, v: Byte) -> Self {
        self.0[31] = v;
        self
    }
    pub fn nth32(mut self, v: Byte) -> Self {
        self.0[32] = v;
        self
    }
    pub fn nth33(mut self, v: Byte) -> Self {
        self.0[33] = v;
        self
    }
    pub fn nth34(mut self, v: Byte) -> Self {
        self.0[34] = v;
        self
    }
    pub fn nth35(mut self, v: Byte) -> Self {
        self.0[35] = v;
        self
    }
    pub fn nth36(mut self, v: Byte) -> Self {
        self.0[36] = v;
        self
    }
    pub fn nth37(mut self, v: Byte) -> Self {
        self.0[37] = v;
        self
    }
    pub fn nth38(mut self, v: Byte) -> Self {
        self.0[38] = v;
        self
    }
    pub fn nth39(mut self, v: Byte) -> Self {
        self.0[39] = v;
        self
    }
    pub fn nth40(mut self, v: Byte) -> Self {
        self.0[40] = v;
        self
    }
    pub fn nth41(mut self, v: Byte) -> Self {
        self.0[41] = v;
        self
    }
    pub fn nth42(mut self, v: Byte) -> Self {
        self.0[42] = v;
        self
    }
    pub fn nth43(mut self, v: Byte) -> Self {
        self.0[43] = v;
        self
    }
    pub fn nth44(mut self, v: Byte) -> Self {
        self.0[44] = v;
        self
    }
    pub fn nth45(mut self, v: Byte) -> Self {
        self.0[45] = v;
        self
    }
    pub fn nth46(mut self, v: Byte) -> Self {
        self.0[46] = v;
        self
    }
    pub fn nth47(mut self, v: Byte) -> Self {
        self.0[47] = v;
        self
    }
    pub fn nth48(mut self, v: Byte) -> Self {
        self.0[48] = v;
        self
    }
    pub fn nth49(mut self, v: Byte) -> Self {
        self.0[49] = v;
        self
    }
    pub fn nth50(mut self, v: Byte) -> Self {
        self.0[50] = v;
        self
    }
    pub fn nth51(mut self, v: Byte) -> Self {
        self.0[51] = v;
        self
    }
    pub fn nth52(mut self, v: Byte) -> Self {
        self.0[52] = v;
        self
    }
    pub fn nth53(mut self, v: Byte) -> Self {
        self.0[53] = v;
        self
    }
    pub fn nth54(mut self, v: Byte) -> Self {
        self.0[54] = v;
        self
    }
    pub fn nth55(mut self, v: Byte) -> Self {
        self.0[55] = v;
        self
    }
    pub fn nth56(mut self, v: Byte) -> Self {
        self.0[56] = v;
        self
    }
    pub fn nth57(mut self, v: Byte) -> Self {
        self.0[57] = v;
        self
    }
    pub fn nth58(mut self, v: Byte) -> Self {
        self.0[58] = v;
        self
    }
    pub fn nth59(mut self, v: Byte) -> Self {
        self.0[59] = v;
        self
    }
    pub fn nth60(mut self, v: Byte) -> Self {
        self.0[60] = v;
        self
    }
    pub fn nth61(mut self, v: Byte) -> Self {
        self.0[61] = v;
        self
    }
    pub fn nth62(mut self, v: Byte) -> Self {
        self.0[62] = v;
        self
    }
    pub fn nth63(mut self, v: Byte) -> Self {
        self.0[63] = v;
        self
    }
}
impl molecule::prelude::Builder for EcdsaSignatureBuilder {
    type Entity = EcdsaSignature;
    const NAME: &'static str = "EcdsaSignatureBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.0[0].as_slice())?;
        writer.write_all(self.0[1].as_slice())?;
        writer.write_all(self.0[2].as_slice())?;
        writer.write_all(self.0[3].as_slice())?;
        writer.write_all(self.0[4].as_slice())?;
        writer.write_all(self.0[5].as_slice())?;
        writer.write_all(self.0[6].as_slice())?;
        writer.write_all(self.0[7].as_slice())?;
        writer.write_all(self.0[8].as_slice())?;
        writer.write_all(self.0[9].as_slice())?;
        writer.write_all(self.0[10].as_slice())?;
        writer.write_all(self.0[11].as_slice())?;
        writer.write_all(self.0[12].as_slice())?;
        writer.write_all(self.0[13].as_slice())?;
        writer.write_all(self.0[14].as_slice())?;
        writer.write_all(self.0[15].as_slice())?;
        writer.write_all(self.0[16].as_slice())?;
        writer.write_all(self.0[17].as_slice())?;
        writer.write_all(self.0[18].as_slice())?;
        writer.write_all(self.0[19].as_slice())?;
        writer.write_all(self.0[20].as_slice())?;
        writer.write_all(self.0[21].as_slice())?;
        writer.write_all(self.0[22].as_slice())?;
        writer.write_all(self.0[23].as_slice())?;
        writer.write_all(self.0[24].as_slice())?;
        writer.write_all(self.0[25].as_slice())?;
        writer.write_all(self.0[26].as_slice())?;
        writer.write_all(self.0[27].as_slice())?;
        writer.write_all(self.0[28].as_slice())?;
        writer.write_all(self.0[29].as_slice())?;
        writer.write_all(self.0[30].as_slice())?;
        writer.write_all(self.0[31].as_slice())?;
        writer.write_all(self.0[32].as_slice())?;
        writer.write_all(self.0[33].as_slice())?;
        writer.write_all(self.0[34].as_slice())?;
        writer.write_all(self.0[35].as_slice())?;
        writer.write_all(self.0[36].as_slice())?;
        writer.write_all(self.0[37].as_slice())?;
        writer.write_all(self.0[38].as_slice())?;
        writer.write_all(self.0[39].as_slice())?;
        writer.write_all(self.0[40].as_slice())?;
        writer.write_all(self.0[41].as_slice())?;
        writer.write_all(self.0[42].as_slice())?;
        writer.write_all(self.0[43].as_slice())?;
        writer.write_all(self.0[44].as_slice())?;
        writer.write_all(self.0[45].as_slice())?;
        writer.write_all(self.0[46].as_slice())?;
        writer.write_all(self.0[47].as_slice())?;
        writer.write_all(self.0[48].as_slice())?;
        writer.write_all(self.0[49].as_slice())?;
        writer.write_all(self.0[50].as_slice())?;
        writer.write_all(self.0[51].as_slice())?;
        writer.write_all(self.0[52].as_slice())?;
        writer.write_all(self.0[53].as_slice())?;
        writer.write_all(self.0[54].as_slice())?;
        writer.write_all(self.0[55].as_slice())?;
        writer.write_all(self.0[56].as_slice())?;
        writer.write_all(self.0[57].as_slice())?;
        writer.write_all(self.0[58].as_slice())?;
        writer.write_all(self.0[59].as_slice())?;
        writer.write_all(self.0[60].as_slice())?;
        writer.write_all(self.0[61].as_slice())?;
        writer.write_all(self.0[62].as_slice())?;
        writer.write_all(self.0[63].as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        EcdsaSignature::new_unchecked(inner.into())
    }
}
impl From<[Byte; 64usize]> for EcdsaSignature {
    fn from(value: [Byte; 64usize]) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl ::core::convert::TryFrom<&[Byte]> for EcdsaSignature {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[Byte]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(Self::new_builder()
            .set(<&[Byte; 64usize]>::try_from(value)?.clone())
            .build())
    }
}
impl From<EcdsaSignature> for [Byte; 64usize] {
    #[track_caller]
    fn from(value: EcdsaSignature) -> Self {
        [
            value.nth0(),
            value.nth1(),
            value.nth2(),
            value.nth3(),
            value.nth4(),
            value.nth5(),
            value.nth6(),
            value.nth7(),
            value.nth8(),
            value.nth9(),
            value.nth10(),
            value.nth11(),
            value.nth12(),
            value.nth13(),
            value.nth14(),
            value.nth15(),
            value.nth16(),
            value.nth17(),
            value.nth18(),
            value.nth19(),
            value.nth20(),
            value.nth21(),
            value.nth22(),
            value.nth23(),
            value.nth24(),
            value.nth25(),
            value.nth26(),
            value.nth27(),
            value.nth28(),
            value.nth29(),
            value.nth30(),
            value.nth31(),
            value.nth32(),
            value.nth33(),
            value.nth34(),
            value.nth35(),
            value.nth36(),
            value.nth37(),
            value.nth38(),
            value.nth39(),
            value.nth40(),
            value.nth41(),
            value.nth42(),
            value.nth43(),
            value.nth44(),
            value.nth45(),
            value.nth46(),
            value.nth47(),
            value.nth48(),
            value.nth49(),
            value.nth50(),
            value.nth51(),
            value.nth52(),
            value.nth53(),
            value.nth54(),
            value.nth55(),
            value.nth56(),
            value.nth57(),
            value.nth58(),
            value.nth59(),
            value.nth60(),
            value.nth61(),
            value.nth62(),
            value.nth63(),
        ]
    }
}
impl From<[u8; 64usize]> for EcdsaSignature {
    fn from(value: [u8; 64usize]) -> Self {
        EcdsaSignatureReader::new_unchecked(&value).to_entity()
    }
}
impl ::core::convert::TryFrom<&[u8]> for EcdsaSignature {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[u8]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(<[u8; 64usize]>::try_from(value)?.into())
    }
}
impl From<EcdsaSignature> for [u8; 64usize] {
    #[track_caller]
    fn from(value: EcdsaSignature) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<EcdsaSignatureReader<'a>> for &'a [u8; 64usize] {
    #[track_caller]
    fn from(value: EcdsaSignatureReader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<&'a EcdsaSignatureReader<'a>> for &'a [u8; 64usize] {
    #[track_caller]
    fn from(value: &'a EcdsaSignatureReader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
#[derive(Clone)]
pub struct PubNonce(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for PubNonce {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for PubNonce {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for PubNonce {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl ::core::default::Default for PubNonce {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        PubNonce::new_unchecked(v)
    }
}
impl PubNonce {
    const DEFAULT_VALUE: [u8; 66] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0,
    ];
    pub const TOTAL_SIZE: usize = 66;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 66;
    pub fn nth0(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(0..1))
    }
    pub fn nth1(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(1..2))
    }
    pub fn nth2(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(2..3))
    }
    pub fn nth3(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(3..4))
    }
    pub fn nth4(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(4..5))
    }
    pub fn nth5(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(5..6))
    }
    pub fn nth6(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(6..7))
    }
    pub fn nth7(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(7..8))
    }
    pub fn nth8(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(8..9))
    }
    pub fn nth9(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(9..10))
    }
    pub fn nth10(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(10..11))
    }
    pub fn nth11(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(11..12))
    }
    pub fn nth12(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(12..13))
    }
    pub fn nth13(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(13..14))
    }
    pub fn nth14(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(14..15))
    }
    pub fn nth15(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(15..16))
    }
    pub fn nth16(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(16..17))
    }
    pub fn nth17(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(17..18))
    }
    pub fn nth18(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(18..19))
    }
    pub fn nth19(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(19..20))
    }
    pub fn nth20(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(20..21))
    }
    pub fn nth21(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(21..22))
    }
    pub fn nth22(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(22..23))
    }
    pub fn nth23(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(23..24))
    }
    pub fn nth24(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(24..25))
    }
    pub fn nth25(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(25..26))
    }
    pub fn nth26(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(26..27))
    }
    pub fn nth27(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(27..28))
    }
    pub fn nth28(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(28..29))
    }
    pub fn nth29(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(29..30))
    }
    pub fn nth30(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(30..31))
    }
    pub fn nth31(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(31..32))
    }
    pub fn nth32(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(32..33))
    }
    pub fn nth33(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(33..34))
    }
    pub fn nth34(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(34..35))
    }
    pub fn nth35(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(35..36))
    }
    pub fn nth36(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(36..37))
    }
    pub fn nth37(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(37..38))
    }
    pub fn nth38(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(38..39))
    }
    pub fn nth39(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(39..40))
    }
    pub fn nth40(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(40..41))
    }
    pub fn nth41(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(41..42))
    }
    pub fn nth42(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(42..43))
    }
    pub fn nth43(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(43..44))
    }
    pub fn nth44(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(44..45))
    }
    pub fn nth45(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(45..46))
    }
    pub fn nth46(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(46..47))
    }
    pub fn nth47(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(47..48))
    }
    pub fn nth48(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(48..49))
    }
    pub fn nth49(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(49..50))
    }
    pub fn nth50(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(50..51))
    }
    pub fn nth51(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(51..52))
    }
    pub fn nth52(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(52..53))
    }
    pub fn nth53(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(53..54))
    }
    pub fn nth54(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(54..55))
    }
    pub fn nth55(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(55..56))
    }
    pub fn nth56(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(56..57))
    }
    pub fn nth57(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(57..58))
    }
    pub fn nth58(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(58..59))
    }
    pub fn nth59(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(59..60))
    }
    pub fn nth60(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(60..61))
    }
    pub fn nth61(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(61..62))
    }
    pub fn nth62(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(62..63))
    }
    pub fn nth63(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(63..64))
    }
    pub fn nth64(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(64..65))
    }
    pub fn nth65(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(65..66))
    }
    pub fn raw_data(&self) -> molecule::bytes::Bytes {
        self.as_bytes()
    }
    pub fn as_reader<'r>(&'r self) -> PubNonceReader<'r> {
        PubNonceReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for PubNonce {
    type Builder = PubNonceBuilder;
    const NAME: &'static str = "PubNonce";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        PubNonce(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        PubNonceReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        PubNonceReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set([
            self.nth0(),
            self.nth1(),
            self.nth2(),
            self.nth3(),
            self.nth4(),
            self.nth5(),
            self.nth6(),
            self.nth7(),
            self.nth8(),
            self.nth9(),
            self.nth10(),
            self.nth11(),
            self.nth12(),
            self.nth13(),
            self.nth14(),
            self.nth15(),
            self.nth16(),
            self.nth17(),
            self.nth18(),
            self.nth19(),
            self.nth20(),
            self.nth21(),
            self.nth22(),
            self.nth23(),
            self.nth24(),
            self.nth25(),
            self.nth26(),
            self.nth27(),
            self.nth28(),
            self.nth29(),
            self.nth30(),
            self.nth31(),
            self.nth32(),
            self.nth33(),
            self.nth34(),
            self.nth35(),
            self.nth36(),
            self.nth37(),
            self.nth38(),
            self.nth39(),
            self.nth40(),
            self.nth41(),
            self.nth42(),
            self.nth43(),
            self.nth44(),
            self.nth45(),
            self.nth46(),
            self.nth47(),
            self.nth48(),
            self.nth49(),
            self.nth50(),
            self.nth51(),
            self.nth52(),
            self.nth53(),
            self.nth54(),
            self.nth55(),
            self.nth56(),
            self.nth57(),
            self.nth58(),
            self.nth59(),
            self.nth60(),
            self.nth61(),
            self.nth62(),
            self.nth63(),
            self.nth64(),
            self.nth65(),
        ])
    }
}
#[derive(Clone, Copy)]
pub struct PubNonceReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for PubNonceReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for PubNonceReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for PubNonceReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl<'r> PubNonceReader<'r> {
    pub const TOTAL_SIZE: usize = 66;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 66;
    pub fn nth0(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[0..1])
    }
    pub fn nth1(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[1..2])
    }
    pub fn nth2(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[2..3])
    }
    pub fn nth3(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[3..4])
    }
    pub fn nth4(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[4..5])
    }
    pub fn nth5(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[5..6])
    }
    pub fn nth6(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[6..7])
    }
    pub fn nth7(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[7..8])
    }
    pub fn nth8(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[8..9])
    }
    pub fn nth9(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[9..10])
    }
    pub fn nth10(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[10..11])
    }
    pub fn nth11(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[11..12])
    }
    pub fn nth12(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[12..13])
    }
    pub fn nth13(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[13..14])
    }
    pub fn nth14(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[14..15])
    }
    pub fn nth15(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[15..16])
    }
    pub fn nth16(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[16..17])
    }
    pub fn nth17(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[17..18])
    }
    pub fn nth18(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[18..19])
    }
    pub fn nth19(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[19..20])
    }
    pub fn nth20(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[20..21])
    }
    pub fn nth21(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[21..22])
    }
    pub fn nth22(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[22..23])
    }
    pub fn nth23(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[23..24])
    }
    pub fn nth24(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[24..25])
    }
    pub fn nth25(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[25..26])
    }
    pub fn nth26(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[26..27])
    }
    pub fn nth27(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[27..28])
    }
    pub fn nth28(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[28..29])
    }
    pub fn nth29(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[29..30])
    }
    pub fn nth30(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[30..31])
    }
    pub fn nth31(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[31..32])
    }
    pub fn nth32(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[32..33])
    }
    pub fn nth33(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[33..34])
    }
    pub fn nth34(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[34..35])
    }
    pub fn nth35(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[35..36])
    }
    pub fn nth36(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[36..37])
    }
    pub fn nth37(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[37..38])
    }
    pub fn nth38(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[38..39])
    }
    pub fn nth39(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[39..40])
    }
    pub fn nth40(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[40..41])
    }
    pub fn nth41(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[41..42])
    }
    pub fn nth42(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[42..43])
    }
    pub fn nth43(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[43..44])
    }
    pub fn nth44(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[44..45])
    }
    pub fn nth45(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[45..46])
    }
    pub fn nth46(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[46..47])
    }
    pub fn nth47(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[47..48])
    }
    pub fn nth48(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[48..49])
    }
    pub fn nth49(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[49..50])
    }
    pub fn nth50(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[50..51])
    }
    pub fn nth51(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[51..52])
    }
    pub fn nth52(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[52..53])
    }
    pub fn nth53(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[53..54])
    }
    pub fn nth54(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[54..55])
    }
    pub fn nth55(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[55..56])
    }
    pub fn nth56(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[56..57])
    }
    pub fn nth57(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[57..58])
    }
    pub fn nth58(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[58..59])
    }
    pub fn nth59(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[59..60])
    }
    pub fn nth60(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[60..61])
    }
    pub fn nth61(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[61..62])
    }
    pub fn nth62(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[62..63])
    }
    pub fn nth63(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[63..64])
    }
    pub fn nth64(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[64..65])
    }
    pub fn nth65(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[65..66])
    }
    pub fn raw_data(&self) -> &'r [u8] {
        self.as_slice()
    }
}
impl<'r> molecule::prelude::Reader<'r> for PubNonceReader<'r> {
    type Entity = PubNonce;
    const NAME: &'static str = "PubNonceReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        PubNonceReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone)]
pub struct PubNonceBuilder(pub(crate) [Byte; 66]);
impl ::core::fmt::Debug for PubNonceBuilder {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:?})", Self::NAME, &self.0[..])
    }
}
impl ::core::default::Default for PubNonceBuilder {
    fn default() -> Self {
        PubNonceBuilder([
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
        ])
    }
}
impl PubNonceBuilder {
    pub const TOTAL_SIZE: usize = 66;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 66;
    pub fn set(mut self, v: [Byte; 66]) -> Self {
        self.0 = v;
        self
    }
    pub fn nth0(mut self, v: Byte) -> Self {
        self.0[0] = v;
        self
    }
    pub fn nth1(mut self, v: Byte) -> Self {
        self.0[1] = v;
        self
    }
    pub fn nth2(mut self, v: Byte) -> Self {
        self.0[2] = v;
        self
    }
    pub fn nth3(mut self, v: Byte) -> Self {
        self.0[3] = v;
        self
    }
    pub fn nth4(mut self, v: Byte) -> Self {
        self.0[4] = v;
        self
    }
    pub fn nth5(mut self, v: Byte) -> Self {
        self.0[5] = v;
        self
    }
    pub fn nth6(mut self, v: Byte) -> Self {
        self.0[6] = v;
        self
    }
    pub fn nth7(mut self, v: Byte) -> Self {
        self.0[7] = v;
        self
    }
    pub fn nth8(mut self, v: Byte) -> Self {
        self.0[8] = v;
        self
    }
    pub fn nth9(mut self, v: Byte) -> Self {
        self.0[9] = v;
        self
    }
    pub fn nth10(mut self, v: Byte) -> Self {
        self.0[10] = v;
        self
    }
    pub fn nth11(mut self, v: Byte) -> Self {
        self.0[11] = v;
        self
    }
    pub fn nth12(mut self, v: Byte) -> Self {
        self.0[12] = v;
        self
    }
    pub fn nth13(mut self, v: Byte) -> Self {
        self.0[13] = v;
        self
    }
    pub fn nth14(mut self, v: Byte) -> Self {
        self.0[14] = v;
        self
    }
    pub fn nth15(mut self, v: Byte) -> Self {
        self.0[15] = v;
        self
    }
    pub fn nth16(mut self, v: Byte) -> Self {
        self.0[16] = v;
        self
    }
    pub fn nth17(mut self, v: Byte) -> Self {
        self.0[17] = v;
        self
    }
    pub fn nth18(mut self, v: Byte) -> Self {
        self.0[18] = v;
        self
    }
    pub fn nth19(mut self, v: Byte) -> Self {
        self.0[19] = v;
        self
    }
    pub fn nth20(mut self, v: Byte) -> Self {
        self.0[20] = v;
        self
    }
    pub fn nth21(mut self, v: Byte) -> Self {
        self.0[21] = v;
        self
    }
    pub fn nth22(mut self, v: Byte) -> Self {
        self.0[22] = v;
        self
    }
    pub fn nth23(mut self, v: Byte) -> Self {
        self.0[23] = v;
        self
    }
    pub fn nth24(mut self, v: Byte) -> Self {
        self.0[24] = v;
        self
    }
    pub fn nth25(mut self, v: Byte) -> Self {
        self.0[25] = v;
        self
    }
    pub fn nth26(mut self, v: Byte) -> Self {
        self.0[26] = v;
        self
    }
    pub fn nth27(mut self, v: Byte) -> Self {
        self.0[27] = v;
        self
    }
    pub fn nth28(mut self, v: Byte) -> Self {
        self.0[28] = v;
        self
    }
    pub fn nth29(mut self, v: Byte) -> Self {
        self.0[29] = v;
        self
    }
    pub fn nth30(mut self, v: Byte) -> Self {
        self.0[30] = v;
        self
    }
    pub fn nth31(mut self, v: Byte) -> Self {
        self.0[31] = v;
        self
    }
    pub fn nth32(mut self, v: Byte) -> Self {
        self.0[32] = v;
        self
    }
    pub fn nth33(mut self, v: Byte) -> Self {
        self.0[33] = v;
        self
    }
    pub fn nth34(mut self, v: Byte) -> Self {
        self.0[34] = v;
        self
    }
    pub fn nth35(mut self, v: Byte) -> Self {
        self.0[35] = v;
        self
    }
    pub fn nth36(mut self, v: Byte) -> Self {
        self.0[36] = v;
        self
    }
    pub fn nth37(mut self, v: Byte) -> Self {
        self.0[37] = v;
        self
    }
    pub fn nth38(mut self, v: Byte) -> Self {
        self.0[38] = v;
        self
    }
    pub fn nth39(mut self, v: Byte) -> Self {
        self.0[39] = v;
        self
    }
    pub fn nth40(mut self, v: Byte) -> Self {
        self.0[40] = v;
        self
    }
    pub fn nth41(mut self, v: Byte) -> Self {
        self.0[41] = v;
        self
    }
    pub fn nth42(mut self, v: Byte) -> Self {
        self.0[42] = v;
        self
    }
    pub fn nth43(mut self, v: Byte) -> Self {
        self.0[43] = v;
        self
    }
    pub fn nth44(mut self, v: Byte) -> Self {
        self.0[44] = v;
        self
    }
    pub fn nth45(mut self, v: Byte) -> Self {
        self.0[45] = v;
        self
    }
    pub fn nth46(mut self, v: Byte) -> Self {
        self.0[46] = v;
        self
    }
    pub fn nth47(mut self, v: Byte) -> Self {
        self.0[47] = v;
        self
    }
    pub fn nth48(mut self, v: Byte) -> Self {
        self.0[48] = v;
        self
    }
    pub fn nth49(mut self, v: Byte) -> Self {
        self.0[49] = v;
        self
    }
    pub fn nth50(mut self, v: Byte) -> Self {
        self.0[50] = v;
        self
    }
    pub fn nth51(mut self, v: Byte) -> Self {
        self.0[51] = v;
        self
    }
    pub fn nth52(mut self, v: Byte) -> Self {
        self.0[52] = v;
        self
    }
    pub fn nth53(mut self, v: Byte) -> Self {
        self.0[53] = v;
        self
    }
    pub fn nth54(mut self, v: Byte) -> Self {
        self.0[54] = v;
        self
    }
    pub fn nth55(mut self, v: Byte) -> Self {
        self.0[55] = v;
        self
    }
    pub fn nth56(mut self, v: Byte) -> Self {
        self.0[56] = v;
        self
    }
    pub fn nth57(mut self, v: Byte) -> Self {
        self.0[57] = v;
        self
    }
    pub fn nth58(mut self, v: Byte) -> Self {
        self.0[58] = v;
        self
    }
    pub fn nth59(mut self, v: Byte) -> Self {
        self.0[59] = v;
        self
    }
    pub fn nth60(mut self, v: Byte) -> Self {
        self.0[60] = v;
        self
    }
    pub fn nth61(mut self, v: Byte) -> Self {
        self.0[61] = v;
        self
    }
    pub fn nth62(mut self, v: Byte) -> Self {
        self.0[62] = v;
        self
    }
    pub fn nth63(mut self, v: Byte) -> Self {
        self.0[63] = v;
        self
    }
    pub fn nth64(mut self, v: Byte) -> Self {
        self.0[64] = v;
        self
    }
    pub fn nth65(mut self, v: Byte) -> Self {
        self.0[65] = v;
        self
    }
}
impl molecule::prelude::Builder for PubNonceBuilder {
    type Entity = PubNonce;
    const NAME: &'static str = "PubNonceBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.0[0].as_slice())?;
        writer.write_all(self.0[1].as_slice())?;
        writer.write_all(self.0[2].as_slice())?;
        writer.write_all(self.0[3].as_slice())?;
        writer.write_all(self.0[4].as_slice())?;
        writer.write_all(self.0[5].as_slice())?;
        writer.write_all(self.0[6].as_slice())?;
        writer.write_all(self.0[7].as_slice())?;
        writer.write_all(self.0[8].as_slice())?;
        writer.write_all(self.0[9].as_slice())?;
        writer.write_all(self.0[10].as_slice())?;
        writer.write_all(self.0[11].as_slice())?;
        writer.write_all(self.0[12].as_slice())?;
        writer.write_all(self.0[13].as_slice())?;
        writer.write_all(self.0[14].as_slice())?;
        writer.write_all(self.0[15].as_slice())?;
        writer.write_all(self.0[16].as_slice())?;
        writer.write_all(self.0[17].as_slice())?;
        writer.write_all(self.0[18].as_slice())?;
        writer.write_all(self.0[19].as_slice())?;
        writer.write_all(self.0[20].as_slice())?;
        writer.write_all(self.0[21].as_slice())?;
        writer.write_all(self.0[22].as_slice())?;
        writer.write_all(self.0[23].as_slice())?;
        writer.write_all(self.0[24].as_slice())?;
        writer.write_all(self.0[25].as_slice())?;
        writer.write_all(self.0[26].as_slice())?;
        writer.write_all(self.0[27].as_slice())?;
        writer.write_all(self.0[28].as_slice())?;
        writer.write_all(self.0[29].as_slice())?;
        writer.write_all(self.0[30].as_slice())?;
        writer.write_all(self.0[31].as_slice())?;
        writer.write_all(self.0[32].as_slice())?;
        writer.write_all(self.0[33].as_slice())?;
        writer.write_all(self.0[34].as_slice())?;
        writer.write_all(self.0[35].as_slice())?;
        writer.write_all(self.0[36].as_slice())?;
        writer.write_all(self.0[37].as_slice())?;
        writer.write_all(self.0[38].as_slice())?;
        writer.write_all(self.0[39].as_slice())?;
        writer.write_all(self.0[40].as_slice())?;
        writer.write_all(self.0[41].as_slice())?;
        writer.write_all(self.0[42].as_slice())?;
        writer.write_all(self.0[43].as_slice())?;
        writer.write_all(self.0[44].as_slice())?;
        writer.write_all(self.0[45].as_slice())?;
        writer.write_all(self.0[46].as_slice())?;
        writer.write_all(self.0[47].as_slice())?;
        writer.write_all(self.0[48].as_slice())?;
        writer.write_all(self.0[49].as_slice())?;
        writer.write_all(self.0[50].as_slice())?;
        writer.write_all(self.0[51].as_slice())?;
        writer.write_all(self.0[52].as_slice())?;
        writer.write_all(self.0[53].as_slice())?;
        writer.write_all(self.0[54].as_slice())?;
        writer.write_all(self.0[55].as_slice())?;
        writer.write_all(self.0[56].as_slice())?;
        writer.write_all(self.0[57].as_slice())?;
        writer.write_all(self.0[58].as_slice())?;
        writer.write_all(self.0[59].as_slice())?;
        writer.write_all(self.0[60].as_slice())?;
        writer.write_all(self.0[61].as_slice())?;
        writer.write_all(self.0[62].as_slice())?;
        writer.write_all(self.0[63].as_slice())?;
        writer.write_all(self.0[64].as_slice())?;
        writer.write_all(self.0[65].as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        PubNonce::new_unchecked(inner.into())
    }
}
impl From<[Byte; 66usize]> for PubNonce {
    fn from(value: [Byte; 66usize]) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl ::core::convert::TryFrom<&[Byte]> for PubNonce {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[Byte]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(Self::new_builder()
            .set(<&[Byte; 66usize]>::try_from(value)?.clone())
            .build())
    }
}
impl From<PubNonce> for [Byte; 66usize] {
    #[track_caller]
    fn from(value: PubNonce) -> Self {
        [
            value.nth0(),
            value.nth1(),
            value.nth2(),
            value.nth3(),
            value.nth4(),
            value.nth5(),
            value.nth6(),
            value.nth7(),
            value.nth8(),
            value.nth9(),
            value.nth10(),
            value.nth11(),
            value.nth12(),
            value.nth13(),
            value.nth14(),
            value.nth15(),
            value.nth16(),
            value.nth17(),
            value.nth18(),
            value.nth19(),
            value.nth20(),
            value.nth21(),
            value.nth22(),
            value.nth23(),
            value.nth24(),
            value.nth25(),
            value.nth26(),
            value.nth27(),
            value.nth28(),
            value.nth29(),
            value.nth30(),
            value.nth31(),
            value.nth32(),
            value.nth33(),
            value.nth34(),
            value.nth35(),
            value.nth36(),
            value.nth37(),
            value.nth38(),
            value.nth39(),
            value.nth40(),
            value.nth41(),
            value.nth42(),
            value.nth43(),
            value.nth44(),
            value.nth45(),
            value.nth46(),
            value.nth47(),
            value.nth48(),
            value.nth49(),
            value.nth50(),
            value.nth51(),
            value.nth52(),
            value.nth53(),
            value.nth54(),
            value.nth55(),
            value.nth56(),
            value.nth57(),
            value.nth58(),
            value.nth59(),
            value.nth60(),
            value.nth61(),
            value.nth62(),
            value.nth63(),
            value.nth64(),
            value.nth65(),
        ]
    }
}
impl From<[u8; 66usize]> for PubNonce {
    fn from(value: [u8; 66usize]) -> Self {
        PubNonceReader::new_unchecked(&value).to_entity()
    }
}
impl ::core::convert::TryFrom<&[u8]> for PubNonce {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[u8]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(<[u8; 66usize]>::try_from(value)?.into())
    }
}
impl From<PubNonce> for [u8; 66usize] {
    #[track_caller]
    fn from(value: PubNonce) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<PubNonceReader<'a>> for &'a [u8; 66usize] {
    #[track_caller]
    fn from(value: PubNonceReader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<&'a PubNonceReader<'a>> for &'a [u8; 66usize] {
    #[track_caller]
    fn from(value: &'a PubNonceReader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
#[derive(Clone)]
pub struct PubNonceOpt(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for PubNonceOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for PubNonceOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for PubNonceOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl ::core::default::Default for PubNonceOpt {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        PubNonceOpt::new_unchecked(v)
    }
}
impl PubNonceOpt {
    const DEFAULT_VALUE: [u8; 0] = [];
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<PubNonce> {
        if self.is_none() {
            None
        } else {
            Some(PubNonce::new_unchecked(self.0.clone()))
        }
    }
    pub fn as_reader<'r>(&'r self) -> PubNonceOptReader<'r> {
        PubNonceOptReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for PubNonceOpt {
    type Builder = PubNonceOptBuilder;
    const NAME: &'static str = "PubNonceOpt";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        PubNonceOpt(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        PubNonceOptReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        PubNonceOptReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_opt())
    }
}
#[derive(Clone, Copy)]
pub struct PubNonceOptReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for PubNonceOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for PubNonceOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for PubNonceOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl<'r> PubNonceOptReader<'r> {
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<PubNonceReader<'r>> {
        if self.is_none() {
            None
        } else {
            Some(PubNonceReader::new_unchecked(self.as_slice()))
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for PubNonceOptReader<'r> {
    type Entity = PubNonceOpt;
    const NAME: &'static str = "PubNonceOptReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        PubNonceOptReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        if !slice.is_empty() {
            PubNonceReader::verify(&slice[..], compatible)?;
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct PubNonceOptBuilder(pub(crate) Option<PubNonce>);
impl PubNonceOptBuilder {
    pub fn set(mut self, v: Option<PubNonce>) -> Self {
        self.0 = v;
        self
    }
}
impl molecule::prelude::Builder for PubNonceOptBuilder {
    type Entity = PubNonceOpt;
    const NAME: &'static str = "PubNonceOptBuilder";
    fn expected_length(&self) -> usize {
        self.0
            .as_ref()
            .map(|ref inner| inner.as_slice().len())
            .unwrap_or(0)
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        self.0
            .as_ref()
            .map(|ref inner| writer.write_all(inner.as_slice()))
            .unwrap_or(Ok(()))
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        PubNonceOpt::new_unchecked(inner.into())
    }
}
impl From<PubNonce> for PubNonceOpt {
    fn from(value: PubNonce) -> Self {
        Self::new_builder().set(Some(value)).build()
    }
}
#[derive(Clone)]
pub struct Pubkey(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for Pubkey {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for Pubkey {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for Pubkey {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl ::core::default::Default for Pubkey {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        Pubkey::new_unchecked(v)
    }
}
impl Pubkey {
    const DEFAULT_VALUE: [u8; 33] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0,
    ];
    pub const TOTAL_SIZE: usize = 33;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 33;
    pub fn nth0(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(0..1))
    }
    pub fn nth1(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(1..2))
    }
    pub fn nth2(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(2..3))
    }
    pub fn nth3(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(3..4))
    }
    pub fn nth4(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(4..5))
    }
    pub fn nth5(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(5..6))
    }
    pub fn nth6(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(6..7))
    }
    pub fn nth7(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(7..8))
    }
    pub fn nth8(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(8..9))
    }
    pub fn nth9(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(9..10))
    }
    pub fn nth10(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(10..11))
    }
    pub fn nth11(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(11..12))
    }
    pub fn nth12(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(12..13))
    }
    pub fn nth13(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(13..14))
    }
    pub fn nth14(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(14..15))
    }
    pub fn nth15(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(15..16))
    }
    pub fn nth16(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(16..17))
    }
    pub fn nth17(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(17..18))
    }
    pub fn nth18(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(18..19))
    }
    pub fn nth19(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(19..20))
    }
    pub fn nth20(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(20..21))
    }
    pub fn nth21(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(21..22))
    }
    pub fn nth22(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(22..23))
    }
    pub fn nth23(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(23..24))
    }
    pub fn nth24(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(24..25))
    }
    pub fn nth25(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(25..26))
    }
    pub fn nth26(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(26..27))
    }
    pub fn nth27(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(27..28))
    }
    pub fn nth28(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(28..29))
    }
    pub fn nth29(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(29..30))
    }
    pub fn nth30(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(30..31))
    }
    pub fn nth31(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(31..32))
    }
    pub fn nth32(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(32..33))
    }
    pub fn raw_data(&self) -> molecule::bytes::Bytes {
        self.as_bytes()
    }
    pub fn as_reader<'r>(&'r self) -> PubkeyReader<'r> {
        PubkeyReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for Pubkey {
    type Builder = PubkeyBuilder;
    const NAME: &'static str = "Pubkey";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        Pubkey(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        PubkeyReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        PubkeyReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set([
            self.nth0(),
            self.nth1(),
            self.nth2(),
            self.nth3(),
            self.nth4(),
            self.nth5(),
            self.nth6(),
            self.nth7(),
            self.nth8(),
            self.nth9(),
            self.nth10(),
            self.nth11(),
            self.nth12(),
            self.nth13(),
            self.nth14(),
            self.nth15(),
            self.nth16(),
            self.nth17(),
            self.nth18(),
            self.nth19(),
            self.nth20(),
            self.nth21(),
            self.nth22(),
            self.nth23(),
            self.nth24(),
            self.nth25(),
            self.nth26(),
            self.nth27(),
            self.nth28(),
            self.nth29(),
            self.nth30(),
            self.nth31(),
            self.nth32(),
        ])
    }
}
#[derive(Clone, Copy)]
pub struct PubkeyReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for PubkeyReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for PubkeyReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for PubkeyReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl<'r> PubkeyReader<'r> {
    pub const TOTAL_SIZE: usize = 33;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 33;
    pub fn nth0(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[0..1])
    }
    pub fn nth1(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[1..2])
    }
    pub fn nth2(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[2..3])
    }
    pub fn nth3(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[3..4])
    }
    pub fn nth4(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[4..5])
    }
    pub fn nth5(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[5..6])
    }
    pub fn nth6(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[6..7])
    }
    pub fn nth7(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[7..8])
    }
    pub fn nth8(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[8..9])
    }
    pub fn nth9(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[9..10])
    }
    pub fn nth10(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[10..11])
    }
    pub fn nth11(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[11..12])
    }
    pub fn nth12(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[12..13])
    }
    pub fn nth13(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[13..14])
    }
    pub fn nth14(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[14..15])
    }
    pub fn nth15(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[15..16])
    }
    pub fn nth16(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[16..17])
    }
    pub fn nth17(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[17..18])
    }
    pub fn nth18(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[18..19])
    }
    pub fn nth19(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[19..20])
    }
    pub fn nth20(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[20..21])
    }
    pub fn nth21(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[21..22])
    }
    pub fn nth22(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[22..23])
    }
    pub fn nth23(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[23..24])
    }
    pub fn nth24(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[24..25])
    }
    pub fn nth25(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[25..26])
    }
    pub fn nth26(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[26..27])
    }
    pub fn nth27(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[27..28])
    }
    pub fn nth28(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[28..29])
    }
    pub fn nth29(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[29..30])
    }
    pub fn nth30(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[30..31])
    }
    pub fn nth31(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[31..32])
    }
    pub fn nth32(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[32..33])
    }
    pub fn raw_data(&self) -> &'r [u8] {
        self.as_slice()
    }
}
impl<'r> molecule::prelude::Reader<'r> for PubkeyReader<'r> {
    type Entity = Pubkey;
    const NAME: &'static str = "PubkeyReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        PubkeyReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone)]
pub struct PubkeyBuilder(pub(crate) [Byte; 33]);
impl ::core::fmt::Debug for PubkeyBuilder {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:?})", Self::NAME, &self.0[..])
    }
}
impl ::core::default::Default for PubkeyBuilder {
    fn default() -> Self {
        PubkeyBuilder([
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
        ])
    }
}
impl PubkeyBuilder {
    pub const TOTAL_SIZE: usize = 33;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 33;
    pub fn set(mut self, v: [Byte; 33]) -> Self {
        self.0 = v;
        self
    }
    pub fn nth0(mut self, v: Byte) -> Self {
        self.0[0] = v;
        self
    }
    pub fn nth1(mut self, v: Byte) -> Self {
        self.0[1] = v;
        self
    }
    pub fn nth2(mut self, v: Byte) -> Self {
        self.0[2] = v;
        self
    }
    pub fn nth3(mut self, v: Byte) -> Self {
        self.0[3] = v;
        self
    }
    pub fn nth4(mut self, v: Byte) -> Self {
        self.0[4] = v;
        self
    }
    pub fn nth5(mut self, v: Byte) -> Self {
        self.0[5] = v;
        self
    }
    pub fn nth6(mut self, v: Byte) -> Self {
        self.0[6] = v;
        self
    }
    pub fn nth7(mut self, v: Byte) -> Self {
        self.0[7] = v;
        self
    }
    pub fn nth8(mut self, v: Byte) -> Self {
        self.0[8] = v;
        self
    }
    pub fn nth9(mut self, v: Byte) -> Self {
        self.0[9] = v;
        self
    }
    pub fn nth10(mut self, v: Byte) -> Self {
        self.0[10] = v;
        self
    }
    pub fn nth11(mut self, v: Byte) -> Self {
        self.0[11] = v;
        self
    }
    pub fn nth12(mut self, v: Byte) -> Self {
        self.0[12] = v;
        self
    }
    pub fn nth13(mut self, v: Byte) -> Self {
        self.0[13] = v;
        self
    }
    pub fn nth14(mut self, v: Byte) -> Self {
        self.0[14] = v;
        self
    }
    pub fn nth15(mut self, v: Byte) -> Self {
        self.0[15] = v;
        self
    }
    pub fn nth16(mut self, v: Byte) -> Self {
        self.0[16] = v;
        self
    }
    pub fn nth17(mut self, v: Byte) -> Self {
        self.0[17] = v;
        self
    }
    pub fn nth18(mut self, v: Byte) -> Self {
        self.0[18] = v;
        self
    }
    pub fn nth19(mut self, v: Byte) -> Self {
        self.0[19] = v;
        self
    }
    pub fn nth20(mut self, v: Byte) -> Self {
        self.0[20] = v;
        self
    }
    pub fn nth21(mut self, v: Byte) -> Self {
        self.0[21] = v;
        self
    }
    pub fn nth22(mut self, v: Byte) -> Self {
        self.0[22] = v;
        self
    }
    pub fn nth23(mut self, v: Byte) -> Self {
        self.0[23] = v;
        self
    }
    pub fn nth24(mut self, v: Byte) -> Self {
        self.0[24] = v;
        self
    }
    pub fn nth25(mut self, v: Byte) -> Self {
        self.0[25] = v;
        self
    }
    pub fn nth26(mut self, v: Byte) -> Self {
        self.0[26] = v;
        self
    }
    pub fn nth27(mut self, v: Byte) -> Self {
        self.0[27] = v;
        self
    }
    pub fn nth28(mut self, v: Byte) -> Self {
        self.0[28] = v;
        self
    }
    pub fn nth29(mut self, v: Byte) -> Self {
        self.0[29] = v;
        self
    }
    pub fn nth30(mut self, v: Byte) -> Self {
        self.0[30] = v;
        self
    }
    pub fn nth31(mut self, v: Byte) -> Self {
        self.0[31] = v;
        self
    }
    pub fn nth32(mut self, v: Byte) -> Self {
        self.0[32] = v;
        self
    }
}
impl molecule::prelude::Builder for PubkeyBuilder {
    type Entity = Pubkey;
    const NAME: &'static str = "PubkeyBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.0[0].as_slice())?;
        writer.write_all(self.0[1].as_slice())?;
        writer.write_all(self.0[2].as_slice())?;
        writer.write_all(self.0[3].as_slice())?;
        writer.write_all(self.0[4].as_slice())?;
        writer.write_all(self.0[5].as_slice())?;
        writer.write_all(self.0[6].as_slice())?;
        writer.write_all(self.0[7].as_slice())?;
        writer.write_all(self.0[8].as_slice())?;
        writer.write_all(self.0[9].as_slice())?;
        writer.write_all(self.0[10].as_slice())?;
        writer.write_all(self.0[11].as_slice())?;
        writer.write_all(self.0[12].as_slice())?;
        writer.write_all(self.0[13].as_slice())?;
        writer.write_all(self.0[14].as_slice())?;
        writer.write_all(self.0[15].as_slice())?;
        writer.write_all(self.0[16].as_slice())?;
        writer.write_all(self.0[17].as_slice())?;
        writer.write_all(self.0[18].as_slice())?;
        writer.write_all(self.0[19].as_slice())?;
        writer.write_all(self.0[20].as_slice())?;
        writer.write_all(self.0[21].as_slice())?;
        writer.write_all(self.0[22].as_slice())?;
        writer.write_all(self.0[23].as_slice())?;
        writer.write_all(self.0[24].as_slice())?;
        writer.write_all(self.0[25].as_slice())?;
        writer.write_all(self.0[26].as_slice())?;
        writer.write_all(self.0[27].as_slice())?;
        writer.write_all(self.0[28].as_slice())?;
        writer.write_all(self.0[29].as_slice())?;
        writer.write_all(self.0[30].as_slice())?;
        writer.write_all(self.0[31].as_slice())?;
        writer.write_all(self.0[32].as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        Pubkey::new_unchecked(inner.into())
    }
}
impl From<[Byte; 33usize]> for Pubkey {
    fn from(value: [Byte; 33usize]) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl ::core::convert::TryFrom<&[Byte]> for Pubkey {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[Byte]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(Self::new_builder()
            .set(<&[Byte; 33usize]>::try_from(value)?.clone())
            .build())
    }
}
impl From<Pubkey> for [Byte; 33usize] {
    #[track_caller]
    fn from(value: Pubkey) -> Self {
        [
            value.nth0(),
            value.nth1(),
            value.nth2(),
            value.nth3(),
            value.nth4(),
            value.nth5(),
            value.nth6(),
            value.nth7(),
            value.nth8(),
            value.nth9(),
            value.nth10(),
            value.nth11(),
            value.nth12(),
            value.nth13(),
            value.nth14(),
            value.nth15(),
            value.nth16(),
            value.nth17(),
            value.nth18(),
            value.nth19(),
            value.nth20(),
            value.nth21(),
            value.nth22(),
            value.nth23(),
            value.nth24(),
            value.nth25(),
            value.nth26(),
            value.nth27(),
            value.nth28(),
            value.nth29(),
            value.nth30(),
            value.nth31(),
            value.nth32(),
        ]
    }
}
impl From<[u8; 33usize]> for Pubkey {
    fn from(value: [u8; 33usize]) -> Self {
        PubkeyReader::new_unchecked(&value).to_entity()
    }
}
impl ::core::convert::TryFrom<&[u8]> for Pubkey {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[u8]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(<[u8; 33usize]>::try_from(value)?.into())
    }
}
impl From<Pubkey> for [u8; 33usize] {
    #[track_caller]
    fn from(value: Pubkey) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<PubkeyReader<'a>> for &'a [u8; 33usize] {
    #[track_caller]
    fn from(value: PubkeyReader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<&'a PubkeyReader<'a>> for &'a [u8; 33usize] {
    #[track_caller]
    fn from(value: &'a PubkeyReader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
#[derive(Clone)]
pub struct Uint64Opt(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for Uint64Opt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for Uint64Opt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for Uint64Opt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl ::core::default::Default for Uint64Opt {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        Uint64Opt::new_unchecked(v)
    }
}
impl Uint64Opt {
    const DEFAULT_VALUE: [u8; 0] = [];
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<Uint64> {
        if self.is_none() {
            None
        } else {
            Some(Uint64::new_unchecked(self.0.clone()))
        }
    }
    pub fn as_reader<'r>(&'r self) -> Uint64OptReader<'r> {
        Uint64OptReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for Uint64Opt {
    type Builder = Uint64OptBuilder;
    const NAME: &'static str = "Uint64Opt";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        Uint64Opt(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        Uint64OptReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        Uint64OptReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_opt())
    }
}
#[derive(Clone, Copy)]
pub struct Uint64OptReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for Uint64OptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for Uint64OptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for Uint64OptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl<'r> Uint64OptReader<'r> {
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<Uint64Reader<'r>> {
        if self.is_none() {
            None
        } else {
            Some(Uint64Reader::new_unchecked(self.as_slice()))
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for Uint64OptReader<'r> {
    type Entity = Uint64Opt;
    const NAME: &'static str = "Uint64OptReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        Uint64OptReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        if !slice.is_empty() {
            Uint64Reader::verify(&slice[..], compatible)?;
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct Uint64OptBuilder(pub(crate) Option<Uint64>);
impl Uint64OptBuilder {
    pub fn set(mut self, v: Option<Uint64>) -> Self {
        self.0 = v;
        self
    }
}
impl molecule::prelude::Builder for Uint64OptBuilder {
    type Entity = Uint64Opt;
    const NAME: &'static str = "Uint64OptBuilder";
    fn expected_length(&self) -> usize {
        self.0
            .as_ref()
            .map(|ref inner| inner.as_slice().len())
            .unwrap_or(0)
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        self.0
            .as_ref()
            .map(|ref inner| writer.write_all(inner.as_slice()))
            .unwrap_or(Ok(()))
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        Uint64Opt::new_unchecked(inner.into())
    }
}
impl From<Uint64> for Uint64Opt {
    fn from(value: Uint64) -> Self {
        Self::new_builder().set(Some(value)).build()
    }
}
#[derive(Clone)]
pub struct Uint128Opt(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for Uint128Opt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for Uint128Opt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for Uint128Opt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl ::core::default::Default for Uint128Opt {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        Uint128Opt::new_unchecked(v)
    }
}
impl Uint128Opt {
    const DEFAULT_VALUE: [u8; 0] = [];
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<Uint128> {
        if self.is_none() {
            None
        } else {
            Some(Uint128::new_unchecked(self.0.clone()))
        }
    }
    pub fn as_reader<'r>(&'r self) -> Uint128OptReader<'r> {
        Uint128OptReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for Uint128Opt {
    type Builder = Uint128OptBuilder;
    const NAME: &'static str = "Uint128Opt";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        Uint128Opt(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        Uint128OptReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        Uint128OptReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_opt())
    }
}
#[derive(Clone, Copy)]
pub struct Uint128OptReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for Uint128OptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for Uint128OptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for Uint128OptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl<'r> Uint128OptReader<'r> {
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<Uint128Reader<'r>> {
        if self.is_none() {
            None
        } else {
            Some(Uint128Reader::new_unchecked(self.as_slice()))
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for Uint128OptReader<'r> {
    type Entity = Uint128Opt;
    const NAME: &'static str = "Uint128OptReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        Uint128OptReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        if !slice.is_empty() {
            Uint128Reader::verify(&slice[..], compatible)?;
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct Uint128OptBuilder(pub(crate) Option<Uint128>);
impl Uint128OptBuilder {
    pub fn set(mut self, v: Option<Uint128>) -> Self {
        self.0 = v;
        self
    }
}
impl molecule::prelude::Builder for Uint128OptBuilder {
    type Entity = Uint128Opt;
    const NAME: &'static str = "Uint128OptBuilder";
    fn expected_length(&self) -> usize {
        self.0
            .as_ref()
            .map(|ref inner| inner.as_slice().len())
            .unwrap_or(0)
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        self.0
            .as_ref()
            .map(|ref inner| writer.write_all(inner.as_slice()))
            .unwrap_or(Ok(()))
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        Uint128Opt::new_unchecked(inner.into())
    }
}
impl From<Uint128> for Uint128Opt {
    fn from(value: Uint128) -> Self {
        Self::new_builder().set(Some(value)).build()
    }
}
#[derive(Clone)]
pub struct OpenChannel(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for OpenChannel {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for OpenChannel {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for OpenChannel {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "chain_hash", self.chain_hash())?;
        write!(f, ", {}: {}", "channel_id", self.channel_id())?;
        write!(
            f,
            ", {}: {}",
            "funding_udt_type_script",
            self.funding_udt_type_script()
        )?;
        write!(f, ", {}: {}", "funding_amount", self.funding_amount())?;
        write!(f, ", {}: {}", "shutdown_script", self.shutdown_script())?;
        write!(
            f,
            ", {}: {}",
            "reserved_ckb_amount",
            self.reserved_ckb_amount()
        )?;
        write!(f, ", {}: {}", "funding_fee_rate", self.funding_fee_rate())?;
        write!(
            f,
            ", {}: {}",
            "commitment_fee_rate",
            self.commitment_fee_rate()
        )?;
        write!(
            f,
            ", {}: {}",
            "max_tlc_value_in_flight",
            self.max_tlc_value_in_flight()
        )?;
        write!(
            f,
            ", {}: {}",
            "max_tlc_number_in_flight",
            self.max_tlc_number_in_flight()
        )?;
        write!(
            f,
            ", {}: {}",
            "commitment_delay_epoch",
            self.commitment_delay_epoch()
        )?;
        write!(f, ", {}: {}", "funding_pubkey", self.funding_pubkey())?;
        write!(f, ", {}: {}", "tlc_basepoint", self.tlc_basepoint())?;
        write!(
            f,
            ", {}: {}",
            "first_per_commitment_point",
            self.first_per_commitment_point()
        )?;
        write!(
            f,
            ", {}: {}",
            "second_per_commitment_point",
            self.second_per_commitment_point()
        )?;
        write!(
            f,
            ", {}: {}",
            "channel_annoucement_nonce",
            self.channel_annoucement_nonce()
        )?;
        write!(f, ", {}: {}", "next_local_nonce", self.next_local_nonce())?;
        write!(f, ", {}: {}", "channel_flags", self.channel_flags())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for OpenChannel {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        OpenChannel::new_unchecked(v)
    }
}
impl OpenChannel {
    const DEFAULT_VALUE: [u8; 464] = [
        208, 1, 0, 0, 76, 0, 0, 0, 108, 0, 0, 0, 140, 0, 0, 0, 140, 0, 0, 0, 156, 0, 0, 0, 209, 0,
        0, 0, 217, 0, 0, 0, 225, 0, 0, 0, 233, 0, 0, 0, 249, 0, 0, 0, 1, 1, 0, 0, 9, 1, 0, 0, 42,
        1, 0, 0, 75, 1, 0, 0, 108, 1, 0, 0, 141, 1, 0, 0, 141, 1, 0, 0, 207, 1, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 53, 0, 0, 0, 16, 0, 0, 0, 48, 0, 0, 0, 49,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 18;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn chain_hash(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn channel_id(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn funding_udt_type_script(&self) -> ScriptOpt {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        ScriptOpt::new_unchecked(self.0.slice(start..end))
    }
    pub fn funding_amount(&self) -> Uint128 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        let end = molecule::unpack_number(&slice[20..]) as usize;
        Uint128::new_unchecked(self.0.slice(start..end))
    }
    pub fn shutdown_script(&self) -> Script {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[20..]) as usize;
        let end = molecule::unpack_number(&slice[24..]) as usize;
        Script::new_unchecked(self.0.slice(start..end))
    }
    pub fn reserved_ckb_amount(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[24..]) as usize;
        let end = molecule::unpack_number(&slice[28..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn funding_fee_rate(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[28..]) as usize;
        let end = molecule::unpack_number(&slice[32..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn commitment_fee_rate(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[32..]) as usize;
        let end = molecule::unpack_number(&slice[36..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn max_tlc_value_in_flight(&self) -> Uint128 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[36..]) as usize;
        let end = molecule::unpack_number(&slice[40..]) as usize;
        Uint128::new_unchecked(self.0.slice(start..end))
    }
    pub fn max_tlc_number_in_flight(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[40..]) as usize;
        let end = molecule::unpack_number(&slice[44..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn commitment_delay_epoch(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[44..]) as usize;
        let end = molecule::unpack_number(&slice[48..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn funding_pubkey(&self) -> Pubkey {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[48..]) as usize;
        let end = molecule::unpack_number(&slice[52..]) as usize;
        Pubkey::new_unchecked(self.0.slice(start..end))
    }
    pub fn tlc_basepoint(&self) -> Pubkey {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[52..]) as usize;
        let end = molecule::unpack_number(&slice[56..]) as usize;
        Pubkey::new_unchecked(self.0.slice(start..end))
    }
    pub fn first_per_commitment_point(&self) -> Pubkey {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[56..]) as usize;
        let end = molecule::unpack_number(&slice[60..]) as usize;
        Pubkey::new_unchecked(self.0.slice(start..end))
    }
    pub fn second_per_commitment_point(&self) -> Pubkey {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[60..]) as usize;
        let end = molecule::unpack_number(&slice[64..]) as usize;
        Pubkey::new_unchecked(self.0.slice(start..end))
    }
    pub fn channel_annoucement_nonce(&self) -> PubNonceOpt {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[64..]) as usize;
        let end = molecule::unpack_number(&slice[68..]) as usize;
        PubNonceOpt::new_unchecked(self.0.slice(start..end))
    }
    pub fn next_local_nonce(&self) -> PubNonce {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[68..]) as usize;
        let end = molecule::unpack_number(&slice[72..]) as usize;
        PubNonce::new_unchecked(self.0.slice(start..end))
    }
    pub fn channel_flags(&self) -> Byte {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[72..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[76..]) as usize;
            Byte::new_unchecked(self.0.slice(start..end))
        } else {
            Byte::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> OpenChannelReader<'r> {
        OpenChannelReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for OpenChannel {
    type Builder = OpenChannelBuilder;
    const NAME: &'static str = "OpenChannel";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        OpenChannel(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        OpenChannelReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        OpenChannelReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .chain_hash(self.chain_hash())
            .channel_id(self.channel_id())
            .funding_udt_type_script(self.funding_udt_type_script())
            .funding_amount(self.funding_amount())
            .shutdown_script(self.shutdown_script())
            .reserved_ckb_amount(self.reserved_ckb_amount())
            .funding_fee_rate(self.funding_fee_rate())
            .commitment_fee_rate(self.commitment_fee_rate())
            .max_tlc_value_in_flight(self.max_tlc_value_in_flight())
            .max_tlc_number_in_flight(self.max_tlc_number_in_flight())
            .commitment_delay_epoch(self.commitment_delay_epoch())
            .funding_pubkey(self.funding_pubkey())
            .tlc_basepoint(self.tlc_basepoint())
            .first_per_commitment_point(self.first_per_commitment_point())
            .second_per_commitment_point(self.second_per_commitment_point())
            .channel_annoucement_nonce(self.channel_annoucement_nonce())
            .next_local_nonce(self.next_local_nonce())
            .channel_flags(self.channel_flags())
    }
}
#[derive(Clone, Copy)]
pub struct OpenChannelReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for OpenChannelReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for OpenChannelReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for OpenChannelReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "chain_hash", self.chain_hash())?;
        write!(f, ", {}: {}", "channel_id", self.channel_id())?;
        write!(
            f,
            ", {}: {}",
            "funding_udt_type_script",
            self.funding_udt_type_script()
        )?;
        write!(f, ", {}: {}", "funding_amount", self.funding_amount())?;
        write!(f, ", {}: {}", "shutdown_script", self.shutdown_script())?;
        write!(
            f,
            ", {}: {}",
            "reserved_ckb_amount",
            self.reserved_ckb_amount()
        )?;
        write!(f, ", {}: {}", "funding_fee_rate", self.funding_fee_rate())?;
        write!(
            f,
            ", {}: {}",
            "commitment_fee_rate",
            self.commitment_fee_rate()
        )?;
        write!(
            f,
            ", {}: {}",
            "max_tlc_value_in_flight",
            self.max_tlc_value_in_flight()
        )?;
        write!(
            f,
            ", {}: {}",
            "max_tlc_number_in_flight",
            self.max_tlc_number_in_flight()
        )?;
        write!(
            f,
            ", {}: {}",
            "commitment_delay_epoch",
            self.commitment_delay_epoch()
        )?;
        write!(f, ", {}: {}", "funding_pubkey", self.funding_pubkey())?;
        write!(f, ", {}: {}", "tlc_basepoint", self.tlc_basepoint())?;
        write!(
            f,
            ", {}: {}",
            "first_per_commitment_point",
            self.first_per_commitment_point()
        )?;
        write!(
            f,
            ", {}: {}",
            "second_per_commitment_point",
            self.second_per_commitment_point()
        )?;
        write!(
            f,
            ", {}: {}",
            "channel_annoucement_nonce",
            self.channel_annoucement_nonce()
        )?;
        write!(f, ", {}: {}", "next_local_nonce", self.next_local_nonce())?;
        write!(f, ", {}: {}", "channel_flags", self.channel_flags())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> OpenChannelReader<'r> {
    pub const FIELD_COUNT: usize = 18;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn chain_hash(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn funding_udt_type_script(&self) -> ScriptOptReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        ScriptOptReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn funding_amount(&self) -> Uint128Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        let end = molecule::unpack_number(&slice[20..]) as usize;
        Uint128Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn shutdown_script(&self) -> ScriptReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[20..]) as usize;
        let end = molecule::unpack_number(&slice[24..]) as usize;
        ScriptReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn reserved_ckb_amount(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[24..]) as usize;
        let end = molecule::unpack_number(&slice[28..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn funding_fee_rate(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[28..]) as usize;
        let end = molecule::unpack_number(&slice[32..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn commitment_fee_rate(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[32..]) as usize;
        let end = molecule::unpack_number(&slice[36..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn max_tlc_value_in_flight(&self) -> Uint128Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[36..]) as usize;
        let end = molecule::unpack_number(&slice[40..]) as usize;
        Uint128Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn max_tlc_number_in_flight(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[40..]) as usize;
        let end = molecule::unpack_number(&slice[44..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn commitment_delay_epoch(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[44..]) as usize;
        let end = molecule::unpack_number(&slice[48..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn funding_pubkey(&self) -> PubkeyReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[48..]) as usize;
        let end = molecule::unpack_number(&slice[52..]) as usize;
        PubkeyReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn tlc_basepoint(&self) -> PubkeyReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[52..]) as usize;
        let end = molecule::unpack_number(&slice[56..]) as usize;
        PubkeyReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn first_per_commitment_point(&self) -> PubkeyReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[56..]) as usize;
        let end = molecule::unpack_number(&slice[60..]) as usize;
        PubkeyReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn second_per_commitment_point(&self) -> PubkeyReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[60..]) as usize;
        let end = molecule::unpack_number(&slice[64..]) as usize;
        PubkeyReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn channel_annoucement_nonce(&self) -> PubNonceOptReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[64..]) as usize;
        let end = molecule::unpack_number(&slice[68..]) as usize;
        PubNonceOptReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn next_local_nonce(&self) -> PubNonceReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[68..]) as usize;
        let end = molecule::unpack_number(&slice[72..]) as usize;
        PubNonceReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn channel_flags(&self) -> ByteReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[72..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[76..]) as usize;
            ByteReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            ByteReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for OpenChannelReader<'r> {
    type Entity = OpenChannel;
    const NAME: &'static str = "OpenChannelReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        OpenChannelReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Byte32Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Byte32Reader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        ScriptOptReader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        Uint128Reader::verify(&slice[offsets[3]..offsets[4]], compatible)?;
        ScriptReader::verify(&slice[offsets[4]..offsets[5]], compatible)?;
        Uint64Reader::verify(&slice[offsets[5]..offsets[6]], compatible)?;
        Uint64Reader::verify(&slice[offsets[6]..offsets[7]], compatible)?;
        Uint64Reader::verify(&slice[offsets[7]..offsets[8]], compatible)?;
        Uint128Reader::verify(&slice[offsets[8]..offsets[9]], compatible)?;
        Uint64Reader::verify(&slice[offsets[9]..offsets[10]], compatible)?;
        Uint64Reader::verify(&slice[offsets[10]..offsets[11]], compatible)?;
        PubkeyReader::verify(&slice[offsets[11]..offsets[12]], compatible)?;
        PubkeyReader::verify(&slice[offsets[12]..offsets[13]], compatible)?;
        PubkeyReader::verify(&slice[offsets[13]..offsets[14]], compatible)?;
        PubkeyReader::verify(&slice[offsets[14]..offsets[15]], compatible)?;
        PubNonceOptReader::verify(&slice[offsets[15]..offsets[16]], compatible)?;
        PubNonceReader::verify(&slice[offsets[16]..offsets[17]], compatible)?;
        ByteReader::verify(&slice[offsets[17]..offsets[18]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct OpenChannelBuilder {
    pub(crate) chain_hash: Byte32,
    pub(crate) channel_id: Byte32,
    pub(crate) funding_udt_type_script: ScriptOpt,
    pub(crate) funding_amount: Uint128,
    pub(crate) shutdown_script: Script,
    pub(crate) reserved_ckb_amount: Uint64,
    pub(crate) funding_fee_rate: Uint64,
    pub(crate) commitment_fee_rate: Uint64,
    pub(crate) max_tlc_value_in_flight: Uint128,
    pub(crate) max_tlc_number_in_flight: Uint64,
    pub(crate) commitment_delay_epoch: Uint64,
    pub(crate) funding_pubkey: Pubkey,
    pub(crate) tlc_basepoint: Pubkey,
    pub(crate) first_per_commitment_point: Pubkey,
    pub(crate) second_per_commitment_point: Pubkey,
    pub(crate) channel_annoucement_nonce: PubNonceOpt,
    pub(crate) next_local_nonce: PubNonce,
    pub(crate) channel_flags: Byte,
}
impl OpenChannelBuilder {
    pub const FIELD_COUNT: usize = 18;
    pub fn chain_hash(mut self, v: Byte32) -> Self {
        self.chain_hash = v;
        self
    }
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
    pub fn funding_udt_type_script(mut self, v: ScriptOpt) -> Self {
        self.funding_udt_type_script = v;
        self
    }
    pub fn funding_amount(mut self, v: Uint128) -> Self {
        self.funding_amount = v;
        self
    }
    pub fn shutdown_script(mut self, v: Script) -> Self {
        self.shutdown_script = v;
        self
    }
    pub fn reserved_ckb_amount(mut self, v: Uint64) -> Self {
        self.reserved_ckb_amount = v;
        self
    }
    pub fn funding_fee_rate(mut self, v: Uint64) -> Self {
        self.funding_fee_rate = v;
        self
    }
    pub fn commitment_fee_rate(mut self, v: Uint64) -> Self {
        self.commitment_fee_rate = v;
        self
    }
    pub fn max_tlc_value_in_flight(mut self, v: Uint128) -> Self {
        self.max_tlc_value_in_flight = v;
        self
    }
    pub fn max_tlc_number_in_flight(mut self, v: Uint64) -> Self {
        self.max_tlc_number_in_flight = v;
        self
    }
    pub fn commitment_delay_epoch(mut self, v: Uint64) -> Self {
        self.commitment_delay_epoch = v;
        self
    }
    pub fn funding_pubkey(mut self, v: Pubkey) -> Self {
        self.funding_pubkey = v;
        self
    }
    pub fn tlc_basepoint(mut self, v: Pubkey) -> Self {
        self.tlc_basepoint = v;
        self
    }
    pub fn first_per_commitment_point(mut self, v: Pubkey) -> Self {
        self.first_per_commitment_point = v;
        self
    }
    pub fn second_per_commitment_point(mut self, v: Pubkey) -> Self {
        self.second_per_commitment_point = v;
        self
    }
    pub fn channel_annoucement_nonce(mut self, v: PubNonceOpt) -> Self {
        self.channel_annoucement_nonce = v;
        self
    }
    pub fn next_local_nonce(mut self, v: PubNonce) -> Self {
        self.next_local_nonce = v;
        self
    }
    pub fn channel_flags(mut self, v: Byte) -> Self {
        self.channel_flags = v;
        self
    }
}
impl molecule::prelude::Builder for OpenChannelBuilder {
    type Entity = OpenChannel;
    const NAME: &'static str = "OpenChannelBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.chain_hash.as_slice().len()
            + self.channel_id.as_slice().len()
            + self.funding_udt_type_script.as_slice().len()
            + self.funding_amount.as_slice().len()
            + self.shutdown_script.as_slice().len()
            + self.reserved_ckb_amount.as_slice().len()
            + self.funding_fee_rate.as_slice().len()
            + self.commitment_fee_rate.as_slice().len()
            + self.max_tlc_value_in_flight.as_slice().len()
            + self.max_tlc_number_in_flight.as_slice().len()
            + self.commitment_delay_epoch.as_slice().len()
            + self.funding_pubkey.as_slice().len()
            + self.tlc_basepoint.as_slice().len()
            + self.first_per_commitment_point.as_slice().len()
            + self.second_per_commitment_point.as_slice().len()
            + self.channel_annoucement_nonce.as_slice().len()
            + self.next_local_nonce.as_slice().len()
            + self.channel_flags.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.chain_hash.as_slice().len();
        offsets.push(total_size);
        total_size += self.channel_id.as_slice().len();
        offsets.push(total_size);
        total_size += self.funding_udt_type_script.as_slice().len();
        offsets.push(total_size);
        total_size += self.funding_amount.as_slice().len();
        offsets.push(total_size);
        total_size += self.shutdown_script.as_slice().len();
        offsets.push(total_size);
        total_size += self.reserved_ckb_amount.as_slice().len();
        offsets.push(total_size);
        total_size += self.funding_fee_rate.as_slice().len();
        offsets.push(total_size);
        total_size += self.commitment_fee_rate.as_slice().len();
        offsets.push(total_size);
        total_size += self.max_tlc_value_in_flight.as_slice().len();
        offsets.push(total_size);
        total_size += self.max_tlc_number_in_flight.as_slice().len();
        offsets.push(total_size);
        total_size += self.commitment_delay_epoch.as_slice().len();
        offsets.push(total_size);
        total_size += self.funding_pubkey.as_slice().len();
        offsets.push(total_size);
        total_size += self.tlc_basepoint.as_slice().len();
        offsets.push(total_size);
        total_size += self.first_per_commitment_point.as_slice().len();
        offsets.push(total_size);
        total_size += self.second_per_commitment_point.as_slice().len();
        offsets.push(total_size);
        total_size += self.channel_annoucement_nonce.as_slice().len();
        offsets.push(total_size);
        total_size += self.next_local_nonce.as_slice().len();
        offsets.push(total_size);
        total_size += self.channel_flags.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.chain_hash.as_slice())?;
        writer.write_all(self.channel_id.as_slice())?;
        writer.write_all(self.funding_udt_type_script.as_slice())?;
        writer.write_all(self.funding_amount.as_slice())?;
        writer.write_all(self.shutdown_script.as_slice())?;
        writer.write_all(self.reserved_ckb_amount.as_slice())?;
        writer.write_all(self.funding_fee_rate.as_slice())?;
        writer.write_all(self.commitment_fee_rate.as_slice())?;
        writer.write_all(self.max_tlc_value_in_flight.as_slice())?;
        writer.write_all(self.max_tlc_number_in_flight.as_slice())?;
        writer.write_all(self.commitment_delay_epoch.as_slice())?;
        writer.write_all(self.funding_pubkey.as_slice())?;
        writer.write_all(self.tlc_basepoint.as_slice())?;
        writer.write_all(self.first_per_commitment_point.as_slice())?;
        writer.write_all(self.second_per_commitment_point.as_slice())?;
        writer.write_all(self.channel_annoucement_nonce.as_slice())?;
        writer.write_all(self.next_local_nonce.as_slice())?;
        writer.write_all(self.channel_flags.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        OpenChannel::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct AcceptChannel(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for AcceptChannel {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for AcceptChannel {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for AcceptChannel {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "funding_amount", self.funding_amount())?;
        write!(f, ", {}: {}", "shutdown_script", self.shutdown_script())?;
        write!(
            f,
            ", {}: {}",
            "reserved_ckb_amount",
            self.reserved_ckb_amount()
        )?;
        write!(
            f,
            ", {}: {}",
            "max_tlc_value_in_flight",
            self.max_tlc_value_in_flight()
        )?;
        write!(
            f,
            ", {}: {}",
            "max_tlc_number_in_flight",
            self.max_tlc_number_in_flight()
        )?;
        write!(f, ", {}: {}", "funding_pubkey", self.funding_pubkey())?;
        write!(f, ", {}: {}", "tlc_basepoint", self.tlc_basepoint())?;
        write!(
            f,
            ", {}: {}",
            "first_per_commitment_point",
            self.first_per_commitment_point()
        )?;
        write!(
            f,
            ", {}: {}",
            "second_per_commitment_point",
            self.second_per_commitment_point()
        )?;
        write!(
            f,
            ", {}: {}",
            "channel_annoucement_nonce",
            self.channel_annoucement_nonce()
        )?;
        write!(f, ", {}: {}", "next_local_nonce", self.next_local_nonce())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for AcceptChannel {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        AcceptChannel::new_unchecked(v)
    }
}
impl AcceptChannel {
    const DEFAULT_VALUE: [u8; 383] = [
        127, 1, 0, 0, 52, 0, 0, 0, 84, 0, 0, 0, 100, 0, 0, 0, 153, 0, 0, 0, 161, 0, 0, 0, 177, 0,
        0, 0, 185, 0, 0, 0, 218, 0, 0, 0, 251, 0, 0, 0, 28, 1, 0, 0, 61, 1, 0, 0, 61, 1, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 53, 0, 0, 0, 16, 0, 0, 0, 48, 0, 0, 0,
        49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0,
    ];
    pub const FIELD_COUNT: usize = 12;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn funding_amount(&self) -> Uint128 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Uint128::new_unchecked(self.0.slice(start..end))
    }
    pub fn shutdown_script(&self) -> Script {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        Script::new_unchecked(self.0.slice(start..end))
    }
    pub fn reserved_ckb_amount(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        let end = molecule::unpack_number(&slice[20..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn max_tlc_value_in_flight(&self) -> Uint128 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[20..]) as usize;
        let end = molecule::unpack_number(&slice[24..]) as usize;
        Uint128::new_unchecked(self.0.slice(start..end))
    }
    pub fn max_tlc_number_in_flight(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[24..]) as usize;
        let end = molecule::unpack_number(&slice[28..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn funding_pubkey(&self) -> Pubkey {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[28..]) as usize;
        let end = molecule::unpack_number(&slice[32..]) as usize;
        Pubkey::new_unchecked(self.0.slice(start..end))
    }
    pub fn tlc_basepoint(&self) -> Pubkey {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[32..]) as usize;
        let end = molecule::unpack_number(&slice[36..]) as usize;
        Pubkey::new_unchecked(self.0.slice(start..end))
    }
    pub fn first_per_commitment_point(&self) -> Pubkey {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[36..]) as usize;
        let end = molecule::unpack_number(&slice[40..]) as usize;
        Pubkey::new_unchecked(self.0.slice(start..end))
    }
    pub fn second_per_commitment_point(&self) -> Pubkey {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[40..]) as usize;
        let end = molecule::unpack_number(&slice[44..]) as usize;
        Pubkey::new_unchecked(self.0.slice(start..end))
    }
    pub fn channel_annoucement_nonce(&self) -> PubNonceOpt {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[44..]) as usize;
        let end = molecule::unpack_number(&slice[48..]) as usize;
        PubNonceOpt::new_unchecked(self.0.slice(start..end))
    }
    pub fn next_local_nonce(&self) -> PubNonce {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[48..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[52..]) as usize;
            PubNonce::new_unchecked(self.0.slice(start..end))
        } else {
            PubNonce::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> AcceptChannelReader<'r> {
        AcceptChannelReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for AcceptChannel {
    type Builder = AcceptChannelBuilder;
    const NAME: &'static str = "AcceptChannel";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        AcceptChannel(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        AcceptChannelReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        AcceptChannelReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_id(self.channel_id())
            .funding_amount(self.funding_amount())
            .shutdown_script(self.shutdown_script())
            .reserved_ckb_amount(self.reserved_ckb_amount())
            .max_tlc_value_in_flight(self.max_tlc_value_in_flight())
            .max_tlc_number_in_flight(self.max_tlc_number_in_flight())
            .funding_pubkey(self.funding_pubkey())
            .tlc_basepoint(self.tlc_basepoint())
            .first_per_commitment_point(self.first_per_commitment_point())
            .second_per_commitment_point(self.second_per_commitment_point())
            .channel_annoucement_nonce(self.channel_annoucement_nonce())
            .next_local_nonce(self.next_local_nonce())
    }
}
#[derive(Clone, Copy)]
pub struct AcceptChannelReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for AcceptChannelReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for AcceptChannelReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for AcceptChannelReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "funding_amount", self.funding_amount())?;
        write!(f, ", {}: {}", "shutdown_script", self.shutdown_script())?;
        write!(
            f,
            ", {}: {}",
            "reserved_ckb_amount",
            self.reserved_ckb_amount()
        )?;
        write!(
            f,
            ", {}: {}",
            "max_tlc_value_in_flight",
            self.max_tlc_value_in_flight()
        )?;
        write!(
            f,
            ", {}: {}",
            "max_tlc_number_in_flight",
            self.max_tlc_number_in_flight()
        )?;
        write!(f, ", {}: {}", "funding_pubkey", self.funding_pubkey())?;
        write!(f, ", {}: {}", "tlc_basepoint", self.tlc_basepoint())?;
        write!(
            f,
            ", {}: {}",
            "first_per_commitment_point",
            self.first_per_commitment_point()
        )?;
        write!(
            f,
            ", {}: {}",
            "second_per_commitment_point",
            self.second_per_commitment_point()
        )?;
        write!(
            f,
            ", {}: {}",
            "channel_annoucement_nonce",
            self.channel_annoucement_nonce()
        )?;
        write!(f, ", {}: {}", "next_local_nonce", self.next_local_nonce())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> AcceptChannelReader<'r> {
    pub const FIELD_COUNT: usize = 12;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn funding_amount(&self) -> Uint128Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Uint128Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn shutdown_script(&self) -> ScriptReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        ScriptReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn reserved_ckb_amount(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        let end = molecule::unpack_number(&slice[20..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn max_tlc_value_in_flight(&self) -> Uint128Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[20..]) as usize;
        let end = molecule::unpack_number(&slice[24..]) as usize;
        Uint128Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn max_tlc_number_in_flight(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[24..]) as usize;
        let end = molecule::unpack_number(&slice[28..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn funding_pubkey(&self) -> PubkeyReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[28..]) as usize;
        let end = molecule::unpack_number(&slice[32..]) as usize;
        PubkeyReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn tlc_basepoint(&self) -> PubkeyReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[32..]) as usize;
        let end = molecule::unpack_number(&slice[36..]) as usize;
        PubkeyReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn first_per_commitment_point(&self) -> PubkeyReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[36..]) as usize;
        let end = molecule::unpack_number(&slice[40..]) as usize;
        PubkeyReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn second_per_commitment_point(&self) -> PubkeyReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[40..]) as usize;
        let end = molecule::unpack_number(&slice[44..]) as usize;
        PubkeyReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn channel_annoucement_nonce(&self) -> PubNonceOptReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[44..]) as usize;
        let end = molecule::unpack_number(&slice[48..]) as usize;
        PubNonceOptReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn next_local_nonce(&self) -> PubNonceReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[48..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[52..]) as usize;
            PubNonceReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            PubNonceReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for AcceptChannelReader<'r> {
    type Entity = AcceptChannel;
    const NAME: &'static str = "AcceptChannelReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        AcceptChannelReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Byte32Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Uint128Reader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        ScriptReader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        Uint64Reader::verify(&slice[offsets[3]..offsets[4]], compatible)?;
        Uint128Reader::verify(&slice[offsets[4]..offsets[5]], compatible)?;
        Uint64Reader::verify(&slice[offsets[5]..offsets[6]], compatible)?;
        PubkeyReader::verify(&slice[offsets[6]..offsets[7]], compatible)?;
        PubkeyReader::verify(&slice[offsets[7]..offsets[8]], compatible)?;
        PubkeyReader::verify(&slice[offsets[8]..offsets[9]], compatible)?;
        PubkeyReader::verify(&slice[offsets[9]..offsets[10]], compatible)?;
        PubNonceOptReader::verify(&slice[offsets[10]..offsets[11]], compatible)?;
        PubNonceReader::verify(&slice[offsets[11]..offsets[12]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct AcceptChannelBuilder {
    pub(crate) channel_id: Byte32,
    pub(crate) funding_amount: Uint128,
    pub(crate) shutdown_script: Script,
    pub(crate) reserved_ckb_amount: Uint64,
    pub(crate) max_tlc_value_in_flight: Uint128,
    pub(crate) max_tlc_number_in_flight: Uint64,
    pub(crate) funding_pubkey: Pubkey,
    pub(crate) tlc_basepoint: Pubkey,
    pub(crate) first_per_commitment_point: Pubkey,
    pub(crate) second_per_commitment_point: Pubkey,
    pub(crate) channel_annoucement_nonce: PubNonceOpt,
    pub(crate) next_local_nonce: PubNonce,
}
impl AcceptChannelBuilder {
    pub const FIELD_COUNT: usize = 12;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
    pub fn funding_amount(mut self, v: Uint128) -> Self {
        self.funding_amount = v;
        self
    }
    pub fn shutdown_script(mut self, v: Script) -> Self {
        self.shutdown_script = v;
        self
    }
    pub fn reserved_ckb_amount(mut self, v: Uint64) -> Self {
        self.reserved_ckb_amount = v;
        self
    }
    pub fn max_tlc_value_in_flight(mut self, v: Uint128) -> Self {
        self.max_tlc_value_in_flight = v;
        self
    }
    pub fn max_tlc_number_in_flight(mut self, v: Uint64) -> Self {
        self.max_tlc_number_in_flight = v;
        self
    }
    pub fn funding_pubkey(mut self, v: Pubkey) -> Self {
        self.funding_pubkey = v;
        self
    }
    pub fn tlc_basepoint(mut self, v: Pubkey) -> Self {
        self.tlc_basepoint = v;
        self
    }
    pub fn first_per_commitment_point(mut self, v: Pubkey) -> Self {
        self.first_per_commitment_point = v;
        self
    }
    pub fn second_per_commitment_point(mut self, v: Pubkey) -> Self {
        self.second_per_commitment_point = v;
        self
    }
    pub fn channel_annoucement_nonce(mut self, v: PubNonceOpt) -> Self {
        self.channel_annoucement_nonce = v;
        self
    }
    pub fn next_local_nonce(mut self, v: PubNonce) -> Self {
        self.next_local_nonce = v;
        self
    }
}
impl molecule::prelude::Builder for AcceptChannelBuilder {
    type Entity = AcceptChannel;
    const NAME: &'static str = "AcceptChannelBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.channel_id.as_slice().len()
            + self.funding_amount.as_slice().len()
            + self.shutdown_script.as_slice().len()
            + self.reserved_ckb_amount.as_slice().len()
            + self.max_tlc_value_in_flight.as_slice().len()
            + self.max_tlc_number_in_flight.as_slice().len()
            + self.funding_pubkey.as_slice().len()
            + self.tlc_basepoint.as_slice().len()
            + self.first_per_commitment_point.as_slice().len()
            + self.second_per_commitment_point.as_slice().len()
            + self.channel_annoucement_nonce.as_slice().len()
            + self.next_local_nonce.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.channel_id.as_slice().len();
        offsets.push(total_size);
        total_size += self.funding_amount.as_slice().len();
        offsets.push(total_size);
        total_size += self.shutdown_script.as_slice().len();
        offsets.push(total_size);
        total_size += self.reserved_ckb_amount.as_slice().len();
        offsets.push(total_size);
        total_size += self.max_tlc_value_in_flight.as_slice().len();
        offsets.push(total_size);
        total_size += self.max_tlc_number_in_flight.as_slice().len();
        offsets.push(total_size);
        total_size += self.funding_pubkey.as_slice().len();
        offsets.push(total_size);
        total_size += self.tlc_basepoint.as_slice().len();
        offsets.push(total_size);
        total_size += self.first_per_commitment_point.as_slice().len();
        offsets.push(total_size);
        total_size += self.second_per_commitment_point.as_slice().len();
        offsets.push(total_size);
        total_size += self.channel_annoucement_nonce.as_slice().len();
        offsets.push(total_size);
        total_size += self.next_local_nonce.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.channel_id.as_slice())?;
        writer.write_all(self.funding_amount.as_slice())?;
        writer.write_all(self.shutdown_script.as_slice())?;
        writer.write_all(self.reserved_ckb_amount.as_slice())?;
        writer.write_all(self.max_tlc_value_in_flight.as_slice())?;
        writer.write_all(self.max_tlc_number_in_flight.as_slice())?;
        writer.write_all(self.funding_pubkey.as_slice())?;
        writer.write_all(self.tlc_basepoint.as_slice())?;
        writer.write_all(self.first_per_commitment_point.as_slice())?;
        writer.write_all(self.second_per_commitment_point.as_slice())?;
        writer.write_all(self.channel_annoucement_nonce.as_slice())?;
        writer.write_all(self.next_local_nonce.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        AcceptChannel::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct CommitmentSigned(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for CommitmentSigned {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for CommitmentSigned {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for CommitmentSigned {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(
            f,
            ", {}: {}",
            "funding_tx_partial_signature",
            self.funding_tx_partial_signature()
        )?;
        write!(
            f,
            ", {}: {}",
            "commitment_tx_partial_signature",
            self.commitment_tx_partial_signature()
        )?;
        write!(f, ", {}: {}", "next_local_nonce", self.next_local_nonce())?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for CommitmentSigned {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        CommitmentSigned::new_unchecked(v)
    }
}
impl CommitmentSigned {
    const DEFAULT_VALUE: [u8; 162] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const TOTAL_SIZE: usize = 162;
    pub const FIELD_SIZES: [usize; 4] = [32, 32, 32, 66];
    pub const FIELD_COUNT: usize = 4;
    pub fn channel_id(&self) -> Byte32 {
        Byte32::new_unchecked(self.0.slice(0..32))
    }
    pub fn funding_tx_partial_signature(&self) -> Byte32 {
        Byte32::new_unchecked(self.0.slice(32..64))
    }
    pub fn commitment_tx_partial_signature(&self) -> Byte32 {
        Byte32::new_unchecked(self.0.slice(64..96))
    }
    pub fn next_local_nonce(&self) -> PubNonce {
        PubNonce::new_unchecked(self.0.slice(96..162))
    }
    pub fn as_reader<'r>(&'r self) -> CommitmentSignedReader<'r> {
        CommitmentSignedReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for CommitmentSigned {
    type Builder = CommitmentSignedBuilder;
    const NAME: &'static str = "CommitmentSigned";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        CommitmentSigned(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        CommitmentSignedReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        CommitmentSignedReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_id(self.channel_id())
            .funding_tx_partial_signature(self.funding_tx_partial_signature())
            .commitment_tx_partial_signature(self.commitment_tx_partial_signature())
            .next_local_nonce(self.next_local_nonce())
    }
}
#[derive(Clone, Copy)]
pub struct CommitmentSignedReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for CommitmentSignedReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for CommitmentSignedReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for CommitmentSignedReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(
            f,
            ", {}: {}",
            "funding_tx_partial_signature",
            self.funding_tx_partial_signature()
        )?;
        write!(
            f,
            ", {}: {}",
            "commitment_tx_partial_signature",
            self.commitment_tx_partial_signature()
        )?;
        write!(f, ", {}: {}", "next_local_nonce", self.next_local_nonce())?;
        write!(f, " }}")
    }
}
impl<'r> CommitmentSignedReader<'r> {
    pub const TOTAL_SIZE: usize = 162;
    pub const FIELD_SIZES: [usize; 4] = [32, 32, 32, 66];
    pub const FIELD_COUNT: usize = 4;
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        Byte32Reader::new_unchecked(&self.as_slice()[0..32])
    }
    pub fn funding_tx_partial_signature(&self) -> Byte32Reader<'r> {
        Byte32Reader::new_unchecked(&self.as_slice()[32..64])
    }
    pub fn commitment_tx_partial_signature(&self) -> Byte32Reader<'r> {
        Byte32Reader::new_unchecked(&self.as_slice()[64..96])
    }
    pub fn next_local_nonce(&self) -> PubNonceReader<'r> {
        PubNonceReader::new_unchecked(&self.as_slice()[96..162])
    }
}
impl<'r> molecule::prelude::Reader<'r> for CommitmentSignedReader<'r> {
    type Entity = CommitmentSigned;
    const NAME: &'static str = "CommitmentSignedReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        CommitmentSignedReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct CommitmentSignedBuilder {
    pub(crate) channel_id: Byte32,
    pub(crate) funding_tx_partial_signature: Byte32,
    pub(crate) commitment_tx_partial_signature: Byte32,
    pub(crate) next_local_nonce: PubNonce,
}
impl CommitmentSignedBuilder {
    pub const TOTAL_SIZE: usize = 162;
    pub const FIELD_SIZES: [usize; 4] = [32, 32, 32, 66];
    pub const FIELD_COUNT: usize = 4;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
    pub fn funding_tx_partial_signature(mut self, v: Byte32) -> Self {
        self.funding_tx_partial_signature = v;
        self
    }
    pub fn commitment_tx_partial_signature(mut self, v: Byte32) -> Self {
        self.commitment_tx_partial_signature = v;
        self
    }
    pub fn next_local_nonce(mut self, v: PubNonce) -> Self {
        self.next_local_nonce = v;
        self
    }
}
impl molecule::prelude::Builder for CommitmentSignedBuilder {
    type Entity = CommitmentSigned;
    const NAME: &'static str = "CommitmentSignedBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.channel_id.as_slice())?;
        writer.write_all(self.funding_tx_partial_signature.as_slice())?;
        writer.write_all(self.commitment_tx_partial_signature.as_slice())?;
        writer.write_all(self.next_local_nonce.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        CommitmentSigned::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct TxSignatures(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for TxSignatures {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for TxSignatures {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for TxSignatures {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "witnesses", self.witnesses())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for TxSignatures {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        TxSignatures::new_unchecked(v)
    }
}
impl TxSignatures {
    const DEFAULT_VALUE: [u8; 48] = [
        48, 0, 0, 0, 12, 0, 0, 0, 44, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 2;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn witnesses(&self) -> BytesVec {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[12..]) as usize;
            BytesVec::new_unchecked(self.0.slice(start..end))
        } else {
            BytesVec::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> TxSignaturesReader<'r> {
        TxSignaturesReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for TxSignatures {
    type Builder = TxSignaturesBuilder;
    const NAME: &'static str = "TxSignatures";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        TxSignatures(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TxSignaturesReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TxSignaturesReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_id(self.channel_id())
            .witnesses(self.witnesses())
    }
}
#[derive(Clone, Copy)]
pub struct TxSignaturesReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for TxSignaturesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for TxSignaturesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for TxSignaturesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "witnesses", self.witnesses())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> TxSignaturesReader<'r> {
    pub const FIELD_COUNT: usize = 2;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn witnesses(&self) -> BytesVecReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[12..]) as usize;
            BytesVecReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            BytesVecReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for TxSignaturesReader<'r> {
    type Entity = TxSignatures;
    const NAME: &'static str = "TxSignaturesReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        TxSignaturesReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Byte32Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        BytesVecReader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct TxSignaturesBuilder {
    pub(crate) channel_id: Byte32,
    pub(crate) witnesses: BytesVec,
}
impl TxSignaturesBuilder {
    pub const FIELD_COUNT: usize = 2;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
    pub fn witnesses(mut self, v: BytesVec) -> Self {
        self.witnesses = v;
        self
    }
}
impl molecule::prelude::Builder for TxSignaturesBuilder {
    type Entity = TxSignatures;
    const NAME: &'static str = "TxSignaturesBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.channel_id.as_slice().len()
            + self.witnesses.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.channel_id.as_slice().len();
        offsets.push(total_size);
        total_size += self.witnesses.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.channel_id.as_slice())?;
        writer.write_all(self.witnesses.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        TxSignatures::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct ChannelReady(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for ChannelReady {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for ChannelReady {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for ChannelReady {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for ChannelReady {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        ChannelReady::new_unchecked(v)
    }
}
impl ChannelReady {
    const DEFAULT_VALUE: [u8; 32] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0,
    ];
    pub const TOTAL_SIZE: usize = 32;
    pub const FIELD_SIZES: [usize; 1] = [32];
    pub const FIELD_COUNT: usize = 1;
    pub fn channel_id(&self) -> Byte32 {
        Byte32::new_unchecked(self.0.slice(0..32))
    }
    pub fn as_reader<'r>(&'r self) -> ChannelReadyReader<'r> {
        ChannelReadyReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for ChannelReady {
    type Builder = ChannelReadyBuilder;
    const NAME: &'static str = "ChannelReady";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        ChannelReady(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ChannelReadyReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ChannelReadyReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().channel_id(self.channel_id())
    }
}
#[derive(Clone, Copy)]
pub struct ChannelReadyReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for ChannelReadyReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for ChannelReadyReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for ChannelReadyReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, " }}")
    }
}
impl<'r> ChannelReadyReader<'r> {
    pub const TOTAL_SIZE: usize = 32;
    pub const FIELD_SIZES: [usize; 1] = [32];
    pub const FIELD_COUNT: usize = 1;
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        Byte32Reader::new_unchecked(&self.as_slice()[0..32])
    }
}
impl<'r> molecule::prelude::Reader<'r> for ChannelReadyReader<'r> {
    type Entity = ChannelReady;
    const NAME: &'static str = "ChannelReadyReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        ChannelReadyReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct ChannelReadyBuilder {
    pub(crate) channel_id: Byte32,
}
impl ChannelReadyBuilder {
    pub const TOTAL_SIZE: usize = 32;
    pub const FIELD_SIZES: [usize; 1] = [32];
    pub const FIELD_COUNT: usize = 1;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
}
impl molecule::prelude::Builder for ChannelReadyBuilder {
    type Entity = ChannelReady;
    const NAME: &'static str = "ChannelReadyBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.channel_id.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        ChannelReady::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct TxUpdate(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for TxUpdate {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for TxUpdate {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for TxUpdate {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "tx", self.tx())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for TxUpdate {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        TxUpdate::new_unchecked(v)
    }
}
impl TxUpdate {
    const DEFAULT_VALUE: [u8; 112] = [
        112, 0, 0, 0, 12, 0, 0, 0, 44, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 68, 0, 0, 0, 12, 0, 0, 0, 64, 0, 0, 0, 52, 0,
        0, 0, 28, 0, 0, 0, 32, 0, 0, 0, 36, 0, 0, 0, 40, 0, 0, 0, 44, 0, 0, 0, 48, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 2;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn tx(&self) -> Transaction {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[12..]) as usize;
            Transaction::new_unchecked(self.0.slice(start..end))
        } else {
            Transaction::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> TxUpdateReader<'r> {
        TxUpdateReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for TxUpdate {
    type Builder = TxUpdateBuilder;
    const NAME: &'static str = "TxUpdate";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        TxUpdate(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TxUpdateReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TxUpdateReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_id(self.channel_id())
            .tx(self.tx())
    }
}
#[derive(Clone, Copy)]
pub struct TxUpdateReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for TxUpdateReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for TxUpdateReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for TxUpdateReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "tx", self.tx())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> TxUpdateReader<'r> {
    pub const FIELD_COUNT: usize = 2;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn tx(&self) -> TransactionReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[12..]) as usize;
            TransactionReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            TransactionReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for TxUpdateReader<'r> {
    type Entity = TxUpdate;
    const NAME: &'static str = "TxUpdateReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        TxUpdateReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Byte32Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        TransactionReader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct TxUpdateBuilder {
    pub(crate) channel_id: Byte32,
    pub(crate) tx: Transaction,
}
impl TxUpdateBuilder {
    pub const FIELD_COUNT: usize = 2;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
    pub fn tx(mut self, v: Transaction) -> Self {
        self.tx = v;
        self
    }
}
impl molecule::prelude::Builder for TxUpdateBuilder {
    type Entity = TxUpdate;
    const NAME: &'static str = "TxUpdateBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.channel_id.as_slice().len()
            + self.tx.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.channel_id.as_slice().len();
        offsets.push(total_size);
        total_size += self.tx.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.channel_id.as_slice())?;
        writer.write_all(self.tx.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        TxUpdate::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct TxComplete(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for TxComplete {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for TxComplete {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for TxComplete {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(
            f,
            ", {}: {}",
            "commitment_tx_partial_signature",
            self.commitment_tx_partial_signature()
        )?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for TxComplete {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        TxComplete::new_unchecked(v)
    }
}
impl TxComplete {
    const DEFAULT_VALUE: [u8; 64] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0,
    ];
    pub const TOTAL_SIZE: usize = 64;
    pub const FIELD_SIZES: [usize; 2] = [32, 32];
    pub const FIELD_COUNT: usize = 2;
    pub fn channel_id(&self) -> Byte32 {
        Byte32::new_unchecked(self.0.slice(0..32))
    }
    pub fn commitment_tx_partial_signature(&self) -> Byte32 {
        Byte32::new_unchecked(self.0.slice(32..64))
    }
    pub fn as_reader<'r>(&'r self) -> TxCompleteReader<'r> {
        TxCompleteReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for TxComplete {
    type Builder = TxCompleteBuilder;
    const NAME: &'static str = "TxComplete";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        TxComplete(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TxCompleteReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TxCompleteReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_id(self.channel_id())
            .commitment_tx_partial_signature(self.commitment_tx_partial_signature())
    }
}
#[derive(Clone, Copy)]
pub struct TxCompleteReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for TxCompleteReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for TxCompleteReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for TxCompleteReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(
            f,
            ", {}: {}",
            "commitment_tx_partial_signature",
            self.commitment_tx_partial_signature()
        )?;
        write!(f, " }}")
    }
}
impl<'r> TxCompleteReader<'r> {
    pub const TOTAL_SIZE: usize = 64;
    pub const FIELD_SIZES: [usize; 2] = [32, 32];
    pub const FIELD_COUNT: usize = 2;
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        Byte32Reader::new_unchecked(&self.as_slice()[0..32])
    }
    pub fn commitment_tx_partial_signature(&self) -> Byte32Reader<'r> {
        Byte32Reader::new_unchecked(&self.as_slice()[32..64])
    }
}
impl<'r> molecule::prelude::Reader<'r> for TxCompleteReader<'r> {
    type Entity = TxComplete;
    const NAME: &'static str = "TxCompleteReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        TxCompleteReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct TxCompleteBuilder {
    pub(crate) channel_id: Byte32,
    pub(crate) commitment_tx_partial_signature: Byte32,
}
impl TxCompleteBuilder {
    pub const TOTAL_SIZE: usize = 64;
    pub const FIELD_SIZES: [usize; 2] = [32, 32];
    pub const FIELD_COUNT: usize = 2;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
    pub fn commitment_tx_partial_signature(mut self, v: Byte32) -> Self {
        self.commitment_tx_partial_signature = v;
        self
    }
}
impl molecule::prelude::Builder for TxCompleteBuilder {
    type Entity = TxComplete;
    const NAME: &'static str = "TxCompleteBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.channel_id.as_slice())?;
        writer.write_all(self.commitment_tx_partial_signature.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        TxComplete::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct TxAbort(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for TxAbort {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for TxAbort {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for TxAbort {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "message", self.message())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for TxAbort {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        TxAbort::new_unchecked(v)
    }
}
impl TxAbort {
    const DEFAULT_VALUE: [u8; 48] = [
        48, 0, 0, 0, 12, 0, 0, 0, 44, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 2;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn message(&self) -> Bytes {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[12..]) as usize;
            Bytes::new_unchecked(self.0.slice(start..end))
        } else {
            Bytes::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> TxAbortReader<'r> {
        TxAbortReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for TxAbort {
    type Builder = TxAbortBuilder;
    const NAME: &'static str = "TxAbort";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        TxAbort(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TxAbortReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TxAbortReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_id(self.channel_id())
            .message(self.message())
    }
}
#[derive(Clone, Copy)]
pub struct TxAbortReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for TxAbortReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for TxAbortReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for TxAbortReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "message", self.message())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> TxAbortReader<'r> {
    pub const FIELD_COUNT: usize = 2;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn message(&self) -> BytesReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[12..]) as usize;
            BytesReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            BytesReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for TxAbortReader<'r> {
    type Entity = TxAbort;
    const NAME: &'static str = "TxAbortReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        TxAbortReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Byte32Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        BytesReader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct TxAbortBuilder {
    pub(crate) channel_id: Byte32,
    pub(crate) message: Bytes,
}
impl TxAbortBuilder {
    pub const FIELD_COUNT: usize = 2;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
    pub fn message(mut self, v: Bytes) -> Self {
        self.message = v;
        self
    }
}
impl molecule::prelude::Builder for TxAbortBuilder {
    type Entity = TxAbort;
    const NAME: &'static str = "TxAbortBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.channel_id.as_slice().len()
            + self.message.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.channel_id.as_slice().len();
        offsets.push(total_size);
        total_size += self.message.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.channel_id.as_slice())?;
        writer.write_all(self.message.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        TxAbort::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct TxInitRBF(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for TxInitRBF {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for TxInitRBF {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for TxInitRBF {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "fee_rate", self.fee_rate())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for TxInitRBF {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        TxInitRBF::new_unchecked(v)
    }
}
impl TxInitRBF {
    const DEFAULT_VALUE: [u8; 52] = [
        52, 0, 0, 0, 12, 0, 0, 0, 44, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 2;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn fee_rate(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[12..]) as usize;
            Uint64::new_unchecked(self.0.slice(start..end))
        } else {
            Uint64::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> TxInitRBFReader<'r> {
        TxInitRBFReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for TxInitRBF {
    type Builder = TxInitRBFBuilder;
    const NAME: &'static str = "TxInitRBF";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        TxInitRBF(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TxInitRBFReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TxInitRBFReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_id(self.channel_id())
            .fee_rate(self.fee_rate())
    }
}
#[derive(Clone, Copy)]
pub struct TxInitRBFReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for TxInitRBFReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for TxInitRBFReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for TxInitRBFReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "fee_rate", self.fee_rate())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> TxInitRBFReader<'r> {
    pub const FIELD_COUNT: usize = 2;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn fee_rate(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[12..]) as usize;
            Uint64Reader::new_unchecked(&self.as_slice()[start..end])
        } else {
            Uint64Reader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for TxInitRBFReader<'r> {
    type Entity = TxInitRBF;
    const NAME: &'static str = "TxInitRBFReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        TxInitRBFReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Byte32Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Uint64Reader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct TxInitRBFBuilder {
    pub(crate) channel_id: Byte32,
    pub(crate) fee_rate: Uint64,
}
impl TxInitRBFBuilder {
    pub const FIELD_COUNT: usize = 2;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
    pub fn fee_rate(mut self, v: Uint64) -> Self {
        self.fee_rate = v;
        self
    }
}
impl molecule::prelude::Builder for TxInitRBFBuilder {
    type Entity = TxInitRBF;
    const NAME: &'static str = "TxInitRBFBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.channel_id.as_slice().len()
            + self.fee_rate.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.channel_id.as_slice().len();
        offsets.push(total_size);
        total_size += self.fee_rate.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.channel_id.as_slice())?;
        writer.write_all(self.fee_rate.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        TxInitRBF::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct TxAckRBF(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for TxAckRBF {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for TxAckRBF {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for TxAckRBF {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for TxAckRBF {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        TxAckRBF::new_unchecked(v)
    }
}
impl TxAckRBF {
    const DEFAULT_VALUE: [u8; 40] = [
        40, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 1;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[8..]) as usize;
            Byte32::new_unchecked(self.0.slice(start..end))
        } else {
            Byte32::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> TxAckRBFReader<'r> {
        TxAckRBFReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for TxAckRBF {
    type Builder = TxAckRBFBuilder;
    const NAME: &'static str = "TxAckRBF";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        TxAckRBF(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TxAckRBFReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TxAckRBFReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().channel_id(self.channel_id())
    }
}
#[derive(Clone, Copy)]
pub struct TxAckRBFReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for TxAckRBFReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for TxAckRBFReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for TxAckRBFReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> TxAckRBFReader<'r> {
    pub const FIELD_COUNT: usize = 1;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[8..]) as usize;
            Byte32Reader::new_unchecked(&self.as_slice()[start..end])
        } else {
            Byte32Reader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for TxAckRBFReader<'r> {
    type Entity = TxAckRBF;
    const NAME: &'static str = "TxAckRBFReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        TxAckRBFReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Byte32Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct TxAckRBFBuilder {
    pub(crate) channel_id: Byte32,
}
impl TxAckRBFBuilder {
    pub const FIELD_COUNT: usize = 1;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
}
impl molecule::prelude::Builder for TxAckRBFBuilder {
    type Entity = TxAckRBF;
    const NAME: &'static str = "TxAckRBFBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1) + self.channel_id.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.channel_id.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.channel_id.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        TxAckRBF::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct Shutdown(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for Shutdown {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for Shutdown {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for Shutdown {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "fee_rate", self.fee_rate())?;
        write!(f, ", {}: {}", "close_script", self.close_script())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for Shutdown {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        Shutdown::new_unchecked(v)
    }
}
impl Shutdown {
    const DEFAULT_VALUE: [u8; 109] = [
        109, 0, 0, 0, 16, 0, 0, 0, 48, 0, 0, 0, 56, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 53, 0, 0,
        0, 16, 0, 0, 0, 48, 0, 0, 0, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn fee_rate(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn close_script(&self) -> Script {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            Script::new_unchecked(self.0.slice(start..end))
        } else {
            Script::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> ShutdownReader<'r> {
        ShutdownReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for Shutdown {
    type Builder = ShutdownBuilder;
    const NAME: &'static str = "Shutdown";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        Shutdown(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ShutdownReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ShutdownReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_id(self.channel_id())
            .fee_rate(self.fee_rate())
            .close_script(self.close_script())
    }
}
#[derive(Clone, Copy)]
pub struct ShutdownReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for ShutdownReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for ShutdownReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for ShutdownReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "fee_rate", self.fee_rate())?;
        write!(f, ", {}: {}", "close_script", self.close_script())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> ShutdownReader<'r> {
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn fee_rate(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn close_script(&self) -> ScriptReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            ScriptReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            ScriptReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for ShutdownReader<'r> {
    type Entity = Shutdown;
    const NAME: &'static str = "ShutdownReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        ShutdownReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Byte32Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Uint64Reader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        ScriptReader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct ShutdownBuilder {
    pub(crate) channel_id: Byte32,
    pub(crate) fee_rate: Uint64,
    pub(crate) close_script: Script,
}
impl ShutdownBuilder {
    pub const FIELD_COUNT: usize = 3;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
    pub fn fee_rate(mut self, v: Uint64) -> Self {
        self.fee_rate = v;
        self
    }
    pub fn close_script(mut self, v: Script) -> Self {
        self.close_script = v;
        self
    }
}
impl molecule::prelude::Builder for ShutdownBuilder {
    type Entity = Shutdown;
    const NAME: &'static str = "ShutdownBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.channel_id.as_slice().len()
            + self.fee_rate.as_slice().len()
            + self.close_script.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.channel_id.as_slice().len();
        offsets.push(total_size);
        total_size += self.fee_rate.as_slice().len();
        offsets.push(total_size);
        total_size += self.close_script.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.channel_id.as_slice())?;
        writer.write_all(self.fee_rate.as_slice())?;
        writer.write_all(self.close_script.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        Shutdown::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct ClosingSigned(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for ClosingSigned {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for ClosingSigned {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for ClosingSigned {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "partial_signature", self.partial_signature())?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for ClosingSigned {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        ClosingSigned::new_unchecked(v)
    }
}
impl ClosingSigned {
    const DEFAULT_VALUE: [u8; 64] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0,
    ];
    pub const TOTAL_SIZE: usize = 64;
    pub const FIELD_SIZES: [usize; 2] = [32, 32];
    pub const FIELD_COUNT: usize = 2;
    pub fn channel_id(&self) -> Byte32 {
        Byte32::new_unchecked(self.0.slice(0..32))
    }
    pub fn partial_signature(&self) -> Byte32 {
        Byte32::new_unchecked(self.0.slice(32..64))
    }
    pub fn as_reader<'r>(&'r self) -> ClosingSignedReader<'r> {
        ClosingSignedReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for ClosingSigned {
    type Builder = ClosingSignedBuilder;
    const NAME: &'static str = "ClosingSigned";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        ClosingSigned(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ClosingSignedReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ClosingSignedReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_id(self.channel_id())
            .partial_signature(self.partial_signature())
    }
}
#[derive(Clone, Copy)]
pub struct ClosingSignedReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for ClosingSignedReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for ClosingSignedReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for ClosingSignedReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "partial_signature", self.partial_signature())?;
        write!(f, " }}")
    }
}
impl<'r> ClosingSignedReader<'r> {
    pub const TOTAL_SIZE: usize = 64;
    pub const FIELD_SIZES: [usize; 2] = [32, 32];
    pub const FIELD_COUNT: usize = 2;
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        Byte32Reader::new_unchecked(&self.as_slice()[0..32])
    }
    pub fn partial_signature(&self) -> Byte32Reader<'r> {
        Byte32Reader::new_unchecked(&self.as_slice()[32..64])
    }
}
impl<'r> molecule::prelude::Reader<'r> for ClosingSignedReader<'r> {
    type Entity = ClosingSigned;
    const NAME: &'static str = "ClosingSignedReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        ClosingSignedReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct ClosingSignedBuilder {
    pub(crate) channel_id: Byte32,
    pub(crate) partial_signature: Byte32,
}
impl ClosingSignedBuilder {
    pub const TOTAL_SIZE: usize = 64;
    pub const FIELD_SIZES: [usize; 2] = [32, 32];
    pub const FIELD_COUNT: usize = 2;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
    pub fn partial_signature(mut self, v: Byte32) -> Self {
        self.partial_signature = v;
        self
    }
}
impl molecule::prelude::Builder for ClosingSignedBuilder {
    type Entity = ClosingSigned;
    const NAME: &'static str = "ClosingSignedBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.channel_id.as_slice())?;
        writer.write_all(self.partial_signature.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        ClosingSigned::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct UpdateTlcInfo(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for UpdateTlcInfo {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for UpdateTlcInfo {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for UpdateTlcInfo {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "timestamp", self.timestamp())?;
        write!(f, ", {}: {}", "channel_flags", self.channel_flags())?;
        write!(f, ", {}: {}", "tlc_expiry_delta", self.tlc_expiry_delta())?;
        write!(f, ", {}: {}", "tlc_minimum_value", self.tlc_minimum_value())?;
        write!(f, ", {}: {}", "tlc_maximum_value", self.tlc_maximum_value())?;
        write!(
            f,
            ", {}: {}",
            "tlc_fee_proportional_millionths",
            self.tlc_fee_proportional_millionths()
        )?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for UpdateTlcInfo {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        UpdateTlcInfo::new_unchecked(v)
    }
}
impl UpdateTlcInfo {
    const DEFAULT_VALUE: [u8; 100] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const TOTAL_SIZE: usize = 100;
    pub const FIELD_SIZES: [usize; 7] = [32, 8, 4, 8, 16, 16, 16];
    pub const FIELD_COUNT: usize = 7;
    pub fn channel_id(&self) -> Byte32 {
        Byte32::new_unchecked(self.0.slice(0..32))
    }
    pub fn timestamp(&self) -> Uint64 {
        Uint64::new_unchecked(self.0.slice(32..40))
    }
    pub fn channel_flags(&self) -> Uint32 {
        Uint32::new_unchecked(self.0.slice(40..44))
    }
    pub fn tlc_expiry_delta(&self) -> Uint64 {
        Uint64::new_unchecked(self.0.slice(44..52))
    }
    pub fn tlc_minimum_value(&self) -> Uint128 {
        Uint128::new_unchecked(self.0.slice(52..68))
    }
    pub fn tlc_maximum_value(&self) -> Uint128 {
        Uint128::new_unchecked(self.0.slice(68..84))
    }
    pub fn tlc_fee_proportional_millionths(&self) -> Uint128 {
        Uint128::new_unchecked(self.0.slice(84..100))
    }
    pub fn as_reader<'r>(&'r self) -> UpdateTlcInfoReader<'r> {
        UpdateTlcInfoReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for UpdateTlcInfo {
    type Builder = UpdateTlcInfoBuilder;
    const NAME: &'static str = "UpdateTlcInfo";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        UpdateTlcInfo(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        UpdateTlcInfoReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        UpdateTlcInfoReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_id(self.channel_id())
            .timestamp(self.timestamp())
            .channel_flags(self.channel_flags())
            .tlc_expiry_delta(self.tlc_expiry_delta())
            .tlc_minimum_value(self.tlc_minimum_value())
            .tlc_maximum_value(self.tlc_maximum_value())
            .tlc_fee_proportional_millionths(self.tlc_fee_proportional_millionths())
    }
}
#[derive(Clone, Copy)]
pub struct UpdateTlcInfoReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for UpdateTlcInfoReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for UpdateTlcInfoReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for UpdateTlcInfoReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "timestamp", self.timestamp())?;
        write!(f, ", {}: {}", "channel_flags", self.channel_flags())?;
        write!(f, ", {}: {}", "tlc_expiry_delta", self.tlc_expiry_delta())?;
        write!(f, ", {}: {}", "tlc_minimum_value", self.tlc_minimum_value())?;
        write!(f, ", {}: {}", "tlc_maximum_value", self.tlc_maximum_value())?;
        write!(
            f,
            ", {}: {}",
            "tlc_fee_proportional_millionths",
            self.tlc_fee_proportional_millionths()
        )?;
        write!(f, " }}")
    }
}
impl<'r> UpdateTlcInfoReader<'r> {
    pub const TOTAL_SIZE: usize = 100;
    pub const FIELD_SIZES: [usize; 7] = [32, 8, 4, 8, 16, 16, 16];
    pub const FIELD_COUNT: usize = 7;
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        Byte32Reader::new_unchecked(&self.as_slice()[0..32])
    }
    pub fn timestamp(&self) -> Uint64Reader<'r> {
        Uint64Reader::new_unchecked(&self.as_slice()[32..40])
    }
    pub fn channel_flags(&self) -> Uint32Reader<'r> {
        Uint32Reader::new_unchecked(&self.as_slice()[40..44])
    }
    pub fn tlc_expiry_delta(&self) -> Uint64Reader<'r> {
        Uint64Reader::new_unchecked(&self.as_slice()[44..52])
    }
    pub fn tlc_minimum_value(&self) -> Uint128Reader<'r> {
        Uint128Reader::new_unchecked(&self.as_slice()[52..68])
    }
    pub fn tlc_maximum_value(&self) -> Uint128Reader<'r> {
        Uint128Reader::new_unchecked(&self.as_slice()[68..84])
    }
    pub fn tlc_fee_proportional_millionths(&self) -> Uint128Reader<'r> {
        Uint128Reader::new_unchecked(&self.as_slice()[84..100])
    }
}
impl<'r> molecule::prelude::Reader<'r> for UpdateTlcInfoReader<'r> {
    type Entity = UpdateTlcInfo;
    const NAME: &'static str = "UpdateTlcInfoReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        UpdateTlcInfoReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct UpdateTlcInfoBuilder {
    pub(crate) channel_id: Byte32,
    pub(crate) timestamp: Uint64,
    pub(crate) channel_flags: Uint32,
    pub(crate) tlc_expiry_delta: Uint64,
    pub(crate) tlc_minimum_value: Uint128,
    pub(crate) tlc_maximum_value: Uint128,
    pub(crate) tlc_fee_proportional_millionths: Uint128,
}
impl UpdateTlcInfoBuilder {
    pub const TOTAL_SIZE: usize = 100;
    pub const FIELD_SIZES: [usize; 7] = [32, 8, 4, 8, 16, 16, 16];
    pub const FIELD_COUNT: usize = 7;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
    pub fn timestamp(mut self, v: Uint64) -> Self {
        self.timestamp = v;
        self
    }
    pub fn channel_flags(mut self, v: Uint32) -> Self {
        self.channel_flags = v;
        self
    }
    pub fn tlc_expiry_delta(mut self, v: Uint64) -> Self {
        self.tlc_expiry_delta = v;
        self
    }
    pub fn tlc_minimum_value(mut self, v: Uint128) -> Self {
        self.tlc_minimum_value = v;
        self
    }
    pub fn tlc_maximum_value(mut self, v: Uint128) -> Self {
        self.tlc_maximum_value = v;
        self
    }
    pub fn tlc_fee_proportional_millionths(mut self, v: Uint128) -> Self {
        self.tlc_fee_proportional_millionths = v;
        self
    }
}
impl molecule::prelude::Builder for UpdateTlcInfoBuilder {
    type Entity = UpdateTlcInfo;
    const NAME: &'static str = "UpdateTlcInfoBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.channel_id.as_slice())?;
        writer.write_all(self.timestamp.as_slice())?;
        writer.write_all(self.channel_flags.as_slice())?;
        writer.write_all(self.tlc_expiry_delta.as_slice())?;
        writer.write_all(self.tlc_minimum_value.as_slice())?;
        writer.write_all(self.tlc_maximum_value.as_slice())?;
        writer.write_all(self.tlc_fee_proportional_millionths.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        UpdateTlcInfo::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct AddTlc(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for AddTlc {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for AddTlc {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for AddTlc {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "tlc_id", self.tlc_id())?;
        write!(f, ", {}: {}", "amount", self.amount())?;
        write!(f, ", {}: {}", "payment_hash", self.payment_hash())?;
        write!(f, ", {}: {}", "expiry", self.expiry())?;
        write!(f, ", {}: {}", "hash_algorithm", self.hash_algorithm())?;
        write!(f, ", {}: {}", "onion_packet", self.onion_packet())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for AddTlc {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        AddTlc::new_unchecked(v)
    }
}
impl AddTlc {
    const DEFAULT_VALUE: [u8; 133] = [
        133, 0, 0, 0, 32, 0, 0, 0, 64, 0, 0, 0, 72, 0, 0, 0, 88, 0, 0, 0, 120, 0, 0, 0, 128, 0, 0,
        0, 129, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 7;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn tlc_id(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn amount(&self) -> Uint128 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        Uint128::new_unchecked(self.0.slice(start..end))
    }
    pub fn payment_hash(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        let end = molecule::unpack_number(&slice[20..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn expiry(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[20..]) as usize;
        let end = molecule::unpack_number(&slice[24..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn hash_algorithm(&self) -> Byte {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[24..]) as usize;
        let end = molecule::unpack_number(&slice[28..]) as usize;
        Byte::new_unchecked(self.0.slice(start..end))
    }
    pub fn onion_packet(&self) -> Bytes {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[28..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[32..]) as usize;
            Bytes::new_unchecked(self.0.slice(start..end))
        } else {
            Bytes::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> AddTlcReader<'r> {
        AddTlcReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for AddTlc {
    type Builder = AddTlcBuilder;
    const NAME: &'static str = "AddTlc";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        AddTlc(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        AddTlcReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        AddTlcReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_id(self.channel_id())
            .tlc_id(self.tlc_id())
            .amount(self.amount())
            .payment_hash(self.payment_hash())
            .expiry(self.expiry())
            .hash_algorithm(self.hash_algorithm())
            .onion_packet(self.onion_packet())
    }
}
#[derive(Clone, Copy)]
pub struct AddTlcReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for AddTlcReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for AddTlcReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for AddTlcReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "tlc_id", self.tlc_id())?;
        write!(f, ", {}: {}", "amount", self.amount())?;
        write!(f, ", {}: {}", "payment_hash", self.payment_hash())?;
        write!(f, ", {}: {}", "expiry", self.expiry())?;
        write!(f, ", {}: {}", "hash_algorithm", self.hash_algorithm())?;
        write!(f, ", {}: {}", "onion_packet", self.onion_packet())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> AddTlcReader<'r> {
    pub const FIELD_COUNT: usize = 7;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn tlc_id(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn amount(&self) -> Uint128Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        Uint128Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn payment_hash(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        let end = molecule::unpack_number(&slice[20..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn expiry(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[20..]) as usize;
        let end = molecule::unpack_number(&slice[24..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn hash_algorithm(&self) -> ByteReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[24..]) as usize;
        let end = molecule::unpack_number(&slice[28..]) as usize;
        ByteReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn onion_packet(&self) -> BytesReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[28..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[32..]) as usize;
            BytesReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            BytesReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for AddTlcReader<'r> {
    type Entity = AddTlc;
    const NAME: &'static str = "AddTlcReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        AddTlcReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Byte32Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Uint64Reader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        Uint128Reader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        Byte32Reader::verify(&slice[offsets[3]..offsets[4]], compatible)?;
        Uint64Reader::verify(&slice[offsets[4]..offsets[5]], compatible)?;
        ByteReader::verify(&slice[offsets[5]..offsets[6]], compatible)?;
        BytesReader::verify(&slice[offsets[6]..offsets[7]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct AddTlcBuilder {
    pub(crate) channel_id: Byte32,
    pub(crate) tlc_id: Uint64,
    pub(crate) amount: Uint128,
    pub(crate) payment_hash: Byte32,
    pub(crate) expiry: Uint64,
    pub(crate) hash_algorithm: Byte,
    pub(crate) onion_packet: Bytes,
}
impl AddTlcBuilder {
    pub const FIELD_COUNT: usize = 7;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
    pub fn tlc_id(mut self, v: Uint64) -> Self {
        self.tlc_id = v;
        self
    }
    pub fn amount(mut self, v: Uint128) -> Self {
        self.amount = v;
        self
    }
    pub fn payment_hash(mut self, v: Byte32) -> Self {
        self.payment_hash = v;
        self
    }
    pub fn expiry(mut self, v: Uint64) -> Self {
        self.expiry = v;
        self
    }
    pub fn hash_algorithm(mut self, v: Byte) -> Self {
        self.hash_algorithm = v;
        self
    }
    pub fn onion_packet(mut self, v: Bytes) -> Self {
        self.onion_packet = v;
        self
    }
}
impl molecule::prelude::Builder for AddTlcBuilder {
    type Entity = AddTlc;
    const NAME: &'static str = "AddTlcBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.channel_id.as_slice().len()
            + self.tlc_id.as_slice().len()
            + self.amount.as_slice().len()
            + self.payment_hash.as_slice().len()
            + self.expiry.as_slice().len()
            + self.hash_algorithm.as_slice().len()
            + self.onion_packet.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.channel_id.as_slice().len();
        offsets.push(total_size);
        total_size += self.tlc_id.as_slice().len();
        offsets.push(total_size);
        total_size += self.amount.as_slice().len();
        offsets.push(total_size);
        total_size += self.payment_hash.as_slice().len();
        offsets.push(total_size);
        total_size += self.expiry.as_slice().len();
        offsets.push(total_size);
        total_size += self.hash_algorithm.as_slice().len();
        offsets.push(total_size);
        total_size += self.onion_packet.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.channel_id.as_slice())?;
        writer.write_all(self.tlc_id.as_slice())?;
        writer.write_all(self.amount.as_slice())?;
        writer.write_all(self.payment_hash.as_slice())?;
        writer.write_all(self.expiry.as_slice())?;
        writer.write_all(self.hash_algorithm.as_slice())?;
        writer.write_all(self.onion_packet.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        AddTlc::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct RevokeAndAck(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for RevokeAndAck {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for RevokeAndAck {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for RevokeAndAck {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(
            f,
            ", {}: {}",
            "revocation_partial_signature",
            self.revocation_partial_signature()
        )?;
        write!(
            f,
            ", {}: {}",
            "commitment_tx_partial_signature",
            self.commitment_tx_partial_signature()
        )?;
        write!(
            f,
            ", {}: {}",
            "next_per_commitment_point",
            self.next_per_commitment_point()
        )?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for RevokeAndAck {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        RevokeAndAck::new_unchecked(v)
    }
}
impl RevokeAndAck {
    const DEFAULT_VALUE: [u8; 129] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const TOTAL_SIZE: usize = 129;
    pub const FIELD_SIZES: [usize; 4] = [32, 32, 32, 33];
    pub const FIELD_COUNT: usize = 4;
    pub fn channel_id(&self) -> Byte32 {
        Byte32::new_unchecked(self.0.slice(0..32))
    }
    pub fn revocation_partial_signature(&self) -> Byte32 {
        Byte32::new_unchecked(self.0.slice(32..64))
    }
    pub fn commitment_tx_partial_signature(&self) -> Byte32 {
        Byte32::new_unchecked(self.0.slice(64..96))
    }
    pub fn next_per_commitment_point(&self) -> Pubkey {
        Pubkey::new_unchecked(self.0.slice(96..129))
    }
    pub fn as_reader<'r>(&'r self) -> RevokeAndAckReader<'r> {
        RevokeAndAckReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for RevokeAndAck {
    type Builder = RevokeAndAckBuilder;
    const NAME: &'static str = "RevokeAndAck";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        RevokeAndAck(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        RevokeAndAckReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        RevokeAndAckReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_id(self.channel_id())
            .revocation_partial_signature(self.revocation_partial_signature())
            .commitment_tx_partial_signature(self.commitment_tx_partial_signature())
            .next_per_commitment_point(self.next_per_commitment_point())
    }
}
#[derive(Clone, Copy)]
pub struct RevokeAndAckReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for RevokeAndAckReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for RevokeAndAckReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for RevokeAndAckReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(
            f,
            ", {}: {}",
            "revocation_partial_signature",
            self.revocation_partial_signature()
        )?;
        write!(
            f,
            ", {}: {}",
            "commitment_tx_partial_signature",
            self.commitment_tx_partial_signature()
        )?;
        write!(
            f,
            ", {}: {}",
            "next_per_commitment_point",
            self.next_per_commitment_point()
        )?;
        write!(f, " }}")
    }
}
impl<'r> RevokeAndAckReader<'r> {
    pub const TOTAL_SIZE: usize = 129;
    pub const FIELD_SIZES: [usize; 4] = [32, 32, 32, 33];
    pub const FIELD_COUNT: usize = 4;
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        Byte32Reader::new_unchecked(&self.as_slice()[0..32])
    }
    pub fn revocation_partial_signature(&self) -> Byte32Reader<'r> {
        Byte32Reader::new_unchecked(&self.as_slice()[32..64])
    }
    pub fn commitment_tx_partial_signature(&self) -> Byte32Reader<'r> {
        Byte32Reader::new_unchecked(&self.as_slice()[64..96])
    }
    pub fn next_per_commitment_point(&self) -> PubkeyReader<'r> {
        PubkeyReader::new_unchecked(&self.as_slice()[96..129])
    }
}
impl<'r> molecule::prelude::Reader<'r> for RevokeAndAckReader<'r> {
    type Entity = RevokeAndAck;
    const NAME: &'static str = "RevokeAndAckReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        RevokeAndAckReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct RevokeAndAckBuilder {
    pub(crate) channel_id: Byte32,
    pub(crate) revocation_partial_signature: Byte32,
    pub(crate) commitment_tx_partial_signature: Byte32,
    pub(crate) next_per_commitment_point: Pubkey,
}
impl RevokeAndAckBuilder {
    pub const TOTAL_SIZE: usize = 129;
    pub const FIELD_SIZES: [usize; 4] = [32, 32, 32, 33];
    pub const FIELD_COUNT: usize = 4;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
    pub fn revocation_partial_signature(mut self, v: Byte32) -> Self {
        self.revocation_partial_signature = v;
        self
    }
    pub fn commitment_tx_partial_signature(mut self, v: Byte32) -> Self {
        self.commitment_tx_partial_signature = v;
        self
    }
    pub fn next_per_commitment_point(mut self, v: Pubkey) -> Self {
        self.next_per_commitment_point = v;
        self
    }
}
impl molecule::prelude::Builder for RevokeAndAckBuilder {
    type Entity = RevokeAndAck;
    const NAME: &'static str = "RevokeAndAckBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.channel_id.as_slice())?;
        writer.write_all(self.revocation_partial_signature.as_slice())?;
        writer.write_all(self.commitment_tx_partial_signature.as_slice())?;
        writer.write_all(self.next_per_commitment_point.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        RevokeAndAck::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct RemoveTlcFulfill(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for RemoveTlcFulfill {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for RemoveTlcFulfill {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for RemoveTlcFulfill {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "payment_preimage", self.payment_preimage())?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for RemoveTlcFulfill {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        RemoveTlcFulfill::new_unchecked(v)
    }
}
impl RemoveTlcFulfill {
    const DEFAULT_VALUE: [u8; 32] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0,
    ];
    pub const TOTAL_SIZE: usize = 32;
    pub const FIELD_SIZES: [usize; 1] = [32];
    pub const FIELD_COUNT: usize = 1;
    pub fn payment_preimage(&self) -> Byte32 {
        Byte32::new_unchecked(self.0.slice(0..32))
    }
    pub fn as_reader<'r>(&'r self) -> RemoveTlcFulfillReader<'r> {
        RemoveTlcFulfillReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for RemoveTlcFulfill {
    type Builder = RemoveTlcFulfillBuilder;
    const NAME: &'static str = "RemoveTlcFulfill";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        RemoveTlcFulfill(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        RemoveTlcFulfillReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        RemoveTlcFulfillReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().payment_preimage(self.payment_preimage())
    }
}
#[derive(Clone, Copy)]
pub struct RemoveTlcFulfillReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for RemoveTlcFulfillReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for RemoveTlcFulfillReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for RemoveTlcFulfillReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "payment_preimage", self.payment_preimage())?;
        write!(f, " }}")
    }
}
impl<'r> RemoveTlcFulfillReader<'r> {
    pub const TOTAL_SIZE: usize = 32;
    pub const FIELD_SIZES: [usize; 1] = [32];
    pub const FIELD_COUNT: usize = 1;
    pub fn payment_preimage(&self) -> Byte32Reader<'r> {
        Byte32Reader::new_unchecked(&self.as_slice()[0..32])
    }
}
impl<'r> molecule::prelude::Reader<'r> for RemoveTlcFulfillReader<'r> {
    type Entity = RemoveTlcFulfill;
    const NAME: &'static str = "RemoveTlcFulfillReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        RemoveTlcFulfillReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct RemoveTlcFulfillBuilder {
    pub(crate) payment_preimage: Byte32,
}
impl RemoveTlcFulfillBuilder {
    pub const TOTAL_SIZE: usize = 32;
    pub const FIELD_SIZES: [usize; 1] = [32];
    pub const FIELD_COUNT: usize = 1;
    pub fn payment_preimage(mut self, v: Byte32) -> Self {
        self.payment_preimage = v;
        self
    }
}
impl molecule::prelude::Builder for RemoveTlcFulfillBuilder {
    type Entity = RemoveTlcFulfill;
    const NAME: &'static str = "RemoveTlcFulfillBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.payment_preimage.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        RemoveTlcFulfill::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct TlcErrPacket(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for TlcErrPacket {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for TlcErrPacket {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for TlcErrPacket {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "onion_packet", self.onion_packet())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for TlcErrPacket {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        TlcErrPacket::new_unchecked(v)
    }
}
impl TlcErrPacket {
    const DEFAULT_VALUE: [u8; 12] = [12, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0];
    pub const FIELD_COUNT: usize = 1;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn onion_packet(&self) -> Bytes {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[8..]) as usize;
            Bytes::new_unchecked(self.0.slice(start..end))
        } else {
            Bytes::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> TlcErrPacketReader<'r> {
        TlcErrPacketReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for TlcErrPacket {
    type Builder = TlcErrPacketBuilder;
    const NAME: &'static str = "TlcErrPacket";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        TlcErrPacket(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TlcErrPacketReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TlcErrPacketReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().onion_packet(self.onion_packet())
    }
}
#[derive(Clone, Copy)]
pub struct TlcErrPacketReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for TlcErrPacketReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for TlcErrPacketReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for TlcErrPacketReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "onion_packet", self.onion_packet())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> TlcErrPacketReader<'r> {
    pub const FIELD_COUNT: usize = 1;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn onion_packet(&self) -> BytesReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[8..]) as usize;
            BytesReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            BytesReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for TlcErrPacketReader<'r> {
    type Entity = TlcErrPacket;
    const NAME: &'static str = "TlcErrPacketReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        TlcErrPacketReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        BytesReader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct TlcErrPacketBuilder {
    pub(crate) onion_packet: Bytes,
}
impl TlcErrPacketBuilder {
    pub const FIELD_COUNT: usize = 1;
    pub fn onion_packet(mut self, v: Bytes) -> Self {
        self.onion_packet = v;
        self
    }
}
impl molecule::prelude::Builder for TlcErrPacketBuilder {
    type Entity = TlcErrPacket;
    const NAME: &'static str = "TlcErrPacketBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1) + self.onion_packet.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.onion_packet.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.onion_packet.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        TlcErrPacket::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct RemoveTlcReason(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for RemoveTlcReason {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for RemoveTlcReason {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for RemoveTlcReason {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}(", Self::NAME)?;
        self.to_enum().display_inner(f)?;
        write!(f, ")")
    }
}
impl ::core::default::Default for RemoveTlcReason {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        RemoveTlcReason::new_unchecked(v)
    }
}
impl RemoveTlcReason {
    const DEFAULT_VALUE: [u8; 36] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0,
    ];
    pub const ITEMS_COUNT: usize = 2;
    pub fn item_id(&self) -> molecule::Number {
        molecule::unpack_number(self.as_slice())
    }
    pub fn to_enum(&self) -> RemoveTlcReasonUnion {
        let inner = self.0.slice(molecule::NUMBER_SIZE..);
        match self.item_id() {
            0 => RemoveTlcFulfill::new_unchecked(inner).into(),
            1 => TlcErrPacket::new_unchecked(inner).into(),
            _ => panic!("{}: invalid data", Self::NAME),
        }
    }
    pub fn as_reader<'r>(&'r self) -> RemoveTlcReasonReader<'r> {
        RemoveTlcReasonReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for RemoveTlcReason {
    type Builder = RemoveTlcReasonBuilder;
    const NAME: &'static str = "RemoveTlcReason";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        RemoveTlcReason(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        RemoveTlcReasonReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        RemoveTlcReasonReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_enum())
    }
}
#[derive(Clone, Copy)]
pub struct RemoveTlcReasonReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for RemoveTlcReasonReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for RemoveTlcReasonReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for RemoveTlcReasonReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}(", Self::NAME)?;
        self.to_enum().display_inner(f)?;
        write!(f, ")")
    }
}
impl<'r> RemoveTlcReasonReader<'r> {
    pub const ITEMS_COUNT: usize = 2;
    pub fn item_id(&self) -> molecule::Number {
        molecule::unpack_number(self.as_slice())
    }
    pub fn to_enum(&self) -> RemoveTlcReasonUnionReader<'r> {
        let inner = &self.as_slice()[molecule::NUMBER_SIZE..];
        match self.item_id() {
            0 => RemoveTlcFulfillReader::new_unchecked(inner).into(),
            1 => TlcErrPacketReader::new_unchecked(inner).into(),
            _ => panic!("{}: invalid data", Self::NAME),
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for RemoveTlcReasonReader<'r> {
    type Entity = RemoveTlcReason;
    const NAME: &'static str = "RemoveTlcReasonReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        RemoveTlcReasonReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let item_id = molecule::unpack_number(slice);
        let inner_slice = &slice[molecule::NUMBER_SIZE..];
        match item_id {
            0 => RemoveTlcFulfillReader::verify(inner_slice, compatible),
            1 => TlcErrPacketReader::verify(inner_slice, compatible),
            _ => ve!(Self, UnknownItem, Self::ITEMS_COUNT, item_id),
        }?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct RemoveTlcReasonBuilder(pub(crate) RemoveTlcReasonUnion);
impl RemoveTlcReasonBuilder {
    pub const ITEMS_COUNT: usize = 2;
    pub fn set<I>(mut self, v: I) -> Self
    where
        I: ::core::convert::Into<RemoveTlcReasonUnion>,
    {
        self.0 = v.into();
        self
    }
}
impl molecule::prelude::Builder for RemoveTlcReasonBuilder {
    type Entity = RemoveTlcReason;
    const NAME: &'static str = "RemoveTlcReasonBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE + self.0.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(&molecule::pack_number(self.0.item_id()))?;
        writer.write_all(self.0.as_slice())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        RemoveTlcReason::new_unchecked(inner.into())
    }
}
#[derive(Debug, Clone)]
pub enum RemoveTlcReasonUnion {
    RemoveTlcFulfill(RemoveTlcFulfill),
    TlcErrPacket(TlcErrPacket),
}
#[derive(Debug, Clone, Copy)]
pub enum RemoveTlcReasonUnionReader<'r> {
    RemoveTlcFulfill(RemoveTlcFulfillReader<'r>),
    TlcErrPacket(TlcErrPacketReader<'r>),
}
impl ::core::default::Default for RemoveTlcReasonUnion {
    fn default() -> Self {
        RemoveTlcReasonUnion::RemoveTlcFulfill(::core::default::Default::default())
    }
}
impl ::core::fmt::Display for RemoveTlcReasonUnion {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            RemoveTlcReasonUnion::RemoveTlcFulfill(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, RemoveTlcFulfill::NAME, item)
            }
            RemoveTlcReasonUnion::TlcErrPacket(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, TlcErrPacket::NAME, item)
            }
        }
    }
}
impl<'r> ::core::fmt::Display for RemoveTlcReasonUnionReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            RemoveTlcReasonUnionReader::RemoveTlcFulfill(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, RemoveTlcFulfill::NAME, item)
            }
            RemoveTlcReasonUnionReader::TlcErrPacket(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, TlcErrPacket::NAME, item)
            }
        }
    }
}
impl RemoveTlcReasonUnion {
    pub(crate) fn display_inner(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            RemoveTlcReasonUnion::RemoveTlcFulfill(ref item) => write!(f, "{}", item),
            RemoveTlcReasonUnion::TlcErrPacket(ref item) => write!(f, "{}", item),
        }
    }
}
impl<'r> RemoveTlcReasonUnionReader<'r> {
    pub(crate) fn display_inner(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            RemoveTlcReasonUnionReader::RemoveTlcFulfill(ref item) => write!(f, "{}", item),
            RemoveTlcReasonUnionReader::TlcErrPacket(ref item) => write!(f, "{}", item),
        }
    }
}
impl ::core::convert::From<RemoveTlcFulfill> for RemoveTlcReasonUnion {
    fn from(item: RemoveTlcFulfill) -> Self {
        RemoveTlcReasonUnion::RemoveTlcFulfill(item)
    }
}
impl ::core::convert::From<TlcErrPacket> for RemoveTlcReasonUnion {
    fn from(item: TlcErrPacket) -> Self {
        RemoveTlcReasonUnion::TlcErrPacket(item)
    }
}
impl<'r> ::core::convert::From<RemoveTlcFulfillReader<'r>> for RemoveTlcReasonUnionReader<'r> {
    fn from(item: RemoveTlcFulfillReader<'r>) -> Self {
        RemoveTlcReasonUnionReader::RemoveTlcFulfill(item)
    }
}
impl<'r> ::core::convert::From<TlcErrPacketReader<'r>> for RemoveTlcReasonUnionReader<'r> {
    fn from(item: TlcErrPacketReader<'r>) -> Self {
        RemoveTlcReasonUnionReader::TlcErrPacket(item)
    }
}
impl RemoveTlcReasonUnion {
    pub const NAME: &'static str = "RemoveTlcReasonUnion";
    pub fn as_bytes(&self) -> molecule::bytes::Bytes {
        match self {
            RemoveTlcReasonUnion::RemoveTlcFulfill(item) => item.as_bytes(),
            RemoveTlcReasonUnion::TlcErrPacket(item) => item.as_bytes(),
        }
    }
    pub fn as_slice(&self) -> &[u8] {
        match self {
            RemoveTlcReasonUnion::RemoveTlcFulfill(item) => item.as_slice(),
            RemoveTlcReasonUnion::TlcErrPacket(item) => item.as_slice(),
        }
    }
    pub fn item_id(&self) -> molecule::Number {
        match self {
            RemoveTlcReasonUnion::RemoveTlcFulfill(_) => 0,
            RemoveTlcReasonUnion::TlcErrPacket(_) => 1,
        }
    }
    pub fn item_name(&self) -> &str {
        match self {
            RemoveTlcReasonUnion::RemoveTlcFulfill(_) => "RemoveTlcFulfill",
            RemoveTlcReasonUnion::TlcErrPacket(_) => "TlcErrPacket",
        }
    }
    pub fn as_reader<'r>(&'r self) -> RemoveTlcReasonUnionReader<'r> {
        match self {
            RemoveTlcReasonUnion::RemoveTlcFulfill(item) => item.as_reader().into(),
            RemoveTlcReasonUnion::TlcErrPacket(item) => item.as_reader().into(),
        }
    }
}
impl<'r> RemoveTlcReasonUnionReader<'r> {
    pub const NAME: &'r str = "RemoveTlcReasonUnionReader";
    pub fn as_slice(&self) -> &'r [u8] {
        match self {
            RemoveTlcReasonUnionReader::RemoveTlcFulfill(item) => item.as_slice(),
            RemoveTlcReasonUnionReader::TlcErrPacket(item) => item.as_slice(),
        }
    }
    pub fn item_id(&self) -> molecule::Number {
        match self {
            RemoveTlcReasonUnionReader::RemoveTlcFulfill(_) => 0,
            RemoveTlcReasonUnionReader::TlcErrPacket(_) => 1,
        }
    }
    pub fn item_name(&self) -> &str {
        match self {
            RemoveTlcReasonUnionReader::RemoveTlcFulfill(_) => "RemoveTlcFulfill",
            RemoveTlcReasonUnionReader::TlcErrPacket(_) => "TlcErrPacket",
        }
    }
}
impl From<RemoveTlcFulfill> for RemoveTlcReason {
    fn from(value: RemoveTlcFulfill) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<TlcErrPacket> for RemoveTlcReason {
    fn from(value: TlcErrPacket) -> Self {
        Self::new_builder().set(value).build()
    }
}
#[derive(Clone)]
pub struct RemoveTlc(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for RemoveTlc {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for RemoveTlc {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for RemoveTlc {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "tlc_id", self.tlc_id())?;
        write!(f, ", {}: {}", "reason", self.reason())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for RemoveTlc {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        RemoveTlc::new_unchecked(v)
    }
}
impl RemoveTlc {
    const DEFAULT_VALUE: [u8; 92] = [
        92, 0, 0, 0, 16, 0, 0, 0, 48, 0, 0, 0, 56, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn tlc_id(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn reason(&self) -> RemoveTlcReason {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            RemoveTlcReason::new_unchecked(self.0.slice(start..end))
        } else {
            RemoveTlcReason::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> RemoveTlcReader<'r> {
        RemoveTlcReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for RemoveTlc {
    type Builder = RemoveTlcBuilder;
    const NAME: &'static str = "RemoveTlc";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        RemoveTlc(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        RemoveTlcReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        RemoveTlcReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_id(self.channel_id())
            .tlc_id(self.tlc_id())
            .reason(self.reason())
    }
}
#[derive(Clone, Copy)]
pub struct RemoveTlcReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for RemoveTlcReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for RemoveTlcReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for RemoveTlcReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "tlc_id", self.tlc_id())?;
        write!(f, ", {}: {}", "reason", self.reason())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> RemoveTlcReader<'r> {
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn tlc_id(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn reason(&self) -> RemoveTlcReasonReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            RemoveTlcReasonReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            RemoveTlcReasonReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for RemoveTlcReader<'r> {
    type Entity = RemoveTlc;
    const NAME: &'static str = "RemoveTlcReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        RemoveTlcReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Byte32Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Uint64Reader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        RemoveTlcReasonReader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct RemoveTlcBuilder {
    pub(crate) channel_id: Byte32,
    pub(crate) tlc_id: Uint64,
    pub(crate) reason: RemoveTlcReason,
}
impl RemoveTlcBuilder {
    pub const FIELD_COUNT: usize = 3;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
    pub fn tlc_id(mut self, v: Uint64) -> Self {
        self.tlc_id = v;
        self
    }
    pub fn reason(mut self, v: RemoveTlcReason) -> Self {
        self.reason = v;
        self
    }
}
impl molecule::prelude::Builder for RemoveTlcBuilder {
    type Entity = RemoveTlc;
    const NAME: &'static str = "RemoveTlcBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.channel_id.as_slice().len()
            + self.tlc_id.as_slice().len()
            + self.reason.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.channel_id.as_slice().len();
        offsets.push(total_size);
        total_size += self.tlc_id.as_slice().len();
        offsets.push(total_size);
        total_size += self.reason.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.channel_id.as_slice())?;
        writer.write_all(self.tlc_id.as_slice())?;
        writer.write_all(self.reason.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        RemoveTlc::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct ReestablishChannel(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for ReestablishChannel {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for ReestablishChannel {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for ReestablishChannel {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(
            f,
            ", {}: {}",
            "local_commitment_number",
            self.local_commitment_number()
        )?;
        write!(
            f,
            ", {}: {}",
            "remote_commitment_number",
            self.remote_commitment_number()
        )?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for ReestablishChannel {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        ReestablishChannel::new_unchecked(v)
    }
}
impl ReestablishChannel {
    const DEFAULT_VALUE: [u8; 64] = [
        64, 0, 0, 0, 16, 0, 0, 0, 48, 0, 0, 0, 56, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn local_commitment_number(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn remote_commitment_number(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            Uint64::new_unchecked(self.0.slice(start..end))
        } else {
            Uint64::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> ReestablishChannelReader<'r> {
        ReestablishChannelReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for ReestablishChannel {
    type Builder = ReestablishChannelBuilder;
    const NAME: &'static str = "ReestablishChannel";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        ReestablishChannel(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ReestablishChannelReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ReestablishChannelReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_id(self.channel_id())
            .local_commitment_number(self.local_commitment_number())
            .remote_commitment_number(self.remote_commitment_number())
    }
}
#[derive(Clone, Copy)]
pub struct ReestablishChannelReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for ReestablishChannelReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for ReestablishChannelReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for ReestablishChannelReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(
            f,
            ", {}: {}",
            "local_commitment_number",
            self.local_commitment_number()
        )?;
        write!(
            f,
            ", {}: {}",
            "remote_commitment_number",
            self.remote_commitment_number()
        )?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> ReestablishChannelReader<'r> {
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn local_commitment_number(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn remote_commitment_number(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            Uint64Reader::new_unchecked(&self.as_slice()[start..end])
        } else {
            Uint64Reader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for ReestablishChannelReader<'r> {
    type Entity = ReestablishChannel;
    const NAME: &'static str = "ReestablishChannelReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        ReestablishChannelReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Byte32Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Uint64Reader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        Uint64Reader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct ReestablishChannelBuilder {
    pub(crate) channel_id: Byte32,
    pub(crate) local_commitment_number: Uint64,
    pub(crate) remote_commitment_number: Uint64,
}
impl ReestablishChannelBuilder {
    pub const FIELD_COUNT: usize = 3;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
    pub fn local_commitment_number(mut self, v: Uint64) -> Self {
        self.local_commitment_number = v;
        self
    }
    pub fn remote_commitment_number(mut self, v: Uint64) -> Self {
        self.remote_commitment_number = v;
        self
    }
}
impl molecule::prelude::Builder for ReestablishChannelBuilder {
    type Entity = ReestablishChannel;
    const NAME: &'static str = "ReestablishChannelBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.channel_id.as_slice().len()
            + self.local_commitment_number.as_slice().len()
            + self.remote_commitment_number.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.channel_id.as_slice().len();
        offsets.push(total_size);
        total_size += self.local_commitment_number.as_slice().len();
        offsets.push(total_size);
        total_size += self.remote_commitment_number.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.channel_id.as_slice())?;
        writer.write_all(self.local_commitment_number.as_slice())?;
        writer.write_all(self.remote_commitment_number.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        ReestablishChannel::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct AnnouncementSignatures(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for AnnouncementSignatures {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for AnnouncementSignatures {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for AnnouncementSignatures {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "channel_outpoint", self.channel_outpoint())?;
        write!(f, ", {}: {}", "node_signature", self.node_signature())?;
        write!(f, ", {}: {}", "partial_signature", self.partial_signature())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for AnnouncementSignatures {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        AnnouncementSignatures::new_unchecked(v)
    }
}
impl AnnouncementSignatures {
    const DEFAULT_VALUE: [u8; 184] = [
        184, 0, 0, 0, 20, 0, 0, 0, 52, 0, 0, 0, 88, 0, 0, 0, 152, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 4;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn channel_outpoint(&self) -> OutPoint {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        OutPoint::new_unchecked(self.0.slice(start..end))
    }
    pub fn node_signature(&self) -> EcdsaSignature {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        EcdsaSignature::new_unchecked(self.0.slice(start..end))
    }
    pub fn partial_signature(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[20..]) as usize;
            Byte32::new_unchecked(self.0.slice(start..end))
        } else {
            Byte32::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> AnnouncementSignaturesReader<'r> {
        AnnouncementSignaturesReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for AnnouncementSignatures {
    type Builder = AnnouncementSignaturesBuilder;
    const NAME: &'static str = "AnnouncementSignatures";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        AnnouncementSignatures(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        AnnouncementSignaturesReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        AnnouncementSignaturesReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_id(self.channel_id())
            .channel_outpoint(self.channel_outpoint())
            .node_signature(self.node_signature())
            .partial_signature(self.partial_signature())
    }
}
#[derive(Clone, Copy)]
pub struct AnnouncementSignaturesReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for AnnouncementSignaturesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for AnnouncementSignaturesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for AnnouncementSignaturesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_id", self.channel_id())?;
        write!(f, ", {}: {}", "channel_outpoint", self.channel_outpoint())?;
        write!(f, ", {}: {}", "node_signature", self.node_signature())?;
        write!(f, ", {}: {}", "partial_signature", self.partial_signature())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> AnnouncementSignaturesReader<'r> {
    pub const FIELD_COUNT: usize = 4;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_id(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn channel_outpoint(&self) -> OutPointReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        OutPointReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn node_signature(&self) -> EcdsaSignatureReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        EcdsaSignatureReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn partial_signature(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[20..]) as usize;
            Byte32Reader::new_unchecked(&self.as_slice()[start..end])
        } else {
            Byte32Reader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for AnnouncementSignaturesReader<'r> {
    type Entity = AnnouncementSignatures;
    const NAME: &'static str = "AnnouncementSignaturesReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        AnnouncementSignaturesReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Byte32Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        OutPointReader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        EcdsaSignatureReader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        Byte32Reader::verify(&slice[offsets[3]..offsets[4]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct AnnouncementSignaturesBuilder {
    pub(crate) channel_id: Byte32,
    pub(crate) channel_outpoint: OutPoint,
    pub(crate) node_signature: EcdsaSignature,
    pub(crate) partial_signature: Byte32,
}
impl AnnouncementSignaturesBuilder {
    pub const FIELD_COUNT: usize = 4;
    pub fn channel_id(mut self, v: Byte32) -> Self {
        self.channel_id = v;
        self
    }
    pub fn channel_outpoint(mut self, v: OutPoint) -> Self {
        self.channel_outpoint = v;
        self
    }
    pub fn node_signature(mut self, v: EcdsaSignature) -> Self {
        self.node_signature = v;
        self
    }
    pub fn partial_signature(mut self, v: Byte32) -> Self {
        self.partial_signature = v;
        self
    }
}
impl molecule::prelude::Builder for AnnouncementSignaturesBuilder {
    type Entity = AnnouncementSignatures;
    const NAME: &'static str = "AnnouncementSignaturesBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.channel_id.as_slice().len()
            + self.channel_outpoint.as_slice().len()
            + self.node_signature.as_slice().len()
            + self.partial_signature.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.channel_id.as_slice().len();
        offsets.push(total_size);
        total_size += self.channel_outpoint.as_slice().len();
        offsets.push(total_size);
        total_size += self.node_signature.as_slice().len();
        offsets.push(total_size);
        total_size += self.partial_signature.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.channel_id.as_slice())?;
        writer.write_all(self.channel_outpoint.as_slice())?;
        writer.write_all(self.node_signature.as_slice())?;
        writer.write_all(self.partial_signature.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        AnnouncementSignatures::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct UdtCellDep(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for UdtCellDep {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for UdtCellDep {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for UdtCellDep {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "dep_type", self.dep_type())?;
        write!(f, ", {}: {}", "tx_hash", self.tx_hash())?;
        write!(f, ", {}: {}", "index", self.index())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for UdtCellDep {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        UdtCellDep::new_unchecked(v)
    }
}
impl UdtCellDep {
    const DEFAULT_VALUE: [u8; 53] = [
        53, 0, 0, 0, 16, 0, 0, 0, 17, 0, 0, 0, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn dep_type(&self) -> Byte {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte::new_unchecked(self.0.slice(start..end))
    }
    pub fn tx_hash(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn index(&self) -> Uint32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            Uint32::new_unchecked(self.0.slice(start..end))
        } else {
            Uint32::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> UdtCellDepReader<'r> {
        UdtCellDepReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for UdtCellDep {
    type Builder = UdtCellDepBuilder;
    const NAME: &'static str = "UdtCellDep";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        UdtCellDep(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        UdtCellDepReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        UdtCellDepReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .dep_type(self.dep_type())
            .tx_hash(self.tx_hash())
            .index(self.index())
    }
}
#[derive(Clone, Copy)]
pub struct UdtCellDepReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for UdtCellDepReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for UdtCellDepReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for UdtCellDepReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "dep_type", self.dep_type())?;
        write!(f, ", {}: {}", "tx_hash", self.tx_hash())?;
        write!(f, ", {}: {}", "index", self.index())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> UdtCellDepReader<'r> {
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn dep_type(&self) -> ByteReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        ByteReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn tx_hash(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn index(&self) -> Uint32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            Uint32Reader::new_unchecked(&self.as_slice()[start..end])
        } else {
            Uint32Reader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for UdtCellDepReader<'r> {
    type Entity = UdtCellDep;
    const NAME: &'static str = "UdtCellDepReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        UdtCellDepReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        ByteReader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Byte32Reader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        Uint32Reader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct UdtCellDepBuilder {
    pub(crate) dep_type: Byte,
    pub(crate) tx_hash: Byte32,
    pub(crate) index: Uint32,
}
impl UdtCellDepBuilder {
    pub const FIELD_COUNT: usize = 3;
    pub fn dep_type(mut self, v: Byte) -> Self {
        self.dep_type = v;
        self
    }
    pub fn tx_hash(mut self, v: Byte32) -> Self {
        self.tx_hash = v;
        self
    }
    pub fn index(mut self, v: Uint32) -> Self {
        self.index = v;
        self
    }
}
impl molecule::prelude::Builder for UdtCellDepBuilder {
    type Entity = UdtCellDep;
    const NAME: &'static str = "UdtCellDepBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.dep_type.as_slice().len()
            + self.tx_hash.as_slice().len()
            + self.index.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.dep_type.as_slice().len();
        offsets.push(total_size);
        total_size += self.tx_hash.as_slice().len();
        offsets.push(total_size);
        total_size += self.index.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.dep_type.as_slice())?;
        writer.write_all(self.tx_hash.as_slice())?;
        writer.write_all(self.index.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        UdtCellDep::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct UdtScript(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for UdtScript {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for UdtScript {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for UdtScript {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "code_hash", self.code_hash())?;
        write!(f, ", {}: {}", "hash_type", self.hash_type())?;
        write!(f, ", {}: {}", "args", self.args())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for UdtScript {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        UdtScript::new_unchecked(v)
    }
}
impl UdtScript {
    const DEFAULT_VALUE: [u8; 53] = [
        53, 0, 0, 0, 16, 0, 0, 0, 48, 0, 0, 0, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn code_hash(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn hash_type(&self) -> Byte {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Byte::new_unchecked(self.0.slice(start..end))
    }
    pub fn args(&self) -> Bytes {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            Bytes::new_unchecked(self.0.slice(start..end))
        } else {
            Bytes::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> UdtScriptReader<'r> {
        UdtScriptReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for UdtScript {
    type Builder = UdtScriptBuilder;
    const NAME: &'static str = "UdtScript";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        UdtScript(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        UdtScriptReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        UdtScriptReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .code_hash(self.code_hash())
            .hash_type(self.hash_type())
            .args(self.args())
    }
}
#[derive(Clone, Copy)]
pub struct UdtScriptReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for UdtScriptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for UdtScriptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for UdtScriptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "code_hash", self.code_hash())?;
        write!(f, ", {}: {}", "hash_type", self.hash_type())?;
        write!(f, ", {}: {}", "args", self.args())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> UdtScriptReader<'r> {
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn code_hash(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn hash_type(&self) -> ByteReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        ByteReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn args(&self) -> BytesReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            BytesReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            BytesReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for UdtScriptReader<'r> {
    type Entity = UdtScript;
    const NAME: &'static str = "UdtScriptReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        UdtScriptReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Byte32Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        ByteReader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        BytesReader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct UdtScriptBuilder {
    pub(crate) code_hash: Byte32,
    pub(crate) hash_type: Byte,
    pub(crate) args: Bytes,
}
impl UdtScriptBuilder {
    pub const FIELD_COUNT: usize = 3;
    pub fn code_hash(mut self, v: Byte32) -> Self {
        self.code_hash = v;
        self
    }
    pub fn hash_type(mut self, v: Byte) -> Self {
        self.hash_type = v;
        self
    }
    pub fn args(mut self, v: Bytes) -> Self {
        self.args = v;
        self
    }
}
impl molecule::prelude::Builder for UdtScriptBuilder {
    type Entity = UdtScript;
    const NAME: &'static str = "UdtScriptBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.code_hash.as_slice().len()
            + self.hash_type.as_slice().len()
            + self.args.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.code_hash.as_slice().len();
        offsets.push(total_size);
        total_size += self.hash_type.as_slice().len();
        offsets.push(total_size);
        total_size += self.args.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.code_hash.as_slice())?;
        writer.write_all(self.hash_type.as_slice())?;
        writer.write_all(self.args.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        UdtScript::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct UdtCellDeps(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for UdtCellDeps {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for UdtCellDeps {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for UdtCellDeps {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} [", Self::NAME)?;
        for i in 0..self.len() {
            if i == 0 {
                write!(f, "{}", self.get_unchecked(i))?;
            } else {
                write!(f, ", {}", self.get_unchecked(i))?;
            }
        }
        write!(f, "]")
    }
}
impl ::core::default::Default for UdtCellDeps {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        UdtCellDeps::new_unchecked(v)
    }
}
impl UdtCellDeps {
    const DEFAULT_VALUE: [u8; 4] = [4, 0, 0, 0];
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn item_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn len(&self) -> usize {
        self.item_count()
    }
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
    pub fn get(&self, idx: usize) -> Option<UdtCellDep> {
        if idx >= self.len() {
            None
        } else {
            Some(self.get_unchecked(idx))
        }
    }
    pub fn get_unchecked(&self, idx: usize) -> UdtCellDep {
        let slice = self.as_slice();
        let start_idx = molecule::NUMBER_SIZE * (1 + idx);
        let start = molecule::unpack_number(&slice[start_idx..]) as usize;
        if idx == self.len() - 1 {
            UdtCellDep::new_unchecked(self.0.slice(start..))
        } else {
            let end_idx = start_idx + molecule::NUMBER_SIZE;
            let end = molecule::unpack_number(&slice[end_idx..]) as usize;
            UdtCellDep::new_unchecked(self.0.slice(start..end))
        }
    }
    pub fn as_reader<'r>(&'r self) -> UdtCellDepsReader<'r> {
        UdtCellDepsReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for UdtCellDeps {
    type Builder = UdtCellDepsBuilder;
    const NAME: &'static str = "UdtCellDeps";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        UdtCellDeps(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        UdtCellDepsReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        UdtCellDepsReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().extend(self.into_iter())
    }
}
#[derive(Clone, Copy)]
pub struct UdtCellDepsReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for UdtCellDepsReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for UdtCellDepsReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for UdtCellDepsReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} [", Self::NAME)?;
        for i in 0..self.len() {
            if i == 0 {
                write!(f, "{}", self.get_unchecked(i))?;
            } else {
                write!(f, ", {}", self.get_unchecked(i))?;
            }
        }
        write!(f, "]")
    }
}
impl<'r> UdtCellDepsReader<'r> {
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn item_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn len(&self) -> usize {
        self.item_count()
    }
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
    pub fn get(&self, idx: usize) -> Option<UdtCellDepReader<'r>> {
        if idx >= self.len() {
            None
        } else {
            Some(self.get_unchecked(idx))
        }
    }
    pub fn get_unchecked(&self, idx: usize) -> UdtCellDepReader<'r> {
        let slice = self.as_slice();
        let start_idx = molecule::NUMBER_SIZE * (1 + idx);
        let start = molecule::unpack_number(&slice[start_idx..]) as usize;
        if idx == self.len() - 1 {
            UdtCellDepReader::new_unchecked(&self.as_slice()[start..])
        } else {
            let end_idx = start_idx + molecule::NUMBER_SIZE;
            let end = molecule::unpack_number(&slice[end_idx..]) as usize;
            UdtCellDepReader::new_unchecked(&self.as_slice()[start..end])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for UdtCellDepsReader<'r> {
    type Entity = UdtCellDeps;
    const NAME: &'static str = "UdtCellDepsReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        UdtCellDepsReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len == molecule::NUMBER_SIZE {
            return Ok(());
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(
                Self,
                TotalSizeNotMatch,
                molecule::NUMBER_SIZE * 2,
                slice_len
            );
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        for pair in offsets.windows(2) {
            let start = pair[0];
            let end = pair[1];
            UdtCellDepReader::verify(&slice[start..end], compatible)?;
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct UdtCellDepsBuilder(pub(crate) Vec<UdtCellDep>);
impl UdtCellDepsBuilder {
    pub fn set(mut self, v: Vec<UdtCellDep>) -> Self {
        self.0 = v;
        self
    }
    pub fn push(mut self, v: UdtCellDep) -> Self {
        self.0.push(v);
        self
    }
    pub fn extend<T: ::core::iter::IntoIterator<Item = UdtCellDep>>(mut self, iter: T) -> Self {
        for elem in iter {
            self.0.push(elem);
        }
        self
    }
    pub fn replace(&mut self, index: usize, v: UdtCellDep) -> Option<UdtCellDep> {
        self.0
            .get_mut(index)
            .map(|item| ::core::mem::replace(item, v))
    }
}
impl molecule::prelude::Builder for UdtCellDepsBuilder {
    type Entity = UdtCellDeps;
    const NAME: &'static str = "UdtCellDepsBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (self.0.len() + 1)
            + self
                .0
                .iter()
                .map(|inner| inner.as_slice().len())
                .sum::<usize>()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let item_count = self.0.len();
        if item_count == 0 {
            writer.write_all(&molecule::pack_number(
                molecule::NUMBER_SIZE as molecule::Number,
            ))?;
        } else {
            let (total_size, offsets) = self.0.iter().fold(
                (
                    molecule::NUMBER_SIZE * (item_count + 1),
                    Vec::with_capacity(item_count),
                ),
                |(start, mut offsets), inner| {
                    offsets.push(start);
                    (start + inner.as_slice().len(), offsets)
                },
            );
            writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
            for offset in offsets.into_iter() {
                writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
            }
            for inner in self.0.iter() {
                writer.write_all(inner.as_slice())?;
            }
        }
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        UdtCellDeps::new_unchecked(inner.into())
    }
}
pub struct UdtCellDepsIterator(UdtCellDeps, usize, usize);
impl ::core::iter::Iterator for UdtCellDepsIterator {
    type Item = UdtCellDep;
    fn next(&mut self) -> Option<Self::Item> {
        if self.1 >= self.2 {
            None
        } else {
            let ret = self.0.get_unchecked(self.1);
            self.1 += 1;
            Some(ret)
        }
    }
}
impl ::core::iter::ExactSizeIterator for UdtCellDepsIterator {
    fn len(&self) -> usize {
        self.2 - self.1
    }
}
impl ::core::iter::IntoIterator for UdtCellDeps {
    type Item = UdtCellDep;
    type IntoIter = UdtCellDepsIterator;
    fn into_iter(self) -> Self::IntoIter {
        let len = self.len();
        UdtCellDepsIterator(self, 0, len)
    }
}
impl<'r> UdtCellDepsReader<'r> {
    pub fn iter<'t>(&'t self) -> UdtCellDepsReaderIterator<'t, 'r> {
        UdtCellDepsReaderIterator(&self, 0, self.len())
    }
}
pub struct UdtCellDepsReaderIterator<'t, 'r>(&'t UdtCellDepsReader<'r>, usize, usize);
impl<'t: 'r, 'r> ::core::iter::Iterator for UdtCellDepsReaderIterator<'t, 'r> {
    type Item = UdtCellDepReader<'t>;
    fn next(&mut self) -> Option<Self::Item> {
        if self.1 >= self.2 {
            None
        } else {
            let ret = self.0.get_unchecked(self.1);
            self.1 += 1;
            Some(ret)
        }
    }
}
impl<'t: 'r, 'r> ::core::iter::ExactSizeIterator for UdtCellDepsReaderIterator<'t, 'r> {
    fn len(&self) -> usize {
        self.2 - self.1
    }
}
impl ::core::iter::FromIterator<UdtCellDep> for UdtCellDeps {
    fn from_iter<T: IntoIterator<Item = UdtCellDep>>(iter: T) -> Self {
        Self::new_builder().extend(iter).build()
    }
}
#[derive(Clone)]
pub struct UdtArgInfo(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for UdtArgInfo {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for UdtArgInfo {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for UdtArgInfo {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "name", self.name())?;
        write!(f, ", {}: {}", "script", self.script())?;
        write!(
            f,
            ", {}: {}",
            "auto_accept_amount",
            self.auto_accept_amount()
        )?;
        write!(f, ", {}: {}", "cell_deps", self.cell_deps())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for UdtArgInfo {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        UdtArgInfo::new_unchecked(v)
    }
}
impl UdtArgInfo {
    const DEFAULT_VALUE: [u8; 81] = [
        81, 0, 0, 0, 20, 0, 0, 0, 24, 0, 0, 0, 77, 0, 0, 0, 77, 0, 0, 0, 0, 0, 0, 0, 53, 0, 0, 0,
        16, 0, 0, 0, 48, 0, 0, 0, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 4;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn name(&self) -> Bytes {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Bytes::new_unchecked(self.0.slice(start..end))
    }
    pub fn script(&self) -> UdtScript {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        UdtScript::new_unchecked(self.0.slice(start..end))
    }
    pub fn auto_accept_amount(&self) -> Uint128Opt {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        Uint128Opt::new_unchecked(self.0.slice(start..end))
    }
    pub fn cell_deps(&self) -> UdtCellDeps {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[20..]) as usize;
            UdtCellDeps::new_unchecked(self.0.slice(start..end))
        } else {
            UdtCellDeps::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> UdtArgInfoReader<'r> {
        UdtArgInfoReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for UdtArgInfo {
    type Builder = UdtArgInfoBuilder;
    const NAME: &'static str = "UdtArgInfo";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        UdtArgInfo(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        UdtArgInfoReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        UdtArgInfoReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .name(self.name())
            .script(self.script())
            .auto_accept_amount(self.auto_accept_amount())
            .cell_deps(self.cell_deps())
    }
}
#[derive(Clone, Copy)]
pub struct UdtArgInfoReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for UdtArgInfoReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for UdtArgInfoReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for UdtArgInfoReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "name", self.name())?;
        write!(f, ", {}: {}", "script", self.script())?;
        write!(
            f,
            ", {}: {}",
            "auto_accept_amount",
            self.auto_accept_amount()
        )?;
        write!(f, ", {}: {}", "cell_deps", self.cell_deps())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> UdtArgInfoReader<'r> {
    pub const FIELD_COUNT: usize = 4;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn name(&self) -> BytesReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        BytesReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn script(&self) -> UdtScriptReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        UdtScriptReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn auto_accept_amount(&self) -> Uint128OptReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        Uint128OptReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn cell_deps(&self) -> UdtCellDepsReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[20..]) as usize;
            UdtCellDepsReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            UdtCellDepsReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for UdtArgInfoReader<'r> {
    type Entity = UdtArgInfo;
    const NAME: &'static str = "UdtArgInfoReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        UdtArgInfoReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        BytesReader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        UdtScriptReader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        Uint128OptReader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        UdtCellDepsReader::verify(&slice[offsets[3]..offsets[4]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct UdtArgInfoBuilder {
    pub(crate) name: Bytes,
    pub(crate) script: UdtScript,
    pub(crate) auto_accept_amount: Uint128Opt,
    pub(crate) cell_deps: UdtCellDeps,
}
impl UdtArgInfoBuilder {
    pub const FIELD_COUNT: usize = 4;
    pub fn name(mut self, v: Bytes) -> Self {
        self.name = v;
        self
    }
    pub fn script(mut self, v: UdtScript) -> Self {
        self.script = v;
        self
    }
    pub fn auto_accept_amount(mut self, v: Uint128Opt) -> Self {
        self.auto_accept_amount = v;
        self
    }
    pub fn cell_deps(mut self, v: UdtCellDeps) -> Self {
        self.cell_deps = v;
        self
    }
}
impl molecule::prelude::Builder for UdtArgInfoBuilder {
    type Entity = UdtArgInfo;
    const NAME: &'static str = "UdtArgInfoBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.name.as_slice().len()
            + self.script.as_slice().len()
            + self.auto_accept_amount.as_slice().len()
            + self.cell_deps.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.name.as_slice().len();
        offsets.push(total_size);
        total_size += self.script.as_slice().len();
        offsets.push(total_size);
        total_size += self.auto_accept_amount.as_slice().len();
        offsets.push(total_size);
        total_size += self.cell_deps.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.name.as_slice())?;
        writer.write_all(self.script.as_slice())?;
        writer.write_all(self.auto_accept_amount.as_slice())?;
        writer.write_all(self.cell_deps.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        UdtArgInfo::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct UdtCfgInfos(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for UdtCfgInfos {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for UdtCfgInfos {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for UdtCfgInfos {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} [", Self::NAME)?;
        for i in 0..self.len() {
            if i == 0 {
                write!(f, "{}", self.get_unchecked(i))?;
            } else {
                write!(f, ", {}", self.get_unchecked(i))?;
            }
        }
        write!(f, "]")
    }
}
impl ::core::default::Default for UdtCfgInfos {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        UdtCfgInfos::new_unchecked(v)
    }
}
impl UdtCfgInfos {
    const DEFAULT_VALUE: [u8; 4] = [4, 0, 0, 0];
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn item_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn len(&self) -> usize {
        self.item_count()
    }
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
    pub fn get(&self, idx: usize) -> Option<UdtArgInfo> {
        if idx >= self.len() {
            None
        } else {
            Some(self.get_unchecked(idx))
        }
    }
    pub fn get_unchecked(&self, idx: usize) -> UdtArgInfo {
        let slice = self.as_slice();
        let start_idx = molecule::NUMBER_SIZE * (1 + idx);
        let start = molecule::unpack_number(&slice[start_idx..]) as usize;
        if idx == self.len() - 1 {
            UdtArgInfo::new_unchecked(self.0.slice(start..))
        } else {
            let end_idx = start_idx + molecule::NUMBER_SIZE;
            let end = molecule::unpack_number(&slice[end_idx..]) as usize;
            UdtArgInfo::new_unchecked(self.0.slice(start..end))
        }
    }
    pub fn as_reader<'r>(&'r self) -> UdtCfgInfosReader<'r> {
        UdtCfgInfosReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for UdtCfgInfos {
    type Builder = UdtCfgInfosBuilder;
    const NAME: &'static str = "UdtCfgInfos";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        UdtCfgInfos(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        UdtCfgInfosReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        UdtCfgInfosReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().extend(self.into_iter())
    }
}
#[derive(Clone, Copy)]
pub struct UdtCfgInfosReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for UdtCfgInfosReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for UdtCfgInfosReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for UdtCfgInfosReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} [", Self::NAME)?;
        for i in 0..self.len() {
            if i == 0 {
                write!(f, "{}", self.get_unchecked(i))?;
            } else {
                write!(f, ", {}", self.get_unchecked(i))?;
            }
        }
        write!(f, "]")
    }
}
impl<'r> UdtCfgInfosReader<'r> {
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn item_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn len(&self) -> usize {
        self.item_count()
    }
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
    pub fn get(&self, idx: usize) -> Option<UdtArgInfoReader<'r>> {
        if idx >= self.len() {
            None
        } else {
            Some(self.get_unchecked(idx))
        }
    }
    pub fn get_unchecked(&self, idx: usize) -> UdtArgInfoReader<'r> {
        let slice = self.as_slice();
        let start_idx = molecule::NUMBER_SIZE * (1 + idx);
        let start = molecule::unpack_number(&slice[start_idx..]) as usize;
        if idx == self.len() - 1 {
            UdtArgInfoReader::new_unchecked(&self.as_slice()[start..])
        } else {
            let end_idx = start_idx + molecule::NUMBER_SIZE;
            let end = molecule::unpack_number(&slice[end_idx..]) as usize;
            UdtArgInfoReader::new_unchecked(&self.as_slice()[start..end])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for UdtCfgInfosReader<'r> {
    type Entity = UdtCfgInfos;
    const NAME: &'static str = "UdtCfgInfosReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        UdtCfgInfosReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len == molecule::NUMBER_SIZE {
            return Ok(());
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(
                Self,
                TotalSizeNotMatch,
                molecule::NUMBER_SIZE * 2,
                slice_len
            );
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        for pair in offsets.windows(2) {
            let start = pair[0];
            let end = pair[1];
            UdtArgInfoReader::verify(&slice[start..end], compatible)?;
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct UdtCfgInfosBuilder(pub(crate) Vec<UdtArgInfo>);
impl UdtCfgInfosBuilder {
    pub fn set(mut self, v: Vec<UdtArgInfo>) -> Self {
        self.0 = v;
        self
    }
    pub fn push(mut self, v: UdtArgInfo) -> Self {
        self.0.push(v);
        self
    }
    pub fn extend<T: ::core::iter::IntoIterator<Item = UdtArgInfo>>(mut self, iter: T) -> Self {
        for elem in iter {
            self.0.push(elem);
        }
        self
    }
    pub fn replace(&mut self, index: usize, v: UdtArgInfo) -> Option<UdtArgInfo> {
        self.0
            .get_mut(index)
            .map(|item| ::core::mem::replace(item, v))
    }
}
impl molecule::prelude::Builder for UdtCfgInfosBuilder {
    type Entity = UdtCfgInfos;
    const NAME: &'static str = "UdtCfgInfosBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (self.0.len() + 1)
            + self
                .0
                .iter()
                .map(|inner| inner.as_slice().len())
                .sum::<usize>()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let item_count = self.0.len();
        if item_count == 0 {
            writer.write_all(&molecule::pack_number(
                molecule::NUMBER_SIZE as molecule::Number,
            ))?;
        } else {
            let (total_size, offsets) = self.0.iter().fold(
                (
                    molecule::NUMBER_SIZE * (item_count + 1),
                    Vec::with_capacity(item_count),
                ),
                |(start, mut offsets), inner| {
                    offsets.push(start);
                    (start + inner.as_slice().len(), offsets)
                },
            );
            writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
            for offset in offsets.into_iter() {
                writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
            }
            for inner in self.0.iter() {
                writer.write_all(inner.as_slice())?;
            }
        }
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        UdtCfgInfos::new_unchecked(inner.into())
    }
}
pub struct UdtCfgInfosIterator(UdtCfgInfos, usize, usize);
impl ::core::iter::Iterator for UdtCfgInfosIterator {
    type Item = UdtArgInfo;
    fn next(&mut self) -> Option<Self::Item> {
        if self.1 >= self.2 {
            None
        } else {
            let ret = self.0.get_unchecked(self.1);
            self.1 += 1;
            Some(ret)
        }
    }
}
impl ::core::iter::ExactSizeIterator for UdtCfgInfosIterator {
    fn len(&self) -> usize {
        self.2 - self.1
    }
}
impl ::core::iter::IntoIterator for UdtCfgInfos {
    type Item = UdtArgInfo;
    type IntoIter = UdtCfgInfosIterator;
    fn into_iter(self) -> Self::IntoIter {
        let len = self.len();
        UdtCfgInfosIterator(self, 0, len)
    }
}
impl<'r> UdtCfgInfosReader<'r> {
    pub fn iter<'t>(&'t self) -> UdtCfgInfosReaderIterator<'t, 'r> {
        UdtCfgInfosReaderIterator(&self, 0, self.len())
    }
}
pub struct UdtCfgInfosReaderIterator<'t, 'r>(&'t UdtCfgInfosReader<'r>, usize, usize);
impl<'t: 'r, 'r> ::core::iter::Iterator for UdtCfgInfosReaderIterator<'t, 'r> {
    type Item = UdtArgInfoReader<'t>;
    fn next(&mut self) -> Option<Self::Item> {
        if self.1 >= self.2 {
            None
        } else {
            let ret = self.0.get_unchecked(self.1);
            self.1 += 1;
            Some(ret)
        }
    }
}
impl<'t: 'r, 'r> ::core::iter::ExactSizeIterator for UdtCfgInfosReaderIterator<'t, 'r> {
    fn len(&self) -> usize {
        self.2 - self.1
    }
}
impl ::core::iter::FromIterator<UdtArgInfo> for UdtCfgInfos {
    fn from_iter<T: IntoIterator<Item = UdtArgInfo>>(iter: T) -> Self {
        Self::new_builder().extend(iter).build()
    }
}
#[derive(Clone)]
pub struct FiberMessage(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for FiberMessage {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for FiberMessage {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for FiberMessage {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}(", Self::NAME)?;
        self.to_enum().display_inner(f)?;
        write!(f, ")")
    }
}
impl ::core::default::Default for FiberMessage {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        FiberMessage::new_unchecked(v)
    }
}
impl FiberMessage {
    const DEFAULT_VALUE: [u8; 468] = [
        0, 0, 0, 0, 208, 1, 0, 0, 76, 0, 0, 0, 108, 0, 0, 0, 140, 0, 0, 0, 140, 0, 0, 0, 156, 0, 0,
        0, 209, 0, 0, 0, 217, 0, 0, 0, 225, 0, 0, 0, 233, 0, 0, 0, 249, 0, 0, 0, 1, 1, 0, 0, 9, 1,
        0, 0, 42, 1, 0, 0, 75, 1, 0, 0, 108, 1, 0, 0, 141, 1, 0, 0, 141, 1, 0, 0, 207, 1, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 53, 0, 0, 0, 16, 0, 0, 0, 48, 0,
        0, 0, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const ITEMS_COUNT: usize = 18;
    pub fn item_id(&self) -> molecule::Number {
        molecule::unpack_number(self.as_slice())
    }
    pub fn to_enum(&self) -> FiberMessageUnion {
        let inner = self.0.slice(molecule::NUMBER_SIZE..);
        match self.item_id() {
            0 => OpenChannel::new_unchecked(inner).into(),
            1 => AcceptChannel::new_unchecked(inner).into(),
            2 => TxSignatures::new_unchecked(inner).into(),
            3 => TxUpdate::new_unchecked(inner).into(),
            4 => TxComplete::new_unchecked(inner).into(),
            5 => TxAbort::new_unchecked(inner).into(),
            6 => TxInitRBF::new_unchecked(inner).into(),
            7 => TxAckRBF::new_unchecked(inner).into(),
            8 => CommitmentSigned::new_unchecked(inner).into(),
            9 => ChannelReady::new_unchecked(inner).into(),
            10 => UpdateTlcInfo::new_unchecked(inner).into(),
            11 => AddTlc::new_unchecked(inner).into(),
            12 => RemoveTlc::new_unchecked(inner).into(),
            13 => RevokeAndAck::new_unchecked(inner).into(),
            14 => Shutdown::new_unchecked(inner).into(),
            15 => ClosingSigned::new_unchecked(inner).into(),
            16 => ReestablishChannel::new_unchecked(inner).into(),
            17 => AnnouncementSignatures::new_unchecked(inner).into(),
            _ => panic!("{}: invalid data", Self::NAME),
        }
    }
    pub fn as_reader<'r>(&'r self) -> FiberMessageReader<'r> {
        FiberMessageReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for FiberMessage {
    type Builder = FiberMessageBuilder;
    const NAME: &'static str = "FiberMessage";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        FiberMessage(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        FiberMessageReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        FiberMessageReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_enum())
    }
}
#[derive(Clone, Copy)]
pub struct FiberMessageReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for FiberMessageReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for FiberMessageReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for FiberMessageReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}(", Self::NAME)?;
        self.to_enum().display_inner(f)?;
        write!(f, ")")
    }
}
impl<'r> FiberMessageReader<'r> {
    pub const ITEMS_COUNT: usize = 18;
    pub fn item_id(&self) -> molecule::Number {
        molecule::unpack_number(self.as_slice())
    }
    pub fn to_enum(&self) -> FiberMessageUnionReader<'r> {
        let inner = &self.as_slice()[molecule::NUMBER_SIZE..];
        match self.item_id() {
            0 => OpenChannelReader::new_unchecked(inner).into(),
            1 => AcceptChannelReader::new_unchecked(inner).into(),
            2 => TxSignaturesReader::new_unchecked(inner).into(),
            3 => TxUpdateReader::new_unchecked(inner).into(),
            4 => TxCompleteReader::new_unchecked(inner).into(),
            5 => TxAbortReader::new_unchecked(inner).into(),
            6 => TxInitRBFReader::new_unchecked(inner).into(),
            7 => TxAckRBFReader::new_unchecked(inner).into(),
            8 => CommitmentSignedReader::new_unchecked(inner).into(),
            9 => ChannelReadyReader::new_unchecked(inner).into(),
            10 => UpdateTlcInfoReader::new_unchecked(inner).into(),
            11 => AddTlcReader::new_unchecked(inner).into(),
            12 => RemoveTlcReader::new_unchecked(inner).into(),
            13 => RevokeAndAckReader::new_unchecked(inner).into(),
            14 => ShutdownReader::new_unchecked(inner).into(),
            15 => ClosingSignedReader::new_unchecked(inner).into(),
            16 => ReestablishChannelReader::new_unchecked(inner).into(),
            17 => AnnouncementSignaturesReader::new_unchecked(inner).into(),
            _ => panic!("{}: invalid data", Self::NAME),
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for FiberMessageReader<'r> {
    type Entity = FiberMessage;
    const NAME: &'static str = "FiberMessageReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        FiberMessageReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let item_id = molecule::unpack_number(slice);
        let inner_slice = &slice[molecule::NUMBER_SIZE..];
        match item_id {
            0 => OpenChannelReader::verify(inner_slice, compatible),
            1 => AcceptChannelReader::verify(inner_slice, compatible),
            2 => TxSignaturesReader::verify(inner_slice, compatible),
            3 => TxUpdateReader::verify(inner_slice, compatible),
            4 => TxCompleteReader::verify(inner_slice, compatible),
            5 => TxAbortReader::verify(inner_slice, compatible),
            6 => TxInitRBFReader::verify(inner_slice, compatible),
            7 => TxAckRBFReader::verify(inner_slice, compatible),
            8 => CommitmentSignedReader::verify(inner_slice, compatible),
            9 => ChannelReadyReader::verify(inner_slice, compatible),
            10 => UpdateTlcInfoReader::verify(inner_slice, compatible),
            11 => AddTlcReader::verify(inner_slice, compatible),
            12 => RemoveTlcReader::verify(inner_slice, compatible),
            13 => RevokeAndAckReader::verify(inner_slice, compatible),
            14 => ShutdownReader::verify(inner_slice, compatible),
            15 => ClosingSignedReader::verify(inner_slice, compatible),
            16 => ReestablishChannelReader::verify(inner_slice, compatible),
            17 => AnnouncementSignaturesReader::verify(inner_slice, compatible),
            _ => ve!(Self, UnknownItem, Self::ITEMS_COUNT, item_id),
        }?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct FiberMessageBuilder(pub(crate) FiberMessageUnion);
impl FiberMessageBuilder {
    pub const ITEMS_COUNT: usize = 18;
    pub fn set<I>(mut self, v: I) -> Self
    where
        I: ::core::convert::Into<FiberMessageUnion>,
    {
        self.0 = v.into();
        self
    }
}
impl molecule::prelude::Builder for FiberMessageBuilder {
    type Entity = FiberMessage;
    const NAME: &'static str = "FiberMessageBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE + self.0.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(&molecule::pack_number(self.0.item_id()))?;
        writer.write_all(self.0.as_slice())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        FiberMessage::new_unchecked(inner.into())
    }
}
#[derive(Debug, Clone)]
pub enum FiberMessageUnion {
    OpenChannel(OpenChannel),
    AcceptChannel(AcceptChannel),
    TxSignatures(TxSignatures),
    TxUpdate(TxUpdate),
    TxComplete(TxComplete),
    TxAbort(TxAbort),
    TxInitRBF(TxInitRBF),
    TxAckRBF(TxAckRBF),
    CommitmentSigned(CommitmentSigned),
    ChannelReady(ChannelReady),
    UpdateTlcInfo(UpdateTlcInfo),
    AddTlc(AddTlc),
    RemoveTlc(RemoveTlc),
    RevokeAndAck(RevokeAndAck),
    Shutdown(Shutdown),
    ClosingSigned(ClosingSigned),
    ReestablishChannel(ReestablishChannel),
    AnnouncementSignatures(AnnouncementSignatures),
}
#[derive(Debug, Clone, Copy)]
pub enum FiberMessageUnionReader<'r> {
    OpenChannel(OpenChannelReader<'r>),
    AcceptChannel(AcceptChannelReader<'r>),
    TxSignatures(TxSignaturesReader<'r>),
    TxUpdate(TxUpdateReader<'r>),
    TxComplete(TxCompleteReader<'r>),
    TxAbort(TxAbortReader<'r>),
    TxInitRBF(TxInitRBFReader<'r>),
    TxAckRBF(TxAckRBFReader<'r>),
    CommitmentSigned(CommitmentSignedReader<'r>),
    ChannelReady(ChannelReadyReader<'r>),
    UpdateTlcInfo(UpdateTlcInfoReader<'r>),
    AddTlc(AddTlcReader<'r>),
    RemoveTlc(RemoveTlcReader<'r>),
    RevokeAndAck(RevokeAndAckReader<'r>),
    Shutdown(ShutdownReader<'r>),
    ClosingSigned(ClosingSignedReader<'r>),
    ReestablishChannel(ReestablishChannelReader<'r>),
    AnnouncementSignatures(AnnouncementSignaturesReader<'r>),
}
impl ::core::default::Default for FiberMessageUnion {
    fn default() -> Self {
        FiberMessageUnion::OpenChannel(::core::default::Default::default())
    }
}
impl ::core::fmt::Display for FiberMessageUnion {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            FiberMessageUnion::OpenChannel(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, OpenChannel::NAME, item)
            }
            FiberMessageUnion::AcceptChannel(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, AcceptChannel::NAME, item)
            }
            FiberMessageUnion::TxSignatures(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, TxSignatures::NAME, item)
            }
            FiberMessageUnion::TxUpdate(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, TxUpdate::NAME, item)
            }
            FiberMessageUnion::TxComplete(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, TxComplete::NAME, item)
            }
            FiberMessageUnion::TxAbort(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, TxAbort::NAME, item)
            }
            FiberMessageUnion::TxInitRBF(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, TxInitRBF::NAME, item)
            }
            FiberMessageUnion::TxAckRBF(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, TxAckRBF::NAME, item)
            }
            FiberMessageUnion::CommitmentSigned(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, CommitmentSigned::NAME, item)
            }
            FiberMessageUnion::ChannelReady(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, ChannelReady::NAME, item)
            }
            FiberMessageUnion::UpdateTlcInfo(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, UpdateTlcInfo::NAME, item)
            }
            FiberMessageUnion::AddTlc(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, AddTlc::NAME, item)
            }
            FiberMessageUnion::RemoveTlc(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, RemoveTlc::NAME, item)
            }
            FiberMessageUnion::RevokeAndAck(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, RevokeAndAck::NAME, item)
            }
            FiberMessageUnion::Shutdown(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, Shutdown::NAME, item)
            }
            FiberMessageUnion::ClosingSigned(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, ClosingSigned::NAME, item)
            }
            FiberMessageUnion::ReestablishChannel(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, ReestablishChannel::NAME, item)
            }
            FiberMessageUnion::AnnouncementSignatures(ref item) => {
                write!(
                    f,
                    "{}::{}({})",
                    Self::NAME,
                    AnnouncementSignatures::NAME,
                    item
                )
            }
        }
    }
}
impl<'r> ::core::fmt::Display for FiberMessageUnionReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            FiberMessageUnionReader::OpenChannel(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, OpenChannel::NAME, item)
            }
            FiberMessageUnionReader::AcceptChannel(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, AcceptChannel::NAME, item)
            }
            FiberMessageUnionReader::TxSignatures(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, TxSignatures::NAME, item)
            }
            FiberMessageUnionReader::TxUpdate(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, TxUpdate::NAME, item)
            }
            FiberMessageUnionReader::TxComplete(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, TxComplete::NAME, item)
            }
            FiberMessageUnionReader::TxAbort(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, TxAbort::NAME, item)
            }
            FiberMessageUnionReader::TxInitRBF(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, TxInitRBF::NAME, item)
            }
            FiberMessageUnionReader::TxAckRBF(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, TxAckRBF::NAME, item)
            }
            FiberMessageUnionReader::CommitmentSigned(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, CommitmentSigned::NAME, item)
            }
            FiberMessageUnionReader::ChannelReady(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, ChannelReady::NAME, item)
            }
            FiberMessageUnionReader::UpdateTlcInfo(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, UpdateTlcInfo::NAME, item)
            }
            FiberMessageUnionReader::AddTlc(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, AddTlc::NAME, item)
            }
            FiberMessageUnionReader::RemoveTlc(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, RemoveTlc::NAME, item)
            }
            FiberMessageUnionReader::RevokeAndAck(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, RevokeAndAck::NAME, item)
            }
            FiberMessageUnionReader::Shutdown(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, Shutdown::NAME, item)
            }
            FiberMessageUnionReader::ClosingSigned(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, ClosingSigned::NAME, item)
            }
            FiberMessageUnionReader::ReestablishChannel(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, ReestablishChannel::NAME, item)
            }
            FiberMessageUnionReader::AnnouncementSignatures(ref item) => {
                write!(
                    f,
                    "{}::{}({})",
                    Self::NAME,
                    AnnouncementSignatures::NAME,
                    item
                )
            }
        }
    }
}
impl FiberMessageUnion {
    pub(crate) fn display_inner(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            FiberMessageUnion::OpenChannel(ref item) => write!(f, "{}", item),
            FiberMessageUnion::AcceptChannel(ref item) => write!(f, "{}", item),
            FiberMessageUnion::TxSignatures(ref item) => write!(f, "{}", item),
            FiberMessageUnion::TxUpdate(ref item) => write!(f, "{}", item),
            FiberMessageUnion::TxComplete(ref item) => write!(f, "{}", item),
            FiberMessageUnion::TxAbort(ref item) => write!(f, "{}", item),
            FiberMessageUnion::TxInitRBF(ref item) => write!(f, "{}", item),
            FiberMessageUnion::TxAckRBF(ref item) => write!(f, "{}", item),
            FiberMessageUnion::CommitmentSigned(ref item) => write!(f, "{}", item),
            FiberMessageUnion::ChannelReady(ref item) => write!(f, "{}", item),
            FiberMessageUnion::UpdateTlcInfo(ref item) => write!(f, "{}", item),
            FiberMessageUnion::AddTlc(ref item) => write!(f, "{}", item),
            FiberMessageUnion::RemoveTlc(ref item) => write!(f, "{}", item),
            FiberMessageUnion::RevokeAndAck(ref item) => write!(f, "{}", item),
            FiberMessageUnion::Shutdown(ref item) => write!(f, "{}", item),
            FiberMessageUnion::ClosingSigned(ref item) => write!(f, "{}", item),
            FiberMessageUnion::ReestablishChannel(ref item) => write!(f, "{}", item),
            FiberMessageUnion::AnnouncementSignatures(ref item) => write!(f, "{}", item),
        }
    }
}
impl<'r> FiberMessageUnionReader<'r> {
    pub(crate) fn display_inner(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            FiberMessageUnionReader::OpenChannel(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::AcceptChannel(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::TxSignatures(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::TxUpdate(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::TxComplete(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::TxAbort(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::TxInitRBF(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::TxAckRBF(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::CommitmentSigned(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::ChannelReady(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::UpdateTlcInfo(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::AddTlc(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::RemoveTlc(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::RevokeAndAck(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::Shutdown(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::ClosingSigned(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::ReestablishChannel(ref item) => write!(f, "{}", item),
            FiberMessageUnionReader::AnnouncementSignatures(ref item) => write!(f, "{}", item),
        }
    }
}
impl ::core::convert::From<OpenChannel> for FiberMessageUnion {
    fn from(item: OpenChannel) -> Self {
        FiberMessageUnion::OpenChannel(item)
    }
}
impl ::core::convert::From<AcceptChannel> for FiberMessageUnion {
    fn from(item: AcceptChannel) -> Self {
        FiberMessageUnion::AcceptChannel(item)
    }
}
impl ::core::convert::From<TxSignatures> for FiberMessageUnion {
    fn from(item: TxSignatures) -> Self {
        FiberMessageUnion::TxSignatures(item)
    }
}
impl ::core::convert::From<TxUpdate> for FiberMessageUnion {
    fn from(item: TxUpdate) -> Self {
        FiberMessageUnion::TxUpdate(item)
    }
}
impl ::core::convert::From<TxComplete> for FiberMessageUnion {
    fn from(item: TxComplete) -> Self {
        FiberMessageUnion::TxComplete(item)
    }
}
impl ::core::convert::From<TxAbort> for FiberMessageUnion {
    fn from(item: TxAbort) -> Self {
        FiberMessageUnion::TxAbort(item)
    }
}
impl ::core::convert::From<TxInitRBF> for FiberMessageUnion {
    fn from(item: TxInitRBF) -> Self {
        FiberMessageUnion::TxInitRBF(item)
    }
}
impl ::core::convert::From<TxAckRBF> for FiberMessageUnion {
    fn from(item: TxAckRBF) -> Self {
        FiberMessageUnion::TxAckRBF(item)
    }
}
impl ::core::convert::From<CommitmentSigned> for FiberMessageUnion {
    fn from(item: CommitmentSigned) -> Self {
        FiberMessageUnion::CommitmentSigned(item)
    }
}
impl ::core::convert::From<ChannelReady> for FiberMessageUnion {
    fn from(item: ChannelReady) -> Self {
        FiberMessageUnion::ChannelReady(item)
    }
}
impl ::core::convert::From<UpdateTlcInfo> for FiberMessageUnion {
    fn from(item: UpdateTlcInfo) -> Self {
        FiberMessageUnion::UpdateTlcInfo(item)
    }
}
impl ::core::convert::From<AddTlc> for FiberMessageUnion {
    fn from(item: AddTlc) -> Self {
        FiberMessageUnion::AddTlc(item)
    }
}
impl ::core::convert::From<RemoveTlc> for FiberMessageUnion {
    fn from(item: RemoveTlc) -> Self {
        FiberMessageUnion::RemoveTlc(item)
    }
}
impl ::core::convert::From<RevokeAndAck> for FiberMessageUnion {
    fn from(item: RevokeAndAck) -> Self {
        FiberMessageUnion::RevokeAndAck(item)
    }
}
impl ::core::convert::From<Shutdown> for FiberMessageUnion {
    fn from(item: Shutdown) -> Self {
        FiberMessageUnion::Shutdown(item)
    }
}
impl ::core::convert::From<ClosingSigned> for FiberMessageUnion {
    fn from(item: ClosingSigned) -> Self {
        FiberMessageUnion::ClosingSigned(item)
    }
}
impl ::core::convert::From<ReestablishChannel> for FiberMessageUnion {
    fn from(item: ReestablishChannel) -> Self {
        FiberMessageUnion::ReestablishChannel(item)
    }
}
impl ::core::convert::From<AnnouncementSignatures> for FiberMessageUnion {
    fn from(item: AnnouncementSignatures) -> Self {
        FiberMessageUnion::AnnouncementSignatures(item)
    }
}
impl<'r> ::core::convert::From<OpenChannelReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: OpenChannelReader<'r>) -> Self {
        FiberMessageUnionReader::OpenChannel(item)
    }
}
impl<'r> ::core::convert::From<AcceptChannelReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: AcceptChannelReader<'r>) -> Self {
        FiberMessageUnionReader::AcceptChannel(item)
    }
}
impl<'r> ::core::convert::From<TxSignaturesReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: TxSignaturesReader<'r>) -> Self {
        FiberMessageUnionReader::TxSignatures(item)
    }
}
impl<'r> ::core::convert::From<TxUpdateReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: TxUpdateReader<'r>) -> Self {
        FiberMessageUnionReader::TxUpdate(item)
    }
}
impl<'r> ::core::convert::From<TxCompleteReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: TxCompleteReader<'r>) -> Self {
        FiberMessageUnionReader::TxComplete(item)
    }
}
impl<'r> ::core::convert::From<TxAbortReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: TxAbortReader<'r>) -> Self {
        FiberMessageUnionReader::TxAbort(item)
    }
}
impl<'r> ::core::convert::From<TxInitRBFReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: TxInitRBFReader<'r>) -> Self {
        FiberMessageUnionReader::TxInitRBF(item)
    }
}
impl<'r> ::core::convert::From<TxAckRBFReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: TxAckRBFReader<'r>) -> Self {
        FiberMessageUnionReader::TxAckRBF(item)
    }
}
impl<'r> ::core::convert::From<CommitmentSignedReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: CommitmentSignedReader<'r>) -> Self {
        FiberMessageUnionReader::CommitmentSigned(item)
    }
}
impl<'r> ::core::convert::From<ChannelReadyReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: ChannelReadyReader<'r>) -> Self {
        FiberMessageUnionReader::ChannelReady(item)
    }
}
impl<'r> ::core::convert::From<UpdateTlcInfoReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: UpdateTlcInfoReader<'r>) -> Self {
        FiberMessageUnionReader::UpdateTlcInfo(item)
    }
}
impl<'r> ::core::convert::From<AddTlcReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: AddTlcReader<'r>) -> Self {
        FiberMessageUnionReader::AddTlc(item)
    }
}
impl<'r> ::core::convert::From<RemoveTlcReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: RemoveTlcReader<'r>) -> Self {
        FiberMessageUnionReader::RemoveTlc(item)
    }
}
impl<'r> ::core::convert::From<RevokeAndAckReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: RevokeAndAckReader<'r>) -> Self {
        FiberMessageUnionReader::RevokeAndAck(item)
    }
}
impl<'r> ::core::convert::From<ShutdownReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: ShutdownReader<'r>) -> Self {
        FiberMessageUnionReader::Shutdown(item)
    }
}
impl<'r> ::core::convert::From<ClosingSignedReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: ClosingSignedReader<'r>) -> Self {
        FiberMessageUnionReader::ClosingSigned(item)
    }
}
impl<'r> ::core::convert::From<ReestablishChannelReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: ReestablishChannelReader<'r>) -> Self {
        FiberMessageUnionReader::ReestablishChannel(item)
    }
}
impl<'r> ::core::convert::From<AnnouncementSignaturesReader<'r>> for FiberMessageUnionReader<'r> {
    fn from(item: AnnouncementSignaturesReader<'r>) -> Self {
        FiberMessageUnionReader::AnnouncementSignatures(item)
    }
}
impl FiberMessageUnion {
    pub const NAME: &'static str = "FiberMessageUnion";
    pub fn as_bytes(&self) -> molecule::bytes::Bytes {
        match self {
            FiberMessageUnion::OpenChannel(item) => item.as_bytes(),
            FiberMessageUnion::AcceptChannel(item) => item.as_bytes(),
            FiberMessageUnion::TxSignatures(item) => item.as_bytes(),
            FiberMessageUnion::TxUpdate(item) => item.as_bytes(),
            FiberMessageUnion::TxComplete(item) => item.as_bytes(),
            FiberMessageUnion::TxAbort(item) => item.as_bytes(),
            FiberMessageUnion::TxInitRBF(item) => item.as_bytes(),
            FiberMessageUnion::TxAckRBF(item) => item.as_bytes(),
            FiberMessageUnion::CommitmentSigned(item) => item.as_bytes(),
            FiberMessageUnion::ChannelReady(item) => item.as_bytes(),
            FiberMessageUnion::UpdateTlcInfo(item) => item.as_bytes(),
            FiberMessageUnion::AddTlc(item) => item.as_bytes(),
            FiberMessageUnion::RemoveTlc(item) => item.as_bytes(),
            FiberMessageUnion::RevokeAndAck(item) => item.as_bytes(),
            FiberMessageUnion::Shutdown(item) => item.as_bytes(),
            FiberMessageUnion::ClosingSigned(item) => item.as_bytes(),
            FiberMessageUnion::ReestablishChannel(item) => item.as_bytes(),
            FiberMessageUnion::AnnouncementSignatures(item) => item.as_bytes(),
        }
    }
    pub fn as_slice(&self) -> &[u8] {
        match self {
            FiberMessageUnion::OpenChannel(item) => item.as_slice(),
            FiberMessageUnion::AcceptChannel(item) => item.as_slice(),
            FiberMessageUnion::TxSignatures(item) => item.as_slice(),
            FiberMessageUnion::TxUpdate(item) => item.as_slice(),
            FiberMessageUnion::TxComplete(item) => item.as_slice(),
            FiberMessageUnion::TxAbort(item) => item.as_slice(),
            FiberMessageUnion::TxInitRBF(item) => item.as_slice(),
            FiberMessageUnion::TxAckRBF(item) => item.as_slice(),
            FiberMessageUnion::CommitmentSigned(item) => item.as_slice(),
            FiberMessageUnion::ChannelReady(item) => item.as_slice(),
            FiberMessageUnion::UpdateTlcInfo(item) => item.as_slice(),
            FiberMessageUnion::AddTlc(item) => item.as_slice(),
            FiberMessageUnion::RemoveTlc(item) => item.as_slice(),
            FiberMessageUnion::RevokeAndAck(item) => item.as_slice(),
            FiberMessageUnion::Shutdown(item) => item.as_slice(),
            FiberMessageUnion::ClosingSigned(item) => item.as_slice(),
            FiberMessageUnion::ReestablishChannel(item) => item.as_slice(),
            FiberMessageUnion::AnnouncementSignatures(item) => item.as_slice(),
        }
    }
    pub fn item_id(&self) -> molecule::Number {
        match self {
            FiberMessageUnion::OpenChannel(_) => 0,
            FiberMessageUnion::AcceptChannel(_) => 1,
            FiberMessageUnion::TxSignatures(_) => 2,
            FiberMessageUnion::TxUpdate(_) => 3,
            FiberMessageUnion::TxComplete(_) => 4,
            FiberMessageUnion::TxAbort(_) => 5,
            FiberMessageUnion::TxInitRBF(_) => 6,
            FiberMessageUnion::TxAckRBF(_) => 7,
            FiberMessageUnion::CommitmentSigned(_) => 8,
            FiberMessageUnion::ChannelReady(_) => 9,
            FiberMessageUnion::UpdateTlcInfo(_) => 10,
            FiberMessageUnion::AddTlc(_) => 11,
            FiberMessageUnion::RemoveTlc(_) => 12,
            FiberMessageUnion::RevokeAndAck(_) => 13,
            FiberMessageUnion::Shutdown(_) => 14,
            FiberMessageUnion::ClosingSigned(_) => 15,
            FiberMessageUnion::ReestablishChannel(_) => 16,
            FiberMessageUnion::AnnouncementSignatures(_) => 17,
        }
    }
    pub fn item_name(&self) -> &str {
        match self {
            FiberMessageUnion::OpenChannel(_) => "OpenChannel",
            FiberMessageUnion::AcceptChannel(_) => "AcceptChannel",
            FiberMessageUnion::TxSignatures(_) => "TxSignatures",
            FiberMessageUnion::TxUpdate(_) => "TxUpdate",
            FiberMessageUnion::TxComplete(_) => "TxComplete",
            FiberMessageUnion::TxAbort(_) => "TxAbort",
            FiberMessageUnion::TxInitRBF(_) => "TxInitRBF",
            FiberMessageUnion::TxAckRBF(_) => "TxAckRBF",
            FiberMessageUnion::CommitmentSigned(_) => "CommitmentSigned",
            FiberMessageUnion::ChannelReady(_) => "ChannelReady",
            FiberMessageUnion::UpdateTlcInfo(_) => "UpdateTlcInfo",
            FiberMessageUnion::AddTlc(_) => "AddTlc",
            FiberMessageUnion::RemoveTlc(_) => "RemoveTlc",
            FiberMessageUnion::RevokeAndAck(_) => "RevokeAndAck",
            FiberMessageUnion::Shutdown(_) => "Shutdown",
            FiberMessageUnion::ClosingSigned(_) => "ClosingSigned",
            FiberMessageUnion::ReestablishChannel(_) => "ReestablishChannel",
            FiberMessageUnion::AnnouncementSignatures(_) => "AnnouncementSignatures",
        }
    }
    pub fn as_reader<'r>(&'r self) -> FiberMessageUnionReader<'r> {
        match self {
            FiberMessageUnion::OpenChannel(item) => item.as_reader().into(),
            FiberMessageUnion::AcceptChannel(item) => item.as_reader().into(),
            FiberMessageUnion::TxSignatures(item) => item.as_reader().into(),
            FiberMessageUnion::TxUpdate(item) => item.as_reader().into(),
            FiberMessageUnion::TxComplete(item) => item.as_reader().into(),
            FiberMessageUnion::TxAbort(item) => item.as_reader().into(),
            FiberMessageUnion::TxInitRBF(item) => item.as_reader().into(),
            FiberMessageUnion::TxAckRBF(item) => item.as_reader().into(),
            FiberMessageUnion::CommitmentSigned(item) => item.as_reader().into(),
            FiberMessageUnion::ChannelReady(item) => item.as_reader().into(),
            FiberMessageUnion::UpdateTlcInfo(item) => item.as_reader().into(),
            FiberMessageUnion::AddTlc(item) => item.as_reader().into(),
            FiberMessageUnion::RemoveTlc(item) => item.as_reader().into(),
            FiberMessageUnion::RevokeAndAck(item) => item.as_reader().into(),
            FiberMessageUnion::Shutdown(item) => item.as_reader().into(),
            FiberMessageUnion::ClosingSigned(item) => item.as_reader().into(),
            FiberMessageUnion::ReestablishChannel(item) => item.as_reader().into(),
            FiberMessageUnion::AnnouncementSignatures(item) => item.as_reader().into(),
        }
    }
}
impl<'r> FiberMessageUnionReader<'r> {
    pub const NAME: &'r str = "FiberMessageUnionReader";
    pub fn as_slice(&self) -> &'r [u8] {
        match self {
            FiberMessageUnionReader::OpenChannel(item) => item.as_slice(),
            FiberMessageUnionReader::AcceptChannel(item) => item.as_slice(),
            FiberMessageUnionReader::TxSignatures(item) => item.as_slice(),
            FiberMessageUnionReader::TxUpdate(item) => item.as_slice(),
            FiberMessageUnionReader::TxComplete(item) => item.as_slice(),
            FiberMessageUnionReader::TxAbort(item) => item.as_slice(),
            FiberMessageUnionReader::TxInitRBF(item) => item.as_slice(),
            FiberMessageUnionReader::TxAckRBF(item) => item.as_slice(),
            FiberMessageUnionReader::CommitmentSigned(item) => item.as_slice(),
            FiberMessageUnionReader::ChannelReady(item) => item.as_slice(),
            FiberMessageUnionReader::UpdateTlcInfo(item) => item.as_slice(),
            FiberMessageUnionReader::AddTlc(item) => item.as_slice(),
            FiberMessageUnionReader::RemoveTlc(item) => item.as_slice(),
            FiberMessageUnionReader::RevokeAndAck(item) => item.as_slice(),
            FiberMessageUnionReader::Shutdown(item) => item.as_slice(),
            FiberMessageUnionReader::ClosingSigned(item) => item.as_slice(),
            FiberMessageUnionReader::ReestablishChannel(item) => item.as_slice(),
            FiberMessageUnionReader::AnnouncementSignatures(item) => item.as_slice(),
        }
    }
    pub fn item_id(&self) -> molecule::Number {
        match self {
            FiberMessageUnionReader::OpenChannel(_) => 0,
            FiberMessageUnionReader::AcceptChannel(_) => 1,
            FiberMessageUnionReader::TxSignatures(_) => 2,
            FiberMessageUnionReader::TxUpdate(_) => 3,
            FiberMessageUnionReader::TxComplete(_) => 4,
            FiberMessageUnionReader::TxAbort(_) => 5,
            FiberMessageUnionReader::TxInitRBF(_) => 6,
            FiberMessageUnionReader::TxAckRBF(_) => 7,
            FiberMessageUnionReader::CommitmentSigned(_) => 8,
            FiberMessageUnionReader::ChannelReady(_) => 9,
            FiberMessageUnionReader::UpdateTlcInfo(_) => 10,
            FiberMessageUnionReader::AddTlc(_) => 11,
            FiberMessageUnionReader::RemoveTlc(_) => 12,
            FiberMessageUnionReader::RevokeAndAck(_) => 13,
            FiberMessageUnionReader::Shutdown(_) => 14,
            FiberMessageUnionReader::ClosingSigned(_) => 15,
            FiberMessageUnionReader::ReestablishChannel(_) => 16,
            FiberMessageUnionReader::AnnouncementSignatures(_) => 17,
        }
    }
    pub fn item_name(&self) -> &str {
        match self {
            FiberMessageUnionReader::OpenChannel(_) => "OpenChannel",
            FiberMessageUnionReader::AcceptChannel(_) => "AcceptChannel",
            FiberMessageUnionReader::TxSignatures(_) => "TxSignatures",
            FiberMessageUnionReader::TxUpdate(_) => "TxUpdate",
            FiberMessageUnionReader::TxComplete(_) => "TxComplete",
            FiberMessageUnionReader::TxAbort(_) => "TxAbort",
            FiberMessageUnionReader::TxInitRBF(_) => "TxInitRBF",
            FiberMessageUnionReader::TxAckRBF(_) => "TxAckRBF",
            FiberMessageUnionReader::CommitmentSigned(_) => "CommitmentSigned",
            FiberMessageUnionReader::ChannelReady(_) => "ChannelReady",
            FiberMessageUnionReader::UpdateTlcInfo(_) => "UpdateTlcInfo",
            FiberMessageUnionReader::AddTlc(_) => "AddTlc",
            FiberMessageUnionReader::RemoveTlc(_) => "RemoveTlc",
            FiberMessageUnionReader::RevokeAndAck(_) => "RevokeAndAck",
            FiberMessageUnionReader::Shutdown(_) => "Shutdown",
            FiberMessageUnionReader::ClosingSigned(_) => "ClosingSigned",
            FiberMessageUnionReader::ReestablishChannel(_) => "ReestablishChannel",
            FiberMessageUnionReader::AnnouncementSignatures(_) => "AnnouncementSignatures",
        }
    }
}
impl From<OpenChannel> for FiberMessage {
    fn from(value: OpenChannel) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<AcceptChannel> for FiberMessage {
    fn from(value: AcceptChannel) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<TxSignatures> for FiberMessage {
    fn from(value: TxSignatures) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<TxUpdate> for FiberMessage {
    fn from(value: TxUpdate) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<TxComplete> for FiberMessage {
    fn from(value: TxComplete) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<TxAbort> for FiberMessage {
    fn from(value: TxAbort) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<TxInitRBF> for FiberMessage {
    fn from(value: TxInitRBF) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<TxAckRBF> for FiberMessage {
    fn from(value: TxAckRBF) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<CommitmentSigned> for FiberMessage {
    fn from(value: CommitmentSigned) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<ChannelReady> for FiberMessage {
    fn from(value: ChannelReady) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<UpdateTlcInfo> for FiberMessage {
    fn from(value: UpdateTlcInfo) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<AddTlc> for FiberMessage {
    fn from(value: AddTlc) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<RemoveTlc> for FiberMessage {
    fn from(value: RemoveTlc) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<RevokeAndAck> for FiberMessage {
    fn from(value: RevokeAndAck) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<Shutdown> for FiberMessage {
    fn from(value: Shutdown) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<ClosingSigned> for FiberMessage {
    fn from(value: ClosingSigned) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<ReestablishChannel> for FiberMessage {
    fn from(value: ReestablishChannel) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<AnnouncementSignatures> for FiberMessage {
    fn from(value: AnnouncementSignatures) -> Self {
        Self::new_builder().set(value).build()
    }
}
#[derive(Clone)]
pub struct PaymentPreimageOpt(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for PaymentPreimageOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for PaymentPreimageOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for PaymentPreimageOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl ::core::default::Default for PaymentPreimageOpt {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        PaymentPreimageOpt::new_unchecked(v)
    }
}
impl PaymentPreimageOpt {
    const DEFAULT_VALUE: [u8; 0] = [];
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<Byte32> {
        if self.is_none() {
            None
        } else {
            Some(Byte32::new_unchecked(self.0.clone()))
        }
    }
    pub fn as_reader<'r>(&'r self) -> PaymentPreimageOptReader<'r> {
        PaymentPreimageOptReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for PaymentPreimageOpt {
    type Builder = PaymentPreimageOptBuilder;
    const NAME: &'static str = "PaymentPreimageOpt";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        PaymentPreimageOpt(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        PaymentPreimageOptReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        PaymentPreimageOptReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_opt())
    }
}
#[derive(Clone, Copy)]
pub struct PaymentPreimageOptReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for PaymentPreimageOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for PaymentPreimageOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for PaymentPreimageOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl<'r> PaymentPreimageOptReader<'r> {
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<Byte32Reader<'r>> {
        if self.is_none() {
            None
        } else {
            Some(Byte32Reader::new_unchecked(self.as_slice()))
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for PaymentPreimageOptReader<'r> {
    type Entity = PaymentPreimageOpt;
    const NAME: &'static str = "PaymentPreimageOptReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        PaymentPreimageOptReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        if !slice.is_empty() {
            Byte32Reader::verify(&slice[..], compatible)?;
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct PaymentPreimageOptBuilder(pub(crate) Option<Byte32>);
impl PaymentPreimageOptBuilder {
    pub fn set(mut self, v: Option<Byte32>) -> Self {
        self.0 = v;
        self
    }
}
impl molecule::prelude::Builder for PaymentPreimageOptBuilder {
    type Entity = PaymentPreimageOpt;
    const NAME: &'static str = "PaymentPreimageOptBuilder";
    fn expected_length(&self) -> usize {
        self.0
            .as_ref()
            .map(|ref inner| inner.as_slice().len())
            .unwrap_or(0)
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        self.0
            .as_ref()
            .map(|ref inner| writer.write_all(inner.as_slice()))
            .unwrap_or(Ok(()))
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        PaymentPreimageOpt::new_unchecked(inner.into())
    }
}
impl From<Byte32> for PaymentPreimageOpt {
    fn from(value: Byte32) -> Self {
        Self::new_builder().set(Some(value)).build()
    }
}
#[derive(Clone)]
pub struct PubkeyOpt(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for PubkeyOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for PubkeyOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for PubkeyOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl ::core::default::Default for PubkeyOpt {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        PubkeyOpt::new_unchecked(v)
    }
}
impl PubkeyOpt {
    const DEFAULT_VALUE: [u8; 0] = [];
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<Pubkey> {
        if self.is_none() {
            None
        } else {
            Some(Pubkey::new_unchecked(self.0.clone()))
        }
    }
    pub fn as_reader<'r>(&'r self) -> PubkeyOptReader<'r> {
        PubkeyOptReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for PubkeyOpt {
    type Builder = PubkeyOptBuilder;
    const NAME: &'static str = "PubkeyOpt";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        PubkeyOpt(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        PubkeyOptReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        PubkeyOptReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_opt())
    }
}
#[derive(Clone, Copy)]
pub struct PubkeyOptReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for PubkeyOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for PubkeyOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for PubkeyOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl<'r> PubkeyOptReader<'r> {
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<PubkeyReader<'r>> {
        if self.is_none() {
            None
        } else {
            Some(PubkeyReader::new_unchecked(self.as_slice()))
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for PubkeyOptReader<'r> {
    type Entity = PubkeyOpt;
    const NAME: &'static str = "PubkeyOptReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        PubkeyOptReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        if !slice.is_empty() {
            PubkeyReader::verify(&slice[..], compatible)?;
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct PubkeyOptBuilder(pub(crate) Option<Pubkey>);
impl PubkeyOptBuilder {
    pub fn set(mut self, v: Option<Pubkey>) -> Self {
        self.0 = v;
        self
    }
}
impl molecule::prelude::Builder for PubkeyOptBuilder {
    type Entity = PubkeyOpt;
    const NAME: &'static str = "PubkeyOptBuilder";
    fn expected_length(&self) -> usize {
        self.0
            .as_ref()
            .map(|ref inner| inner.as_slice().len())
            .unwrap_or(0)
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        self.0
            .as_ref()
            .map(|ref inner| writer.write_all(inner.as_slice()))
            .unwrap_or(Ok(()))
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        PubkeyOpt::new_unchecked(inner.into())
    }
}
impl From<Pubkey> for PubkeyOpt {
    fn from(value: Pubkey) -> Self {
        Self::new_builder().set(Some(value)).build()
    }
}
#[derive(Clone)]
pub struct PaymentHopData(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for PaymentHopData {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for PaymentHopData {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for PaymentHopData {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "amount", self.amount())?;
        write!(f, ", {}: {}", "expiry", self.expiry())?;
        write!(f, ", {}: {}", "payment_preimage", self.payment_preimage())?;
        write!(f, ", {}: {}", "hash_algorithm", self.hash_algorithm())?;
        write!(f, ", {}: {}", "funding_tx_hash", self.funding_tx_hash())?;
        write!(f, ", {}: {}", "next_hop", self.next_hop())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for PaymentHopData {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        PaymentHopData::new_unchecked(v)
    }
}
impl PaymentHopData {
    const DEFAULT_VALUE: [u8; 85] = [
        85, 0, 0, 0, 28, 0, 0, 0, 44, 0, 0, 0, 52, 0, 0, 0, 52, 0, 0, 0, 53, 0, 0, 0, 85, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 6;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn amount(&self) -> Uint128 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Uint128::new_unchecked(self.0.slice(start..end))
    }
    pub fn expiry(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn payment_preimage(&self) -> PaymentPreimageOpt {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        PaymentPreimageOpt::new_unchecked(self.0.slice(start..end))
    }
    pub fn hash_algorithm(&self) -> Byte {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        let end = molecule::unpack_number(&slice[20..]) as usize;
        Byte::new_unchecked(self.0.slice(start..end))
    }
    pub fn funding_tx_hash(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[20..]) as usize;
        let end = molecule::unpack_number(&slice[24..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn next_hop(&self) -> PubkeyOpt {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[24..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[28..]) as usize;
            PubkeyOpt::new_unchecked(self.0.slice(start..end))
        } else {
            PubkeyOpt::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> PaymentHopDataReader<'r> {
        PaymentHopDataReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for PaymentHopData {
    type Builder = PaymentHopDataBuilder;
    const NAME: &'static str = "PaymentHopData";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        PaymentHopData(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        PaymentHopDataReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        PaymentHopDataReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .amount(self.amount())
            .expiry(self.expiry())
            .payment_preimage(self.payment_preimage())
            .hash_algorithm(self.hash_algorithm())
            .funding_tx_hash(self.funding_tx_hash())
            .next_hop(self.next_hop())
    }
}
#[derive(Clone, Copy)]
pub struct PaymentHopDataReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for PaymentHopDataReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for PaymentHopDataReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for PaymentHopDataReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "amount", self.amount())?;
        write!(f, ", {}: {}", "expiry", self.expiry())?;
        write!(f, ", {}: {}", "payment_preimage", self.payment_preimage())?;
        write!(f, ", {}: {}", "hash_algorithm", self.hash_algorithm())?;
        write!(f, ", {}: {}", "funding_tx_hash", self.funding_tx_hash())?;
        write!(f, ", {}: {}", "next_hop", self.next_hop())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> PaymentHopDataReader<'r> {
    pub const FIELD_COUNT: usize = 6;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn amount(&self) -> Uint128Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Uint128Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn expiry(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn payment_preimage(&self) -> PaymentPreimageOptReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        PaymentPreimageOptReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn hash_algorithm(&self) -> ByteReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        let end = molecule::unpack_number(&slice[20..]) as usize;
        ByteReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn funding_tx_hash(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[20..]) as usize;
        let end = molecule::unpack_number(&slice[24..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn next_hop(&self) -> PubkeyOptReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[24..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[28..]) as usize;
            PubkeyOptReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            PubkeyOptReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for PaymentHopDataReader<'r> {
    type Entity = PaymentHopData;
    const NAME: &'static str = "PaymentHopDataReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        PaymentHopDataReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Uint128Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Uint64Reader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        PaymentPreimageOptReader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        ByteReader::verify(&slice[offsets[3]..offsets[4]], compatible)?;
        Byte32Reader::verify(&slice[offsets[4]..offsets[5]], compatible)?;
        PubkeyOptReader::verify(&slice[offsets[5]..offsets[6]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct PaymentHopDataBuilder {
    pub(crate) amount: Uint128,
    pub(crate) expiry: Uint64,
    pub(crate) payment_preimage: PaymentPreimageOpt,
    pub(crate) hash_algorithm: Byte,
    pub(crate) funding_tx_hash: Byte32,
    pub(crate) next_hop: PubkeyOpt,
}
impl PaymentHopDataBuilder {
    pub const FIELD_COUNT: usize = 6;
    pub fn amount(mut self, v: Uint128) -> Self {
        self.amount = v;
        self
    }
    pub fn expiry(mut self, v: Uint64) -> Self {
        self.expiry = v;
        self
    }
    pub fn payment_preimage(mut self, v: PaymentPreimageOpt) -> Self {
        self.payment_preimage = v;
        self
    }
    pub fn hash_algorithm(mut self, v: Byte) -> Self {
        self.hash_algorithm = v;
        self
    }
    pub fn funding_tx_hash(mut self, v: Byte32) -> Self {
        self.funding_tx_hash = v;
        self
    }
    pub fn next_hop(mut self, v: PubkeyOpt) -> Self {
        self.next_hop = v;
        self
    }
}
impl molecule::prelude::Builder for PaymentHopDataBuilder {
    type Entity = PaymentHopData;
    const NAME: &'static str = "PaymentHopDataBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.amount.as_slice().len()
            + self.expiry.as_slice().len()
            + self.payment_preimage.as_slice().len()
            + self.hash_algorithm.as_slice().len()
            + self.funding_tx_hash.as_slice().len()
            + self.next_hop.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.amount.as_slice().len();
        offsets.push(total_size);
        total_size += self.expiry.as_slice().len();
        offsets.push(total_size);
        total_size += self.payment_preimage.as_slice().len();
        offsets.push(total_size);
        total_size += self.hash_algorithm.as_slice().len();
        offsets.push(total_size);
        total_size += self.funding_tx_hash.as_slice().len();
        offsets.push(total_size);
        total_size += self.next_hop.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.amount.as_slice())?;
        writer.write_all(self.expiry.as_slice())?;
        writer.write_all(self.payment_preimage.as_slice())?;
        writer.write_all(self.hash_algorithm.as_slice())?;
        writer.write_all(self.funding_tx_hash.as_slice())?;
        writer.write_all(self.next_hop.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        PaymentHopData::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct ChannelUpdate(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for ChannelUpdate {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for ChannelUpdate {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for ChannelUpdate {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "signature", self.signature())?;
        write!(f, ", {}: {}", "chain_hash", self.chain_hash())?;
        write!(f, ", {}: {}", "channel_outpoint", self.channel_outpoint())?;
        write!(f, ", {}: {}", "timestamp", self.timestamp())?;
        write!(f, ", {}: {}", "message_flags", self.message_flags())?;
        write!(f, ", {}: {}", "channel_flags", self.channel_flags())?;
        write!(f, ", {}: {}", "tlc_expiry_delta", self.tlc_expiry_delta())?;
        write!(f, ", {}: {}", "tlc_minimum_value", self.tlc_minimum_value())?;
        write!(f, ", {}: {}", "tlc_maximum_value", self.tlc_maximum_value())?;
        write!(
            f,
            ", {}: {}",
            "tlc_fee_proportional_millionths",
            self.tlc_fee_proportional_millionths()
        )?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for ChannelUpdate {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        ChannelUpdate::new_unchecked(v)
    }
}
impl ChannelUpdate {
    const DEFAULT_VALUE: [u8; 204] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const TOTAL_SIZE: usize = 204;
    pub const FIELD_SIZES: [usize; 10] = [64, 32, 36, 8, 4, 4, 8, 16, 16, 16];
    pub const FIELD_COUNT: usize = 10;
    pub fn signature(&self) -> EcdsaSignature {
        EcdsaSignature::new_unchecked(self.0.slice(0..64))
    }
    pub fn chain_hash(&self) -> Byte32 {
        Byte32::new_unchecked(self.0.slice(64..96))
    }
    pub fn channel_outpoint(&self) -> OutPoint {
        OutPoint::new_unchecked(self.0.slice(96..132))
    }
    pub fn timestamp(&self) -> Uint64 {
        Uint64::new_unchecked(self.0.slice(132..140))
    }
    pub fn message_flags(&self) -> Uint32 {
        Uint32::new_unchecked(self.0.slice(140..144))
    }
    pub fn channel_flags(&self) -> Uint32 {
        Uint32::new_unchecked(self.0.slice(144..148))
    }
    pub fn tlc_expiry_delta(&self) -> Uint64 {
        Uint64::new_unchecked(self.0.slice(148..156))
    }
    pub fn tlc_minimum_value(&self) -> Uint128 {
        Uint128::new_unchecked(self.0.slice(156..172))
    }
    pub fn tlc_maximum_value(&self) -> Uint128 {
        Uint128::new_unchecked(self.0.slice(172..188))
    }
    pub fn tlc_fee_proportional_millionths(&self) -> Uint128 {
        Uint128::new_unchecked(self.0.slice(188..204))
    }
    pub fn as_reader<'r>(&'r self) -> ChannelUpdateReader<'r> {
        ChannelUpdateReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for ChannelUpdate {
    type Builder = ChannelUpdateBuilder;
    const NAME: &'static str = "ChannelUpdate";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        ChannelUpdate(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ChannelUpdateReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ChannelUpdateReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .signature(self.signature())
            .chain_hash(self.chain_hash())
            .channel_outpoint(self.channel_outpoint())
            .timestamp(self.timestamp())
            .message_flags(self.message_flags())
            .channel_flags(self.channel_flags())
            .tlc_expiry_delta(self.tlc_expiry_delta())
            .tlc_minimum_value(self.tlc_minimum_value())
            .tlc_maximum_value(self.tlc_maximum_value())
            .tlc_fee_proportional_millionths(self.tlc_fee_proportional_millionths())
    }
}
#[derive(Clone, Copy)]
pub struct ChannelUpdateReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for ChannelUpdateReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for ChannelUpdateReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for ChannelUpdateReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "signature", self.signature())?;
        write!(f, ", {}: {}", "chain_hash", self.chain_hash())?;
        write!(f, ", {}: {}", "channel_outpoint", self.channel_outpoint())?;
        write!(f, ", {}: {}", "timestamp", self.timestamp())?;
        write!(f, ", {}: {}", "message_flags", self.message_flags())?;
        write!(f, ", {}: {}", "channel_flags", self.channel_flags())?;
        write!(f, ", {}: {}", "tlc_expiry_delta", self.tlc_expiry_delta())?;
        write!(f, ", {}: {}", "tlc_minimum_value", self.tlc_minimum_value())?;
        write!(f, ", {}: {}", "tlc_maximum_value", self.tlc_maximum_value())?;
        write!(
            f,
            ", {}: {}",
            "tlc_fee_proportional_millionths",
            self.tlc_fee_proportional_millionths()
        )?;
        write!(f, " }}")
    }
}
impl<'r> ChannelUpdateReader<'r> {
    pub const TOTAL_SIZE: usize = 204;
    pub const FIELD_SIZES: [usize; 10] = [64, 32, 36, 8, 4, 4, 8, 16, 16, 16];
    pub const FIELD_COUNT: usize = 10;
    pub fn signature(&self) -> EcdsaSignatureReader<'r> {
        EcdsaSignatureReader::new_unchecked(&self.as_slice()[0..64])
    }
    pub fn chain_hash(&self) -> Byte32Reader<'r> {
        Byte32Reader::new_unchecked(&self.as_slice()[64..96])
    }
    pub fn channel_outpoint(&self) -> OutPointReader<'r> {
        OutPointReader::new_unchecked(&self.as_slice()[96..132])
    }
    pub fn timestamp(&self) -> Uint64Reader<'r> {
        Uint64Reader::new_unchecked(&self.as_slice()[132..140])
    }
    pub fn message_flags(&self) -> Uint32Reader<'r> {
        Uint32Reader::new_unchecked(&self.as_slice()[140..144])
    }
    pub fn channel_flags(&self) -> Uint32Reader<'r> {
        Uint32Reader::new_unchecked(&self.as_slice()[144..148])
    }
    pub fn tlc_expiry_delta(&self) -> Uint64Reader<'r> {
        Uint64Reader::new_unchecked(&self.as_slice()[148..156])
    }
    pub fn tlc_minimum_value(&self) -> Uint128Reader<'r> {
        Uint128Reader::new_unchecked(&self.as_slice()[156..172])
    }
    pub fn tlc_maximum_value(&self) -> Uint128Reader<'r> {
        Uint128Reader::new_unchecked(&self.as_slice()[172..188])
    }
    pub fn tlc_fee_proportional_millionths(&self) -> Uint128Reader<'r> {
        Uint128Reader::new_unchecked(&self.as_slice()[188..204])
    }
}
impl<'r> molecule::prelude::Reader<'r> for ChannelUpdateReader<'r> {
    type Entity = ChannelUpdate;
    const NAME: &'static str = "ChannelUpdateReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        ChannelUpdateReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct ChannelUpdateBuilder {
    pub(crate) signature: EcdsaSignature,
    pub(crate) chain_hash: Byte32,
    pub(crate) channel_outpoint: OutPoint,
    pub(crate) timestamp: Uint64,
    pub(crate) message_flags: Uint32,
    pub(crate) channel_flags: Uint32,
    pub(crate) tlc_expiry_delta: Uint64,
    pub(crate) tlc_minimum_value: Uint128,
    pub(crate) tlc_maximum_value: Uint128,
    pub(crate) tlc_fee_proportional_millionths: Uint128,
}
impl ChannelUpdateBuilder {
    pub const TOTAL_SIZE: usize = 204;
    pub const FIELD_SIZES: [usize; 10] = [64, 32, 36, 8, 4, 4, 8, 16, 16, 16];
    pub const FIELD_COUNT: usize = 10;
    pub fn signature(mut self, v: EcdsaSignature) -> Self {
        self.signature = v;
        self
    }
    pub fn chain_hash(mut self, v: Byte32) -> Self {
        self.chain_hash = v;
        self
    }
    pub fn channel_outpoint(mut self, v: OutPoint) -> Self {
        self.channel_outpoint = v;
        self
    }
    pub fn timestamp(mut self, v: Uint64) -> Self {
        self.timestamp = v;
        self
    }
    pub fn message_flags(mut self, v: Uint32) -> Self {
        self.message_flags = v;
        self
    }
    pub fn channel_flags(mut self, v: Uint32) -> Self {
        self.channel_flags = v;
        self
    }
    pub fn tlc_expiry_delta(mut self, v: Uint64) -> Self {
        self.tlc_expiry_delta = v;
        self
    }
    pub fn tlc_minimum_value(mut self, v: Uint128) -> Self {
        self.tlc_minimum_value = v;
        self
    }
    pub fn tlc_maximum_value(mut self, v: Uint128) -> Self {
        self.tlc_maximum_value = v;
        self
    }
    pub fn tlc_fee_proportional_millionths(mut self, v: Uint128) -> Self {
        self.tlc_fee_proportional_millionths = v;
        self
    }
}
impl molecule::prelude::Builder for ChannelUpdateBuilder {
    type Entity = ChannelUpdate;
    const NAME: &'static str = "ChannelUpdateBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.signature.as_slice())?;
        writer.write_all(self.chain_hash.as_slice())?;
        writer.write_all(self.channel_outpoint.as_slice())?;
        writer.write_all(self.timestamp.as_slice())?;
        writer.write_all(self.message_flags.as_slice())?;
        writer.write_all(self.channel_flags.as_slice())?;
        writer.write_all(self.tlc_expiry_delta.as_slice())?;
        writer.write_all(self.tlc_minimum_value.as_slice())?;
        writer.write_all(self.tlc_maximum_value.as_slice())?;
        writer.write_all(self.tlc_fee_proportional_millionths.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        ChannelUpdate::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct ChannelUpdateOpt(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for ChannelUpdateOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for ChannelUpdateOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for ChannelUpdateOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl ::core::default::Default for ChannelUpdateOpt {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        ChannelUpdateOpt::new_unchecked(v)
    }
}
impl ChannelUpdateOpt {
    const DEFAULT_VALUE: [u8; 0] = [];
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<ChannelUpdate> {
        if self.is_none() {
            None
        } else {
            Some(ChannelUpdate::new_unchecked(self.0.clone()))
        }
    }
    pub fn as_reader<'r>(&'r self) -> ChannelUpdateOptReader<'r> {
        ChannelUpdateOptReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for ChannelUpdateOpt {
    type Builder = ChannelUpdateOptBuilder;
    const NAME: &'static str = "ChannelUpdateOpt";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        ChannelUpdateOpt(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ChannelUpdateOptReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ChannelUpdateOptReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_opt())
    }
}
#[derive(Clone, Copy)]
pub struct ChannelUpdateOptReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for ChannelUpdateOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for ChannelUpdateOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for ChannelUpdateOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl<'r> ChannelUpdateOptReader<'r> {
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<ChannelUpdateReader<'r>> {
        if self.is_none() {
            None
        } else {
            Some(ChannelUpdateReader::new_unchecked(self.as_slice()))
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for ChannelUpdateOptReader<'r> {
    type Entity = ChannelUpdateOpt;
    const NAME: &'static str = "ChannelUpdateOptReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        ChannelUpdateOptReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        if !slice.is_empty() {
            ChannelUpdateReader::verify(&slice[..], compatible)?;
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct ChannelUpdateOptBuilder(pub(crate) Option<ChannelUpdate>);
impl ChannelUpdateOptBuilder {
    pub fn set(mut self, v: Option<ChannelUpdate>) -> Self {
        self.0 = v;
        self
    }
}
impl molecule::prelude::Builder for ChannelUpdateOptBuilder {
    type Entity = ChannelUpdateOpt;
    const NAME: &'static str = "ChannelUpdateOptBuilder";
    fn expected_length(&self) -> usize {
        self.0
            .as_ref()
            .map(|ref inner| inner.as_slice().len())
            .unwrap_or(0)
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        self.0
            .as_ref()
            .map(|ref inner| writer.write_all(inner.as_slice()))
            .unwrap_or(Ok(()))
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        ChannelUpdateOpt::new_unchecked(inner.into())
    }
}
impl From<ChannelUpdate> for ChannelUpdateOpt {
    fn from(value: ChannelUpdate) -> Self {
        Self::new_builder().set(Some(value)).build()
    }
}
#[derive(Clone)]
pub struct ChannelFailed(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for ChannelFailed {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for ChannelFailed {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for ChannelFailed {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_outpoint", self.channel_outpoint())?;
        write!(f, ", {}: {}", "channel_update", self.channel_update())?;
        write!(f, ", {}: {}", "node_id", self.node_id())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for ChannelFailed {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        ChannelFailed::new_unchecked(v)
    }
}
impl ChannelFailed {
    const DEFAULT_VALUE: [u8; 85] = [
        85, 0, 0, 0, 16, 0, 0, 0, 52, 0, 0, 0, 52, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_outpoint(&self) -> OutPoint {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        OutPoint::new_unchecked(self.0.slice(start..end))
    }
    pub fn channel_update(&self) -> ChannelUpdateOpt {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        ChannelUpdateOpt::new_unchecked(self.0.slice(start..end))
    }
    pub fn node_id(&self) -> Pubkey {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            Pubkey::new_unchecked(self.0.slice(start..end))
        } else {
            Pubkey::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> ChannelFailedReader<'r> {
        ChannelFailedReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for ChannelFailed {
    type Builder = ChannelFailedBuilder;
    const NAME: &'static str = "ChannelFailed";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        ChannelFailed(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ChannelFailedReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ChannelFailedReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_outpoint(self.channel_outpoint())
            .channel_update(self.channel_update())
            .node_id(self.node_id())
    }
}
#[derive(Clone, Copy)]
pub struct ChannelFailedReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for ChannelFailedReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for ChannelFailedReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for ChannelFailedReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_outpoint", self.channel_outpoint())?;
        write!(f, ", {}: {}", "channel_update", self.channel_update())?;
        write!(f, ", {}: {}", "node_id", self.node_id())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> ChannelFailedReader<'r> {
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn channel_outpoint(&self) -> OutPointReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        OutPointReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn channel_update(&self) -> ChannelUpdateOptReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        ChannelUpdateOptReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn node_id(&self) -> PubkeyReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            PubkeyReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            PubkeyReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for ChannelFailedReader<'r> {
    type Entity = ChannelFailed;
    const NAME: &'static str = "ChannelFailedReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        ChannelFailedReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        OutPointReader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        ChannelUpdateOptReader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        PubkeyReader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct ChannelFailedBuilder {
    pub(crate) channel_outpoint: OutPoint,
    pub(crate) channel_update: ChannelUpdateOpt,
    pub(crate) node_id: Pubkey,
}
impl ChannelFailedBuilder {
    pub const FIELD_COUNT: usize = 3;
    pub fn channel_outpoint(mut self, v: OutPoint) -> Self {
        self.channel_outpoint = v;
        self
    }
    pub fn channel_update(mut self, v: ChannelUpdateOpt) -> Self {
        self.channel_update = v;
        self
    }
    pub fn node_id(mut self, v: Pubkey) -> Self {
        self.node_id = v;
        self
    }
}
impl molecule::prelude::Builder for ChannelFailedBuilder {
    type Entity = ChannelFailed;
    const NAME: &'static str = "ChannelFailedBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.channel_outpoint.as_slice().len()
            + self.channel_update.as_slice().len()
            + self.node_id.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.channel_outpoint.as_slice().len();
        offsets.push(total_size);
        total_size += self.channel_update.as_slice().len();
        offsets.push(total_size);
        total_size += self.node_id.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.channel_outpoint.as_slice())?;
        writer.write_all(self.channel_update.as_slice())?;
        writer.write_all(self.node_id.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        ChannelFailed::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct NodeFailed(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for NodeFailed {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for NodeFailed {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for NodeFailed {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "node_id", self.node_id())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for NodeFailed {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        NodeFailed::new_unchecked(v)
    }
}
impl NodeFailed {
    const DEFAULT_VALUE: [u8; 41] = [
        41, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 1;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn node_id(&self) -> Pubkey {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[8..]) as usize;
            Pubkey::new_unchecked(self.0.slice(start..end))
        } else {
            Pubkey::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> NodeFailedReader<'r> {
        NodeFailedReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for NodeFailed {
    type Builder = NodeFailedBuilder;
    const NAME: &'static str = "NodeFailed";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        NodeFailed(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        NodeFailedReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        NodeFailedReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().node_id(self.node_id())
    }
}
#[derive(Clone, Copy)]
pub struct NodeFailedReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for NodeFailedReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for NodeFailedReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for NodeFailedReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "node_id", self.node_id())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> NodeFailedReader<'r> {
    pub const FIELD_COUNT: usize = 1;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn node_id(&self) -> PubkeyReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[8..]) as usize;
            PubkeyReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            PubkeyReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for NodeFailedReader<'r> {
    type Entity = NodeFailed;
    const NAME: &'static str = "NodeFailedReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        NodeFailedReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        PubkeyReader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct NodeFailedBuilder {
    pub(crate) node_id: Pubkey,
}
impl NodeFailedBuilder {
    pub const FIELD_COUNT: usize = 1;
    pub fn node_id(mut self, v: Pubkey) -> Self {
        self.node_id = v;
        self
    }
}
impl molecule::prelude::Builder for NodeFailedBuilder {
    type Entity = NodeFailed;
    const NAME: &'static str = "NodeFailedBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1) + self.node_id.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.node_id.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.node_id.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        NodeFailed::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct TlcErrData(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for TlcErrData {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for TlcErrData {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for TlcErrData {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}(", Self::NAME)?;
        self.to_enum().display_inner(f)?;
        write!(f, ")")
    }
}
impl ::core::default::Default for TlcErrData {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        TlcErrData::new_unchecked(v)
    }
}
impl TlcErrData {
    const DEFAULT_VALUE: [u8; 89] = [
        0, 0, 0, 0, 85, 0, 0, 0, 16, 0, 0, 0, 52, 0, 0, 0, 52, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const ITEMS_COUNT: usize = 2;
    pub fn item_id(&self) -> molecule::Number {
        molecule::unpack_number(self.as_slice())
    }
    pub fn to_enum(&self) -> TlcErrDataUnion {
        let inner = self.0.slice(molecule::NUMBER_SIZE..);
        match self.item_id() {
            0 => ChannelFailed::new_unchecked(inner).into(),
            1 => NodeFailed::new_unchecked(inner).into(),
            _ => panic!("{}: invalid data", Self::NAME),
        }
    }
    pub fn as_reader<'r>(&'r self) -> TlcErrDataReader<'r> {
        TlcErrDataReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for TlcErrData {
    type Builder = TlcErrDataBuilder;
    const NAME: &'static str = "TlcErrData";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        TlcErrData(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TlcErrDataReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TlcErrDataReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_enum())
    }
}
#[derive(Clone, Copy)]
pub struct TlcErrDataReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for TlcErrDataReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for TlcErrDataReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for TlcErrDataReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}(", Self::NAME)?;
        self.to_enum().display_inner(f)?;
        write!(f, ")")
    }
}
impl<'r> TlcErrDataReader<'r> {
    pub const ITEMS_COUNT: usize = 2;
    pub fn item_id(&self) -> molecule::Number {
        molecule::unpack_number(self.as_slice())
    }
    pub fn to_enum(&self) -> TlcErrDataUnionReader<'r> {
        let inner = &self.as_slice()[molecule::NUMBER_SIZE..];
        match self.item_id() {
            0 => ChannelFailedReader::new_unchecked(inner).into(),
            1 => NodeFailedReader::new_unchecked(inner).into(),
            _ => panic!("{}: invalid data", Self::NAME),
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for TlcErrDataReader<'r> {
    type Entity = TlcErrData;
    const NAME: &'static str = "TlcErrDataReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        TlcErrDataReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let item_id = molecule::unpack_number(slice);
        let inner_slice = &slice[molecule::NUMBER_SIZE..];
        match item_id {
            0 => ChannelFailedReader::verify(inner_slice, compatible),
            1 => NodeFailedReader::verify(inner_slice, compatible),
            _ => ve!(Self, UnknownItem, Self::ITEMS_COUNT, item_id),
        }?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct TlcErrDataBuilder(pub(crate) TlcErrDataUnion);
impl TlcErrDataBuilder {
    pub const ITEMS_COUNT: usize = 2;
    pub fn set<I>(mut self, v: I) -> Self
    where
        I: ::core::convert::Into<TlcErrDataUnion>,
    {
        self.0 = v.into();
        self
    }
}
impl molecule::prelude::Builder for TlcErrDataBuilder {
    type Entity = TlcErrData;
    const NAME: &'static str = "TlcErrDataBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE + self.0.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(&molecule::pack_number(self.0.item_id()))?;
        writer.write_all(self.0.as_slice())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        TlcErrData::new_unchecked(inner.into())
    }
}
#[derive(Debug, Clone)]
pub enum TlcErrDataUnion {
    ChannelFailed(ChannelFailed),
    NodeFailed(NodeFailed),
}
#[derive(Debug, Clone, Copy)]
pub enum TlcErrDataUnionReader<'r> {
    ChannelFailed(ChannelFailedReader<'r>),
    NodeFailed(NodeFailedReader<'r>),
}
impl ::core::default::Default for TlcErrDataUnion {
    fn default() -> Self {
        TlcErrDataUnion::ChannelFailed(::core::default::Default::default())
    }
}
impl ::core::fmt::Display for TlcErrDataUnion {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            TlcErrDataUnion::ChannelFailed(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, ChannelFailed::NAME, item)
            }
            TlcErrDataUnion::NodeFailed(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, NodeFailed::NAME, item)
            }
        }
    }
}
impl<'r> ::core::fmt::Display for TlcErrDataUnionReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            TlcErrDataUnionReader::ChannelFailed(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, ChannelFailed::NAME, item)
            }
            TlcErrDataUnionReader::NodeFailed(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, NodeFailed::NAME, item)
            }
        }
    }
}
impl TlcErrDataUnion {
    pub(crate) fn display_inner(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            TlcErrDataUnion::ChannelFailed(ref item) => write!(f, "{}", item),
            TlcErrDataUnion::NodeFailed(ref item) => write!(f, "{}", item),
        }
    }
}
impl<'r> TlcErrDataUnionReader<'r> {
    pub(crate) fn display_inner(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            TlcErrDataUnionReader::ChannelFailed(ref item) => write!(f, "{}", item),
            TlcErrDataUnionReader::NodeFailed(ref item) => write!(f, "{}", item),
        }
    }
}
impl ::core::convert::From<ChannelFailed> for TlcErrDataUnion {
    fn from(item: ChannelFailed) -> Self {
        TlcErrDataUnion::ChannelFailed(item)
    }
}
impl ::core::convert::From<NodeFailed> for TlcErrDataUnion {
    fn from(item: NodeFailed) -> Self {
        TlcErrDataUnion::NodeFailed(item)
    }
}
impl<'r> ::core::convert::From<ChannelFailedReader<'r>> for TlcErrDataUnionReader<'r> {
    fn from(item: ChannelFailedReader<'r>) -> Self {
        TlcErrDataUnionReader::ChannelFailed(item)
    }
}
impl<'r> ::core::convert::From<NodeFailedReader<'r>> for TlcErrDataUnionReader<'r> {
    fn from(item: NodeFailedReader<'r>) -> Self {
        TlcErrDataUnionReader::NodeFailed(item)
    }
}
impl TlcErrDataUnion {
    pub const NAME: &'static str = "TlcErrDataUnion";
    pub fn as_bytes(&self) -> molecule::bytes::Bytes {
        match self {
            TlcErrDataUnion::ChannelFailed(item) => item.as_bytes(),
            TlcErrDataUnion::NodeFailed(item) => item.as_bytes(),
        }
    }
    pub fn as_slice(&self) -> &[u8] {
        match self {
            TlcErrDataUnion::ChannelFailed(item) => item.as_slice(),
            TlcErrDataUnion::NodeFailed(item) => item.as_slice(),
        }
    }
    pub fn item_id(&self) -> molecule::Number {
        match self {
            TlcErrDataUnion::ChannelFailed(_) => 0,
            TlcErrDataUnion::NodeFailed(_) => 1,
        }
    }
    pub fn item_name(&self) -> &str {
        match self {
            TlcErrDataUnion::ChannelFailed(_) => "ChannelFailed",
            TlcErrDataUnion::NodeFailed(_) => "NodeFailed",
        }
    }
    pub fn as_reader<'r>(&'r self) -> TlcErrDataUnionReader<'r> {
        match self {
            TlcErrDataUnion::ChannelFailed(item) => item.as_reader().into(),
            TlcErrDataUnion::NodeFailed(item) => item.as_reader().into(),
        }
    }
}
impl<'r> TlcErrDataUnionReader<'r> {
    pub const NAME: &'r str = "TlcErrDataUnionReader";
    pub fn as_slice(&self) -> &'r [u8] {
        match self {
            TlcErrDataUnionReader::ChannelFailed(item) => item.as_slice(),
            TlcErrDataUnionReader::NodeFailed(item) => item.as_slice(),
        }
    }
    pub fn item_id(&self) -> molecule::Number {
        match self {
            TlcErrDataUnionReader::ChannelFailed(_) => 0,
            TlcErrDataUnionReader::NodeFailed(_) => 1,
        }
    }
    pub fn item_name(&self) -> &str {
        match self {
            TlcErrDataUnionReader::ChannelFailed(_) => "ChannelFailed",
            TlcErrDataUnionReader::NodeFailed(_) => "NodeFailed",
        }
    }
}
impl From<ChannelFailed> for TlcErrData {
    fn from(value: ChannelFailed) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<NodeFailed> for TlcErrData {
    fn from(value: NodeFailed) -> Self {
        Self::new_builder().set(value).build()
    }
}
#[derive(Clone)]
pub struct TlcErrDataOpt(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for TlcErrDataOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for TlcErrDataOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for TlcErrDataOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl ::core::default::Default for TlcErrDataOpt {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        TlcErrDataOpt::new_unchecked(v)
    }
}
impl TlcErrDataOpt {
    const DEFAULT_VALUE: [u8; 0] = [];
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<TlcErrData> {
        if self.is_none() {
            None
        } else {
            Some(TlcErrData::new_unchecked(self.0.clone()))
        }
    }
    pub fn as_reader<'r>(&'r self) -> TlcErrDataOptReader<'r> {
        TlcErrDataOptReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for TlcErrDataOpt {
    type Builder = TlcErrDataOptBuilder;
    const NAME: &'static str = "TlcErrDataOpt";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        TlcErrDataOpt(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TlcErrDataOptReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TlcErrDataOptReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_opt())
    }
}
#[derive(Clone, Copy)]
pub struct TlcErrDataOptReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for TlcErrDataOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for TlcErrDataOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for TlcErrDataOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl<'r> TlcErrDataOptReader<'r> {
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<TlcErrDataReader<'r>> {
        if self.is_none() {
            None
        } else {
            Some(TlcErrDataReader::new_unchecked(self.as_slice()))
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for TlcErrDataOptReader<'r> {
    type Entity = TlcErrDataOpt;
    const NAME: &'static str = "TlcErrDataOptReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        TlcErrDataOptReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        if !slice.is_empty() {
            TlcErrDataReader::verify(&slice[..], compatible)?;
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct TlcErrDataOptBuilder(pub(crate) Option<TlcErrData>);
impl TlcErrDataOptBuilder {
    pub fn set(mut self, v: Option<TlcErrData>) -> Self {
        self.0 = v;
        self
    }
}
impl molecule::prelude::Builder for TlcErrDataOptBuilder {
    type Entity = TlcErrDataOpt;
    const NAME: &'static str = "TlcErrDataOptBuilder";
    fn expected_length(&self) -> usize {
        self.0
            .as_ref()
            .map(|ref inner| inner.as_slice().len())
            .unwrap_or(0)
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        self.0
            .as_ref()
            .map(|ref inner| writer.write_all(inner.as_slice()))
            .unwrap_or(Ok(()))
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        TlcErrDataOpt::new_unchecked(inner.into())
    }
}
impl From<TlcErrData> for TlcErrDataOpt {
    fn from(value: TlcErrData) -> Self {
        Self::new_builder().set(Some(value)).build()
    }
}
#[derive(Clone)]
pub struct TlcErr(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for TlcErr {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for TlcErr {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for TlcErr {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "error_code", self.error_code())?;
        write!(f, ", {}: {}", "extra_data", self.extra_data())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for TlcErr {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        TlcErr::new_unchecked(v)
    }
}
impl TlcErr {
    const DEFAULT_VALUE: [u8; 14] = [14, 0, 0, 0, 12, 0, 0, 0, 14, 0, 0, 0, 0, 0];
    pub const FIELD_COUNT: usize = 2;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn error_code(&self) -> Uint16 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Uint16::new_unchecked(self.0.slice(start..end))
    }
    pub fn extra_data(&self) -> TlcErrDataOpt {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[12..]) as usize;
            TlcErrDataOpt::new_unchecked(self.0.slice(start..end))
        } else {
            TlcErrDataOpt::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> TlcErrReader<'r> {
        TlcErrReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for TlcErr {
    type Builder = TlcErrBuilder;
    const NAME: &'static str = "TlcErr";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        TlcErr(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TlcErrReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        TlcErrReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .error_code(self.error_code())
            .extra_data(self.extra_data())
    }
}
#[derive(Clone, Copy)]
pub struct TlcErrReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for TlcErrReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for TlcErrReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for TlcErrReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "error_code", self.error_code())?;
        write!(f, ", {}: {}", "extra_data", self.extra_data())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> TlcErrReader<'r> {
    pub const FIELD_COUNT: usize = 2;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn error_code(&self) -> Uint16Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Uint16Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn extra_data(&self) -> TlcErrDataOptReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[12..]) as usize;
            TlcErrDataOptReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            TlcErrDataOptReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for TlcErrReader<'r> {
    type Entity = TlcErr;
    const NAME: &'static str = "TlcErrReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        TlcErrReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Uint16Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        TlcErrDataOptReader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct TlcErrBuilder {
    pub(crate) error_code: Uint16,
    pub(crate) extra_data: TlcErrDataOpt,
}
impl TlcErrBuilder {
    pub const FIELD_COUNT: usize = 2;
    pub fn error_code(mut self, v: Uint16) -> Self {
        self.error_code = v;
        self
    }
    pub fn extra_data(mut self, v: TlcErrDataOpt) -> Self {
        self.extra_data = v;
        self
    }
}
impl molecule::prelude::Builder for TlcErrBuilder {
    type Entity = TlcErr;
    const NAME: &'static str = "TlcErrBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.error_code.as_slice().len()
            + self.extra_data.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.error_code.as_slice().len();
        offsets.push(total_size);
        total_size += self.extra_data.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.error_code.as_slice())?;
        writer.write_all(self.extra_data.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        TlcErr::new_unchecked(inner.into())
    }
}


================================================
File: src/fiber/gen/gossip.rs
================================================
// Generated by Molecule 0.8.0

use super::blockchain::*;
use super::fiber::*;
use molecule::prelude::*;
#[derive(Clone)]
pub struct SchnorrSignature(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for SchnorrSignature {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for SchnorrSignature {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for SchnorrSignature {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl ::core::default::Default for SchnorrSignature {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        SchnorrSignature::new_unchecked(v)
    }
}
impl SchnorrSignature {
    const DEFAULT_VALUE: [u8; 64] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0,
    ];
    pub const TOTAL_SIZE: usize = 64;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 64;
    pub fn nth0(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(0..1))
    }
    pub fn nth1(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(1..2))
    }
    pub fn nth2(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(2..3))
    }
    pub fn nth3(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(3..4))
    }
    pub fn nth4(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(4..5))
    }
    pub fn nth5(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(5..6))
    }
    pub fn nth6(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(6..7))
    }
    pub fn nth7(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(7..8))
    }
    pub fn nth8(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(8..9))
    }
    pub fn nth9(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(9..10))
    }
    pub fn nth10(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(10..11))
    }
    pub fn nth11(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(11..12))
    }
    pub fn nth12(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(12..13))
    }
    pub fn nth13(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(13..14))
    }
    pub fn nth14(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(14..15))
    }
    pub fn nth15(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(15..16))
    }
    pub fn nth16(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(16..17))
    }
    pub fn nth17(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(17..18))
    }
    pub fn nth18(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(18..19))
    }
    pub fn nth19(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(19..20))
    }
    pub fn nth20(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(20..21))
    }
    pub fn nth21(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(21..22))
    }
    pub fn nth22(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(22..23))
    }
    pub fn nth23(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(23..24))
    }
    pub fn nth24(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(24..25))
    }
    pub fn nth25(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(25..26))
    }
    pub fn nth26(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(26..27))
    }
    pub fn nth27(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(27..28))
    }
    pub fn nth28(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(28..29))
    }
    pub fn nth29(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(29..30))
    }
    pub fn nth30(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(30..31))
    }
    pub fn nth31(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(31..32))
    }
    pub fn nth32(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(32..33))
    }
    pub fn nth33(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(33..34))
    }
    pub fn nth34(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(34..35))
    }
    pub fn nth35(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(35..36))
    }
    pub fn nth36(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(36..37))
    }
    pub fn nth37(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(37..38))
    }
    pub fn nth38(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(38..39))
    }
    pub fn nth39(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(39..40))
    }
    pub fn nth40(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(40..41))
    }
    pub fn nth41(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(41..42))
    }
    pub fn nth42(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(42..43))
    }
    pub fn nth43(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(43..44))
    }
    pub fn nth44(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(44..45))
    }
    pub fn nth45(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(45..46))
    }
    pub fn nth46(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(46..47))
    }
    pub fn nth47(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(47..48))
    }
    pub fn nth48(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(48..49))
    }
    pub fn nth49(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(49..50))
    }
    pub fn nth50(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(50..51))
    }
    pub fn nth51(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(51..52))
    }
    pub fn nth52(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(52..53))
    }
    pub fn nth53(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(53..54))
    }
    pub fn nth54(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(54..55))
    }
    pub fn nth55(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(55..56))
    }
    pub fn nth56(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(56..57))
    }
    pub fn nth57(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(57..58))
    }
    pub fn nth58(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(58..59))
    }
    pub fn nth59(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(59..60))
    }
    pub fn nth60(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(60..61))
    }
    pub fn nth61(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(61..62))
    }
    pub fn nth62(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(62..63))
    }
    pub fn nth63(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(63..64))
    }
    pub fn raw_data(&self) -> molecule::bytes::Bytes {
        self.as_bytes()
    }
    pub fn as_reader<'r>(&'r self) -> SchnorrSignatureReader<'r> {
        SchnorrSignatureReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for SchnorrSignature {
    type Builder = SchnorrSignatureBuilder;
    const NAME: &'static str = "SchnorrSignature";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        SchnorrSignature(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        SchnorrSignatureReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        SchnorrSignatureReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set([
            self.nth0(),
            self.nth1(),
            self.nth2(),
            self.nth3(),
            self.nth4(),
            self.nth5(),
            self.nth6(),
            self.nth7(),
            self.nth8(),
            self.nth9(),
            self.nth10(),
            self.nth11(),
            self.nth12(),
            self.nth13(),
            self.nth14(),
            self.nth15(),
            self.nth16(),
            self.nth17(),
            self.nth18(),
            self.nth19(),
            self.nth20(),
            self.nth21(),
            self.nth22(),
            self.nth23(),
            self.nth24(),
            self.nth25(),
            self.nth26(),
            self.nth27(),
            self.nth28(),
            self.nth29(),
            self.nth30(),
            self.nth31(),
            self.nth32(),
            self.nth33(),
            self.nth34(),
            self.nth35(),
            self.nth36(),
            self.nth37(),
            self.nth38(),
            self.nth39(),
            self.nth40(),
            self.nth41(),
            self.nth42(),
            self.nth43(),
            self.nth44(),
            self.nth45(),
            self.nth46(),
            self.nth47(),
            self.nth48(),
            self.nth49(),
            self.nth50(),
            self.nth51(),
            self.nth52(),
            self.nth53(),
            self.nth54(),
            self.nth55(),
            self.nth56(),
            self.nth57(),
            self.nth58(),
            self.nth59(),
            self.nth60(),
            self.nth61(),
            self.nth62(),
            self.nth63(),
        ])
    }
}
#[derive(Clone, Copy)]
pub struct SchnorrSignatureReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for SchnorrSignatureReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for SchnorrSignatureReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for SchnorrSignatureReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl<'r> SchnorrSignatureReader<'r> {
    pub const TOTAL_SIZE: usize = 64;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 64;
    pub fn nth0(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[0..1])
    }
    pub fn nth1(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[1..2])
    }
    pub fn nth2(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[2..3])
    }
    pub fn nth3(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[3..4])
    }
    pub fn nth4(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[4..5])
    }
    pub fn nth5(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[5..6])
    }
    pub fn nth6(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[6..7])
    }
    pub fn nth7(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[7..8])
    }
    pub fn nth8(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[8..9])
    }
    pub fn nth9(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[9..10])
    }
    pub fn nth10(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[10..11])
    }
    pub fn nth11(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[11..12])
    }
    pub fn nth12(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[12..13])
    }
    pub fn nth13(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[13..14])
    }
    pub fn nth14(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[14..15])
    }
    pub fn nth15(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[15..16])
    }
    pub fn nth16(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[16..17])
    }
    pub fn nth17(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[17..18])
    }
    pub fn nth18(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[18..19])
    }
    pub fn nth19(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[19..20])
    }
    pub fn nth20(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[20..21])
    }
    pub fn nth21(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[21..22])
    }
    pub fn nth22(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[22..23])
    }
    pub fn nth23(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[23..24])
    }
    pub fn nth24(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[24..25])
    }
    pub fn nth25(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[25..26])
    }
    pub fn nth26(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[26..27])
    }
    pub fn nth27(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[27..28])
    }
    pub fn nth28(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[28..29])
    }
    pub fn nth29(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[29..30])
    }
    pub fn nth30(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[30..31])
    }
    pub fn nth31(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[31..32])
    }
    pub fn nth32(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[32..33])
    }
    pub fn nth33(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[33..34])
    }
    pub fn nth34(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[34..35])
    }
    pub fn nth35(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[35..36])
    }
    pub fn nth36(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[36..37])
    }
    pub fn nth37(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[37..38])
    }
    pub fn nth38(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[38..39])
    }
    pub fn nth39(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[39..40])
    }
    pub fn nth40(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[40..41])
    }
    pub fn nth41(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[41..42])
    }
    pub fn nth42(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[42..43])
    }
    pub fn nth43(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[43..44])
    }
    pub fn nth44(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[44..45])
    }
    pub fn nth45(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[45..46])
    }
    pub fn nth46(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[46..47])
    }
    pub fn nth47(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[47..48])
    }
    pub fn nth48(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[48..49])
    }
    pub fn nth49(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[49..50])
    }
    pub fn nth50(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[50..51])
    }
    pub fn nth51(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[51..52])
    }
    pub fn nth52(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[52..53])
    }
    pub fn nth53(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[53..54])
    }
    pub fn nth54(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[54..55])
    }
    pub fn nth55(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[55..56])
    }
    pub fn nth56(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[56..57])
    }
    pub fn nth57(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[57..58])
    }
    pub fn nth58(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[58..59])
    }
    pub fn nth59(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[59..60])
    }
    pub fn nth60(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[60..61])
    }
    pub fn nth61(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[61..62])
    }
    pub fn nth62(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[62..63])
    }
    pub fn nth63(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[63..64])
    }
    pub fn raw_data(&self) -> &'r [u8] {
        self.as_slice()
    }
}
impl<'r> molecule::prelude::Reader<'r> for SchnorrSignatureReader<'r> {
    type Entity = SchnorrSignature;
    const NAME: &'static str = "SchnorrSignatureReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        SchnorrSignatureReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone)]
pub struct SchnorrSignatureBuilder(pub(crate) [Byte; 64]);
impl ::core::fmt::Debug for SchnorrSignatureBuilder {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:?})", Self::NAME, &self.0[..])
    }
}
impl ::core::default::Default for SchnorrSignatureBuilder {
    fn default() -> Self {
        SchnorrSignatureBuilder([
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
        ])
    }
}
impl SchnorrSignatureBuilder {
    pub const TOTAL_SIZE: usize = 64;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 64;
    pub fn set(mut self, v: [Byte; 64]) -> Self {
        self.0 = v;
        self
    }
    pub fn nth0(mut self, v: Byte) -> Self {
        self.0[0] = v;
        self
    }
    pub fn nth1(mut self, v: Byte) -> Self {
        self.0[1] = v;
        self
    }
    pub fn nth2(mut self, v: Byte) -> Self {
        self.0[2] = v;
        self
    }
    pub fn nth3(mut self, v: Byte) -> Self {
        self.0[3] = v;
        self
    }
    pub fn nth4(mut self, v: Byte) -> Self {
        self.0[4] = v;
        self
    }
    pub fn nth5(mut self, v: Byte) -> Self {
        self.0[5] = v;
        self
    }
    pub fn nth6(mut self, v: Byte) -> Self {
        self.0[6] = v;
        self
    }
    pub fn nth7(mut self, v: Byte) -> Self {
        self.0[7] = v;
        self
    }
    pub fn nth8(mut self, v: Byte) -> Self {
        self.0[8] = v;
        self
    }
    pub fn nth9(mut self, v: Byte) -> Self {
        self.0[9] = v;
        self
    }
    pub fn nth10(mut self, v: Byte) -> Self {
        self.0[10] = v;
        self
    }
    pub fn nth11(mut self, v: Byte) -> Self {
        self.0[11] = v;
        self
    }
    pub fn nth12(mut self, v: Byte) -> Self {
        self.0[12] = v;
        self
    }
    pub fn nth13(mut self, v: Byte) -> Self {
        self.0[13] = v;
        self
    }
    pub fn nth14(mut self, v: Byte) -> Self {
        self.0[14] = v;
        self
    }
    pub fn nth15(mut self, v: Byte) -> Self {
        self.0[15] = v;
        self
    }
    pub fn nth16(mut self, v: Byte) -> Self {
        self.0[16] = v;
        self
    }
    pub fn nth17(mut self, v: Byte) -> Self {
        self.0[17] = v;
        self
    }
    pub fn nth18(mut self, v: Byte) -> Self {
        self.0[18] = v;
        self
    }
    pub fn nth19(mut self, v: Byte) -> Self {
        self.0[19] = v;
        self
    }
    pub fn nth20(mut self, v: Byte) -> Self {
        self.0[20] = v;
        self
    }
    pub fn nth21(mut self, v: Byte) -> Self {
        self.0[21] = v;
        self
    }
    pub fn nth22(mut self, v: Byte) -> Self {
        self.0[22] = v;
        self
    }
    pub fn nth23(mut self, v: Byte) -> Self {
        self.0[23] = v;
        self
    }
    pub fn nth24(mut self, v: Byte) -> Self {
        self.0[24] = v;
        self
    }
    pub fn nth25(mut self, v: Byte) -> Self {
        self.0[25] = v;
        self
    }
    pub fn nth26(mut self, v: Byte) -> Self {
        self.0[26] = v;
        self
    }
    pub fn nth27(mut self, v: Byte) -> Self {
        self.0[27] = v;
        self
    }
    pub fn nth28(mut self, v: Byte) -> Self {
        self.0[28] = v;
        self
    }
    pub fn nth29(mut self, v: Byte) -> Self {
        self.0[29] = v;
        self
    }
    pub fn nth30(mut self, v: Byte) -> Self {
        self.0[30] = v;
        self
    }
    pub fn nth31(mut self, v: Byte) -> Self {
        self.0[31] = v;
        self
    }
    pub fn nth32(mut self, v: Byte) -> Self {
        self.0[32] = v;
        self
    }
    pub fn nth33(mut self, v: Byte) -> Self {
        self.0[33] = v;
        self
    }
    pub fn nth34(mut self, v: Byte) -> Self {
        self.0[34] = v;
        self
    }
    pub fn nth35(mut self, v: Byte) -> Self {
        self.0[35] = v;
        self
    }
    pub fn nth36(mut self, v: Byte) -> Self {
        self.0[36] = v;
        self
    }
    pub fn nth37(mut self, v: Byte) -> Self {
        self.0[37] = v;
        self
    }
    pub fn nth38(mut self, v: Byte) -> Self {
        self.0[38] = v;
        self
    }
    pub fn nth39(mut self, v: Byte) -> Self {
        self.0[39] = v;
        self
    }
    pub fn nth40(mut self, v: Byte) -> Self {
        self.0[40] = v;
        self
    }
    pub fn nth41(mut self, v: Byte) -> Self {
        self.0[41] = v;
        self
    }
    pub fn nth42(mut self, v: Byte) -> Self {
        self.0[42] = v;
        self
    }
    pub fn nth43(mut self, v: Byte) -> Self {
        self.0[43] = v;
        self
    }
    pub fn nth44(mut self, v: Byte) -> Self {
        self.0[44] = v;
        self
    }
    pub fn nth45(mut self, v: Byte) -> Self {
        self.0[45] = v;
        self
    }
    pub fn nth46(mut self, v: Byte) -> Self {
        self.0[46] = v;
        self
    }
    pub fn nth47(mut self, v: Byte) -> Self {
        self.0[47] = v;
        self
    }
    pub fn nth48(mut self, v: Byte) -> Self {
        self.0[48] = v;
        self
    }
    pub fn nth49(mut self, v: Byte) -> Self {
        self.0[49] = v;
        self
    }
    pub fn nth50(mut self, v: Byte) -> Self {
        self.0[50] = v;
        self
    }
    pub fn nth51(mut self, v: Byte) -> Self {
        self.0[51] = v;
        self
    }
    pub fn nth52(mut self, v: Byte) -> Self {
        self.0[52] = v;
        self
    }
    pub fn nth53(mut self, v: Byte) -> Self {
        self.0[53] = v;
        self
    }
    pub fn nth54(mut self, v: Byte) -> Self {
        self.0[54] = v;
        self
    }
    pub fn nth55(mut self, v: Byte) -> Self {
        self.0[55] = v;
        self
    }
    pub fn nth56(mut self, v: Byte) -> Self {
        self.0[56] = v;
        self
    }
    pub fn nth57(mut self, v: Byte) -> Self {
        self.0[57] = v;
        self
    }
    pub fn nth58(mut self, v: Byte) -> Self {
        self.0[58] = v;
        self
    }
    pub fn nth59(mut self, v: Byte) -> Self {
        self.0[59] = v;
        self
    }
    pub fn nth60(mut self, v: Byte) -> Self {
        self.0[60] = v;
        self
    }
    pub fn nth61(mut self, v: Byte) -> Self {
        self.0[61] = v;
        self
    }
    pub fn nth62(mut self, v: Byte) -> Self {
        self.0[62] = v;
        self
    }
    pub fn nth63(mut self, v: Byte) -> Self {
        self.0[63] = v;
        self
    }
}
impl molecule::prelude::Builder for SchnorrSignatureBuilder {
    type Entity = SchnorrSignature;
    const NAME: &'static str = "SchnorrSignatureBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.0[0].as_slice())?;
        writer.write_all(self.0[1].as_slice())?;
        writer.write_all(self.0[2].as_slice())?;
        writer.write_all(self.0[3].as_slice())?;
        writer.write_all(self.0[4].as_slice())?;
        writer.write_all(self.0[5].as_slice())?;
        writer.write_all(self.0[6].as_slice())?;
        writer.write_all(self.0[7].as_slice())?;
        writer.write_all(self.0[8].as_slice())?;
        writer.write_all(self.0[9].as_slice())?;
        writer.write_all(self.0[10].as_slice())?;
        writer.write_all(self.0[11].as_slice())?;
        writer.write_all(self.0[12].as_slice())?;
        writer.write_all(self.0[13].as_slice())?;
        writer.write_all(self.0[14].as_slice())?;
        writer.write_all(self.0[15].as_slice())?;
        writer.write_all(self.0[16].as_slice())?;
        writer.write_all(self.0[17].as_slice())?;
        writer.write_all(self.0[18].as_slice())?;
        writer.write_all(self.0[19].as_slice())?;
        writer.write_all(self.0[20].as_slice())?;
        writer.write_all(self.0[21].as_slice())?;
        writer.write_all(self.0[22].as_slice())?;
        writer.write_all(self.0[23].as_slice())?;
        writer.write_all(self.0[24].as_slice())?;
        writer.write_all(self.0[25].as_slice())?;
        writer.write_all(self.0[26].as_slice())?;
        writer.write_all(self.0[27].as_slice())?;
        writer.write_all(self.0[28].as_slice())?;
        writer.write_all(self.0[29].as_slice())?;
        writer.write_all(self.0[30].as_slice())?;
        writer.write_all(self.0[31].as_slice())?;
        writer.write_all(self.0[32].as_slice())?;
        writer.write_all(self.0[33].as_slice())?;
        writer.write_all(self.0[34].as_slice())?;
        writer.write_all(self.0[35].as_slice())?;
        writer.write_all(self.0[36].as_slice())?;
        writer.write_all(self.0[37].as_slice())?;
        writer.write_all(self.0[38].as_slice())?;
        writer.write_all(self.0[39].as_slice())?;
        writer.write_all(self.0[40].as_slice())?;
        writer.write_all(self.0[41].as_slice())?;
        writer.write_all(self.0[42].as_slice())?;
        writer.write_all(self.0[43].as_slice())?;
        writer.write_all(self.0[44].as_slice())?;
        writer.write_all(self.0[45].as_slice())?;
        writer.write_all(self.0[46].as_slice())?;
        writer.write_all(self.0[47].as_slice())?;
        writer.write_all(self.0[48].as_slice())?;
        writer.write_all(self.0[49].as_slice())?;
        writer.write_all(self.0[50].as_slice())?;
        writer.write_all(self.0[51].as_slice())?;
        writer.write_all(self.0[52].as_slice())?;
        writer.write_all(self.0[53].as_slice())?;
        writer.write_all(self.0[54].as_slice())?;
        writer.write_all(self.0[55].as_slice())?;
        writer.write_all(self.0[56].as_slice())?;
        writer.write_all(self.0[57].as_slice())?;
        writer.write_all(self.0[58].as_slice())?;
        writer.write_all(self.0[59].as_slice())?;
        writer.write_all(self.0[60].as_slice())?;
        writer.write_all(self.0[61].as_slice())?;
        writer.write_all(self.0[62].as_slice())?;
        writer.write_all(self.0[63].as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        SchnorrSignature::new_unchecked(inner.into())
    }
}
impl From<[Byte; 64usize]> for SchnorrSignature {
    fn from(value: [Byte; 64usize]) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl ::core::convert::TryFrom<&[Byte]> for SchnorrSignature {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[Byte]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(Self::new_builder()
            .set(<&[Byte; 64usize]>::try_from(value)?.clone())
            .build())
    }
}
impl From<SchnorrSignature> for [Byte; 64usize] {
    #[track_caller]
    fn from(value: SchnorrSignature) -> Self {
        [
            value.nth0(),
            value.nth1(),
            value.nth2(),
            value.nth3(),
            value.nth4(),
            value.nth5(),
            value.nth6(),
            value.nth7(),
            value.nth8(),
            value.nth9(),
            value.nth10(),
            value.nth11(),
            value.nth12(),
            value.nth13(),
            value.nth14(),
            value.nth15(),
            value.nth16(),
            value.nth17(),
            value.nth18(),
            value.nth19(),
            value.nth20(),
            value.nth21(),
            value.nth22(),
            value.nth23(),
            value.nth24(),
            value.nth25(),
            value.nth26(),
            value.nth27(),
            value.nth28(),
            value.nth29(),
            value.nth30(),
            value.nth31(),
            value.nth32(),
            value.nth33(),
            value.nth34(),
            value.nth35(),
            value.nth36(),
            value.nth37(),
            value.nth38(),
            value.nth39(),
            value.nth40(),
            value.nth41(),
            value.nth42(),
            value.nth43(),
            value.nth44(),
            value.nth45(),
            value.nth46(),
            value.nth47(),
            value.nth48(),
            value.nth49(),
            value.nth50(),
            value.nth51(),
            value.nth52(),
            value.nth53(),
            value.nth54(),
            value.nth55(),
            value.nth56(),
            value.nth57(),
            value.nth58(),
            value.nth59(),
            value.nth60(),
            value.nth61(),
            value.nth62(),
            value.nth63(),
        ]
    }
}
impl From<[u8; 64usize]> for SchnorrSignature {
    fn from(value: [u8; 64usize]) -> Self {
        SchnorrSignatureReader::new_unchecked(&value).to_entity()
    }
}
impl ::core::convert::TryFrom<&[u8]> for SchnorrSignature {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[u8]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(<[u8; 64usize]>::try_from(value)?.into())
    }
}
impl From<SchnorrSignature> for [u8; 64usize] {
    #[track_caller]
    fn from(value: SchnorrSignature) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<SchnorrSignatureReader<'a>> for &'a [u8; 64usize] {
    #[track_caller]
    fn from(value: SchnorrSignatureReader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<&'a SchnorrSignatureReader<'a>> for &'a [u8; 64usize] {
    #[track_caller]
    fn from(value: &'a SchnorrSignatureReader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
#[derive(Clone)]
pub struct SchnorrXOnlyPubkey(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for SchnorrXOnlyPubkey {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for SchnorrXOnlyPubkey {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for SchnorrXOnlyPubkey {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl ::core::default::Default for SchnorrXOnlyPubkey {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        SchnorrXOnlyPubkey::new_unchecked(v)
    }
}
impl SchnorrXOnlyPubkey {
    const DEFAULT_VALUE: [u8; 32] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0,
    ];
    pub const TOTAL_SIZE: usize = 32;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 32;
    pub fn nth0(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(0..1))
    }
    pub fn nth1(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(1..2))
    }
    pub fn nth2(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(2..3))
    }
    pub fn nth3(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(3..4))
    }
    pub fn nth4(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(4..5))
    }
    pub fn nth5(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(5..6))
    }
    pub fn nth6(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(6..7))
    }
    pub fn nth7(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(7..8))
    }
    pub fn nth8(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(8..9))
    }
    pub fn nth9(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(9..10))
    }
    pub fn nth10(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(10..11))
    }
    pub fn nth11(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(11..12))
    }
    pub fn nth12(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(12..13))
    }
    pub fn nth13(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(13..14))
    }
    pub fn nth14(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(14..15))
    }
    pub fn nth15(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(15..16))
    }
    pub fn nth16(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(16..17))
    }
    pub fn nth17(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(17..18))
    }
    pub fn nth18(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(18..19))
    }
    pub fn nth19(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(19..20))
    }
    pub fn nth20(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(20..21))
    }
    pub fn nth21(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(21..22))
    }
    pub fn nth22(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(22..23))
    }
    pub fn nth23(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(23..24))
    }
    pub fn nth24(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(24..25))
    }
    pub fn nth25(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(25..26))
    }
    pub fn nth26(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(26..27))
    }
    pub fn nth27(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(27..28))
    }
    pub fn nth28(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(28..29))
    }
    pub fn nth29(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(29..30))
    }
    pub fn nth30(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(30..31))
    }
    pub fn nth31(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(31..32))
    }
    pub fn raw_data(&self) -> molecule::bytes::Bytes {
        self.as_bytes()
    }
    pub fn as_reader<'r>(&'r self) -> SchnorrXOnlyPubkeyReader<'r> {
        SchnorrXOnlyPubkeyReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for SchnorrXOnlyPubkey {
    type Builder = SchnorrXOnlyPubkeyBuilder;
    const NAME: &'static str = "SchnorrXOnlyPubkey";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        SchnorrXOnlyPubkey(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        SchnorrXOnlyPubkeyReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        SchnorrXOnlyPubkeyReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set([
            self.nth0(),
            self.nth1(),
            self.nth2(),
            self.nth3(),
            self.nth4(),
            self.nth5(),
            self.nth6(),
            self.nth7(),
            self.nth8(),
            self.nth9(),
            self.nth10(),
            self.nth11(),
            self.nth12(),
            self.nth13(),
            self.nth14(),
            self.nth15(),
            self.nth16(),
            self.nth17(),
            self.nth18(),
            self.nth19(),
            self.nth20(),
            self.nth21(),
            self.nth22(),
            self.nth23(),
            self.nth24(),
            self.nth25(),
            self.nth26(),
            self.nth27(),
            self.nth28(),
            self.nth29(),
            self.nth30(),
            self.nth31(),
        ])
    }
}
#[derive(Clone, Copy)]
pub struct SchnorrXOnlyPubkeyReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for SchnorrXOnlyPubkeyReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for SchnorrXOnlyPubkeyReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for SchnorrXOnlyPubkeyReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl<'r> SchnorrXOnlyPubkeyReader<'r> {
    pub const TOTAL_SIZE: usize = 32;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 32;
    pub fn nth0(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[0..1])
    }
    pub fn nth1(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[1..2])
    }
    pub fn nth2(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[2..3])
    }
    pub fn nth3(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[3..4])
    }
    pub fn nth4(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[4..5])
    }
    pub fn nth5(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[5..6])
    }
    pub fn nth6(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[6..7])
    }
    pub fn nth7(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[7..8])
    }
    pub fn nth8(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[8..9])
    }
    pub fn nth9(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[9..10])
    }
    pub fn nth10(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[10..11])
    }
    pub fn nth11(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[11..12])
    }
    pub fn nth12(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[12..13])
    }
    pub fn nth13(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[13..14])
    }
    pub fn nth14(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[14..15])
    }
    pub fn nth15(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[15..16])
    }
    pub fn nth16(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[16..17])
    }
    pub fn nth17(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[17..18])
    }
    pub fn nth18(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[18..19])
    }
    pub fn nth19(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[19..20])
    }
    pub fn nth20(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[20..21])
    }
    pub fn nth21(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[21..22])
    }
    pub fn nth22(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[22..23])
    }
    pub fn nth23(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[23..24])
    }
    pub fn nth24(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[24..25])
    }
    pub fn nth25(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[25..26])
    }
    pub fn nth26(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[26..27])
    }
    pub fn nth27(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[27..28])
    }
    pub fn nth28(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[28..29])
    }
    pub fn nth29(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[29..30])
    }
    pub fn nth30(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[30..31])
    }
    pub fn nth31(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[31..32])
    }
    pub fn raw_data(&self) -> &'r [u8] {
        self.as_slice()
    }
}
impl<'r> molecule::prelude::Reader<'r> for SchnorrXOnlyPubkeyReader<'r> {
    type Entity = SchnorrXOnlyPubkey;
    const NAME: &'static str = "SchnorrXOnlyPubkeyReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        SchnorrXOnlyPubkeyReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone)]
pub struct SchnorrXOnlyPubkeyBuilder(pub(crate) [Byte; 32]);
impl ::core::fmt::Debug for SchnorrXOnlyPubkeyBuilder {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:?})", Self::NAME, &self.0[..])
    }
}
impl ::core::default::Default for SchnorrXOnlyPubkeyBuilder {
    fn default() -> Self {
        SchnorrXOnlyPubkeyBuilder([
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
        ])
    }
}
impl SchnorrXOnlyPubkeyBuilder {
    pub const TOTAL_SIZE: usize = 32;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 32;
    pub fn set(mut self, v: [Byte; 32]) -> Self {
        self.0 = v;
        self
    }
    pub fn nth0(mut self, v: Byte) -> Self {
        self.0[0] = v;
        self
    }
    pub fn nth1(mut self, v: Byte) -> Self {
        self.0[1] = v;
        self
    }
    pub fn nth2(mut self, v: Byte) -> Self {
        self.0[2] = v;
        self
    }
    pub fn nth3(mut self, v: Byte) -> Self {
        self.0[3] = v;
        self
    }
    pub fn nth4(mut self, v: Byte) -> Self {
        self.0[4] = v;
        self
    }
    pub fn nth5(mut self, v: Byte) -> Self {
        self.0[5] = v;
        self
    }
    pub fn nth6(mut self, v: Byte) -> Self {
        self.0[6] = v;
        self
    }
    pub fn nth7(mut self, v: Byte) -> Self {
        self.0[7] = v;
        self
    }
    pub fn nth8(mut self, v: Byte) -> Self {
        self.0[8] = v;
        self
    }
    pub fn nth9(mut self, v: Byte) -> Self {
        self.0[9] = v;
        self
    }
    pub fn nth10(mut self, v: Byte) -> Self {
        self.0[10] = v;
        self
    }
    pub fn nth11(mut self, v: Byte) -> Self {
        self.0[11] = v;
        self
    }
    pub fn nth12(mut self, v: Byte) -> Self {
        self.0[12] = v;
        self
    }
    pub fn nth13(mut self, v: Byte) -> Self {
        self.0[13] = v;
        self
    }
    pub fn nth14(mut self, v: Byte) -> Self {
        self.0[14] = v;
        self
    }
    pub fn nth15(mut self, v: Byte) -> Self {
        self.0[15] = v;
        self
    }
    pub fn nth16(mut self, v: Byte) -> Self {
        self.0[16] = v;
        self
    }
    pub fn nth17(mut self, v: Byte) -> Self {
        self.0[17] = v;
        self
    }
    pub fn nth18(mut self, v: Byte) -> Self {
        self.0[18] = v;
        self
    }
    pub fn nth19(mut self, v: Byte) -> Self {
        self.0[19] = v;
        self
    }
    pub fn nth20(mut self, v: Byte) -> Self {
        self.0[20] = v;
        self
    }
    pub fn nth21(mut self, v: Byte) -> Self {
        self.0[21] = v;
        self
    }
    pub fn nth22(mut self, v: Byte) -> Self {
        self.0[22] = v;
        self
    }
    pub fn nth23(mut self, v: Byte) -> Self {
        self.0[23] = v;
        self
    }
    pub fn nth24(mut self, v: Byte) -> Self {
        self.0[24] = v;
        self
    }
    pub fn nth25(mut self, v: Byte) -> Self {
        self.0[25] = v;
        self
    }
    pub fn nth26(mut self, v: Byte) -> Self {
        self.0[26] = v;
        self
    }
    pub fn nth27(mut self, v: Byte) -> Self {
        self.0[27] = v;
        self
    }
    pub fn nth28(mut self, v: Byte) -> Self {
        self.0[28] = v;
        self
    }
    pub fn nth29(mut self, v: Byte) -> Self {
        self.0[29] = v;
        self
    }
    pub fn nth30(mut self, v: Byte) -> Self {
        self.0[30] = v;
        self
    }
    pub fn nth31(mut self, v: Byte) -> Self {
        self.0[31] = v;
        self
    }
}
impl molecule::prelude::Builder for SchnorrXOnlyPubkeyBuilder {
    type Entity = SchnorrXOnlyPubkey;
    const NAME: &'static str = "SchnorrXOnlyPubkeyBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.0[0].as_slice())?;
        writer.write_all(self.0[1].as_slice())?;
        writer.write_all(self.0[2].as_slice())?;
        writer.write_all(self.0[3].as_slice())?;
        writer.write_all(self.0[4].as_slice())?;
        writer.write_all(self.0[5].as_slice())?;
        writer.write_all(self.0[6].as_slice())?;
        writer.write_all(self.0[7].as_slice())?;
        writer.write_all(self.0[8].as_slice())?;
        writer.write_all(self.0[9].as_slice())?;
        writer.write_all(self.0[10].as_slice())?;
        writer.write_all(self.0[11].as_slice())?;
        writer.write_all(self.0[12].as_slice())?;
        writer.write_all(self.0[13].as_slice())?;
        writer.write_all(self.0[14].as_slice())?;
        writer.write_all(self.0[15].as_slice())?;
        writer.write_all(self.0[16].as_slice())?;
        writer.write_all(self.0[17].as_slice())?;
        writer.write_all(self.0[18].as_slice())?;
        writer.write_all(self.0[19].as_slice())?;
        writer.write_all(self.0[20].as_slice())?;
        writer.write_all(self.0[21].as_slice())?;
        writer.write_all(self.0[22].as_slice())?;
        writer.write_all(self.0[23].as_slice())?;
        writer.write_all(self.0[24].as_slice())?;
        writer.write_all(self.0[25].as_slice())?;
        writer.write_all(self.0[26].as_slice())?;
        writer.write_all(self.0[27].as_slice())?;
        writer.write_all(self.0[28].as_slice())?;
        writer.write_all(self.0[29].as_slice())?;
        writer.write_all(self.0[30].as_slice())?;
        writer.write_all(self.0[31].as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        SchnorrXOnlyPubkey::new_unchecked(inner.into())
    }
}
impl From<[Byte; 32usize]> for SchnorrXOnlyPubkey {
    fn from(value: [Byte; 32usize]) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl ::core::convert::TryFrom<&[Byte]> for SchnorrXOnlyPubkey {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[Byte]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(Self::new_builder()
            .set(<&[Byte; 32usize]>::try_from(value)?.clone())
            .build())
    }
}
impl From<SchnorrXOnlyPubkey> for [Byte; 32usize] {
    #[track_caller]
    fn from(value: SchnorrXOnlyPubkey) -> Self {
        [
            value.nth0(),
            value.nth1(),
            value.nth2(),
            value.nth3(),
            value.nth4(),
            value.nth5(),
            value.nth6(),
            value.nth7(),
            value.nth8(),
            value.nth9(),
            value.nth10(),
            value.nth11(),
            value.nth12(),
            value.nth13(),
            value.nth14(),
            value.nth15(),
            value.nth16(),
            value.nth17(),
            value.nth18(),
            value.nth19(),
            value.nth20(),
            value.nth21(),
            value.nth22(),
            value.nth23(),
            value.nth24(),
            value.nth25(),
            value.nth26(),
            value.nth27(),
            value.nth28(),
            value.nth29(),
            value.nth30(),
            value.nth31(),
        ]
    }
}
impl From<[u8; 32usize]> for SchnorrXOnlyPubkey {
    fn from(value: [u8; 32usize]) -> Self {
        SchnorrXOnlyPubkeyReader::new_unchecked(&value).to_entity()
    }
}
impl ::core::convert::TryFrom<&[u8]> for SchnorrXOnlyPubkey {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[u8]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(<[u8; 32usize]>::try_from(value)?.into())
    }
}
impl From<SchnorrXOnlyPubkey> for [u8; 32usize] {
    #[track_caller]
    fn from(value: SchnorrXOnlyPubkey) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<SchnorrXOnlyPubkeyReader<'a>> for &'a [u8; 32usize] {
    #[track_caller]
    fn from(value: SchnorrXOnlyPubkeyReader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<&'a SchnorrXOnlyPubkeyReader<'a>> for &'a [u8; 32usize] {
    #[track_caller]
    fn from(value: &'a SchnorrXOnlyPubkeyReader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
#[derive(Clone)]
pub struct Cursor(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for Cursor {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for Cursor {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for Cursor {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl ::core::default::Default for Cursor {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        Cursor::new_unchecked(v)
    }
}
impl Cursor {
    const DEFAULT_VALUE: [u8; 45] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const TOTAL_SIZE: usize = 45;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 45;
    pub fn nth0(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(0..1))
    }
    pub fn nth1(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(1..2))
    }
    pub fn nth2(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(2..3))
    }
    pub fn nth3(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(3..4))
    }
    pub fn nth4(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(4..5))
    }
    pub fn nth5(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(5..6))
    }
    pub fn nth6(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(6..7))
    }
    pub fn nth7(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(7..8))
    }
    pub fn nth8(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(8..9))
    }
    pub fn nth9(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(9..10))
    }
    pub fn nth10(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(10..11))
    }
    pub fn nth11(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(11..12))
    }
    pub fn nth12(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(12..13))
    }
    pub fn nth13(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(13..14))
    }
    pub fn nth14(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(14..15))
    }
    pub fn nth15(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(15..16))
    }
    pub fn nth16(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(16..17))
    }
    pub fn nth17(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(17..18))
    }
    pub fn nth18(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(18..19))
    }
    pub fn nth19(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(19..20))
    }
    pub fn nth20(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(20..21))
    }
    pub fn nth21(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(21..22))
    }
    pub fn nth22(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(22..23))
    }
    pub fn nth23(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(23..24))
    }
    pub fn nth24(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(24..25))
    }
    pub fn nth25(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(25..26))
    }
    pub fn nth26(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(26..27))
    }
    pub fn nth27(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(27..28))
    }
    pub fn nth28(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(28..29))
    }
    pub fn nth29(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(29..30))
    }
    pub fn nth30(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(30..31))
    }
    pub fn nth31(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(31..32))
    }
    pub fn nth32(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(32..33))
    }
    pub fn nth33(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(33..34))
    }
    pub fn nth34(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(34..35))
    }
    pub fn nth35(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(35..36))
    }
    pub fn nth36(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(36..37))
    }
    pub fn nth37(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(37..38))
    }
    pub fn nth38(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(38..39))
    }
    pub fn nth39(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(39..40))
    }
    pub fn nth40(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(40..41))
    }
    pub fn nth41(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(41..42))
    }
    pub fn nth42(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(42..43))
    }
    pub fn nth43(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(43..44))
    }
    pub fn nth44(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(44..45))
    }
    pub fn raw_data(&self) -> molecule::bytes::Bytes {
        self.as_bytes()
    }
    pub fn as_reader<'r>(&'r self) -> CursorReader<'r> {
        CursorReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for Cursor {
    type Builder = CursorBuilder;
    const NAME: &'static str = "Cursor";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        Cursor(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        CursorReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        CursorReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set([
            self.nth0(),
            self.nth1(),
            self.nth2(),
            self.nth3(),
            self.nth4(),
            self.nth5(),
            self.nth6(),
            self.nth7(),
            self.nth8(),
            self.nth9(),
            self.nth10(),
            self.nth11(),
            self.nth12(),
            self.nth13(),
            self.nth14(),
            self.nth15(),
            self.nth16(),
            self.nth17(),
            self.nth18(),
            self.nth19(),
            self.nth20(),
            self.nth21(),
            self.nth22(),
            self.nth23(),
            self.nth24(),
            self.nth25(),
            self.nth26(),
            self.nth27(),
            self.nth28(),
            self.nth29(),
            self.nth30(),
            self.nth31(),
            self.nth32(),
            self.nth33(),
            self.nth34(),
            self.nth35(),
            self.nth36(),
            self.nth37(),
            self.nth38(),
            self.nth39(),
            self.nth40(),
            self.nth41(),
            self.nth42(),
            self.nth43(),
            self.nth44(),
        ])
    }
}
#[derive(Clone, Copy)]
pub struct CursorReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for CursorReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for CursorReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for CursorReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl<'r> CursorReader<'r> {
    pub const TOTAL_SIZE: usize = 45;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 45;
    pub fn nth0(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[0..1])
    }
    pub fn nth1(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[1..2])
    }
    pub fn nth2(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[2..3])
    }
    pub fn nth3(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[3..4])
    }
    pub fn nth4(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[4..5])
    }
    pub fn nth5(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[5..6])
    }
    pub fn nth6(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[6..7])
    }
    pub fn nth7(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[7..8])
    }
    pub fn nth8(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[8..9])
    }
    pub fn nth9(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[9..10])
    }
    pub fn nth10(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[10..11])
    }
    pub fn nth11(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[11..12])
    }
    pub fn nth12(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[12..13])
    }
    pub fn nth13(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[13..14])
    }
    pub fn nth14(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[14..15])
    }
    pub fn nth15(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[15..16])
    }
    pub fn nth16(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[16..17])
    }
    pub fn nth17(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[17..18])
    }
    pub fn nth18(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[18..19])
    }
    pub fn nth19(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[19..20])
    }
    pub fn nth20(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[20..21])
    }
    pub fn nth21(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[21..22])
    }
    pub fn nth22(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[22..23])
    }
    pub fn nth23(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[23..24])
    }
    pub fn nth24(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[24..25])
    }
    pub fn nth25(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[25..26])
    }
    pub fn nth26(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[26..27])
    }
    pub fn nth27(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[27..28])
    }
    pub fn nth28(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[28..29])
    }
    pub fn nth29(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[29..30])
    }
    pub fn nth30(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[30..31])
    }
    pub fn nth31(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[31..32])
    }
    pub fn nth32(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[32..33])
    }
    pub fn nth33(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[33..34])
    }
    pub fn nth34(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[34..35])
    }
    pub fn nth35(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[35..36])
    }
    pub fn nth36(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[36..37])
    }
    pub fn nth37(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[37..38])
    }
    pub fn nth38(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[38..39])
    }
    pub fn nth39(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[39..40])
    }
    pub fn nth40(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[40..41])
    }
    pub fn nth41(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[41..42])
    }
    pub fn nth42(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[42..43])
    }
    pub fn nth43(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[43..44])
    }
    pub fn nth44(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[44..45])
    }
    pub fn raw_data(&self) -> &'r [u8] {
        self.as_slice()
    }
}
impl<'r> molecule::prelude::Reader<'r> for CursorReader<'r> {
    type Entity = Cursor;
    const NAME: &'static str = "CursorReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        CursorReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone)]
pub struct CursorBuilder(pub(crate) [Byte; 45]);
impl ::core::fmt::Debug for CursorBuilder {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:?})", Self::NAME, &self.0[..])
    }
}
impl ::core::default::Default for CursorBuilder {
    fn default() -> Self {
        CursorBuilder([
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
        ])
    }
}
impl CursorBuilder {
    pub const TOTAL_SIZE: usize = 45;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 45;
    pub fn set(mut self, v: [Byte; 45]) -> Self {
        self.0 = v;
        self
    }
    pub fn nth0(mut self, v: Byte) -> Self {
        self.0[0] = v;
        self
    }
    pub fn nth1(mut self, v: Byte) -> Self {
        self.0[1] = v;
        self
    }
    pub fn nth2(mut self, v: Byte) -> Self {
        self.0[2] = v;
        self
    }
    pub fn nth3(mut self, v: Byte) -> Self {
        self.0[3] = v;
        self
    }
    pub fn nth4(mut self, v: Byte) -> Self {
        self.0[4] = v;
        self
    }
    pub fn nth5(mut self, v: Byte) -> Self {
        self.0[5] = v;
        self
    }
    pub fn nth6(mut self, v: Byte) -> Self {
        self.0[6] = v;
        self
    }
    pub fn nth7(mut self, v: Byte) -> Self {
        self.0[7] = v;
        self
    }
    pub fn nth8(mut self, v: Byte) -> Self {
        self.0[8] = v;
        self
    }
    pub fn nth9(mut self, v: Byte) -> Self {
        self.0[9] = v;
        self
    }
    pub fn nth10(mut self, v: Byte) -> Self {
        self.0[10] = v;
        self
    }
    pub fn nth11(mut self, v: Byte) -> Self {
        self.0[11] = v;
        self
    }
    pub fn nth12(mut self, v: Byte) -> Self {
        self.0[12] = v;
        self
    }
    pub fn nth13(mut self, v: Byte) -> Self {
        self.0[13] = v;
        self
    }
    pub fn nth14(mut self, v: Byte) -> Self {
        self.0[14] = v;
        self
    }
    pub fn nth15(mut self, v: Byte) -> Self {
        self.0[15] = v;
        self
    }
    pub fn nth16(mut self, v: Byte) -> Self {
        self.0[16] = v;
        self
    }
    pub fn nth17(mut self, v: Byte) -> Self {
        self.0[17] = v;
        self
    }
    pub fn nth18(mut self, v: Byte) -> Self {
        self.0[18] = v;
        self
    }
    pub fn nth19(mut self, v: Byte) -> Self {
        self.0[19] = v;
        self
    }
    pub fn nth20(mut self, v: Byte) -> Self {
        self.0[20] = v;
        self
    }
    pub fn nth21(mut self, v: Byte) -> Self {
        self.0[21] = v;
        self
    }
    pub fn nth22(mut self, v: Byte) -> Self {
        self.0[22] = v;
        self
    }
    pub fn nth23(mut self, v: Byte) -> Self {
        self.0[23] = v;
        self
    }
    pub fn nth24(mut self, v: Byte) -> Self {
        self.0[24] = v;
        self
    }
    pub fn nth25(mut self, v: Byte) -> Self {
        self.0[25] = v;
        self
    }
    pub fn nth26(mut self, v: Byte) -> Self {
        self.0[26] = v;
        self
    }
    pub fn nth27(mut self, v: Byte) -> Self {
        self.0[27] = v;
        self
    }
    pub fn nth28(mut self, v: Byte) -> Self {
        self.0[28] = v;
        self
    }
    pub fn nth29(mut self, v: Byte) -> Self {
        self.0[29] = v;
        self
    }
    pub fn nth30(mut self, v: Byte) -> Self {
        self.0[30] = v;
        self
    }
    pub fn nth31(mut self, v: Byte) -> Self {
        self.0[31] = v;
        self
    }
    pub fn nth32(mut self, v: Byte) -> Self {
        self.0[32] = v;
        self
    }
    pub fn nth33(mut self, v: Byte) -> Self {
        self.0[33] = v;
        self
    }
    pub fn nth34(mut self, v: Byte) -> Self {
        self.0[34] = v;
        self
    }
    pub fn nth35(mut self, v: Byte) -> Self {
        self.0[35] = v;
        self
    }
    pub fn nth36(mut self, v: Byte) -> Self {
        self.0[36] = v;
        self
    }
    pub fn nth37(mut self, v: Byte) -> Self {
        self.0[37] = v;
        self
    }
    pub fn nth38(mut self, v: Byte) -> Self {
        self.0[38] = v;
        self
    }
    pub fn nth39(mut self, v: Byte) -> Self {
        self.0[39] = v;
        self
    }
    pub fn nth40(mut self, v: Byte) -> Self {
        self.0[40] = v;
        self
    }
    pub fn nth41(mut self, v: Byte) -> Self {
        self.0[41] = v;
        self
    }
    pub fn nth42(mut self, v: Byte) -> Self {
        self.0[42] = v;
        self
    }
    pub fn nth43(mut self, v: Byte) -> Self {
        self.0[43] = v;
        self
    }
    pub fn nth44(mut self, v: Byte) -> Self {
        self.0[44] = v;
        self
    }
}
impl molecule::prelude::Builder for CursorBuilder {
    type Entity = Cursor;
    const NAME: &'static str = "CursorBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.0[0].as_slice())?;
        writer.write_all(self.0[1].as_slice())?;
        writer.write_all(self.0[2].as_slice())?;
        writer.write_all(self.0[3].as_slice())?;
        writer.write_all(self.0[4].as_slice())?;
        writer.write_all(self.0[5].as_slice())?;
        writer.write_all(self.0[6].as_slice())?;
        writer.write_all(self.0[7].as_slice())?;
        writer.write_all(self.0[8].as_slice())?;
        writer.write_all(self.0[9].as_slice())?;
        writer.write_all(self.0[10].as_slice())?;
        writer.write_all(self.0[11].as_slice())?;
        writer.write_all(self.0[12].as_slice())?;
        writer.write_all(self.0[13].as_slice())?;
        writer.write_all(self.0[14].as_slice())?;
        writer.write_all(self.0[15].as_slice())?;
        writer.write_all(self.0[16].as_slice())?;
        writer.write_all(self.0[17].as_slice())?;
        writer.write_all(self.0[18].as_slice())?;
        writer.write_all(self.0[19].as_slice())?;
        writer.write_all(self.0[20].as_slice())?;
        writer.write_all(self.0[21].as_slice())?;
        writer.write_all(self.0[22].as_slice())?;
        writer.write_all(self.0[23].as_slice())?;
        writer.write_all(self.0[24].as_slice())?;
        writer.write_all(self.0[25].as_slice())?;
        writer.write_all(self.0[26].as_slice())?;
        writer.write_all(self.0[27].as_slice())?;
        writer.write_all(self.0[28].as_slice())?;
        writer.write_all(self.0[29].as_slice())?;
        writer.write_all(self.0[30].as_slice())?;
        writer.write_all(self.0[31].as_slice())?;
        writer.write_all(self.0[32].as_slice())?;
        writer.write_all(self.0[33].as_slice())?;
        writer.write_all(self.0[34].as_slice())?;
        writer.write_all(self.0[35].as_slice())?;
        writer.write_all(self.0[36].as_slice())?;
        writer.write_all(self.0[37].as_slice())?;
        writer.write_all(self.0[38].as_slice())?;
        writer.write_all(self.0[39].as_slice())?;
        writer.write_all(self.0[40].as_slice())?;
        writer.write_all(self.0[41].as_slice())?;
        writer.write_all(self.0[42].as_slice())?;
        writer.write_all(self.0[43].as_slice())?;
        writer.write_all(self.0[44].as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        Cursor::new_unchecked(inner.into())
    }
}
impl From<[Byte; 45usize]> for Cursor {
    fn from(value: [Byte; 45usize]) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl ::core::convert::TryFrom<&[Byte]> for Cursor {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[Byte]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(Self::new_builder()
            .set(<&[Byte; 45usize]>::try_from(value)?.clone())
            .build())
    }
}
impl From<Cursor> for [Byte; 45usize] {
    #[track_caller]
    fn from(value: Cursor) -> Self {
        [
            value.nth0(),
            value.nth1(),
            value.nth2(),
            value.nth3(),
            value.nth4(),
            value.nth5(),
            value.nth6(),
            value.nth7(),
            value.nth8(),
            value.nth9(),
            value.nth10(),
            value.nth11(),
            value.nth12(),
            value.nth13(),
            value.nth14(),
            value.nth15(),
            value.nth16(),
            value.nth17(),
            value.nth18(),
            value.nth19(),
            value.nth20(),
            value.nth21(),
            value.nth22(),
            value.nth23(),
            value.nth24(),
            value.nth25(),
            value.nth26(),
            value.nth27(),
            value.nth28(),
            value.nth29(),
            value.nth30(),
            value.nth31(),
            value.nth32(),
            value.nth33(),
            value.nth34(),
            value.nth35(),
            value.nth36(),
            value.nth37(),
            value.nth38(),
            value.nth39(),
            value.nth40(),
            value.nth41(),
            value.nth42(),
            value.nth43(),
            value.nth44(),
        ]
    }
}
impl From<[u8; 45usize]> for Cursor {
    fn from(value: [u8; 45usize]) -> Self {
        CursorReader::new_unchecked(&value).to_entity()
    }
}
impl ::core::convert::TryFrom<&[u8]> for Cursor {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[u8]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(<[u8; 45usize]>::try_from(value)?.into())
    }
}
impl From<Cursor> for [u8; 45usize] {
    #[track_caller]
    fn from(value: Cursor) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<CursorReader<'a>> for &'a [u8; 45usize] {
    #[track_caller]
    fn from(value: CursorReader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<&'a CursorReader<'a>> for &'a [u8; 45usize] {
    #[track_caller]
    fn from(value: &'a CursorReader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
#[derive(Clone)]
pub struct BroadcastMessageQuery(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for BroadcastMessageQuery {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for BroadcastMessageQuery {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for BroadcastMessageQuery {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_outpoint", self.channel_outpoint())?;
        write!(f, ", {}: {}", "flags", self.flags())?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for BroadcastMessageQuery {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        BroadcastMessageQuery::new_unchecked(v)
    }
}
impl BroadcastMessageQuery {
    const DEFAULT_VALUE: [u8; 37] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0,
    ];
    pub const TOTAL_SIZE: usize = 37;
    pub const FIELD_SIZES: [usize; 2] = [36, 1];
    pub const FIELD_COUNT: usize = 2;
    pub fn channel_outpoint(&self) -> OutPoint {
        OutPoint::new_unchecked(self.0.slice(0..36))
    }
    pub fn flags(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(36..37))
    }
    pub fn as_reader<'r>(&'r self) -> BroadcastMessageQueryReader<'r> {
        BroadcastMessageQueryReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for BroadcastMessageQuery {
    type Builder = BroadcastMessageQueryBuilder;
    const NAME: &'static str = "BroadcastMessageQuery";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        BroadcastMessageQuery(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        BroadcastMessageQueryReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        BroadcastMessageQueryReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .channel_outpoint(self.channel_outpoint())
            .flags(self.flags())
    }
}
#[derive(Clone, Copy)]
pub struct BroadcastMessageQueryReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for BroadcastMessageQueryReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for BroadcastMessageQueryReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for BroadcastMessageQueryReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "channel_outpoint", self.channel_outpoint())?;
        write!(f, ", {}: {}", "flags", self.flags())?;
        write!(f, " }}")
    }
}
impl<'r> BroadcastMessageQueryReader<'r> {
    pub const TOTAL_SIZE: usize = 37;
    pub const FIELD_SIZES: [usize; 2] = [36, 1];
    pub const FIELD_COUNT: usize = 2;
    pub fn channel_outpoint(&self) -> OutPointReader<'r> {
        OutPointReader::new_unchecked(&self.as_slice()[0..36])
    }
    pub fn flags(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[36..37])
    }
}
impl<'r> molecule::prelude::Reader<'r> for BroadcastMessageQueryReader<'r> {
    type Entity = BroadcastMessageQuery;
    const NAME: &'static str = "BroadcastMessageQueryReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        BroadcastMessageQueryReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct BroadcastMessageQueryBuilder {
    pub(crate) channel_outpoint: OutPoint,
    pub(crate) flags: Byte,
}
impl BroadcastMessageQueryBuilder {
    pub const TOTAL_SIZE: usize = 37;
    pub const FIELD_SIZES: [usize; 2] = [36, 1];
    pub const FIELD_COUNT: usize = 2;
    pub fn channel_outpoint(mut self, v: OutPoint) -> Self {
        self.channel_outpoint = v;
        self
    }
    pub fn flags(mut self, v: Byte) -> Self {
        self.flags = v;
        self
    }
}
impl molecule::prelude::Builder for BroadcastMessageQueryBuilder {
    type Entity = BroadcastMessageQuery;
    const NAME: &'static str = "BroadcastMessageQueryBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.channel_outpoint.as_slice())?;
        writer.write_all(self.flags.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        BroadcastMessageQuery::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct BroadcastMessageQueries(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for BroadcastMessageQueries {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for BroadcastMessageQueries {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for BroadcastMessageQueries {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} [", Self::NAME)?;
        for i in 0..self.len() {
            if i == 0 {
                write!(f, "{}", self.get_unchecked(i))?;
            } else {
                write!(f, ", {}", self.get_unchecked(i))?;
            }
        }
        write!(f, "]")
    }
}
impl ::core::default::Default for BroadcastMessageQueries {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        BroadcastMessageQueries::new_unchecked(v)
    }
}
impl BroadcastMessageQueries {
    const DEFAULT_VALUE: [u8; 4] = [0, 0, 0, 0];
    pub const ITEM_SIZE: usize = 37;
    pub fn total_size(&self) -> usize {
        molecule::NUMBER_SIZE + Self::ITEM_SIZE * self.item_count()
    }
    pub fn item_count(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn len(&self) -> usize {
        self.item_count()
    }
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
    pub fn get(&self, idx: usize) -> Option<BroadcastMessageQuery> {
        if idx >= self.len() {
            None
        } else {
            Some(self.get_unchecked(idx))
        }
    }
    pub fn get_unchecked(&self, idx: usize) -> BroadcastMessageQuery {
        let start = molecule::NUMBER_SIZE + Self::ITEM_SIZE * idx;
        let end = start + Self::ITEM_SIZE;
        BroadcastMessageQuery::new_unchecked(self.0.slice(start..end))
    }
    pub fn as_reader<'r>(&'r self) -> BroadcastMessageQueriesReader<'r> {
        BroadcastMessageQueriesReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for BroadcastMessageQueries {
    type Builder = BroadcastMessageQueriesBuilder;
    const NAME: &'static str = "BroadcastMessageQueries";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        BroadcastMessageQueries(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        BroadcastMessageQueriesReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        BroadcastMessageQueriesReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().extend(self.into_iter())
    }
}
#[derive(Clone, Copy)]
pub struct BroadcastMessageQueriesReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for BroadcastMessageQueriesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for BroadcastMessageQueriesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for BroadcastMessageQueriesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} [", Self::NAME)?;
        for i in 0..self.len() {
            if i == 0 {
                write!(f, "{}", self.get_unchecked(i))?;
            } else {
                write!(f, ", {}", self.get_unchecked(i))?;
            }
        }
        write!(f, "]")
    }
}
impl<'r> BroadcastMessageQueriesReader<'r> {
    pub const ITEM_SIZE: usize = 37;
    pub fn total_size(&self) -> usize {
        molecule::NUMBER_SIZE + Self::ITEM_SIZE * self.item_count()
    }
    pub fn item_count(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn len(&self) -> usize {
        self.item_count()
    }
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
    pub fn get(&self, idx: usize) -> Option<BroadcastMessageQueryReader<'r>> {
        if idx >= self.len() {
            None
        } else {
            Some(self.get_unchecked(idx))
        }
    }
    pub fn get_unchecked(&self, idx: usize) -> BroadcastMessageQueryReader<'r> {
        let start = molecule::NUMBER_SIZE + Self::ITEM_SIZE * idx;
        let end = start + Self::ITEM_SIZE;
        BroadcastMessageQueryReader::new_unchecked(&self.as_slice()[start..end])
    }
}
impl<'r> molecule::prelude::Reader<'r> for BroadcastMessageQueriesReader<'r> {
    type Entity = BroadcastMessageQueries;
    const NAME: &'static str = "BroadcastMessageQueriesReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        BroadcastMessageQueriesReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let item_count = molecule::unpack_number(slice) as usize;
        if item_count == 0 {
            if slice_len != molecule::NUMBER_SIZE {
                return ve!(Self, TotalSizeNotMatch, molecule::NUMBER_SIZE, slice_len);
            }
            return Ok(());
        }
        let total_size = molecule::NUMBER_SIZE + Self::ITEM_SIZE * item_count;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct BroadcastMessageQueriesBuilder(pub(crate) Vec<BroadcastMessageQuery>);
impl BroadcastMessageQueriesBuilder {
    pub const ITEM_SIZE: usize = 37;
    pub fn set(mut self, v: Vec<BroadcastMessageQuery>) -> Self {
        self.0 = v;
        self
    }
    pub fn push(mut self, v: BroadcastMessageQuery) -> Self {
        self.0.push(v);
        self
    }
    pub fn extend<T: ::core::iter::IntoIterator<Item = BroadcastMessageQuery>>(
        mut self,
        iter: T,
    ) -> Self {
        for elem in iter {
            self.0.push(elem);
        }
        self
    }
    pub fn replace(
        &mut self,
        index: usize,
        v: BroadcastMessageQuery,
    ) -> Option<BroadcastMessageQuery> {
        self.0
            .get_mut(index)
            .map(|item| ::core::mem::replace(item, v))
    }
}
impl molecule::prelude::Builder for BroadcastMessageQueriesBuilder {
    type Entity = BroadcastMessageQueries;
    const NAME: &'static str = "BroadcastMessageQueriesBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE + Self::ITEM_SIZE * self.0.len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(&molecule::pack_number(self.0.len() as molecule::Number))?;
        for inner in &self.0[..] {
            writer.write_all(inner.as_slice())?;
        }
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        BroadcastMessageQueries::new_unchecked(inner.into())
    }
}
pub struct BroadcastMessageQueriesIterator(BroadcastMessageQueries, usize, usize);
impl ::core::iter::Iterator for BroadcastMessageQueriesIterator {
    type Item = BroadcastMessageQuery;
    fn next(&mut self) -> Option<Self::Item> {
        if self.1 >= self.2 {
            None
        } else {
            let ret = self.0.get_unchecked(self.1);
            self.1 += 1;
            Some(ret)
        }
    }
}
impl ::core::iter::ExactSizeIterator for BroadcastMessageQueriesIterator {
    fn len(&self) -> usize {
        self.2 - self.1
    }
}
impl ::core::iter::IntoIterator for BroadcastMessageQueries {
    type Item = BroadcastMessageQuery;
    type IntoIter = BroadcastMessageQueriesIterator;
    fn into_iter(self) -> Self::IntoIter {
        let len = self.len();
        BroadcastMessageQueriesIterator(self, 0, len)
    }
}
impl<'r> BroadcastMessageQueriesReader<'r> {
    pub fn iter<'t>(&'t self) -> BroadcastMessageQueriesReaderIterator<'t, 'r> {
        BroadcastMessageQueriesReaderIterator(&self, 0, self.len())
    }
}
pub struct BroadcastMessageQueriesReaderIterator<'t, 'r>(
    &'t BroadcastMessageQueriesReader<'r>,
    usize,
    usize,
);
impl<'t: 'r, 'r> ::core::iter::Iterator for BroadcastMessageQueriesReaderIterator<'t, 'r> {
    type Item = BroadcastMessageQueryReader<'t>;
    fn next(&mut self) -> Option<Self::Item> {
        if self.1 >= self.2 {
            None
        } else {
            let ret = self.0.get_unchecked(self.1);
            self.1 += 1;
            Some(ret)
        }
    }
}
impl<'t: 'r, 'r> ::core::iter::ExactSizeIterator for BroadcastMessageQueriesReaderIterator<'t, 'r> {
    fn len(&self) -> usize {
        self.2 - self.1
    }
}
impl ::core::iter::FromIterator<BroadcastMessageQuery> for BroadcastMessageQueries {
    fn from_iter<T: IntoIterator<Item = BroadcastMessageQuery>>(iter: T) -> Self {
        Self::new_builder().extend(iter).build()
    }
}
#[derive(Clone)]
pub struct NodeAnnouncement(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for NodeAnnouncement {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for NodeAnnouncement {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for NodeAnnouncement {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "signature", self.signature())?;
        write!(f, ", {}: {}", "features", self.features())?;
        write!(f, ", {}: {}", "timestamp", self.timestamp())?;
        write!(f, ", {}: {}", "node_id", self.node_id())?;
        write!(f, ", {}: {}", "node_name", self.node_name())?;
        write!(f, ", {}: {}", "address", self.address())?;
        write!(f, ", {}: {}", "chain_hash", self.chain_hash())?;
        write!(
            f,
            ", {}: {}",
            "auto_accept_min_ckb_funding_amount",
            self.auto_accept_min_ckb_funding_amount()
        )?;
        write!(f, ", {}: {}", "udt_cfg_infos", self.udt_cfg_infos())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for NodeAnnouncement {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        NodeAnnouncement::new_unchecked(v)
    }
}
impl NodeAnnouncement {
    const DEFAULT_VALUE: [u8; 233] = [
        233, 0, 0, 0, 40, 0, 0, 0, 104, 0, 0, 0, 112, 0, 0, 0, 120, 0, 0, 0, 153, 0, 0, 0, 185, 0,
        0, 0, 189, 0, 0, 0, 221, 0, 0, 0, 229, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 9;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn signature(&self) -> EcdsaSignature {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        EcdsaSignature::new_unchecked(self.0.slice(start..end))
    }
    pub fn features(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn timestamp(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn node_id(&self) -> Pubkey {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        let end = molecule::unpack_number(&slice[20..]) as usize;
        Pubkey::new_unchecked(self.0.slice(start..end))
    }
    pub fn node_name(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[20..]) as usize;
        let end = molecule::unpack_number(&slice[24..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn address(&self) -> BytesVec {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[24..]) as usize;
        let end = molecule::unpack_number(&slice[28..]) as usize;
        BytesVec::new_unchecked(self.0.slice(start..end))
    }
    pub fn chain_hash(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[28..]) as usize;
        let end = molecule::unpack_number(&slice[32..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn auto_accept_min_ckb_funding_amount(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[32..]) as usize;
        let end = molecule::unpack_number(&slice[36..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn udt_cfg_infos(&self) -> UdtCfgInfos {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[36..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[40..]) as usize;
            UdtCfgInfos::new_unchecked(self.0.slice(start..end))
        } else {
            UdtCfgInfos::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> NodeAnnouncementReader<'r> {
        NodeAnnouncementReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for NodeAnnouncement {
    type Builder = NodeAnnouncementBuilder;
    const NAME: &'static str = "NodeAnnouncement";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        NodeAnnouncement(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        NodeAnnouncementReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        NodeAnnouncementReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .signature(self.signature())
            .features(self.features())
            .timestamp(self.timestamp())
            .node_id(self.node_id())
            .node_name(self.node_name())
            .address(self.address())
            .chain_hash(self.chain_hash())
            .auto_accept_min_ckb_funding_amount(self.auto_accept_min_ckb_funding_amount())
            .udt_cfg_infos(self.udt_cfg_infos())
    }
}
#[derive(Clone, Copy)]
pub struct NodeAnnouncementReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for NodeAnnouncementReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for NodeAnnouncementReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for NodeAnnouncementReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "signature", self.signature())?;
        write!(f, ", {}: {}", "features", self.features())?;
        write!(f, ", {}: {}", "timestamp", self.timestamp())?;
        write!(f, ", {}: {}", "node_id", self.node_id())?;
        write!(f, ", {}: {}", "node_name", self.node_name())?;
        write!(f, ", {}: {}", "address", self.address())?;
        write!(f, ", {}: {}", "chain_hash", self.chain_hash())?;
        write!(
            f,
            ", {}: {}",
            "auto_accept_min_ckb_funding_amount",
            self.auto_accept_min_ckb_funding_amount()
        )?;
        write!(f, ", {}: {}", "udt_cfg_infos", self.udt_cfg_infos())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> NodeAnnouncementReader<'r> {
    pub const FIELD_COUNT: usize = 9;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn signature(&self) -> EcdsaSignatureReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        EcdsaSignatureReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn features(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn timestamp(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn node_id(&self) -> PubkeyReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        let end = molecule::unpack_number(&slice[20..]) as usize;
        PubkeyReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn node_name(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[20..]) as usize;
        let end = molecule::unpack_number(&slice[24..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn address(&self) -> BytesVecReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[24..]) as usize;
        let end = molecule::unpack_number(&slice[28..]) as usize;
        BytesVecReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn chain_hash(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[28..]) as usize;
        let end = molecule::unpack_number(&slice[32..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn auto_accept_min_ckb_funding_amount(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[32..]) as usize;
        let end = molecule::unpack_number(&slice[36..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn udt_cfg_infos(&self) -> UdtCfgInfosReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[36..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[40..]) as usize;
            UdtCfgInfosReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            UdtCfgInfosReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for NodeAnnouncementReader<'r> {
    type Entity = NodeAnnouncement;
    const NAME: &'static str = "NodeAnnouncementReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        NodeAnnouncementReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        EcdsaSignatureReader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Uint64Reader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        Uint64Reader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        PubkeyReader::verify(&slice[offsets[3]..offsets[4]], compatible)?;
        Byte32Reader::verify(&slice[offsets[4]..offsets[5]], compatible)?;
        BytesVecReader::verify(&slice[offsets[5]..offsets[6]], compatible)?;
        Byte32Reader::verify(&slice[offsets[6]..offsets[7]], compatible)?;
        Uint64Reader::verify(&slice[offsets[7]..offsets[8]], compatible)?;
        UdtCfgInfosReader::verify(&slice[offsets[8]..offsets[9]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct NodeAnnouncementBuilder {
    pub(crate) signature: EcdsaSignature,
    pub(crate) features: Uint64,
    pub(crate) timestamp: Uint64,
    pub(crate) node_id: Pubkey,
    pub(crate) node_name: Byte32,
    pub(crate) address: BytesVec,
    pub(crate) chain_hash: Byte32,
    pub(crate) auto_accept_min_ckb_funding_amount: Uint64,
    pub(crate) udt_cfg_infos: UdtCfgInfos,
}
impl NodeAnnouncementBuilder {
    pub const FIELD_COUNT: usize = 9;
    pub fn signature(mut self, v: EcdsaSignature) -> Self {
        self.signature = v;
        self
    }
    pub fn features(mut self, v: Uint64) -> Self {
        self.features = v;
        self
    }
    pub fn timestamp(mut self, v: Uint64) -> Self {
        self.timestamp = v;
        self
    }
    pub fn node_id(mut self, v: Pubkey) -> Self {
        self.node_id = v;
        self
    }
    pub fn node_name(mut self, v: Byte32) -> Self {
        self.node_name = v;
        self
    }
    pub fn address(mut self, v: BytesVec) -> Self {
        self.address = v;
        self
    }
    pub fn chain_hash(mut self, v: Byte32) -> Self {
        self.chain_hash = v;
        self
    }
    pub fn auto_accept_min_ckb_funding_amount(mut self, v: Uint64) -> Self {
        self.auto_accept_min_ckb_funding_amount = v;
        self
    }
    pub fn udt_cfg_infos(mut self, v: UdtCfgInfos) -> Self {
        self.udt_cfg_infos = v;
        self
    }
}
impl molecule::prelude::Builder for NodeAnnouncementBuilder {
    type Entity = NodeAnnouncement;
    const NAME: &'static str = "NodeAnnouncementBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.signature.as_slice().len()
            + self.features.as_slice().len()
            + self.timestamp.as_slice().len()
            + self.node_id.as_slice().len()
            + self.node_name.as_slice().len()
            + self.address.as_slice().len()
            + self.chain_hash.as_slice().len()
            + self.auto_accept_min_ckb_funding_amount.as_slice().len()
            + self.udt_cfg_infos.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.signature.as_slice().len();
        offsets.push(total_size);
        total_size += self.features.as_slice().len();
        offsets.push(total_size);
        total_size += self.timestamp.as_slice().len();
        offsets.push(total_size);
        total_size += self.node_id.as_slice().len();
        offsets.push(total_size);
        total_size += self.node_name.as_slice().len();
        offsets.push(total_size);
        total_size += self.address.as_slice().len();
        offsets.push(total_size);
        total_size += self.chain_hash.as_slice().len();
        offsets.push(total_size);
        total_size += self.auto_accept_min_ckb_funding_amount.as_slice().len();
        offsets.push(total_size);
        total_size += self.udt_cfg_infos.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.signature.as_slice())?;
        writer.write_all(self.features.as_slice())?;
        writer.write_all(self.timestamp.as_slice())?;
        writer.write_all(self.node_id.as_slice())?;
        writer.write_all(self.node_name.as_slice())?;
        writer.write_all(self.address.as_slice())?;
        writer.write_all(self.chain_hash.as_slice())?;
        writer.write_all(self.auto_accept_min_ckb_funding_amount.as_slice())?;
        writer.write_all(self.udt_cfg_infos.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        NodeAnnouncement::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct ChannelAnnouncement(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for ChannelAnnouncement {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for ChannelAnnouncement {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for ChannelAnnouncement {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "node1_signature", self.node1_signature())?;
        write!(f, ", {}: {}", "node2_signature", self.node2_signature())?;
        write!(f, ", {}: {}", "ckb_signature", self.ckb_signature())?;
        write!(f, ", {}: {}", "features", self.features())?;
        write!(f, ", {}: {}", "chain_hash", self.chain_hash())?;
        write!(f, ", {}: {}", "channel_outpoint", self.channel_outpoint())?;
        write!(f, ", {}: {}", "node1_id", self.node1_id())?;
        write!(f, ", {}: {}", "node2_id", self.node2_id())?;
        write!(f, ", {}: {}", "ckb_key", self.ckb_key())?;
        write!(f, ", {}: {}", "capacity", self.capacity())?;
        write!(f, ", {}: {}", "udt_type_script", self.udt_type_script())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for ChannelAnnouncement {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        ChannelAnnouncement::new_unchecked(v)
    }
}
impl ChannelAnnouncement {
    const DEFAULT_VALUE: [u8; 430] = [
        174, 1, 0, 0, 48, 0, 0, 0, 112, 0, 0, 0, 176, 0, 0, 0, 240, 0, 0, 0, 248, 0, 0, 0, 24, 1,
        0, 0, 60, 1, 0, 0, 93, 1, 0, 0, 126, 1, 0, 0, 158, 1, 0, 0, 174, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 11;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn node1_signature(&self) -> EcdsaSignature {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        EcdsaSignature::new_unchecked(self.0.slice(start..end))
    }
    pub fn node2_signature(&self) -> EcdsaSignature {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        EcdsaSignature::new_unchecked(self.0.slice(start..end))
    }
    pub fn ckb_signature(&self) -> SchnorrSignature {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        SchnorrSignature::new_unchecked(self.0.slice(start..end))
    }
    pub fn features(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        let end = molecule::unpack_number(&slice[20..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn chain_hash(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[20..]) as usize;
        let end = molecule::unpack_number(&slice[24..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn channel_outpoint(&self) -> OutPoint {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[24..]) as usize;
        let end = molecule::unpack_number(&slice[28..]) as usize;
        OutPoint::new_unchecked(self.0.slice(start..end))
    }
    pub fn node1_id(&self) -> Pubkey {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[28..]) as usize;
        let end = molecule::unpack_number(&slice[32..]) as usize;
        Pubkey::new_unchecked(self.0.slice(start..end))
    }
    pub fn node2_id(&self) -> Pubkey {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[32..]) as usize;
        let end = molecule::unpack_number(&slice[36..]) as usize;
        Pubkey::new_unchecked(self.0.slice(start..end))
    }
    pub fn ckb_key(&self) -> SchnorrXOnlyPubkey {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[36..]) as usize;
        let end = molecule::unpack_number(&slice[40..]) as usize;
        SchnorrXOnlyPubkey::new_unchecked(self.0.slice(start..end))
    }
    pub fn capacity(&self) -> Uint128 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[40..]) as usize;
        let end = molecule::unpack_number(&slice[44..]) as usize;
        Uint128::new_unchecked(self.0.slice(start..end))
    }
    pub fn udt_type_script(&self) -> ScriptOpt {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[44..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[48..]) as usize;
            ScriptOpt::new_unchecked(self.0.slice(start..end))
        } else {
            ScriptOpt::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> ChannelAnnouncementReader<'r> {
        ChannelAnnouncementReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for ChannelAnnouncement {
    type Builder = ChannelAnnouncementBuilder;
    const NAME: &'static str = "ChannelAnnouncement";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        ChannelAnnouncement(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ChannelAnnouncementReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ChannelAnnouncementReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .node1_signature(self.node1_signature())
            .node2_signature(self.node2_signature())
            .ckb_signature(self.ckb_signature())
            .features(self.features())
            .chain_hash(self.chain_hash())
            .channel_outpoint(self.channel_outpoint())
            .node1_id(self.node1_id())
            .node2_id(self.node2_id())
            .ckb_key(self.ckb_key())
            .capacity(self.capacity())
            .udt_type_script(self.udt_type_script())
    }
}
#[derive(Clone, Copy)]
pub struct ChannelAnnouncementReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for ChannelAnnouncementReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for ChannelAnnouncementReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for ChannelAnnouncementReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "node1_signature", self.node1_signature())?;
        write!(f, ", {}: {}", "node2_signature", self.node2_signature())?;
        write!(f, ", {}: {}", "ckb_signature", self.ckb_signature())?;
        write!(f, ", {}: {}", "features", self.features())?;
        write!(f, ", {}: {}", "chain_hash", self.chain_hash())?;
        write!(f, ", {}: {}", "channel_outpoint", self.channel_outpoint())?;
        write!(f, ", {}: {}", "node1_id", self.node1_id())?;
        write!(f, ", {}: {}", "node2_id", self.node2_id())?;
        write!(f, ", {}: {}", "ckb_key", self.ckb_key())?;
        write!(f, ", {}: {}", "capacity", self.capacity())?;
        write!(f, ", {}: {}", "udt_type_script", self.udt_type_script())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> ChannelAnnouncementReader<'r> {
    pub const FIELD_COUNT: usize = 11;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn node1_signature(&self) -> EcdsaSignatureReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        EcdsaSignatureReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn node2_signature(&self) -> EcdsaSignatureReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        EcdsaSignatureReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn ckb_signature(&self) -> SchnorrSignatureReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        SchnorrSignatureReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn features(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        let end = molecule::unpack_number(&slice[20..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn chain_hash(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[20..]) as usize;
        let end = molecule::unpack_number(&slice[24..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn channel_outpoint(&self) -> OutPointReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[24..]) as usize;
        let end = molecule::unpack_number(&slice[28..]) as usize;
        OutPointReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn node1_id(&self) -> PubkeyReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[28..]) as usize;
        let end = molecule::unpack_number(&slice[32..]) as usize;
        PubkeyReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn node2_id(&self) -> PubkeyReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[32..]) as usize;
        let end = molecule::unpack_number(&slice[36..]) as usize;
        PubkeyReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn ckb_key(&self) -> SchnorrXOnlyPubkeyReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[36..]) as usize;
        let end = molecule::unpack_number(&slice[40..]) as usize;
        SchnorrXOnlyPubkeyReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn capacity(&self) -> Uint128Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[40..]) as usize;
        let end = molecule::unpack_number(&slice[44..]) as usize;
        Uint128Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn udt_type_script(&self) -> ScriptOptReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[44..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[48..]) as usize;
            ScriptOptReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            ScriptOptReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for ChannelAnnouncementReader<'r> {
    type Entity = ChannelAnnouncement;
    const NAME: &'static str = "ChannelAnnouncementReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        ChannelAnnouncementReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        EcdsaSignatureReader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        EcdsaSignatureReader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        SchnorrSignatureReader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        Uint64Reader::verify(&slice[offsets[3]..offsets[4]], compatible)?;
        Byte32Reader::verify(&slice[offsets[4]..offsets[5]], compatible)?;
        OutPointReader::verify(&slice[offsets[5]..offsets[6]], compatible)?;
        PubkeyReader::verify(&slice[offsets[6]..offsets[7]], compatible)?;
        PubkeyReader::verify(&slice[offsets[7]..offsets[8]], compatible)?;
        SchnorrXOnlyPubkeyReader::verify(&slice[offsets[8]..offsets[9]], compatible)?;
        Uint128Reader::verify(&slice[offsets[9]..offsets[10]], compatible)?;
        ScriptOptReader::verify(&slice[offsets[10]..offsets[11]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct ChannelAnnouncementBuilder {
    pub(crate) node1_signature: EcdsaSignature,
    pub(crate) node2_signature: EcdsaSignature,
    pub(crate) ckb_signature: SchnorrSignature,
    pub(crate) features: Uint64,
    pub(crate) chain_hash: Byte32,
    pub(crate) channel_outpoint: OutPoint,
    pub(crate) node1_id: Pubkey,
    pub(crate) node2_id: Pubkey,
    pub(crate) ckb_key: SchnorrXOnlyPubkey,
    pub(crate) capacity: Uint128,
    pub(crate) udt_type_script: ScriptOpt,
}
impl ChannelAnnouncementBuilder {
    pub const FIELD_COUNT: usize = 11;
    pub fn node1_signature(mut self, v: EcdsaSignature) -> Self {
        self.node1_signature = v;
        self
    }
    pub fn node2_signature(mut self, v: EcdsaSignature) -> Self {
        self.node2_signature = v;
        self
    }
    pub fn ckb_signature(mut self, v: SchnorrSignature) -> Self {
        self.ckb_signature = v;
        self
    }
    pub fn features(mut self, v: Uint64) -> Self {
        self.features = v;
        self
    }
    pub fn chain_hash(mut self, v: Byte32) -> Self {
        self.chain_hash = v;
        self
    }
    pub fn channel_outpoint(mut self, v: OutPoint) -> Self {
        self.channel_outpoint = v;
        self
    }
    pub fn node1_id(mut self, v: Pubkey) -> Self {
        self.node1_id = v;
        self
    }
    pub fn node2_id(mut self, v: Pubkey) -> Self {
        self.node2_id = v;
        self
    }
    pub fn ckb_key(mut self, v: SchnorrXOnlyPubkey) -> Self {
        self.ckb_key = v;
        self
    }
    pub fn capacity(mut self, v: Uint128) -> Self {
        self.capacity = v;
        self
    }
    pub fn udt_type_script(mut self, v: ScriptOpt) -> Self {
        self.udt_type_script = v;
        self
    }
}
impl molecule::prelude::Builder for ChannelAnnouncementBuilder {
    type Entity = ChannelAnnouncement;
    const NAME: &'static str = "ChannelAnnouncementBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.node1_signature.as_slice().len()
            + self.node2_signature.as_slice().len()
            + self.ckb_signature.as_slice().len()
            + self.features.as_slice().len()
            + self.chain_hash.as_slice().len()
            + self.channel_outpoint.as_slice().len()
            + self.node1_id.as_slice().len()
            + self.node2_id.as_slice().len()
            + self.ckb_key.as_slice().len()
            + self.capacity.as_slice().len()
            + self.udt_type_script.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.node1_signature.as_slice().len();
        offsets.push(total_size);
        total_size += self.node2_signature.as_slice().len();
        offsets.push(total_size);
        total_size += self.ckb_signature.as_slice().len();
        offsets.push(total_size);
        total_size += self.features.as_slice().len();
        offsets.push(total_size);
        total_size += self.chain_hash.as_slice().len();
        offsets.push(total_size);
        total_size += self.channel_outpoint.as_slice().len();
        offsets.push(total_size);
        total_size += self.node1_id.as_slice().len();
        offsets.push(total_size);
        total_size += self.node2_id.as_slice().len();
        offsets.push(total_size);
        total_size += self.ckb_key.as_slice().len();
        offsets.push(total_size);
        total_size += self.capacity.as_slice().len();
        offsets.push(total_size);
        total_size += self.udt_type_script.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.node1_signature.as_slice())?;
        writer.write_all(self.node2_signature.as_slice())?;
        writer.write_all(self.ckb_signature.as_slice())?;
        writer.write_all(self.features.as_slice())?;
        writer.write_all(self.chain_hash.as_slice())?;
        writer.write_all(self.channel_outpoint.as_slice())?;
        writer.write_all(self.node1_id.as_slice())?;
        writer.write_all(self.node2_id.as_slice())?;
        writer.write_all(self.ckb_key.as_slice())?;
        writer.write_all(self.capacity.as_slice())?;
        writer.write_all(self.udt_type_script.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        ChannelAnnouncement::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct BroadcastMessage(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for BroadcastMessage {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for BroadcastMessage {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for BroadcastMessage {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}(", Self::NAME)?;
        self.to_enum().display_inner(f)?;
        write!(f, ")")
    }
}
impl ::core::default::Default for BroadcastMessage {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        BroadcastMessage::new_unchecked(v)
    }
}
impl BroadcastMessage {
    const DEFAULT_VALUE: [u8; 237] = [
        0, 0, 0, 0, 233, 0, 0, 0, 40, 0, 0, 0, 104, 0, 0, 0, 112, 0, 0, 0, 120, 0, 0, 0, 153, 0, 0,
        0, 185, 0, 0, 0, 189, 0, 0, 0, 221, 0, 0, 0, 229, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0,
        0, 0,
    ];
    pub const ITEMS_COUNT: usize = 3;
    pub fn item_id(&self) -> molecule::Number {
        molecule::unpack_number(self.as_slice())
    }
    pub fn to_enum(&self) -> BroadcastMessageUnion {
        let inner = self.0.slice(molecule::NUMBER_SIZE..);
        match self.item_id() {
            0 => NodeAnnouncement::new_unchecked(inner).into(),
            1 => ChannelAnnouncement::new_unchecked(inner).into(),
            2 => ChannelUpdate::new_unchecked(inner).into(),
            _ => panic!("{}: invalid data", Self::NAME),
        }
    }
    pub fn as_reader<'r>(&'r self) -> BroadcastMessageReader<'r> {
        BroadcastMessageReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for BroadcastMessage {
    type Builder = BroadcastMessageBuilder;
    const NAME: &'static str = "BroadcastMessage";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        BroadcastMessage(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        BroadcastMessageReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        BroadcastMessageReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_enum())
    }
}
#[derive(Clone, Copy)]
pub struct BroadcastMessageReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for BroadcastMessageReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for BroadcastMessageReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for BroadcastMessageReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}(", Self::NAME)?;
        self.to_enum().display_inner(f)?;
        write!(f, ")")
    }
}
impl<'r> BroadcastMessageReader<'r> {
    pub const ITEMS_COUNT: usize = 3;
    pub fn item_id(&self) -> molecule::Number {
        molecule::unpack_number(self.as_slice())
    }
    pub fn to_enum(&self) -> BroadcastMessageUnionReader<'r> {
        let inner = &self.as_slice()[molecule::NUMBER_SIZE..];
        match self.item_id() {
            0 => NodeAnnouncementReader::new_unchecked(inner).into(),
            1 => ChannelAnnouncementReader::new_unchecked(inner).into(),
            2 => ChannelUpdateReader::new_unchecked(inner).into(),
            _ => panic!("{}: invalid data", Self::NAME),
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for BroadcastMessageReader<'r> {
    type Entity = BroadcastMessage;
    const NAME: &'static str = "BroadcastMessageReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        BroadcastMessageReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let item_id = molecule::unpack_number(slice);
        let inner_slice = &slice[molecule::NUMBER_SIZE..];
        match item_id {
            0 => NodeAnnouncementReader::verify(inner_slice, compatible),
            1 => ChannelAnnouncementReader::verify(inner_slice, compatible),
            2 => ChannelUpdateReader::verify(inner_slice, compatible),
            _ => ve!(Self, UnknownItem, Self::ITEMS_COUNT, item_id),
        }?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct BroadcastMessageBuilder(pub(crate) BroadcastMessageUnion);
impl BroadcastMessageBuilder {
    pub const ITEMS_COUNT: usize = 3;
    pub fn set<I>(mut self, v: I) -> Self
    where
        I: ::core::convert::Into<BroadcastMessageUnion>,
    {
        self.0 = v.into();
        self
    }
}
impl molecule::prelude::Builder for BroadcastMessageBuilder {
    type Entity = BroadcastMessage;
    const NAME: &'static str = "BroadcastMessageBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE + self.0.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(&molecule::pack_number(self.0.item_id()))?;
        writer.write_all(self.0.as_slice())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        BroadcastMessage::new_unchecked(inner.into())
    }
}
#[derive(Debug, Clone)]
pub enum BroadcastMessageUnion {
    NodeAnnouncement(NodeAnnouncement),
    ChannelAnnouncement(ChannelAnnouncement),
    ChannelUpdate(ChannelUpdate),
}
#[derive(Debug, Clone, Copy)]
pub enum BroadcastMessageUnionReader<'r> {
    NodeAnnouncement(NodeAnnouncementReader<'r>),
    ChannelAnnouncement(ChannelAnnouncementReader<'r>),
    ChannelUpdate(ChannelUpdateReader<'r>),
}
impl ::core::default::Default for BroadcastMessageUnion {
    fn default() -> Self {
        BroadcastMessageUnion::NodeAnnouncement(::core::default::Default::default())
    }
}
impl ::core::fmt::Display for BroadcastMessageUnion {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            BroadcastMessageUnion::NodeAnnouncement(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, NodeAnnouncement::NAME, item)
            }
            BroadcastMessageUnion::ChannelAnnouncement(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, ChannelAnnouncement::NAME, item)
            }
            BroadcastMessageUnion::ChannelUpdate(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, ChannelUpdate::NAME, item)
            }
        }
    }
}
impl<'r> ::core::fmt::Display for BroadcastMessageUnionReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            BroadcastMessageUnionReader::NodeAnnouncement(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, NodeAnnouncement::NAME, item)
            }
            BroadcastMessageUnionReader::ChannelAnnouncement(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, ChannelAnnouncement::NAME, item)
            }
            BroadcastMessageUnionReader::ChannelUpdate(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, ChannelUpdate::NAME, item)
            }
        }
    }
}
impl BroadcastMessageUnion {
    pub(crate) fn display_inner(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            BroadcastMessageUnion::NodeAnnouncement(ref item) => write!(f, "{}", item),
            BroadcastMessageUnion::ChannelAnnouncement(ref item) => write!(f, "{}", item),
            BroadcastMessageUnion::ChannelUpdate(ref item) => write!(f, "{}", item),
        }
    }
}
impl<'r> BroadcastMessageUnionReader<'r> {
    pub(crate) fn display_inner(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            BroadcastMessageUnionReader::NodeAnnouncement(ref item) => write!(f, "{}", item),
            BroadcastMessageUnionReader::ChannelAnnouncement(ref item) => write!(f, "{}", item),
            BroadcastMessageUnionReader::ChannelUpdate(ref item) => write!(f, "{}", item),
        }
    }
}
impl ::core::convert::From<NodeAnnouncement> for BroadcastMessageUnion {
    fn from(item: NodeAnnouncement) -> Self {
        BroadcastMessageUnion::NodeAnnouncement(item)
    }
}
impl ::core::convert::From<ChannelAnnouncement> for BroadcastMessageUnion {
    fn from(item: ChannelAnnouncement) -> Self {
        BroadcastMessageUnion::ChannelAnnouncement(item)
    }
}
impl ::core::convert::From<ChannelUpdate> for BroadcastMessageUnion {
    fn from(item: ChannelUpdate) -> Self {
        BroadcastMessageUnion::ChannelUpdate(item)
    }
}
impl<'r> ::core::convert::From<NodeAnnouncementReader<'r>> for BroadcastMessageUnionReader<'r> {
    fn from(item: NodeAnnouncementReader<'r>) -> Self {
        BroadcastMessageUnionReader::NodeAnnouncement(item)
    }
}
impl<'r> ::core::convert::From<ChannelAnnouncementReader<'r>> for BroadcastMessageUnionReader<'r> {
    fn from(item: ChannelAnnouncementReader<'r>) -> Self {
        BroadcastMessageUnionReader::ChannelAnnouncement(item)
    }
}
impl<'r> ::core::convert::From<ChannelUpdateReader<'r>> for BroadcastMessageUnionReader<'r> {
    fn from(item: ChannelUpdateReader<'r>) -> Self {
        BroadcastMessageUnionReader::ChannelUpdate(item)
    }
}
impl BroadcastMessageUnion {
    pub const NAME: &'static str = "BroadcastMessageUnion";
    pub fn as_bytes(&self) -> molecule::bytes::Bytes {
        match self {
            BroadcastMessageUnion::NodeAnnouncement(item) => item.as_bytes(),
            BroadcastMessageUnion::ChannelAnnouncement(item) => item.as_bytes(),
            BroadcastMessageUnion::ChannelUpdate(item) => item.as_bytes(),
        }
    }
    pub fn as_slice(&self) -> &[u8] {
        match self {
            BroadcastMessageUnion::NodeAnnouncement(item) => item.as_slice(),
            BroadcastMessageUnion::ChannelAnnouncement(item) => item.as_slice(),
            BroadcastMessageUnion::ChannelUpdate(item) => item.as_slice(),
        }
    }
    pub fn item_id(&self) -> molecule::Number {
        match self {
            BroadcastMessageUnion::NodeAnnouncement(_) => 0,
            BroadcastMessageUnion::ChannelAnnouncement(_) => 1,
            BroadcastMessageUnion::ChannelUpdate(_) => 2,
        }
    }
    pub fn item_name(&self) -> &str {
        match self {
            BroadcastMessageUnion::NodeAnnouncement(_) => "NodeAnnouncement",
            BroadcastMessageUnion::ChannelAnnouncement(_) => "ChannelAnnouncement",
            BroadcastMessageUnion::ChannelUpdate(_) => "ChannelUpdate",
        }
    }
    pub fn as_reader<'r>(&'r self) -> BroadcastMessageUnionReader<'r> {
        match self {
            BroadcastMessageUnion::NodeAnnouncement(item) => item.as_reader().into(),
            BroadcastMessageUnion::ChannelAnnouncement(item) => item.as_reader().into(),
            BroadcastMessageUnion::ChannelUpdate(item) => item.as_reader().into(),
        }
    }
}
impl<'r> BroadcastMessageUnionReader<'r> {
    pub const NAME: &'r str = "BroadcastMessageUnionReader";
    pub fn as_slice(&self) -> &'r [u8] {
        match self {
            BroadcastMessageUnionReader::NodeAnnouncement(item) => item.as_slice(),
            BroadcastMessageUnionReader::ChannelAnnouncement(item) => item.as_slice(),
            BroadcastMessageUnionReader::ChannelUpdate(item) => item.as_slice(),
        }
    }
    pub fn item_id(&self) -> molecule::Number {
        match self {
            BroadcastMessageUnionReader::NodeAnnouncement(_) => 0,
            BroadcastMessageUnionReader::ChannelAnnouncement(_) => 1,
            BroadcastMessageUnionReader::ChannelUpdate(_) => 2,
        }
    }
    pub fn item_name(&self) -> &str {
        match self {
            BroadcastMessageUnionReader::NodeAnnouncement(_) => "NodeAnnouncement",
            BroadcastMessageUnionReader::ChannelAnnouncement(_) => "ChannelAnnouncement",
            BroadcastMessageUnionReader::ChannelUpdate(_) => "ChannelUpdate",
        }
    }
}
impl From<NodeAnnouncement> for BroadcastMessage {
    fn from(value: NodeAnnouncement) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<ChannelAnnouncement> for BroadcastMessage {
    fn from(value: ChannelAnnouncement) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<ChannelUpdate> for BroadcastMessage {
    fn from(value: ChannelUpdate) -> Self {
        Self::new_builder().set(value).build()
    }
}
#[derive(Clone)]
pub struct BroadcastMessages(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for BroadcastMessages {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for BroadcastMessages {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for BroadcastMessages {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} [", Self::NAME)?;
        for i in 0..self.len() {
            if i == 0 {
                write!(f, "{}", self.get_unchecked(i))?;
            } else {
                write!(f, ", {}", self.get_unchecked(i))?;
            }
        }
        write!(f, "]")
    }
}
impl ::core::default::Default for BroadcastMessages {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        BroadcastMessages::new_unchecked(v)
    }
}
impl BroadcastMessages {
    const DEFAULT_VALUE: [u8; 4] = [4, 0, 0, 0];
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn item_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn len(&self) -> usize {
        self.item_count()
    }
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
    pub fn get(&self, idx: usize) -> Option<BroadcastMessage> {
        if idx >= self.len() {
            None
        } else {
            Some(self.get_unchecked(idx))
        }
    }
    pub fn get_unchecked(&self, idx: usize) -> BroadcastMessage {
        let slice = self.as_slice();
        let start_idx = molecule::NUMBER_SIZE * (1 + idx);
        let start = molecule::unpack_number(&slice[start_idx..]) as usize;
        if idx == self.len() - 1 {
            BroadcastMessage::new_unchecked(self.0.slice(start..))
        } else {
            let end_idx = start_idx + molecule::NUMBER_SIZE;
            let end = molecule::unpack_number(&slice[end_idx..]) as usize;
            BroadcastMessage::new_unchecked(self.0.slice(start..end))
        }
    }
    pub fn as_reader<'r>(&'r self) -> BroadcastMessagesReader<'r> {
        BroadcastMessagesReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for BroadcastMessages {
    type Builder = BroadcastMessagesBuilder;
    const NAME: &'static str = "BroadcastMessages";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        BroadcastMessages(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        BroadcastMessagesReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        BroadcastMessagesReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().extend(self.into_iter())
    }
}
#[derive(Clone, Copy)]
pub struct BroadcastMessagesReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for BroadcastMessagesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for BroadcastMessagesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for BroadcastMessagesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} [", Self::NAME)?;
        for i in 0..self.len() {
            if i == 0 {
                write!(f, "{}", self.get_unchecked(i))?;
            } else {
                write!(f, ", {}", self.get_unchecked(i))?;
            }
        }
        write!(f, "]")
    }
}
impl<'r> BroadcastMessagesReader<'r> {
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn item_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn len(&self) -> usize {
        self.item_count()
    }
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
    pub fn get(&self, idx: usize) -> Option<BroadcastMessageReader<'r>> {
        if idx >= self.len() {
            None
        } else {
            Some(self.get_unchecked(idx))
        }
    }
    pub fn get_unchecked(&self, idx: usize) -> BroadcastMessageReader<'r> {
        let slice = self.as_slice();
        let start_idx = molecule::NUMBER_SIZE * (1 + idx);
        let start = molecule::unpack_number(&slice[start_idx..]) as usize;
        if idx == self.len() - 1 {
            BroadcastMessageReader::new_unchecked(&self.as_slice()[start..])
        } else {
            let end_idx = start_idx + molecule::NUMBER_SIZE;
            let end = molecule::unpack_number(&slice[end_idx..]) as usize;
            BroadcastMessageReader::new_unchecked(&self.as_slice()[start..end])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for BroadcastMessagesReader<'r> {
    type Entity = BroadcastMessages;
    const NAME: &'static str = "BroadcastMessagesReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        BroadcastMessagesReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len == molecule::NUMBER_SIZE {
            return Ok(());
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(
                Self,
                TotalSizeNotMatch,
                molecule::NUMBER_SIZE * 2,
                slice_len
            );
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        for pair in offsets.windows(2) {
            let start = pair[0];
            let end = pair[1];
            BroadcastMessageReader::verify(&slice[start..end], compatible)?;
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct BroadcastMessagesBuilder(pub(crate) Vec<BroadcastMessage>);
impl BroadcastMessagesBuilder {
    pub fn set(mut self, v: Vec<BroadcastMessage>) -> Self {
        self.0 = v;
        self
    }
    pub fn push(mut self, v: BroadcastMessage) -> Self {
        self.0.push(v);
        self
    }
    pub fn extend<T: ::core::iter::IntoIterator<Item = BroadcastMessage>>(
        mut self,
        iter: T,
    ) -> Self {
        for elem in iter {
            self.0.push(elem);
        }
        self
    }
    pub fn replace(&mut self, index: usize, v: BroadcastMessage) -> Option<BroadcastMessage> {
        self.0
            .get_mut(index)
            .map(|item| ::core::mem::replace(item, v))
    }
}
impl molecule::prelude::Builder for BroadcastMessagesBuilder {
    type Entity = BroadcastMessages;
    const NAME: &'static str = "BroadcastMessagesBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (self.0.len() + 1)
            + self
                .0
                .iter()
                .map(|inner| inner.as_slice().len())
                .sum::<usize>()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let item_count = self.0.len();
        if item_count == 0 {
            writer.write_all(&molecule::pack_number(
                molecule::NUMBER_SIZE as molecule::Number,
            ))?;
        } else {
            let (total_size, offsets) = self.0.iter().fold(
                (
                    molecule::NUMBER_SIZE * (item_count + 1),
                    Vec::with_capacity(item_count),
                ),
                |(start, mut offsets), inner| {
                    offsets.push(start);
                    (start + inner.as_slice().len(), offsets)
                },
            );
            writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
            for offset in offsets.into_iter() {
                writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
            }
            for inner in self.0.iter() {
                writer.write_all(inner.as_slice())?;
            }
        }
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        BroadcastMessages::new_unchecked(inner.into())
    }
}
pub struct BroadcastMessagesIterator(BroadcastMessages, usize, usize);
impl ::core::iter::Iterator for BroadcastMessagesIterator {
    type Item = BroadcastMessage;
    fn next(&mut self) -> Option<Self::Item> {
        if self.1 >= self.2 {
            None
        } else {
            let ret = self.0.get_unchecked(self.1);
            self.1 += 1;
            Some(ret)
        }
    }
}
impl ::core::iter::ExactSizeIterator for BroadcastMessagesIterator {
    fn len(&self) -> usize {
        self.2 - self.1
    }
}
impl ::core::iter::IntoIterator for BroadcastMessages {
    type Item = BroadcastMessage;
    type IntoIter = BroadcastMessagesIterator;
    fn into_iter(self) -> Self::IntoIter {
        let len = self.len();
        BroadcastMessagesIterator(self, 0, len)
    }
}
impl<'r> BroadcastMessagesReader<'r> {
    pub fn iter<'t>(&'t self) -> BroadcastMessagesReaderIterator<'t, 'r> {
        BroadcastMessagesReaderIterator(&self, 0, self.len())
    }
}
pub struct BroadcastMessagesReaderIterator<'t, 'r>(&'t BroadcastMessagesReader<'r>, usize, usize);
impl<'t: 'r, 'r> ::core::iter::Iterator for BroadcastMessagesReaderIterator<'t, 'r> {
    type Item = BroadcastMessageReader<'t>;
    fn next(&mut self) -> Option<Self::Item> {
        if self.1 >= self.2 {
            None
        } else {
            let ret = self.0.get_unchecked(self.1);
            self.1 += 1;
            Some(ret)
        }
    }
}
impl<'t: 'r, 'r> ::core::iter::ExactSizeIterator for BroadcastMessagesReaderIterator<'t, 'r> {
    fn len(&self) -> usize {
        self.2 - self.1
    }
}
impl ::core::iter::FromIterator<BroadcastMessage> for BroadcastMessages {
    fn from_iter<T: IntoIterator<Item = BroadcastMessage>>(iter: T) -> Self {
        Self::new_builder().extend(iter).build()
    }
}
#[derive(Clone)]
pub struct MissingQueryIndexes(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for MissingQueryIndexes {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for MissingQueryIndexes {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for MissingQueryIndexes {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} [", Self::NAME)?;
        for i in 0..self.len() {
            if i == 0 {
                write!(f, "{}", self.get_unchecked(i))?;
            } else {
                write!(f, ", {}", self.get_unchecked(i))?;
            }
        }
        write!(f, "]")
    }
}
impl ::core::default::Default for MissingQueryIndexes {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        MissingQueryIndexes::new_unchecked(v)
    }
}
impl MissingQueryIndexes {
    const DEFAULT_VALUE: [u8; 4] = [0, 0, 0, 0];
    pub const ITEM_SIZE: usize = 2;
    pub fn total_size(&self) -> usize {
        molecule::NUMBER_SIZE + Self::ITEM_SIZE * self.item_count()
    }
    pub fn item_count(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn len(&self) -> usize {
        self.item_count()
    }
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
    pub fn get(&self, idx: usize) -> Option<Uint16> {
        if idx >= self.len() {
            None
        } else {
            Some(self.get_unchecked(idx))
        }
    }
    pub fn get_unchecked(&self, idx: usize) -> Uint16 {
        let start = molecule::NUMBER_SIZE + Self::ITEM_SIZE * idx;
        let end = start + Self::ITEM_SIZE;
        Uint16::new_unchecked(self.0.slice(start..end))
    }
    pub fn as_reader<'r>(&'r self) -> MissingQueryIndexesReader<'r> {
        MissingQueryIndexesReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for MissingQueryIndexes {
    type Builder = MissingQueryIndexesBuilder;
    const NAME: &'static str = "MissingQueryIndexes";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        MissingQueryIndexes(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        MissingQueryIndexesReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        MissingQueryIndexesReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().extend(self.into_iter())
    }
}
#[derive(Clone, Copy)]
pub struct MissingQueryIndexesReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for MissingQueryIndexesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for MissingQueryIndexesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for MissingQueryIndexesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} [", Self::NAME)?;
        for i in 0..self.len() {
            if i == 0 {
                write!(f, "{}", self.get_unchecked(i))?;
            } else {
                write!(f, ", {}", self.get_unchecked(i))?;
            }
        }
        write!(f, "]")
    }
}
impl<'r> MissingQueryIndexesReader<'r> {
    pub const ITEM_SIZE: usize = 2;
    pub fn total_size(&self) -> usize {
        molecule::NUMBER_SIZE + Self::ITEM_SIZE * self.item_count()
    }
    pub fn item_count(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn len(&self) -> usize {
        self.item_count()
    }
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
    pub fn get(&self, idx: usize) -> Option<Uint16Reader<'r>> {
        if idx >= self.len() {
            None
        } else {
            Some(self.get_unchecked(idx))
        }
    }
    pub fn get_unchecked(&self, idx: usize) -> Uint16Reader<'r> {
        let start = molecule::NUMBER_SIZE + Self::ITEM_SIZE * idx;
        let end = start + Self::ITEM_SIZE;
        Uint16Reader::new_unchecked(&self.as_slice()[start..end])
    }
}
impl<'r> molecule::prelude::Reader<'r> for MissingQueryIndexesReader<'r> {
    type Entity = MissingQueryIndexes;
    const NAME: &'static str = "MissingQueryIndexesReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        MissingQueryIndexesReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let item_count = molecule::unpack_number(slice) as usize;
        if item_count == 0 {
            if slice_len != molecule::NUMBER_SIZE {
                return ve!(Self, TotalSizeNotMatch, molecule::NUMBER_SIZE, slice_len);
            }
            return Ok(());
        }
        let total_size = molecule::NUMBER_SIZE + Self::ITEM_SIZE * item_count;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct MissingQueryIndexesBuilder(pub(crate) Vec<Uint16>);
impl MissingQueryIndexesBuilder {
    pub const ITEM_SIZE: usize = 2;
    pub fn set(mut self, v: Vec<Uint16>) -> Self {
        self.0 = v;
        self
    }
    pub fn push(mut self, v: Uint16) -> Self {
        self.0.push(v);
        self
    }
    pub fn extend<T: ::core::iter::IntoIterator<Item = Uint16>>(mut self, iter: T) -> Self {
        for elem in iter {
            self.0.push(elem);
        }
        self
    }
    pub fn replace(&mut self, index: usize, v: Uint16) -> Option<Uint16> {
        self.0
            .get_mut(index)
            .map(|item| ::core::mem::replace(item, v))
    }
}
impl molecule::prelude::Builder for MissingQueryIndexesBuilder {
    type Entity = MissingQueryIndexes;
    const NAME: &'static str = "MissingQueryIndexesBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE + Self::ITEM_SIZE * self.0.len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(&molecule::pack_number(self.0.len() as molecule::Number))?;
        for inner in &self.0[..] {
            writer.write_all(inner.as_slice())?;
        }
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        MissingQueryIndexes::new_unchecked(inner.into())
    }
}
pub struct MissingQueryIndexesIterator(MissingQueryIndexes, usize, usize);
impl ::core::iter::Iterator for MissingQueryIndexesIterator {
    type Item = Uint16;
    fn next(&mut self) -> Option<Self::Item> {
        if self.1 >= self.2 {
            None
        } else {
            let ret = self.0.get_unchecked(self.1);
            self.1 += 1;
            Some(ret)
        }
    }
}
impl ::core::iter::ExactSizeIterator for MissingQueryIndexesIterator {
    fn len(&self) -> usize {
        self.2 - self.1
    }
}
impl ::core::iter::IntoIterator for MissingQueryIndexes {
    type Item = Uint16;
    type IntoIter = MissingQueryIndexesIterator;
    fn into_iter(self) -> Self::IntoIter {
        let len = self.len();
        MissingQueryIndexesIterator(self, 0, len)
    }
}
impl<'r> MissingQueryIndexesReader<'r> {
    pub fn iter<'t>(&'t self) -> MissingQueryIndexesReaderIterator<'t, 'r> {
        MissingQueryIndexesReaderIterator(&self, 0, self.len())
    }
}
pub struct MissingQueryIndexesReaderIterator<'t, 'r>(
    &'t MissingQueryIndexesReader<'r>,
    usize,
    usize,
);
impl<'t: 'r, 'r> ::core::iter::Iterator for MissingQueryIndexesReaderIterator<'t, 'r> {
    type Item = Uint16Reader<'t>;
    fn next(&mut self) -> Option<Self::Item> {
        if self.1 >= self.2 {
            None
        } else {
            let ret = self.0.get_unchecked(self.1);
            self.1 += 1;
            Some(ret)
        }
    }
}
impl<'t: 'r, 'r> ::core::iter::ExactSizeIterator for MissingQueryIndexesReaderIterator<'t, 'r> {
    fn len(&self) -> usize {
        self.2 - self.1
    }
}
impl ::core::iter::FromIterator<Uint16> for MissingQueryIndexes {
    fn from_iter<T: IntoIterator<Item = Uint16>>(iter: T) -> Self {
        Self::new_builder().extend(iter).build()
    }
}
#[derive(Clone)]
pub struct BroadcastMessagesFilter(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for BroadcastMessagesFilter {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for BroadcastMessagesFilter {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for BroadcastMessagesFilter {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "chain_hash", self.chain_hash())?;
        write!(f, ", {}: {}", "after_cursor", self.after_cursor())?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for BroadcastMessagesFilter {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        BroadcastMessagesFilter::new_unchecked(v)
    }
}
impl BroadcastMessagesFilter {
    const DEFAULT_VALUE: [u8; 77] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const TOTAL_SIZE: usize = 77;
    pub const FIELD_SIZES: [usize; 2] = [32, 45];
    pub const FIELD_COUNT: usize = 2;
    pub fn chain_hash(&self) -> Byte32 {
        Byte32::new_unchecked(self.0.slice(0..32))
    }
    pub fn after_cursor(&self) -> Cursor {
        Cursor::new_unchecked(self.0.slice(32..77))
    }
    pub fn as_reader<'r>(&'r self) -> BroadcastMessagesFilterReader<'r> {
        BroadcastMessagesFilterReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for BroadcastMessagesFilter {
    type Builder = BroadcastMessagesFilterBuilder;
    const NAME: &'static str = "BroadcastMessagesFilter";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        BroadcastMessagesFilter(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        BroadcastMessagesFilterReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        BroadcastMessagesFilterReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .chain_hash(self.chain_hash())
            .after_cursor(self.after_cursor())
    }
}
#[derive(Clone, Copy)]
pub struct BroadcastMessagesFilterReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for BroadcastMessagesFilterReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for BroadcastMessagesFilterReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for BroadcastMessagesFilterReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "chain_hash", self.chain_hash())?;
        write!(f, ", {}: {}", "after_cursor", self.after_cursor())?;
        write!(f, " }}")
    }
}
impl<'r> BroadcastMessagesFilterReader<'r> {
    pub const TOTAL_SIZE: usize = 77;
    pub const FIELD_SIZES: [usize; 2] = [32, 45];
    pub const FIELD_COUNT: usize = 2;
    pub fn chain_hash(&self) -> Byte32Reader<'r> {
        Byte32Reader::new_unchecked(&self.as_slice()[0..32])
    }
    pub fn after_cursor(&self) -> CursorReader<'r> {
        CursorReader::new_unchecked(&self.as_slice()[32..77])
    }
}
impl<'r> molecule::prelude::Reader<'r> for BroadcastMessagesFilterReader<'r> {
    type Entity = BroadcastMessagesFilter;
    const NAME: &'static str = "BroadcastMessagesFilterReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        BroadcastMessagesFilterReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct BroadcastMessagesFilterBuilder {
    pub(crate) chain_hash: Byte32,
    pub(crate) after_cursor: Cursor,
}
impl BroadcastMessagesFilterBuilder {
    pub const TOTAL_SIZE: usize = 77;
    pub const FIELD_SIZES: [usize; 2] = [32, 45];
    pub const FIELD_COUNT: usize = 2;
    pub fn chain_hash(mut self, v: Byte32) -> Self {
        self.chain_hash = v;
        self
    }
    pub fn after_cursor(mut self, v: Cursor) -> Self {
        self.after_cursor = v;
        self
    }
}
impl molecule::prelude::Builder for BroadcastMessagesFilterBuilder {
    type Entity = BroadcastMessagesFilter;
    const NAME: &'static str = "BroadcastMessagesFilterBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.chain_hash.as_slice())?;
        writer.write_all(self.after_cursor.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        BroadcastMessagesFilter::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct GetBroadcastMessages(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for GetBroadcastMessages {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for GetBroadcastMessages {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for GetBroadcastMessages {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "id", self.id())?;
        write!(f, ", {}: {}", "chain_hash", self.chain_hash())?;
        write!(f, ", {}: {}", "after_cursor", self.after_cursor())?;
        write!(f, ", {}: {}", "count", self.count())?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for GetBroadcastMessages {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        GetBroadcastMessages::new_unchecked(v)
    }
}
impl GetBroadcastMessages {
    const DEFAULT_VALUE: [u8; 87] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const TOTAL_SIZE: usize = 87;
    pub const FIELD_SIZES: [usize; 4] = [8, 32, 45, 2];
    pub const FIELD_COUNT: usize = 4;
    pub fn id(&self) -> Uint64 {
        Uint64::new_unchecked(self.0.slice(0..8))
    }
    pub fn chain_hash(&self) -> Byte32 {
        Byte32::new_unchecked(self.0.slice(8..40))
    }
    pub fn after_cursor(&self) -> Cursor {
        Cursor::new_unchecked(self.0.slice(40..85))
    }
    pub fn count(&self) -> Uint16 {
        Uint16::new_unchecked(self.0.slice(85..87))
    }
    pub fn as_reader<'r>(&'r self) -> GetBroadcastMessagesReader<'r> {
        GetBroadcastMessagesReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for GetBroadcastMessages {
    type Builder = GetBroadcastMessagesBuilder;
    const NAME: &'static str = "GetBroadcastMessages";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        GetBroadcastMessages(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        GetBroadcastMessagesReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        GetBroadcastMessagesReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .id(self.id())
            .chain_hash(self.chain_hash())
            .after_cursor(self.after_cursor())
            .count(self.count())
    }
}
#[derive(Clone, Copy)]
pub struct GetBroadcastMessagesReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for GetBroadcastMessagesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for GetBroadcastMessagesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for GetBroadcastMessagesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "id", self.id())?;
        write!(f, ", {}: {}", "chain_hash", self.chain_hash())?;
        write!(f, ", {}: {}", "after_cursor", self.after_cursor())?;
        write!(f, ", {}: {}", "count", self.count())?;
        write!(f, " }}")
    }
}
impl<'r> GetBroadcastMessagesReader<'r> {
    pub const TOTAL_SIZE: usize = 87;
    pub const FIELD_SIZES: [usize; 4] = [8, 32, 45, 2];
    pub const FIELD_COUNT: usize = 4;
    pub fn id(&self) -> Uint64Reader<'r> {
        Uint64Reader::new_unchecked(&self.as_slice()[0..8])
    }
    pub fn chain_hash(&self) -> Byte32Reader<'r> {
        Byte32Reader::new_unchecked(&self.as_slice()[8..40])
    }
    pub fn after_cursor(&self) -> CursorReader<'r> {
        CursorReader::new_unchecked(&self.as_slice()[40..85])
    }
    pub fn count(&self) -> Uint16Reader<'r> {
        Uint16Reader::new_unchecked(&self.as_slice()[85..87])
    }
}
impl<'r> molecule::prelude::Reader<'r> for GetBroadcastMessagesReader<'r> {
    type Entity = GetBroadcastMessages;
    const NAME: &'static str = "GetBroadcastMessagesReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        GetBroadcastMessagesReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct GetBroadcastMessagesBuilder {
    pub(crate) id: Uint64,
    pub(crate) chain_hash: Byte32,
    pub(crate) after_cursor: Cursor,
    pub(crate) count: Uint16,
}
impl GetBroadcastMessagesBuilder {
    pub const TOTAL_SIZE: usize = 87;
    pub const FIELD_SIZES: [usize; 4] = [8, 32, 45, 2];
    pub const FIELD_COUNT: usize = 4;
    pub fn id(mut self, v: Uint64) -> Self {
        self.id = v;
        self
    }
    pub fn chain_hash(mut self, v: Byte32) -> Self {
        self.chain_hash = v;
        self
    }
    pub fn after_cursor(mut self, v: Cursor) -> Self {
        self.after_cursor = v;
        self
    }
    pub fn count(mut self, v: Uint16) -> Self {
        self.count = v;
        self
    }
}
impl molecule::prelude::Builder for GetBroadcastMessagesBuilder {
    type Entity = GetBroadcastMessages;
    const NAME: &'static str = "GetBroadcastMessagesBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.id.as_slice())?;
        writer.write_all(self.chain_hash.as_slice())?;
        writer.write_all(self.after_cursor.as_slice())?;
        writer.write_all(self.count.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        GetBroadcastMessages::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct QueryBroadcastMessages(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for QueryBroadcastMessages {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for QueryBroadcastMessages {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for QueryBroadcastMessages {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "id", self.id())?;
        write!(f, ", {}: {}", "chain_hash", self.chain_hash())?;
        write!(f, ", {}: {}", "queries", self.queries())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for QueryBroadcastMessages {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        QueryBroadcastMessages::new_unchecked(v)
    }
}
impl QueryBroadcastMessages {
    const DEFAULT_VALUE: [u8; 60] = [
        60, 0, 0, 0, 16, 0, 0, 0, 24, 0, 0, 0, 56, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0,
    ];
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn id(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn chain_hash(&self) -> Byte32 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Byte32::new_unchecked(self.0.slice(start..end))
    }
    pub fn queries(&self) -> BroadcastMessageQueries {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            BroadcastMessageQueries::new_unchecked(self.0.slice(start..end))
        } else {
            BroadcastMessageQueries::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> QueryBroadcastMessagesReader<'r> {
        QueryBroadcastMessagesReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for QueryBroadcastMessages {
    type Builder = QueryBroadcastMessagesBuilder;
    const NAME: &'static str = "QueryBroadcastMessages";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        QueryBroadcastMessages(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        QueryBroadcastMessagesReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        QueryBroadcastMessagesReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .id(self.id())
            .chain_hash(self.chain_hash())
            .queries(self.queries())
    }
}
#[derive(Clone, Copy)]
pub struct QueryBroadcastMessagesReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for QueryBroadcastMessagesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for QueryBroadcastMessagesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for QueryBroadcastMessagesReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "id", self.id())?;
        write!(f, ", {}: {}", "chain_hash", self.chain_hash())?;
        write!(f, ", {}: {}", "queries", self.queries())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> QueryBroadcastMessagesReader<'r> {
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn id(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn chain_hash(&self) -> Byte32Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        Byte32Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn queries(&self) -> BroadcastMessageQueriesReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            BroadcastMessageQueriesReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            BroadcastMessageQueriesReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for QueryBroadcastMessagesReader<'r> {
    type Entity = QueryBroadcastMessages;
    const NAME: &'static str = "QueryBroadcastMessagesReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        QueryBroadcastMessagesReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Uint64Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Byte32Reader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        BroadcastMessageQueriesReader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct QueryBroadcastMessagesBuilder {
    pub(crate) id: Uint64,
    pub(crate) chain_hash: Byte32,
    pub(crate) queries: BroadcastMessageQueries,
}
impl QueryBroadcastMessagesBuilder {
    pub const FIELD_COUNT: usize = 3;
    pub fn id(mut self, v: Uint64) -> Self {
        self.id = v;
        self
    }
    pub fn chain_hash(mut self, v: Byte32) -> Self {
        self.chain_hash = v;
        self
    }
    pub fn queries(mut self, v: BroadcastMessageQueries) -> Self {
        self.queries = v;
        self
    }
}
impl molecule::prelude::Builder for QueryBroadcastMessagesBuilder {
    type Entity = QueryBroadcastMessages;
    const NAME: &'static str = "QueryBroadcastMessagesBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.id.as_slice().len()
            + self.chain_hash.as_slice().len()
            + self.queries.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.id.as_slice().len();
        offsets.push(total_size);
        total_size += self.chain_hash.as_slice().len();
        offsets.push(total_size);
        total_size += self.queries.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.id.as_slice())?;
        writer.write_all(self.chain_hash.as_slice())?;
        writer.write_all(self.queries.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        QueryBroadcastMessages::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct BroadcastMessagesFilterResult(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for BroadcastMessagesFilterResult {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for BroadcastMessagesFilterResult {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for BroadcastMessagesFilterResult {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "messages", self.messages())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for BroadcastMessagesFilterResult {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        BroadcastMessagesFilterResult::new_unchecked(v)
    }
}
impl BroadcastMessagesFilterResult {
    const DEFAULT_VALUE: [u8; 12] = [12, 0, 0, 0, 8, 0, 0, 0, 4, 0, 0, 0];
    pub const FIELD_COUNT: usize = 1;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn messages(&self) -> BroadcastMessages {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[8..]) as usize;
            BroadcastMessages::new_unchecked(self.0.slice(start..end))
        } else {
            BroadcastMessages::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> BroadcastMessagesFilterResultReader<'r> {
        BroadcastMessagesFilterResultReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for BroadcastMessagesFilterResult {
    type Builder = BroadcastMessagesFilterResultBuilder;
    const NAME: &'static str = "BroadcastMessagesFilterResult";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        BroadcastMessagesFilterResult(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        BroadcastMessagesFilterResultReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        BroadcastMessagesFilterResultReader::from_compatible_slice(slice)
            .map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().messages(self.messages())
    }
}
#[derive(Clone, Copy)]
pub struct BroadcastMessagesFilterResultReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for BroadcastMessagesFilterResultReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for BroadcastMessagesFilterResultReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for BroadcastMessagesFilterResultReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "messages", self.messages())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> BroadcastMessagesFilterResultReader<'r> {
    pub const FIELD_COUNT: usize = 1;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn messages(&self) -> BroadcastMessagesReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[8..]) as usize;
            BroadcastMessagesReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            BroadcastMessagesReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for BroadcastMessagesFilterResultReader<'r> {
    type Entity = BroadcastMessagesFilterResult;
    const NAME: &'static str = "BroadcastMessagesFilterResultReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        BroadcastMessagesFilterResultReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        BroadcastMessagesReader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct BroadcastMessagesFilterResultBuilder {
    pub(crate) messages: BroadcastMessages,
}
impl BroadcastMessagesFilterResultBuilder {
    pub const FIELD_COUNT: usize = 1;
    pub fn messages(mut self, v: BroadcastMessages) -> Self {
        self.messages = v;
        self
    }
}
impl molecule::prelude::Builder for BroadcastMessagesFilterResultBuilder {
    type Entity = BroadcastMessagesFilterResult;
    const NAME: &'static str = "BroadcastMessagesFilterResultBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1) + self.messages.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.messages.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.messages.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        BroadcastMessagesFilterResult::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct GetBroadcastMessagesResult(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for GetBroadcastMessagesResult {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for GetBroadcastMessagesResult {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for GetBroadcastMessagesResult {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "id", self.id())?;
        write!(f, ", {}: {}", "messages", self.messages())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for GetBroadcastMessagesResult {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        GetBroadcastMessagesResult::new_unchecked(v)
    }
}
impl GetBroadcastMessagesResult {
    const DEFAULT_VALUE: [u8; 24] = [
        24, 0, 0, 0, 12, 0, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 2;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn id(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn messages(&self) -> BroadcastMessages {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[12..]) as usize;
            BroadcastMessages::new_unchecked(self.0.slice(start..end))
        } else {
            BroadcastMessages::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> GetBroadcastMessagesResultReader<'r> {
        GetBroadcastMessagesResultReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for GetBroadcastMessagesResult {
    type Builder = GetBroadcastMessagesResultBuilder;
    const NAME: &'static str = "GetBroadcastMessagesResult";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        GetBroadcastMessagesResult(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        GetBroadcastMessagesResultReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        GetBroadcastMessagesResultReader::from_compatible_slice(slice)
            .map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().id(self.id()).messages(self.messages())
    }
}
#[derive(Clone, Copy)]
pub struct GetBroadcastMessagesResultReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for GetBroadcastMessagesResultReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for GetBroadcastMessagesResultReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for GetBroadcastMessagesResultReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "id", self.id())?;
        write!(f, ", {}: {}", "messages", self.messages())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> GetBroadcastMessagesResultReader<'r> {
    pub const FIELD_COUNT: usize = 2;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn id(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn messages(&self) -> BroadcastMessagesReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[12..]) as usize;
            BroadcastMessagesReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            BroadcastMessagesReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for GetBroadcastMessagesResultReader<'r> {
    type Entity = GetBroadcastMessagesResult;
    const NAME: &'static str = "GetBroadcastMessagesResultReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        GetBroadcastMessagesResultReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Uint64Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        BroadcastMessagesReader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct GetBroadcastMessagesResultBuilder {
    pub(crate) id: Uint64,
    pub(crate) messages: BroadcastMessages,
}
impl GetBroadcastMessagesResultBuilder {
    pub const FIELD_COUNT: usize = 2;
    pub fn id(mut self, v: Uint64) -> Self {
        self.id = v;
        self
    }
    pub fn messages(mut self, v: BroadcastMessages) -> Self {
        self.messages = v;
        self
    }
}
impl molecule::prelude::Builder for GetBroadcastMessagesResultBuilder {
    type Entity = GetBroadcastMessagesResult;
    const NAME: &'static str = "GetBroadcastMessagesResultBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.id.as_slice().len()
            + self.messages.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.id.as_slice().len();
        offsets.push(total_size);
        total_size += self.messages.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.id.as_slice())?;
        writer.write_all(self.messages.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        GetBroadcastMessagesResult::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct QueryBroadcastMessagesResult(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for QueryBroadcastMessagesResult {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for QueryBroadcastMessagesResult {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for QueryBroadcastMessagesResult {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "id", self.id())?;
        write!(f, ", {}: {}", "messages", self.messages())?;
        write!(f, ", {}: {}", "missing_queries", self.missing_queries())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for QueryBroadcastMessagesResult {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        QueryBroadcastMessagesResult::new_unchecked(v)
    }
}
impl QueryBroadcastMessagesResult {
    const DEFAULT_VALUE: [u8; 32] = [
        32, 0, 0, 0, 16, 0, 0, 0, 24, 0, 0, 0, 28, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0,
        0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn id(&self) -> Uint64 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Uint64::new_unchecked(self.0.slice(start..end))
    }
    pub fn messages(&self) -> BroadcastMessages {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        BroadcastMessages::new_unchecked(self.0.slice(start..end))
    }
    pub fn missing_queries(&self) -> MissingQueryIndexes {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            MissingQueryIndexes::new_unchecked(self.0.slice(start..end))
        } else {
            MissingQueryIndexes::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> QueryBroadcastMessagesResultReader<'r> {
        QueryBroadcastMessagesResultReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for QueryBroadcastMessagesResult {
    type Builder = QueryBroadcastMessagesResultBuilder;
    const NAME: &'static str = "QueryBroadcastMessagesResult";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        QueryBroadcastMessagesResult(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        QueryBroadcastMessagesResultReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        QueryBroadcastMessagesResultReader::from_compatible_slice(slice)
            .map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .id(self.id())
            .messages(self.messages())
            .missing_queries(self.missing_queries())
    }
}
#[derive(Clone, Copy)]
pub struct QueryBroadcastMessagesResultReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for QueryBroadcastMessagesResultReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for QueryBroadcastMessagesResultReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for QueryBroadcastMessagesResultReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "id", self.id())?;
        write!(f, ", {}: {}", "messages", self.messages())?;
        write!(f, ", {}: {}", "missing_queries", self.missing_queries())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> QueryBroadcastMessagesResultReader<'r> {
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn id(&self) -> Uint64Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Uint64Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn messages(&self) -> BroadcastMessagesReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        BroadcastMessagesReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn missing_queries(&self) -> MissingQueryIndexesReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            MissingQueryIndexesReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            MissingQueryIndexesReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for QueryBroadcastMessagesResultReader<'r> {
    type Entity = QueryBroadcastMessagesResult;
    const NAME: &'static str = "QueryBroadcastMessagesResultReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        QueryBroadcastMessagesResultReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Uint64Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        BroadcastMessagesReader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        MissingQueryIndexesReader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct QueryBroadcastMessagesResultBuilder {
    pub(crate) id: Uint64,
    pub(crate) messages: BroadcastMessages,
    pub(crate) missing_queries: MissingQueryIndexes,
}
impl QueryBroadcastMessagesResultBuilder {
    pub const FIELD_COUNT: usize = 3;
    pub fn id(mut self, v: Uint64) -> Self {
        self.id = v;
        self
    }
    pub fn messages(mut self, v: BroadcastMessages) -> Self {
        self.messages = v;
        self
    }
    pub fn missing_queries(mut self, v: MissingQueryIndexes) -> Self {
        self.missing_queries = v;
        self
    }
}
impl molecule::prelude::Builder for QueryBroadcastMessagesResultBuilder {
    type Entity = QueryBroadcastMessagesResult;
    const NAME: &'static str = "QueryBroadcastMessagesResultBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.id.as_slice().len()
            + self.messages.as_slice().len()
            + self.missing_queries.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.id.as_slice().len();
        offsets.push(total_size);
        total_size += self.messages.as_slice().len();
        offsets.push(total_size);
        total_size += self.missing_queries.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.id.as_slice())?;
        writer.write_all(self.messages.as_slice())?;
        writer.write_all(self.missing_queries.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        QueryBroadcastMessagesResult::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct GossipMessage(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for GossipMessage {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for GossipMessage {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for GossipMessage {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}(", Self::NAME)?;
        self.to_enum().display_inner(f)?;
        write!(f, ")")
    }
}
impl ::core::default::Default for GossipMessage {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        GossipMessage::new_unchecked(v)
    }
}
impl GossipMessage {
    const DEFAULT_VALUE: [u8; 81] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const ITEMS_COUNT: usize = 6;
    pub fn item_id(&self) -> molecule::Number {
        molecule::unpack_number(self.as_slice())
    }
    pub fn to_enum(&self) -> GossipMessageUnion {
        let inner = self.0.slice(molecule::NUMBER_SIZE..);
        match self.item_id() {
            0 => BroadcastMessagesFilter::new_unchecked(inner).into(),
            1 => BroadcastMessagesFilterResult::new_unchecked(inner).into(),
            2 => GetBroadcastMessages::new_unchecked(inner).into(),
            3 => GetBroadcastMessagesResult::new_unchecked(inner).into(),
            4 => QueryBroadcastMessages::new_unchecked(inner).into(),
            5 => QueryBroadcastMessagesResult::new_unchecked(inner).into(),
            _ => panic!("{}: invalid data", Self::NAME),
        }
    }
    pub fn as_reader<'r>(&'r self) -> GossipMessageReader<'r> {
        GossipMessageReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for GossipMessage {
    type Builder = GossipMessageBuilder;
    const NAME: &'static str = "GossipMessage";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        GossipMessage(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        GossipMessageReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        GossipMessageReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_enum())
    }
}
#[derive(Clone, Copy)]
pub struct GossipMessageReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for GossipMessageReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for GossipMessageReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for GossipMessageReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}(", Self::NAME)?;
        self.to_enum().display_inner(f)?;
        write!(f, ")")
    }
}
impl<'r> GossipMessageReader<'r> {
    pub const ITEMS_COUNT: usize = 6;
    pub fn item_id(&self) -> molecule::Number {
        molecule::unpack_number(self.as_slice())
    }
    pub fn to_enum(&self) -> GossipMessageUnionReader<'r> {
        let inner = &self.as_slice()[molecule::NUMBER_SIZE..];
        match self.item_id() {
            0 => BroadcastMessagesFilterReader::new_unchecked(inner).into(),
            1 => BroadcastMessagesFilterResultReader::new_unchecked(inner).into(),
            2 => GetBroadcastMessagesReader::new_unchecked(inner).into(),
            3 => GetBroadcastMessagesResultReader::new_unchecked(inner).into(),
            4 => QueryBroadcastMessagesReader::new_unchecked(inner).into(),
            5 => QueryBroadcastMessagesResultReader::new_unchecked(inner).into(),
            _ => panic!("{}: invalid data", Self::NAME),
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for GossipMessageReader<'r> {
    type Entity = GossipMessage;
    const NAME: &'static str = "GossipMessageReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        GossipMessageReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let item_id = molecule::unpack_number(slice);
        let inner_slice = &slice[molecule::NUMBER_SIZE..];
        match item_id {
            0 => BroadcastMessagesFilterReader::verify(inner_slice, compatible),
            1 => BroadcastMessagesFilterResultReader::verify(inner_slice, compatible),
            2 => GetBroadcastMessagesReader::verify(inner_slice, compatible),
            3 => GetBroadcastMessagesResultReader::verify(inner_slice, compatible),
            4 => QueryBroadcastMessagesReader::verify(inner_slice, compatible),
            5 => QueryBroadcastMessagesResultReader::verify(inner_slice, compatible),
            _ => ve!(Self, UnknownItem, Self::ITEMS_COUNT, item_id),
        }?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct GossipMessageBuilder(pub(crate) GossipMessageUnion);
impl GossipMessageBuilder {
    pub const ITEMS_COUNT: usize = 6;
    pub fn set<I>(mut self, v: I) -> Self
    where
        I: ::core::convert::Into<GossipMessageUnion>,
    {
        self.0 = v.into();
        self
    }
}
impl molecule::prelude::Builder for GossipMessageBuilder {
    type Entity = GossipMessage;
    const NAME: &'static str = "GossipMessageBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE + self.0.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(&molecule::pack_number(self.0.item_id()))?;
        writer.write_all(self.0.as_slice())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        GossipMessage::new_unchecked(inner.into())
    }
}
#[derive(Debug, Clone)]
pub enum GossipMessageUnion {
    BroadcastMessagesFilter(BroadcastMessagesFilter),
    BroadcastMessagesFilterResult(BroadcastMessagesFilterResult),
    GetBroadcastMessages(GetBroadcastMessages),
    GetBroadcastMessagesResult(GetBroadcastMessagesResult),
    QueryBroadcastMessages(QueryBroadcastMessages),
    QueryBroadcastMessagesResult(QueryBroadcastMessagesResult),
}
#[derive(Debug, Clone, Copy)]
pub enum GossipMessageUnionReader<'r> {
    BroadcastMessagesFilter(BroadcastMessagesFilterReader<'r>),
    BroadcastMessagesFilterResult(BroadcastMessagesFilterResultReader<'r>),
    GetBroadcastMessages(GetBroadcastMessagesReader<'r>),
    GetBroadcastMessagesResult(GetBroadcastMessagesResultReader<'r>),
    QueryBroadcastMessages(QueryBroadcastMessagesReader<'r>),
    QueryBroadcastMessagesResult(QueryBroadcastMessagesResultReader<'r>),
}
impl ::core::default::Default for GossipMessageUnion {
    fn default() -> Self {
        GossipMessageUnion::BroadcastMessagesFilter(::core::default::Default::default())
    }
}
impl ::core::fmt::Display for GossipMessageUnion {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            GossipMessageUnion::BroadcastMessagesFilter(ref item) => {
                write!(
                    f,
                    "{}::{}({})",
                    Self::NAME,
                    BroadcastMessagesFilter::NAME,
                    item
                )
            }
            GossipMessageUnion::BroadcastMessagesFilterResult(ref item) => {
                write!(
                    f,
                    "{}::{}({})",
                    Self::NAME,
                    BroadcastMessagesFilterResult::NAME,
                    item
                )
            }
            GossipMessageUnion::GetBroadcastMessages(ref item) => {
                write!(
                    f,
                    "{}::{}({})",
                    Self::NAME,
                    GetBroadcastMessages::NAME,
                    item
                )
            }
            GossipMessageUnion::GetBroadcastMessagesResult(ref item) => {
                write!(
                    f,
                    "{}::{}({})",
                    Self::NAME,
                    GetBroadcastMessagesResult::NAME,
                    item
                )
            }
            GossipMessageUnion::QueryBroadcastMessages(ref item) => {
                write!(
                    f,
                    "{}::{}({})",
                    Self::NAME,
                    QueryBroadcastMessages::NAME,
                    item
                )
            }
            GossipMessageUnion::QueryBroadcastMessagesResult(ref item) => {
                write!(
                    f,
                    "{}::{}({})",
                    Self::NAME,
                    QueryBroadcastMessagesResult::NAME,
                    item
                )
            }
        }
    }
}
impl<'r> ::core::fmt::Display for GossipMessageUnionReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            GossipMessageUnionReader::BroadcastMessagesFilter(ref item) => {
                write!(
                    f,
                    "{}::{}({})",
                    Self::NAME,
                    BroadcastMessagesFilter::NAME,
                    item
                )
            }
            GossipMessageUnionReader::BroadcastMessagesFilterResult(ref item) => {
                write!(
                    f,
                    "{}::{}({})",
                    Self::NAME,
                    BroadcastMessagesFilterResult::NAME,
                    item
                )
            }
            GossipMessageUnionReader::GetBroadcastMessages(ref item) => {
                write!(
                    f,
                    "{}::{}({})",
                    Self::NAME,
                    GetBroadcastMessages::NAME,
                    item
                )
            }
            GossipMessageUnionReader::GetBroadcastMessagesResult(ref item) => {
                write!(
                    f,
                    "{}::{}({})",
                    Self::NAME,
                    GetBroadcastMessagesResult::NAME,
                    item
                )
            }
            GossipMessageUnionReader::QueryBroadcastMessages(ref item) => {
                write!(
                    f,
                    "{}::{}({})",
                    Self::NAME,
                    QueryBroadcastMessages::NAME,
                    item
                )
            }
            GossipMessageUnionReader::QueryBroadcastMessagesResult(ref item) => {
                write!(
                    f,
                    "{}::{}({})",
                    Self::NAME,
                    QueryBroadcastMessagesResult::NAME,
                    item
                )
            }
        }
    }
}
impl GossipMessageUnion {
    pub(crate) fn display_inner(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            GossipMessageUnion::BroadcastMessagesFilter(ref item) => write!(f, "{}", item),
            GossipMessageUnion::BroadcastMessagesFilterResult(ref item) => write!(f, "{}", item),
            GossipMessageUnion::GetBroadcastMessages(ref item) => write!(f, "{}", item),
            GossipMessageUnion::GetBroadcastMessagesResult(ref item) => write!(f, "{}", item),
            GossipMessageUnion::QueryBroadcastMessages(ref item) => write!(f, "{}", item),
            GossipMessageUnion::QueryBroadcastMessagesResult(ref item) => write!(f, "{}", item),
        }
    }
}
impl<'r> GossipMessageUnionReader<'r> {
    pub(crate) fn display_inner(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            GossipMessageUnionReader::BroadcastMessagesFilter(ref item) => write!(f, "{}", item),
            GossipMessageUnionReader::BroadcastMessagesFilterResult(ref item) => {
                write!(f, "{}", item)
            }
            GossipMessageUnionReader::GetBroadcastMessages(ref item) => write!(f, "{}", item),
            GossipMessageUnionReader::GetBroadcastMessagesResult(ref item) => write!(f, "{}", item),
            GossipMessageUnionReader::QueryBroadcastMessages(ref item) => write!(f, "{}", item),
            GossipMessageUnionReader::QueryBroadcastMessagesResult(ref item) => {
                write!(f, "{}", item)
            }
        }
    }
}
impl ::core::convert::From<BroadcastMessagesFilter> for GossipMessageUnion {
    fn from(item: BroadcastMessagesFilter) -> Self {
        GossipMessageUnion::BroadcastMessagesFilter(item)
    }
}
impl ::core::convert::From<BroadcastMessagesFilterResult> for GossipMessageUnion {
    fn from(item: BroadcastMessagesFilterResult) -> Self {
        GossipMessageUnion::BroadcastMessagesFilterResult(item)
    }
}
impl ::core::convert::From<GetBroadcastMessages> for GossipMessageUnion {
    fn from(item: GetBroadcastMessages) -> Self {
        GossipMessageUnion::GetBroadcastMessages(item)
    }
}
impl ::core::convert::From<GetBroadcastMessagesResult> for GossipMessageUnion {
    fn from(item: GetBroadcastMessagesResult) -> Self {
        GossipMessageUnion::GetBroadcastMessagesResult(item)
    }
}
impl ::core::convert::From<QueryBroadcastMessages> for GossipMessageUnion {
    fn from(item: QueryBroadcastMessages) -> Self {
        GossipMessageUnion::QueryBroadcastMessages(item)
    }
}
impl ::core::convert::From<QueryBroadcastMessagesResult> for GossipMessageUnion {
    fn from(item: QueryBroadcastMessagesResult) -> Self {
        GossipMessageUnion::QueryBroadcastMessagesResult(item)
    }
}
impl<'r> ::core::convert::From<BroadcastMessagesFilterReader<'r>> for GossipMessageUnionReader<'r> {
    fn from(item: BroadcastMessagesFilterReader<'r>) -> Self {
        GossipMessageUnionReader::BroadcastMessagesFilter(item)
    }
}
impl<'r> ::core::convert::From<BroadcastMessagesFilterResultReader<'r>>
    for GossipMessageUnionReader<'r>
{
    fn from(item: BroadcastMessagesFilterResultReader<'r>) -> Self {
        GossipMessageUnionReader::BroadcastMessagesFilterResult(item)
    }
}
impl<'r> ::core::convert::From<GetBroadcastMessagesReader<'r>> for GossipMessageUnionReader<'r> {
    fn from(item: GetBroadcastMessagesReader<'r>) -> Self {
        GossipMessageUnionReader::GetBroadcastMessages(item)
    }
}
impl<'r> ::core::convert::From<GetBroadcastMessagesResultReader<'r>>
    for GossipMessageUnionReader<'r>
{
    fn from(item: GetBroadcastMessagesResultReader<'r>) -> Self {
        GossipMessageUnionReader::GetBroadcastMessagesResult(item)
    }
}
impl<'r> ::core::convert::From<QueryBroadcastMessagesReader<'r>> for GossipMessageUnionReader<'r> {
    fn from(item: QueryBroadcastMessagesReader<'r>) -> Self {
        GossipMessageUnionReader::QueryBroadcastMessages(item)
    }
}
impl<'r> ::core::convert::From<QueryBroadcastMessagesResultReader<'r>>
    for GossipMessageUnionReader<'r>
{
    fn from(item: QueryBroadcastMessagesResultReader<'r>) -> Self {
        GossipMessageUnionReader::QueryBroadcastMessagesResult(item)
    }
}
impl GossipMessageUnion {
    pub const NAME: &'static str = "GossipMessageUnion";
    pub fn as_bytes(&self) -> molecule::bytes::Bytes {
        match self {
            GossipMessageUnion::BroadcastMessagesFilter(item) => item.as_bytes(),
            GossipMessageUnion::BroadcastMessagesFilterResult(item) => item.as_bytes(),
            GossipMessageUnion::GetBroadcastMessages(item) => item.as_bytes(),
            GossipMessageUnion::GetBroadcastMessagesResult(item) => item.as_bytes(),
            GossipMessageUnion::QueryBroadcastMessages(item) => item.as_bytes(),
            GossipMessageUnion::QueryBroadcastMessagesResult(item) => item.as_bytes(),
        }
    }
    pub fn as_slice(&self) -> &[u8] {
        match self {
            GossipMessageUnion::BroadcastMessagesFilter(item) => item.as_slice(),
            GossipMessageUnion::BroadcastMessagesFilterResult(item) => item.as_slice(),
            GossipMessageUnion::GetBroadcastMessages(item) => item.as_slice(),
            GossipMessageUnion::GetBroadcastMessagesResult(item) => item.as_slice(),
            GossipMessageUnion::QueryBroadcastMessages(item) => item.as_slice(),
            GossipMessageUnion::QueryBroadcastMessagesResult(item) => item.as_slice(),
        }
    }
    pub fn item_id(&self) -> molecule::Number {
        match self {
            GossipMessageUnion::BroadcastMessagesFilter(_) => 0,
            GossipMessageUnion::BroadcastMessagesFilterResult(_) => 1,
            GossipMessageUnion::GetBroadcastMessages(_) => 2,
            GossipMessageUnion::GetBroadcastMessagesResult(_) => 3,
            GossipMessageUnion::QueryBroadcastMessages(_) => 4,
            GossipMessageUnion::QueryBroadcastMessagesResult(_) => 5,
        }
    }
    pub fn item_name(&self) -> &str {
        match self {
            GossipMessageUnion::BroadcastMessagesFilter(_) => "BroadcastMessagesFilter",
            GossipMessageUnion::BroadcastMessagesFilterResult(_) => "BroadcastMessagesFilterResult",
            GossipMessageUnion::GetBroadcastMessages(_) => "GetBroadcastMessages",
            GossipMessageUnion::GetBroadcastMessagesResult(_) => "GetBroadcastMessagesResult",
            GossipMessageUnion::QueryBroadcastMessages(_) => "QueryBroadcastMessages",
            GossipMessageUnion::QueryBroadcastMessagesResult(_) => "QueryBroadcastMessagesResult",
        }
    }
    pub fn as_reader<'r>(&'r self) -> GossipMessageUnionReader<'r> {
        match self {
            GossipMessageUnion::BroadcastMessagesFilter(item) => item.as_reader().into(),
            GossipMessageUnion::BroadcastMessagesFilterResult(item) => item.as_reader().into(),
            GossipMessageUnion::GetBroadcastMessages(item) => item.as_reader().into(),
            GossipMessageUnion::GetBroadcastMessagesResult(item) => item.as_reader().into(),
            GossipMessageUnion::QueryBroadcastMessages(item) => item.as_reader().into(),
            GossipMessageUnion::QueryBroadcastMessagesResult(item) => item.as_reader().into(),
        }
    }
}
impl<'r> GossipMessageUnionReader<'r> {
    pub const NAME: &'r str = "GossipMessageUnionReader";
    pub fn as_slice(&self) -> &'r [u8] {
        match self {
            GossipMessageUnionReader::BroadcastMessagesFilter(item) => item.as_slice(),
            GossipMessageUnionReader::BroadcastMessagesFilterResult(item) => item.as_slice(),
            GossipMessageUnionReader::GetBroadcastMessages(item) => item.as_slice(),
            GossipMessageUnionReader::GetBroadcastMessagesResult(item) => item.as_slice(),
            GossipMessageUnionReader::QueryBroadcastMessages(item) => item.as_slice(),
            GossipMessageUnionReader::QueryBroadcastMessagesResult(item) => item.as_slice(),
        }
    }
    pub fn item_id(&self) -> molecule::Number {
        match self {
            GossipMessageUnionReader::BroadcastMessagesFilter(_) => 0,
            GossipMessageUnionReader::BroadcastMessagesFilterResult(_) => 1,
            GossipMessageUnionReader::GetBroadcastMessages(_) => 2,
            GossipMessageUnionReader::GetBroadcastMessagesResult(_) => 3,
            GossipMessageUnionReader::QueryBroadcastMessages(_) => 4,
            GossipMessageUnionReader::QueryBroadcastMessagesResult(_) => 5,
        }
    }
    pub fn item_name(&self) -> &str {
        match self {
            GossipMessageUnionReader::BroadcastMessagesFilter(_) => "BroadcastMessagesFilter",
            GossipMessageUnionReader::BroadcastMessagesFilterResult(_) => {
                "BroadcastMessagesFilterResult"
            }
            GossipMessageUnionReader::GetBroadcastMessages(_) => "GetBroadcastMessages",
            GossipMessageUnionReader::GetBroadcastMessagesResult(_) => "GetBroadcastMessagesResult",
            GossipMessageUnionReader::QueryBroadcastMessages(_) => "QueryBroadcastMessages",
            GossipMessageUnionReader::QueryBroadcastMessagesResult(_) => {
                "QueryBroadcastMessagesResult"
            }
        }
    }
}
impl From<BroadcastMessagesFilter> for GossipMessage {
    fn from(value: BroadcastMessagesFilter) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<BroadcastMessagesFilterResult> for GossipMessage {
    fn from(value: BroadcastMessagesFilterResult) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<GetBroadcastMessages> for GossipMessage {
    fn from(value: GetBroadcastMessages) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<GetBroadcastMessagesResult> for GossipMessage {
    fn from(value: GetBroadcastMessagesResult) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<QueryBroadcastMessages> for GossipMessage {
    fn from(value: QueryBroadcastMessages) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<QueryBroadcastMessagesResult> for GossipMessage {
    fn from(value: QueryBroadcastMessagesResult) -> Self {
        Self::new_builder().set(value).build()
    }
}


================================================
File: src/fiber/gen/invoice.rs
================================================
// Generated by Molecule 0.8.0

use super::blockchain::*;
use molecule::prelude::*;
#[derive(Clone)]
pub struct PaymentHash(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for PaymentHash {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for PaymentHash {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for PaymentHash {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl ::core::default::Default for PaymentHash {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        PaymentHash::new_unchecked(v)
    }
}
impl PaymentHash {
    const DEFAULT_VALUE: [u8; 32] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0,
    ];
    pub const TOTAL_SIZE: usize = 32;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 32;
    pub fn nth0(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(0..1))
    }
    pub fn nth1(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(1..2))
    }
    pub fn nth2(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(2..3))
    }
    pub fn nth3(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(3..4))
    }
    pub fn nth4(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(4..5))
    }
    pub fn nth5(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(5..6))
    }
    pub fn nth6(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(6..7))
    }
    pub fn nth7(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(7..8))
    }
    pub fn nth8(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(8..9))
    }
    pub fn nth9(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(9..10))
    }
    pub fn nth10(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(10..11))
    }
    pub fn nth11(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(11..12))
    }
    pub fn nth12(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(12..13))
    }
    pub fn nth13(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(13..14))
    }
    pub fn nth14(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(14..15))
    }
    pub fn nth15(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(15..16))
    }
    pub fn nth16(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(16..17))
    }
    pub fn nth17(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(17..18))
    }
    pub fn nth18(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(18..19))
    }
    pub fn nth19(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(19..20))
    }
    pub fn nth20(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(20..21))
    }
    pub fn nth21(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(21..22))
    }
    pub fn nth22(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(22..23))
    }
    pub fn nth23(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(23..24))
    }
    pub fn nth24(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(24..25))
    }
    pub fn nth25(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(25..26))
    }
    pub fn nth26(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(26..27))
    }
    pub fn nth27(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(27..28))
    }
    pub fn nth28(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(28..29))
    }
    pub fn nth29(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(29..30))
    }
    pub fn nth30(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(30..31))
    }
    pub fn nth31(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(31..32))
    }
    pub fn raw_data(&self) -> molecule::bytes::Bytes {
        self.as_bytes()
    }
    pub fn as_reader<'r>(&'r self) -> PaymentHashReader<'r> {
        PaymentHashReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for PaymentHash {
    type Builder = PaymentHashBuilder;
    const NAME: &'static str = "PaymentHash";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        PaymentHash(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        PaymentHashReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        PaymentHashReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set([
            self.nth0(),
            self.nth1(),
            self.nth2(),
            self.nth3(),
            self.nth4(),
            self.nth5(),
            self.nth6(),
            self.nth7(),
            self.nth8(),
            self.nth9(),
            self.nth10(),
            self.nth11(),
            self.nth12(),
            self.nth13(),
            self.nth14(),
            self.nth15(),
            self.nth16(),
            self.nth17(),
            self.nth18(),
            self.nth19(),
            self.nth20(),
            self.nth21(),
            self.nth22(),
            self.nth23(),
            self.nth24(),
            self.nth25(),
            self.nth26(),
            self.nth27(),
            self.nth28(),
            self.nth29(),
            self.nth30(),
            self.nth31(),
        ])
    }
}
#[derive(Clone, Copy)]
pub struct PaymentHashReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for PaymentHashReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for PaymentHashReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for PaymentHashReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl<'r> PaymentHashReader<'r> {
    pub const TOTAL_SIZE: usize = 32;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 32;
    pub fn nth0(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[0..1])
    }
    pub fn nth1(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[1..2])
    }
    pub fn nth2(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[2..3])
    }
    pub fn nth3(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[3..4])
    }
    pub fn nth4(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[4..5])
    }
    pub fn nth5(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[5..6])
    }
    pub fn nth6(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[6..7])
    }
    pub fn nth7(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[7..8])
    }
    pub fn nth8(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[8..9])
    }
    pub fn nth9(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[9..10])
    }
    pub fn nth10(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[10..11])
    }
    pub fn nth11(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[11..12])
    }
    pub fn nth12(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[12..13])
    }
    pub fn nth13(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[13..14])
    }
    pub fn nth14(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[14..15])
    }
    pub fn nth15(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[15..16])
    }
    pub fn nth16(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[16..17])
    }
    pub fn nth17(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[17..18])
    }
    pub fn nth18(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[18..19])
    }
    pub fn nth19(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[19..20])
    }
    pub fn nth20(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[20..21])
    }
    pub fn nth21(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[21..22])
    }
    pub fn nth22(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[22..23])
    }
    pub fn nth23(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[23..24])
    }
    pub fn nth24(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[24..25])
    }
    pub fn nth25(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[25..26])
    }
    pub fn nth26(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[26..27])
    }
    pub fn nth27(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[27..28])
    }
    pub fn nth28(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[28..29])
    }
    pub fn nth29(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[29..30])
    }
    pub fn nth30(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[30..31])
    }
    pub fn nth31(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[31..32])
    }
    pub fn raw_data(&self) -> &'r [u8] {
        self.as_slice()
    }
}
impl<'r> molecule::prelude::Reader<'r> for PaymentHashReader<'r> {
    type Entity = PaymentHash;
    const NAME: &'static str = "PaymentHashReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        PaymentHashReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone)]
pub struct PaymentHashBuilder(pub(crate) [Byte; 32]);
impl ::core::fmt::Debug for PaymentHashBuilder {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:?})", Self::NAME, &self.0[..])
    }
}
impl ::core::default::Default for PaymentHashBuilder {
    fn default() -> Self {
        PaymentHashBuilder([
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
        ])
    }
}
impl PaymentHashBuilder {
    pub const TOTAL_SIZE: usize = 32;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 32;
    pub fn set(mut self, v: [Byte; 32]) -> Self {
        self.0 = v;
        self
    }
    pub fn nth0(mut self, v: Byte) -> Self {
        self.0[0] = v;
        self
    }
    pub fn nth1(mut self, v: Byte) -> Self {
        self.0[1] = v;
        self
    }
    pub fn nth2(mut self, v: Byte) -> Self {
        self.0[2] = v;
        self
    }
    pub fn nth3(mut self, v: Byte) -> Self {
        self.0[3] = v;
        self
    }
    pub fn nth4(mut self, v: Byte) -> Self {
        self.0[4] = v;
        self
    }
    pub fn nth5(mut self, v: Byte) -> Self {
        self.0[5] = v;
        self
    }
    pub fn nth6(mut self, v: Byte) -> Self {
        self.0[6] = v;
        self
    }
    pub fn nth7(mut self, v: Byte) -> Self {
        self.0[7] = v;
        self
    }
    pub fn nth8(mut self, v: Byte) -> Self {
        self.0[8] = v;
        self
    }
    pub fn nth9(mut self, v: Byte) -> Self {
        self.0[9] = v;
        self
    }
    pub fn nth10(mut self, v: Byte) -> Self {
        self.0[10] = v;
        self
    }
    pub fn nth11(mut self, v: Byte) -> Self {
        self.0[11] = v;
        self
    }
    pub fn nth12(mut self, v: Byte) -> Self {
        self.0[12] = v;
        self
    }
    pub fn nth13(mut self, v: Byte) -> Self {
        self.0[13] = v;
        self
    }
    pub fn nth14(mut self, v: Byte) -> Self {
        self.0[14] = v;
        self
    }
    pub fn nth15(mut self, v: Byte) -> Self {
        self.0[15] = v;
        self
    }
    pub fn nth16(mut self, v: Byte) -> Self {
        self.0[16] = v;
        self
    }
    pub fn nth17(mut self, v: Byte) -> Self {
        self.0[17] = v;
        self
    }
    pub fn nth18(mut self, v: Byte) -> Self {
        self.0[18] = v;
        self
    }
    pub fn nth19(mut self, v: Byte) -> Self {
        self.0[19] = v;
        self
    }
    pub fn nth20(mut self, v: Byte) -> Self {
        self.0[20] = v;
        self
    }
    pub fn nth21(mut self, v: Byte) -> Self {
        self.0[21] = v;
        self
    }
    pub fn nth22(mut self, v: Byte) -> Self {
        self.0[22] = v;
        self
    }
    pub fn nth23(mut self, v: Byte) -> Self {
        self.0[23] = v;
        self
    }
    pub fn nth24(mut self, v: Byte) -> Self {
        self.0[24] = v;
        self
    }
    pub fn nth25(mut self, v: Byte) -> Self {
        self.0[25] = v;
        self
    }
    pub fn nth26(mut self, v: Byte) -> Self {
        self.0[26] = v;
        self
    }
    pub fn nth27(mut self, v: Byte) -> Self {
        self.0[27] = v;
        self
    }
    pub fn nth28(mut self, v: Byte) -> Self {
        self.0[28] = v;
        self
    }
    pub fn nth29(mut self, v: Byte) -> Self {
        self.0[29] = v;
        self
    }
    pub fn nth30(mut self, v: Byte) -> Self {
        self.0[30] = v;
        self
    }
    pub fn nth31(mut self, v: Byte) -> Self {
        self.0[31] = v;
        self
    }
}
impl molecule::prelude::Builder for PaymentHashBuilder {
    type Entity = PaymentHash;
    const NAME: &'static str = "PaymentHashBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.0[0].as_slice())?;
        writer.write_all(self.0[1].as_slice())?;
        writer.write_all(self.0[2].as_slice())?;
        writer.write_all(self.0[3].as_slice())?;
        writer.write_all(self.0[4].as_slice())?;
        writer.write_all(self.0[5].as_slice())?;
        writer.write_all(self.0[6].as_slice())?;
        writer.write_all(self.0[7].as_slice())?;
        writer.write_all(self.0[8].as_slice())?;
        writer.write_all(self.0[9].as_slice())?;
        writer.write_all(self.0[10].as_slice())?;
        writer.write_all(self.0[11].as_slice())?;
        writer.write_all(self.0[12].as_slice())?;
        writer.write_all(self.0[13].as_slice())?;
        writer.write_all(self.0[14].as_slice())?;
        writer.write_all(self.0[15].as_slice())?;
        writer.write_all(self.0[16].as_slice())?;
        writer.write_all(self.0[17].as_slice())?;
        writer.write_all(self.0[18].as_slice())?;
        writer.write_all(self.0[19].as_slice())?;
        writer.write_all(self.0[20].as_slice())?;
        writer.write_all(self.0[21].as_slice())?;
        writer.write_all(self.0[22].as_slice())?;
        writer.write_all(self.0[23].as_slice())?;
        writer.write_all(self.0[24].as_slice())?;
        writer.write_all(self.0[25].as_slice())?;
        writer.write_all(self.0[26].as_slice())?;
        writer.write_all(self.0[27].as_slice())?;
        writer.write_all(self.0[28].as_slice())?;
        writer.write_all(self.0[29].as_slice())?;
        writer.write_all(self.0[30].as_slice())?;
        writer.write_all(self.0[31].as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        PaymentHash::new_unchecked(inner.into())
    }
}
impl From<[Byte; 32usize]> for PaymentHash {
    fn from(value: [Byte; 32usize]) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl ::core::convert::TryFrom<&[Byte]> for PaymentHash {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[Byte]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(Self::new_builder()
            .set(<&[Byte; 32usize]>::try_from(value)?.clone())
            .build())
    }
}
impl From<PaymentHash> for [Byte; 32usize] {
    #[track_caller]
    fn from(value: PaymentHash) -> Self {
        [
            value.nth0(),
            value.nth1(),
            value.nth2(),
            value.nth3(),
            value.nth4(),
            value.nth5(),
            value.nth6(),
            value.nth7(),
            value.nth8(),
            value.nth9(),
            value.nth10(),
            value.nth11(),
            value.nth12(),
            value.nth13(),
            value.nth14(),
            value.nth15(),
            value.nth16(),
            value.nth17(),
            value.nth18(),
            value.nth19(),
            value.nth20(),
            value.nth21(),
            value.nth22(),
            value.nth23(),
            value.nth24(),
            value.nth25(),
            value.nth26(),
            value.nth27(),
            value.nth28(),
            value.nth29(),
            value.nth30(),
            value.nth31(),
        ]
    }
}
impl From<[u8; 32usize]> for PaymentHash {
    fn from(value: [u8; 32usize]) -> Self {
        PaymentHashReader::new_unchecked(&value).to_entity()
    }
}
impl ::core::convert::TryFrom<&[u8]> for PaymentHash {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[u8]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(<[u8; 32usize]>::try_from(value)?.into())
    }
}
impl From<PaymentHash> for [u8; 32usize] {
    #[track_caller]
    fn from(value: PaymentHash) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<PaymentHashReader<'a>> for &'a [u8; 32usize] {
    #[track_caller]
    fn from(value: PaymentHashReader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<&'a PaymentHashReader<'a>> for &'a [u8; 32usize] {
    #[track_caller]
    fn from(value: &'a PaymentHashReader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
#[derive(Clone)]
pub struct Signature(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for Signature {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for Signature {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for Signature {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl ::core::default::Default for Signature {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        Signature::new_unchecked(v)
    }
}
impl Signature {
    const DEFAULT_VALUE: [u8; 104] = [
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    ];
    pub const TOTAL_SIZE: usize = 104;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 104;
    pub fn nth0(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(0..1))
    }
    pub fn nth1(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(1..2))
    }
    pub fn nth2(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(2..3))
    }
    pub fn nth3(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(3..4))
    }
    pub fn nth4(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(4..5))
    }
    pub fn nth5(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(5..6))
    }
    pub fn nth6(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(6..7))
    }
    pub fn nth7(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(7..8))
    }
    pub fn nth8(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(8..9))
    }
    pub fn nth9(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(9..10))
    }
    pub fn nth10(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(10..11))
    }
    pub fn nth11(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(11..12))
    }
    pub fn nth12(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(12..13))
    }
    pub fn nth13(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(13..14))
    }
    pub fn nth14(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(14..15))
    }
    pub fn nth15(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(15..16))
    }
    pub fn nth16(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(16..17))
    }
    pub fn nth17(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(17..18))
    }
    pub fn nth18(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(18..19))
    }
    pub fn nth19(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(19..20))
    }
    pub fn nth20(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(20..21))
    }
    pub fn nth21(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(21..22))
    }
    pub fn nth22(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(22..23))
    }
    pub fn nth23(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(23..24))
    }
    pub fn nth24(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(24..25))
    }
    pub fn nth25(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(25..26))
    }
    pub fn nth26(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(26..27))
    }
    pub fn nth27(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(27..28))
    }
    pub fn nth28(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(28..29))
    }
    pub fn nth29(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(29..30))
    }
    pub fn nth30(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(30..31))
    }
    pub fn nth31(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(31..32))
    }
    pub fn nth32(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(32..33))
    }
    pub fn nth33(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(33..34))
    }
    pub fn nth34(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(34..35))
    }
    pub fn nth35(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(35..36))
    }
    pub fn nth36(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(36..37))
    }
    pub fn nth37(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(37..38))
    }
    pub fn nth38(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(38..39))
    }
    pub fn nth39(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(39..40))
    }
    pub fn nth40(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(40..41))
    }
    pub fn nth41(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(41..42))
    }
    pub fn nth42(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(42..43))
    }
    pub fn nth43(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(43..44))
    }
    pub fn nth44(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(44..45))
    }
    pub fn nth45(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(45..46))
    }
    pub fn nth46(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(46..47))
    }
    pub fn nth47(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(47..48))
    }
    pub fn nth48(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(48..49))
    }
    pub fn nth49(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(49..50))
    }
    pub fn nth50(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(50..51))
    }
    pub fn nth51(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(51..52))
    }
    pub fn nth52(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(52..53))
    }
    pub fn nth53(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(53..54))
    }
    pub fn nth54(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(54..55))
    }
    pub fn nth55(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(55..56))
    }
    pub fn nth56(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(56..57))
    }
    pub fn nth57(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(57..58))
    }
    pub fn nth58(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(58..59))
    }
    pub fn nth59(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(59..60))
    }
    pub fn nth60(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(60..61))
    }
    pub fn nth61(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(61..62))
    }
    pub fn nth62(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(62..63))
    }
    pub fn nth63(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(63..64))
    }
    pub fn nth64(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(64..65))
    }
    pub fn nth65(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(65..66))
    }
    pub fn nth66(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(66..67))
    }
    pub fn nth67(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(67..68))
    }
    pub fn nth68(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(68..69))
    }
    pub fn nth69(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(69..70))
    }
    pub fn nth70(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(70..71))
    }
    pub fn nth71(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(71..72))
    }
    pub fn nth72(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(72..73))
    }
    pub fn nth73(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(73..74))
    }
    pub fn nth74(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(74..75))
    }
    pub fn nth75(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(75..76))
    }
    pub fn nth76(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(76..77))
    }
    pub fn nth77(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(77..78))
    }
    pub fn nth78(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(78..79))
    }
    pub fn nth79(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(79..80))
    }
    pub fn nth80(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(80..81))
    }
    pub fn nth81(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(81..82))
    }
    pub fn nth82(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(82..83))
    }
    pub fn nth83(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(83..84))
    }
    pub fn nth84(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(84..85))
    }
    pub fn nth85(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(85..86))
    }
    pub fn nth86(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(86..87))
    }
    pub fn nth87(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(87..88))
    }
    pub fn nth88(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(88..89))
    }
    pub fn nth89(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(89..90))
    }
    pub fn nth90(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(90..91))
    }
    pub fn nth91(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(91..92))
    }
    pub fn nth92(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(92..93))
    }
    pub fn nth93(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(93..94))
    }
    pub fn nth94(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(94..95))
    }
    pub fn nth95(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(95..96))
    }
    pub fn nth96(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(96..97))
    }
    pub fn nth97(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(97..98))
    }
    pub fn nth98(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(98..99))
    }
    pub fn nth99(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(99..100))
    }
    pub fn nth100(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(100..101))
    }
    pub fn nth101(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(101..102))
    }
    pub fn nth102(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(102..103))
    }
    pub fn nth103(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(103..104))
    }
    pub fn raw_data(&self) -> molecule::bytes::Bytes {
        self.as_bytes()
    }
    pub fn as_reader<'r>(&'r self) -> SignatureReader<'r> {
        SignatureReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for Signature {
    type Builder = SignatureBuilder;
    const NAME: &'static str = "Signature";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        Signature(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        SignatureReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        SignatureReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set([
            self.nth0(),
            self.nth1(),
            self.nth2(),
            self.nth3(),
            self.nth4(),
            self.nth5(),
            self.nth6(),
            self.nth7(),
            self.nth8(),
            self.nth9(),
            self.nth10(),
            self.nth11(),
            self.nth12(),
            self.nth13(),
            self.nth14(),
            self.nth15(),
            self.nth16(),
            self.nth17(),
            self.nth18(),
            self.nth19(),
            self.nth20(),
            self.nth21(),
            self.nth22(),
            self.nth23(),
            self.nth24(),
            self.nth25(),
            self.nth26(),
            self.nth27(),
            self.nth28(),
            self.nth29(),
            self.nth30(),
            self.nth31(),
            self.nth32(),
            self.nth33(),
            self.nth34(),
            self.nth35(),
            self.nth36(),
            self.nth37(),
            self.nth38(),
            self.nth39(),
            self.nth40(),
            self.nth41(),
            self.nth42(),
            self.nth43(),
            self.nth44(),
            self.nth45(),
            self.nth46(),
            self.nth47(),
            self.nth48(),
            self.nth49(),
            self.nth50(),
            self.nth51(),
            self.nth52(),
            self.nth53(),
            self.nth54(),
            self.nth55(),
            self.nth56(),
            self.nth57(),
            self.nth58(),
            self.nth59(),
            self.nth60(),
            self.nth61(),
            self.nth62(),
            self.nth63(),
            self.nth64(),
            self.nth65(),
            self.nth66(),
            self.nth67(),
            self.nth68(),
            self.nth69(),
            self.nth70(),
            self.nth71(),
            self.nth72(),
            self.nth73(),
            self.nth74(),
            self.nth75(),
            self.nth76(),
            self.nth77(),
            self.nth78(),
            self.nth79(),
            self.nth80(),
            self.nth81(),
            self.nth82(),
            self.nth83(),
            self.nth84(),
            self.nth85(),
            self.nth86(),
            self.nth87(),
            self.nth88(),
            self.nth89(),
            self.nth90(),
            self.nth91(),
            self.nth92(),
            self.nth93(),
            self.nth94(),
            self.nth95(),
            self.nth96(),
            self.nth97(),
            self.nth98(),
            self.nth99(),
            self.nth100(),
            self.nth101(),
            self.nth102(),
            self.nth103(),
        ])
    }
}
#[derive(Clone, Copy)]
pub struct SignatureReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for SignatureReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for SignatureReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for SignatureReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        let raw_data = hex_string(&self.raw_data());
        write!(f, "{}(0x{})", Self::NAME, raw_data)
    }
}
impl<'r> SignatureReader<'r> {
    pub const TOTAL_SIZE: usize = 104;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 104;
    pub fn nth0(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[0..1])
    }
    pub fn nth1(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[1..2])
    }
    pub fn nth2(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[2..3])
    }
    pub fn nth3(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[3..4])
    }
    pub fn nth4(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[4..5])
    }
    pub fn nth5(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[5..6])
    }
    pub fn nth6(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[6..7])
    }
    pub fn nth7(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[7..8])
    }
    pub fn nth8(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[8..9])
    }
    pub fn nth9(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[9..10])
    }
    pub fn nth10(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[10..11])
    }
    pub fn nth11(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[11..12])
    }
    pub fn nth12(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[12..13])
    }
    pub fn nth13(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[13..14])
    }
    pub fn nth14(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[14..15])
    }
    pub fn nth15(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[15..16])
    }
    pub fn nth16(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[16..17])
    }
    pub fn nth17(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[17..18])
    }
    pub fn nth18(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[18..19])
    }
    pub fn nth19(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[19..20])
    }
    pub fn nth20(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[20..21])
    }
    pub fn nth21(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[21..22])
    }
    pub fn nth22(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[22..23])
    }
    pub fn nth23(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[23..24])
    }
    pub fn nth24(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[24..25])
    }
    pub fn nth25(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[25..26])
    }
    pub fn nth26(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[26..27])
    }
    pub fn nth27(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[27..28])
    }
    pub fn nth28(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[28..29])
    }
    pub fn nth29(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[29..30])
    }
    pub fn nth30(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[30..31])
    }
    pub fn nth31(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[31..32])
    }
    pub fn nth32(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[32..33])
    }
    pub fn nth33(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[33..34])
    }
    pub fn nth34(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[34..35])
    }
    pub fn nth35(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[35..36])
    }
    pub fn nth36(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[36..37])
    }
    pub fn nth37(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[37..38])
    }
    pub fn nth38(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[38..39])
    }
    pub fn nth39(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[39..40])
    }
    pub fn nth40(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[40..41])
    }
    pub fn nth41(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[41..42])
    }
    pub fn nth42(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[42..43])
    }
    pub fn nth43(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[43..44])
    }
    pub fn nth44(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[44..45])
    }
    pub fn nth45(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[45..46])
    }
    pub fn nth46(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[46..47])
    }
    pub fn nth47(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[47..48])
    }
    pub fn nth48(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[48..49])
    }
    pub fn nth49(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[49..50])
    }
    pub fn nth50(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[50..51])
    }
    pub fn nth51(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[51..52])
    }
    pub fn nth52(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[52..53])
    }
    pub fn nth53(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[53..54])
    }
    pub fn nth54(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[54..55])
    }
    pub fn nth55(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[55..56])
    }
    pub fn nth56(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[56..57])
    }
    pub fn nth57(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[57..58])
    }
    pub fn nth58(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[58..59])
    }
    pub fn nth59(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[59..60])
    }
    pub fn nth60(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[60..61])
    }
    pub fn nth61(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[61..62])
    }
    pub fn nth62(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[62..63])
    }
    pub fn nth63(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[63..64])
    }
    pub fn nth64(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[64..65])
    }
    pub fn nth65(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[65..66])
    }
    pub fn nth66(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[66..67])
    }
    pub fn nth67(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[67..68])
    }
    pub fn nth68(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[68..69])
    }
    pub fn nth69(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[69..70])
    }
    pub fn nth70(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[70..71])
    }
    pub fn nth71(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[71..72])
    }
    pub fn nth72(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[72..73])
    }
    pub fn nth73(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[73..74])
    }
    pub fn nth74(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[74..75])
    }
    pub fn nth75(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[75..76])
    }
    pub fn nth76(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[76..77])
    }
    pub fn nth77(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[77..78])
    }
    pub fn nth78(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[78..79])
    }
    pub fn nth79(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[79..80])
    }
    pub fn nth80(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[80..81])
    }
    pub fn nth81(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[81..82])
    }
    pub fn nth82(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[82..83])
    }
    pub fn nth83(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[83..84])
    }
    pub fn nth84(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[84..85])
    }
    pub fn nth85(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[85..86])
    }
    pub fn nth86(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[86..87])
    }
    pub fn nth87(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[87..88])
    }
    pub fn nth88(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[88..89])
    }
    pub fn nth89(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[89..90])
    }
    pub fn nth90(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[90..91])
    }
    pub fn nth91(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[91..92])
    }
    pub fn nth92(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[92..93])
    }
    pub fn nth93(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[93..94])
    }
    pub fn nth94(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[94..95])
    }
    pub fn nth95(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[95..96])
    }
    pub fn nth96(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[96..97])
    }
    pub fn nth97(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[97..98])
    }
    pub fn nth98(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[98..99])
    }
    pub fn nth99(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[99..100])
    }
    pub fn nth100(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[100..101])
    }
    pub fn nth101(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[101..102])
    }
    pub fn nth102(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[102..103])
    }
    pub fn nth103(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[103..104])
    }
    pub fn raw_data(&self) -> &'r [u8] {
        self.as_slice()
    }
}
impl<'r> molecule::prelude::Reader<'r> for SignatureReader<'r> {
    type Entity = Signature;
    const NAME: &'static str = "SignatureReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        SignatureReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone)]
pub struct SignatureBuilder(pub(crate) [Byte; 104]);
impl ::core::fmt::Debug for SignatureBuilder {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:?})", Self::NAME, &self.0[..])
    }
}
impl ::core::default::Default for SignatureBuilder {
    fn default() -> Self {
        SignatureBuilder([
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
            Byte::default(),
        ])
    }
}
impl SignatureBuilder {
    pub const TOTAL_SIZE: usize = 104;
    pub const ITEM_SIZE: usize = 1;
    pub const ITEM_COUNT: usize = 104;
    pub fn set(mut self, v: [Byte; 104]) -> Self {
        self.0 = v;
        self
    }
    pub fn nth0(mut self, v: Byte) -> Self {
        self.0[0] = v;
        self
    }
    pub fn nth1(mut self, v: Byte) -> Self {
        self.0[1] = v;
        self
    }
    pub fn nth2(mut self, v: Byte) -> Self {
        self.0[2] = v;
        self
    }
    pub fn nth3(mut self, v: Byte) -> Self {
        self.0[3] = v;
        self
    }
    pub fn nth4(mut self, v: Byte) -> Self {
        self.0[4] = v;
        self
    }
    pub fn nth5(mut self, v: Byte) -> Self {
        self.0[5] = v;
        self
    }
    pub fn nth6(mut self, v: Byte) -> Self {
        self.0[6] = v;
        self
    }
    pub fn nth7(mut self, v: Byte) -> Self {
        self.0[7] = v;
        self
    }
    pub fn nth8(mut self, v: Byte) -> Self {
        self.0[8] = v;
        self
    }
    pub fn nth9(mut self, v: Byte) -> Self {
        self.0[9] = v;
        self
    }
    pub fn nth10(mut self, v: Byte) -> Self {
        self.0[10] = v;
        self
    }
    pub fn nth11(mut self, v: Byte) -> Self {
        self.0[11] = v;
        self
    }
    pub fn nth12(mut self, v: Byte) -> Self {
        self.0[12] = v;
        self
    }
    pub fn nth13(mut self, v: Byte) -> Self {
        self.0[13] = v;
        self
    }
    pub fn nth14(mut self, v: Byte) -> Self {
        self.0[14] = v;
        self
    }
    pub fn nth15(mut self, v: Byte) -> Self {
        self.0[15] = v;
        self
    }
    pub fn nth16(mut self, v: Byte) -> Self {
        self.0[16] = v;
        self
    }
    pub fn nth17(mut self, v: Byte) -> Self {
        self.0[17] = v;
        self
    }
    pub fn nth18(mut self, v: Byte) -> Self {
        self.0[18] = v;
        self
    }
    pub fn nth19(mut self, v: Byte) -> Self {
        self.0[19] = v;
        self
    }
    pub fn nth20(mut self, v: Byte) -> Self {
        self.0[20] = v;
        self
    }
    pub fn nth21(mut self, v: Byte) -> Self {
        self.0[21] = v;
        self
    }
    pub fn nth22(mut self, v: Byte) -> Self {
        self.0[22] = v;
        self
    }
    pub fn nth23(mut self, v: Byte) -> Self {
        self.0[23] = v;
        self
    }
    pub fn nth24(mut self, v: Byte) -> Self {
        self.0[24] = v;
        self
    }
    pub fn nth25(mut self, v: Byte) -> Self {
        self.0[25] = v;
        self
    }
    pub fn nth26(mut self, v: Byte) -> Self {
        self.0[26] = v;
        self
    }
    pub fn nth27(mut self, v: Byte) -> Self {
        self.0[27] = v;
        self
    }
    pub fn nth28(mut self, v: Byte) -> Self {
        self.0[28] = v;
        self
    }
    pub fn nth29(mut self, v: Byte) -> Self {
        self.0[29] = v;
        self
    }
    pub fn nth30(mut self, v: Byte) -> Self {
        self.0[30] = v;
        self
    }
    pub fn nth31(mut self, v: Byte) -> Self {
        self.0[31] = v;
        self
    }
    pub fn nth32(mut self, v: Byte) -> Self {
        self.0[32] = v;
        self
    }
    pub fn nth33(mut self, v: Byte) -> Self {
        self.0[33] = v;
        self
    }
    pub fn nth34(mut self, v: Byte) -> Self {
        self.0[34] = v;
        self
    }
    pub fn nth35(mut self, v: Byte) -> Self {
        self.0[35] = v;
        self
    }
    pub fn nth36(mut self, v: Byte) -> Self {
        self.0[36] = v;
        self
    }
    pub fn nth37(mut self, v: Byte) -> Self {
        self.0[37] = v;
        self
    }
    pub fn nth38(mut self, v: Byte) -> Self {
        self.0[38] = v;
        self
    }
    pub fn nth39(mut self, v: Byte) -> Self {
        self.0[39] = v;
        self
    }
    pub fn nth40(mut self, v: Byte) -> Self {
        self.0[40] = v;
        self
    }
    pub fn nth41(mut self, v: Byte) -> Self {
        self.0[41] = v;
        self
    }
    pub fn nth42(mut self, v: Byte) -> Self {
        self.0[42] = v;
        self
    }
    pub fn nth43(mut self, v: Byte) -> Self {
        self.0[43] = v;
        self
    }
    pub fn nth44(mut self, v: Byte) -> Self {
        self.0[44] = v;
        self
    }
    pub fn nth45(mut self, v: Byte) -> Self {
        self.0[45] = v;
        self
    }
    pub fn nth46(mut self, v: Byte) -> Self {
        self.0[46] = v;
        self
    }
    pub fn nth47(mut self, v: Byte) -> Self {
        self.0[47] = v;
        self
    }
    pub fn nth48(mut self, v: Byte) -> Self {
        self.0[48] = v;
        self
    }
    pub fn nth49(mut self, v: Byte) -> Self {
        self.0[49] = v;
        self
    }
    pub fn nth50(mut self, v: Byte) -> Self {
        self.0[50] = v;
        self
    }
    pub fn nth51(mut self, v: Byte) -> Self {
        self.0[51] = v;
        self
    }
    pub fn nth52(mut self, v: Byte) -> Self {
        self.0[52] = v;
        self
    }
    pub fn nth53(mut self, v: Byte) -> Self {
        self.0[53] = v;
        self
    }
    pub fn nth54(mut self, v: Byte) -> Self {
        self.0[54] = v;
        self
    }
    pub fn nth55(mut self, v: Byte) -> Self {
        self.0[55] = v;
        self
    }
    pub fn nth56(mut self, v: Byte) -> Self {
        self.0[56] = v;
        self
    }
    pub fn nth57(mut self, v: Byte) -> Self {
        self.0[57] = v;
        self
    }
    pub fn nth58(mut self, v: Byte) -> Self {
        self.0[58] = v;
        self
    }
    pub fn nth59(mut self, v: Byte) -> Self {
        self.0[59] = v;
        self
    }
    pub fn nth60(mut self, v: Byte) -> Self {
        self.0[60] = v;
        self
    }
    pub fn nth61(mut self, v: Byte) -> Self {
        self.0[61] = v;
        self
    }
    pub fn nth62(mut self, v: Byte) -> Self {
        self.0[62] = v;
        self
    }
    pub fn nth63(mut self, v: Byte) -> Self {
        self.0[63] = v;
        self
    }
    pub fn nth64(mut self, v: Byte) -> Self {
        self.0[64] = v;
        self
    }
    pub fn nth65(mut self, v: Byte) -> Self {
        self.0[65] = v;
        self
    }
    pub fn nth66(mut self, v: Byte) -> Self {
        self.0[66] = v;
        self
    }
    pub fn nth67(mut self, v: Byte) -> Self {
        self.0[67] = v;
        self
    }
    pub fn nth68(mut self, v: Byte) -> Self {
        self.0[68] = v;
        self
    }
    pub fn nth69(mut self, v: Byte) -> Self {
        self.0[69] = v;
        self
    }
    pub fn nth70(mut self, v: Byte) -> Self {
        self.0[70] = v;
        self
    }
    pub fn nth71(mut self, v: Byte) -> Self {
        self.0[71] = v;
        self
    }
    pub fn nth72(mut self, v: Byte) -> Self {
        self.0[72] = v;
        self
    }
    pub fn nth73(mut self, v: Byte) -> Self {
        self.0[73] = v;
        self
    }
    pub fn nth74(mut self, v: Byte) -> Self {
        self.0[74] = v;
        self
    }
    pub fn nth75(mut self, v: Byte) -> Self {
        self.0[75] = v;
        self
    }
    pub fn nth76(mut self, v: Byte) -> Self {
        self.0[76] = v;
        self
    }
    pub fn nth77(mut self, v: Byte) -> Self {
        self.0[77] = v;
        self
    }
    pub fn nth78(mut self, v: Byte) -> Self {
        self.0[78] = v;
        self
    }
    pub fn nth79(mut self, v: Byte) -> Self {
        self.0[79] = v;
        self
    }
    pub fn nth80(mut self, v: Byte) -> Self {
        self.0[80] = v;
        self
    }
    pub fn nth81(mut self, v: Byte) -> Self {
        self.0[81] = v;
        self
    }
    pub fn nth82(mut self, v: Byte) -> Self {
        self.0[82] = v;
        self
    }
    pub fn nth83(mut self, v: Byte) -> Self {
        self.0[83] = v;
        self
    }
    pub fn nth84(mut self, v: Byte) -> Self {
        self.0[84] = v;
        self
    }
    pub fn nth85(mut self, v: Byte) -> Self {
        self.0[85] = v;
        self
    }
    pub fn nth86(mut self, v: Byte) -> Self {
        self.0[86] = v;
        self
    }
    pub fn nth87(mut self, v: Byte) -> Self {
        self.0[87] = v;
        self
    }
    pub fn nth88(mut self, v: Byte) -> Self {
        self.0[88] = v;
        self
    }
    pub fn nth89(mut self, v: Byte) -> Self {
        self.0[89] = v;
        self
    }
    pub fn nth90(mut self, v: Byte) -> Self {
        self.0[90] = v;
        self
    }
    pub fn nth91(mut self, v: Byte) -> Self {
        self.0[91] = v;
        self
    }
    pub fn nth92(mut self, v: Byte) -> Self {
        self.0[92] = v;
        self
    }
    pub fn nth93(mut self, v: Byte) -> Self {
        self.0[93] = v;
        self
    }
    pub fn nth94(mut self, v: Byte) -> Self {
        self.0[94] = v;
        self
    }
    pub fn nth95(mut self, v: Byte) -> Self {
        self.0[95] = v;
        self
    }
    pub fn nth96(mut self, v: Byte) -> Self {
        self.0[96] = v;
        self
    }
    pub fn nth97(mut self, v: Byte) -> Self {
        self.0[97] = v;
        self
    }
    pub fn nth98(mut self, v: Byte) -> Self {
        self.0[98] = v;
        self
    }
    pub fn nth99(mut self, v: Byte) -> Self {
        self.0[99] = v;
        self
    }
    pub fn nth100(mut self, v: Byte) -> Self {
        self.0[100] = v;
        self
    }
    pub fn nth101(mut self, v: Byte) -> Self {
        self.0[101] = v;
        self
    }
    pub fn nth102(mut self, v: Byte) -> Self {
        self.0[102] = v;
        self
    }
    pub fn nth103(mut self, v: Byte) -> Self {
        self.0[103] = v;
        self
    }
}
impl molecule::prelude::Builder for SignatureBuilder {
    type Entity = Signature;
    const NAME: &'static str = "SignatureBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.0[0].as_slice())?;
        writer.write_all(self.0[1].as_slice())?;
        writer.write_all(self.0[2].as_slice())?;
        writer.write_all(self.0[3].as_slice())?;
        writer.write_all(self.0[4].as_slice())?;
        writer.write_all(self.0[5].as_slice())?;
        writer.write_all(self.0[6].as_slice())?;
        writer.write_all(self.0[7].as_slice())?;
        writer.write_all(self.0[8].as_slice())?;
        writer.write_all(self.0[9].as_slice())?;
        writer.write_all(self.0[10].as_slice())?;
        writer.write_all(self.0[11].as_slice())?;
        writer.write_all(self.0[12].as_slice())?;
        writer.write_all(self.0[13].as_slice())?;
        writer.write_all(self.0[14].as_slice())?;
        writer.write_all(self.0[15].as_slice())?;
        writer.write_all(self.0[16].as_slice())?;
        writer.write_all(self.0[17].as_slice())?;
        writer.write_all(self.0[18].as_slice())?;
        writer.write_all(self.0[19].as_slice())?;
        writer.write_all(self.0[20].as_slice())?;
        writer.write_all(self.0[21].as_slice())?;
        writer.write_all(self.0[22].as_slice())?;
        writer.write_all(self.0[23].as_slice())?;
        writer.write_all(self.0[24].as_slice())?;
        writer.write_all(self.0[25].as_slice())?;
        writer.write_all(self.0[26].as_slice())?;
        writer.write_all(self.0[27].as_slice())?;
        writer.write_all(self.0[28].as_slice())?;
        writer.write_all(self.0[29].as_slice())?;
        writer.write_all(self.0[30].as_slice())?;
        writer.write_all(self.0[31].as_slice())?;
        writer.write_all(self.0[32].as_slice())?;
        writer.write_all(self.0[33].as_slice())?;
        writer.write_all(self.0[34].as_slice())?;
        writer.write_all(self.0[35].as_slice())?;
        writer.write_all(self.0[36].as_slice())?;
        writer.write_all(self.0[37].as_slice())?;
        writer.write_all(self.0[38].as_slice())?;
        writer.write_all(self.0[39].as_slice())?;
        writer.write_all(self.0[40].as_slice())?;
        writer.write_all(self.0[41].as_slice())?;
        writer.write_all(self.0[42].as_slice())?;
        writer.write_all(self.0[43].as_slice())?;
        writer.write_all(self.0[44].as_slice())?;
        writer.write_all(self.0[45].as_slice())?;
        writer.write_all(self.0[46].as_slice())?;
        writer.write_all(self.0[47].as_slice())?;
        writer.write_all(self.0[48].as_slice())?;
        writer.write_all(self.0[49].as_slice())?;
        writer.write_all(self.0[50].as_slice())?;
        writer.write_all(self.0[51].as_slice())?;
        writer.write_all(self.0[52].as_slice())?;
        writer.write_all(self.0[53].as_slice())?;
        writer.write_all(self.0[54].as_slice())?;
        writer.write_all(self.0[55].as_slice())?;
        writer.write_all(self.0[56].as_slice())?;
        writer.write_all(self.0[57].as_slice())?;
        writer.write_all(self.0[58].as_slice())?;
        writer.write_all(self.0[59].as_slice())?;
        writer.write_all(self.0[60].as_slice())?;
        writer.write_all(self.0[61].as_slice())?;
        writer.write_all(self.0[62].as_slice())?;
        writer.write_all(self.0[63].as_slice())?;
        writer.write_all(self.0[64].as_slice())?;
        writer.write_all(self.0[65].as_slice())?;
        writer.write_all(self.0[66].as_slice())?;
        writer.write_all(self.0[67].as_slice())?;
        writer.write_all(self.0[68].as_slice())?;
        writer.write_all(self.0[69].as_slice())?;
        writer.write_all(self.0[70].as_slice())?;
        writer.write_all(self.0[71].as_slice())?;
        writer.write_all(self.0[72].as_slice())?;
        writer.write_all(self.0[73].as_slice())?;
        writer.write_all(self.0[74].as_slice())?;
        writer.write_all(self.0[75].as_slice())?;
        writer.write_all(self.0[76].as_slice())?;
        writer.write_all(self.0[77].as_slice())?;
        writer.write_all(self.0[78].as_slice())?;
        writer.write_all(self.0[79].as_slice())?;
        writer.write_all(self.0[80].as_slice())?;
        writer.write_all(self.0[81].as_slice())?;
        writer.write_all(self.0[82].as_slice())?;
        writer.write_all(self.0[83].as_slice())?;
        writer.write_all(self.0[84].as_slice())?;
        writer.write_all(self.0[85].as_slice())?;
        writer.write_all(self.0[86].as_slice())?;
        writer.write_all(self.0[87].as_slice())?;
        writer.write_all(self.0[88].as_slice())?;
        writer.write_all(self.0[89].as_slice())?;
        writer.write_all(self.0[90].as_slice())?;
        writer.write_all(self.0[91].as_slice())?;
        writer.write_all(self.0[92].as_slice())?;
        writer.write_all(self.0[93].as_slice())?;
        writer.write_all(self.0[94].as_slice())?;
        writer.write_all(self.0[95].as_slice())?;
        writer.write_all(self.0[96].as_slice())?;
        writer.write_all(self.0[97].as_slice())?;
        writer.write_all(self.0[98].as_slice())?;
        writer.write_all(self.0[99].as_slice())?;
        writer.write_all(self.0[100].as_slice())?;
        writer.write_all(self.0[101].as_slice())?;
        writer.write_all(self.0[102].as_slice())?;
        writer.write_all(self.0[103].as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        Signature::new_unchecked(inner.into())
    }
}
impl From<[Byte; 104usize]> for Signature {
    fn from(value: [Byte; 104usize]) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl ::core::convert::TryFrom<&[Byte]> for Signature {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[Byte]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(Self::new_builder()
            .set(<&[Byte; 104usize]>::try_from(value)?.clone())
            .build())
    }
}
impl From<Signature> for [Byte; 104usize] {
    #[track_caller]
    fn from(value: Signature) -> Self {
        [
            value.nth0(),
            value.nth1(),
            value.nth2(),
            value.nth3(),
            value.nth4(),
            value.nth5(),
            value.nth6(),
            value.nth7(),
            value.nth8(),
            value.nth9(),
            value.nth10(),
            value.nth11(),
            value.nth12(),
            value.nth13(),
            value.nth14(),
            value.nth15(),
            value.nth16(),
            value.nth17(),
            value.nth18(),
            value.nth19(),
            value.nth20(),
            value.nth21(),
            value.nth22(),
            value.nth23(),
            value.nth24(),
            value.nth25(),
            value.nth26(),
            value.nth27(),
            value.nth28(),
            value.nth29(),
            value.nth30(),
            value.nth31(),
            value.nth32(),
            value.nth33(),
            value.nth34(),
            value.nth35(),
            value.nth36(),
            value.nth37(),
            value.nth38(),
            value.nth39(),
            value.nth40(),
            value.nth41(),
            value.nth42(),
            value.nth43(),
            value.nth44(),
            value.nth45(),
            value.nth46(),
            value.nth47(),
            value.nth48(),
            value.nth49(),
            value.nth50(),
            value.nth51(),
            value.nth52(),
            value.nth53(),
            value.nth54(),
            value.nth55(),
            value.nth56(),
            value.nth57(),
            value.nth58(),
            value.nth59(),
            value.nth60(),
            value.nth61(),
            value.nth62(),
            value.nth63(),
            value.nth64(),
            value.nth65(),
            value.nth66(),
            value.nth67(),
            value.nth68(),
            value.nth69(),
            value.nth70(),
            value.nth71(),
            value.nth72(),
            value.nth73(),
            value.nth74(),
            value.nth75(),
            value.nth76(),
            value.nth77(),
            value.nth78(),
            value.nth79(),
            value.nth80(),
            value.nth81(),
            value.nth82(),
            value.nth83(),
            value.nth84(),
            value.nth85(),
            value.nth86(),
            value.nth87(),
            value.nth88(),
            value.nth89(),
            value.nth90(),
            value.nth91(),
            value.nth92(),
            value.nth93(),
            value.nth94(),
            value.nth95(),
            value.nth96(),
            value.nth97(),
            value.nth98(),
            value.nth99(),
            value.nth100(),
            value.nth101(),
            value.nth102(),
            value.nth103(),
        ]
    }
}
impl From<[u8; 104usize]> for Signature {
    fn from(value: [u8; 104usize]) -> Self {
        SignatureReader::new_unchecked(&value).to_entity()
    }
}
impl ::core::convert::TryFrom<&[u8]> for Signature {
    type Error = ::core::array::TryFromSliceError;
    fn try_from(value: &[u8]) -> Result<Self, ::core::array::TryFromSliceError> {
        Ok(<[u8; 104usize]>::try_from(value)?.into())
    }
}
impl From<Signature> for [u8; 104usize] {
    #[track_caller]
    fn from(value: Signature) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<SignatureReader<'a>> for &'a [u8; 104usize] {
    #[track_caller]
    fn from(value: SignatureReader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
impl<'a> From<&'a SignatureReader<'a>> for &'a [u8; 104usize] {
    #[track_caller]
    fn from(value: &'a SignatureReader<'a>) -> Self {
        ::core::convert::TryFrom::try_from(value.as_slice()).unwrap()
    }
}
#[derive(Clone)]
pub struct ExpiryTimeOpt(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for ExpiryTimeOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for ExpiryTimeOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for ExpiryTimeOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl ::core::default::Default for ExpiryTimeOpt {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        ExpiryTimeOpt::new_unchecked(v)
    }
}
impl ExpiryTimeOpt {
    const DEFAULT_VALUE: [u8; 0] = [];
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<Duration> {
        if self.is_none() {
            None
        } else {
            Some(Duration::new_unchecked(self.0.clone()))
        }
    }
    pub fn as_reader<'r>(&'r self) -> ExpiryTimeOptReader<'r> {
        ExpiryTimeOptReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for ExpiryTimeOpt {
    type Builder = ExpiryTimeOptBuilder;
    const NAME: &'static str = "ExpiryTimeOpt";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        ExpiryTimeOpt(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ExpiryTimeOptReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ExpiryTimeOptReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_opt())
    }
}
#[derive(Clone, Copy)]
pub struct ExpiryTimeOptReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for ExpiryTimeOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for ExpiryTimeOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for ExpiryTimeOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl<'r> ExpiryTimeOptReader<'r> {
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<DurationReader<'r>> {
        if self.is_none() {
            None
        } else {
            Some(DurationReader::new_unchecked(self.as_slice()))
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for ExpiryTimeOptReader<'r> {
    type Entity = ExpiryTimeOpt;
    const NAME: &'static str = "ExpiryTimeOptReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        ExpiryTimeOptReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        if !slice.is_empty() {
            DurationReader::verify(&slice[..], compatible)?;
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct ExpiryTimeOptBuilder(pub(crate) Option<Duration>);
impl ExpiryTimeOptBuilder {
    pub fn set(mut self, v: Option<Duration>) -> Self {
        self.0 = v;
        self
    }
}
impl molecule::prelude::Builder for ExpiryTimeOptBuilder {
    type Entity = ExpiryTimeOpt;
    const NAME: &'static str = "ExpiryTimeOptBuilder";
    fn expected_length(&self) -> usize {
        self.0
            .as_ref()
            .map(|ref inner| inner.as_slice().len())
            .unwrap_or(0)
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        self.0
            .as_ref()
            .map(|ref inner| writer.write_all(inner.as_slice()))
            .unwrap_or(Ok(()))
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        ExpiryTimeOpt::new_unchecked(inner.into())
    }
}
impl From<Duration> for ExpiryTimeOpt {
    fn from(value: Duration) -> Self {
        Self::new_builder().set(Some(value)).build()
    }
}
#[derive(Clone)]
pub struct SignatureOpt(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for SignatureOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for SignatureOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for SignatureOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl ::core::default::Default for SignatureOpt {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        SignatureOpt::new_unchecked(v)
    }
}
impl SignatureOpt {
    const DEFAULT_VALUE: [u8; 0] = [];
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<Signature> {
        if self.is_none() {
            None
        } else {
            Some(Signature::new_unchecked(self.0.clone()))
        }
    }
    pub fn as_reader<'r>(&'r self) -> SignatureOptReader<'r> {
        SignatureOptReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for SignatureOpt {
    type Builder = SignatureOptBuilder;
    const NAME: &'static str = "SignatureOpt";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        SignatureOpt(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        SignatureOptReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        SignatureOptReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_opt())
    }
}
#[derive(Clone, Copy)]
pub struct SignatureOptReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for SignatureOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for SignatureOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for SignatureOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl<'r> SignatureOptReader<'r> {
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<SignatureReader<'r>> {
        if self.is_none() {
            None
        } else {
            Some(SignatureReader::new_unchecked(self.as_slice()))
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for SignatureOptReader<'r> {
    type Entity = SignatureOpt;
    const NAME: &'static str = "SignatureOptReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        SignatureOptReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        if !slice.is_empty() {
            SignatureReader::verify(&slice[..], compatible)?;
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct SignatureOptBuilder(pub(crate) Option<Signature>);
impl SignatureOptBuilder {
    pub fn set(mut self, v: Option<Signature>) -> Self {
        self.0 = v;
        self
    }
}
impl molecule::prelude::Builder for SignatureOptBuilder {
    type Entity = SignatureOpt;
    const NAME: &'static str = "SignatureOptBuilder";
    fn expected_length(&self) -> usize {
        self.0
            .as_ref()
            .map(|ref inner| inner.as_slice().len())
            .unwrap_or(0)
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        self.0
            .as_ref()
            .map(|ref inner| writer.write_all(inner.as_slice()))
            .unwrap_or(Ok(()))
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        SignatureOpt::new_unchecked(inner.into())
    }
}
impl From<Signature> for SignatureOpt {
    fn from(value: Signature) -> Self {
        Self::new_builder().set(Some(value)).build()
    }
}
#[derive(Clone)]
pub struct AmountOpt(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for AmountOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for AmountOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for AmountOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl ::core::default::Default for AmountOpt {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        AmountOpt::new_unchecked(v)
    }
}
impl AmountOpt {
    const DEFAULT_VALUE: [u8; 0] = [];
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<Uint128> {
        if self.is_none() {
            None
        } else {
            Some(Uint128::new_unchecked(self.0.clone()))
        }
    }
    pub fn as_reader<'r>(&'r self) -> AmountOptReader<'r> {
        AmountOptReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for AmountOpt {
    type Builder = AmountOptBuilder;
    const NAME: &'static str = "AmountOpt";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        AmountOpt(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        AmountOptReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        AmountOptReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_opt())
    }
}
#[derive(Clone, Copy)]
pub struct AmountOptReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for AmountOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for AmountOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for AmountOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl<'r> AmountOptReader<'r> {
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<Uint128Reader<'r>> {
        if self.is_none() {
            None
        } else {
            Some(Uint128Reader::new_unchecked(self.as_slice()))
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for AmountOptReader<'r> {
    type Entity = AmountOpt;
    const NAME: &'static str = "AmountOptReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        AmountOptReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        if !slice.is_empty() {
            Uint128Reader::verify(&slice[..], compatible)?;
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct AmountOptBuilder(pub(crate) Option<Uint128>);
impl AmountOptBuilder {
    pub fn set(mut self, v: Option<Uint128>) -> Self {
        self.0 = v;
        self
    }
}
impl molecule::prelude::Builder for AmountOptBuilder {
    type Entity = AmountOpt;
    const NAME: &'static str = "AmountOptBuilder";
    fn expected_length(&self) -> usize {
        self.0
            .as_ref()
            .map(|ref inner| inner.as_slice().len())
            .unwrap_or(0)
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        self.0
            .as_ref()
            .map(|ref inner| writer.write_all(inner.as_slice()))
            .unwrap_or(Ok(()))
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        AmountOpt::new_unchecked(inner.into())
    }
}
impl From<Uint128> for AmountOpt {
    fn from(value: Uint128) -> Self {
        Self::new_builder().set(Some(value)).build()
    }
}
#[derive(Clone)]
pub struct FeatureOpt(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for FeatureOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for FeatureOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for FeatureOpt {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl ::core::default::Default for FeatureOpt {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        FeatureOpt::new_unchecked(v)
    }
}
impl FeatureOpt {
    const DEFAULT_VALUE: [u8; 0] = [];
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<Uint32> {
        if self.is_none() {
            None
        } else {
            Some(Uint32::new_unchecked(self.0.clone()))
        }
    }
    pub fn as_reader<'r>(&'r self) -> FeatureOptReader<'r> {
        FeatureOptReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for FeatureOpt {
    type Builder = FeatureOptBuilder;
    const NAME: &'static str = "FeatureOpt";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        FeatureOpt(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        FeatureOptReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        FeatureOptReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_opt())
    }
}
#[derive(Clone, Copy)]
pub struct FeatureOptReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for FeatureOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for FeatureOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for FeatureOptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        if let Some(v) = self.to_opt() {
            write!(f, "{}(Some({}))", Self::NAME, v)
        } else {
            write!(f, "{}(None)", Self::NAME)
        }
    }
}
impl<'r> FeatureOptReader<'r> {
    pub fn is_none(&self) -> bool {
        self.0.is_empty()
    }
    pub fn is_some(&self) -> bool {
        !self.0.is_empty()
    }
    pub fn to_opt(&self) -> Option<Uint32Reader<'r>> {
        if self.is_none() {
            None
        } else {
            Some(Uint32Reader::new_unchecked(self.as_slice()))
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for FeatureOptReader<'r> {
    type Entity = FeatureOpt;
    const NAME: &'static str = "FeatureOptReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        FeatureOptReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        if !slice.is_empty() {
            Uint32Reader::verify(&slice[..], compatible)?;
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct FeatureOptBuilder(pub(crate) Option<Uint32>);
impl FeatureOptBuilder {
    pub fn set(mut self, v: Option<Uint32>) -> Self {
        self.0 = v;
        self
    }
}
impl molecule::prelude::Builder for FeatureOptBuilder {
    type Entity = FeatureOpt;
    const NAME: &'static str = "FeatureOptBuilder";
    fn expected_length(&self) -> usize {
        self.0
            .as_ref()
            .map(|ref inner| inner.as_slice().len())
            .unwrap_or(0)
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        self.0
            .as_ref()
            .map(|ref inner| writer.write_all(inner.as_slice()))
            .unwrap_or(Ok(()))
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        FeatureOpt::new_unchecked(inner.into())
    }
}
impl From<Uint32> for FeatureOpt {
    fn from(value: Uint32) -> Self {
        Self::new_builder().set(Some(value)).build()
    }
}
#[derive(Clone)]
pub struct Duration(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for Duration {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for Duration {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for Duration {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "seconds", self.seconds())?;
        write!(f, ", {}: {}", "nanos", self.nanos())?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for Duration {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        Duration::new_unchecked(v)
    }
}
impl Duration {
    const DEFAULT_VALUE: [u8; 16] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];
    pub const TOTAL_SIZE: usize = 16;
    pub const FIELD_SIZES: [usize; 2] = [8, 8];
    pub const FIELD_COUNT: usize = 2;
    pub fn seconds(&self) -> Uint64 {
        Uint64::new_unchecked(self.0.slice(0..8))
    }
    pub fn nanos(&self) -> Uint64 {
        Uint64::new_unchecked(self.0.slice(8..16))
    }
    pub fn as_reader<'r>(&'r self) -> DurationReader<'r> {
        DurationReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for Duration {
    type Builder = DurationBuilder;
    const NAME: &'static str = "Duration";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        Duration(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        DurationReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        DurationReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .seconds(self.seconds())
            .nanos(self.nanos())
    }
}
#[derive(Clone, Copy)]
pub struct DurationReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for DurationReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for DurationReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for DurationReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "seconds", self.seconds())?;
        write!(f, ", {}: {}", "nanos", self.nanos())?;
        write!(f, " }}")
    }
}
impl<'r> DurationReader<'r> {
    pub const TOTAL_SIZE: usize = 16;
    pub const FIELD_SIZES: [usize; 2] = [8, 8];
    pub const FIELD_COUNT: usize = 2;
    pub fn seconds(&self) -> Uint64Reader<'r> {
        Uint64Reader::new_unchecked(&self.as_slice()[0..8])
    }
    pub fn nanos(&self) -> Uint64Reader<'r> {
        Uint64Reader::new_unchecked(&self.as_slice()[8..16])
    }
}
impl<'r> molecule::prelude::Reader<'r> for DurationReader<'r> {
    type Entity = Duration;
    const NAME: &'static str = "DurationReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        DurationReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct DurationBuilder {
    pub(crate) seconds: Uint64,
    pub(crate) nanos: Uint64,
}
impl DurationBuilder {
    pub const TOTAL_SIZE: usize = 16;
    pub const FIELD_SIZES: [usize; 2] = [8, 8];
    pub const FIELD_COUNT: usize = 2;
    pub fn seconds(mut self, v: Uint64) -> Self {
        self.seconds = v;
        self
    }
    pub fn nanos(mut self, v: Uint64) -> Self {
        self.nanos = v;
        self
    }
}
impl molecule::prelude::Builder for DurationBuilder {
    type Entity = Duration;
    const NAME: &'static str = "DurationBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.seconds.as_slice())?;
        writer.write_all(self.nanos.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        Duration::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct FinalHtlcTimeout(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for FinalHtlcTimeout {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for FinalHtlcTimeout {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for FinalHtlcTimeout {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for FinalHtlcTimeout {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        FinalHtlcTimeout::new_unchecked(v)
    }
}
impl FinalHtlcTimeout {
    const DEFAULT_VALUE: [u8; 8] = [0, 0, 0, 0, 0, 0, 0, 0];
    pub const TOTAL_SIZE: usize = 8;
    pub const FIELD_SIZES: [usize; 1] = [8];
    pub const FIELD_COUNT: usize = 1;
    pub fn value(&self) -> Uint64 {
        Uint64::new_unchecked(self.0.slice(0..8))
    }
    pub fn as_reader<'r>(&'r self) -> FinalHtlcTimeoutReader<'r> {
        FinalHtlcTimeoutReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for FinalHtlcTimeout {
    type Builder = FinalHtlcTimeoutBuilder;
    const NAME: &'static str = "FinalHtlcTimeout";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        FinalHtlcTimeout(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        FinalHtlcTimeoutReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        FinalHtlcTimeoutReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().value(self.value())
    }
}
#[derive(Clone, Copy)]
pub struct FinalHtlcTimeoutReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for FinalHtlcTimeoutReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for FinalHtlcTimeoutReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for FinalHtlcTimeoutReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        write!(f, " }}")
    }
}
impl<'r> FinalHtlcTimeoutReader<'r> {
    pub const TOTAL_SIZE: usize = 8;
    pub const FIELD_SIZES: [usize; 1] = [8];
    pub const FIELD_COUNT: usize = 1;
    pub fn value(&self) -> Uint64Reader<'r> {
        Uint64Reader::new_unchecked(&self.as_slice()[0..8])
    }
}
impl<'r> molecule::prelude::Reader<'r> for FinalHtlcTimeoutReader<'r> {
    type Entity = FinalHtlcTimeout;
    const NAME: &'static str = "FinalHtlcTimeoutReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        FinalHtlcTimeoutReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct FinalHtlcTimeoutBuilder {
    pub(crate) value: Uint64,
}
impl FinalHtlcTimeoutBuilder {
    pub const TOTAL_SIZE: usize = 8;
    pub const FIELD_SIZES: [usize; 1] = [8];
    pub const FIELD_COUNT: usize = 1;
    pub fn value(mut self, v: Uint64) -> Self {
        self.value = v;
        self
    }
}
impl molecule::prelude::Builder for FinalHtlcTimeoutBuilder {
    type Entity = FinalHtlcTimeout;
    const NAME: &'static str = "FinalHtlcTimeoutBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.value.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        FinalHtlcTimeout::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct FinalHtlcMinimumExpiryDelta(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for FinalHtlcMinimumExpiryDelta {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for FinalHtlcMinimumExpiryDelta {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for FinalHtlcMinimumExpiryDelta {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for FinalHtlcMinimumExpiryDelta {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        FinalHtlcMinimumExpiryDelta::new_unchecked(v)
    }
}
impl FinalHtlcMinimumExpiryDelta {
    const DEFAULT_VALUE: [u8; 8] = [0, 0, 0, 0, 0, 0, 0, 0];
    pub const TOTAL_SIZE: usize = 8;
    pub const FIELD_SIZES: [usize; 1] = [8];
    pub const FIELD_COUNT: usize = 1;
    pub fn value(&self) -> Uint64 {
        Uint64::new_unchecked(self.0.slice(0..8))
    }
    pub fn as_reader<'r>(&'r self) -> FinalHtlcMinimumExpiryDeltaReader<'r> {
        FinalHtlcMinimumExpiryDeltaReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for FinalHtlcMinimumExpiryDelta {
    type Builder = FinalHtlcMinimumExpiryDeltaBuilder;
    const NAME: &'static str = "FinalHtlcMinimumExpiryDelta";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        FinalHtlcMinimumExpiryDelta(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        FinalHtlcMinimumExpiryDeltaReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        FinalHtlcMinimumExpiryDeltaReader::from_compatible_slice(slice)
            .map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().value(self.value())
    }
}
#[derive(Clone, Copy)]
pub struct FinalHtlcMinimumExpiryDeltaReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for FinalHtlcMinimumExpiryDeltaReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for FinalHtlcMinimumExpiryDeltaReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for FinalHtlcMinimumExpiryDeltaReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        write!(f, " }}")
    }
}
impl<'r> FinalHtlcMinimumExpiryDeltaReader<'r> {
    pub const TOTAL_SIZE: usize = 8;
    pub const FIELD_SIZES: [usize; 1] = [8];
    pub const FIELD_COUNT: usize = 1;
    pub fn value(&self) -> Uint64Reader<'r> {
        Uint64Reader::new_unchecked(&self.as_slice()[0..8])
    }
}
impl<'r> molecule::prelude::Reader<'r> for FinalHtlcMinimumExpiryDeltaReader<'r> {
    type Entity = FinalHtlcMinimumExpiryDelta;
    const NAME: &'static str = "FinalHtlcMinimumExpiryDeltaReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        FinalHtlcMinimumExpiryDeltaReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct FinalHtlcMinimumExpiryDeltaBuilder {
    pub(crate) value: Uint64,
}
impl FinalHtlcMinimumExpiryDeltaBuilder {
    pub const TOTAL_SIZE: usize = 8;
    pub const FIELD_SIZES: [usize; 1] = [8];
    pub const FIELD_COUNT: usize = 1;
    pub fn value(mut self, v: Uint64) -> Self {
        self.value = v;
        self
    }
}
impl molecule::prelude::Builder for FinalHtlcMinimumExpiryDeltaBuilder {
    type Entity = FinalHtlcMinimumExpiryDelta;
    const NAME: &'static str = "FinalHtlcMinimumExpiryDeltaBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.value.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        FinalHtlcMinimumExpiryDelta::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct ExpiryTime(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for ExpiryTime {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for ExpiryTime {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for ExpiryTime {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for ExpiryTime {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        ExpiryTime::new_unchecked(v)
    }
}
impl ExpiryTime {
    const DEFAULT_VALUE: [u8; 16] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];
    pub const TOTAL_SIZE: usize = 16;
    pub const FIELD_SIZES: [usize; 1] = [16];
    pub const FIELD_COUNT: usize = 1;
    pub fn value(&self) -> Duration {
        Duration::new_unchecked(self.0.slice(0..16))
    }
    pub fn as_reader<'r>(&'r self) -> ExpiryTimeReader<'r> {
        ExpiryTimeReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for ExpiryTime {
    type Builder = ExpiryTimeBuilder;
    const NAME: &'static str = "ExpiryTime";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        ExpiryTime(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ExpiryTimeReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        ExpiryTimeReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().value(self.value())
    }
}
#[derive(Clone, Copy)]
pub struct ExpiryTimeReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for ExpiryTimeReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for ExpiryTimeReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for ExpiryTimeReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        write!(f, " }}")
    }
}
impl<'r> ExpiryTimeReader<'r> {
    pub const TOTAL_SIZE: usize = 16;
    pub const FIELD_SIZES: [usize; 1] = [16];
    pub const FIELD_COUNT: usize = 1;
    pub fn value(&self) -> DurationReader<'r> {
        DurationReader::new_unchecked(&self.as_slice()[0..16])
    }
}
impl<'r> molecule::prelude::Reader<'r> for ExpiryTimeReader<'r> {
    type Entity = ExpiryTime;
    const NAME: &'static str = "ExpiryTimeReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        ExpiryTimeReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct ExpiryTimeBuilder {
    pub(crate) value: Duration,
}
impl ExpiryTimeBuilder {
    pub const TOTAL_SIZE: usize = 16;
    pub const FIELD_SIZES: [usize; 1] = [16];
    pub const FIELD_COUNT: usize = 1;
    pub fn value(mut self, v: Duration) -> Self {
        self.value = v;
        self
    }
}
impl molecule::prelude::Builder for ExpiryTimeBuilder {
    type Entity = ExpiryTime;
    const NAME: &'static str = "ExpiryTimeBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.value.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        ExpiryTime::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct Description(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for Description {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for Description {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for Description {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for Description {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        Description::new_unchecked(v)
    }
}
impl Description {
    const DEFAULT_VALUE: [u8; 12] = [12, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0];
    pub const FIELD_COUNT: usize = 1;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn value(&self) -> Bytes {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[8..]) as usize;
            Bytes::new_unchecked(self.0.slice(start..end))
        } else {
            Bytes::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> DescriptionReader<'r> {
        DescriptionReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for Description {
    type Builder = DescriptionBuilder;
    const NAME: &'static str = "Description";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        Description(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        DescriptionReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        DescriptionReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().value(self.value())
    }
}
#[derive(Clone, Copy)]
pub struct DescriptionReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for DescriptionReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for DescriptionReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for DescriptionReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> DescriptionReader<'r> {
    pub const FIELD_COUNT: usize = 1;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn value(&self) -> BytesReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[8..]) as usize;
            BytesReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            BytesReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for DescriptionReader<'r> {
    type Entity = Description;
    const NAME: &'static str = "DescriptionReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        DescriptionReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        BytesReader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct DescriptionBuilder {
    pub(crate) value: Bytes,
}
impl DescriptionBuilder {
    pub const FIELD_COUNT: usize = 1;
    pub fn value(mut self, v: Bytes) -> Self {
        self.value = v;
        self
    }
}
impl molecule::prelude::Builder for DescriptionBuilder {
    type Entity = Description;
    const NAME: &'static str = "DescriptionBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1) + self.value.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.value.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.value.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        Description::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct FallbackAddr(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for FallbackAddr {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for FallbackAddr {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for FallbackAddr {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for FallbackAddr {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        FallbackAddr::new_unchecked(v)
    }
}
impl FallbackAddr {
    const DEFAULT_VALUE: [u8; 12] = [12, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0];
    pub const FIELD_COUNT: usize = 1;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn value(&self) -> Bytes {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[8..]) as usize;
            Bytes::new_unchecked(self.0.slice(start..end))
        } else {
            Bytes::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> FallbackAddrReader<'r> {
        FallbackAddrReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for FallbackAddr {
    type Builder = FallbackAddrBuilder;
    const NAME: &'static str = "FallbackAddr";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        FallbackAddr(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        FallbackAddrReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        FallbackAddrReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().value(self.value())
    }
}
#[derive(Clone, Copy)]
pub struct FallbackAddrReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for FallbackAddrReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for FallbackAddrReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for FallbackAddrReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> FallbackAddrReader<'r> {
    pub const FIELD_COUNT: usize = 1;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn value(&self) -> BytesReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[8..]) as usize;
            BytesReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            BytesReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for FallbackAddrReader<'r> {
    type Entity = FallbackAddr;
    const NAME: &'static str = "FallbackAddrReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        FallbackAddrReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        BytesReader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct FallbackAddrBuilder {
    pub(crate) value: Bytes,
}
impl FallbackAddrBuilder {
    pub const FIELD_COUNT: usize = 1;
    pub fn value(mut self, v: Bytes) -> Self {
        self.value = v;
        self
    }
}
impl molecule::prelude::Builder for FallbackAddrBuilder {
    type Entity = FallbackAddr;
    const NAME: &'static str = "FallbackAddrBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1) + self.value.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.value.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.value.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        FallbackAddr::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct Feature(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for Feature {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for Feature {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for Feature {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for Feature {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        Feature::new_unchecked(v)
    }
}
impl Feature {
    const DEFAULT_VALUE: [u8; 8] = [0, 0, 0, 0, 0, 0, 0, 0];
    pub const TOTAL_SIZE: usize = 8;
    pub const FIELD_SIZES: [usize; 1] = [8];
    pub const FIELD_COUNT: usize = 1;
    pub fn value(&self) -> Uint64 {
        Uint64::new_unchecked(self.0.slice(0..8))
    }
    pub fn as_reader<'r>(&'r self) -> FeatureReader<'r> {
        FeatureReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for Feature {
    type Builder = FeatureBuilder;
    const NAME: &'static str = "Feature";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        Feature(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        FeatureReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        FeatureReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().value(self.value())
    }
}
#[derive(Clone, Copy)]
pub struct FeatureReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for FeatureReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for FeatureReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for FeatureReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        write!(f, " }}")
    }
}
impl<'r> FeatureReader<'r> {
    pub const TOTAL_SIZE: usize = 8;
    pub const FIELD_SIZES: [usize; 1] = [8];
    pub const FIELD_COUNT: usize = 1;
    pub fn value(&self) -> Uint64Reader<'r> {
        Uint64Reader::new_unchecked(&self.as_slice()[0..8])
    }
}
impl<'r> molecule::prelude::Reader<'r> for FeatureReader<'r> {
    type Entity = Feature;
    const NAME: &'static str = "FeatureReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        FeatureReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct FeatureBuilder {
    pub(crate) value: Uint64,
}
impl FeatureBuilder {
    pub const TOTAL_SIZE: usize = 8;
    pub const FIELD_SIZES: [usize; 1] = [8];
    pub const FIELD_COUNT: usize = 1;
    pub fn value(mut self, v: Uint64) -> Self {
        self.value = v;
        self
    }
}
impl molecule::prelude::Builder for FeatureBuilder {
    type Entity = Feature;
    const NAME: &'static str = "FeatureBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.value.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        Feature::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct UdtScript(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for UdtScript {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for UdtScript {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for UdtScript {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for UdtScript {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        UdtScript::new_unchecked(v)
    }
}
impl UdtScript {
    const DEFAULT_VALUE: [u8; 61] = [
        61, 0, 0, 0, 8, 0, 0, 0, 53, 0, 0, 0, 16, 0, 0, 0, 48, 0, 0, 0, 49, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0,
    ];
    pub const FIELD_COUNT: usize = 1;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn value(&self) -> Script {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[8..]) as usize;
            Script::new_unchecked(self.0.slice(start..end))
        } else {
            Script::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> UdtScriptReader<'r> {
        UdtScriptReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for UdtScript {
    type Builder = UdtScriptBuilder;
    const NAME: &'static str = "UdtScript";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        UdtScript(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        UdtScriptReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        UdtScriptReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().value(self.value())
    }
}
#[derive(Clone, Copy)]
pub struct UdtScriptReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for UdtScriptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for UdtScriptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for UdtScriptReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> UdtScriptReader<'r> {
    pub const FIELD_COUNT: usize = 1;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn value(&self) -> ScriptReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[8..]) as usize;
            ScriptReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            ScriptReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for UdtScriptReader<'r> {
    type Entity = UdtScript;
    const NAME: &'static str = "UdtScriptReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        UdtScriptReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        ScriptReader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct UdtScriptBuilder {
    pub(crate) value: Script,
}
impl UdtScriptBuilder {
    pub const FIELD_COUNT: usize = 1;
    pub fn value(mut self, v: Script) -> Self {
        self.value = v;
        self
    }
}
impl molecule::prelude::Builder for UdtScriptBuilder {
    type Entity = UdtScript;
    const NAME: &'static str = "UdtScriptBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1) + self.value.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.value.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.value.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        UdtScript::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct PayeePublicKey(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for PayeePublicKey {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for PayeePublicKey {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for PayeePublicKey {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for PayeePublicKey {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        PayeePublicKey::new_unchecked(v)
    }
}
impl PayeePublicKey {
    const DEFAULT_VALUE: [u8; 12] = [12, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0];
    pub const FIELD_COUNT: usize = 1;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn value(&self) -> Bytes {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[8..]) as usize;
            Bytes::new_unchecked(self.0.slice(start..end))
        } else {
            Bytes::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> PayeePublicKeyReader<'r> {
        PayeePublicKeyReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for PayeePublicKey {
    type Builder = PayeePublicKeyBuilder;
    const NAME: &'static str = "PayeePublicKey";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        PayeePublicKey(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        PayeePublicKeyReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        PayeePublicKeyReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().value(self.value())
    }
}
#[derive(Clone, Copy)]
pub struct PayeePublicKeyReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for PayeePublicKeyReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for PayeePublicKeyReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for PayeePublicKeyReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> PayeePublicKeyReader<'r> {
    pub const FIELD_COUNT: usize = 1;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn value(&self) -> BytesReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[8..]) as usize;
            BytesReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            BytesReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for PayeePublicKeyReader<'r> {
    type Entity = PayeePublicKey;
    const NAME: &'static str = "PayeePublicKeyReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        PayeePublicKeyReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        BytesReader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct PayeePublicKeyBuilder {
    pub(crate) value: Bytes,
}
impl PayeePublicKeyBuilder {
    pub const FIELD_COUNT: usize = 1;
    pub fn value(mut self, v: Bytes) -> Self {
        self.value = v;
        self
    }
}
impl molecule::prelude::Builder for PayeePublicKeyBuilder {
    type Entity = PayeePublicKey;
    const NAME: &'static str = "PayeePublicKeyBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1) + self.value.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.value.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.value.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        PayeePublicKey::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct HashAlgorithm(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for HashAlgorithm {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for HashAlgorithm {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for HashAlgorithm {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        write!(f, " }}")
    }
}
impl ::core::default::Default for HashAlgorithm {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        HashAlgorithm::new_unchecked(v)
    }
}
impl HashAlgorithm {
    const DEFAULT_VALUE: [u8; 1] = [0];
    pub const TOTAL_SIZE: usize = 1;
    pub const FIELD_SIZES: [usize; 1] = [1];
    pub const FIELD_COUNT: usize = 1;
    pub fn value(&self) -> Byte {
        Byte::new_unchecked(self.0.slice(0..1))
    }
    pub fn as_reader<'r>(&'r self) -> HashAlgorithmReader<'r> {
        HashAlgorithmReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for HashAlgorithm {
    type Builder = HashAlgorithmBuilder;
    const NAME: &'static str = "HashAlgorithm";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        HashAlgorithm(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        HashAlgorithmReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        HashAlgorithmReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().value(self.value())
    }
}
#[derive(Clone, Copy)]
pub struct HashAlgorithmReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for HashAlgorithmReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for HashAlgorithmReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for HashAlgorithmReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "value", self.value())?;
        write!(f, " }}")
    }
}
impl<'r> HashAlgorithmReader<'r> {
    pub const TOTAL_SIZE: usize = 1;
    pub const FIELD_SIZES: [usize; 1] = [1];
    pub const FIELD_COUNT: usize = 1;
    pub fn value(&self) -> ByteReader<'r> {
        ByteReader::new_unchecked(&self.as_slice()[0..1])
    }
}
impl<'r> molecule::prelude::Reader<'r> for HashAlgorithmReader<'r> {
    type Entity = HashAlgorithm;
    const NAME: &'static str = "HashAlgorithmReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        HashAlgorithmReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], _compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len != Self::TOTAL_SIZE {
            return ve!(Self, TotalSizeNotMatch, Self::TOTAL_SIZE, slice_len);
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct HashAlgorithmBuilder {
    pub(crate) value: Byte,
}
impl HashAlgorithmBuilder {
    pub const TOTAL_SIZE: usize = 1;
    pub const FIELD_SIZES: [usize; 1] = [1];
    pub const FIELD_COUNT: usize = 1;
    pub fn value(mut self, v: Byte) -> Self {
        self.value = v;
        self
    }
}
impl molecule::prelude::Builder for HashAlgorithmBuilder {
    type Entity = HashAlgorithm;
    const NAME: &'static str = "HashAlgorithmBuilder";
    fn expected_length(&self) -> usize {
        Self::TOTAL_SIZE
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(self.value.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        HashAlgorithm::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct InvoiceAttr(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for InvoiceAttr {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for InvoiceAttr {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for InvoiceAttr {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}(", Self::NAME)?;
        self.to_enum().display_inner(f)?;
        write!(f, ")")
    }
}
impl ::core::default::Default for InvoiceAttr {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        InvoiceAttr::new_unchecked(v)
    }
}
impl InvoiceAttr {
    const DEFAULT_VALUE: [u8; 20] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];
    pub const ITEMS_COUNT: usize = 9;
    pub fn item_id(&self) -> molecule::Number {
        molecule::unpack_number(self.as_slice())
    }
    pub fn to_enum(&self) -> InvoiceAttrUnion {
        let inner = self.0.slice(molecule::NUMBER_SIZE..);
        match self.item_id() {
            0 => ExpiryTime::new_unchecked(inner).into(),
            1 => Description::new_unchecked(inner).into(),
            2 => FinalHtlcTimeout::new_unchecked(inner).into(),
            3 => FinalHtlcMinimumExpiryDelta::new_unchecked(inner).into(),
            4 => FallbackAddr::new_unchecked(inner).into(),
            5 => Feature::new_unchecked(inner).into(),
            6 => UdtScript::new_unchecked(inner).into(),
            7 => PayeePublicKey::new_unchecked(inner).into(),
            8 => HashAlgorithm::new_unchecked(inner).into(),
            _ => panic!("{}: invalid data", Self::NAME),
        }
    }
    pub fn as_reader<'r>(&'r self) -> InvoiceAttrReader<'r> {
        InvoiceAttrReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for InvoiceAttr {
    type Builder = InvoiceAttrBuilder;
    const NAME: &'static str = "InvoiceAttr";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        InvoiceAttr(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        InvoiceAttrReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        InvoiceAttrReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().set(self.to_enum())
    }
}
#[derive(Clone, Copy)]
pub struct InvoiceAttrReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for InvoiceAttrReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for InvoiceAttrReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for InvoiceAttrReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}(", Self::NAME)?;
        self.to_enum().display_inner(f)?;
        write!(f, ")")
    }
}
impl<'r> InvoiceAttrReader<'r> {
    pub const ITEMS_COUNT: usize = 9;
    pub fn item_id(&self) -> molecule::Number {
        molecule::unpack_number(self.as_slice())
    }
    pub fn to_enum(&self) -> InvoiceAttrUnionReader<'r> {
        let inner = &self.as_slice()[molecule::NUMBER_SIZE..];
        match self.item_id() {
            0 => ExpiryTimeReader::new_unchecked(inner).into(),
            1 => DescriptionReader::new_unchecked(inner).into(),
            2 => FinalHtlcTimeoutReader::new_unchecked(inner).into(),
            3 => FinalHtlcMinimumExpiryDeltaReader::new_unchecked(inner).into(),
            4 => FallbackAddrReader::new_unchecked(inner).into(),
            5 => FeatureReader::new_unchecked(inner).into(),
            6 => UdtScriptReader::new_unchecked(inner).into(),
            7 => PayeePublicKeyReader::new_unchecked(inner).into(),
            8 => HashAlgorithmReader::new_unchecked(inner).into(),
            _ => panic!("{}: invalid data", Self::NAME),
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for InvoiceAttrReader<'r> {
    type Entity = InvoiceAttr;
    const NAME: &'static str = "InvoiceAttrReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        InvoiceAttrReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let item_id = molecule::unpack_number(slice);
        let inner_slice = &slice[molecule::NUMBER_SIZE..];
        match item_id {
            0 => ExpiryTimeReader::verify(inner_slice, compatible),
            1 => DescriptionReader::verify(inner_slice, compatible),
            2 => FinalHtlcTimeoutReader::verify(inner_slice, compatible),
            3 => FinalHtlcMinimumExpiryDeltaReader::verify(inner_slice, compatible),
            4 => FallbackAddrReader::verify(inner_slice, compatible),
            5 => FeatureReader::verify(inner_slice, compatible),
            6 => UdtScriptReader::verify(inner_slice, compatible),
            7 => PayeePublicKeyReader::verify(inner_slice, compatible),
            8 => HashAlgorithmReader::verify(inner_slice, compatible),
            _ => ve!(Self, UnknownItem, Self::ITEMS_COUNT, item_id),
        }?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct InvoiceAttrBuilder(pub(crate) InvoiceAttrUnion);
impl InvoiceAttrBuilder {
    pub const ITEMS_COUNT: usize = 9;
    pub fn set<I>(mut self, v: I) -> Self
    where
        I: ::core::convert::Into<InvoiceAttrUnion>,
    {
        self.0 = v.into();
        self
    }
}
impl molecule::prelude::Builder for InvoiceAttrBuilder {
    type Entity = InvoiceAttr;
    const NAME: &'static str = "InvoiceAttrBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE + self.0.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        writer.write_all(&molecule::pack_number(self.0.item_id()))?;
        writer.write_all(self.0.as_slice())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        InvoiceAttr::new_unchecked(inner.into())
    }
}
#[derive(Debug, Clone)]
pub enum InvoiceAttrUnion {
    ExpiryTime(ExpiryTime),
    Description(Description),
    FinalHtlcTimeout(FinalHtlcTimeout),
    FinalHtlcMinimumExpiryDelta(FinalHtlcMinimumExpiryDelta),
    FallbackAddr(FallbackAddr),
    Feature(Feature),
    UdtScript(UdtScript),
    PayeePublicKey(PayeePublicKey),
    HashAlgorithm(HashAlgorithm),
}
#[derive(Debug, Clone, Copy)]
pub enum InvoiceAttrUnionReader<'r> {
    ExpiryTime(ExpiryTimeReader<'r>),
    Description(DescriptionReader<'r>),
    FinalHtlcTimeout(FinalHtlcTimeoutReader<'r>),
    FinalHtlcMinimumExpiryDelta(FinalHtlcMinimumExpiryDeltaReader<'r>),
    FallbackAddr(FallbackAddrReader<'r>),
    Feature(FeatureReader<'r>),
    UdtScript(UdtScriptReader<'r>),
    PayeePublicKey(PayeePublicKeyReader<'r>),
    HashAlgorithm(HashAlgorithmReader<'r>),
}
impl ::core::default::Default for InvoiceAttrUnion {
    fn default() -> Self {
        InvoiceAttrUnion::ExpiryTime(::core::default::Default::default())
    }
}
impl ::core::fmt::Display for InvoiceAttrUnion {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            InvoiceAttrUnion::ExpiryTime(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, ExpiryTime::NAME, item)
            }
            InvoiceAttrUnion::Description(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, Description::NAME, item)
            }
            InvoiceAttrUnion::FinalHtlcTimeout(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, FinalHtlcTimeout::NAME, item)
            }
            InvoiceAttrUnion::FinalHtlcMinimumExpiryDelta(ref item) => {
                write!(
                    f,
                    "{}::{}({})",
                    Self::NAME,
                    FinalHtlcMinimumExpiryDelta::NAME,
                    item
                )
            }
            InvoiceAttrUnion::FallbackAddr(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, FallbackAddr::NAME, item)
            }
            InvoiceAttrUnion::Feature(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, Feature::NAME, item)
            }
            InvoiceAttrUnion::UdtScript(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, UdtScript::NAME, item)
            }
            InvoiceAttrUnion::PayeePublicKey(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, PayeePublicKey::NAME, item)
            }
            InvoiceAttrUnion::HashAlgorithm(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, HashAlgorithm::NAME, item)
            }
        }
    }
}
impl<'r> ::core::fmt::Display for InvoiceAttrUnionReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            InvoiceAttrUnionReader::ExpiryTime(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, ExpiryTime::NAME, item)
            }
            InvoiceAttrUnionReader::Description(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, Description::NAME, item)
            }
            InvoiceAttrUnionReader::FinalHtlcTimeout(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, FinalHtlcTimeout::NAME, item)
            }
            InvoiceAttrUnionReader::FinalHtlcMinimumExpiryDelta(ref item) => {
                write!(
                    f,
                    "{}::{}({})",
                    Self::NAME,
                    FinalHtlcMinimumExpiryDelta::NAME,
                    item
                )
            }
            InvoiceAttrUnionReader::FallbackAddr(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, FallbackAddr::NAME, item)
            }
            InvoiceAttrUnionReader::Feature(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, Feature::NAME, item)
            }
            InvoiceAttrUnionReader::UdtScript(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, UdtScript::NAME, item)
            }
            InvoiceAttrUnionReader::PayeePublicKey(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, PayeePublicKey::NAME, item)
            }
            InvoiceAttrUnionReader::HashAlgorithm(ref item) => {
                write!(f, "{}::{}({})", Self::NAME, HashAlgorithm::NAME, item)
            }
        }
    }
}
impl InvoiceAttrUnion {
    pub(crate) fn display_inner(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            InvoiceAttrUnion::ExpiryTime(ref item) => write!(f, "{}", item),
            InvoiceAttrUnion::Description(ref item) => write!(f, "{}", item),
            InvoiceAttrUnion::FinalHtlcTimeout(ref item) => write!(f, "{}", item),
            InvoiceAttrUnion::FinalHtlcMinimumExpiryDelta(ref item) => write!(f, "{}", item),
            InvoiceAttrUnion::FallbackAddr(ref item) => write!(f, "{}", item),
            InvoiceAttrUnion::Feature(ref item) => write!(f, "{}", item),
            InvoiceAttrUnion::UdtScript(ref item) => write!(f, "{}", item),
            InvoiceAttrUnion::PayeePublicKey(ref item) => write!(f, "{}", item),
            InvoiceAttrUnion::HashAlgorithm(ref item) => write!(f, "{}", item),
        }
    }
}
impl<'r> InvoiceAttrUnionReader<'r> {
    pub(crate) fn display_inner(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        match self {
            InvoiceAttrUnionReader::ExpiryTime(ref item) => write!(f, "{}", item),
            InvoiceAttrUnionReader::Description(ref item) => write!(f, "{}", item),
            InvoiceAttrUnionReader::FinalHtlcTimeout(ref item) => write!(f, "{}", item),
            InvoiceAttrUnionReader::FinalHtlcMinimumExpiryDelta(ref item) => write!(f, "{}", item),
            InvoiceAttrUnionReader::FallbackAddr(ref item) => write!(f, "{}", item),
            InvoiceAttrUnionReader::Feature(ref item) => write!(f, "{}", item),
            InvoiceAttrUnionReader::UdtScript(ref item) => write!(f, "{}", item),
            InvoiceAttrUnionReader::PayeePublicKey(ref item) => write!(f, "{}", item),
            InvoiceAttrUnionReader::HashAlgorithm(ref item) => write!(f, "{}", item),
        }
    }
}
impl ::core::convert::From<ExpiryTime> for InvoiceAttrUnion {
    fn from(item: ExpiryTime) -> Self {
        InvoiceAttrUnion::ExpiryTime(item)
    }
}
impl ::core::convert::From<Description> for InvoiceAttrUnion {
    fn from(item: Description) -> Self {
        InvoiceAttrUnion::Description(item)
    }
}
impl ::core::convert::From<FinalHtlcTimeout> for InvoiceAttrUnion {
    fn from(item: FinalHtlcTimeout) -> Self {
        InvoiceAttrUnion::FinalHtlcTimeout(item)
    }
}
impl ::core::convert::From<FinalHtlcMinimumExpiryDelta> for InvoiceAttrUnion {
    fn from(item: FinalHtlcMinimumExpiryDelta) -> Self {
        InvoiceAttrUnion::FinalHtlcMinimumExpiryDelta(item)
    }
}
impl ::core::convert::From<FallbackAddr> for InvoiceAttrUnion {
    fn from(item: FallbackAddr) -> Self {
        InvoiceAttrUnion::FallbackAddr(item)
    }
}
impl ::core::convert::From<Feature> for InvoiceAttrUnion {
    fn from(item: Feature) -> Self {
        InvoiceAttrUnion::Feature(item)
    }
}
impl ::core::convert::From<UdtScript> for InvoiceAttrUnion {
    fn from(item: UdtScript) -> Self {
        InvoiceAttrUnion::UdtScript(item)
    }
}
impl ::core::convert::From<PayeePublicKey> for InvoiceAttrUnion {
    fn from(item: PayeePublicKey) -> Self {
        InvoiceAttrUnion::PayeePublicKey(item)
    }
}
impl ::core::convert::From<HashAlgorithm> for InvoiceAttrUnion {
    fn from(item: HashAlgorithm) -> Self {
        InvoiceAttrUnion::HashAlgorithm(item)
    }
}
impl<'r> ::core::convert::From<ExpiryTimeReader<'r>> for InvoiceAttrUnionReader<'r> {
    fn from(item: ExpiryTimeReader<'r>) -> Self {
        InvoiceAttrUnionReader::ExpiryTime(item)
    }
}
impl<'r> ::core::convert::From<DescriptionReader<'r>> for InvoiceAttrUnionReader<'r> {
    fn from(item: DescriptionReader<'r>) -> Self {
        InvoiceAttrUnionReader::Description(item)
    }
}
impl<'r> ::core::convert::From<FinalHtlcTimeoutReader<'r>> for InvoiceAttrUnionReader<'r> {
    fn from(item: FinalHtlcTimeoutReader<'r>) -> Self {
        InvoiceAttrUnionReader::FinalHtlcTimeout(item)
    }
}
impl<'r> ::core::convert::From<FinalHtlcMinimumExpiryDeltaReader<'r>>
    for InvoiceAttrUnionReader<'r>
{
    fn from(item: FinalHtlcMinimumExpiryDeltaReader<'r>) -> Self {
        InvoiceAttrUnionReader::FinalHtlcMinimumExpiryDelta(item)
    }
}
impl<'r> ::core::convert::From<FallbackAddrReader<'r>> for InvoiceAttrUnionReader<'r> {
    fn from(item: FallbackAddrReader<'r>) -> Self {
        InvoiceAttrUnionReader::FallbackAddr(item)
    }
}
impl<'r> ::core::convert::From<FeatureReader<'r>> for InvoiceAttrUnionReader<'r> {
    fn from(item: FeatureReader<'r>) -> Self {
        InvoiceAttrUnionReader::Feature(item)
    }
}
impl<'r> ::core::convert::From<UdtScriptReader<'r>> for InvoiceAttrUnionReader<'r> {
    fn from(item: UdtScriptReader<'r>) -> Self {
        InvoiceAttrUnionReader::UdtScript(item)
    }
}
impl<'r> ::core::convert::From<PayeePublicKeyReader<'r>> for InvoiceAttrUnionReader<'r> {
    fn from(item: PayeePublicKeyReader<'r>) -> Self {
        InvoiceAttrUnionReader::PayeePublicKey(item)
    }
}
impl<'r> ::core::convert::From<HashAlgorithmReader<'r>> for InvoiceAttrUnionReader<'r> {
    fn from(item: HashAlgorithmReader<'r>) -> Self {
        InvoiceAttrUnionReader::HashAlgorithm(item)
    }
}
impl InvoiceAttrUnion {
    pub const NAME: &'static str = "InvoiceAttrUnion";
    pub fn as_bytes(&self) -> molecule::bytes::Bytes {
        match self {
            InvoiceAttrUnion::ExpiryTime(item) => item.as_bytes(),
            InvoiceAttrUnion::Description(item) => item.as_bytes(),
            InvoiceAttrUnion::FinalHtlcTimeout(item) => item.as_bytes(),
            InvoiceAttrUnion::FinalHtlcMinimumExpiryDelta(item) => item.as_bytes(),
            InvoiceAttrUnion::FallbackAddr(item) => item.as_bytes(),
            InvoiceAttrUnion::Feature(item) => item.as_bytes(),
            InvoiceAttrUnion::UdtScript(item) => item.as_bytes(),
            InvoiceAttrUnion::PayeePublicKey(item) => item.as_bytes(),
            InvoiceAttrUnion::HashAlgorithm(item) => item.as_bytes(),
        }
    }
    pub fn as_slice(&self) -> &[u8] {
        match self {
            InvoiceAttrUnion::ExpiryTime(item) => item.as_slice(),
            InvoiceAttrUnion::Description(item) => item.as_slice(),
            InvoiceAttrUnion::FinalHtlcTimeout(item) => item.as_slice(),
            InvoiceAttrUnion::FinalHtlcMinimumExpiryDelta(item) => item.as_slice(),
            InvoiceAttrUnion::FallbackAddr(item) => item.as_slice(),
            InvoiceAttrUnion::Feature(item) => item.as_slice(),
            InvoiceAttrUnion::UdtScript(item) => item.as_slice(),
            InvoiceAttrUnion::PayeePublicKey(item) => item.as_slice(),
            InvoiceAttrUnion::HashAlgorithm(item) => item.as_slice(),
        }
    }
    pub fn item_id(&self) -> molecule::Number {
        match self {
            InvoiceAttrUnion::ExpiryTime(_) => 0,
            InvoiceAttrUnion::Description(_) => 1,
            InvoiceAttrUnion::FinalHtlcTimeout(_) => 2,
            InvoiceAttrUnion::FinalHtlcMinimumExpiryDelta(_) => 3,
            InvoiceAttrUnion::FallbackAddr(_) => 4,
            InvoiceAttrUnion::Feature(_) => 5,
            InvoiceAttrUnion::UdtScript(_) => 6,
            InvoiceAttrUnion::PayeePublicKey(_) => 7,
            InvoiceAttrUnion::HashAlgorithm(_) => 8,
        }
    }
    pub fn item_name(&self) -> &str {
        match self {
            InvoiceAttrUnion::ExpiryTime(_) => "ExpiryTime",
            InvoiceAttrUnion::Description(_) => "Description",
            InvoiceAttrUnion::FinalHtlcTimeout(_) => "FinalHtlcTimeout",
            InvoiceAttrUnion::FinalHtlcMinimumExpiryDelta(_) => "FinalHtlcMinimumExpiryDelta",
            InvoiceAttrUnion::FallbackAddr(_) => "FallbackAddr",
            InvoiceAttrUnion::Feature(_) => "Feature",
            InvoiceAttrUnion::UdtScript(_) => "UdtScript",
            InvoiceAttrUnion::PayeePublicKey(_) => "PayeePublicKey",
            InvoiceAttrUnion::HashAlgorithm(_) => "HashAlgorithm",
        }
    }
    pub fn as_reader<'r>(&'r self) -> InvoiceAttrUnionReader<'r> {
        match self {
            InvoiceAttrUnion::ExpiryTime(item) => item.as_reader().into(),
            InvoiceAttrUnion::Description(item) => item.as_reader().into(),
            InvoiceAttrUnion::FinalHtlcTimeout(item) => item.as_reader().into(),
            InvoiceAttrUnion::FinalHtlcMinimumExpiryDelta(item) => item.as_reader().into(),
            InvoiceAttrUnion::FallbackAddr(item) => item.as_reader().into(),
            InvoiceAttrUnion::Feature(item) => item.as_reader().into(),
            InvoiceAttrUnion::UdtScript(item) => item.as_reader().into(),
            InvoiceAttrUnion::PayeePublicKey(item) => item.as_reader().into(),
            InvoiceAttrUnion::HashAlgorithm(item) => item.as_reader().into(),
        }
    }
}
impl<'r> InvoiceAttrUnionReader<'r> {
    pub const NAME: &'r str = "InvoiceAttrUnionReader";
    pub fn as_slice(&self) -> &'r [u8] {
        match self {
            InvoiceAttrUnionReader::ExpiryTime(item) => item.as_slice(),
            InvoiceAttrUnionReader::Description(item) => item.as_slice(),
            InvoiceAttrUnionReader::FinalHtlcTimeout(item) => item.as_slice(),
            InvoiceAttrUnionReader::FinalHtlcMinimumExpiryDelta(item) => item.as_slice(),
            InvoiceAttrUnionReader::FallbackAddr(item) => item.as_slice(),
            InvoiceAttrUnionReader::Feature(item) => item.as_slice(),
            InvoiceAttrUnionReader::UdtScript(item) => item.as_slice(),
            InvoiceAttrUnionReader::PayeePublicKey(item) => item.as_slice(),
            InvoiceAttrUnionReader::HashAlgorithm(item) => item.as_slice(),
        }
    }
    pub fn item_id(&self) -> molecule::Number {
        match self {
            InvoiceAttrUnionReader::ExpiryTime(_) => 0,
            InvoiceAttrUnionReader::Description(_) => 1,
            InvoiceAttrUnionReader::FinalHtlcTimeout(_) => 2,
            InvoiceAttrUnionReader::FinalHtlcMinimumExpiryDelta(_) => 3,
            InvoiceAttrUnionReader::FallbackAddr(_) => 4,
            InvoiceAttrUnionReader::Feature(_) => 5,
            InvoiceAttrUnionReader::UdtScript(_) => 6,
            InvoiceAttrUnionReader::PayeePublicKey(_) => 7,
            InvoiceAttrUnionReader::HashAlgorithm(_) => 8,
        }
    }
    pub fn item_name(&self) -> &str {
        match self {
            InvoiceAttrUnionReader::ExpiryTime(_) => "ExpiryTime",
            InvoiceAttrUnionReader::Description(_) => "Description",
            InvoiceAttrUnionReader::FinalHtlcTimeout(_) => "FinalHtlcTimeout",
            InvoiceAttrUnionReader::FinalHtlcMinimumExpiryDelta(_) => "FinalHtlcMinimumExpiryDelta",
            InvoiceAttrUnionReader::FallbackAddr(_) => "FallbackAddr",
            InvoiceAttrUnionReader::Feature(_) => "Feature",
            InvoiceAttrUnionReader::UdtScript(_) => "UdtScript",
            InvoiceAttrUnionReader::PayeePublicKey(_) => "PayeePublicKey",
            InvoiceAttrUnionReader::HashAlgorithm(_) => "HashAlgorithm",
        }
    }
}
impl From<ExpiryTime> for InvoiceAttr {
    fn from(value: ExpiryTime) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<Description> for InvoiceAttr {
    fn from(value: Description) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<FinalHtlcTimeout> for InvoiceAttr {
    fn from(value: FinalHtlcTimeout) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<FinalHtlcMinimumExpiryDelta> for InvoiceAttr {
    fn from(value: FinalHtlcMinimumExpiryDelta) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<FallbackAddr> for InvoiceAttr {
    fn from(value: FallbackAddr) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<Feature> for InvoiceAttr {
    fn from(value: Feature) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<UdtScript> for InvoiceAttr {
    fn from(value: UdtScript) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<PayeePublicKey> for InvoiceAttr {
    fn from(value: PayeePublicKey) -> Self {
        Self::new_builder().set(value).build()
    }
}
impl From<HashAlgorithm> for InvoiceAttr {
    fn from(value: HashAlgorithm) -> Self {
        Self::new_builder().set(value).build()
    }
}
#[derive(Clone)]
pub struct InvoiceAttrsVec(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for InvoiceAttrsVec {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for InvoiceAttrsVec {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for InvoiceAttrsVec {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} [", Self::NAME)?;
        for i in 0..self.len() {
            if i == 0 {
                write!(f, "{}", self.get_unchecked(i))?;
            } else {
                write!(f, ", {}", self.get_unchecked(i))?;
            }
        }
        write!(f, "]")
    }
}
impl ::core::default::Default for InvoiceAttrsVec {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        InvoiceAttrsVec::new_unchecked(v)
    }
}
impl InvoiceAttrsVec {
    const DEFAULT_VALUE: [u8; 4] = [4, 0, 0, 0];
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn item_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn len(&self) -> usize {
        self.item_count()
    }
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
    pub fn get(&self, idx: usize) -> Option<InvoiceAttr> {
        if idx >= self.len() {
            None
        } else {
            Some(self.get_unchecked(idx))
        }
    }
    pub fn get_unchecked(&self, idx: usize) -> InvoiceAttr {
        let slice = self.as_slice();
        let start_idx = molecule::NUMBER_SIZE * (1 + idx);
        let start = molecule::unpack_number(&slice[start_idx..]) as usize;
        if idx == self.len() - 1 {
            InvoiceAttr::new_unchecked(self.0.slice(start..))
        } else {
            let end_idx = start_idx + molecule::NUMBER_SIZE;
            let end = molecule::unpack_number(&slice[end_idx..]) as usize;
            InvoiceAttr::new_unchecked(self.0.slice(start..end))
        }
    }
    pub fn as_reader<'r>(&'r self) -> InvoiceAttrsVecReader<'r> {
        InvoiceAttrsVecReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for InvoiceAttrsVec {
    type Builder = InvoiceAttrsVecBuilder;
    const NAME: &'static str = "InvoiceAttrsVec";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        InvoiceAttrsVec(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        InvoiceAttrsVecReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        InvoiceAttrsVecReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder().extend(self.into_iter())
    }
}
#[derive(Clone, Copy)]
pub struct InvoiceAttrsVecReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for InvoiceAttrsVecReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for InvoiceAttrsVecReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for InvoiceAttrsVecReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} [", Self::NAME)?;
        for i in 0..self.len() {
            if i == 0 {
                write!(f, "{}", self.get_unchecked(i))?;
            } else {
                write!(f, ", {}", self.get_unchecked(i))?;
            }
        }
        write!(f, "]")
    }
}
impl<'r> InvoiceAttrsVecReader<'r> {
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn item_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn len(&self) -> usize {
        self.item_count()
    }
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
    pub fn get(&self, idx: usize) -> Option<InvoiceAttrReader<'r>> {
        if idx >= self.len() {
            None
        } else {
            Some(self.get_unchecked(idx))
        }
    }
    pub fn get_unchecked(&self, idx: usize) -> InvoiceAttrReader<'r> {
        let slice = self.as_slice();
        let start_idx = molecule::NUMBER_SIZE * (1 + idx);
        let start = molecule::unpack_number(&slice[start_idx..]) as usize;
        if idx == self.len() - 1 {
            InvoiceAttrReader::new_unchecked(&self.as_slice()[start..])
        } else {
            let end_idx = start_idx + molecule::NUMBER_SIZE;
            let end = molecule::unpack_number(&slice[end_idx..]) as usize;
            InvoiceAttrReader::new_unchecked(&self.as_slice()[start..end])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for InvoiceAttrsVecReader<'r> {
    type Entity = InvoiceAttrsVec;
    const NAME: &'static str = "InvoiceAttrsVecReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        InvoiceAttrsVecReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len == molecule::NUMBER_SIZE {
            return Ok(());
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(
                Self,
                TotalSizeNotMatch,
                molecule::NUMBER_SIZE * 2,
                slice_len
            );
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        for pair in offsets.windows(2) {
            let start = pair[0];
            let end = pair[1];
            InvoiceAttrReader::verify(&slice[start..end], compatible)?;
        }
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct InvoiceAttrsVecBuilder(pub(crate) Vec<InvoiceAttr>);
impl InvoiceAttrsVecBuilder {
    pub fn set(mut self, v: Vec<InvoiceAttr>) -> Self {
        self.0 = v;
        self
    }
    pub fn push(mut self, v: InvoiceAttr) -> Self {
        self.0.push(v);
        self
    }
    pub fn extend<T: ::core::iter::IntoIterator<Item = InvoiceAttr>>(mut self, iter: T) -> Self {
        for elem in iter {
            self.0.push(elem);
        }
        self
    }
    pub fn replace(&mut self, index: usize, v: InvoiceAttr) -> Option<InvoiceAttr> {
        self.0
            .get_mut(index)
            .map(|item| ::core::mem::replace(item, v))
    }
}
impl molecule::prelude::Builder for InvoiceAttrsVecBuilder {
    type Entity = InvoiceAttrsVec;
    const NAME: &'static str = "InvoiceAttrsVecBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (self.0.len() + 1)
            + self
                .0
                .iter()
                .map(|inner| inner.as_slice().len())
                .sum::<usize>()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let item_count = self.0.len();
        if item_count == 0 {
            writer.write_all(&molecule::pack_number(
                molecule::NUMBER_SIZE as molecule::Number,
            ))?;
        } else {
            let (total_size, offsets) = self.0.iter().fold(
                (
                    molecule::NUMBER_SIZE * (item_count + 1),
                    Vec::with_capacity(item_count),
                ),
                |(start, mut offsets), inner| {
                    offsets.push(start);
                    (start + inner.as_slice().len(), offsets)
                },
            );
            writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
            for offset in offsets.into_iter() {
                writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
            }
            for inner in self.0.iter() {
                writer.write_all(inner.as_slice())?;
            }
        }
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        InvoiceAttrsVec::new_unchecked(inner.into())
    }
}
pub struct InvoiceAttrsVecIterator(InvoiceAttrsVec, usize, usize);
impl ::core::iter::Iterator for InvoiceAttrsVecIterator {
    type Item = InvoiceAttr;
    fn next(&mut self) -> Option<Self::Item> {
        if self.1 >= self.2 {
            None
        } else {
            let ret = self.0.get_unchecked(self.1);
            self.1 += 1;
            Some(ret)
        }
    }
}
impl ::core::iter::ExactSizeIterator for InvoiceAttrsVecIterator {
    fn len(&self) -> usize {
        self.2 - self.1
    }
}
impl ::core::iter::IntoIterator for InvoiceAttrsVec {
    type Item = InvoiceAttr;
    type IntoIter = InvoiceAttrsVecIterator;
    fn into_iter(self) -> Self::IntoIter {
        let len = self.len();
        InvoiceAttrsVecIterator(self, 0, len)
    }
}
impl<'r> InvoiceAttrsVecReader<'r> {
    pub fn iter<'t>(&'t self) -> InvoiceAttrsVecReaderIterator<'t, 'r> {
        InvoiceAttrsVecReaderIterator(&self, 0, self.len())
    }
}
pub struct InvoiceAttrsVecReaderIterator<'t, 'r>(&'t InvoiceAttrsVecReader<'r>, usize, usize);
impl<'t: 'r, 'r> ::core::iter::Iterator for InvoiceAttrsVecReaderIterator<'t, 'r> {
    type Item = InvoiceAttrReader<'t>;
    fn next(&mut self) -> Option<Self::Item> {
        if self.1 >= self.2 {
            None
        } else {
            let ret = self.0.get_unchecked(self.1);
            self.1 += 1;
            Some(ret)
        }
    }
}
impl<'t: 'r, 'r> ::core::iter::ExactSizeIterator for InvoiceAttrsVecReaderIterator<'t, 'r> {
    fn len(&self) -> usize {
        self.2 - self.1
    }
}
impl ::core::iter::FromIterator<InvoiceAttr> for InvoiceAttrsVec {
    fn from_iter<T: IntoIterator<Item = InvoiceAttr>>(iter: T) -> Self {
        Self::new_builder().extend(iter).build()
    }
}
#[derive(Clone)]
pub struct RawInvoiceData(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for RawInvoiceData {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for RawInvoiceData {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for RawInvoiceData {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "timestamp", self.timestamp())?;
        write!(f, ", {}: {}", "payment_hash", self.payment_hash())?;
        write!(f, ", {}: {}", "attrs", self.attrs())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for RawInvoiceData {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        RawInvoiceData::new_unchecked(v)
    }
}
impl RawInvoiceData {
    const DEFAULT_VALUE: [u8; 68] = [
        68, 0, 0, 0, 16, 0, 0, 0, 32, 0, 0, 0, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 4, 0, 0, 0,
    ];
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn timestamp(&self) -> Uint128 {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Uint128::new_unchecked(self.0.slice(start..end))
    }
    pub fn payment_hash(&self) -> PaymentHash {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        PaymentHash::new_unchecked(self.0.slice(start..end))
    }
    pub fn attrs(&self) -> InvoiceAttrsVec {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            InvoiceAttrsVec::new_unchecked(self.0.slice(start..end))
        } else {
            InvoiceAttrsVec::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> RawInvoiceDataReader<'r> {
        RawInvoiceDataReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for RawInvoiceData {
    type Builder = RawInvoiceDataBuilder;
    const NAME: &'static str = "RawInvoiceData";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        RawInvoiceData(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        RawInvoiceDataReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        RawInvoiceDataReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .timestamp(self.timestamp())
            .payment_hash(self.payment_hash())
            .attrs(self.attrs())
    }
}
#[derive(Clone, Copy)]
pub struct RawInvoiceDataReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for RawInvoiceDataReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for RawInvoiceDataReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for RawInvoiceDataReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "timestamp", self.timestamp())?;
        write!(f, ", {}: {}", "payment_hash", self.payment_hash())?;
        write!(f, ", {}: {}", "attrs", self.attrs())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> RawInvoiceDataReader<'r> {
    pub const FIELD_COUNT: usize = 3;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn timestamp(&self) -> Uint128Reader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Uint128Reader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn payment_hash(&self) -> PaymentHashReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        PaymentHashReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn attrs(&self) -> InvoiceAttrsVecReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[16..]) as usize;
            InvoiceAttrsVecReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            InvoiceAttrsVecReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for RawInvoiceDataReader<'r> {
    type Entity = RawInvoiceData;
    const NAME: &'static str = "RawInvoiceDataReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        RawInvoiceDataReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        Uint128Reader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        PaymentHashReader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        InvoiceAttrsVecReader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct RawInvoiceDataBuilder {
    pub(crate) timestamp: Uint128,
    pub(crate) payment_hash: PaymentHash,
    pub(crate) attrs: InvoiceAttrsVec,
}
impl RawInvoiceDataBuilder {
    pub const FIELD_COUNT: usize = 3;
    pub fn timestamp(mut self, v: Uint128) -> Self {
        self.timestamp = v;
        self
    }
    pub fn payment_hash(mut self, v: PaymentHash) -> Self {
        self.payment_hash = v;
        self
    }
    pub fn attrs(mut self, v: InvoiceAttrsVec) -> Self {
        self.attrs = v;
        self
    }
}
impl molecule::prelude::Builder for RawInvoiceDataBuilder {
    type Entity = RawInvoiceData;
    const NAME: &'static str = "RawInvoiceDataBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.timestamp.as_slice().len()
            + self.payment_hash.as_slice().len()
            + self.attrs.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.timestamp.as_slice().len();
        offsets.push(total_size);
        total_size += self.payment_hash.as_slice().len();
        offsets.push(total_size);
        total_size += self.attrs.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.timestamp.as_slice())?;
        writer.write_all(self.payment_hash.as_slice())?;
        writer.write_all(self.attrs.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        RawInvoiceData::new_unchecked(inner.into())
    }
}
#[derive(Clone)]
pub struct RawCkbInvoice(molecule::bytes::Bytes);
impl ::core::fmt::LowerHex for RawCkbInvoice {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl ::core::fmt::Debug for RawCkbInvoice {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl ::core::fmt::Display for RawCkbInvoice {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "currency", self.currency())?;
        write!(f, ", {}: {}", "amount", self.amount())?;
        write!(f, ", {}: {}", "signature", self.signature())?;
        write!(f, ", {}: {}", "data", self.data())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl ::core::default::Default for RawCkbInvoice {
    fn default() -> Self {
        let v = molecule::bytes::Bytes::from_static(&Self::DEFAULT_VALUE);
        RawCkbInvoice::new_unchecked(v)
    }
}
impl RawCkbInvoice {
    const DEFAULT_VALUE: [u8; 89] = [
        89, 0, 0, 0, 20, 0, 0, 0, 21, 0, 0, 0, 21, 0, 0, 0, 21, 0, 0, 0, 0, 68, 0, 0, 0, 16, 0, 0,
        0, 32, 0, 0, 0, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0,
        0,
    ];
    pub const FIELD_COUNT: usize = 4;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn currency(&self) -> Byte {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        Byte::new_unchecked(self.0.slice(start..end))
    }
    pub fn amount(&self) -> AmountOpt {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        AmountOpt::new_unchecked(self.0.slice(start..end))
    }
    pub fn signature(&self) -> SignatureOpt {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        SignatureOpt::new_unchecked(self.0.slice(start..end))
    }
    pub fn data(&self) -> RawInvoiceData {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[20..]) as usize;
            RawInvoiceData::new_unchecked(self.0.slice(start..end))
        } else {
            RawInvoiceData::new_unchecked(self.0.slice(start..))
        }
    }
    pub fn as_reader<'r>(&'r self) -> RawCkbInvoiceReader<'r> {
        RawCkbInvoiceReader::new_unchecked(self.as_slice())
    }
}
impl molecule::prelude::Entity for RawCkbInvoice {
    type Builder = RawCkbInvoiceBuilder;
    const NAME: &'static str = "RawCkbInvoice";
    fn new_unchecked(data: molecule::bytes::Bytes) -> Self {
        RawCkbInvoice(data)
    }
    fn as_bytes(&self) -> molecule::bytes::Bytes {
        self.0.clone()
    }
    fn as_slice(&self) -> &[u8] {
        &self.0[..]
    }
    fn from_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        RawCkbInvoiceReader::from_slice(slice).map(|reader| reader.to_entity())
    }
    fn from_compatible_slice(slice: &[u8]) -> molecule::error::VerificationResult<Self> {
        RawCkbInvoiceReader::from_compatible_slice(slice).map(|reader| reader.to_entity())
    }
    fn new_builder() -> Self::Builder {
        ::core::default::Default::default()
    }
    fn as_builder(self) -> Self::Builder {
        Self::new_builder()
            .currency(self.currency())
            .amount(self.amount())
            .signature(self.signature())
            .data(self.data())
    }
}
#[derive(Clone, Copy)]
pub struct RawCkbInvoiceReader<'r>(&'r [u8]);
impl<'r> ::core::fmt::LowerHex for RawCkbInvoiceReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        use molecule::hex_string;
        if f.alternate() {
            write!(f, "0x")?;
        }
        write!(f, "{}", hex_string(self.as_slice()))
    }
}
impl<'r> ::core::fmt::Debug for RawCkbInvoiceReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{}({:#x})", Self::NAME, self)
    }
}
impl<'r> ::core::fmt::Display for RawCkbInvoiceReader<'r> {
    fn fmt(&self, f: &mut ::core::fmt::Formatter) -> ::core::fmt::Result {
        write!(f, "{} {{ ", Self::NAME)?;
        write!(f, "{}: {}", "currency", self.currency())?;
        write!(f, ", {}: {}", "amount", self.amount())?;
        write!(f, ", {}: {}", "signature", self.signature())?;
        write!(f, ", {}: {}", "data", self.data())?;
        let extra_count = self.count_extra_fields();
        if extra_count != 0 {
            write!(f, ", .. ({} fields)", extra_count)?;
        }
        write!(f, " }}")
    }
}
impl<'r> RawCkbInvoiceReader<'r> {
    pub const FIELD_COUNT: usize = 4;
    pub fn total_size(&self) -> usize {
        molecule::unpack_number(self.as_slice()) as usize
    }
    pub fn field_count(&self) -> usize {
        if self.total_size() == molecule::NUMBER_SIZE {
            0
        } else {
            (molecule::unpack_number(&self.as_slice()[molecule::NUMBER_SIZE..]) as usize / 4) - 1
        }
    }
    pub fn count_extra_fields(&self) -> usize {
        self.field_count() - Self::FIELD_COUNT
    }
    pub fn has_extra_fields(&self) -> bool {
        Self::FIELD_COUNT != self.field_count()
    }
    pub fn currency(&self) -> ByteReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[4..]) as usize;
        let end = molecule::unpack_number(&slice[8..]) as usize;
        ByteReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn amount(&self) -> AmountOptReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[8..]) as usize;
        let end = molecule::unpack_number(&slice[12..]) as usize;
        AmountOptReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn signature(&self) -> SignatureOptReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[12..]) as usize;
        let end = molecule::unpack_number(&slice[16..]) as usize;
        SignatureOptReader::new_unchecked(&self.as_slice()[start..end])
    }
    pub fn data(&self) -> RawInvoiceDataReader<'r> {
        let slice = self.as_slice();
        let start = molecule::unpack_number(&slice[16..]) as usize;
        if self.has_extra_fields() {
            let end = molecule::unpack_number(&slice[20..]) as usize;
            RawInvoiceDataReader::new_unchecked(&self.as_slice()[start..end])
        } else {
            RawInvoiceDataReader::new_unchecked(&self.as_slice()[start..])
        }
    }
}
impl<'r> molecule::prelude::Reader<'r> for RawCkbInvoiceReader<'r> {
    type Entity = RawCkbInvoice;
    const NAME: &'static str = "RawCkbInvoiceReader";
    fn to_entity(&self) -> Self::Entity {
        Self::Entity::new_unchecked(self.as_slice().to_owned().into())
    }
    fn new_unchecked(slice: &'r [u8]) -> Self {
        RawCkbInvoiceReader(slice)
    }
    fn as_slice(&self) -> &'r [u8] {
        self.0
    }
    fn verify(slice: &[u8], compatible: bool) -> molecule::error::VerificationResult<()> {
        use molecule::verification_error as ve;
        let slice_len = slice.len();
        if slice_len < molecule::NUMBER_SIZE {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE, slice_len);
        }
        let total_size = molecule::unpack_number(slice) as usize;
        if slice_len != total_size {
            return ve!(Self, TotalSizeNotMatch, total_size, slice_len);
        }
        if slice_len < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, HeaderIsBroken, molecule::NUMBER_SIZE * 2, slice_len);
        }
        let offset_first = molecule::unpack_number(&slice[molecule::NUMBER_SIZE..]) as usize;
        if offset_first % molecule::NUMBER_SIZE != 0 || offset_first < molecule::NUMBER_SIZE * 2 {
            return ve!(Self, OffsetsNotMatch);
        }
        if slice_len < offset_first {
            return ve!(Self, HeaderIsBroken, offset_first, slice_len);
        }
        let field_count = offset_first / molecule::NUMBER_SIZE - 1;
        if field_count < Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        } else if !compatible && field_count > Self::FIELD_COUNT {
            return ve!(Self, FieldCountNotMatch, Self::FIELD_COUNT, field_count);
        };
        let mut offsets: Vec<usize> = slice[molecule::NUMBER_SIZE..offset_first]
            .chunks_exact(molecule::NUMBER_SIZE)
            .map(|x| molecule::unpack_number(x) as usize)
            .collect();
        offsets.push(total_size);
        if offsets.windows(2).any(|i| i[0] > i[1]) {
            return ve!(Self, OffsetsNotMatch);
        }
        ByteReader::verify(&slice[offsets[0]..offsets[1]], compatible)?;
        AmountOptReader::verify(&slice[offsets[1]..offsets[2]], compatible)?;
        SignatureOptReader::verify(&slice[offsets[2]..offsets[3]], compatible)?;
        RawInvoiceDataReader::verify(&slice[offsets[3]..offsets[4]], compatible)?;
        Ok(())
    }
}
#[derive(Clone, Debug, Default)]
pub struct RawCkbInvoiceBuilder {
    pub(crate) currency: Byte,
    pub(crate) amount: AmountOpt,
    pub(crate) signature: SignatureOpt,
    pub(crate) data: RawInvoiceData,
}
impl RawCkbInvoiceBuilder {
    pub const FIELD_COUNT: usize = 4;
    pub fn currency(mut self, v: Byte) -> Self {
        self.currency = v;
        self
    }
    pub fn amount(mut self, v: AmountOpt) -> Self {
        self.amount = v;
        self
    }
    pub fn signature(mut self, v: SignatureOpt) -> Self {
        self.signature = v;
        self
    }
    pub fn data(mut self, v: RawInvoiceData) -> Self {
        self.data = v;
        self
    }
}
impl molecule::prelude::Builder for RawCkbInvoiceBuilder {
    type Entity = RawCkbInvoice;
    const NAME: &'static str = "RawCkbInvoiceBuilder";
    fn expected_length(&self) -> usize {
        molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1)
            + self.currency.as_slice().len()
            + self.amount.as_slice().len()
            + self.signature.as_slice().len()
            + self.data.as_slice().len()
    }
    fn write<W: molecule::io::Write>(&self, writer: &mut W) -> molecule::io::Result<()> {
        let mut total_size = molecule::NUMBER_SIZE * (Self::FIELD_COUNT + 1);
        let mut offsets = Vec::with_capacity(Self::FIELD_COUNT);
        offsets.push(total_size);
        total_size += self.currency.as_slice().len();
        offsets.push(total_size);
        total_size += self.amount.as_slice().len();
        offsets.push(total_size);
        total_size += self.signature.as_slice().len();
        offsets.push(total_size);
        total_size += self.data.as_slice().len();
        writer.write_all(&molecule::pack_number(total_size as molecule::Number))?;
        for offset in offsets.into_iter() {
            writer.write_all(&molecule::pack_number(offset as molecule::Number))?;
        }
        writer.write_all(self.currency.as_slice())?;
        writer.write_all(self.amount.as_slice())?;
        writer.write_all(self.signature.as_slice())?;
        writer.write_all(self.data.as_slice())?;
        Ok(())
    }
    fn build(&self) -> Self::Entity {
        let mut inner = Vec::with_capacity(self.expected_length());
        self.write(&mut inner)
            .unwrap_or_else(|_| panic!("{} build should be ok", Self::NAME));
        RawCkbInvoice::new_unchecked(inner.into())
    }
}


================================================
File: src/fiber/gen/mod.rs
================================================
#[allow(clippy::all)]
pub mod fiber;
#[allow(clippy::all)]
pub mod gossip;
#[allow(clippy::all)]
pub mod invoice;
// fiber module requires types from blockchain.
// We need to re-export these types.
mod blockchain {
    pub use ckb_gen_types::packed::{
        Byte32, Byte32Reader, Bytes, BytesReader, BytesVec, BytesVecReader, OutPoint,
        OutPointReader, Script, ScriptOpt, ScriptOptReader, ScriptReader, Transaction,
        TransactionReader, Uint128, Uint128Reader, Uint32, Uint32Reader, Uint64, Uint64Reader,
    };
}


================================================
File: src/fiber/schema/README.md
================================================
# Schema for Fiber Network Messages

The messages type definitions in Fiber Network Protocol (FNP) depend on message type definitions in CKB.
We copied v0.114.0 of upstream schema files in directory [ckb/util/gen-types/schemas](https://github.com/nervosnetwork/ckb/tree/pkg/v0.114.0/util/gen-types/schemas).
One problem is that if we directly generate all type definitions, rust compiler would believe we have two different types of `Transaction`. Because they are from different crates. Instead, we make sure we generate the same code, and directly use the crate [`ckb-gen-types`](https://crates.io/crates/ckb-gen-types). This way we are using the same `Transaction` type. But we must be careful when generating FNP message definitions and importing `ckb-gen-types` (both code should be generated from an identical version of molecule and identical schema files). The schema files in current repo are copied from ckb `v0.114.0`. And as of `ckb-gen-types` v0.114.0, these files in `ckb-gen-types` are created with molecule `v0.7.5`.


================================================
File: src/fiber/schema/blockchain.mol
================================================
/* Basic Types */

// The `UintN` is used to store a `N` bits unsigned integer
// as a byte array in little endian.
array Uint32 [byte; 4];
array Uint64 [byte; 8];
array Uint128 [byte; 16];
array Byte32 [byte; 32];
array Uint256 [byte; 32];

vector Bytes <byte>;
option BytesOpt (Bytes);
vector BytesOptVec <BytesOpt>;
vector BytesVec <Bytes>;
vector Byte32Vec <Byte32>;

/* Types for Chain */

option ScriptOpt (Script);

array ProposalShortId [byte; 10];

vector UncleBlockVec <UncleBlock>;
vector TransactionVec <Transaction>;
vector ProposalShortIdVec <ProposalShortId>;
vector CellDepVec <CellDep>;
vector CellInputVec <CellInput>;
vector CellOutputVec <CellOutput>;

table Script {
    code_hash:      Byte32,
    hash_type:      byte,
    args:           Bytes,
}

struct OutPoint {
    tx_hash:        Byte32,
    index:          Uint32,
}

struct CellInput {
    since:           Uint64,
    previous_output: OutPoint,
}

table CellOutput {
    capacity:       Uint64,
    lock:           Script,
    type_:          ScriptOpt,
}

struct CellDep {
    out_point:      OutPoint,
    dep_type:       byte,
}

table RawTransaction {
    version:        Uint32,
    cell_deps:      CellDepVec,
    header_deps:    Byte32Vec,
    inputs:         CellInputVec,
    outputs:        CellOutputVec,
    outputs_data:   BytesVec,
}

table Transaction {
    raw:            RawTransaction,
    witnesses:      BytesVec,
}

struct RawHeader {
    version:                Uint32,
    compact_target:         Uint32,
    timestamp:              Uint64,
    number:                 Uint64,
    epoch:                  Uint64,
    parent_hash:            Byte32,
    transactions_root:      Byte32,
    proposals_hash:         Byte32,
    extra_hash:             Byte32,
    dao:                    Byte32,
}

struct Header {
    raw:                    RawHeader,
    nonce:                  Uint128,
}

table UncleBlock {
    header:                 Header,
    proposals:              ProposalShortIdVec,
}

table Block {
    header:                 Header,
    uncles:                 UncleBlockVec,
    transactions:           TransactionVec,
    proposals:              ProposalShortIdVec,
}

table BlockV1 {
    header:                 Header,
    uncles:                 UncleBlockVec,
    transactions:           TransactionVec,
    proposals:              ProposalShortIdVec,
    extension:              Bytes,
}

table CellbaseWitness {
    lock:    Script,
    message: Bytes,
}

table WitnessArgs {
    lock:                   BytesOpt,          // Lock args
    input_type:             BytesOpt,          // Type args for input
    output_type:            BytesOpt,          // Type args for output
}


================================================
File: src/fiber/schema/fiber.mol
================================================
import blockchain;

array Uint16 [byte; 2];
array EcdsaSignature [byte; 64];
array PubNonce [byte; 66]; // PubNonce used by musig2 crate.
option PubNonceOpt (PubNonce);
array Pubkey [byte; 33];
option Uint64Opt (Uint64);
option Uint128Opt (Uint128);

table OpenChannel {
    chain_hash:                  Byte32,
    channel_id:                  Byte32,
    funding_udt_type_script:     ScriptOpt,
    funding_amount:              Uint128,
    shutdown_script:             Script,
    reserved_ckb_amount:         Uint64,
    funding_fee_rate:            Uint64,
    commitment_fee_rate:         Uint64,
    max_tlc_value_in_flight:     Uint128,
    max_tlc_number_in_flight:    Uint64,
    commitment_delay_epoch:      Uint64,
    funding_pubkey:              Pubkey,
    tlc_basepoint:               Pubkey,
    first_per_commitment_point:  Pubkey,
    second_per_commitment_point: Pubkey,
    channel_annoucement_nonce:   PubNonceOpt,
    next_local_nonce:            PubNonce,
    channel_flags:               byte,
}

table AcceptChannel {
    channel_id:                  Byte32,
    funding_amount:              Uint128,
    shutdown_script:             Script,
    reserved_ckb_amount:         Uint64,
    max_tlc_value_in_flight:     Uint128,
    max_tlc_number_in_flight:    Uint64,
    funding_pubkey:              Pubkey,
    tlc_basepoint:               Pubkey,
    first_per_commitment_point:  Pubkey,
    second_per_commitment_point: Pubkey,
    channel_annoucement_nonce:   PubNonceOpt,
    next_local_nonce:            PubNonce,
}

struct CommitmentSigned {
    channel_id:                       Byte32,
    funding_tx_partial_signature:     Byte32,
    commitment_tx_partial_signature:  Byte32,
    next_local_nonce:                 PubNonce,
}

table TxSignatures {
    channel_id: Byte32,
    witnesses:  BytesVec,
}

struct ChannelReady {
    channel_id: Byte32,
}

table TxUpdate {
    channel_id: Byte32,
    tx:         Transaction,
}

struct TxComplete {
    channel_id:                       Byte32,
    commitment_tx_partial_signature:  Byte32,
}

table TxAbort {
    channel_id: Byte32,
    message:    Bytes,
}

table TxInitRBF {
    channel_id: Byte32,
    fee_rate:   Uint64,
}

table TxAckRBF {
    channel_id: Byte32,
}

table Shutdown {
    channel_id:   Byte32,
    fee_rate:     Uint64,
    close_script: Script,
}

struct ClosingSigned {
    channel_id:         Byte32,
    partial_signature:  Byte32,
}

struct UpdateTlcInfo {
    channel_id: Byte32,
    timestamp: Uint64,
    channel_flags: Uint32,
    tlc_expiry_delta: Uint64,
    tlc_minimum_value: Uint128,
    tlc_maximum_value: Uint128,
    tlc_fee_proportional_millionths: Uint128,
}

table AddTlc {
    channel_id:     Byte32,
    tlc_id:         Uint64,
    amount:         Uint128,
    payment_hash:   Byte32,
    expiry:         Uint64,
    hash_algorithm: byte,
    // This is the packet each hops need to decrypt and determine
    // which nodes to forward (or accept the tlc if it is the final node).
    onion_packet:   Bytes,
}

struct RevokeAndAck {
    channel_id:                         Byte32,
    revocation_partial_signature:       Byte32,
    commitment_tx_partial_signature:    Byte32,
    next_per_commitment_point:          Pubkey,
}

struct RemoveTlcFulfill {
    payment_preimage:   Byte32,
}

table TlcErrPacket {
    onion_packet:        Bytes,
}

union RemoveTlcReason {
    RemoveTlcFulfill,
    TlcErrPacket,
}

table RemoveTlc {
    channel_id:         Byte32,
    tlc_id:             Uint64,
    reason:             RemoveTlcReason,
}

table ReestablishChannel {
    channel_id: Byte32,
    local_commitment_number: Uint64,
    remote_commitment_number: Uint64,
}

table AnnouncementSignatures {
    channel_id: Byte32,
    channel_outpoint: OutPoint,
    node_signature: EcdsaSignature,
    partial_signature: Byte32,
}

table UdtCellDep {
    dep_type: byte,
    tx_hash: Byte32,
    index: Uint32,
}

table UdtScript {
    code_hash: Byte32,
    hash_type: byte,
    args: Bytes,
}

vector UdtCellDeps <UdtCellDep>;

table UdtArgInfo {
    name: Bytes,
    script: UdtScript,
    auto_accept_amount: Uint128Opt,
    cell_deps: UdtCellDeps,
}

vector UdtCfgInfos <UdtArgInfo>;

union FiberMessage {
    OpenChannel,
    AcceptChannel,
    TxSignatures,
    TxUpdate,
    TxComplete,
    TxAbort,
    TxInitRBF,
    TxAckRBF,
    CommitmentSigned,
    ChannelReady,
    UpdateTlcInfo,
    AddTlc,
    RemoveTlc,
    RevokeAndAck,
    Shutdown,
    ClosingSigned,
    ReestablishChannel,
    AnnouncementSignatures,
}

option PaymentPreimageOpt (Byte32);
option PubkeyOpt (Pubkey);
table PaymentHopData {
    amount: Uint128,
    expiry: Uint64,
    payment_preimage: PaymentPreimageOpt,
    hash_algorithm: byte,
    funding_tx_hash: Byte32,
    next_hop: PubkeyOpt,
}

// A ChannelUpdate is a update to the public channel. Newer channel information may be updated with
// a ChannelUpdate with a larger timestamp.
struct ChannelUpdate {
    // Signature of the node that wants to update the channel information.
    signature: EcdsaSignature,
    chain_hash: Byte32,
    channel_outpoint: OutPoint,
    timestamp: Uint64,
    message_flags: Uint32,
    channel_flags: Uint32,
    tlc_expiry_delta: Uint64,
    tlc_minimum_value: Uint128,
    tlc_maximum_value: Uint128,
    tlc_fee_proportional_millionths: Uint128,
}

option ChannelUpdateOpt (ChannelUpdate);
table ChannelFailed {
    channel_outpoint: OutPoint,
    channel_update: ChannelUpdateOpt,
    node_id: Pubkey,
}

table NodeFailed {
    node_id: Pubkey,
}

union TlcErrData {
    ChannelFailed,
    NodeFailed,
}

option TlcErrDataOpt (TlcErrData);
table TlcErr {
    error_code: Uint16,
    extra_data: TlcErrDataOpt,
}

================================================
File: src/fiber/schema/gen.sh
================================================
#!/usr/bin/env bash

set -euo pipefail

MOLC="${MOLC:-moleculec}"

schema_dir="$(cd -- "$(dirname -- "${BASH_SOURCE[0]}")" &>/dev/null && pwd)"
gen_dir="$(dirname "$schema_dir")/gen"

files=("fiber.mol" "invoice.mol" "gossip.mol")
for file in "${files[@]}"; do
    f="$schema_dir/$file"
    output_file="$gen_dir/$(basename "${f%%.mol}.rs")"
    "$MOLC" --language rust --schema-file "$f" | rustfmt >"$output_file"
done


================================================
File: src/fiber/schema/gossip.mol
================================================
import blockchain;
import fiber;

array SchnorrSignature [byte; 64];
array SchnorrXOnlyPubkey [byte; 32];

// A cursor for the broadcast message. Consists of the following data
// timestamp (8 bytes in big-endian), union id (1 byte), message id (36 bytes)
// where message ID is defined as
// ChannelAnnouncement (union ID 0): channel_outpoint, 36 bytes
// ChannelUpdate (union ID 1): channel_outpoint, 36 bytes
// NodeAnnouncement (union ID 2): node_id 33 bytes padding 3 zero bytes
// All broadcast messages are sorted by Cursor in dictionary order,
// so whenever we pass a `after_cursor` parameter below, we want data that
// come after the `after_cursor` in dictionary order, which basically means that we
// need data after certain timestamp.
array Cursor [byte; 45];

// BroadcastMessageQuery is a query sent to another peer to query
// ChannelAnnouncement/ChannelUpdate/NodeAnnouncement messages related a channel outpoint.
// The `flags` is used to specify an array of bitfields. Bits have the following meaning:
// 0 	Sender wants ChannelAnnouncement
// 1 	Sender wants ChannelUpdate for node 1
// 2 	Sender wants ChannelUpdate for node 2
// 3 	Sender wants NodeAnnouncement for node 1
// 4 	Sender wants NodeAnnouncement for node 2
// The bit field order of these messages is the same to the union id order of cursors.
struct BroadcastMessageQuery {
    channel_outpoint: OutPoint,
    flags: byte,
}

vector BroadcastMessageQueries <BroadcastMessageQuery>;

// A NodeAnnouncement is a broadcast message to the network for the node information.
// An update to the node information can be broadcasted with a NodeAnnouncement with larger timestamp.
table NodeAnnouncement {
    // Signature to this message.
    signature: EcdsaSignature,
    // Tentatively using 64 bits for features. May change the type later while developing.
    // https://github.com/lightningdevkit/rust-lightning/blob/8c1b3d1263f6b9247c0c819039ef2027dc4d4588/lightning/src/ln/features.rs#L448-L457
    // rust-lightning uses a Vec<u8> here.
    features: Uint64,
    // Timestamp to the node announcement update, later update should have larger timestamp.
    timestamp: Uint64,
    node_id: Pubkey,
    // Must be a valid utf-8 string of length maximal length 32 bytes.
    node_name: Byte32,
    // All the reachable addresses.
    address: BytesVec,
    // Chain hash
    chain_hash: Byte32,
    // Minimal auto accept ckb amount
    auto_accept_min_ckb_funding_amount: Uint64,
    // UDT configs
    udt_cfg_infos: UdtCfgInfos,
}

// A ChannelAnnouncement is an announcement of a channel to the network.
// This message must be immutable for any specific channel.
table ChannelAnnouncement {
    node1_signature: EcdsaSignature,
    node2_signature: EcdsaSignature,
    // Signature signed by the funding transaction output public key.
    ckb_signature: SchnorrSignature,
    // Tentatively using 64 bits for features. May change the type later while developing.
    // https://github.com/lightningdevkit/rust-lightning/blob/8c1b3d1263f6b9247c0c819039ef2027dc4d4588/lightning/src/ln/msgs.rs#L1200-L1200
    // rust-lightning uses a Vec<u8> here.
    features: Uint64,
    chain_hash: Byte32,
    channel_outpoint: OutPoint,
    node1_id: Pubkey,
    node2_id: Pubkey,
    // The aggregated public key of the funding transaction output.
    ckb_key: SchnorrXOnlyPubkey,
    capacity: Uint128,
    udt_type_script: ScriptOpt,
}

// All the broadcast messages.
union BroadcastMessage {
    NodeAnnouncement,
    ChannelAnnouncement,
    ChannelUpdate,
}

vector BroadcastMessages <BroadcastMessage>;

vector MissingQueryIndexes <Uint16>;

// BroadcastMessagesFilter is used to instruct peer to broadcast messages to the sender.
// The sender must only send messages after the cursor specified in `after_cursor`.
// The sender should also send current broadcast message which are after the cursor immediately.
struct BroadcastMessagesFilter {
    chain_hash: Byte32,
    after_cursor: Cursor,
}

// GetBroadcastMessages is used to batch get broadcast messages from another peer.
// This is used in the initial sync process of a node. The node should repeatedly send GetBroadcastMessages
// to peers (with `after_cursor` replaced with the cursor of the latest data) until an empty result is returned.
// The difference between GetBroadcastMessages and QueryBroadcastMessages is that QueryBroadcastMessages
// will make some specific queries to some specific channels/nodes, while GetBroadcastMessages only gets
// messages after a cursor.
struct GetBroadcastMessages {
    id: Uint64,
    chain_hash: Byte32,
    after_cursor: Cursor,
    count: Uint16,
}

// To query some specific messages (e.g. a NodeAnnouncement) from peers.
// The difference between GetBroadcastMessages and QueryBroadcastMessages is that QueryBroadcastMessages
// will make some specific queries to some specific channels/nodes, while GetBroadcastMessages only gets
// messages after a cursor.
table QueryBroadcastMessages {
    id: Uint64,
    chain_hash: Byte32,
    queries: BroadcastMessageQueries,
}

// BroadcastMessagesFilterResult is the message to BroadcastMessagesFilter requests.
table BroadcastMessagesFilterResult {
    messages: BroadcastMessages,
}

// GetBroadcastMessagesResult is the response to GetBroadcastMessages requests.
// The id here corresponds to the id passed by the peer. This is used to track the progress of certain request.
table GetBroadcastMessagesResult {
    id: Uint64,
    messages: BroadcastMessages,
}

// QueryBroadcastMessagesResult is the response to QueryBroadcastMessages requests.
// The id here corresponds to the id passed by the peer. This is used to track the progress of certain request.
// The missing_queries here is used to indicate that the results correpsonding to some queries can not be found
// by the remote peer. The request initiator should try another remote node for the missing data.
table QueryBroadcastMessagesResult {
    id: Uint64,
    messages: BroadcastMessages,
    missing_queries: MissingQueryIndexes,
}

union GossipMessage {
    BroadcastMessagesFilter,
    BroadcastMessagesFilterResult,
    GetBroadcastMessages,
    GetBroadcastMessagesResult,
    QueryBroadcastMessages,
    QueryBroadcastMessagesResult,
}


================================================
File: src/fiber/schema/invoice.mol
================================================
import blockchain;

array PaymentHash [byte; 32];
array Signature [byte; 104];
option ExpiryTimeOpt (Duration);
option SignatureOpt (Signature);

option AmountOpt (Uint128);

option FeatureOpt (Uint32);

struct Duration {
    seconds: Uint64,
    nanos: Uint64,
}

struct FinalHtlcTimeout {
    value: Uint64,
}

struct FinalHtlcMinimumExpiryDelta {
    value: Uint64,
}

struct ExpiryTime {
    value: Duration,
}

table Description {
    value: Bytes,
}

table FallbackAddr {
    value: Bytes,
}

struct Feature {
    value: Uint64,
}

table UdtScript {
    value: Script,
}

table PayeePublicKey {
    value: Bytes,
}

// 0 - ckb hash (Default)
// 1 - sha256
struct HashAlgorithm {
    value: byte,
}

union InvoiceAttr {
    ExpiryTime,
    Description,
    FinalHtlcTimeout,
    FinalHtlcMinimumExpiryDelta,
    FallbackAddr,
    Feature,
    UdtScript,
    PayeePublicKey,
    HashAlgorithm,
}

vector InvoiceAttrsVec <InvoiceAttr>;

table RawInvoiceData {
    timestamp: Uint128,
    payment_hash: PaymentHash,
    attrs: InvoiceAttrsVec,
}

table RawCkbInvoice {
    currency: byte,
    amount: AmountOpt,
    signature: SignatureOpt,
    data: RawInvoiceData,
}


================================================
File: src/fiber/tests/channel.rs
================================================
use super::test_utils::{init_tracing, NetworkNode};
use crate::fiber::channel::UpdateCommand;
use crate::fiber::config::MAX_PAYMENT_TLC_EXPIRY_LIMIT;
use crate::fiber::graph::{ChannelInfo, PaymentSessionStatus};
use crate::fiber::network::{DebugEvent, SendPaymentCommand};
use crate::fiber::tests::test_utils::*;
use crate::fiber::types::{
    Hash256, PaymentHopData, PeeledOnionPacket, Pubkey, TlcErrorCode, NO_SHARED_SECRET,
};
use crate::invoice::{CkbInvoiceStatus, Currency, InvoiceBuilder};
use crate::{
    ckb::contracts::{get_cell_deps, Contract},
    fiber::{
        channel::{
            derive_private_key, derive_tlc_pubkey, AddTlcCommand, ChannelActorStateStore,
            ChannelCommand, ChannelCommandWithId, InMemorySigner, RemoveTlcCommand,
            ShutdownCommand, DEFAULT_COMMITMENT_FEE_RATE,
        },
        config::DEFAULT_AUTO_ACCEPT_CHANNEL_CKB_FUNDING_AMOUNT,
        hash_algorithm::HashAlgorithm,
        network::{AcceptChannelCommand, OpenChannelCommand},
        tests::test_utils::establish_channel_between_nodes,
        types::{Privkey, RemoveTlcFulfill, RemoveTlcReason},
        NetworkActorCommand, NetworkActorMessage,
    },
    gen_rand_fiber_private_key, gen_rand_fiber_public_key, gen_rand_sha256_hash,
    now_timestamp_as_millis_u64, NetworkServiceEvent,
};
use ckb_jsonrpc_types::Status;
use ckb_types::{
    core::FeeRate,
    packed::{CellInput, Script, Transaction},
    prelude::{AsTransactionBuilder, Builder, Entity, IntoTransactionView, Pack, Unpack},
};
use ractor::call;
use secp256k1::Secp256k1;
use std::collections::HashSet;
use std::time::Duration;

const DEFAULT_EXPIRY_DELTA: u64 = 24 * 60 * 60 * 1000; // 24 hours

#[test]
fn test_per_commitment_point_and_secret_consistency() {
    init_tracing();

    let signer = InMemorySigner::generate_from_seed(&[1; 32]);
    assert_eq!(
        signer.get_commitment_point(0),
        Privkey::from(&signer.get_commitment_secret(0)).pubkey()
    );
}

#[test]
fn test_derive_private_and_public_tlc_keys() {
    let privkey = Privkey::from(&[1; 32]);
    let per_commitment_point = Privkey::from(&[2; 32]).pubkey();
    let derived_privkey = derive_private_key(&privkey, &per_commitment_point);
    let derived_pubkey = derive_tlc_pubkey(&privkey.pubkey(), &per_commitment_point);
    assert_eq!(derived_privkey.pubkey(), derived_pubkey);
}

#[tokio::test]
async fn test_open_channel_to_peer() {
    let [node_a, mut node_b] = NetworkNode::new_n_interconnected_nodes().await;

    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::OpenChannel(
            OpenChannelCommand {
                peer_id: node_b.peer_id.clone(),
                public: false,
                shutdown_script: None,
                funding_amount: 100000000000,
                funding_udt_type_script: None,
                commitment_fee_rate: None,
                commitment_delay_epoch: None,
                funding_fee_rate: None,
                tlc_expiry_delta: None,
                tlc_min_value: None,
                tlc_fee_proportional_millionths: None,
                max_tlc_number_in_flight: None,
                max_tlc_value_in_flight: None,
            },
            rpc_reply,
        ))
    };
    let _open_channel_result = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .expect("open channel success");

    node_b
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelPendingToBeAccepted(peer_id, channel_id) => {
                println!("A channel ({:?}) to {:?} create", channel_id, peer_id);
                assert_eq!(peer_id, &node_a.peer_id);
                true
            }
            _ => false,
        })
        .await;
}

#[tokio::test]
async fn test_open_and_accept_channel() {
    let [node_a, mut node_b] = NetworkNode::new_n_interconnected_nodes().await;

    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::OpenChannel(
            OpenChannelCommand {
                peer_id: node_b.peer_id.clone(),
                public: false,
                shutdown_script: None,
                funding_amount: 100000000000,
                funding_udt_type_script: None,
                commitment_fee_rate: None,
                commitment_delay_epoch: None,
                funding_fee_rate: None,
                tlc_expiry_delta: None,
                tlc_min_value: None,
                tlc_fee_proportional_millionths: None,
                max_tlc_number_in_flight: None,
                max_tlc_value_in_flight: None,
            },
            rpc_reply,
        ))
    };
    let open_channel_result = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .expect("open channel success");

    node_b
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelPendingToBeAccepted(peer_id, channel_id) => {
                println!("A channel ({:?}) to {:?} create", &channel_id, peer_id);
                assert_eq!(peer_id, &node_a.peer_id);
                true
            }
            _ => false,
        })
        .await;

    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::AcceptChannel(
            AcceptChannelCommand {
                temp_channel_id: open_channel_result.channel_id,
                funding_amount: DEFAULT_AUTO_ACCEPT_CHANNEL_CKB_FUNDING_AMOUNT as u128,
                shutdown_script: None,
                max_tlc_number_in_flight: None,
                max_tlc_value_in_flight: None,
                min_tlc_value: None,
                tlc_fee_proportional_millionths: None,
                tlc_expiry_delta: None,
            },
            rpc_reply,
        ))
    };

    let _accept_channel_result = call!(node_b.network_actor, message)
        .expect("node_b alive")
        .expect("accept channel success");
}

#[tokio::test]
async fn test_create_private_channel() {
    init_tracing();

    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (_node_a, _node_b, _new_channel_id, _) = NetworkNode::new_2_nodes_with_established_channel(
        node_a_funding_amount,
        node_b_funding_amount,
        false,
    )
    .await;
}

#[tokio::test]
async fn test_create_channel_with_remote_tlc_info() {
    async fn test(public: bool) {
        let node_a_funding_amount = 100000000000;
        let node_b_funding_amount = 6200000000;

        let (node_a, node_b, channel_id, _) = NetworkNode::new_2_nodes_with_established_channel(
            node_a_funding_amount,
            node_b_funding_amount,
            public,
        )
        .await;

        tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

        let node_a_channel_state = node_a.store.get_channel_actor_state(&channel_id).unwrap();
        let node_b_channel_state = node_b.store.get_channel_actor_state(&channel_id).unwrap();

        assert_eq!(
            Some(node_a_channel_state.local_tlc_info),
            node_b_channel_state.remote_tlc_info
        );
        assert_eq!(
            Some(node_b_channel_state.local_tlc_info),
            node_a_channel_state.remote_tlc_info
        );
    }

    test(true).await;
    test(false).await;
}

#[tokio::test]
async fn test_create_public_channel() {
    init_tracing();

    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (_node_a, _node_b, _new_channel_id, _) = NetworkNode::new_2_nodes_with_established_channel(
        node_a_funding_amount,
        node_b_funding_amount,
        true,
    )
    .await;
}

async fn do_test_owned_channel_saved_to_the_owner_graph(public: bool) {
    let node1_funding_amount = 100000000000;
    let node2_funding_amount = 6200000000;

    let (mut node1, mut node2, _new_channel_id, _) =
        NetworkNode::new_2_nodes_with_established_channel(
            node1_funding_amount,
            node2_funding_amount,
            public,
        )
        .await;

    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let node1_id = node1.peer_id.clone();
    node1.stop().await;
    let node2_id = node2.peer_id.clone();
    node2.stop().await;

    let node1_channels = node1.get_network_graph_channels().await;
    assert_eq!(node1_channels.len(), 1);
    let node1_channel = &node1_channels[0];
    assert_eq!(
        HashSet::from([node1_channel.node1_peerid(), node1_channel.node2_peerid()]),
        HashSet::from([node1_id.clone(), node2_id.clone()])
    );
    assert_ne!(node1_channel.update_of_node1, None);
    assert_ne!(node1_channel.update_of_node2, None);
    let node1_nodes = node1.get_network_graph_nodes().await;
    assert_eq!(node1_nodes.len(), 2);
    for node in node1_nodes {
        assert!(node.node_id == node1_channel.node1() || node.node_id == node1_channel.node2());
    }

    let node2_channels = node2.get_network_graph_channels().await;
    assert_eq!(node2_channels.len(), 1);
    let node2_channel = &node2_channels[0];
    assert_ne!(node2_channel.update_of_node1, None);
    assert_ne!(node2_channel.update_of_node2, None);
    assert_eq!(
        HashSet::from([node2_channel.node1_peerid(), node2_channel.node2_peerid()]),
        HashSet::from([node1_id, node2_id])
    );
    let node2_nodes = node2.get_network_graph_nodes().await;
    assert_eq!(node2_nodes.len(), 2);
    for node in node2_nodes {
        assert!(node.node_id == node2_channel.node1() || node.node_id == node2_channel.node2());
    }
}

#[tokio::test]
async fn test_owned_public_channel_saved_to_the_owner_graph() {
    do_test_owned_channel_saved_to_the_owner_graph(true).await;
}

#[tokio::test]
async fn test_owned_private_channel_saved_to_the_owner_graph() {
    do_test_owned_channel_saved_to_the_owner_graph(false).await;
}

async fn do_test_owned_channel_removed_from_graph_on_disconnected(public: bool) {
    let node1_funding_amount = 100000000000;
    let node2_funding_amount = 6200000000;

    let (mut node1, mut node2, _new_channel_id, _) =
        NetworkNode::new_2_nodes_with_established_channel(
            node1_funding_amount,
            node2_funding_amount,
            public,
        )
        .await;

    let node1_id = node1.peer_id.clone();
    let node2_id = node2.peer_id.clone();

    let node1_channels = node1.get_network_graph_channels().await;
    assert_ne!(node1_channels, vec![]);
    let node2_channels = node2.get_network_graph_channels().await;
    assert_ne!(node2_channels, vec![]);

    node1
        .network_actor
        .send_message(NetworkActorMessage::new_command(
            NetworkActorCommand::DisconnectPeer(node2_id.clone()),
        ))
        .expect("node_a alive");

    node1
        .expect_event(|event| match event {
            NetworkServiceEvent::PeerDisConnected(peer_id, _) => {
                assert_eq!(peer_id, &node2_id);
                true
            }
            _ => false,
        })
        .await;

    node2
        .expect_event(|event| match event {
            NetworkServiceEvent::PeerDisConnected(peer_id, _) => {
                assert_eq!(peer_id, &node1_id);
                true
            }
            _ => false,
        })
        .await;

    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
    let node1_channels = node1.get_network_graph_channels().await;
    assert_eq!(node1_channels, vec![]);
    let node2_channels = node2.get_network_graph_channels().await;
    assert_eq!(node2_channels, vec![]);
}

#[tokio::test]
async fn test_owned_channel_removed_from_graph_on_disconnected_public_channel() {
    do_test_owned_channel_removed_from_graph_on_disconnected(true).await;
}

#[tokio::test]
async fn test_owned_channel_removed_from_graph_on_disconnected_private_channel() {
    do_test_owned_channel_removed_from_graph_on_disconnected(false).await;
}

async fn do_test_owned_channel_saved_to_graph_on_reconnected(public: bool) {
    let node1_funding_amount = 100000000000;
    let node2_funding_amount = 6200000000;

    let (mut node1, mut node2, _new_channel_id, _) =
        NetworkNode::new_2_nodes_with_established_channel(
            node1_funding_amount,
            node2_funding_amount,
            public,
        )
        .await;

    let node1_id = node1.peer_id.clone();
    let node2_id = node2.peer_id.clone();

    let node1_channels = node1.get_network_graph_channels().await;
    assert_ne!(node1_channels, vec![]);
    let node2_channels = node2.get_network_graph_channels().await;
    assert_ne!(node2_channels, vec![]);

    node1
        .network_actor
        .send_message(NetworkActorMessage::new_command(
            NetworkActorCommand::DisconnectPeer(node2_id.clone()),
        ))
        .expect("node_a alive");

    node1
        .expect_event(|event| match event {
            NetworkServiceEvent::PeerDisConnected(peer_id, _) => {
                assert_eq!(peer_id, &node2_id);
                true
            }
            _ => false,
        })
        .await;

    node2
        .expect_event(|event| match event {
            NetworkServiceEvent::PeerDisConnected(peer_id, _) => {
                assert_eq!(peer_id, &node1_id);
                true
            }
            _ => false,
        })
        .await;

    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
    let node1_channels = node1.get_network_graph_channels().await;
    assert_eq!(node1_channels, vec![]);
    let node2_channels = node2.get_network_graph_channels().await;
    assert_eq!(node2_channels, vec![]);

    // Don't use `connect_to` here as that may consume the `ChannelCreated` event.
    // This is due to tentacle connection is async. We may actually send
    // the `ChannelCreated` event before the `PeerConnected` event.
    node1.connect_to_nonblocking(&node2).await;

    node1
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelCreated(peer_id, channel_id) => {
                println!("A channel ({:?}) to {:?} create", channel_id, peer_id);
                assert_eq!(peer_id, &node2_id);
                true
            }
            _ => false,
        })
        .await;

    node2
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelCreated(peer_id, channel_id) => {
                println!("A channel ({:?}) to {:?} create", channel_id, peer_id);
                assert_eq!(peer_id, &node1_id);
                true
            }
            _ => false,
        })
        .await;

    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
    let node1_channels = node1.get_network_graph_channels().await;
    assert_ne!(node1_channels, vec![]);
    let node2_channels = node2.get_network_graph_channels().await;
    assert_ne!(node2_channels, vec![]);
}

#[tokio::test]
async fn test_owned_channel_saved_to_graph_on_reconnected_public_channel() {
    do_test_owned_channel_saved_to_graph_on_reconnected(true).await;
}

#[tokio::test]
async fn test_owned_channel_saved_to_graph_on_reconnected_private_channel() {
    do_test_owned_channel_saved_to_graph_on_reconnected(false).await;
}

async fn do_test_update_graph_balance_after_payment(public: bool) {
    init_tracing();

    let _span = tracing::info_span!("node", node = "test").entered();
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, node_b, new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, public)
            .await;
    let node_a_pubkey = node_a.pubkey;
    let node_b_pubkey = node_b.pubkey;

    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;

    let test_channel_info = |channels: Vec<ChannelInfo>,
                             node_a_pubkey: Pubkey,
                             node_b_pubkey: Pubkey,
                             node_a_balance: u128,
                             node_b_balance: u128| {
        assert_eq!(channels.len(), 1);
        let channel = &channels[0];
        assert_ne!(channel.update_of_node1, None);
        assert_ne!(channel.update_of_node2, None);
        assert_ne!(channel.get_channel_update_of(node_a_pubkey), None);
        assert_ne!(channel.get_channel_update_of(node_b_pubkey), None);
        assert_eq!(
            channel
                .get_channel_update_of(node_a_pubkey)
                .unwrap()
                .outbound_liquidity,
            Some(node_a_balance)
        );
        assert_eq!(
            channel
                .get_channel_update_of(node_b_pubkey)
                .unwrap()
                .outbound_liquidity,
            Some(node_b_balance)
        );
    };

    let node_a_old_balance = node_a.get_local_balance_from_channel(new_channel_id);
    let node_b_old_balance = node_b.get_local_balance_from_channel(new_channel_id);
    let node_a_old_channels = node_a.get_network_graph_channels().await;
    let node_b_old_channels = node_b.get_network_graph_channels().await;
    test_channel_info(
        node_a_old_channels,
        node_a_pubkey,
        node_b_pubkey,
        node_a_old_balance,
        node_b_old_balance,
    );
    test_channel_info(
        node_b_old_channels,
        node_a_pubkey,
        node_b_pubkey,
        node_a_old_balance,
        node_b_old_balance,
    );

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(10000),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res1 = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    // this is the payment_hash generated by keysend
    assert_eq!(res1.status, PaymentSessionStatus::Created);
    let payment_hash1 = res1.payment_hash;

    // the second payment is send from node_b to node_a
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_a_pubkey),
                amount: Some(9999),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                tlc_expiry_limit: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res2 = call!(node_b.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    // this is the payment_hash generated by keysend
    assert_eq!(res2.status, PaymentSessionStatus::Created);
    let payment_hash2 = res2.payment_hash;

    // sleep for 2 seconds to make sure the payment is processed
    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::GetPayment(payment_hash1, rpc_reply))
    };
    let res = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    assert_eq!(res.status, PaymentSessionStatus::Success);
    assert_eq!(res.failed_error, None);

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::GetPayment(payment_hash2, rpc_reply))
    };
    let res = call!(node_b.network_actor, message)
        .expect("node_a alive")
        .unwrap();

    assert_eq!(res.status, PaymentSessionStatus::Success);
    assert_eq!(res.failed_error, None);

    let node_a_new_balance = node_a.get_local_balance_from_channel(new_channel_id);
    let node_b_new_balance = node_b.get_local_balance_from_channel(new_channel_id);

    // assert the balance is right,
    // node_a send 10000 to node_b, and node_b send 9999 to node_a
    // so the balance should be node_a_old_balance - 1, node_b_old_balance + 1
    assert_eq!(node_a_new_balance, node_a_old_balance - 1);
    assert_eq!(node_b_new_balance, node_b_old_balance + 1);

    let node_a_new_channels = node_a.get_network_graph_channels().await;
    let node_b_new_channels = node_b.get_network_graph_channels().await;
    test_channel_info(
        node_a_new_channels,
        node_a_pubkey,
        node_b_pubkey,
        node_a_new_balance,
        node_b_new_balance,
    );
    test_channel_info(
        node_b_new_channels,
        node_a_pubkey,
        node_b_pubkey,
        node_a_new_balance,
        node_b_new_balance,
    );
}

#[tokio::test]
async fn test_update_graph_balance_after_payment_public_channel() {
    do_test_update_graph_balance_after_payment(true).await;
}

#[tokio::test]
async fn test_update_graph_balance_after_payment_private_channel() {
    do_test_update_graph_balance_after_payment(false).await;
}

#[tokio::test]
async fn test_public_channel_saved_to_the_other_nodes_graph() {
    init_tracing();

    let node1_funding_amount = 100000000000;
    let node2_funding_amount = 6200000000;

    let [mut node1, mut node2, mut node3] = NetworkNode::new_n_interconnected_nodes().await;
    let (_channel_id, funding_tx) = establish_channel_between_nodes(
        &mut node1,
        &mut node2,
        true,
        node1_funding_amount,
        node2_funding_amount,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
    )
    .await;
    let status = node3.submit_tx(funding_tx).await;
    assert_eq!(status, Status::Committed);

    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    node3.stop().await;
    let channels = node3.get_network_graph_channels().await;
    assert_eq!(channels.len(), 1);
    let channel = &channels[0];
    assert_eq!(
        HashSet::from([channel.node1_peerid(), channel.node2_peerid()]),
        HashSet::from([node1.peer_id.clone(), node2.peer_id.clone()])
    );

    let nodes = node3.get_network_graph_nodes().await;
    let node_pubkeys = nodes
        .iter()
        .map(|node| node.node_id)
        .collect::<HashSet<_>>();
    assert!(node_pubkeys.contains(&channel.node1()));
    assert!(node_pubkeys.contains(&channel.node2()));
}

#[tokio::test]
async fn test_public_channel_with_unconfirmed_funding_tx() {
    init_tracing();

    let node1_funding_amount = 100000000000;
    let node2_funding_amount = 6200000000;

    let [mut node1, mut node2, mut node3] = NetworkNode::new_n_interconnected_nodes().await;
    let (_channel_id, _funding_tx) = establish_channel_between_nodes(
        &mut node1,
        &mut node2,
        true,
        node1_funding_amount,
        node2_funding_amount,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
    )
    .await;

    // We should submit the transaction to node 3's chain actor here.
    // If we don't do that node 3 will deem the funding transaction unconfirmed,
    // thus refusing to save the channel to the graph.

    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    node3.stop().await;
    let channels = node3.get_network_graph_channels().await;
    // No channels here as node 3 didn't think the funding transaction is confirmed.
    assert_eq!(channels.len(), 0);
}

#[tokio::test]
async fn test_network_send_payment_normal_keysend_workflow() {
    init_tracing();

    let _span = tracing::info_span!("node", node = "test").entered();
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, node_b, channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, true)
            .await;

    let node_a_local_balance = node_a.get_local_balance_from_channel(channel_id);
    let node_b_local_balance = node_b.get_local_balance_from_channel(channel_id);

    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let node_b_pubkey = node_b.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(10000),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    // this is the payment_hash generated by keysend
    assert_eq!(res.status, PaymentSessionStatus::Created);
    let payment_hash = res.payment_hash;

    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::GetPayment(payment_hash, rpc_reply))
    };
    let res = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .unwrap();

    let new_balance_node_a = node_a.get_local_balance_from_channel(channel_id);
    let new_balance_node_b = node_b.get_local_balance_from_channel(channel_id);

    assert_eq!(node_a_local_balance - new_balance_node_a, 10000);
    assert_eq!(new_balance_node_b - node_b_local_balance, 10000);

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    assert_eq!(res.status, PaymentSessionStatus::Success);
    assert_eq!(res.failed_error, None);

    // we can make the same payment again, since payment_hash will be generated randomly
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(10000),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                tlc_expiry_limit: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    // this is the payment_hash generated by keysend
    assert_eq!(res.status, PaymentSessionStatus::Created);
    let payment_hash = res.payment_hash;

    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::GetPayment(payment_hash, rpc_reply))
    };
    let res = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .unwrap();

    assert_eq!(res.status, PaymentSessionStatus::Success);
    assert_eq!(res.failed_error, None);
}

#[tokio::test]
async fn test_network_send_payment_send_each_other() {
    init_tracing();

    let _span = tracing::info_span!("node", node = "test").entered();
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, node_b, new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, true)
            .await;
    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
    let node_a_old_balance = node_a.get_local_balance_from_channel(new_channel_id);
    let node_b_old_balance = node_b.get_local_balance_from_channel(new_channel_id);

    let node_a_pubkey = node_a.pubkey;
    let node_b_pubkey = node_b.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(10000),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res1 = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    // this is the payment_hash generated by keysend
    assert_eq!(res1.status, PaymentSessionStatus::Created);
    let payment_hash1 = res1.payment_hash;

    // the second payment is send from node_b to node_a
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_a_pubkey),
                amount: Some(9999),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                tlc_expiry_limit: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res2 = call!(node_b.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    // this is the payment_hash generated by keysend
    assert_eq!(res2.status, PaymentSessionStatus::Created);
    let payment_hash2 = res2.payment_hash;

    // sleep for 2 seconds to make sure the payment is processed
    tokio::time::sleep(tokio::time::Duration::from_millis(4000)).await;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::GetPayment(payment_hash1, rpc_reply))
    };
    let res = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    assert_eq!(res.status, PaymentSessionStatus::Success);
    assert_eq!(res.failed_error, None);

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::GetPayment(payment_hash2, rpc_reply))
    };
    let res = call!(node_b.network_actor, message)
        .expect("node_a alive")
        .unwrap();

    assert_eq!(res.status, PaymentSessionStatus::Success);
    assert_eq!(res.failed_error, None);

    let node_a_new_balance = node_a.get_local_balance_from_channel(new_channel_id);
    let node_b_new_balance = node_b.get_local_balance_from_channel(new_channel_id);

    // assert the balance is right,
    // node_a send 10000 to node_b, and node_b send 9999 to node_a
    // so the balance should be node_a_old_balance - 1, node_b_old_balance + 1
    assert_eq!(node_a_new_balance, node_a_old_balance - 1);
    assert_eq!(node_b_new_balance, node_b_old_balance + 1);
}

#[tokio::test]
async fn test_network_send_payment_more_send_each_other() {
    init_tracing();

    // node_a -> node_b  add_tlc 10000
    // node_b -> node_a  add_tlc 9999
    // node_a -> node_b  add_tlc 9999
    // node_b -> node_a  add_tlc 10000
    //
    // all the add_tlc are added at the same time
    // and the final balance should be same as the initial balance

    let _span = tracing::info_span!("node", node = "test").entered();
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, node_b, new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, true)
            .await;
    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
    let node_a_old_balance = node_a.get_local_balance_from_channel(new_channel_id);
    let node_b_old_balance = node_b.get_local_balance_from_channel(new_channel_id);

    let node_a_pubkey = node_a.pubkey;
    let node_b_pubkey = node_b.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(10000),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res1 = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    // this is the payment_hash generated by keysend
    assert_eq!(res1.status, PaymentSessionStatus::Created);
    let payment_hash1 = res1.payment_hash;

    // the second payment is send from node_b to node_a
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_a_pubkey),
                amount: Some(9999),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                tlc_expiry_limit: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res2 = call!(node_b.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    // this is the payment_hash generated by keysend
    assert_eq!(res2.status, PaymentSessionStatus::Created);
    let payment_hash2 = res2.payment_hash;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(9999),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res3 = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    // this is the payment_hash generated by keysend
    assert_eq!(res3.status, PaymentSessionStatus::Created);
    let payment_hash3 = res3.payment_hash;

    // the second payment is send from node_b to node_a
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_a_pubkey),
                amount: Some(10000),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                tlc_expiry_limit: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res4 = call!(node_b.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    // this is the payment_hash generated by keysend
    assert_eq!(res4.status, PaymentSessionStatus::Created);
    let payment_hash4 = res4.payment_hash;

    // sleep for 3 seconds to make sure the payment is processed
    node_a.wait_until_success(payment_hash1).await;
    node_b.wait_until_success(payment_hash2).await;
    node_a.wait_until_success(payment_hash3).await;
    node_b.wait_until_success(payment_hash4).await;

    let node_a_new_balance = node_a.get_local_balance_from_channel(new_channel_id);
    let node_b_new_balance = node_b.get_local_balance_from_channel(new_channel_id);

    // assert the balance is right, the balance should be same as the initial balance
    assert_eq!(node_a_new_balance, node_a_old_balance);
    assert_eq!(node_b_new_balance, node_b_old_balance);
}

#[tokio::test]
async fn test_network_send_payment_send_with_ack() {
    init_tracing();

    let _span = tracing::info_span!("node", node = "test").entered();
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, node_b, _new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, true)
            .await;
    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let node_b_pubkey = node_b.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(10000),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res1 = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    // this is the payment_hash generated by keysend
    assert_eq!(res1.status, PaymentSessionStatus::Created);
    let payment_hash1 = res1.payment_hash;

    // DON'T WAIT FOR A MOMENT, so the second payment will meet WaitingTlcAck first
    // but payment session will handle this case

    // we can make the same payment again, since payment_hash will be generated randomly
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(10000),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                tlc_expiry_limit: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res2 = call!(node_a.network_actor, message).expect("node_a alive");
    // the second send_payment will be blocked by WaitingTlcAck, since we didn't wait for a moment
    assert!(res2.is_ok());
    let payment_hash2 = res2.unwrap().payment_hash;

    node_a.wait_until_success(payment_hash1).await;
    node_a.wait_until_success(payment_hash2).await;
}

#[tokio::test]
async fn test_network_send_previous_tlc_error() {
    init_tracing();

    let _span = tracing::info_span!("node", node = "test").entered();
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, mut node_b, new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, true)
            .await;
    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;

    let secp = Secp256k1::new();
    let keys: Vec<Privkey> = std::iter::repeat_with(gen_rand_fiber_private_key)
        .take(1)
        .collect();
    let hops_infos = vec![
        PaymentHopData {
            amount: 2,
            expiry: 3,
            next_hop: Some(keys[0].pubkey()),
            funding_tx_hash: Hash256::default(),
            hash_algorithm: HashAlgorithm::Sha256,
            payment_preimage: None,
        },
        PaymentHopData {
            amount: 8,
            expiry: 9,
            next_hop: None,
            funding_tx_hash: Hash256::default(),
            hash_algorithm: HashAlgorithm::Sha256,
            payment_preimage: None,
        },
    ];
    let generated_payment_hash = gen_rand_sha256_hash();

    let packet = PeeledOnionPacket::create(
        gen_rand_fiber_private_key(),
        hops_infos.clone(),
        Some(generated_payment_hash.as_ref().to_vec()),
        &secp,
    )
    .expect("create peeled packet");

    // step1: try to send a invalid onion_packet with add_tlc
    // ==================================================================================
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::AddTlc(
                    AddTlcCommand {
                        amount: 10000,
                        payment_hash: generated_payment_hash,
                        expiry: DEFAULT_EXPIRY_DELTA + now_timestamp_as_millis_u64(),
                        hash_algorithm: HashAlgorithm::Sha256,
                        // invalid onion packet
                        onion_packet: packet.next.clone(),
                        shared_secret: packet.shared_secret,
                        previous_tlc: None,
                    },
                    rpc_reply,
                ),
            },
        ))
    };

    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());
    let node_b_peer_id = node_b.peer_id.clone();
    node_b
        .expect_event(|event| match event {
            NetworkServiceEvent::DebugEvent(DebugEvent::AddTlcFailed(
                peer_id,
                payment_hash,
                err,
            )) => {
                assert_eq!(peer_id, &node_b_peer_id);
                assert_eq!(payment_hash, &generated_payment_hash);
                assert_eq!(err.error_code, TlcErrorCode::InvalidOnionPayload);
                true
            }
            _ => false,
        })
        .await;
    // sleep 2 seconds to make sure node_b processed handle_add_tlc_peer_message
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    // XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

    // step2: try to send the second valid payment, expect it to success
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b.pubkey),
                amount: Some(10000),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
                tlc_expiry_limit: None,
            },
            rpc_reply,
        ))
    };

    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;

    node_a.wait_until_success(payment_hash).await;
}

#[tokio::test]
async fn test_network_send_payment_keysend_with_payment_hash() {
    init_tracing();

    let _span = tracing::info_span!("node", node = "test").entered();
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, node_b, _new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, true)
            .await;
    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let node_b_pubkey = node_b.pubkey;
    let payment_hash = gen_rand_sha256_hash();

    // This payment request is without an invoice, the receiver will return an error `IncorrectOrUnknownPaymentDetails`
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(10000),
                payment_hash: Some(payment_hash),
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,

                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res
        .err()
        .unwrap()
        .contains("keysend payment should not have payment_hash"));
}

#[tokio::test]
async fn test_network_send_payment_final_incorrect_hash() {
    init_tracing();

    let _span = tracing::info_span!("node", node = "test").entered();
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, node_b, channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, true)
            .await;
    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let node_a_local_balance = node_a.get_local_balance_from_channel(channel_id);
    let node_b_local_balance = node_b.get_local_balance_from_channel(channel_id);

    let node_b_pubkey = node_b.pubkey;
    let payment_hash = gen_rand_sha256_hash();

    // This payment request is without an invoice, the receiver will return an error `IncorrectOrUnknownPaymentDetails`
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(10000),
                payment_hash: Some(payment_hash),
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: None,
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::GetPayment(payment_hash, rpc_reply))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());
    assert_eq!(res.unwrap().status, PaymentSessionStatus::Inflight);

    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::GetPayment(payment_hash, rpc_reply))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    let res = res.unwrap();
    assert_eq!(res.status, PaymentSessionStatus::Failed);
    assert_eq!(
        res.failed_error,
        Some("IncorrectOrUnknownPaymentDetails".to_string())
    );

    let new_balance_node_a = node_a.get_local_balance_from_channel(channel_id);
    let new_balance_node_b = node_b.get_local_balance_from_channel(channel_id);

    assert_eq!(node_a_local_balance - new_balance_node_a, 0);
    assert_eq!(new_balance_node_b - node_b_local_balance, 0);
}

#[tokio::test]
async fn test_network_send_payment_target_not_found() {
    init_tracing();

    let _span = tracing::info_span!("node", node = "test").entered();
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, _node_b, _new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, true)
            .await;
    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let node_b_pubkey = gen_rand_fiber_public_key();
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(10000),
                payment_hash: Some(gen_rand_sha256_hash()),
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: None,
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_err());
    assert!(res.err().unwrap().contains("no path found"));
}

#[tokio::test]
async fn test_network_send_payment_amount_is_too_large() {
    init_tracing();

    let _span = tracing::info_span!("node", node = "test").entered();
    let node_a_funding_amount = 100000000000 + MIN_RESERVED_CKB;
    let node_b_funding_amount = MIN_RESERVED_CKB + 2;

    let (node_a, node_b, _new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, true)
            .await;
    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let node_b_pubkey = node_b.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(100000000000 + 5),
                payment_hash: Some(gen_rand_sha256_hash()),
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: None,
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");

    assert!(res.is_err());
    // because the amount is too large, we will consider balance for direct channel
    // so fail to build a path
    assert!(res.err().unwrap().contains("no path found"));
}

// FIXME: this is the case send_payment with direct channels, we should handle this case
#[tokio::test]
async fn test_network_send_payment_with_dry_run() {
    init_tracing();

    let _span = tracing::info_span!("node", node = "test").entered();
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 62000000000;

    let (node_a, node_b, _new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, true)
            .await;
    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let node_b_pubkey = node_b.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(100000),
                payment_hash: Some(gen_rand_sha256_hash()),
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: None,
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: true,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());
    let res = res.unwrap();
    assert_eq!(res.status, PaymentSessionStatus::Created);
    // since there are only sender and receiver in the router, fee will be 0
    assert_eq!(res.fee, 0);

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(gen_rand_fiber_public_key()),
                amount: Some(1000 + 5),
                payment_hash: Some(gen_rand_sha256_hash()),
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: None,
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: true,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    // since the target is not valid, the payment check will fail
    assert!(res.is_err());
}

#[tokio::test]
async fn test_send_payment_with_3_nodes() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (node_a, node_b, node_c, channel_1, channel_2) = create_3_nodes_with_established_channel(
        (100000000000, 100000000000),
        (100000000000, 100000000000),
        true,
    )
    .await;
    let node_a_local = node_a.get_local_balance_from_channel(channel_1);
    let node_b_local_left = node_b.get_local_balance_from_channel(channel_1);
    let node_b_local_right = node_b.get_local_balance_from_channel(channel_2);
    let node_c_local = node_c.get_local_balance_from_channel(channel_2);

    // sleep for 2 seconds to make sure the channel is established
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
    let sent_amount = 1000000 + 5;
    let node_c_pubkey = node_c.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_c_pubkey),
                amount: Some(sent_amount),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());
    let res = res.unwrap();
    assert_eq!(res.status, PaymentSessionStatus::Created);
    assert!(res.fee > 0);
    // sleep for 2 seconds to make sure the payment is sent
    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::GetPayment(res.payment_hash, rpc_reply))
    };
    let res = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    assert_eq!(res.status, PaymentSessionStatus::Success);
    assert_eq!(res.failed_error, None);

    let new_node_a_local = node_a.get_local_balance_from_channel(channel_1);
    let new_node_b_left = node_b.get_local_balance_from_channel(channel_1);
    let new_node_b_right = node_b.get_local_balance_from_channel(channel_2);
    let new_node_c_local = node_c.get_local_balance_from_channel(channel_2);

    let node_a_sent = node_a_local - new_node_a_local;
    assert_eq!(node_a_sent, sent_amount + res.fee);
    let node_b_sent = node_b_local_right - new_node_b_right;
    let node_b_received = new_node_b_left - node_b_local_left;
    let node_b_got = node_b_received - node_b_sent;
    assert_eq!(node_b_got, res.fee);
    let node_c_got = new_node_c_local - node_c_local;
    assert_eq!(node_c_got, sent_amount);
}

#[tokio::test]
async fn test_send_payment_with_rev_3_nodes() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        vec![
            ((2, 1), (100000000000, 100000000000)),
            ((1, 0), (100000000000, 100000000000)),
        ]
        .as_slice(),
        3,
        true,
    )
    .await;

    let [node_a, node_b, node_c] = nodes.try_into().expect("3 nodes");
    let [channel_1, channel_2] = channels.try_into().expect("2 channels");

    let node_c_local = node_c.get_local_balance_from_channel(channel_1);
    let node_b_local_right = node_b.get_local_balance_from_channel(channel_1);
    let node_b_local_left = node_b.get_local_balance_from_channel(channel_2);
    let node_a_local = node_a.get_local_balance_from_channel(channel_2);

    let sent_amount = 1000000 + 5;
    let node_a_pubkey = node_a.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_a_pubkey),
                amount: Some(sent_amount),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_c.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());
    let res = res.unwrap();
    assert_eq!(res.status, PaymentSessionStatus::Created);
    assert!(res.fee > 0);
    // sleep for 2 seconds to make sure the payment is sent
    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::GetPayment(res.payment_hash, rpc_reply))
    };
    let res = call!(node_c.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    assert_eq!(res.status, PaymentSessionStatus::Success);
    assert_eq!(res.failed_error, None);

    let new_node_c_local = node_c.get_local_balance_from_channel(channel_1);
    let new_node_b_right = node_b.get_local_balance_from_channel(channel_1);
    let new_node_b_left = node_b.get_local_balance_from_channel(channel_2);
    let new_node_a_local = node_a.get_local_balance_from_channel(channel_2);

    let node_c_sent = node_c_local - new_node_c_local;
    assert_eq!(node_c_sent, sent_amount + res.fee);
    let node_b_sent = node_b_local_left - new_node_b_left;
    let node_b_received = new_node_b_right - node_b_local_right;
    let node_b_got = node_b_received - node_b_sent;
    assert_eq!(node_b_got, res.fee);
    let node_a_got = new_node_a_local - node_a_local;
    assert_eq!(node_a_got, sent_amount);
}

#[tokio::test]
async fn test_send_payment_with_max_nodes() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let nodes_num = 15;
    let last = nodes_num - 1;
    let amounts = vec![(100000000000, 100000000000); nodes_num - 1];
    let (nodes, channels) =
        create_n_nodes_with_established_channel(&amounts, nodes_num, true).await;
    let source_node = &nodes[0];
    let target_pubkey = nodes[last].pubkey;

    let sender_local = nodes[0].get_local_balance_from_channel(channels[0]);
    let receiver_local = nodes[last].get_local_balance_from_channel(channels[last - 1]);

    // sleep for seconds to make sure the channel is established
    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
    let sent_amount = 1000000 + 5;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(target_pubkey),
                amount: Some(sent_amount),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: true,
            },
            rpc_reply,
        ))
    };
    let res = call!(source_node.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(target_pubkey),
                amount: Some(sent_amount),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let source_node = &nodes[0];
    let res = call!(source_node.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());
    let res = res.unwrap();
    assert_eq!(res.status, PaymentSessionStatus::Created);
    assert!(res.fee > 0);

    nodes[0].wait_until_success(res.payment_hash).await;

    let sender_local_new = nodes[0].get_local_balance_from_channel(channels[0]);
    let receiver_local_new = nodes[last].get_local_balance_from_channel(channels[last - 1]);

    let sender_sent = sender_local - sender_local_new;
    let receiver_received = receiver_local_new - receiver_local;

    assert_eq!(sender_sent, sent_amount + res.fee);
    assert_eq!(receiver_received, sent_amount);
}

#[tokio::test]
async fn test_send_payment_with_3_nodes_overflow() {
    // Fix issue #361

    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (node_a, _node_b, node_c, ..) = create_3_nodes_with_established_channel(
        (1000000000 * 100000000, 1000000000 * 100000000),
        (1000000000 * 100000000, 1000000000 * 100000000),
        true,
    )
    .await;

    // sleep for 2 seconds to make sure the channel is established
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
    let sent_amount = 0xfffffffffffffffffffffffffffffff;
    let node_c_pubkey = node_c.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_c_pubkey),
                amount: Some(sent_amount),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_err());
    assert!(res
        .err()
        .unwrap()
        .contains("The payment amount (21267647932558653966460912964485513215) should be less than 1844674407370955161"));
}

#[tokio::test]
async fn test_send_payment_fail_with_3_nodes_invalid_hash() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();

    let (node_a, node_b, node_c, channel_1, channel_2) = create_3_nodes_with_established_channel(
        (100000000000, 100000000000),
        (100000000000, 100000000000),
        true,
    )
    .await;

    let node_a_local = node_a.get_local_balance_from_channel(channel_1);
    let node_b_local_left = node_b.get_local_balance_from_channel(channel_1);
    let node_b_local_right = node_b.get_local_balance_from_channel(channel_2);
    let node_c_local = node_c.get_local_balance_from_channel(channel_2);

    // sleep for 2 seconds to make sure the channel is established
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
    let node_c_pubkey = node_c.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_c_pubkey),
                amount: Some(1000000 + 5),
                payment_hash: Some(gen_rand_sha256_hash()), // this payment hash is not from node_c
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: None,
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());
    let res = res.unwrap();
    assert_eq!(res.status, PaymentSessionStatus::Created);
    assert!(res.fee > 0);
    // sleep for 2 seconds to make sure the payment is sent
    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::GetPayment(res.payment_hash, rpc_reply))
    };
    let res = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    assert_eq!(res.status, PaymentSessionStatus::Failed);
    assert_eq!(
        res.failed_error,
        Some("IncorrectOrUnknownPaymentDetails".to_string())
    );

    let new_node_a_local = node_a.get_local_balance_from_channel(channel_1);
    let new_node_b_left = node_b.get_local_balance_from_channel(channel_1);
    let new_node_b_right = node_b.get_local_balance_from_channel(channel_2);
    let new_node_c_local = node_c.get_local_balance_from_channel(channel_2);

    let node_a_sent = node_a_local - new_node_a_local;
    assert_eq!(node_a_sent, 0);
    let node_b_sent = node_b_local_right - new_node_b_right;
    let node_b_received = new_node_b_left - node_b_local_left;
    let node_b_got = node_b_received - node_b_sent;
    assert_eq!(node_b_got, 0);
    let node_c_got = new_node_c_local - node_c_local;
    assert_eq!(node_c_got, 0);
}

#[tokio::test]
async fn test_send_payment_fail_with_3_nodes_final_tlc_expiry_delta() {
    // Fix issue #367, we should check the final_tlc_expiry_delta

    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();

    let (node_a, _node_b, node_c, ..) = create_3_nodes_with_established_channel(
        (100000000000, 100000000000),
        (100000000000, 100000000000),
        true,
    )
    .await;

    // sleep for 2 seconds to make sure the channel is established
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
    let node_c_pubkey = node_c.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_c_pubkey),
                amount: Some(1000000000),
                payment_hash: None,
                final_tlc_expiry_delta: Some(86400000 + 100), // should be in normal range
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());
    let res = res.unwrap();
    assert_eq!(res.status, PaymentSessionStatus::Created);

    let node_c_pubkey = node_c.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_c_pubkey),
                amount: Some(1000000000),
                payment_hash: None,
                final_tlc_expiry_delta: Some(14 * 24 * 60 * 60 * 1000 + 1), // 14 days + 1 ms
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_err());
    assert!(res.unwrap_err().contains("invalid final_tlc_expiry_delta"));

    let node_c_pubkey = node_c.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_c_pubkey),
                amount: Some(1000000000),
                payment_hash: None,
                final_tlc_expiry_delta: Some(14 * 24 * 60 * 60 * 1000 - 100), // 14 days - 100, will not find a path
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_err());
    assert!(res.unwrap_err().contains("no path found"));
}

#[tokio::test]
async fn test_send_payment_fail_with_3_nodes_dry_run_fee() {
    // Fix issue #360, dryrun option should get correct fee

    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();

    let (node_a, _node_b, node_c, ..) = create_3_nodes_with_established_channel(
        (100000000000, 100000000000),
        (100000000000, 100000000000),
        true,
    )
    .await;

    // sleep for 2 seconds to make sure the channel is established
    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;
    let node_c_pubkey = node_c.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_c_pubkey),
                amount: Some(2000000000),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: true,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());
    let res = res.unwrap();
    assert_eq!(res.fee, 2000000);

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_c_pubkey),
                amount: Some(1000000000),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: true,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());
    let res = res.unwrap();
    // expect smaller fee since amount is smaller
    assert_eq!(res.fee, 1000000);

    let node_c_pubkey = node_c.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_c_pubkey),
                amount: Some(1000000000),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: Some(res.fee), // exact the same fee limit
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());
    let res = res.unwrap();
    assert_eq!(res.fee, 1000000);

    let node_c_pubkey = node_c.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_c_pubkey),
                amount: Some(1000000000),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: Some(res.fee - 1), // set a smaller fee limit, path find will fail
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_err());
}

#[tokio::test]
async fn test_network_send_payment_dry_run_can_still_query() {
    init_tracing();

    let _span = tracing::info_span!("node", node = "test").entered();
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, node_b, _new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, true)
            .await;
    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;

    let payment_hash = gen_rand_sha256_hash();
    let node_b_pubkey = node_b.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(10000),
                payment_hash: Some(payment_hash),
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: None,
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());

    // sleep for a while to make sure the payment session is created
    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(10000),
                payment_hash: Some(payment_hash),
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: None,
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: true,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());
}

#[tokio::test]
async fn test_network_send_payment_dry_run_will_not_create_payment_session() {
    init_tracing();

    let _span = tracing::info_span!("node", node = "test").entered();
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, node_b, _new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, true)
            .await;
    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;

    let payment_hash = gen_rand_sha256_hash();
    let node_b_pubkey = node_b.pubkey;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(10000),
                payment_hash: Some(payment_hash),
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: None,
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: true,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    dbg!(&res);
    assert!(res.is_ok());

    // make sure we can send the same payment after dry run query
    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(10000),
                payment_hash: Some(payment_hash),
                final_tlc_expiry_delta: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                tlc_expiry_limit: None,
                max_parts: None,
                keysend: None,
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());
}

#[tokio::test]
async fn test_stash_broadcast_messages() {
    init_tracing();

    let _span = tracing::info_span!("node", node = "test").entered();

    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (_node_a, _node_b, _new_channel_id, _) = NetworkNode::new_2_nodes_with_established_channel(
        node_a_funding_amount,
        node_b_funding_amount,
        true,
    )
    .await;

    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
}

async fn do_test_channel_commitment_tx_after_add_tlc(algorithm: HashAlgorithm) {
    let [mut node_a, mut node_b] = NetworkNode::new_n_interconnected_nodes().await;

    let node_a_funding_amount = 100000000000;
    let node_b_funidng_amount = 6200000000;

    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::OpenChannel(
            OpenChannelCommand {
                peer_id: node_b.peer_id.clone(),
                public: false,
                shutdown_script: None,
                funding_amount: node_a_funding_amount,
                funding_udt_type_script: None,
                commitment_fee_rate: None,
                commitment_delay_epoch: None,
                funding_fee_rate: None,
                tlc_expiry_delta: None,
                tlc_min_value: None,
                tlc_fee_proportional_millionths: None,
                max_tlc_number_in_flight: None,
                max_tlc_value_in_flight: None,
            },
            rpc_reply,
        ))
    };
    let open_channel_result = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .expect("open channel success");

    node_b
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelPendingToBeAccepted(peer_id, channel_id) => {
                println!("A channel ({:?}) to {:?} create", &channel_id, peer_id);
                assert_eq!(peer_id, &node_a.peer_id);
                true
            }
            _ => false,
        })
        .await;
    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::AcceptChannel(
            AcceptChannelCommand {
                temp_channel_id: open_channel_result.channel_id,
                funding_amount: node_b_funidng_amount,
                shutdown_script: None,
                max_tlc_number_in_flight: None,
                max_tlc_value_in_flight: None,
                min_tlc_value: None,
                tlc_fee_proportional_millionths: None,
                tlc_expiry_delta: None,
            },
            rpc_reply,
        ))
    };
    let accept_channel_result = call!(node_b.network_actor, message)
        .expect("node_b alive")
        .expect("accept channel success");
    let new_channel_id = accept_channel_result.new_channel_id;

    node_a
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelReady(peer_id, channel_id, _funding_tx_hash) => {
                println!(
                    "A channel ({:?}) to {:?} is now ready",
                    &channel_id, &peer_id
                );
                assert_eq!(peer_id, &node_b.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                true
            }
            _ => false,
        })
        .await;

    node_b
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelReady(peer_id, channel_id, _funding_tx_hash) => {
                println!(
                    "A channel ({:?}) to {:?} is now ready",
                    &channel_id, &peer_id
                );
                assert_eq!(peer_id, &node_a.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                true
            }
            _ => false,
        })
        .await;

    let preimage = [1; 32];
    let digest = algorithm.hash(preimage);
    let tlc_amount = 1000000000;

    let add_tlc_result = call!(node_a.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::AddTlc(
                    AddTlcCommand {
                        amount: tlc_amount,
                        hash_algorithm: algorithm,
                        payment_hash: digest.into(),
                        expiry: now_timestamp_as_millis_u64() + DEFAULT_EXPIRY_DELTA,
                        onion_packet: None,
                        shared_secret: NO_SHARED_SECRET,
                        previous_tlc: None,
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .expect("node_b alive")
    .expect("successfully added tlc");

    dbg!(&add_tlc_result);

    // Since we currently automatically send a `CommitmentSigned` message
    // after sending a `AddTlc` message, we can expect the `RemoteCommitmentSigned`
    // to be received by node b.
    let node_b_commitment_tx = node_b
        .expect_to_process_event(|event| match event {
            NetworkServiceEvent::RemoteCommitmentSigned(peer_id, channel_id, tx, _) => {
                println!(
                    "Commitment tx {:?} from {:?} for channel {:?} received",
                    &tx, peer_id, channel_id
                );
                assert_eq!(peer_id, &node_a.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                Some(tx.clone())
            }
            _ => None,
        })
        .await;

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    call!(node_b.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::RemoveTlc(
                    RemoveTlcCommand {
                        id: add_tlc_result.tlc_id,
                        reason: RemoveTlcReason::RemoveTlcFulfill(RemoveTlcFulfill {
                            payment_preimage: preimage.into(),
                        }),
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .expect("node_b alive")
    .expect("successfully removed tlc");

    // Since we currently automatically send a `CommitmentSigned` message
    // after sending a `RemoveTlc` message, we can expect the `RemoteCommitmentSigned`
    // to be received by node a.
    let node_a_commitment_tx = node_a
        .expect_to_process_event(|event| match event {
            NetworkServiceEvent::RemoteCommitmentSigned(peer_id, channel_id, tx, _) => {
                println!(
                    "Commitment tx {:?} from {:?} for channel {:?} received",
                    &tx, peer_id, channel_id
                );
                assert_eq!(peer_id, &node_b.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                Some(tx.clone())
            }
            _ => None,
        })
        .await;

    assert_eq!(
        node_a.submit_tx(node_a_commitment_tx.clone()).await,
        Status::Committed
    );

    assert_eq!(
        node_b.submit_tx(node_b_commitment_tx.clone()).await,
        Status::Committed
    );
}

#[tokio::test]
async fn test_channel_commitment_tx_after_add_tlc_ckbhash() {
    do_test_channel_commitment_tx_after_add_tlc(HashAlgorithm::CkbHash).await
}

#[tokio::test]
async fn test_channel_commitment_tx_after_add_tlc_sha256() {
    do_test_channel_commitment_tx_after_add_tlc(HashAlgorithm::Sha256).await
}

async fn do_test_remove_tlc_with_wrong_hash_algorithm(
    correct_algorithm: HashAlgorithm,
    wrong_algorithm: HashAlgorithm,
) {
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, node_b, new_channel_id, _) = NetworkNode::new_2_nodes_with_established_channel(
        node_a_funding_amount,
        node_b_funding_amount,
        false,
    )
    .await;

    let preimage = [1; 32];
    let digest = correct_algorithm.hash(preimage);
    let tlc_amount = 1000000000;

    let add_tlc_result = call!(node_a.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::AddTlc(
                    AddTlcCommand {
                        amount: tlc_amount,
                        hash_algorithm: correct_algorithm,
                        payment_hash: digest.into(),
                        expiry: now_timestamp_as_millis_u64() + DEFAULT_EXPIRY_DELTA,
                        onion_packet: None,
                        shared_secret: NO_SHARED_SECRET,
                        previous_tlc: None,
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .expect("node_b alive")
    .expect("successfully added tlc");

    dbg!(&add_tlc_result);

    dbg!("Sleeping for some time to wait for the AddTlc processed by both party");
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    call!(node_b.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::RemoveTlc(
                    RemoveTlcCommand {
                        id: add_tlc_result.tlc_id,
                        reason: RemoveTlcReason::RemoveTlcFulfill(RemoveTlcFulfill {
                            payment_preimage: preimage.into(),
                        }),
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .expect("node_b alive")
    .expect("successfully removed tlc");

    dbg!("Sleeping for some time to wait for the RemoveTlc processed by both party");
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    let preimage = [2; 32];
    // create a new payment hash
    let digest = correct_algorithm.hash(preimage);
    let add_tlc_result = call!(node_a.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::AddTlc(
                    AddTlcCommand {
                        amount: tlc_amount,
                        hash_algorithm: wrong_algorithm,
                        payment_hash: digest.into(),
                        expiry: now_timestamp_as_millis_u64() + DEFAULT_EXPIRY_DELTA,
                        onion_packet: None,
                        shared_secret: NO_SHARED_SECRET,
                        previous_tlc: None,
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .expect("node_b alive")
    .expect("successfully added tlc");

    dbg!(&add_tlc_result);

    dbg!("Sleeping for some time to wait for the AddTlc processed by both party");
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    let remove_tlc_result = call!(node_b.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::RemoveTlc(
                    RemoveTlcCommand {
                        id: add_tlc_result.tlc_id,
                        reason: RemoveTlcReason::RemoveTlcFulfill(RemoveTlcFulfill {
                            payment_preimage: preimage.into(),
                        }),
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .expect("node_b alive");

    dbg!(&remove_tlc_result);
    assert!(remove_tlc_result.is_err());
}

#[tokio::test]
async fn do_test_channel_remote_commitment_error() {
    // https://github.com/nervosnetwork/fiber/issues/447
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 100000000000;

    let tlc_number_in_flight_limit = 5;
    let [mut node_a, mut node_b] = NetworkNode::new_n_interconnected_nodes().await;

    let (new_channel_id, _funding_tx) = establish_channel_between_nodes(
        &mut node_a,
        &mut node_b,
        false,
        node_a_funding_amount,
        node_b_funding_amount,
        Some(tlc_number_in_flight_limit as u64),
        None,
        None,
        None,
        None,
        Some(tlc_number_in_flight_limit as u64),
        None,
        None,
        None,
        None,
    )
    .await;

    let mut all_sent = vec![];
    let mut batch_remove_count = 0;
    while batch_remove_count <= 3 {
        let preimage: [u8; 32] = gen_rand_sha256_hash().as_ref().try_into().unwrap();

        // create a new payment hash
        let hash_algorithm = HashAlgorithm::Sha256;
        let digest = hash_algorithm.hash(preimage);
        if let Ok(add_tlc_result) = call!(node_a.network_actor, |rpc_reply| {
            NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                ChannelCommandWithId {
                    channel_id: new_channel_id,
                    command: ChannelCommand::AddTlc(
                        AddTlcCommand {
                            amount: 1000,
                            hash_algorithm,
                            payment_hash: digest.into(),
                            expiry: now_timestamp_as_millis_u64() + DEFAULT_EXPIRY_DELTA,
                            onion_packet: None,
                            shared_secret: NO_SHARED_SECRET,
                            previous_tlc: None,
                        },
                        rpc_reply,
                    ),
                },
            ))
        })
        .expect("node_b alive")
        {
            dbg!(&add_tlc_result);
            all_sent.push((preimage, add_tlc_result.tlc_id));
        }
        tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
        if all_sent.len() >= tlc_number_in_flight_limit {
            while all_sent.len() > tlc_number_in_flight_limit - 2 {
                if let Some((preimage, tlc_id)) = all_sent.first().cloned() {
                    let remove_tlc_result = call!(node_b.network_actor, |rpc_reply| {
                        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                            ChannelCommandWithId {
                                channel_id: new_channel_id,
                                command: ChannelCommand::RemoveTlc(
                                    RemoveTlcCommand {
                                        id: tlc_id,
                                        reason: RemoveTlcReason::RemoveTlcFulfill(
                                            RemoveTlcFulfill {
                                                payment_preimage: Hash256::from(preimage),
                                            },
                                        ),
                                    },
                                    rpc_reply,
                                ),
                            },
                        ))
                    })
                    .expect("node_b alive");
                    dbg!(&remove_tlc_result);
                    if remove_tlc_result.is_ok()
                        || remove_tlc_result
                            .unwrap_err()
                            .to_string()
                            .contains("Trying to remove non-existing tlc")
                    {
                        all_sent.remove(0);
                    }
                }
            }
            batch_remove_count += 1;
        }
    }
}

#[tokio::test]
async fn test_network_add_two_tlcs_remove_one() {
    let _span = tracing::info_span!("node", node = "test").entered();
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 100000000000;

    let (node_a, node_b, channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, true)
            .await;
    // Wait for the channel announcement to be broadcasted

    let old_a_balance = node_a.get_local_balance_from_channel(channel_id);
    let old_b_balance = node_b.get_local_balance_from_channel(channel_id);

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let preimage_a = [1; 32];
    let algorithm = HashAlgorithm::Sha256;
    let digest = algorithm.hash(preimage_a);

    let add_tlc_result_a = call!(node_a.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id,
                command: ChannelCommand::AddTlc(
                    AddTlcCommand {
                        amount: 1000,
                        hash_algorithm: algorithm,
                        payment_hash: digest.into(),
                        expiry: now_timestamp_as_millis_u64() + DEFAULT_EXPIRY_DELTA,
                        onion_packet: None,
                        shared_secret: NO_SHARED_SECRET,
                        previous_tlc: None,
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .expect("node_a alive")
    .expect("successfully added tlc");
    eprintln!("add_tlc_result: {:?}", add_tlc_result_a);

    // if we don't wait for a while, the next add_tlc will fail with temporary failure
    let preimage_b = [2; 32];
    let algorithm = HashAlgorithm::Sha256;
    let digest = algorithm.hash(preimage_b);
    let add_tlc_result = call!(node_a.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id,
                command: ChannelCommand::AddTlc(
                    AddTlcCommand {
                        amount: 2000,
                        hash_algorithm: algorithm,
                        payment_hash: digest.into(),
                        expiry: now_timestamp_as_millis_u64() + DEFAULT_EXPIRY_DELTA,
                        onion_packet: None,
                        shared_secret: NO_SHARED_SECRET,
                        previous_tlc: None,
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .expect("node_b alive");
    assert!(add_tlc_result.is_err());

    // now wait for a while, then add a tlc again, it will success
    tokio::time::sleep(tokio::time::Duration::from_millis(200)).await;
    let add_tlc_result_b = call!(node_a.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id,
                command: ChannelCommand::AddTlc(
                    AddTlcCommand {
                        amount: 2000,
                        hash_algorithm: algorithm,
                        payment_hash: digest.into(),
                        expiry: now_timestamp_as_millis_u64() + DEFAULT_EXPIRY_DELTA,
                        onion_packet: None,
                        shared_secret: NO_SHARED_SECRET,
                        previous_tlc: None,
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .expect("node_b alive");
    assert!(add_tlc_result_b.is_ok());

    eprintln!("add_tlc_result: {:?}", add_tlc_result_b);

    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
    // remove tlc from node_b
    call!(node_b.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id,
                command: ChannelCommand::RemoveTlc(
                    RemoveTlcCommand {
                        id: add_tlc_result_a.tlc_id,
                        reason: RemoveTlcReason::RemoveTlcFulfill(RemoveTlcFulfill {
                            payment_preimage: preimage_a.into(),
                        }),
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .expect("node_b alive")
    .expect("successfully removed tlc");
    eprintln!("remove tlc result: {:?}", ());
    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;

    let new_a_balance = node_a.get_local_balance_from_channel(channel_id);
    let new_b_balance = node_b.get_local_balance_from_channel(channel_id);
    eprintln!(
        "old_a_balance: {}, new_a_balance: {}, old_b_balance: {}, new_b_balance: {}",
        old_a_balance, new_a_balance, old_b_balance, new_b_balance
    );
    assert_eq!(new_a_balance, old_a_balance - 1000);
    assert_eq!(new_b_balance, old_b_balance + 1000);

    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
    // remove the later tlc from node_b
    call!(node_b.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id,
                command: ChannelCommand::RemoveTlc(
                    RemoveTlcCommand {
                        id: add_tlc_result_b.unwrap().tlc_id,
                        reason: RemoveTlcReason::RemoveTlcFulfill(RemoveTlcFulfill {
                            payment_preimage: preimage_b.into(),
                        }),
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .expect("node_b alive")
    .expect("successfully removed tlc");
    eprintln!("remove tlc result: {:?}", ());
    tokio::time::sleep(tokio::time::Duration::from_millis(400)).await;

    let new_a_balance = node_a.get_local_balance_from_channel(channel_id);
    let new_b_balance = node_b.get_local_balance_from_channel(channel_id);
    eprintln!(
        "old_a_balance: {}, new_a_balance: {}, old_b_balance: {}, new_b_balance: {}",
        old_a_balance, new_a_balance, old_b_balance, new_b_balance
    );
    assert_eq!(new_a_balance, old_a_balance - 3000);
    assert_eq!(new_b_balance, old_b_balance + 3000);
}

#[tokio::test]
async fn test_remove_tlc_with_expiry_error() {
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, _node_b, new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, false)
            .await;

    let preimage = [1; 32];
    let digest = HashAlgorithm::CkbHash.hash(preimage);
    let tlc_amount = 1000000000;

    // add tlc command with expiry soon
    let add_tlc_command = AddTlcCommand {
        amount: tlc_amount,
        hash_algorithm: HashAlgorithm::CkbHash,
        payment_hash: digest.into(),
        expiry: now_timestamp_as_millis_u64() + 10,
        onion_packet: None,
        shared_secret: NO_SHARED_SECRET,
        previous_tlc: None,
    };

    std::thread::sleep(std::time::Duration::from_millis(400));
    let add_tlc_result = call!(node_a.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::AddTlc(add_tlc_command, rpc_reply),
            },
        ))
    })
    .expect("node_b alive");
    assert!(add_tlc_result.is_err());

    // add tlc command with expiry in the future too long
    let add_tlc_command = AddTlcCommand {
        amount: tlc_amount,
        hash_algorithm: HashAlgorithm::CkbHash,
        payment_hash: digest.into(),
        expiry: now_timestamp_as_millis_u64() + MAX_PAYMENT_TLC_EXPIRY_LIMIT + 20 * 1000,
        onion_packet: None,
        shared_secret: NO_SHARED_SECRET,
        previous_tlc: None,
    };

    let add_tlc_result = call!(node_a.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::AddTlc(add_tlc_command, rpc_reply),
            },
        ))
    })
    .expect("node_b alive");

    assert!(add_tlc_result.is_err());
}

#[tokio::test]
async fn do_test_add_tlc_duplicated() {
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, _node_b, new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, false)
            .await;

    let preimage = [1; 32];
    let digest = HashAlgorithm::CkbHash.hash(preimage);
    let tlc_amount = 1000000000;

    for i in 1..=2 {
        std::thread::sleep(std::time::Duration::from_millis(400));
        // add tlc command with expiry soon
        let add_tlc_command = AddTlcCommand {
            amount: tlc_amount,
            hash_algorithm: HashAlgorithm::CkbHash,
            payment_hash: digest.into(),
            expiry: now_timestamp_as_millis_u64() + 10,
            onion_packet: None,
            shared_secret: NO_SHARED_SECRET,
            previous_tlc: None,
        };
        let add_tlc_result = call!(node_a.network_actor, |rpc_reply| {
            NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                ChannelCommandWithId {
                    channel_id: new_channel_id,
                    command: ChannelCommand::AddTlc(add_tlc_command, rpc_reply),
                },
            ))
        })
        .expect("node_b alive");
        if i == 1 {
            assert!(add_tlc_result.is_ok());
        }
        if i == 2 {
            assert!(add_tlc_result.is_err());
        }
    }
}

#[tokio::test]
async fn do_test_add_tlc_waiting_ack() {
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, node_b, new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, false)
            .await;

    let tlc_amount = 1000000000;

    for i in 1..=2 {
        let add_tlc_command = AddTlcCommand {
            amount: tlc_amount,
            hash_algorithm: HashAlgorithm::CkbHash,
            payment_hash: gen_rand_sha256_hash(),
            expiry: now_timestamp_as_millis_u64() + 100000000,
            onion_packet: None,
            shared_secret: NO_SHARED_SECRET,
            previous_tlc: None,
        };
        let add_tlc_result = call!(node_a.network_actor, |rpc_reply| {
            NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                ChannelCommandWithId {
                    channel_id: new_channel_id,
                    command: ChannelCommand::AddTlc(add_tlc_command, rpc_reply),
                },
            ))
        })
        .expect("node_b alive");
        if i == 2 {
            // we are sending AddTlc constantly, so we should get a WaitingTlcAck
            assert!(add_tlc_result.is_err());
            let code = add_tlc_result.unwrap_err();
            assert_eq!(code.error_code, TlcErrorCode::TemporaryChannelFailure);
        } else {
            assert!(add_tlc_result.is_ok());
        }
    }

    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
    // send from b to a
    for i in 1..=2 {
        let add_tlc_command = AddTlcCommand {
            amount: tlc_amount,
            hash_algorithm: HashAlgorithm::CkbHash,
            payment_hash: gen_rand_sha256_hash(),
            expiry: now_timestamp_as_millis_u64() + 100000000,
            onion_packet: None,
            previous_tlc: None,
            shared_secret: NO_SHARED_SECRET,
        };
        let add_tlc_result = call!(node_b.network_actor, |rpc_reply| {
            NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                ChannelCommandWithId {
                    channel_id: new_channel_id,
                    command: ChannelCommand::AddTlc(add_tlc_command, rpc_reply),
                },
            ))
        })
        .expect("node_b alive");
        if i == 2 {
            // we are sending AddTlc constantly, so we should get a WaitingTlcAck
            assert!(add_tlc_result.is_err());
            let code = add_tlc_result.unwrap_err();
            assert_eq!(code.error_code, TlcErrorCode::TemporaryChannelFailure);
        } else {
            eprintln!("add_tlc_result: {:?}", add_tlc_result);
            assert!(add_tlc_result.is_ok());
        }
    }
}

#[tokio::test]
async fn do_test_add_tlc_with_number_limit() {
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 100000000000;

    let [mut node_a, mut node_b] = NetworkNode::new_n_interconnected_nodes().await;

    let node_a_max_tlc_number = 2;
    let (new_channel_id, _funding_tx) = establish_channel_between_nodes(
        &mut node_a,
        &mut node_b,
        true,
        node_a_funding_amount,
        node_b_funding_amount,
        Some(node_a_max_tlc_number),
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
    )
    .await;

    let tlc_amount = 1000000000;

    // A -> B will have tlc number limit 2
    for i in 1..=node_a_max_tlc_number + 1 {
        let add_tlc_command = AddTlcCommand {
            amount: tlc_amount,
            hash_algorithm: HashAlgorithm::CkbHash,
            payment_hash: gen_rand_sha256_hash(),
            expiry: now_timestamp_as_millis_u64() + 100000000,
            onion_packet: None,
            shared_secret: NO_SHARED_SECRET,
            previous_tlc: None,
        };
        let add_tlc_result = call!(node_a.network_actor, |rpc_reply| {
            NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                ChannelCommandWithId {
                    channel_id: new_channel_id,
                    command: ChannelCommand::AddTlc(add_tlc_command, rpc_reply),
                },
            ))
        })
        .expect("source node alive");
        tokio::time::sleep(tokio::time::Duration::from_millis(300)).await;
        if i == node_a_max_tlc_number + 1 {
            assert!(add_tlc_result.is_err());
            let code = add_tlc_result.unwrap_err();
            assert_eq!(code.error_code, TlcErrorCode::TemporaryChannelFailure);
        } else {
            dbg!(&add_tlc_result);
            assert!(add_tlc_result.is_ok());
        }
    }

    // B -> A can still add tlc
    for _ in 1..=node_a_max_tlc_number + 1 {
        let add_tlc_command = AddTlcCommand {
            amount: tlc_amount,
            hash_algorithm: HashAlgorithm::CkbHash,
            payment_hash: gen_rand_sha256_hash(),
            expiry: now_timestamp_as_millis_u64() + 100000000,
            onion_packet: None,
            shared_secret: NO_SHARED_SECRET,
            previous_tlc: None,
        };
        let add_tlc_result = call!(node_b.network_actor, |rpc_reply| {
            NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                ChannelCommandWithId {
                    channel_id: new_channel_id,
                    command: ChannelCommand::AddTlc(add_tlc_command, rpc_reply),
                },
            ))
        })
        .expect("source node alive");
        tokio::time::sleep(tokio::time::Duration::from_millis(300)).await;
        dbg!(&add_tlc_result);
        assert!(add_tlc_result.is_ok());
    }
}

#[tokio::test]
async fn do_test_add_tlc_number_limit_reverse() {
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 100000000000;

    let [mut node_a, mut node_b] = NetworkNode::new_n_interconnected_nodes().await;

    let node_b_max_tlc_number = 2;
    let (new_channel_id, _funding_tx) = establish_channel_between_nodes(
        &mut node_a,
        &mut node_b,
        true,
        node_a_funding_amount,
        node_b_funding_amount,
        None,
        None,
        None,
        None,
        None,
        Some(node_b_max_tlc_number),
        None,
        None,
        None,
        None,
    )
    .await;

    let tlc_amount = 1000000000;
    // B -> A will have tlc number limit 2
    for i in 1..=node_b_max_tlc_number + 1 {
        let add_tlc_command = AddTlcCommand {
            amount: tlc_amount,
            hash_algorithm: HashAlgorithm::CkbHash,
            payment_hash: gen_rand_sha256_hash(),
            expiry: now_timestamp_as_millis_u64() + 100000000,
            onion_packet: None,
            shared_secret: NO_SHARED_SECRET,
            previous_tlc: None,
        };
        let add_tlc_result = call!(node_b.network_actor, |rpc_reply| {
            NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                ChannelCommandWithId {
                    channel_id: new_channel_id,
                    command: ChannelCommand::AddTlc(add_tlc_command, rpc_reply),
                },
            ))
        })
        .expect("source node alive");
        tokio::time::sleep(tokio::time::Duration::from_millis(300)).await;
        if i == node_b_max_tlc_number + 1 {
            assert!(add_tlc_result.is_err());
            let code = add_tlc_result.unwrap_err();
            assert_eq!(code.error_code, TlcErrorCode::TemporaryChannelFailure);
        } else {
            dbg!(&add_tlc_result);
            assert!(add_tlc_result.is_ok());
        }
    }

    // A -> B can still add tlc
    for _ in 1..=node_b_max_tlc_number + 1 {
        let add_tlc_command = AddTlcCommand {
            amount: tlc_amount,
            hash_algorithm: HashAlgorithm::CkbHash,
            payment_hash: gen_rand_sha256_hash(),
            expiry: now_timestamp_as_millis_u64() + 100000000,
            onion_packet: None,
            shared_secret: NO_SHARED_SECRET,
            previous_tlc: None,
        };
        let add_tlc_result = call!(node_a.network_actor, |rpc_reply| {
            NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                ChannelCommandWithId {
                    channel_id: new_channel_id,
                    command: ChannelCommand::AddTlc(add_tlc_command, rpc_reply),
                },
            ))
        })
        .expect("source node alive");
        tokio::time::sleep(tokio::time::Duration::from_millis(300)).await;
        dbg!(&add_tlc_result);
        assert!(add_tlc_result.is_ok());
    }
}

#[tokio::test]
async fn do_test_add_tlc_value_limit() {
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 100000000000;

    let [mut node_a, mut node_b] = NetworkNode::new_n_interconnected_nodes().await;

    let max_tlc_number = 3;
    let (new_channel_id, _funding_tx) = establish_channel_between_nodes(
        &mut node_a,
        &mut node_b,
        true,
        node_a_funding_amount,
        node_b_funding_amount,
        None,
        Some(3000000000),
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
    )
    .await;

    let tlc_amount = 1000000000;

    // A -> B have tlc value limit 3_000_000_000
    for i in 1..=max_tlc_number + 1 {
        let add_tlc_command = AddTlcCommand {
            amount: tlc_amount,
            hash_algorithm: HashAlgorithm::CkbHash,
            payment_hash: gen_rand_sha256_hash(),
            expiry: now_timestamp_as_millis_u64() + 100000000,
            onion_packet: None,
            shared_secret: NO_SHARED_SECRET,
            previous_tlc: None,
        };
        let add_tlc_result = call!(node_a.network_actor, |rpc_reply| {
            NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                ChannelCommandWithId {
                    channel_id: new_channel_id,
                    command: ChannelCommand::AddTlc(add_tlc_command, rpc_reply),
                },
            ))
        })
        .expect("node_b alive");
        // sleep for a while to make sure the AddTlc processed by both party
        tokio::time::sleep(tokio::time::Duration::from_millis(300)).await;
        if i == max_tlc_number + 1 {
            assert!(add_tlc_result.is_err());
            let code = add_tlc_result.unwrap_err();

            assert_eq!(code.error_code, TlcErrorCode::TemporaryChannelFailure);
        } else {
            assert!(add_tlc_result.is_ok());
        }
    }

    // B -> A can still add tlc
    for _ in 1..=max_tlc_number + 1 {
        let add_tlc_command = AddTlcCommand {
            amount: tlc_amount,
            hash_algorithm: HashAlgorithm::CkbHash,
            payment_hash: gen_rand_sha256_hash(),
            expiry: now_timestamp_as_millis_u64() + 100000000,
            onion_packet: None,
            shared_secret: NO_SHARED_SECRET,
            previous_tlc: None,
        };
        let add_tlc_result = call!(node_b.network_actor, |rpc_reply| {
            NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                ChannelCommandWithId {
                    channel_id: new_channel_id,
                    command: ChannelCommand::AddTlc(add_tlc_command, rpc_reply),
                },
            ))
        })
        .expect("node_b alive");
        // sleep for a while to make sure the AddTlc processed by both party
        tokio::time::sleep(tokio::time::Duration::from_millis(300)).await;
        assert!(add_tlc_result.is_ok());
    }
}

#[tokio::test]
async fn do_test_add_tlc_min_tlc_value_limit() {
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let [mut node_a, mut node_b] = NetworkNode::new_n_interconnected_nodes().await;

    let (new_channel_id, _funding_tx) = establish_channel_between_nodes(
        &mut node_a,
        &mut node_b,
        true,
        node_a_funding_amount,
        node_b_funding_amount,
        None,
        None,
        None,
        Some(100),
        None,
        None,
        None,
        None,
        None,
        None,
    )
    .await;
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    // A -> B will be no limit
    let tlc_amount = 200;
    let add_tlc_command = AddTlcCommand {
        amount: tlc_amount,
        hash_algorithm: HashAlgorithm::CkbHash,
        payment_hash: gen_rand_sha256_hash(),
        expiry: now_timestamp_as_millis_u64() + 100000000,
        onion_packet: None,
        previous_tlc: None,
        shared_secret: NO_SHARED_SECRET,
    };
    let add_tlc_result = call!(node_a.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::AddTlc(add_tlc_command, rpc_reply),
            },
        ))
    })
    .expect("node_b alive");
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
    assert!(add_tlc_result.is_ok());

    // B -> A can still able to send amount less than 100
    // since it's not under the tlc relay context
    let tlc_amount = 99;
    let add_tlc_command = AddTlcCommand {
        amount: tlc_amount,
        hash_algorithm: HashAlgorithm::CkbHash,
        payment_hash: gen_rand_sha256_hash(),
        expiry: now_timestamp_as_millis_u64() + 100000000,
        onion_packet: None,
        previous_tlc: None,
        shared_secret: NO_SHARED_SECRET,
    };
    let add_tlc_result = call!(node_b.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::AddTlc(add_tlc_command, rpc_reply),
            },
        ))
    })
    .expect("node_b alive");
    assert!(add_tlc_result.is_ok());
    // sleep for a while to make sure the AddTlc processed by both party
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    // B -> A can send at least 100
    let tlc_amount = 100;
    let add_tlc_command = AddTlcCommand {
        amount: tlc_amount,
        hash_algorithm: HashAlgorithm::CkbHash,
        payment_hash: gen_rand_sha256_hash(),
        expiry: now_timestamp_as_millis_u64() + 100000000,
        onion_packet: None,
        previous_tlc: None,
        shared_secret: NO_SHARED_SECRET,
    };
    let add_tlc_result = call!(node_b.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::AddTlc(add_tlc_command, rpc_reply),
            },
        ))
    })
    .expect("node_b alive");
    eprintln!("add_local_tlc_result: {:?}", add_tlc_result);
    assert!(add_tlc_result.is_ok());
}

#[tokio::test]
async fn test_channel_update_tlc_expiry() {
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let [mut node_a, mut node_b] = NetworkNode::new_n_interconnected_nodes().await;

    let (new_channel_id, _funding_tx) = establish_channel_between_nodes(
        &mut node_a,
        &mut node_b,
        true,
        node_a_funding_amount,
        node_b_funding_amount,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
    )
    .await;

    // update channel with new tlc_expiry_delta which is too small
    let update_result = call!(node_b.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::Update(
                    UpdateCommand {
                        enabled: Some(true),
                        tlc_expiry_delta: Some(1000),
                        tlc_minimum_value: None,
                        tlc_fee_proportional_millionths: None,
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .unwrap();
    assert!(update_result.is_err());
    assert!(update_result
        .unwrap_err()
        .to_string()
        .contains("TLC expiry delta is too small"));

    // update channel with new tlc_expiry_delta which is ok
    let update_result = call!(node_b.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::Update(
                    UpdateCommand {
                        enabled: Some(true),
                        tlc_expiry_delta: Some(900000),
                        tlc_minimum_value: None,
                        tlc_fee_proportional_millionths: None,
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .unwrap();
    assert!(update_result.is_ok());
}

#[tokio::test]
async fn test_forward_payment_channel_disabled() {
    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        3,
        true,
    )
    .await;
    let [node_a, node_b, node_c] = nodes.try_into().expect("3 nodes");
    let [_channel_a_b, channel_b_c] = channels.try_into().expect("2 channels");

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let res = node_a
        .send_payment_keysend(&node_c, 10_000_000, false)
        .await;
    assert!(res.is_ok(), "Send payment failed: {:?}", res);
    let res = res.unwrap();
    let payment_hash = res.payment_hash;
    node_a.wait_until_success(payment_hash).await;

    let res = node_b
        .send_payment_keysend(&node_c, 10_000_000, false)
        .await;
    assert!(res.is_ok(), "Send payment failed: {:?}", res);
    let res = res.unwrap();
    let payment_hash = res.payment_hash;
    node_b.wait_until_success(payment_hash).await;

    let res = node_c
        .send_payment_keysend(&node_a, 10_000_000, false)
        .await;
    assert!(res.is_ok(), "Send payment failed: {:?}", res);
    let res = res.unwrap();
    let payment_hash = res.payment_hash;
    node_c.wait_until_success(payment_hash).await;

    let res = node_b
        .send_payment_keysend(&node_a, 10_000_000, false)
        .await;
    assert!(res.is_ok(), "Send payment failed: {:?}", res);
    let res = res.unwrap();
    let payment_hash = res.payment_hash;
    node_b.wait_until_success(payment_hash).await;

    // update channel to disable it from node_b
    let update_result = call!(node_b.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: channel_b_c,
                command: ChannelCommand::Update(
                    UpdateCommand {
                        enabled: Some(false),
                        tlc_expiry_delta: None,
                        tlc_minimum_value: None,
                        tlc_fee_proportional_millionths: None,
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .unwrap();
    assert!(update_result.is_ok());
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let res = node_a
        .send_payment_keysend(&node_c, 10_000_000, false)
        .await;
    assert!(res.is_err(), "Send payment should fail: {:?}", res);

    let res = node_b
        .send_payment_keysend(&node_c, 10_000_000, false)
        .await;
    assert!(res.is_err(), "Send payment should fail: {:?}", res);

    let res = node_c
        .send_payment_keysend(&node_b, 10_000_000, false)
        .await;
    assert!(res.is_ok(), "Send payment failed: {:?}", res);
    let res = res.unwrap();
    let payment_hash = res.payment_hash;
    node_c.wait_until_success(payment_hash).await;

    let res = node_c
        .send_payment_keysend(&node_a, 80_000_000, false)
        .await;
    assert!(res.is_ok(), "Send payment failed: {:?}", res);
    let res = res.unwrap();
    let payment_hash = res.payment_hash;
    node_c.wait_until_success(payment_hash).await;
}

#[tokio::test]
async fn test_forward_payment_tlc_minimum_value() {
    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        3,
        true,
    )
    .await;
    let [node_a, node_b, node_c] = nodes.try_into().expect("3 nodes");
    let [channel_a_b, channel_b_c] = channels.try_into().expect("2 channels");

    let node_c_pubkey = node_c.pubkey;
    let node_b_pubkey = node_b.pubkey;
    let tlc_amount = 99;

    // update B's ChannelUpdate in channel_b_c with tlc_minimum_value set to our tlc_amount
    // this is used to override the default tlc_minimum_value value.
    let update_result = call!(node_b.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: channel_b_c,
                command: ChannelCommand::Update(
                    UpdateCommand {
                        enabled: Some(true),
                        tlc_expiry_delta: None,
                        tlc_minimum_value: Some(tlc_amount),
                        tlc_fee_proportional_millionths: None,
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .unwrap();
    assert!(update_result.is_ok());
    // sleep for a while to make sure the Update processed by both party
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    // A -> C now will be with no limit
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_c_pubkey),
                amount: Some(tlc_amount),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    // this is the payment_hash generated by keysend
    assert_eq!(res.status, PaymentSessionStatus::Created);
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    // update B's ChannelUpdate in channel_b_c with new tlc_minimum_value
    let update_result = call!(node_b.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: channel_b_c,
                command: ChannelCommand::Update(
                    UpdateCommand {
                        enabled: Some(true),
                        tlc_expiry_delta: None,
                        tlc_minimum_value: Some(100),
                        tlc_fee_proportional_millionths: None,
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .unwrap();
    assert!(update_result.is_ok());
    // sleep for a while to make sure the Update processed by both party
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    // AddTlc from A to B is OK because we didn't update the channel
    let tlc_amount = 99;
    let add_tlc_command = AddTlcCommand {
        amount: tlc_amount,
        hash_algorithm: HashAlgorithm::CkbHash,
        payment_hash: gen_rand_sha256_hash(),
        expiry: now_timestamp_as_millis_u64() + 100000000,
        onion_packet: None,
        previous_tlc: None,
        shared_secret: NO_SHARED_SECRET,
    };
    let add_tlc_result = call!(node_a.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: channel_a_b,
                command: ChannelCommand::AddTlc(add_tlc_command.clone(), rpc_reply),
            },
        ))
    })
    .expect("node_b alive");
    assert!(add_tlc_result.is_ok());
    // sleep for a while to make sure the AddTlc processed by both party
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    // AddTlc from B to C is not OK because the forwarding value is too small
    let add_tlc_result = call!(node_b.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: channel_b_c,
                command: ChannelCommand::AddTlc(add_tlc_command.clone(), rpc_reply),
            },
        ))
    })
    .expect("node_b alive");
    assert!(add_tlc_result.is_err());
    // sleep for a while to make sure the AddTlc processed by both party
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    // sending payment from A to B is OK because this has nothing to do with the channel_a_b.
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(tlc_amount),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_b alive");
    assert!(res.is_ok());
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    // sending payment from B to C is not OK because the forwarding value is too small
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_c_pubkey),
                amount: Some(tlc_amount),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_b.network_actor, message).expect("node_b alive");
    assert!(res.is_err());
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    // sending payment from A to C should fail because the forwarding value is too small
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_c_pubkey),
                amount: Some(tlc_amount),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_err());
    assert!(res
        .unwrap_err()
        .to_string()
        .contains("Failed to build route, PathFind error: no path found"));
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
}

#[tokio::test]
async fn test_send_payment_with_outdated_fee_rate() {
    init_tracing();
    let (nodes, _) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        3,
        true,
    )
    .await;
    let [node_a, node_b, node_c] = nodes.try_into().expect("3 nodes");

    let node_b_pubkey = node_b.pubkey;
    let node_c_pubkey = node_c.pubkey;
    let hash_set: HashSet<_> = [node_b_pubkey, node_c_pubkey].into_iter().collect();

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    node_a
        .with_network_graph_mut(|graph| {
            for channel in graph.channels.values_mut() {
                tracing::debug!("channel: {:?}", channel);
                if hash_set.contains(&channel.node1()) && hash_set.contains(&channel.node2()) {
                    let channel_update = if channel.node1() == node_b_pubkey {
                        channel.update_of_node1.as_mut().unwrap()
                    } else {
                        channel.update_of_node2.as_mut().unwrap()
                    };
                    tracing::debug!("channel_update: {:?}", channel_update);
                    channel_update.fee_rate = 0;
                }
            }
        })
        .await;

    // sending payment from A to C should fail because the forwarding value is too small
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_c_pubkey),
                amount: Some(10000000000),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(
        res.is_ok(),
        "Send payment should be ok because we can find path: {:?}",
        res
    );
    let res = res.unwrap();
    let payment_hash = res.payment_hash;
    // The payment should fail because our fee rate is too low.
    node_a.wait_until_failed(payment_hash).await;
}

#[tokio::test]
async fn test_remove_tlc_with_wrong_hash_algorithm() {
    let supported_algorithms = HashAlgorithm::supported_algorithms();
    for algorithm1 in &supported_algorithms {
        for algorithm2 in &supported_algorithms {
            if algorithm2 == algorithm1 {
                continue;
            }
            do_test_remove_tlc_with_wrong_hash_algorithm(*algorithm1, *algorithm2).await;
        }
    }
}

async fn do_test_channel_with_simple_update_operation(algorithm: HashAlgorithm) {
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (mut node_a, mut node_b, new_channel_id, _) =
        NetworkNode::new_2_nodes_with_established_channel(
            node_a_funding_amount,
            node_b_funding_amount,
            false,
        )
        .await;

    let preimage = [1; 32];
    let digest = algorithm.hash(preimage);
    let tlc_amount = 1000000000;

    let add_tlc_result = call!(node_a.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::AddTlc(
                    AddTlcCommand {
                        amount: tlc_amount,
                        hash_algorithm: algorithm,
                        payment_hash: digest.into(),
                        expiry: now_timestamp_as_millis_u64() + DEFAULT_EXPIRY_DELTA,
                        onion_packet: None,
                        shared_secret: NO_SHARED_SECRET,
                        previous_tlc: None,
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .expect("node_b alive")
    .expect("successfully added tlc");

    dbg!(&add_tlc_result);

    dbg!("Sleeping for some time to wait for the AddTlc processed by both party");
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    call!(node_b.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::RemoveTlc(
                    RemoveTlcCommand {
                        id: add_tlc_result.tlc_id,
                        reason: RemoveTlcReason::RemoveTlcFulfill(RemoveTlcFulfill {
                            payment_preimage: preimage.into(),
                        }),
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .expect("node_b alive")
    .expect("successfully removed tlc");

    let fee_rate = FeeRate::from_u64(DEFAULT_COMMITMENT_FEE_RATE);
    call!(node_b.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::Shutdown(
                    ShutdownCommand {
                        close_script: Script::default().as_builder().build(),
                        fee_rate,
                        force: false,
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .expect("node_b alive")
    .expect("successfully shutdown channel");

    let node_a_shutdown_tx_hash = node_a
        .expect_to_process_event(|event| match event {
            NetworkServiceEvent::ChannelClosed(peer_id, channel_id, tx_hash) => {
                println!(
                    "Shutdown tx ({:?}) from {:?} for channel {:?} received",
                    &tx_hash, &peer_id, channel_id
                );
                assert_eq!(peer_id, &node_b.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                Some(tx_hash.clone())
            }
            _ => None,
        })
        .await;

    dbg!(&node_a_shutdown_tx_hash);

    let node_b_shutdown_tx_hash = node_b
        .expect_to_process_event(|event| match event {
            NetworkServiceEvent::ChannelClosed(peer_id, channel_id, tx_hash) => {
                println!(
                    "Shutdown tx ({:?}) from {:?} for channel {:?} received",
                    &tx_hash, &peer_id, channel_id
                );
                assert_eq!(peer_id, &node_a.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                Some(tx_hash.clone())
            }
            _ => None,
        })
        .await;

    dbg!(&node_b_shutdown_tx_hash);

    assert_eq!(node_a_shutdown_tx_hash, node_b_shutdown_tx_hash);

    assert_eq!(
        node_a.trace_tx_hash(node_a_shutdown_tx_hash.clone()).await,
        Status::Committed
    );
    assert_eq!(
        node_b.trace_tx_hash(node_b_shutdown_tx_hash.clone()).await,
        Status::Committed
    );

    // TODO: maybe also check shutdown tx outputs and output balances here.
}

#[tokio::test]
async fn test_open_channel_with_invalid_ckb_amount_range() {
    init_tracing();

    let [node_a, node_b] = NetworkNode::new_n_interconnected_nodes().await;
    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::OpenChannel(
            OpenChannelCommand {
                peer_id: node_b.peer_id.clone(),
                public: true,
                shutdown_script: None,
                funding_amount: 0xfffffffffffffffffffffffffffffff,
                funding_udt_type_script: None,
                commitment_fee_rate: None,
                commitment_delay_epoch: None,
                funding_fee_rate: None,
                tlc_expiry_delta: None,
                tlc_min_value: None,
                tlc_fee_proportional_millionths: None,
                max_tlc_number_in_flight: None,
                max_tlc_value_in_flight: None,
            },
            rpc_reply,
        ))
    };
    let open_channel_result = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(open_channel_result
        .err()
        .unwrap()
        .contains("The funding amount (21267647932558653966460912964485513215) should be less than 18446744073709551615"));
}

#[tokio::test]
async fn test_revoke_old_commitment_transaction() {
    init_tracing();

    let [mut node_a, mut node_b] = NetworkNode::new_n_interconnected_nodes().await;

    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::OpenChannel(
            OpenChannelCommand {
                peer_id: node_b.peer_id.clone(),
                public: false,
                shutdown_script: None,
                funding_amount: 100000000000,
                funding_udt_type_script: None,
                commitment_fee_rate: None,
                commitment_delay_epoch: None,
                funding_fee_rate: None,
                tlc_expiry_delta: None,
                tlc_min_value: None,
                tlc_fee_proportional_millionths: None,
                max_tlc_number_in_flight: None,
                max_tlc_value_in_flight: None,
            },
            rpc_reply,
        ))
    };
    let open_channel_result = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .expect("open channel success");

    node_b
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelPendingToBeAccepted(peer_id, channel_id) => {
                println!("A channel ({:?}) to {:?} create", &channel_id, peer_id);
                assert_eq!(peer_id, &node_a.peer_id);
                true
            }
            _ => false,
        })
        .await;
    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::AcceptChannel(
            AcceptChannelCommand {
                temp_channel_id: open_channel_result.channel_id,
                funding_amount: 6200000000,
                shutdown_script: None,
                max_tlc_number_in_flight: None,
                max_tlc_value_in_flight: None,
                min_tlc_value: None,
                tlc_fee_proportional_millionths: None,
                tlc_expiry_delta: None,
            },
            rpc_reply,
        ))
    };
    let accept_channel_result = call!(node_b.network_actor, message)
        .expect("node_b alive")
        .expect("accept channel success");
    let new_channel_id = accept_channel_result.new_channel_id;

    let commitment_tx = node_b
        .expect_to_process_event(|event| match event {
            NetworkServiceEvent::RemoteCommitmentSigned(peer_id, channel_id, tx, _) => {
                println!(
                    "Commitment tx {:?} from {:?} for channel {:?} received",
                    &tx, peer_id, channel_id
                );
                assert_eq!(peer_id, &node_a.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                Some(tx.clone())
            }
            _ => None,
        })
        .await;

    node_a
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelReady(peer_id, channel_id, _funding_tx_hash) => {
                println!(
                    "A channel ({:?}) to {:?} is now ready",
                    &channel_id, &peer_id
                );
                assert_eq!(peer_id, &node_b.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                true
            }
            _ => false,
        })
        .await;

    node_b
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelReady(peer_id, channel_id, _funding_tx_hash) => {
                println!(
                    "A channel ({:?}) to {:?} is now ready",
                    &channel_id, &peer_id
                );
                assert_eq!(peer_id, &node_a.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                true
            }
            _ => false,
        })
        .await;

    node_a
        .network_actor
        .send_message(NetworkActorMessage::Command(
            NetworkActorCommand::ControlFiberChannel(ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::CommitmentSigned(),
            }),
        ))
        .expect("node_a alive");

    let revocation_data = node_a
        .expect_to_process_event(|event| match event {
            NetworkServiceEvent::RevokeAndAckReceived(
                peer_id,
                channel_id,
                revocation_data,
                _settlement_data,
            ) => {
                assert_eq!(peer_id, &node_b.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                assert_eq!(revocation_data.commitment_number, 0u64);
                Some(revocation_data.clone())
            }
            _ => None,
        })
        .await;

    assert_eq!(
        node_a.submit_tx(commitment_tx.clone()).await,
        Status::Committed
    );

    println!("commitment_tx: {:?}", commitment_tx);

    let tx = Transaction::default()
        .as_advanced_builder()
        .cell_deps(get_cell_deps(vec![Contract::CommitmentLock], &None))
        .input(
            CellInput::new_builder()
                .previous_output(commitment_tx.output_pts().first().unwrap().clone())
                .build(),
        )
        .output(revocation_data.output)
        .output_data(revocation_data.output_data)
        .build();

    let empty_witness_args = [16, 0, 0, 0, 16, 0, 0, 0, 16, 0, 0, 0, 16, 0, 0, 0];
    let witness = [
        empty_witness_args.to_vec(),
        vec![0xFF],
        revocation_data.commitment_number.to_be_bytes().to_vec(),
        revocation_data.x_only_aggregated_pubkey.to_vec(),
        revocation_data.aggregated_signature.serialize().to_vec(),
    ]
    .concat();

    let revocation_tx = tx.as_advanced_builder().witness(witness.pack()).build();

    assert_eq!(
        node_a.submit_tx(revocation_tx.clone()).await,
        Status::Committed
    );
}

#[tokio::test]
async fn test_channel_with_simple_update_operation() {
    for algorithm in HashAlgorithm::supported_algorithms() {
        do_test_channel_with_simple_update_operation(algorithm).await
    }
}

#[tokio::test]
async fn test_create_channel() {
    init_tracing();
    let [mut node_a, mut node_b] = NetworkNode::new_n_interconnected_nodes().await;

    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::OpenChannel(
            OpenChannelCommand {
                peer_id: node_b.peer_id.clone(),
                public: false,
                shutdown_script: None,
                funding_amount: 100000000000,
                funding_udt_type_script: None,
                commitment_fee_rate: None,
                commitment_delay_epoch: None,
                funding_fee_rate: None,
                tlc_expiry_delta: None,
                tlc_min_value: None,
                tlc_fee_proportional_millionths: None,
                max_tlc_number_in_flight: None,
                max_tlc_value_in_flight: None,
            },
            rpc_reply,
        ))
    };
    let open_channel_result = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .expect("open channel success");

    node_b
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelPendingToBeAccepted(peer_id, channel_id) => {
                println!("A channel ({:?}) to {:?} create", &channel_id, peer_id);
                assert_eq!(peer_id, &node_a.peer_id);
                true
            }
            _ => false,
        })
        .await;
    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::AcceptChannel(
            AcceptChannelCommand {
                temp_channel_id: open_channel_result.channel_id,
                funding_amount: 6200000000,
                shutdown_script: None,
                max_tlc_number_in_flight: None,
                max_tlc_value_in_flight: None,
                min_tlc_value: None,
                tlc_fee_proportional_millionths: None,
                tlc_expiry_delta: None,
            },
            rpc_reply,
        ))
    };
    let accept_channel_result = call!(node_b.network_actor, message)
        .expect("node_b alive")
        .expect("accept channel success");
    let new_channel_id = accept_channel_result.new_channel_id;

    let node_a_commitment_tx = node_a
        .expect_to_process_event(|event| match event {
            NetworkServiceEvent::RemoteCommitmentSigned(peer_id, channel_id, tx, _) => {
                println!(
                    "Commitment tx {:?} from {:?} for channel {:?} received",
                    &tx, peer_id, channel_id
                );
                assert_eq!(peer_id, &node_b.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                Some(tx.clone())
            }
            _ => None,
        })
        .await;

    let node_b_commitment_tx = node_b
        .expect_to_process_event(|event| match event {
            NetworkServiceEvent::RemoteCommitmentSigned(peer_id, channel_id, tx, _) => {
                println!(
                    "Commitment tx {:?} from {:?} for channel {:?} received",
                    &tx, peer_id, channel_id
                );
                assert_eq!(peer_id, &node_a.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                Some(tx.clone())
            }
            _ => None,
        })
        .await;

    node_a
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelReady(peer_id, channel_id, _funding_tx_hash) => {
                println!(
                    "A channel ({:?}) to {:?} is now ready",
                    &channel_id, &peer_id
                );
                assert_eq!(peer_id, &node_b.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                true
            }
            _ => false,
        })
        .await;

    node_b
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelReady(peer_id, channel_id, _funding_tx_hash) => {
                println!(
                    "A channel ({:?}) to {:?} is now ready",
                    &channel_id, &peer_id
                );
                assert_eq!(peer_id, &node_a.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                true
            }
            _ => false,
        })
        .await;

    // We can submit the commitment txs to the chain now.
    assert_eq!(
        node_a.submit_tx(node_a_commitment_tx.clone()).await,
        Status::Committed
    );
    assert_eq!(
        node_b.submit_tx(node_b_commitment_tx.clone()).await,
        Status::Committed
    );
}

#[tokio::test]
async fn test_reestablish_channel() {
    let [mut node_a, mut node_b] = NetworkNode::new_n_interconnected_nodes().await;

    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::OpenChannel(
            OpenChannelCommand {
                peer_id: node_b.peer_id.clone(),
                public: false,
                shutdown_script: None,
                funding_amount: 100000000000,
                funding_udt_type_script: None,
                commitment_fee_rate: None,
                commitment_delay_epoch: None,
                funding_fee_rate: None,
                tlc_expiry_delta: None,
                tlc_min_value: None,
                tlc_fee_proportional_millionths: None,
                max_tlc_number_in_flight: None,
                max_tlc_value_in_flight: None,
            },
            rpc_reply,
        ))
    };
    let open_channel_result = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .expect("open channel success");

    node_b
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelPendingToBeAccepted(peer_id, channel_id) => {
                println!("A channel ({:?}) to {:?} create", &channel_id, peer_id);
                assert_eq!(peer_id, &node_a.peer_id);
                true
            }
            _ => false,
        })
        .await;

    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::AcceptChannel(
            AcceptChannelCommand {
                temp_channel_id: open_channel_result.channel_id,
                funding_amount: 6200000000,
                shutdown_script: None,
                max_tlc_number_in_flight: None,
                max_tlc_value_in_flight: None,
                min_tlc_value: None,
                tlc_fee_proportional_millionths: None,
                tlc_expiry_delta: None,
            },
            rpc_reply,
        ))
    };
    let _accept_channel_result = call!(node_b.network_actor, message)
        .expect("node_b alive")
        .expect("accept channel success");

    node_a
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelCreated(peer_id, channel_id) => {
                println!("A channel ({:?}) to {:?} create", channel_id, peer_id);
                assert_eq!(peer_id, &node_b.peer_id);
                true
            }
            _ => false,
        })
        .await;

    node_b
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelCreated(peer_id, channel_id) => {
                println!("A channel ({:?}) to {:?} create", channel_id, peer_id);
                assert_eq!(peer_id, &node_a.peer_id);
                true
            }
            _ => false,
        })
        .await;

    node_a
        .network_actor
        .send_message(NetworkActorMessage::new_command(
            NetworkActorCommand::DisconnectPeer(node_b.peer_id.clone()),
        ))
        .expect("node_a alive");

    node_a
        .expect_event(|event| match event {
            NetworkServiceEvent::PeerDisConnected(peer_id, _) => {
                assert_eq!(peer_id, &node_b.peer_id);
                true
            }
            _ => false,
        })
        .await;

    node_b
        .expect_event(|event| match event {
            NetworkServiceEvent::PeerDisConnected(peer_id, _) => {
                assert_eq!(peer_id, &node_a.peer_id);
                true
            }
            _ => false,
        })
        .await;

    // Don't use `connect_to` here as that may consume the `ChannelCreated` event.
    // This is due to tentacle connection is async. We may actually send
    // the `ChannelCreated` event before the `PeerConnected` event.
    node_a.connect_to_nonblocking(&node_b).await;

    node_a
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelCreated(peer_id, channel_id) => {
                println!("A channel ({:?}) to {:?} create", channel_id, peer_id);
                assert_eq!(peer_id, &node_b.peer_id);
                true
            }
            _ => false,
        })
        .await;

    node_b
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelCreated(peer_id, channel_id) => {
                println!("A channel ({:?}) to {:?} create", channel_id, peer_id);
                assert_eq!(peer_id, &node_a.peer_id);
                true
            }
            _ => false,
        })
        .await;
}

#[tokio::test]
async fn test_force_close_channel_when_remote_is_offline() {
    let (mut node_a, mut node_b, channel_id, _) =
        NetworkNode::new_2_nodes_with_established_channel(16200000000, 6200000000, true).await;

    node_b.stop().await;
    node_a
        .expect_event(|event| matches!(event, NetworkServiceEvent::PeerDisConnected(_, _)))
        .await;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id,
                command: ChannelCommand::Shutdown(
                    ShutdownCommand {
                        close_script: Script::default(),
                        fee_rate: FeeRate::from_u64(1000),
                        force: true,
                    },
                    rpc_reply,
                ),
            },
        ))
    };

    call!(node_a.network_actor, message)
        .expect("node_a alive")
        .expect("successfully shutdown channel");
}

#[tokio::test]
async fn test_commitment_tx_capacity() {
    let (amount_a, amount_b) = (16200000000, 6200000000);
    let (node_a, _node_b, channel_id, _) =
        NetworkNode::new_2_nodes_with_established_channel(amount_a, amount_b, true).await;

    let state = node_a.store.get_channel_actor_state(&channel_id).unwrap();
    let commitment_tx = state.latest_commitment_transaction.unwrap().into_view();
    let output_capacity: u64 = commitment_tx.output(0).unwrap().capacity().unpack();

    // default fee rate is 1000 shannons per kb, and there is a gap of 20 bytes between the mock commitment tx and the real one
    // ref to fn commitment_tx_size
    assert_eq!(
        amount_a + amount_b - (commitment_tx.data().serialized_size_in_block() + 20) as u128,
        output_capacity as u128
    );
}

#[tokio::test]
async fn test_connect_to_peers_with_mutual_channel_on_restart_1() {
    init_tracing();

    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (mut node_a, mut node_b, _new_channel_id, _) =
        NetworkNode::new_2_nodes_with_established_channel(
            node_a_funding_amount,
            node_b_funding_amount,
            true,
        )
        .await;

    // sleep for a while to make sure this test works both for release mode
    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;

    node_a.restart().await;

    node_a.expect_event(
        |event| matches!(event, NetworkServiceEvent::PeerConnected(id, _addr) if id == &node_b.peer_id),
    ).await;
    node_a
        .expect_event(|event| {
            matches!(
                event,
                NetworkServiceEvent::DebugEvent(DebugEvent::Common(
                    info
                )) if "Reestablished channel in ChannelReady" == info)
        })
        .await;
    node_b
        .expect_event(|event| {
            matches!(
                event,
                NetworkServiceEvent::DebugEvent(DebugEvent::Common(
                    info
                )) if "Reestablished channel in ChannelReady" == info)
        })
        .await;
}

#[tokio::test]
async fn test_connect_to_peers_with_mutual_channel_on_restart_2() {
    init_tracing();

    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (mut node_a, mut node_b, _new_channel_id, _) =
        NetworkNode::new_2_nodes_with_established_channel(
            node_a_funding_amount,
            node_b_funding_amount,
            true,
        )
        .await;

    // sleep for a while to make sure this test works both for release mode
    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;

    node_a.stop().await;

    node_b.expect_event(
        |event| matches!(event, NetworkServiceEvent::PeerDisConnected(id, _addr) if id == &node_a.peer_id),
    )
    .await;

    node_a.start().await;

    node_a.expect_event(
        |event| matches!(event, NetworkServiceEvent::PeerConnected(id, _addr) if id == &node_b.peer_id),
    )
    .await;
}

#[tokio::test]
async fn test_send_payment_with_node_restart_then_resend_add_tlc() {
    init_tracing();

    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (mut node_a, mut node_b, _new_channel_id, _) =
        NetworkNode::new_2_nodes_with_established_channel(
            node_a_funding_amount,
            node_b_funding_amount,
            true,
        )
        .await;

    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;

    let node_b_pubkey = node_b.pubkey;
    let tlc_amount = 99;
    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_b_pubkey),
                amount: Some(tlc_amount),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(node_a.network_actor, message).expect("node_a alive");
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;

    node_b.stop().await;

    let payment_status = node_a.get_payment_status(payment_hash).await;
    assert_eq!(payment_status, PaymentSessionStatus::Inflight);

    node_b.start().await;

    node_a.expect_event(
        |event| matches!(event, NetworkServiceEvent::PeerConnected(id, _addr) if id == &node_b.peer_id),
    )
    .await;

    node_a
        .expect_event(|event| {
            matches!(
            event,
            NetworkServiceEvent::DebugEvent(DebugEvent::Common(
                info
            )) if "resend add tlc" == info)
        })
        .await;

    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;
    let payment_status = node_a.get_payment_status(payment_hash).await;
    assert_eq!(payment_status, PaymentSessionStatus::Success);
}

#[tokio::test]
async fn test_node_reestablish_resend_remove_tlc() {
    init_tracing();

    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (mut node_a, mut node_b, new_channel_id, _) =
        NetworkNode::new_2_nodes_with_established_channel(
            node_a_funding_amount,
            node_b_funding_amount,
            true,
        )
        .await;

    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;

    let node_a_balance = node_a.get_local_balance_from_channel(new_channel_id);
    let node_b_balance = node_b.get_local_balance_from_channel(new_channel_id);

    let preimage = [2; 32];
    // create a new payment hash
    let payment_hash = HashAlgorithm::CkbHash.hash(preimage);

    let add_tlc_result = call!(node_a.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::AddTlc(
                    AddTlcCommand {
                        amount: 1000,
                        hash_algorithm: HashAlgorithm::CkbHash,
                        payment_hash: payment_hash.into(),
                        expiry: now_timestamp_as_millis_u64() + DEFAULT_EXPIRY_DELTA,
                        onion_packet: None,
                        shared_secret: NO_SHARED_SECRET,
                        previous_tlc: None,
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .expect("node_b alive")
    .expect("successfully added tlc");

    dbg!(&add_tlc_result);

    dbg!("Sleeping for some time to wait for the AddTlc processed by both party");
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    node_a.stop().await;

    let remove_tlc_result = call!(node_b.network_actor, |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::RemoveTlc(
                    RemoveTlcCommand {
                        id: add_tlc_result.tlc_id,
                        reason: RemoveTlcReason::RemoveTlcFulfill(RemoveTlcFulfill {
                            payment_preimage: preimage.into(),
                        }),
                    },
                    rpc_reply,
                ),
            },
        ))
    })
    .expect("node_b alive");

    dbg!(&remove_tlc_result);
    assert!(remove_tlc_result.is_ok());

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    // assert balance does not changed since remove tlc is not processed by node_a
    let new_node_a_balance = node_a.get_local_balance_from_channel(new_channel_id);
    let new_node_b_balance = node_b.get_local_balance_from_channel(new_channel_id);
    assert_eq!(node_a_balance, new_node_a_balance);
    assert_eq!(node_b_balance, new_node_b_balance);

    node_a.start().await;
    node_b
        .expect_event(|event| {
            matches!(
        event,
        NetworkServiceEvent::DebugEvent(DebugEvent::Common(
            info
        )) if "resend remove tlc" == info)
        })
        .await;

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    // assert balance changed since remove tlc is processed by node_a after node_b resending remove tlc
    let new_node_a_balance = node_a.get_local_balance_from_channel(new_channel_id);
    let new_node_b_balance = node_b.get_local_balance_from_channel(new_channel_id);
    assert_eq!(node_a_balance - 1000, new_node_a_balance);
    assert_eq!(node_b_balance + 1000, new_node_b_balance);
    eprintln!(
        "node_a_balance: {}, new_node_a_balance: {}",
        node_a_balance, new_node_a_balance
    );
    eprintln!(
        "node_b_balance: {}, new_node_b_balance: {}",
        node_b_balance, new_node_b_balance
    );
}

#[tokio::test]
async fn test_open_channel_with_large_size_shutdown_script_should_fail() {
    let [node_a, node_b] = NetworkNode::new_n_interconnected_nodes().await;

    // test open channel with large size shutdown script
    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::OpenChannel(
            OpenChannelCommand {
                peer_id: node_b.peer_id.clone(),
                public: false,
                shutdown_script: Some(Script::new_builder().args([0u8; 40].pack()).build()),
                funding_amount: (81 + 1) * 100000000 - 1,
                funding_udt_type_script: None,
                commitment_fee_rate: None,
                commitment_delay_epoch: None,
                funding_fee_rate: None,
                tlc_expiry_delta: None,
                tlc_min_value: None,
                tlc_fee_proportional_millionths: None,
                max_tlc_number_in_flight: None,
                max_tlc_value_in_flight: None,
            },
            rpc_reply,
        ))
    };

    let open_channel_result = call!(node_a.network_actor, message).expect("node_a alive");

    assert!(open_channel_result
        .err()
        .unwrap()
        .contains("The funding amount (8199999999) should be greater than or equal to 8200000000"));
}

#[tokio::test]
#[should_panic(expected = "Waiting for event timeout")]
async fn test_accept_channel_with_large_size_shutdown_script_should_fail() {
    let mut nodes = NetworkNode::new_n_interconnected_nodes_with_config(2, |i| {
        NetworkNodeConfigBuilder::new()
            .node_name(Some(format!("node-{}", i)))
            .base_dir_prefix(&format!("test-fnn-node-{}-", i))
            .fiber_config_updater(|config| {
                // enable auto accept channel with default value
                config.auto_accept_channel_ckb_funding_amount = Some(6200000000);
                config.open_channel_auto_accept_min_ckb_funding_amount = Some(16200000000);
            })
            .build()
    })
    .await;

    let mut node_a = nodes.pop().unwrap();
    let mut node_b = nodes.pop().unwrap();

    // test auto accept channel with large size shutdown script
    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::OpenChannel(
            OpenChannelCommand {
                peer_id: node_b.peer_id.clone(),
                public: false,
                shutdown_script: Some(Script::new_builder().args([0u8; 40].pack()).build()),
                funding_amount: (81 + 1 + 90) * 100000000,
                funding_udt_type_script: None,
                commitment_fee_rate: None,
                commitment_delay_epoch: None,
                funding_fee_rate: None,
                tlc_expiry_delta: None,
                tlc_min_value: None,
                tlc_fee_proportional_millionths: None,
                max_tlc_number_in_flight: None,
                max_tlc_value_in_flight: None,
            },
            rpc_reply,
        ))
    };

    let open_channel_result = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .expect("open channel success");

    node_b
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelPendingToBeAccepted(peer_id, channel_id) => {
                println!("A channel ({:?}) to {:?} create", channel_id, peer_id);
                assert_eq!(channel_id, &open_channel_result.channel_id);
                assert_eq!(peer_id, &node_a.peer_id);
                true
            }
            _ => false,
        })
        .await;

    // should fail
    node_a
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelReady(peer_id, channel_id, _funding_tx_hash) => {
                println!(
                    "A channel ({:?}) to {:?} is now ready",
                    &channel_id, &peer_id
                );
                assert_eq!(peer_id, &node_b.peer_id);
                true
            }
            _ => false,
        })
        .await;
}

#[tokio::test]
async fn test_shutdown_channel_with_large_size_shutdown_script_should_fail() {
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (_node_a, node_b, new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, false)
            .await;

    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::Shutdown(
                    ShutdownCommand {
                        close_script: Script::new_builder().args([0u8; 21].pack()).build(),
                        fee_rate: FeeRate::from_u64(DEFAULT_COMMITMENT_FEE_RATE),
                        force: false,
                    },
                    rpc_reply,
                ),
            },
        ))
    };

    let shutdown_channel_result = call!(node_b.network_actor, message).expect("node_b alive");
    assert!(shutdown_channel_result
        .err()
        .unwrap()
        .contains("Local balance is not enough to pay the fee"));
}

#[tokio::test]
async fn test_shutdown_channel_with_different_size_shutdown_script() {
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    // create a private channel for testing shutdown,
    // https://github.com/nervosnetwork/fiber/issues/431
    let (mut node_a, mut node_b, new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, false)
            .await;

    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: new_channel_id,
                command: ChannelCommand::Shutdown(
                    ShutdownCommand {
                        close_script: Script::new_builder().args([0u8; 19].pack()).build(),
                        fee_rate: FeeRate::from_u64(DEFAULT_COMMITMENT_FEE_RATE),
                        force: false,
                    },
                    rpc_reply,
                ),
            },
        ))
    };

    call!(node_b.network_actor, message)
        .expect("node_b alive")
        .expect("successfully shutdown channel");

    let node_a_shutdown_tx_hash = node_a
        .expect_to_process_event(|event| match event {
            NetworkServiceEvent::ChannelClosed(peer_id, channel_id, tx_hash) => {
                println!(
                    "Shutdown tx ({:?}) from {:?} for channel {:?} received",
                    &tx_hash, &peer_id, channel_id
                );
                assert_eq!(peer_id, &node_b.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                Some(tx_hash.clone())
            }
            _ => None,
        })
        .await;

    let node_b_shutdown_tx_hash = node_b
        .expect_to_process_event(|event| match event {
            NetworkServiceEvent::ChannelClosed(peer_id, channel_id, tx_hash) => {
                println!(
                    "Shutdown tx ({:?}) from {:?} for channel {:?} received",
                    &tx_hash, &peer_id, channel_id
                );
                assert_eq!(peer_id, &node_a.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                Some(tx_hash.clone())
            }
            _ => None,
        })
        .await;

    node_a
        .expect_event(|event| matches!(event, NetworkServiceEvent::DebugEvent(DebugEvent::Common(message)) if message == "ChannelClosed"))
        .await;

    node_b
        .expect_event(|event| matches!(event, NetworkServiceEvent::DebugEvent(DebugEvent::Common(message)) if message == "ChannelClosed"))
        .await;

    assert_eq!(node_a_shutdown_tx_hash, node_b_shutdown_tx_hash);

    assert_eq!(
        node_a.trace_tx_hash(node_a_shutdown_tx_hash.clone()).await,
        Status::Committed
    );
    assert_eq!(
        node_b.trace_tx_hash(node_b_shutdown_tx_hash.clone()).await,
        Status::Committed
    );
}

#[tokio::test]
async fn test_shutdown_channel_network_graph_will_not_sync_private_channel() {
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, node_b, _channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, false)
            .await;

    // sleep for 1 second
    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;

    let network_nodes = node_a.get_network_nodes().await;
    assert_eq!(network_nodes.len(), 2);

    let network_nodes = node_b.get_network_nodes().await;
    assert_eq!(network_nodes.len(), 2);

    let network_channels = node_a.get_network_channels().await;
    assert_eq!(network_channels.len(), 0);

    let network_channels = node_b.get_network_channels().await;
    assert_eq!(network_channels.len(), 0);
}

#[tokio::test]
async fn test_shutdown_channel_network_graph_with_sync_up() {
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let (node_a, node_b, channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, true)
            .await;

    // sleep for 1 second
    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;

    let network_nodes = node_a.get_network_nodes().await;
    assert_eq!(network_nodes.len(), 2);

    let network_nodes = node_b.get_network_nodes().await;
    assert_eq!(network_nodes.len(), 2);

    let network_channels = node_a.get_network_channels().await;
    assert_eq!(network_channels.len(), 1);

    let network_channels = node_b.get_network_channels().await;
    assert_eq!(network_channels.len(), 1);

    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id,
                command: ChannelCommand::Shutdown(
                    ShutdownCommand {
                        close_script: Script::new_builder().args([0u8; 19].pack()).build(),
                        fee_rate: FeeRate::from_u64(DEFAULT_COMMITMENT_FEE_RATE),
                        force: false,
                    },
                    rpc_reply,
                ),
            },
        ))
    };

    call!(node_b.network_actor, message)
        .expect("node_b alive")
        .expect("successfully shutdown channel");

    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;

    let network_nodes = node_a.get_network_nodes().await;
    assert_eq!(network_nodes.len(), 2);

    let network_nodes = node_b.get_network_nodes().await;
    assert_eq!(network_nodes.len(), 2);

    let network_channels = node_a.get_network_channels().await;
    assert_eq!(network_channels.len(), 0);

    let network_channels = node_b.get_network_channels().await;
    assert_eq!(network_channels.len(), 0);
}

#[tokio::test]
async fn test_send_payment_with_channel_balance_error() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let nodes_num = 4;
    let amounts = vec![(100000000000, 100000000000); nodes_num - 1];
    let (nodes, channels) =
        create_n_nodes_with_established_channel(&amounts, nodes_num, true).await;
    let [node_0, _node_1, node_2, node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &node_0;
    let target_pubkey = node_3.pubkey;

    // sleep for a while
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(target_pubkey),
                amount: Some(3000),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };
    let res = call!(source_node.network_actor, message).expect("source_node alive");
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;
    // sleep for a while
    source_node.wait_until_success(payment_hash).await;

    node_2.update_channel_local_balance(channels[2], 100).await;
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(target_pubkey),
                amount: Some(3000),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };

    // expect send payment failed
    let res = call!(source_node.network_actor, message).expect("source_node alive");
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;

    source_node.wait_until_failed(payment_hash).await;
    let res = source_node.get_payment_result(payment_hash).await;

    assert_eq!(res.status, PaymentSessionStatus::Failed);
    assert!(res.failed_error.unwrap().contains("Failed to build route"));

    // because there is only one path for the payment, the payment will fail in the second try
    // this assertion make sure we didn't do meaningless retry
    let payment_session = source_node.get_payment_session(payment_hash).unwrap();
    assert_eq!(payment_session.retried_times, 2);
}

#[tokio::test]
async fn test_send_payment_with_disable_channel() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let nodes_num = 4;
    let amounts = vec![(100000000000, 100000000000); nodes_num - 1];
    let (nodes, channels) =
        create_n_nodes_with_established_channel(&amounts, nodes_num, true).await;
    let [node_0, _node_1, node_2, node_3] = nodes.try_into().expect("4 nodes");

    // begin to set channel disable, but do not notify the network
    node_2.disable_channel_stealthy(channels[1]).await;
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    // expect send payment failed from node_3 to node_0
    let res = node_3.send_payment_keysend(&node_0, 3000, false).await;
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;

    node_3.wait_until_failed(payment_hash).await;

    // because there is only one path for the payment, the payment will fail in the second try
    // this assertion make sure we didn't do meaningless retry
    let payment_session = node_3.get_payment_session(payment_hash).unwrap();
    assert_eq!(payment_session.retried_times, 2);

    // expect send payment successfully from node_0 to node_3
    let res = node_0.send_payment_keysend(&node_3, 3000, false).await;
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;

    node_0.wait_until_success(payment_hash).await;

    let payment_session = node_0.get_payment_session(payment_hash).unwrap();
    assert_eq!(payment_session.retried_times, 1);
}

#[tokio::test]
async fn test_send_payment_with_multiple_edges_in_middle_hops() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    // we have two chaneels between node_1 and node_2, they are all with the same meta information except the later one has more capacity
    // path finding will try the channel with larger capacity first, so we assert the payment retry times is 1
    // the send payment should be succeed
    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (100000000000, 100000000000)),
            ((1, 2), (MIN_RESERVED_CKB + 900, 5200000000)),
            ((1, 2), (MIN_RESERVED_CKB + 1000, 5200000000)),
            ((2, 3), (100000000000, 100000000000)),
        ],
        4,
        true,
    )
    .await;
    let [node_0, _node_1, _node_2, node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &node_0;
    let target_pubkey = node_3.pubkey;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(target_pubkey),
                amount: Some(999),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };

    // expect send payment to succeed
    let res = call!(source_node.network_actor, message).expect("source_node alive");
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;

    source_node.wait_until_success(payment_hash).await;
    // because there is only one path for the payment, the payment will fail in the second try
    // this assertion make sure we didn't do meaningless retry
    let payment_session = source_node.get_payment_session(payment_hash).unwrap();
    assert_eq!(payment_session.retried_times, 1);
}

#[tokio::test]
async fn test_send_payment_with_all_failed_middle_hops() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    // we have two chaneels between node_1 and node_2
    // they liquid capacity is enough for send payment, but actual balance are both not enough
    // path finding will all try them but all failed, so we assert the payment retry times is 3
    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (100000000000, 100000000000)),
            ((1, 2), (MIN_RESERVED_CKB + 900, MIN_RESERVED_CKB + 1000)),
            ((1, 2), (MIN_RESERVED_CKB + 910, MIN_RESERVED_CKB + 1000)),
            ((2, 3), (100000000000, 100000000000)),
        ],
        4,
        true,
    )
    .await;
    let [node_0, _node_1, _node_2, node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &node_0;
    let target_pubkey = node_3.pubkey;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(target_pubkey),
                amount: Some(999),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };

    // expect send payment to failed
    let res = call!(source_node.network_actor, message).expect("source_node alive");
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;
    source_node.wait_until_failed(payment_hash).await;

    // because there is only one path for the payment, the payment will fail in the second try
    // this assertion make sure we didn't do meaningless retry
    assert!(node_0.get_triggered_unexpected_events().await.is_empty());
    let payment_session = source_node.get_payment_session(payment_hash).unwrap();
    assert_eq!(payment_session.retried_times, 3);
}

#[tokio::test]
async fn test_send_payment_with_multiple_edges_can_succeed_in_retry() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    // we have two chaneels between node_1 and node_2, they are all with the same meta information except the later one has more capacity
    // but even channel_2's capacity is larger, the to_local_amount is not enough for the payment
    // path finding will retry the first channel and the send payment should be succeed
    // the payment retry times should be 2
    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (100000000000, 100000000000)),
            ((1, 2), (MIN_RESERVED_CKB + 1000, 5200000000)),
            ((1, 2), (MIN_RESERVED_CKB + 900, 6200000000)),
            ((2, 3), (100000000000, 100000000000)),
        ],
        4,
        true,
    )
    .await;
    let [node_0, _node_1, _node_2, node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &node_0;
    let target_pubkey = node_3.pubkey;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(target_pubkey),
                amount: Some(999),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };

    // expect send payment to succeed
    let res = call!(source_node.network_actor, message).expect("source_node alive");
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;
    source_node.wait_until_success(payment_hash).await;

    // because there is only one path for the payment, the payment will fail in the second try
    // this assertion make sure we didn't do meaningless retry
    let payment_session = source_node.get_payment_session(payment_hash).unwrap();
    assert_eq!(payment_session.retried_times, 2);
}

#[tokio::test]
async fn test_send_payment_with_final_hop_multiple_edges_in_middle_hops() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    // we have two chaneels between node_2 and node_3, they are all with the same meta information except the later one has more capacity
    // path finding will try the channel with larger capacity first, so we assert the payment retry times is 1
    // the send payment should be succeed
    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (100000000000, 100000000000)),
            ((1, 2), (100000000000, 100000000000)),
            ((2, 3), (MIN_RESERVED_CKB + 900, 5200000000)),
            ((2, 3), (MIN_RESERVED_CKB + 1000, 5200000000)),
        ],
        4,
        true,
    )
    .await;
    let [node_0, _node_1, _node_2, node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &node_0;
    let target_pubkey = node_3.pubkey;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(target_pubkey),
                amount: Some(999),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };

    // expect send payment to succeed
    let res = call!(source_node.network_actor, message).expect("source_node alive");
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;
    source_node.wait_until_success(payment_hash).await;

    // because there is only one path for the payment, the payment will fail in the second try
    // this assertion make sure we didn't do meaningless retry
    let payment_session = source_node.get_payment_session(payment_hash).unwrap();
    assert_eq!(payment_session.retried_times, 1);
}

#[tokio::test]
async fn test_send_payment_with_final_all_failed_middle_hops() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    // we have two chaneels between node_2 and node_3
    // they liquid capacity is enough for send payment, but actual balance are both not enough
    // path finding will all try them but all failed, so we assert the payment retry times is 3
    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (100000000000, 100000000000)),
            ((1, 2), (100000000000, 100000000000)),
            ((2, 3), (MIN_RESERVED_CKB + 900, MIN_RESERVED_CKB + 1000)),
            ((2, 3), (MIN_RESERVED_CKB + 910, MIN_RESERVED_CKB + 1000)),
        ],
        4,
        true,
    )
    .await;
    let [node_0, _node_1, _node_2, node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &node_0;
    let target_pubkey = node_3.pubkey;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(target_pubkey),
                amount: Some(999),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };

    // expect send payment to succeed
    let res = call!(source_node.network_actor, message).expect("source_node alive");
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;

    source_node.wait_until_failed(payment_hash).await;
    source_node
        .assert_payment_status(payment_hash, PaymentSessionStatus::Failed, Some(3))
        .await;
}

#[tokio::test]
async fn test_send_payment_with_final_multiple_edges_can_succeed_in_retry() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    // we have two chaneels between node_2 and node_3, they are all with the same meta information except the later one has more capacity
    // but even channel_2's capacity is larger, the to_local_amount is not enough for the payment
    // path finding will retry the first channel and the send payment should be succeed
    // the payment retry times should be 2
    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (100000000000, 100000000000)),
            ((1, 2), (100000000000, 100000000000)),
            ((2, 3), (MIN_RESERVED_CKB + 1000, 5200000000)),
            ((2, 3), (MIN_RESERVED_CKB + 900, 6200000000)),
        ],
        4,
        true,
    )
    .await;
    let [node_0, _node_1, _node_2, node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &node_0;
    let target_pubkey = node_3.pubkey;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(target_pubkey),
                amount: Some(999),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };

    // expect send payment to succeed
    let res = call!(source_node.network_actor, message).expect("source_node alive");
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;

    source_node.wait_until_success(payment_hash).await;
    source_node
        .assert_payment_status(payment_hash, PaymentSessionStatus::Success, Some(2))
        .await;
}

#[tokio::test]
async fn test_send_payment_with_first_hop_failed_with_fee() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            // even 1000 > 999, but it's not enough for fee, and this is the direct channel
            // so we can check the actual balance of channel
            // the payment will fail
            ((0, 1), (MIN_RESERVED_CKB + 1000, 5200000000)),
            ((1, 2), (100000000000, 100000000000)),
            ((2, 3), (100000000000, 100000000000)),
        ],
        4,
        true,
    )
    .await;
    let [node_0, _node_1, _node_2, node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &node_0;
    let target_pubkey = node_3.pubkey;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(target_pubkey),
                amount: Some(999),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };

    // expect send payment to fail
    let res = call!(source_node.network_actor, message).expect("source_node alive");
    assert!(res.is_err());
    assert!(res.unwrap_err().contains("Failed to build route"));
}

#[tokio::test]
async fn test_send_payment_succeed_with_multiple_edges_in_first_hop() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    // we have two chaneels between node_0 and node_1, they are all with the same meta information except the later one has more capacity
    // path finding will try the channel with larger capacity first, so we assert the payment retry times is 1
    // the send payment should be succeed
    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (MIN_RESERVED_CKB + 900, 5200000000)),
            ((0, 1), (MIN_RESERVED_CKB + 1001, 5200000000)),
            ((1, 2), (100000000000, 100000000000)),
            ((2, 3), (100000000000, 100000000000)),
        ],
        4,
        true,
    )
    .await;
    let [node_0, _node_1, _node_2, node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &node_0;
    let target_pubkey = node_3.pubkey;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(target_pubkey),
                amount: Some(999),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };

    // expect send payment to succeed
    let res = call!(source_node.network_actor, message).expect("source_node alive");
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;

    source_node.wait_until_success(payment_hash).await;
    source_node
        .assert_payment_status(payment_hash, PaymentSessionStatus::Success, Some(1))
        .await;
}

#[tokio::test]
async fn test_send_payment_with_first_hop_all_failed() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    // we have two chaneels between node_0 and node_1
    // they liquid capacity is enough for send payment, but actual balance are both not enough
    // path finding will fail in the first time of send payment
    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (MIN_RESERVED_CKB + 900, MIN_RESERVED_CKB + 1000)),
            ((0, 1), (MIN_RESERVED_CKB + 910, MIN_RESERVED_CKB + 1000)),
            ((1, 2), (100000000000, 100000000000)),
            ((2, 3), (100000000000, 100000000000)),
        ],
        4,
        true,
    )
    .await;
    let [node_0, _node_1, _node_2, node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &node_0;
    let target_pubkey = node_3.pubkey;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(target_pubkey),
                amount: Some(999),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };

    // expect send payment to faile
    let res = call!(source_node.network_actor, message).expect("source_node alive");
    assert!(res.is_err());
    assert!(res.unwrap_err().contains("Failed to build route"));
}

#[tokio::test]
async fn test_send_payment_will_succeed_with_direct_channel_info_first_hop() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    // we have two chaneels between node_0 and node_1
    // the path finding will first try the channel with larger capacity,
    // but we manually set the to_local_amount to smaller value for testing
    // path finding will get the direct channel info with actual balance of channel,
    // so it will try the channel with smaller capacity and the payment will succeed
    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (MIN_RESERVED_CKB + 2000, MIN_RESERVED_CKB + 1000)),
            ((0, 1), (MIN_RESERVED_CKB + 1005, MIN_RESERVED_CKB + 1000)),
            ((1, 2), (100000000000, 100000000000)),
            ((2, 3), (100000000000, 100000000000)),
        ],
        4,
        true,
    )
    .await;
    let [mut node_0, _node_1, _node_2, node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &mut node_0;
    let target_pubkey = node_3.pubkey;

    // manually update the channel's to_local_amount
    source_node
        .update_channel_local_balance(channels[0], 100)
        .await;
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(target_pubkey),
                amount: Some(999),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };

    // expect send payment to succeed
    let res = call!(source_node.network_actor, message).expect("source_node alive");
    assert!(res.is_ok());

    let payment_hash = res.unwrap().payment_hash;
    source_node.wait_until_success(payment_hash).await;
    source_node
        .assert_payment_status(payment_hash, PaymentSessionStatus::Success, Some(1))
        .await;
}

#[tokio::test]
async fn test_send_payment_will_succeed_with_retry_in_middle_hops() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    // we have two chaneels between node_2 and node_3
    // the path finding will first try the channel with larger capacity,
    // but we manually set the to_local_amount to smaller value for testing
    // path finding will get a temporary failure in the first try and retry the second channel
    // so it will try the channel with smaller capacity and the payment will succeed
    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (100000000000, 100000000000)),
            ((1, 2), (100000000000, 100000000000)),
            ((2, 3), (MIN_RESERVED_CKB + 2000, MIN_RESERVED_CKB + 1000)),
            ((2, 3), (MIN_RESERVED_CKB + 1005, MIN_RESERVED_CKB + 1000)),
        ],
        4,
        true,
    )
    .await;
    let [mut node_0, _node_1, node_2, node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &mut node_0;
    let node_0_amount = source_node.get_local_balance_from_channel(channels[0]);
    let target_pubkey = node_3.pubkey;

    // manually update the channel's to_local_amount
    node_2.update_channel_local_balance(channels[2], 100).await;
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    let amount = 999;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(target_pubkey),
                amount: Some(amount),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };

    // expect send payment to succeed
    let res = call!(source_node.network_actor, message)
        .expect("source_node alive")
        .unwrap();

    let payment_hash = res.payment_hash;
    source_node.wait_until_success(payment_hash).await;

    let fee = res.fee;
    eprintln!("fee: {:?}", fee);
    source_node
        .assert_payment_status(payment_hash, PaymentSessionStatus::Success, Some(2))
        .await;

    let new_node0_amount = source_node.get_local_balance_from_channel(channels[0]);
    assert_eq!(node_0_amount - amount - fee, new_node0_amount);
}

#[tokio::test]
async fn test_send_payment_will_fail_with_last_hop_info_in_add_tlc_peer() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    // we have two chaneels between node_2 and node_3
    // the path finding will first try the channel with larger capacity,
    // but we manually set the to_remote_amount for node_3 to a larger amount,
    // this will make node3 trigger error in add_tlc_peer and got an Musig2VerifyError(BadSignature)
    // the send_payment will failed with retry times of 1
    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (100000000000, 100000000000)),
            ((1, 2), (100000000000, 100000000000)),
            ((2, 3), (MIN_RESERVED_CKB + 2000, MIN_RESERVED_CKB + 1000)),
            ((2, 3), (MIN_RESERVED_CKB + 1005, MIN_RESERVED_CKB + 1000)),
        ],
        4,
        true,
    )
    .await;
    let [mut node_0, _node_1, _node_2, mut node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &mut node_0;
    let target_pubkey = node_3.pubkey;

    // manually update the channel's to_remote_amount
    node_3
        .update_channel_remote_balance(channels[2], 100000000)
        .await;
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    let res = source_node
        .send_payment(SendPaymentCommand {
            target_pubkey: Some(target_pubkey),
            amount: Some(999),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: None,
            invoice: None,
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: Some(true),
            udt_type_script: None,
            allow_self_payment: false,
            hop_hints: None,
            dry_run: false,
        })
        .await;

    // expect send payment to failed
    assert!(res.is_ok());

    node_3
        .expect_event(|event| match event {
            NetworkServiceEvent::DebugEvent(DebugEvent::Common(error)) => {
                assert!(error.contains("Musig2VerifyError(BadSignature)"));
                true
            }
            _ => false,
        })
        .await;

    let payment_hash = res.unwrap().payment_hash;
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    source_node
        .assert_payment_status(payment_hash, PaymentSessionStatus::Inflight, Some(1))
        .await;
}

#[tokio::test]
async fn test_send_payment_will_fail_with_invoice_not_generated_by_target() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();

    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (100000000000, 100000000000)),
            ((1, 2), (100000000000, 100000000000)),
            ((2, 3), (MIN_RESERVED_CKB + 2000, MIN_RESERVED_CKB + 1000)),
            ((2, 3), (MIN_RESERVED_CKB + 1005, MIN_RESERVED_CKB + 1000)),
        ],
        4,
        true,
    )
    .await;
    let [mut node_0, _node_1, _node_2, node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &mut node_0;
    let target_pubkey = node_3.pubkey;

    let invoice = InvoiceBuilder::new(Currency::Fibd)
        .amount(Some(100))
        .payment_preimage(gen_rand_sha256_hash())
        .payee_pub_key(target_pubkey.into())
        .expiry_time(Duration::from_secs(100))
        .build()
        .expect("build invoice success")
        .to_string();

    let res = source_node
        .send_payment(SendPaymentCommand {
            target_pubkey: Some(target_pubkey),
            amount: Some(100),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: None,
            invoice: Some(invoice.clone()),
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: None,
            udt_type_script: None,
            allow_self_payment: false,
            hop_hints: None,
            dry_run: false,
        })
        .await;

    // expect send payment to succeed
    assert!(res.is_ok());

    let payment_hash = res.unwrap().payment_hash;
    source_node.wait_until_failed(payment_hash).await;
    source_node
        .assert_payment_status(payment_hash, PaymentSessionStatus::Failed, Some(1))
        .await;
}

#[tokio::test]
async fn test_send_payment_will_succeed_with_valid_invoice() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();

    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (100000000000, 100000000000)),
            ((1, 2), (100000000000, 100000000000)),
            ((2, 3), (MIN_RESERVED_CKB + 2000, MIN_RESERVED_CKB + 1000)),
            ((2, 3), (MIN_RESERVED_CKB + 1005, MIN_RESERVED_CKB + 1000)),
        ],
        4,
        true,
    )
    .await;
    let [mut node_0, _node_1, _node_2, mut node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &mut node_0;
    let target_pubkey = node_3.pubkey;
    let old_amount = node_3.get_local_balance_from_channel(channels[2]);

    let preimage = gen_rand_sha256_hash();
    let ckb_invoice = InvoiceBuilder::new(Currency::Fibd)
        .amount(Some(100))
        .payment_preimage(preimage)
        .payee_pub_key(target_pubkey.into())
        .expiry_time(Duration::from_secs(100))
        .build()
        .expect("build invoice success");

    node_3.insert_invoice(ckb_invoice.clone(), Some(preimage));

    let res = source_node
        .send_payment(SendPaymentCommand {
            target_pubkey: Some(target_pubkey),
            amount: Some(100),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: None,
            invoice: Some(ckb_invoice.to_string()),
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: None,
            udt_type_script: None,
            allow_self_payment: false,
            hop_hints: None,
            dry_run: false,
        })
        .await;

    // expect send payment to succeed
    assert!(res.is_ok());

    let payment_hash = res.unwrap().payment_hash;
    source_node.wait_until_success(payment_hash).await;

    source_node
        .assert_payment_status(payment_hash, PaymentSessionStatus::Success, Some(1))
        .await;

    let new_amount = node_3.get_local_balance_from_channel(channels[2]);
    assert_eq!(new_amount, old_amount + 100);
    assert_eq!(
        node_3.get_invoice_status(ckb_invoice.payment_hash()),
        Some(CkbInvoiceStatus::Paid)
    );
}

#[tokio::test]
async fn test_send_payment_will_fail_with_no_invoice_preimage() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (100000000000, 100000000000)),
            ((1, 2), (100000000000, 100000000000)),
            ((2, 3), (MIN_RESERVED_CKB + 2000, MIN_RESERVED_CKB + 1000)),
            ((2, 3), (MIN_RESERVED_CKB + 1005, MIN_RESERVED_CKB + 1000)),
        ],
        4,
        true,
    )
    .await;
    let [mut node_0, _node_1, _node_2, mut node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &mut node_0;
    let target_pubkey = node_3.pubkey;
    let old_amount = node_3.get_local_balance_from_channel(channels[2]);

    let preimage = gen_rand_sha256_hash();
    let ckb_invoice = InvoiceBuilder::new(Currency::Fibd)
        .amount(Some(100))
        .payment_preimage(preimage)
        .payee_pub_key(target_pubkey.into())
        .expiry_time(Duration::from_secs(100))
        .build()
        .expect("build invoice success");

    // insert invoice without preimage
    node_3.insert_invoice(ckb_invoice.clone(), None);

    let res = source_node
        .send_payment(SendPaymentCommand {
            target_pubkey: Some(target_pubkey),
            amount: Some(100),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: None,
            invoice: Some(ckb_invoice.to_string()),
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: None,
            udt_type_script: None,
            allow_self_payment: false,
            hop_hints: None,
            dry_run: false,
        })
        .await;

    // expect send payment to failed because we can not find preimage
    assert!(res.is_ok());

    let payment_hash = res.unwrap().payment_hash;
    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;

    source_node
        .assert_payment_status(payment_hash, PaymentSessionStatus::Failed, Some(1))
        .await;

    let new_amount = node_3.get_local_balance_from_channel(channels[2]);
    assert_eq!(new_amount, old_amount);

    // we should never update the invoice status if there is an error
    assert_eq!(
        node_3.get_invoice_status(ckb_invoice.payment_hash()),
        Some(CkbInvoiceStatus::Open)
    );
}

#[tokio::test]
async fn test_send_payment_will_fail_with_cancelled_invoice() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();

    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (100000000000, 100000000000)),
            ((1, 2), (100000000000, 100000000000)),
            ((2, 3), (MIN_RESERVED_CKB + 2000, MIN_RESERVED_CKB + 1000)),
            ((2, 3), (MIN_RESERVED_CKB + 1005, MIN_RESERVED_CKB + 1000)),
        ],
        4,
        true,
    )
    .await;
    let [mut node_0, _node_1, _node_2, mut node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &mut node_0;
    let target_pubkey = node_3.pubkey;
    let old_amount = node_3.get_local_balance_from_channel(channels[2]);

    let preimage = gen_rand_sha256_hash();
    let ckb_invoice = InvoiceBuilder::new(Currency::Fibd)
        .amount(Some(100))
        .payment_preimage(preimage)
        .payee_pub_key(target_pubkey.into())
        .expiry_time(Duration::from_secs(100))
        .build()
        .expect("build invoice success");

    node_3.insert_invoice(ckb_invoice.clone(), Some(preimage));
    node_3.cancel_invoice(ckb_invoice.payment_hash());
    // sleep for a while
    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;

    let res = source_node
        .send_payment(SendPaymentCommand {
            target_pubkey: Some(target_pubkey),
            amount: Some(100),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: None,
            invoice: Some(ckb_invoice.to_string()),
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: None,
            udt_type_script: None,
            allow_self_payment: false,
            hop_hints: None,
            dry_run: false,
        })
        .await;

    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;
    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;

    source_node
        .assert_payment_status(payment_hash, PaymentSessionStatus::Failed, Some(1))
        .await;

    let new_amount = node_3.get_local_balance_from_channel(channels[2]);
    assert_eq!(new_amount, old_amount);
    assert_eq!(
        node_3.get_invoice_status(ckb_invoice.payment_hash()),
        Some(CkbInvoiceStatus::Cancelled)
    );
}

#[tokio::test]
async fn test_send_payment_will_succeed_with_large_tlc_expiry_limit() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    // from https://github.com/nervosnetwork/fiber/issues/367

    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (MIN_RESERVED_CKB + 2000, MIN_RESERVED_CKB + 1000)),
            ((1, 2), (100000000000, 100000000000)),
            ((2, 3), (100000000000, 100000000000)),
        ],
        4,
        true,
    )
    .await;
    let [mut node_0, _node_1, _node_2, node_3] = nodes.try_into().expect("4 nodes");
    let source_node = &mut node_0;
    let target_pubkey = node_3.pubkey;

    let expected_minimal_tlc_expiry_limit = (24 * 60 * 60 * 1000) * 3;

    let res = source_node
        .send_payment(SendPaymentCommand {
            target_pubkey: Some(target_pubkey),
            amount: Some(999),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: Some(expected_minimal_tlc_expiry_limit - 1),
            invoice: None,
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: Some(true),
            udt_type_script: None,
            allow_self_payment: false,
            hop_hints: None,
            dry_run: false,
        })
        .await;

    assert!(res.unwrap_err().contains("Failed to build route"));

    let res = source_node
        .send_payment(SendPaymentCommand {
            target_pubkey: Some(target_pubkey),
            amount: Some(999),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: Some(expected_minimal_tlc_expiry_limit),
            invoice: None,
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: Some(true),
            udt_type_script: None,
            allow_self_payment: false,
            hop_hints: None,
            dry_run: false,
        })
        .await;

    // expect send payment to succeed
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;
    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;

    source_node
        .assert_payment_status(payment_hash, PaymentSessionStatus::Success, Some(1))
        .await;
}


================================================
File: src/fiber/tests/gossip.rs
================================================
use std::{collections::HashSet, str::FromStr, sync::Arc};

use ckb_jsonrpc_types::Status;
use ckb_types::core::TransactionView;
use ckb_types::packed::Bytes;
use ckb_types::prelude::{Builder, Entity};
use molecule::prelude::Byte;
use ractor::{async_trait, concurrency::Duration, Actor, ActorProcessingErr, ActorRef};
use tentacle::{
    builder::ServiceBuilder,
    context::ServiceContext,
    multiaddr::MultiAddr,
    secio::SecioKeyPair,
    service::{ServiceError, ServiceEvent},
    traits::ServiceHandle,
};
use tokio::{spawn, sync::RwLock};

use crate::fiber::tests::test_utils::{establish_channel_between_nodes, NetworkNode};
use crate::fiber::types::{ChannelUpdateChannelFlags, NodeAnnouncement};
use crate::{
    ckb::{
        tests::{actor::create_mock_chain_actor, test_utils::submit_tx},
        CkbChainMessage,
    },
    fiber::{
        gossip::{
            ExtendedGossipMessageStore, ExtendedGossipMessageStoreMessage, GossipMessageStore,
            GossipMessageUpdates, GossipProtocolHandle, SubscribableGossipMessageStore,
        },
        types::{BroadcastMessage, BroadcastMessageWithTimestamp, Cursor},
    },
    gen_node_announcement_from_privkey, gen_rand_node_announcement,
    store::Store,
};
use crate::{create_invalid_ecdsa_signature, ChannelTestContext};

use super::test_utils::{get_test_root_actor, TempDir};

struct DummyServiceHandle;

impl DummyServiceHandle {
    pub fn new() -> Self {
        DummyServiceHandle
    }
}

#[async_trait]
impl ServiceHandle for DummyServiceHandle {
    async fn handle_error(&mut self, _context: &mut ServiceContext, error: ServiceError) {
        println!("Service error: {:?}", error);
    }
    async fn handle_event(&mut self, _context: &mut ServiceContext, event: ServiceEvent) {
        println!("Service event: {:?}", event);
    }
}

struct GossipTestingContext {
    chain_actor: ActorRef<CkbChainMessage>,
    store_update_subscriber: ExtendedGossipMessageStore<Store>,
}

impl GossipTestingContext {
    async fn new() -> Self {
        let dir = TempDir::new("test-gossip-store");
        let store = Store::new(dir).expect("created store failed");
        let chain_actor = create_mock_chain_actor().await;
        let root_actor = get_test_root_actor().await;
        let (gossip_handle, store_update_subscriber) = GossipProtocolHandle::new(
            None,
            Duration::from_millis(50),
            Duration::from_millis(50),
            true,
            None,
            None,
            store.clone(),
            chain_actor.clone(),
            root_actor.get_cell(),
        )
        .await;

        run_dummy_tentacle_service(gossip_handle).await;

        Self {
            chain_actor,
            store_update_subscriber,
        }
    }
}

impl GossipTestingContext {
    fn get_chain_actor(&self) -> &ActorRef<CkbChainMessage> {
        &self.chain_actor
    }

    fn get_store_update_subscriber(&self) -> &ExtendedGossipMessageStore<Store> {
        &self.store_update_subscriber
    }

    fn get_store(&self) -> &Store {
        &self.store_update_subscriber.store
    }

    fn get_store_actor(&self) -> &ActorRef<ExtendedGossipMessageStoreMessage> {
        &self.store_update_subscriber.actor
    }

    async fn subscribe(&self, cursor: Cursor) -> Arc<RwLock<Vec<BroadcastMessageWithTimestamp>>> {
        let (subscriber, messages) = Subscriber::start_actor().await;
        self.get_store_update_subscriber()
            .subscribe(cursor, subscriber, |m| Some(SubscriberMessage::Update(m)))
            .await
            .expect("subscribe to store updates");
        messages
    }

    fn save_message(&self, message: BroadcastMessage) {
        self.get_store_actor()
            .send_message(ExtendedGossipMessageStoreMessage::SaveMessages(vec![
                message,
            ]))
            .expect("send message");
    }

    async fn submit_tx(&self, tx: TransactionView) -> Status {
        submit_tx(self.get_chain_actor().clone(), tx).await
    }
}

// The gossip actor expects us to pass a tentacle control. This is a dummy tentacle service that
// passes the control to the gossip actor. It serves no other purpose.
async fn run_dummy_tentacle_service(gossip_handle: GossipProtocolHandle) {
    let secio_kp = SecioKeyPair::secp256k1_generated();
    let mut service = ServiceBuilder::default()
        .insert_protocol(gossip_handle.create_meta())
        .handshake_type(secio_kp.into())
        .build(DummyServiceHandle::new());
    let _ = service
        .listen(
            MultiAddr::from_str("/ip4/127.0.0.1/tcp/0").expect("valid tentacle listening address"),
        )
        .await
        .expect("listen tentacle");

    spawn(async move {
        service.run().await;
    });
}

// A subscriber which subscribes to the store updates and save all updates to a vector.
struct Subscriber {
    messages: Arc<RwLock<Vec<BroadcastMessageWithTimestamp>>>,
}

impl Subscriber {
    fn new() -> Self {
        Subscriber {
            messages: Arc::new(RwLock::new(Vec::new())),
        }
    }

    async fn start_actor() -> (
        ActorRef<SubscriberMessage>,
        Arc<RwLock<Vec<BroadcastMessageWithTimestamp>>>,
    ) {
        let subscriber = Subscriber::new();
        let messages = subscriber.messages.clone();
        let (actor, _) = Actor::spawn(None, subscriber, ())
            .await
            .expect("start subscriber");
        (actor, messages)
    }
}

enum SubscriberMessage {
    Update(GossipMessageUpdates),
}

#[async_trait]
impl Actor for Subscriber {
    type Msg = SubscriberMessage;
    type State = ();
    type Arguments = ();

    async fn pre_start(
        &self,
        _: ActorRef<Self::Msg>,
        _: Self::Arguments,
    ) -> Result<Self::State, ActorProcessingErr> {
        Ok(())
    }

    async fn post_stop(
        &self,
        _myself: ActorRef<Self::Msg>,
        _state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        Ok(())
    }

    async fn handle(
        &self,
        _myself: ActorRef<Self::Msg>,
        message: Self::Msg,
        _state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        match message {
            SubscriberMessage::Update(updates) => {
                let mut messages = self.messages.write().await;
                messages.extend(updates.messages);
            }
        }
        Ok(())
    }
}

#[tokio::test]
async fn test_save_gossip_message() {
    let context = GossipTestingContext::new().await;
    let (_, announcement) = gen_rand_node_announcement();
    context.save_message(BroadcastMessage::NodeAnnouncement(announcement.clone()));
    tokio::time::sleep(Duration::from_millis(200)).await;
    let new_announcement = context
        .get_store()
        .get_latest_node_announcement(&announcement.node_id)
        .expect("get latest node announcement");
    assert_eq!(new_announcement, announcement);
}

#[tokio::test]
async fn test_saving_unconfirmed_channel_announcement() {
    let context = GossipTestingContext::new().await;
    let channel_context = ChannelTestContext::gen();
    context.save_message(BroadcastMessage::ChannelAnnouncement(
        channel_context.channel_announcement.clone(),
    ));
    tokio::time::sleep(Duration::from_millis(200)).await;
    let new_announcement = context
        .get_store()
        .get_latest_channel_announcement(channel_context.channel_outpoint());
    assert_eq!(new_announcement, None);
}

#[tokio::test]
async fn test_saving_confirmed_channel_announcement() {
    let context = GossipTestingContext::new().await;
    let channel_context = ChannelTestContext::gen();
    context.save_message(BroadcastMessage::ChannelAnnouncement(
        channel_context.channel_announcement.clone(),
    ));
    let status = context.submit_tx(channel_context.funding_tx.clone()).await;
    assert_eq!(status, Status::Committed);
    tokio::time::sleep(Duration::from_millis(200)).await;
    let new_announcement = context
        .get_store()
        .get_latest_channel_announcement(channel_context.channel_outpoint());
    assert_ne!(new_announcement, None);
}

#[tokio::test]
async fn test_saving_invalid_channel_announcement() {
    let context = GossipTestingContext::new().await;
    let channel_context = ChannelTestContext::gen();
    let tx = channel_context.funding_tx.clone();
    context.save_message(BroadcastMessage::ChannelAnnouncement(
        channel_context.channel_announcement.clone(),
    ));
    let output = tx.output(0).expect("get output").clone();
    let invalid_lock = output
        .lock()
        .as_builder()
        .args(
            Bytes::new_builder()
                .set(b"wrong lock args".iter().map(|b| Byte::new(*b)).collect())
                .build(),
        )
        .build();
    let invalid_output = output.as_builder().lock(invalid_lock).build();
    let invalid_tx = tx
        .as_advanced_builder()
        .set_outputs(vec![invalid_output])
        .build();
    let status = context.submit_tx(invalid_tx).await;
    assert_eq!(status, Status::Committed);
    tokio::time::sleep(Duration::from_millis(200)).await;
    let new_announcement = context
        .get_store()
        .get_latest_channel_announcement(channel_context.channel_outpoint());
    assert_eq!(new_announcement, None);
}

#[tokio::test]
async fn test_saving_channel_update_after_saving_channel_announcement() {
    let context = GossipTestingContext::new().await;
    let channel_context = ChannelTestContext::gen();
    context.save_message(BroadcastMessage::ChannelAnnouncement(
        channel_context.channel_announcement.clone(),
    ));
    let status = context.submit_tx(channel_context.funding_tx.clone()).await;
    assert_eq!(status, Status::Committed);
    tokio::time::sleep(Duration::from_millis(200)).await;
    let new_announcement = context
        .get_store()
        .get_latest_channel_announcement(channel_context.channel_outpoint());
    assert_ne!(new_announcement, None);
    for channel_update in [
        channel_context.create_channel_update_of_node1(
            ChannelUpdateChannelFlags::empty(),
            42,
            42,
            42,
        ),
        channel_context.create_channel_update_of_node2(
            ChannelUpdateChannelFlags::empty(),
            42,
            42,
            42,
        ),
    ] {
        context.save_message(BroadcastMessage::ChannelUpdate(channel_update.clone()));
    }
    tokio::time::sleep(Duration::from_millis(200)).await;
    for b in [true, false] {
        let channel_update = context
            .get_store()
            .get_latest_channel_update(channel_context.channel_outpoint(), b);
        assert_ne!(channel_update, None);
    }
}

#[tokio::test]
async fn test_saving_channel_update_before_saving_channel_announcement() {
    let context = GossipTestingContext::new().await;
    let channel_context = ChannelTestContext::gen();

    for channel_update in [
        channel_context.create_channel_update_of_node1(
            ChannelUpdateChannelFlags::empty(),
            42,
            42,
            42,
        ),
        channel_context.create_channel_update_of_node2(
            ChannelUpdateChannelFlags::empty(),
            42,
            42,
            42,
        ),
    ] {
        context.save_message(BroadcastMessage::ChannelUpdate(channel_update.clone()));
    }
    tokio::time::sleep(Duration::from_millis(200)).await;
    for b in [true, false] {
        let channel_update = context
            .get_store()
            .get_latest_channel_update(channel_context.channel_outpoint(), b);
        assert_eq!(channel_update, None);
    }

    context.save_message(BroadcastMessage::ChannelAnnouncement(
        channel_context.channel_announcement.clone(),
    ));
    let status = context.submit_tx(channel_context.funding_tx.clone()).await;
    assert_eq!(status, Status::Committed);
    tokio::time::sleep(Duration::from_millis(200)).await;
    let new_announcement = context
        .get_store()
        .get_latest_channel_announcement(channel_context.channel_outpoint());
    assert_ne!(new_announcement, None);
    for b in [true, false] {
        let channel_update = context
            .get_store()
            .get_latest_channel_update(channel_context.channel_outpoint(), b);
        assert_ne!(channel_update, None);
    }
}

#[tokio::test]
async fn test_saving_invalid_channel_update() {
    let context = GossipTestingContext::new().await;
    let channel_context = ChannelTestContext::gen();
    context.save_message(BroadcastMessage::ChannelAnnouncement(
        channel_context.channel_announcement.clone(),
    ));
    let status = context.submit_tx(channel_context.funding_tx.clone()).await;
    assert_eq!(status, Status::Committed);
    tokio::time::sleep(Duration::from_millis(200)).await;
    let new_announcement = context
        .get_store()
        .get_latest_channel_announcement(channel_context.channel_outpoint());
    assert_ne!(new_announcement, None);
    for mut channel_update in [
        channel_context.create_channel_update_of_node1(
            ChannelUpdateChannelFlags::empty(),
            42,
            42,
            42,
        ),
        channel_context.create_channel_update_of_node2(
            ChannelUpdateChannelFlags::empty(),
            42,
            42,
            42,
        ),
    ] {
        channel_update.signature = Some(create_invalid_ecdsa_signature());
        context.save_message(BroadcastMessage::ChannelUpdate(channel_update.clone()));
    }
    tokio::time::sleep(Duration::from_millis(200)).await;
    for b in [true, false] {
        let channel_update = context
            .get_store()
            .get_latest_channel_update(channel_context.channel_outpoint(), b);
        assert_eq!(channel_update, None);
    }
}

#[tokio::test]
async fn test_saving_channel_update_independency() {
    async fn test(node1_has_invalid_signature: bool, node2_has_invalid_signature: bool) {
        let context = GossipTestingContext::new().await;
        let channel_context = ChannelTestContext::gen();
        context.save_message(BroadcastMessage::ChannelAnnouncement(
            channel_context.channel_announcement.clone(),
        ));
        let status = context.submit_tx(channel_context.funding_tx.clone()).await;
        assert_eq!(status, Status::Committed);
        tokio::time::sleep(Duration::from_millis(200)).await;
        let new_announcement = context
            .get_store()
            .get_latest_channel_announcement(channel_context.channel_outpoint());
        assert_ne!(new_announcement, None);
        for mut channel_update in [
            channel_context.create_channel_update_of_node1(
                ChannelUpdateChannelFlags::empty(),
                42,
                42,
                42,
            ),
            channel_context.create_channel_update_of_node2(
                ChannelUpdateChannelFlags::empty(),
                42,
                42,
                42,
            ),
        ] {
            if channel_update.is_update_of_node_1() && node1_has_invalid_signature {
                channel_update.signature = Some(create_invalid_ecdsa_signature());
            }
            if channel_update.is_update_of_node_2() && node2_has_invalid_signature {
                channel_update.signature = Some(create_invalid_ecdsa_signature());
            }
            context.save_message(BroadcastMessage::ChannelUpdate(channel_update.clone()));
        }
        tokio::time::sleep(Duration::from_millis(200)).await;
        for is_channel_update_of_node1 in [true, false] {
            let channel_update = context.get_store().get_latest_channel_update(
                channel_context.channel_outpoint(),
                is_channel_update_of_node1,
            );
            if is_channel_update_of_node1 {
                if node1_has_invalid_signature {
                    assert_eq!(channel_update, None);
                } else {
                    assert_ne!(channel_update, None);
                }
            } else if node2_has_invalid_signature {
                assert_eq!(channel_update, None);
            } else {
                assert_ne!(channel_update, None);
            }
        }
    }

    for node1_has_invalid_signature in [true, false] {
        for node2_has_invalid_signature in [true, false] {
            test(node1_has_invalid_signature, node2_has_invalid_signature).await;
        }
    }
}

#[tokio::test]
async fn test_saving_channel_update_with_invalid_channel_announcement() {
    let context = GossipTestingContext::new().await;
    let channel_context = ChannelTestContext::gen();
    context.save_message(BroadcastMessage::ChannelAnnouncement(
        channel_context.channel_announcement.clone(),
    ));
    let tx = channel_context.funding_tx.clone();
    context.save_message(BroadcastMessage::ChannelAnnouncement(
        channel_context.channel_announcement.clone(),
    ));
    let output = tx.output(0).expect("get output").clone();
    let invalid_lock = output
        .lock()
        .as_builder()
        .args(
            Bytes::new_builder()
                .set(b"wrong lock args".iter().map(|b| Byte::new(*b)).collect())
                .build(),
        )
        .build();
    let invalid_output = output.as_builder().lock(invalid_lock).build();
    let invalid_tx = tx
        .as_advanced_builder()
        .set_outputs(vec![invalid_output])
        .build();
    let status = context.submit_tx(invalid_tx).await;
    assert_eq!(status, Status::Committed);
    tokio::time::sleep(Duration::from_millis(200)).await;
    let new_announcement = context
        .get_store()
        .get_latest_channel_announcement(channel_context.channel_outpoint());
    assert_eq!(new_announcement, None);
    for channel_update in [
        channel_context.create_channel_update_of_node1(
            ChannelUpdateChannelFlags::empty(),
            42,
            42,
            42,
        ),
        channel_context.create_channel_update_of_node2(
            ChannelUpdateChannelFlags::empty(),
            42,
            42,
            42,
        ),
    ] {
        context.save_message(BroadcastMessage::ChannelUpdate(channel_update.clone()));
    }
    tokio::time::sleep(Duration::from_millis(200)).await;
    for b in [true, false] {
        let channel_update = context
            .get_store()
            .get_latest_channel_update(channel_context.channel_outpoint(), b);
        assert_eq!(channel_update, None);
    }
}

#[tokio::test]
async fn test_save_outdated_gossip_message() {
    let context = GossipTestingContext::new().await;
    let (sk, old_announcement) = gen_rand_node_announcement();
    // Make sure new announcement has a different timestamp
    tokio::time::sleep(Duration::from_millis(2)).await;
    let new_announcement = gen_node_announcement_from_privkey(&sk);
    context.save_message(BroadcastMessage::NodeAnnouncement(new_announcement.clone()));
    tokio::time::sleep(Duration::from_millis(200)).await;
    let announcement_in_store = context
        .get_store()
        .get_latest_node_announcement(&new_announcement.node_id)
        .expect("get latest node announcement");
    assert_eq!(announcement_in_store, new_announcement);

    context.save_message(BroadcastMessage::NodeAnnouncement(old_announcement.clone()));
    tokio::time::sleep(Duration::from_millis(200)).await;
    let announcement_in_store = context
        .get_store()
        .get_latest_node_announcement(&new_announcement.node_id)
        .expect("get latest node announcement");
    assert_eq!(announcement_in_store, new_announcement);
}

#[tokio::test]
async fn test_gossip_store_updates_basic_subscription() {
    let context = GossipTestingContext::new().await;
    let messages = context.subscribe(Default::default()).await;
    let (_, announcement) = gen_rand_node_announcement();
    context.save_message(BroadcastMessage::NodeAnnouncement(announcement.clone()));
    tokio::time::sleep(Duration::from_millis(200)).await;
    let messages = messages.read().await;
    assert!(messages.len() == 1);
    assert_eq!(
        messages[0],
        BroadcastMessageWithTimestamp::NodeAnnouncement(announcement)
    );
}

#[tokio::test]
async fn test_gossip_store_updates_repeated_saving() {
    let context = GossipTestingContext::new().await;
    let messages = context.subscribe(Default::default()).await;
    let (_, announcement) = gen_rand_node_announcement();
    for _ in 0..10 {
        context.save_message(BroadcastMessage::NodeAnnouncement(announcement.clone()));
    }
    tokio::time::sleep(Duration::from_millis(200)).await;
    let messages = messages.read().await;
    assert!(messages.len() == 1);
    assert_eq!(
        messages[0],
        BroadcastMessageWithTimestamp::NodeAnnouncement(announcement)
    );
}

#[tokio::test]
async fn test_gossip_store_updates_saving_multiple_messages() {
    let context = GossipTestingContext::new().await;
    let messages = context.subscribe(Default::default()).await;
    let announcements = (0..10)
        .map(|_| gen_rand_node_announcement().1)
        .collect::<Vec<_>>();
    for annoncement in &announcements {
        context.save_message(BroadcastMessage::NodeAnnouncement(annoncement.clone()));
    }
    tokio::time::sleep(Duration::from_millis(200)).await;
    let messages = messages.read().await;
    assert_eq!(
        messages.iter().cloned().collect::<HashSet<_>>(),
        announcements
            .into_iter()
            .map(BroadcastMessageWithTimestamp::NodeAnnouncement)
            .collect::<HashSet<_>>()
    );
}

#[tokio::test]
async fn test_gossip_store_updates_saving_outdated_message() {
    let context = GossipTestingContext::new().await;
    let messages = context.subscribe(Default::default()).await;
    let (sk, old_announcement) = gen_rand_node_announcement();
    // Make sure new announcement has a different timestamp
    tokio::time::sleep(Duration::from_millis(2)).await;
    let new_announcement = gen_node_announcement_from_privkey(&sk);
    for announcement in [&old_announcement, &new_announcement] {
        context.save_message(BroadcastMessage::NodeAnnouncement(announcement.clone()));
    }

    tokio::time::sleep(Duration::from_millis(200)).await;
    let messages = messages.read().await;
    // The subscriber may or may not receive the old announcement, but it should always receive the
    // new announcement.
    assert_eq!(
        messages[messages.len() - 1],
        BroadcastMessageWithTimestamp::NodeAnnouncement(new_announcement)
    );
}

async fn check_two_node_announcements_with_one_invalid(
    valid_announcement: NodeAnnouncement,
    invalid_announcement: NodeAnnouncement,
) {
    // Checking both saving orders (valid first, invalid first)
    for announcements in [
        [&valid_announcement, &invalid_announcement],
        [&invalid_announcement, &valid_announcement],
    ] {
        let context = GossipTestingContext::new().await;
        let messages = context.subscribe(Default::default()).await;
        for announcement in announcements {
            context.save_message(BroadcastMessage::NodeAnnouncement(announcement.clone()));
        }
        tokio::time::sleep(Duration::from_millis(200)).await;
        let messages = messages.read().await;
        assert_eq!(messages.len(), 1);
        assert_eq!(
            messages[0],
            BroadcastMessageWithTimestamp::NodeAnnouncement(valid_announcement.clone())
        );
    }
}

// Old message is invalid, new message is valid
#[tokio::test]
async fn test_gossip_store_updates_saving_invalid_message_1() {
    let (sk, mut old_announcement) = gen_rand_node_announcement();
    old_announcement.signature = Some(create_invalid_ecdsa_signature());
    // Make sure new announcement has a different timestamp
    tokio::time::sleep(Duration::from_millis(2)).await;
    let new_announcement = gen_node_announcement_from_privkey(&sk);

    check_two_node_announcements_with_one_invalid(new_announcement, old_announcement).await;
}

// New message is invalid, old message is valid
#[tokio::test]
async fn test_gossip_store_updates_saving_invalid_message_2() {
    let (sk, old_announcement) = gen_rand_node_announcement();
    // Make sure new announcement has a different timestamp
    tokio::time::sleep(Duration::from_millis(2)).await;
    let mut new_announcement = gen_node_announcement_from_privkey(&sk);
    new_announcement.signature = Some(create_invalid_ecdsa_signature());

    check_two_node_announcements_with_one_invalid(old_announcement, new_announcement).await;
}

// Both messages have the same timestamp, but there is one invalid message
#[tokio::test]
async fn test_gossip_store_updates_saving_invalid_message_3() {
    let (_, old_announcement) = gen_rand_node_announcement();
    let mut new_announcement = old_announcement.clone();
    new_announcement.signature = Some(create_invalid_ecdsa_signature());

    check_two_node_announcements_with_one_invalid(old_announcement, new_announcement).await;
}

#[tokio::test]
async fn test_our_own_channel_gossip_message_propagated() {
    crate::fiber::tests::test_utils::init_tracing();
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 6200000000;

    let [mut node_a, mut node_b] = NetworkNode::new_n_interconnected_nodes().await;

    let (_new_channel_id, _funding_tx) = establish_channel_between_nodes(
        &mut node_a,
        &mut node_b,
        true,
        node_a_funding_amount,
        node_b_funding_amount,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
    )
    .await;
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    for node in [&node_a, &node_b] {
        node.with_network_graph(|graph| {
            let channels = graph.channels().collect::<Vec<_>>();
            assert_eq!(channels.len(), 1);

            let channel = channels[0].clone();
            assert!(channel.update_of_node1.is_some());
            assert!(channel.update_of_node2.is_some());

            let nodes = graph.nodes().collect::<Vec<_>>();
            assert_eq!(nodes.len(), 2);
        })
        .await;
    }
}

// We may need to run this test multiple times to check if the gossip messages are really propagated.
#[tokio::test]
async fn test_never_miss_any_message() {
    let (_, announcement) = gen_rand_node_announcement();
    let context = GossipTestingContext::new().await;
    let messages = context.subscribe(Default::default()).await;
    context.save_message(BroadcastMessage::NodeAnnouncement(announcement.clone()));
    tokio::time::sleep(Duration::from_secs(1)).await;
    let messages = messages.read().await;
    assert_eq!(messages.len(), 1);
    assert_eq!(
        messages[0],
        BroadcastMessageWithTimestamp::NodeAnnouncement(announcement)
    );
}


================================================
File: src/fiber/tests/graph.rs
================================================
#![allow(clippy::needless_range_loop)]
use crate::fiber::config::MAX_PAYMENT_TLC_EXPIRY_LIMIT;
use crate::fiber::gossip::GossipMessageStore;
use crate::fiber::graph::{PathFindError, SessionRoute};
use crate::fiber::types::{ChannelUpdateChannelFlags, ChannelUpdateMessageFlags, Pubkey};
use crate::now_timestamp_as_millis_u64;
use crate::{
    fiber::{
        graph::{NetworkGraph, PathEdge},
        network::{get_chain_hash, SendPaymentCommand, SendPaymentData},
        types::{ChannelAnnouncement, ChannelUpdate, Hash256, NodeAnnouncement},
    },
    store::Store,
};
use ckb_types::{
    packed::{OutPoint, Script},
    prelude::Entity,
};
use secp256k1::{PublicKey, SecretKey, XOnlyPublicKey};

use crate::gen_rand_secp256k1_keypair_tuple;

use super::test_utils::TempDir;

// Default tlc expiry delta used in this test environment.
// Should be a value larger than the running duration of the unit tests.
// The value below is 42 minutes.
const TLC_EXPIRY_DELTA_IN_TESTS: u64 = 42 * 60 * 1000;
// Default final tlc expiry delta used in this test environment.
const FINAL_TLC_EXPIRY_DELTA_IN_TESTS: u64 = 43 * 60 * 1000;

fn generate_key_pairs(num: usize) -> Vec<(SecretKey, PublicKey)> {
    let mut keys = vec![];
    for _ in 0..num {
        keys.push(gen_rand_secp256k1_keypair_tuple());
    }
    keys
}

struct MockNetworkGraph {
    pub keys: Vec<PublicKey>,
    pub edges: Vec<(usize, usize, OutPoint)>,
    pub store: Store,
    pub graph: NetworkGraph<Store>,
}

impl MockNetworkGraph {
    pub fn new(node_num: usize) -> Self {
        let temp_path = TempDir::new("test-network-graph");
        let store = Store::new(temp_path).expect("create store failed");
        let keypairs = generate_key_pairs(node_num + 1);
        let (secret_key1, public_key1) = keypairs[0];
        store.save_node_announcement(NodeAnnouncement::new(
            "node0".into(),
            vec![],
            &secret_key1.into(),
            now_timestamp_as_millis_u64(),
            0,
        ));
        for (i, keypair) in keypairs.iter().enumerate().skip(1) {
            let (sk, _pk) = keypair;
            store.save_node_announcement(NodeAnnouncement::new(
                format!("node{i}").as_str().into(),
                vec![],
                &(*sk).into(),
                now_timestamp_as_millis_u64(),
                0,
            ));
        }
        let mut graph = NetworkGraph::new(store.clone(), public_key1.into(), true);
        graph.always_process_gossip_message = true;

        Self {
            keys: keypairs.into_iter().map(|x| x.1).collect(),
            edges: vec![],
            store,
            graph,
        }
    }

    fn set_source(&mut self, source: PublicKey) {
        self.graph.set_source(source.into());
    }

    pub fn mark_node_failed(&mut self, node: usize) {
        self.graph.mark_node_failed(self.keys[node].into());
    }

    pub fn mark_channel_failed(&mut self, node_a: usize, node_b: usize) {
        let outpoint = self
            .edges
            .iter()
            .find(|(a, b, _)| (*a == node_a && *b == node_b) || (*a == node_b && *b == node_a));
        if let Some((_, _, outpoint)) = outpoint {
            self.graph.mark_channel_failed(outpoint);
        }
    }

    // Add an directed edge from node_a to node_b with the given configuration.
    // The capacity is the capacity of the channel, the fee_rate is the fee rate
    // that node_b will charge when forwarding tlc for node_a. The min_tlc_value
    // is the minimum tlc value that node_b will accept when forwarding tlc for node_a.
    // The udt_type_script is the udt type script of the channel. The other_fee_rate
    // is the fee rate that node_a will charge when forwarding tlc for node_b.
    #[allow(clippy::too_many_arguments)]
    pub fn add_edge_with_config(
        &mut self,
        node_a: usize,
        node_b: usize,
        capacity: Option<u128>,
        fee_rate: Option<u128>,
        min_tlc_value: Option<u128>,
        udt_type_script: Option<Script>,
        other_fee_rate: Option<u128>,
    ) {
        let public_key1 = self.keys[node_a];
        let public_key2 = self.keys[node_b];
        let node_a_is_node1 = public_key1 < public_key2;
        let idx = self.edges.len() + 1;
        let channel_outpoint = OutPoint::from_slice(&[idx as u8; 36]).unwrap();
        self.edges.push((node_a, node_b, channel_outpoint.clone()));
        let (node_a_key, node_b_key) = if node_a_is_node1 {
            (public_key1, public_key2)
        } else {
            (public_key2, public_key1)
        };
        self.store.save_channel_announcement(
            now_timestamp_as_millis_u64(),
            ChannelAnnouncement {
                chain_hash: get_chain_hash(),
                node1_id: node_a_key.into(),
                node2_id: node_b_key.into(),
                channel_outpoint: channel_outpoint.clone(),
                node1_signature: None,
                node2_signature: None,
                capacity: capacity.unwrap_or(1000),
                ckb_key: XOnlyPublicKey::from_slice([0x01; 32].as_ref()).unwrap(),
                ckb_signature: None,
                udt_type_script,
                features: 0,
            },
        );
        self.store.save_channel_update(ChannelUpdate::new_unsigned(
            channel_outpoint.clone(),
            now_timestamp_as_millis_u64(),
            if node_a_is_node1 {
                ChannelUpdateMessageFlags::UPDATE_OF_NODE1
            } else {
                ChannelUpdateMessageFlags::UPDATE_OF_NODE2
            },
            ChannelUpdateChannelFlags::empty(),
            TLC_EXPIRY_DELTA_IN_TESTS,
            min_tlc_value.unwrap_or(0),
            fee_rate.unwrap_or(0),
        ));
        if let Some(fee_rate) = other_fee_rate {
            self.store.save_channel_update(ChannelUpdate::new_unsigned(
                channel_outpoint.clone(),
                now_timestamp_as_millis_u64(),
                if node_a_is_node1 {
                    ChannelUpdateMessageFlags::UPDATE_OF_NODE2
                } else {
                    ChannelUpdateMessageFlags::UPDATE_OF_NODE1
                },
                ChannelUpdateChannelFlags::empty(),
                22,
                min_tlc_value.unwrap_or(0),
                fee_rate,
            ));
        }
        self.graph.reload_from_store();
    }

    // Add an directed edge from node_a to node_b with the given capacity and fee rate.
    // The fee rate is the fee rate that node_b will charge when forwarding tlc for node_a.
    pub fn add_edge(
        &mut self,
        node_a: usize,
        node_b: usize,
        capacity: Option<u128>,
        fee_rate: Option<u128>,
    ) {
        self.add_edge_with_config(node_a, node_b, capacity, fee_rate, Some(0), None, None);
    }

    pub fn add_edge_udt(
        &mut self,
        node_a: usize,
        node_b: usize,
        capacity: Option<u128>,
        fee_rate: Option<u128>,
        udt_type_script: Script,
    ) {
        self.add_edge_with_config(
            node_a,
            node_b,
            capacity,
            fee_rate,
            Some(0),
            Some(udt_type_script),
            None,
        );
    }

    pub fn find_path(
        &self,
        source: usize,
        target: usize,
        amount: u128,
        max_fee: u128,
    ) -> Result<Vec<PathEdge>, PathFindError> {
        let source = self.keys[source].into();
        let target = self.keys[target].into();
        self.graph.find_path(
            source,
            target,
            amount,
            Some(max_fee),
            None,
            FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
            MAX_PAYMENT_TLC_EXPIRY_LIMIT,
            false,
            vec![],
        )
    }

    pub fn find_path_udt(
        &self,
        source: usize,
        target: usize,
        amount: u128,
        max_fee: u128,
        udt_type_script: Script,
    ) -> Result<Vec<PathEdge>, PathFindError> {
        let source = self.keys[source].into();
        let target = self.keys[target].into();
        self.graph.find_path(
            source,
            target,
            amount,
            Some(max_fee),
            Some(udt_type_script),
            FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
            MAX_PAYMENT_TLC_EXPIRY_LIMIT,
            false,
            vec![],
        )
    }

    pub fn build_route_with_expect(&self, payment_data: &SendPaymentData, expect: Vec<usize>) {
        let route = self.graph.build_route(payment_data.clone());
        assert!(route.is_ok());
        let route = route.unwrap();
        let nodes = route.iter().filter_map(|x| x.next_hop).collect::<Vec<_>>();
        let expecptected_nodes: Vec<Pubkey> = expect
            .iter()
            .map(|x| self.keys[*x].into())
            .collect::<Vec<_>>();
        assert_eq!(nodes, expecptected_nodes);
    }

    pub fn build_route_with_possible_expects(
        &self,
        payment_data: &SendPaymentData,
        expects: &[Vec<usize>],
    ) {
        let route = self.graph.build_route(payment_data.clone());
        assert!(route.is_ok());
        let route = route.unwrap();
        let nodes = route.iter().filter_map(|x| x.next_hop).collect::<Vec<_>>();
        let expecptected_nodes: Vec<Vec<Pubkey>> = expects
            .iter()
            .map(|x| x.iter().map(|i| self.keys[*i].into()).collect::<Vec<_>>())
            .collect::<Vec<_>>();
        assert!(expecptected_nodes.contains(&nodes));
    }
}

#[test]
fn test_graph_channel_info() {
    let mut mock_network = MockNetworkGraph::new(1);
    mock_network.add_edge(0, 1, Some(1000), Some(1));
    for i in 1..=mock_network.edges.len() {
        let channel_info = mock_network
            .graph
            .get_channel(&OutPoint::from_slice(&[i as u8; 36]).unwrap());
        assert!(channel_info.is_some());
    }
}

#[test]
fn test_graph_graph_apis() {
    let mut mock_network = MockNetworkGraph::new(4);
    let node1 = mock_network.keys[1];
    let node2 = mock_network.keys[2];
    let node3 = mock_network.keys[3];
    assert!(mock_network.graph.get_node(&node1.into()).is_some());
    assert!(mock_network.graph.get_node(&node2.into()).is_some());

    let node1_channels = mock_network.graph.get_channels_by_peer(node1.into());
    assert_eq!(node1_channels.count(), 0);
    let node2_channels = mock_network.graph.get_channels_by_peer(node2.into());
    assert_eq!(node2_channels.count(), 0);

    mock_network.add_edge(1, 2, Some(1000), Some(1));
    let node1_channels = mock_network.graph.get_channels_by_peer(node1.into());
    assert_eq!(node1_channels.count(), 1);
    let node2_channels = mock_network.graph.get_channels_by_peer(node2.into());
    assert_eq!(node2_channels.count(), 1);

    mock_network.add_edge(1, 3, Some(1000), Some(1));
    let node1_channels = mock_network.graph.get_channels_by_peer(node1.into());
    assert_eq!(node1_channels.count(), 2);

    let node1_channels = mock_network.graph.get_channels_by_peer(node3.into());
    assert_eq!(node1_channels.count(), 1);
}

#[test]
fn test_graph_find_path_basic() {
    let mut network = MockNetworkGraph::new(4);
    network.add_edge(1, 2, Some(1), Some(2));
    let node2 = network.keys[2];

    let route = network.find_path(1, 2, 100, 1000);
    assert!(route.is_err());

    network.add_edge(1, 2, Some(120), Some(2));
    let route = network.find_path(1, 2, 100, 1000);
    assert!(route.is_ok());
    let route = route.unwrap();
    assert_eq!(route.len(), 1);
    assert_eq!(route[0].target, node2.into());
    assert_eq!(route[0].channel_outpoint, network.edges[1].2);

    let route = network.find_path(1, 3, 10, 100);
    assert!(route.is_err());
}

#[test]
fn test_graph_find_path_three_nodes() {
    let mut network = MockNetworkGraph::new(3);
    network.add_edge(1, 2, Some(500), Some(2));
    network.add_edge(2, 3, Some(500), Some(2));
    let node2 = network.keys[2];
    let node3 = network.keys[3];

    // Test route from node 1 to node 3
    let route = network.find_path(1, 3, 100, 1000);
    assert!(route.is_ok());
    let route = route.unwrap();
    assert_eq!(route.len(), 2);
    assert_eq!(route[0].target, node2.into());
    assert_eq!(route[1].target, node3.into());
    assert_eq!(route[0].channel_outpoint, network.edges[0].2);
    assert_eq!(route[1].channel_outpoint, network.edges[1].2);

    // Test route from node 1 to node 2
    let route = network.find_path(1, 2, 100, 1000);
    assert!(route.is_ok());
    let route = route.unwrap();
    assert_eq!(route.len(), 1);
    assert_eq!(route[0].target, node2.into());
    assert_eq!(route[0].channel_outpoint, network.edges[0].2);

    // Test route from node 2 to node 3
    let route = network.find_path(2, 3, 100, 1000);
    assert!(route.is_ok());
    let route = route.unwrap();
    assert_eq!(route.len(), 1);
    assert_eq!(route[0].target, node3.into());
    assert_eq!(route[0].channel_outpoint, network.edges[1].2);

    // Test route from node 3 to node 1 (should fail)
    let route = network.find_path(3, 1, 100, 1000);
    assert!(route.is_err());
}

#[test]
fn test_graph_find_path_fee() {
    let mut network = MockNetworkGraph::new(5);

    network.add_edge(1, 2, Some(1000), Some(30000));
    // means node 2 will charge fee_rate 10000 when forwarding tlc

    network.add_edge(2, 4, Some(1000), Some(10000));

    network.add_edge(1, 3, Some(1000), Some(30000));
    // means node 3 will charge fee_rate 30000 when forwarding tlc
    network.add_edge(3, 4, Some(1000), Some(30000));

    let route = network.find_path(1, 4, 100, 1000);

    assert!(route.is_ok());
    let route = route.unwrap();
    eprintln!("route: {:?}", route);

    // make sure we choose the path with lower fees
    assert_eq!(route.len(), 2);

    // assert we choose the second path
    assert_eq!(route[0].channel_outpoint, network.edges[0].2);
    assert_eq!(route[1].channel_outpoint, network.edges[1].2);

    // assert that we have the correct amount received
    assert_eq!(route[0].amount_received, 101);
    assert_eq!(route[1].amount_received, 100);
}

#[test]
fn test_graph_find_path_expiry() {
    let mut network = MockNetworkGraph::new(5);

    network.add_edge(1, 2, Some(1000), Some(10000));
    // means node 2 will charge fee_rate 10000 when forwarding tlc
    network.add_edge(2, 3, Some(1000), Some(30000));

    let route = network.find_path(1, 3, 100, 1000);

    assert!(route.is_ok());
    let route = route.unwrap();
    eprintln!("route: {:?}", route);

    // make sure we choose the path with lower fees
    assert_eq!(route.len(), 2);
    // assert we choose the second path
    assert_eq!(
        route[0].incoming_tlc_expiry - route[1].incoming_tlc_expiry,
        TLC_EXPIRY_DELTA_IN_TESTS
    );
    assert_eq!(
        route[1].incoming_tlc_expiry,
        FINAL_TLC_EXPIRY_DELTA_IN_TESTS
    );
}

#[test]
fn test_graph_find_path_direct_linear() {
    let mut network = MockNetworkGraph::new(6);

    network.add_edge(1, 2, Some(1000), Some(4));
    network.add_edge(2, 3, Some(1000), Some(3));
    network.add_edge(3, 4, Some(1000), Some(2));
    network.add_edge(4, 5, Some(1000), Some(1));

    let route = network.find_path(1, 5, 100, 1000);

    assert!(route.is_ok());
    let route = route.unwrap();

    assert_eq!(route.len(), 4);
    assert_eq!(route[0].channel_outpoint, network.edges[0].2);
    assert_eq!(route[1].channel_outpoint, network.edges[1].2);
    assert_eq!(route[2].channel_outpoint, network.edges[2].2);
    assert_eq!(route[3].channel_outpoint, network.edges[3].2);
}

#[test]
fn test_graph_find_path_cycle() {
    let mut network = MockNetworkGraph::new(6);

    network.add_edge(1, 2, Some(1000), Some(4));
    network.add_edge(2, 3, Some(1000), Some(3));
    network.add_edge(3, 1, Some(1000), Some(2));

    let route = network.find_path(1, 3, 100, 1000);

    assert!(route.is_ok());

    network.add_edge(3, 4, Some(1000), Some(2));
    network.add_edge(4, 5, Some(1000), Some(1));

    let route = network.find_path(1, 5, 100, 1000);
    assert!(route.is_ok());
}

#[test]
fn test_graph_find_path_cycle_in_middle() {
    let mut network = MockNetworkGraph::new(6);

    network.add_edge(1, 2, Some(1000), Some(4));

    network.add_edge(2, 3, Some(1000), Some(3));
    network.add_edge(3, 4, Some(1000), Some(2));
    network.add_edge(4, 2, Some(1000), Some(2));

    network.add_edge(4, 5, Some(1000), Some(1));

    let route = network.find_path(1, 5, 100, 1000);
    assert!(route.is_ok());
}

#[test]
fn test_graph_find_path_loop_exit() {
    let mut network = MockNetworkGraph::new(6);

    // node2 and node3 are connected with each other, node1 is disconnected
    network.add_edge(2, 3, Some(1000), Some(3));
    network.add_edge(3, 2, Some(1000), Some(2));

    let route = network.find_path(1, 3, 100, 1000);
    assert!(route.is_err());

    // now add a path from node1 to node2, so that node1 can reach node3
    network.add_edge(1, 2, Some(1000), Some(4));
    let route = network.find_path(1, 3, 100, 1000);
    assert!(route.is_ok());
}

#[test]
fn test_graph_find_path_amount_failed() {
    let mut network = MockNetworkGraph::new(6);

    network.add_edge(1, 2, Some(1000), Some(4));
    network.add_edge(2, 3, Some(1000), Some(4));
    network.add_edge(3, 4, Some(1000), Some(4));
    network.add_edge(4, 5, Some(1000), Some(1));

    let route = network.find_path(1, 5, 1000, 10);
    assert!(route.is_err());
}

#[test]
fn test_graph_find_optimal_path() {
    let mut network = MockNetworkGraph::new(6);

    // Longer path with lower total fee
    network.add_edge(1, 2, Some(2000), Some(10000));
    network.add_edge(2, 3, Some(2000), Some(10000));
    network.add_edge(3, 4, Some(2000), Some(10000));
    network.add_edge(4, 5, Some(2000), Some(10000));

    // Path with insufficient capacity
    network.add_edge(1, 6, Some(500), Some(10000));
    network.add_edge(6, 5, Some(500), Some(10000));

    // Check that the algorithm chose the longer path with lower fees
    let route = network.find_path(1, 5, 1000, 1000).unwrap();
    assert_eq!(route.len(), 4);
    for (i, edge_index) in (0..=3).enumerate() {
        assert_eq!(route[i].channel_outpoint, network.edges[edge_index].2);
    }

    // Test with a smaller amount that allows using the direct path
    let small_route = network.find_path(1, 5, 100, 100);
    assert!(small_route.is_ok());
    let small_route = small_route.unwrap();

    // Check that the algorithm chose the direct path for a smaller amount
    assert_eq!(small_route.len(), 2);
    assert_eq!(small_route[0].channel_outpoint, network.edges[4].2);
    assert_eq!(small_route[1].channel_outpoint, network.edges[5].2);
}

#[test]
fn test_graph_build_router_is_ok_with_fee_rate() {
    let mut network = MockNetworkGraph::new(6);

    // Direct path with high fee, but there are no middle hop nodes, so there will be no fee
    network.add_edge(1, 5, Some(2000), Some(50000));

    // Longer path with lower total fee
    network.add_edge(1, 2, Some(2000), Some(10000));
    // this node has a very low fee rate
    network.add_edge(2, 3, Some(2000), Some(1));
    network.add_edge(3, 4, Some(2000), Some(10000));
    network.add_edge(4, 5, Some(2000), Some(10000));

    // check the fee rate
    let source = network.keys[1];
    network.set_source(source);
    let node5 = network.keys[5];
    let route = network.graph.build_route(SendPaymentData {
        target_pubkey: node5.into(),
        amount: 1000,
        payment_hash: Hash256::default(),
        invoice: None,
        final_tlc_expiry_delta: FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        tlc_expiry_limit: MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        timeout: None,
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: false,
        udt_type_script: None,
        preimage: None,
        allow_self_payment: false,
        hop_hints: vec![],
        dry_run: false,
    });
    assert!(route.is_ok());
    let route = route.unwrap();
    let amounts = route.iter().map(|x| x.amount).collect::<Vec<_>>();
    assert_eq!(amounts, vec![1000, 1000]);
}

#[test]
fn test_graph_build_router_fee_rate_optimize() {
    let mut network = MockNetworkGraph::new(10);

    // Direct path with low total fee rate
    network.add_edge(1, 6, Some(2000), Some(50000));
    network.add_edge(6, 5, Some(2000), Some(50000));

    // Longer path with lower total fee
    network.add_edge(1, 2, Some(2000), Some(10000));
    network.add_edge(2, 3, Some(2000), Some(20000));
    network.add_edge(3, 4, Some(2000), Some(30000));
    network.add_edge(4, 5, Some(2000), Some(40000));

    // check the fee rate
    let source = network.keys[1];
    network.set_source(source);
    let node5 = network.keys[5];
    let route = network.graph.build_route(SendPaymentData {
        target_pubkey: node5.into(),
        amount: 1000,
        payment_hash: Hash256::default(),
        invoice: None,
        final_tlc_expiry_delta: FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        tlc_expiry_limit: MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        timeout: None,
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: false,
        udt_type_script: None,
        preimage: None,
        allow_self_payment: false,
        hop_hints: vec![],
        dry_run: false,
    });
    assert!(route.is_ok());
    let route = route.unwrap();
    let amounts = route.iter().map(|x| x.amount).collect::<Vec<_>>();
    assert_eq!(amounts, vec![1050, 1000, 1000]);
}

#[test]
fn test_graph_build_router_no_fee_with_direct_pay() {
    let mut network = MockNetworkGraph::new(10);

    network.add_edge(1, 5, Some(2000), Some(50000));

    // check the fee rate
    let source = network.keys[1];
    network.set_source(source);
    let node5 = network.keys[5];
    let route = network.graph.build_route(SendPaymentData {
        target_pubkey: node5.into(),
        amount: 1000,
        payment_hash: Hash256::default(),
        invoice: None,
        final_tlc_expiry_delta: FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        tlc_expiry_limit: MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        timeout: None,
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: false,
        udt_type_script: None,
        preimage: None,
        allow_self_payment: false,
        hop_hints: vec![],
        dry_run: false,
    });
    assert!(route.is_ok());
    let route = route.unwrap();
    let amounts = route.iter().map(|x| x.amount).collect::<Vec<_>>();
    assert_eq!(amounts, vec![1000, 1000]);
}

#[test]
fn test_graph_find_path_err() {
    let mut network = MockNetworkGraph::new(6);
    let node1 = network.keys[1];

    network.add_edge(1, 2, Some(1000), Some(4));
    let route = network.find_path(1, 1, 100, 1000);
    assert!(route.is_err());

    let no_exits_public_key = network.keys[0];
    let route = network.graph.find_path(
        node1.into(),
        no_exits_public_key.into(),
        100,
        Some(1000),
        None,
        FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        false,
        vec![],
    );
    assert!(route.is_err());

    let route = network.graph.find_path(
        no_exits_public_key.into(),
        node1.into(),
        100,
        Some(1000),
        None,
        FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        false,
        vec![],
    );
    assert!(route.is_err());
}

#[test]
fn test_graph_find_path_node_order() {
    let mut network = MockNetworkGraph::new(6);
    let node1 = network.keys[1];
    let node2 = network.keys[2];
    let node3 = network.keys[3];

    network.add_edge(1, 2, Some(1000), Some(4));
    network.add_edge(2, 3, Some(1000), Some(4));

    let route = network.graph.find_path(
        node1.into(),
        node3.into(),
        100,
        Some(1000),
        None,
        FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        false,
        vec![],
    );
    assert!(route.is_ok());
    // check the order of nodes in router is node1 -> node2 -> node3
    let route = route.unwrap();
    assert_eq!(route.len(), 2);
    assert_eq!(route[0].target, node2.into());
    assert_eq!(route[1].target, node3.into());
}

#[test]
fn test_graph_build_route_with_expiry_limit() {
    let mut network = MockNetworkGraph::new(6);
    let (node1, node2) = (network.keys[1], network.keys[2]);

    network.add_edge(1, 2, Some(1000), Some(4));

    let route = network.graph.find_path(
        node1.into(),
        node2.into(),
        100,
        Some(1000),
        None,
        FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        false,
        vec![],
    );
    assert!(route.is_ok());

    let route = network.graph.find_path(
        node1.into(),
        node2.into(),
        100,
        Some(1000),
        None,
        FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        100,
        false,
        vec![],
    );
    assert!(route.is_err());
}

#[test]
fn test_graph_build_route_three_nodes_amount() {
    let mut network = MockNetworkGraph::new(3);
    network.add_edge(0, 2, Some(500), Some(200000));
    network.add_edge(2, 3, Some(500), Some(20000));
    let node2 = network.keys[2];
    let node3 = network.keys[3];
    // Test build route from node1 to node3
    let route = network.graph.build_route(SendPaymentData {
        target_pubkey: node3.into(),
        amount: 100,
        payment_hash: Hash256::default(),
        invoice: None,
        final_tlc_expiry_delta: FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        tlc_expiry_limit: MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: false,
        udt_type_script: None,
        preimage: None,
        allow_self_payment: false,
        hop_hints: vec![],
        dry_run: false,
    });
    assert!(route.is_ok());
    let route = route.unwrap();
    assert_eq!(route.len(), 3);
    assert_eq!(
        route[0].funding_tx_hash,
        network.edges[0].2.tx_hash().into()
    );
    assert_eq!(
        route[1].funding_tx_hash,
        network.edges[1].2.tx_hash().into()
    );

    assert_eq!(route[0].next_hop, Some(node2.into()));
    assert_eq!(route[1].next_hop, Some(node3.into()));
    assert_eq!(route[2].next_hop, None);

    assert_eq!(route[0].amount, 102);
    assert_eq!(route[1].amount, 100);
    assert_eq!(route[2].amount, 100);
}

// TODO: pass randomized input to this function.
fn do_test_graph_build_route_expiry(n_nodes: usize) {
    let mut network = MockNetworkGraph::new(n_nodes);
    let ns = (0..n_nodes).collect::<Vec<_>>();
    for window in ns.windows(2) {
        let source = window[0];
        let target = window[1];
        network.add_edge(source, target, Some(500000), Some(0));
    }
    let last_node = network.keys[n_nodes - 1];
    let timestamp_before_building_route = now_timestamp_as_millis_u64();
    // Send a payment from the first node to the last node
    let route = network.graph.build_route(SendPaymentData {
        target_pubkey: last_node.into(),
        amount: 100,
        payment_hash: Hash256::default(),
        invoice: None,
        final_tlc_expiry_delta: FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        tlc_expiry_limit: MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: false,
        udt_type_script: None,
        preimage: None,
        allow_self_payment: false,
        hop_hints: vec![],
        dry_run: false,
    });
    let timestamp_after_building_route = now_timestamp_as_millis_u64();
    assert!(route.is_ok());
    let route = route.unwrap();
    assert_eq!(route.len(), n_nodes);
    for i in 0..(n_nodes - 1) {
        assert_eq!(
            route[i].funding_tx_hash,
            network.edges[i].2.tx_hash().into()
        );
        assert_eq!(route[i].next_hop, Some(network.keys[i + 1].into()));
    }

    assert_eq!(route[n_nodes - 1].next_hop, None);
    assert_eq!(route[n_nodes - 1].funding_tx_hash, Default::default());

    for i in 0..n_nodes - 1 {
        assert!(
            route[i].expiry
                <= timestamp_after_building_route
                    + TLC_EXPIRY_DELTA_IN_TESTS * ((n_nodes - i - 2) as u64)
                    + FINAL_TLC_EXPIRY_DELTA_IN_TESTS
        );
        assert!(
            route[i].expiry
                >= timestamp_before_building_route
                    + TLC_EXPIRY_DELTA_IN_TESTS * ((n_nodes - i - 2) as u64)
                    + FINAL_TLC_EXPIRY_DELTA_IN_TESTS
        );
    }
    assert_eq!(route[n_nodes - 1].expiry, route[n_nodes - 2].expiry);
}

#[test]
fn test_graph_build_route_2_nodes_expiry() {
    do_test_graph_build_route_expiry(2);
}

#[test]
fn test_graph_build_route_3_nodes_expiry() {
    do_test_graph_build_route_expiry(3);
}

#[test]
fn test_graph_build_route_4_nodes_expiry() {
    do_test_graph_build_route_expiry(4);
}

#[test]
fn test_graph_build_route_99_nodes_expiry() {
    do_test_graph_build_route_expiry(99);
}

#[test]
fn test_graph_build_route_below_min_tlc_value() {
    let mut network = MockNetworkGraph::new(3);
    // Add edges with min_tlc_value set to 50
    network.add_edge_with_config(0, 2, Some(500), Some(2), Some(50), None, None);
    network.add_edge_with_config(2, 3, Some(500), Some(2), Some(50), None, None);
    let node3 = network.keys[3];

    // Test build route from node1 to node3 with amount below min_tlc_value
    let route = network.graph.build_route(SendPaymentData {
        target_pubkey: node3.into(),
        amount: 10, // Below min_tlc_value of 50
        payment_hash: Hash256::default(),
        invoice: None,
        final_tlc_expiry_delta: FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        tlc_expiry_limit: MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: false,
        udt_type_script: None,
        preimage: None,
        allow_self_payment: false,
        hop_hints: vec![],
        dry_run: false,
    });
    assert!(route.is_err());
}

#[test]
fn test_graph_build_route_select_edge_with_latest_timestamp() {
    let mut network = MockNetworkGraph::new(3);
    // Add edges with min_tlc_value set to 50
    network.add_edge_with_config(0, 2, Some(500), Some(2), Some(50), None, None);
    // sleep 100 ms
    std::thread::sleep(std::time::Duration::from_millis(100));
    network.add_edge_with_config(0, 2, Some(500), Some(2), Some(50), None, None);
    let node2 = network.keys[2];

    let route = network.graph.build_route(SendPaymentData {
        target_pubkey: node2.into(),
        amount: 100,
        payment_hash: Hash256::default(),
        invoice: None,
        final_tlc_expiry_delta: FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        tlc_expiry_limit: MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: false,
        udt_type_script: None,
        preimage: None,
        allow_self_payment: false,
        hop_hints: vec![],
        dry_run: false,
    });
    assert!(route.is_ok());
    eprintln!("got route {:?}", route);
    let route = route.unwrap();
    assert_eq!(route.len(), 2);
    // assert we use the second added edge
    assert_eq!(
        route[0].funding_tx_hash,
        network.edges[1].2.tx_hash().into()
    );
}

#[test]
fn test_graph_build_route_select_edge_with_large_capacity() {
    let mut network = MockNetworkGraph::new(3);
    // Add edges with min_tlc_value set to 50
    network.add_edge_with_config(0, 2, Some(501), Some(2), Some(50), None, None);
    // sleep 100 ms
    std::thread::sleep(std::time::Duration::from_millis(100));
    network.add_edge_with_config(0, 2, Some(500), Some(2), Some(50), None, None);
    let node2 = network.keys[2];

    let route = network.graph.build_route(SendPaymentData {
        target_pubkey: node2.into(),
        amount: 100,
        payment_hash: Hash256::default(),
        invoice: None,
        final_tlc_expiry_delta: FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        tlc_expiry_limit: MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: false,
        udt_type_script: None,
        preimage: None,
        allow_self_payment: false,
        hop_hints: vec![],
        dry_run: false,
    });
    assert!(route.is_ok());
    let route = route.unwrap();
    assert_eq!(route.len(), 2);
    // assert we use the first edge with large capacity
    assert_eq!(
        route[0].funding_tx_hash,
        network.edges[0].2.tx_hash().into()
    );
}

#[test]
fn test_graph_find_path_udt() {
    let mut network = MockNetworkGraph::new(3);
    let udt_type_script = Script::default();
    network.add_edge_udt(1, 2, Some(1000), Some(1), udt_type_script.clone());
    let node2 = network.keys[2];

    let route = network.find_path_udt(1, 2, 100, 1000, udt_type_script.clone());
    assert!(route.is_ok());

    let route = route.unwrap();
    assert_eq!(route.len(), 1);
    assert_eq!(route[0].target, node2.into());
    assert_eq!(route[0].channel_outpoint, network.edges[0].2);

    let route = network.find_path(1, 3, 10, 100);
    assert!(route.is_err());
}

#[test]
fn test_graph_mark_failed_channel() {
    let mut network = MockNetworkGraph::new(5);
    network.add_edge(0, 2, Some(500), Some(2));
    network.add_edge(2, 3, Some(500), Some(2));
    let node3 = network.keys[3];

    network.mark_channel_failed(2, 3);
    // Test build route from node1 to node3
    let route = network.graph.build_route(SendPaymentData {
        target_pubkey: node3.into(),
        amount: 100,
        payment_hash: Hash256::default(),
        invoice: None,
        final_tlc_expiry_delta: FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        tlc_expiry_limit: MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: false,
        udt_type_script: None,
        preimage: None,
        allow_self_payment: false,
        hop_hints: vec![],
        dry_run: false,
    });
    assert!(route.is_err());

    network.add_edge(0, 5, Some(500), Some(2));
    network.add_edge(5, 3, Some(500), Some(2));

    // Test build route from node1 to node3
    let route = network.graph.build_route(SendPaymentData {
        target_pubkey: node3.into(),
        amount: 100,
        payment_hash: Hash256::default(),
        invoice: None,
        final_tlc_expiry_delta: FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        tlc_expiry_limit: MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: false,
        udt_type_script: None,
        preimage: None,
        allow_self_payment: false,
        hop_hints: vec![],
        dry_run: false,
    });
    assert!(route.is_ok());
}

#[test]
fn test_graph_session_router() {
    let mut network = MockNetworkGraph::new(5);
    network.add_edge(0, 2, Some(500), Some(50000));
    network.add_edge(2, 3, Some(500), Some(20000));
    network.add_edge(3, 4, Some(500), Some(2));

    let node0 = network.keys[0];
    let node2 = network.keys[2];
    let node3 = network.keys[3];
    let node4 = network.keys[4];

    // Test build route from node1 to node4 should be Ok
    let route = network.graph.build_route(SendPaymentData {
        target_pubkey: node4.into(),
        amount: 100,
        payment_hash: Hash256::default(),
        invoice: None,
        final_tlc_expiry_delta: FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        tlc_expiry_limit: MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: false,
        udt_type_script: None,
        preimage: None,
        allow_self_payment: false,
        hop_hints: vec![],
        dry_run: false,
    });
    assert!(route.is_ok());

    let route = route.unwrap();
    let session_route = SessionRoute::new(node0.into(), node4.into(), &route);
    let fee = session_route.fee();
    // round_up(101 * 2000 / 1000000) = 3, so the total amount = 101 + 3 = 104
    assert_eq!(route[0].amount, 104);
    assert_eq!(route[1].amount, 101);
    assert_eq!(route[2].amount, 100);
    assert_eq!(route[3].amount, 100);
    assert_eq!(fee, 4);
    let session_route_keys: Vec<_> = session_route.nodes.iter().map(|x| x.pubkey).collect();
    assert_eq!(
        session_route_keys,
        vec![node0.into(), node2.into(), node3.into(), node4.into()]
    );
}

#[test]
fn test_graph_mark_failed_node() {
    let mut network = MockNetworkGraph::new(5);
    network.add_edge(0, 2, Some(500), Some(2));
    network.add_edge(2, 3, Some(500), Some(2));
    network.add_edge(2, 4, Some(500), Some(2));

    let node3 = network.keys[3];
    let node4 = network.keys[4];

    // Test build route from node1 to node3
    let route = network.graph.build_route(SendPaymentData {
        target_pubkey: node3.into(),
        amount: 100,
        payment_hash: Hash256::default(),
        invoice: None,
        final_tlc_expiry_delta: FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        tlc_expiry_limit: MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: false,
        udt_type_script: None,
        preimage: None,
        allow_self_payment: false,
        hop_hints: vec![],
        dry_run: false,
    });
    assert!(route.is_ok());

    // Test build route from node1 to node4 should be Ok
    let route = network.graph.build_route(SendPaymentData {
        target_pubkey: node4.into(),
        amount: 100,
        payment_hash: Hash256::default(),
        invoice: None,
        final_tlc_expiry_delta: FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        tlc_expiry_limit: MAX_PAYMENT_TLC_EXPIRY_LIMIT,

        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: false,
        udt_type_script: None,
        preimage: None,
        allow_self_payment: false,
        hop_hints: vec![],
        dry_run: false,
    });
    assert!(route.is_ok());

    network.mark_node_failed(2);

    // Test build route from node1 to node3
    let route = network.graph.build_route(SendPaymentData {
        target_pubkey: node3.into(),
        amount: 100,
        payment_hash: Hash256::default(),
        invoice: None,
        final_tlc_expiry_delta: FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        tlc_expiry_limit: MAX_PAYMENT_TLC_EXPIRY_LIMIT,

        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: false,
        udt_type_script: None,
        preimage: None,
        allow_self_payment: false,
        hop_hints: vec![],
        dry_run: false,
    });
    assert!(route.is_err());

    // Test build route from node1 to node4
    let route = network.graph.build_route(SendPaymentData {
        target_pubkey: node4.into(),
        amount: 100,
        payment_hash: Hash256::default(),
        invoice: None,
        final_tlc_expiry_delta: FINAL_TLC_EXPIRY_DELTA_IN_TESTS,
        tlc_expiry_limit: MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: false,
        udt_type_script: None,
        preimage: None,
        allow_self_payment: false,
        hop_hints: vec![],
        dry_run: false,
    });
    assert!(route.is_err());
}

#[test]
fn test_graph_payment_self_default_is_false() {
    let mut network = MockNetworkGraph::new(5);
    network.add_edge(0, 2, Some(500), Some(2));
    network.add_edge(2, 3, Some(500), Some(2));
    network.add_edge(2, 4, Some(500), Some(2));

    let node0 = network.keys[0];

    // node0 is the source node
    let command = SendPaymentCommand {
        target_pubkey: Some(node0.into()),
        amount: Some(100),
        payment_hash: Some(Hash256::default()),
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,
        invoice: None,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: Some(false),
        udt_type_script: None,
        allow_self_payment: false,
        hop_hints: None,
        dry_run: false,
    };
    let payment_data = SendPaymentData::new(command);
    assert!(payment_data.is_ok());

    let route = network.graph.build_route(payment_data.unwrap());
    assert!(route.is_err());
    let message = route.unwrap_err().to_string();
    assert!(message.contains("allow_self_payment is not enable, can not pay to self"));
}

#[test]
fn test_graph_payment_pay_single_path() {
    let mut network = MockNetworkGraph::new(9);
    network.add_edge(0, 2, Some(500), Some(2));
    network.add_edge(2, 3, Some(500), Some(2));
    network.add_edge(2, 4, Some(500), Some(2));
    network.add_edge(4, 5, Some(500), Some(2));
    network.add_edge(5, 6, Some(500), Some(2));

    // node0 is the source node
    let command = SendPaymentCommand {
        target_pubkey: Some(network.keys[6].into()),
        amount: Some(100),
        payment_hash: Some(Hash256::default()),
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,
        invoice: None,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: Some(false),
        udt_type_script: None,
        allow_self_payment: true,
        hop_hints: None,
        dry_run: false,
    };
    let payment_data = SendPaymentData::new(command);
    assert!(payment_data.is_ok());
    let payment_data = payment_data.unwrap();

    network.add_edge(4, 0, Some(1000), Some(2));
    network.build_route_with_expect(&payment_data, vec![2, 4, 5, 6]);
}

#[test]
fn test_graph_payment_pay_self_with_one_node() {
    let mut network = MockNetworkGraph::new(9);
    network.add_edge(0, 2, Some(500), Some(2));
    network.add_edge(2, 0, Some(500), Some(2));

    let node0 = network.keys[0];

    // node0 is the source node
    let command = SendPaymentCommand {
        target_pubkey: Some(network.keys[0].into()),
        amount: Some(100),
        payment_hash: Some(Hash256::default()),
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,
        invoice: None,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: Some(false),
        udt_type_script: None,
        allow_self_payment: true,
        hop_hints: None,
        dry_run: false,
    };
    let payment_data = SendPaymentData::new(command);
    assert!(payment_data.is_ok());
    let payment_data = payment_data.unwrap();

    let route = network.graph.build_route(payment_data);
    assert!(route.is_ok());
    let route = route.unwrap();
    assert_eq!(route[1].next_hop, Some(node0.into()));
}

#[test]
fn test_graph_payment_pay_self_with_one_node_fee_rate() {
    let mut network = MockNetworkGraph::new(9);
    network.add_edge(0, 2, Some(500), Some(2));
    network.add_edge(2, 0, Some(500), Some(200000));

    let node0 = network.keys[0];

    // node0 is the source node
    let command = SendPaymentCommand {
        target_pubkey: Some(network.keys[0].into()),
        amount: Some(100),
        payment_hash: Some(Hash256::default()),
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,
        invoice: None,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: Some(false),
        udt_type_script: None,
        allow_self_payment: true,
        hop_hints: None,
        dry_run: false,
    };
    let payment_data = SendPaymentData::new(command);
    assert!(payment_data.is_ok());
    let payment_data = payment_data.unwrap();

    let route = network.graph.build_route(payment_data);
    assert!(route.is_ok());
    let route = route.unwrap();
    assert_eq!(route.len(), 3);
    assert_eq!(route[0].amount, 120);
    assert_eq!(route[1].amount, 100);
    assert_eq!(route[2].amount, 100);
    assert_eq!(route[1].next_hop, Some(node0.into()));
}

#[test]
fn test_graph_build_route_with_double_edge_node() {
    let mut network = MockNetworkGraph::new(3);
    // Add edges with min_tlc_value set to 50
    // A <-> B, A is initiator, and A -> B with fee rate 5000, B -> A with fee rate 600000
    network.add_edge_with_config(0, 2, Some(500), Some(5000), Some(50), None, Some(600000));
    // A -> B, B is initiator, B -> A with fee rate 100000, A -> B with fee rate 200
    network.add_edge_with_config(2, 0, Some(500), Some(100000), Some(50), None, Some(200));

    // node0 is the source node
    let command = SendPaymentCommand {
        target_pubkey: Some(network.keys[0].into()),
        amount: Some(100),
        payment_hash: Some(Hash256::default()),
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,
        invoice: None,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: Some(false),
        udt_type_script: None,
        allow_self_payment: true,
        hop_hints: None,
        dry_run: false,
    };
    let payment_data = SendPaymentData::new(command).unwrap();
    let route = network.graph.build_route(payment_data);
    assert!(route.is_ok());
}

#[test]
fn test_graph_build_route_with_other_node_maybe_better() {
    let mut network = MockNetworkGraph::new(3);
    // Add edges with min_tlc_value set to 50
    // A <-> B, A is initiator, and A -> B with fee rate 5000, B -> A with fee rate 600000
    network.add_edge_with_config(0, 2, Some(500), Some(600000), Some(50), None, Some(600000));
    // A -> B, B is initiator, B -> A with fee rate 100000, A -> B with fee rate 200
    network.add_edge_with_config(2, 0, Some(500), Some(100000), Some(50), None, Some(600000));
    // B <-> C, B is initiator
    network.add_edge_with_config(2, 3, Some(500), Some(2), Some(50), None, Some(1));

    let node0 = network.keys[0];
    let node1 = network.keys[2];

    // node0 is the source node
    let command = SendPaymentCommand {
        target_pubkey: Some(network.keys[0].into()),
        amount: Some(100),
        payment_hash: Some(Hash256::default()),
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,
        invoice: None,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: Some(false),
        udt_type_script: None,
        allow_self_payment: true,
        hop_hints: None,
        dry_run: false,
    };
    let payment_data = SendPaymentData::new(command).unwrap();
    let route = network.graph.build_route(payment_data);
    assert!(route.is_ok());
    let route = route.unwrap();
    assert_eq!(route[0].next_hop, Some(node1.into()));
    assert_eq!(route[1].next_hop, Some(node0.into()));
}

#[test]
fn test_graph_payment_pay_self_will_ok() {
    let mut network = MockNetworkGraph::new(9);
    network.add_edge(0, 2, Some(500), Some(2));
    network.add_edge(2, 3, Some(500), Some(2));
    network.add_edge(2, 4, Some(500), Some(2));
    network.add_edge(4, 5, Some(500), Some(2));
    network.add_edge(5, 6, Some(500), Some(2));

    // node0 is the source node
    let command = SendPaymentCommand {
        target_pubkey: Some(network.keys[0].into()),
        amount: Some(100),
        payment_hash: Some(Hash256::default()),
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,
        invoice: None,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: Some(false),
        udt_type_script: None,
        allow_self_payment: true,
        hop_hints: None,
        dry_run: false,
    };
    let payment_data = SendPaymentData::new(command);
    assert!(payment_data.is_ok());
    let payment_data = payment_data.unwrap();

    let route = network.graph.build_route(payment_data.clone());
    // since we don't have a route to node0, it will fail
    assert!(route.is_err());

    // add a long path
    let mut possible_expects = vec![];
    network.add_edge(6, 0, Some(500), Some(2));
    possible_expects.push(vec![2, 4, 5, 6, 0]);
    network.build_route_with_possible_expects(&payment_data, &possible_expects);

    // now add another shorter path
    network.add_edge(4, 0, Some(1000), Some(2));
    possible_expects.push(vec![2, 4, 0]);
    network.build_route_with_possible_expects(&payment_data, &possible_expects);

    // now add another shorter path
    network.add_edge(2, 0, Some(1000), Some(2));
    possible_expects.push(vec![2, 0]);
    network.build_route_with_possible_expects(&payment_data, &possible_expects);
}

#[test]
fn test_graph_build_route_with_path_limits() {
    let mut network = MockNetworkGraph::new(100);
    // Add edges with min_tlc_value set to 50
    let mut fee_rate = 100000;
    for i in 0..99 {
        fee_rate -= 1000;
        network.add_edge_with_config(
            i,
            i + 1,
            Some(5000000),
            Some(fee_rate),
            Some(50),
            None,
            Some(100),
        );
    }

    let node99 = network.keys[99];

    // node0 is the source node
    let command = SendPaymentCommand {
        target_pubkey: Some(node99.into()),
        amount: Some(100),
        payment_hash: Some(Hash256::default()),
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,
        invoice: None,
        timeout: Some(10),
        max_fee_amount: Some(10000000),
        max_parts: None,
        keysend: Some(false),
        udt_type_script: None,
        allow_self_payment: true,
        hop_hints: None,
        dry_run: false,
    };
    let payment_data = SendPaymentData::new(command).unwrap();
    let route = network.graph.build_route(payment_data);
    assert!(route.is_ok());
    let route = route.unwrap();
    assert_eq!(route.len(), 100);
    assert_eq!(route[98].next_hop, Some(node99.into()));

    // make sure the fee is decreasing
    let mut fees = vec![];
    for i in 0..98 {
        fees.push(route[i].amount - route[i + 1].amount);
    }
    assert!(fees.windows(2).all(|x| x[0] >= x[1]));
}

#[test]
fn test_graph_build_route_with_path_limit_fail_with_fee_not_enough() {
    let mut network = MockNetworkGraph::new(100);
    // Add edges with min_tlc_value set to 50
    for i in 0..99 {
        network.add_edge_with_config(
            i,
            i + 1,
            Some(100), // the capacity can not provide the fee with long path
            Some(500),
            Some(50),
            None,
            Some(100),
        );
    }

    let node99 = network.keys[99];

    // node0 is the source node
    let command = SendPaymentCommand {
        target_pubkey: Some(node99.into()),
        amount: Some(100),
        payment_hash: Some(Hash256::default()),
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,
        invoice: None,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: Some(false),
        udt_type_script: None,
        allow_self_payment: true,
        hop_hints: None,
        dry_run: false,
    };
    let payment_data = SendPaymentData::new(command).unwrap();
    let route = network.graph.build_route(payment_data);
    assert!(route.is_err());
}

#[test]
fn test_graph_payment_expiry_is_in_right_order() {
    let mut network = MockNetworkGraph::new(5);
    network.add_edge(0, 1, Some(500), Some(2));
    network.add_edge(1, 2, Some(500), Some(2));
    network.add_edge(2, 3, Some(500), Some(2));

    let node3 = network.keys[3];

    let command = SendPaymentCommand {
        target_pubkey: Some(node3.into()),
        amount: Some(100),
        payment_hash: Some(Hash256::default()),
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,
        invoice: None,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: Some(false),
        udt_type_script: None,
        allow_self_payment: false,
        hop_hints: None,
        dry_run: false,
    };
    let payment_data = SendPaymentData::new(command);
    assert!(payment_data.is_ok());

    let current_time = now_timestamp_as_millis_u64();
    let route = network.graph.build_route(payment_data.unwrap());
    assert!(route.is_ok());
    let route = route.unwrap();
    let expiries = route.iter().map(|e| e.expiry).collect::<Vec<_>>();
    assert_eq!(expiries.len(), 4);
    assert_eq!(expiries[0] - expiries[1], TLC_EXPIRY_DELTA_IN_TESTS);
    assert_eq!(expiries[1] - expiries[2], TLC_EXPIRY_DELTA_IN_TESTS);
    assert_eq!(expiries[2], expiries[3]);
    assert!(expiries[3] >= current_time + FINAL_TLC_EXPIRY_DELTA_IN_TESTS);

    let final_tlc_expiry_delta = 987654;
    let command = SendPaymentCommand {
        target_pubkey: Some(node3.into()),
        amount: Some(100),
        payment_hash: Some(Hash256::default()),
        final_tlc_expiry_delta: Some(final_tlc_expiry_delta),
        tlc_expiry_limit: None,
        invoice: None,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: Some(false),
        udt_type_script: None,
        allow_self_payment: false,
        hop_hints: None,
        dry_run: false,
    };
    let payment_data = SendPaymentData::new(command);
    assert!(payment_data.is_ok());

    let current_time = now_timestamp_as_millis_u64();
    let route = network.graph.build_route(payment_data.unwrap());
    assert!(route.is_ok());
    let route = route.unwrap();
    let expiries = route.iter().map(|e| e.expiry).collect::<Vec<_>>();
    assert_eq!(expiries.len(), 4);
    assert!(expiries[3] >= current_time + final_tlc_expiry_delta);
}


================================================
File: src/fiber/tests/hash_algorithm.rs
================================================
use crate::fiber::hash_algorithm::HashAlgorithm;

#[test]
fn test_hash_algorithm_serialization_sha256() {
    let algorithm = HashAlgorithm::Sha256;
    let serialized = serde_json::to_string(&algorithm).expect("hash algorithm to json");
    assert_eq!(serialized, r#""sha256""#);
    let deserialized: HashAlgorithm =
        serde_json::from_str(&serialized).expect("hash algorithm from json");
    assert_eq!(deserialized, algorithm);
}

#[test]
fn test_hash_algorithm_serialization_ckb_hash() {
    let algorithm = HashAlgorithm::CkbHash;
    let serialized = serde_json::to_string(&algorithm).expect("hash algorithm to json");
    assert_eq!(serialized, r#""ckb_hash""#);
    let deserialized: HashAlgorithm =
        serde_json::from_str(&serialized).expect("hash algorithm from json");
    assert_eq!(deserialized, algorithm);
}


================================================
File: src/fiber/tests/history.rs
================================================
use crate::fiber::graph::SessionRouteNode;
use crate::fiber::history::output_direction;
use crate::fiber::history::{Direction, DEFAULT_BIMODAL_DECAY_TIME};
use crate::fiber::history::{InternalPairResult, InternalResult};
use crate::fiber::history::{PaymentHistory, TimedResult};
use crate::fiber::tests::test_utils::{generate_store, TempDir};
use crate::store::Store;
use crate::{gen_rand_channel_outpoint, gen_rand_fiber_public_key, now_timestamp_as_millis_u64};
use ckb_types::packed::OutPoint;

trait Round {
    fn round_to_2(self) -> f64;
}

impl Round for f64 {
    fn round_to_2(self) -> f64 {
        (self * 100.0).round() / 100.0
    }
}

#[test]
fn test_history() {
    let mut history = PaymentHistory::new(gen_rand_fiber_public_key(), None, generate_store());
    let channel_outpoint = OutPoint::default();
    let direction = Direction::Forward;

    let result1 = TimedResult {
        fail_time: 1,
        fail_amount: 2,
        success_time: 3,
        success_amount: 4,
    };
    history.add_result(channel_outpoint.clone(), direction, result1);
    assert_eq!(
        history.get_result(&channel_outpoint.clone(), direction),
        Some(&result1)
    );

    let channel_outpoint2 = gen_rand_channel_outpoint();
    let result2 = TimedResult {
        fail_time: 5,
        fail_amount: 6,
        success_time: 7,
        success_amount: 8,
    };

    history.add_result(channel_outpoint2.clone(), Direction::Backward, result2);
    assert_eq!(
        history.get_result(&channel_outpoint2, Direction::Backward),
        Some(&result2)
    );
    assert_eq!(
        history.get_result(&channel_outpoint2, Direction::Forward),
        None,
    );
}

#[test]
fn test_history_apply_channel_result() {
    let mut history = PaymentHistory::new(gen_rand_fiber_public_key(), None, generate_store());
    let channel_outpoint = OutPoint::default();
    let direction = Direction::Forward;

    history.apply_pair_result(channel_outpoint.clone(), direction, 10, false, 11);
    assert_eq!(
        history.get_result(&channel_outpoint, direction),
        Some(&TimedResult {
            fail_time: 11,
            fail_amount: 10,
            success_time: 0,
            success_amount: 0,
        })
    );

    let channel_outpoint2 = gen_rand_channel_outpoint();
    let direction_2 = Direction::Backward;
    history.apply_pair_result(channel_outpoint2.clone(), direction_2, 10, true, 12);
    assert_eq!(
        history.get_result(&channel_outpoint2, direction_2),
        Some(&TimedResult {
            fail_time: 0,
            fail_amount: 0,
            success_time: 12,
            success_amount: 10,
        })
    );
}

#[test]
fn test_history_internal_result() {
    let mut internal_result = InternalResult::default();
    let from = gen_rand_fiber_public_key();
    let target = gen_rand_fiber_public_key();
    let channel_outpoint = gen_rand_channel_outpoint();
    let (direction, rev_direction) = output_direction(from, target);
    internal_result.add(from, target, channel_outpoint.clone(), 10, 11, true);
    assert_eq!(internal_result.pairs.len(), 1);
    assert_eq!(
        internal_result
            .pairs
            .get(&(channel_outpoint.clone(), direction))
            .unwrap(),
        &InternalPairResult {
            amount: 11,
            success: true,
            time: 10
        }
    );

    assert_eq!(
        internal_result
            .pairs
            .get(&(channel_outpoint.clone(), rev_direction)),
        None,
    );

    assert_eq!(internal_result.pairs.len(), 1);
    internal_result.add_fail_pair(from, target, channel_outpoint.clone());
    assert_eq!(internal_result.pairs.len(), 2);

    let res = internal_result
        .pairs
        .get(&(channel_outpoint.clone(), direction))
        .unwrap();
    assert_eq!(res.amount, 0);
    assert!(!res.success);
    assert_ne!(res.time, 0);

    let res = internal_result
        .pairs
        .get(&(channel_outpoint.clone(), rev_direction))
        .unwrap();
    assert_eq!(res.amount, 0);
    assert!(!res.success);
    assert_ne!(res.time, 0);

    internal_result.add_fail_pair_balanced(from, target, channel_outpoint.clone(), 100);
    assert_eq!(internal_result.pairs.len(), 2);
    let res = internal_result
        .pairs
        .get(&(channel_outpoint, direction))
        .unwrap();
    assert_eq!(res.amount, 100);
    assert!(!res.success);
}

#[test]
fn test_history_internal_result_fail_pair() {
    let mut internal_result = InternalResult::default();
    let from = gen_rand_fiber_public_key();
    let target = gen_rand_fiber_public_key();

    let channel_outpoint = gen_rand_channel_outpoint();
    let route = vec![
        SessionRouteNode {
            pubkey: from,
            amount: 10,
            channel_outpoint: channel_outpoint.clone(),
        },
        SessionRouteNode {
            pubkey: target,
            amount: 5,
            channel_outpoint: gen_rand_channel_outpoint(),
        },
    ];

    internal_result.fail_pair(&route, 0);
    assert_eq!(internal_result.pairs.len(), 0);

    internal_result.fail_pair(&route, 1);
    assert_eq!(internal_result.pairs.len(), 2);
    let (direction, rev_direction) = output_direction(from, target);
    let res = internal_result
        .pairs
        .get(&(channel_outpoint.clone(), direction))
        .unwrap();
    assert_eq!(res.amount, 0);
    assert!(!res.success);

    let res = internal_result
        .pairs
        .get(&(channel_outpoint, rev_direction))
        .unwrap();
    assert_eq!(res.amount, 0);
    assert!(!res.success);
}

#[test]
fn test_history_internal_result_success_range_pair() {
    let mut internal_result = InternalResult::default();
    let node1 = gen_rand_fiber_public_key();
    let node2 = gen_rand_fiber_public_key();
    let node3 = gen_rand_fiber_public_key();

    let channel_outpoint1 = gen_rand_channel_outpoint();
    let channel_outpoint2 = gen_rand_channel_outpoint();
    let (direction1, _) = output_direction(node1, node2);
    let (direction2, _) = output_direction(node2, node3);
    let route = vec![
        SessionRouteNode {
            pubkey: node1,
            amount: 10,
            channel_outpoint: channel_outpoint1.clone(),
        },
        SessionRouteNode {
            pubkey: node2,
            amount: 5,
            channel_outpoint: channel_outpoint2.clone(),
        },
        SessionRouteNode {
            pubkey: node3,
            amount: 3,
            channel_outpoint: OutPoint::default(),
        },
    ];

    internal_result.succeed_range_pairs(&route, 0, 2);
    assert_eq!(internal_result.pairs.len(), 2);
    let res = internal_result
        .pairs
        .get(&(channel_outpoint1, direction1))
        .unwrap();
    assert_eq!(res.amount, 10);
    assert!(res.success);
    let res = internal_result
        .pairs
        .get(&(channel_outpoint2, direction2))
        .unwrap();
    assert_eq!(res.amount, 5);
    assert!(res.success);
}

#[test]
fn test_history_internal_result_fail_range_pair() {
    let mut internal_result = InternalResult::default();
    let node1 = gen_rand_fiber_public_key();
    let node2 = gen_rand_fiber_public_key();
    let node3 = gen_rand_fiber_public_key();
    let channel_outpoint1 = gen_rand_channel_outpoint();
    let channel_outpoint2 = gen_rand_channel_outpoint();

    let route = vec![
        SessionRouteNode {
            pubkey: node1,
            amount: 10,
            channel_outpoint: channel_outpoint1.clone(),
        },
        SessionRouteNode {
            pubkey: node2,
            amount: 5,
            channel_outpoint: channel_outpoint2.clone(),
        },
        SessionRouteNode {
            pubkey: node3,
            amount: 3,
            channel_outpoint: OutPoint::default(),
        },
    ];

    internal_result.fail_range_pairs(&route, 0, 2);
    assert_eq!(internal_result.pairs.len(), 4);

    let (direction1, rev_direction1) = output_direction(node1, node2);
    let (direction2, rev_direction2) = output_direction(node2, node3);
    let res = internal_result
        .pairs
        .get(&(channel_outpoint1.clone(), direction1))
        .unwrap();
    assert_eq!(res.amount, 0);
    assert!(!res.success);
    let res = internal_result
        .pairs
        .get(&(channel_outpoint1.clone(), rev_direction1))
        .unwrap();
    assert_eq!(res.amount, 0);
    assert!(!res.success);
    let res = internal_result
        .pairs
        .get(&(channel_outpoint2.clone(), direction2))
        .unwrap();
    assert_eq!(res.amount, 0);
    assert!(!res.success);
    let res = internal_result
        .pairs
        .get(&(channel_outpoint2.clone(), rev_direction2))
        .unwrap();
    assert_eq!(res.amount, 0);
    assert!(!res.success);

    let mut history = PaymentHistory::new(gen_rand_fiber_public_key(), None, generate_store());
    history.apply_internal_result(internal_result);

    assert!(matches!(
        history.get_result(&channel_outpoint1, direction1),
        Some(&TimedResult {
            fail_amount: 0,
            success_amount: 0,
            success_time: 0,
            ..
        })
    ));

    assert!(matches!(
        history.get_result(&channel_outpoint1, rev_direction1),
        Some(&TimedResult {
            fail_amount: 0,
            success_amount: 0,
            success_time: 0,
            ..
        })
    ));

    assert!(matches!(
        history.get_result(&channel_outpoint2, direction2),
        Some(&TimedResult {
            fail_amount: 0,
            success_amount: 0,
            success_time: 0,
            ..
        })
    ));

    assert!(matches!(
        history.get_result(&channel_outpoint2, rev_direction2),
        Some(&TimedResult {
            fail_amount: 0,
            success_amount: 0,
            success_time: 0,
            ..
        })
    ));
}

#[test]
fn test_history_apply_internal_result_fail_node() {
    let mut internal_result = InternalResult::default();
    let mut history = PaymentHistory::new(gen_rand_fiber_public_key(), None, generate_store());
    let node1 = gen_rand_fiber_public_key();
    let node2 = gen_rand_fiber_public_key();
    let node3 = gen_rand_fiber_public_key();
    let channel_outpoint1 = gen_rand_channel_outpoint();
    let channel_outpoint2 = gen_rand_channel_outpoint();

    let route = vec![
        SessionRouteNode {
            pubkey: node1,
            amount: 10,
            channel_outpoint: channel_outpoint1.clone(),
        },
        SessionRouteNode {
            pubkey: node2,
            amount: 5,
            channel_outpoint: channel_outpoint2.clone(),
        },
        SessionRouteNode {
            pubkey: node3,
            amount: 3,
            channel_outpoint: OutPoint::default(),
        },
    ];

    internal_result.fail_node(&route, 1);
    assert_eq!(internal_result.pairs.len(), 4);

    let (direction1, rev_direction1) = output_direction(node1, node2);
    let (direction2, rev_direction2) = output_direction(node2, node3);

    history.apply_pair_result(channel_outpoint1.clone(), direction1, 10, true, 1);
    history.apply_pair_result(channel_outpoint2.clone(), direction2, 11, true, 2);
    assert!(matches!(
        history.get_result(&channel_outpoint1, direction1),
        Some(&TimedResult {
            fail_amount: 0,
            success_amount: 10,
            success_time: 1,
            ..
        })
    ));

    assert!(matches!(
        history.get_result(&channel_outpoint2, direction2),
        Some(&TimedResult {
            fail_amount: 0,
            success_amount: 11,
            success_time: 2,
            ..
        })
    ));

    history.apply_internal_result(internal_result);
    assert!(matches!(
        history.get_result(&channel_outpoint1, direction1),
        Some(&TimedResult {
            fail_amount: 0,
            success_amount: 0,
            success_time: 1,
            ..
        })
    ));

    assert!(matches!(
        history.get_result(&channel_outpoint1, rev_direction1),
        Some(&TimedResult {
            fail_amount: 0,
            success_amount: 0,
            success_time: 0,
            ..
        })
    ));

    assert!(matches!(
        history.get_result(&channel_outpoint2, direction2),
        Some(&TimedResult {
            fail_amount: 0,
            success_amount: 0,
            success_time: 2,
            ..
        })
    ));
    assert!(matches!(
        history.get_result(&channel_outpoint2, rev_direction2),
        Some(&TimedResult {
            fail_amount: 0,
            success_amount: 0,
            success_time: 0,
            ..
        })
    ));
}

#[test]
fn test_history_fail_node_with_multiple_channels() {
    let mut internal_result = InternalResult::default();
    let mut history = PaymentHistory::new(gen_rand_fiber_public_key(), None, generate_store());
    let node1 = gen_rand_fiber_public_key();
    let node2 = gen_rand_fiber_public_key();
    let node3 = gen_rand_fiber_public_key();
    let channel_outpoint1 = gen_rand_channel_outpoint();
    let channel_outpoint2 = gen_rand_channel_outpoint();
    let channel_outpoint3 = gen_rand_channel_outpoint();
    let channel_outpoint4 = gen_rand_channel_outpoint();

    let route1 = vec![
        SessionRouteNode {
            pubkey: node1,
            amount: 10,
            channel_outpoint: channel_outpoint1.clone(),
        },
        SessionRouteNode {
            pubkey: node2,
            amount: 5,
            channel_outpoint: channel_outpoint2.clone(),
        },
        SessionRouteNode {
            pubkey: node3,
            amount: 3,
            channel_outpoint: OutPoint::default(),
        },
    ];

    let route2 = vec![
        SessionRouteNode {
            pubkey: node1,
            amount: 10,
            channel_outpoint: channel_outpoint3.clone(),
        },
        SessionRouteNode {
            pubkey: node2,
            amount: 5,
            channel_outpoint: channel_outpoint4.clone(),
        },
        SessionRouteNode {
            pubkey: node3,
            amount: 3,
            channel_outpoint: OutPoint::default(),
        },
    ];

    let (direction1, rev_direction1) = output_direction(node1, node2);
    let (direction2, rev_direction2) = output_direction(node2, node3);

    internal_result.succeed_range_pairs(&route1, 0, 2);
    history.apply_internal_result(internal_result.clone());

    assert!(matches!(
        history.get_result(&channel_outpoint1, direction1),
        Some(&TimedResult {
            fail_amount: 0,
            fail_time: 0,
            success_amount: 10,
            ..
        })
    ));

    assert!(matches!(
        history.get_result(&channel_outpoint2, direction2),
        Some(&TimedResult {
            fail_amount: 0,
            fail_time: 0,
            success_amount: 5,
            ..
        })
    ));

    internal_result.fail_node(&route2, 1);
    assert_eq!(internal_result.pairs.len(), 6);
    history.apply_internal_result(internal_result);

    assert!(matches!(
        history.get_result(&channel_outpoint1, direction1),
        Some(&TimedResult {
            fail_amount: 0,
            success_amount: 0,
            ..
        })
    ));

    assert!(matches!(
        history.get_result(&channel_outpoint2, direction2),
        Some(&TimedResult {
            fail_amount: 0,
            success_amount: 0,
            ..
        })
    ));

    assert!(history
        .get_result(&channel_outpoint1, rev_direction1)
        .is_none());

    assert!(history
        .get_result(&channel_outpoint2, rev_direction2)
        .is_none());

    assert!(matches!(
        history.get_result(&channel_outpoint3, direction1),
        Some(&TimedResult {
            fail_amount: 0,
            success_amount: 0,
            ..
        })
    ));

    assert!(matches!(
        history.get_result(&channel_outpoint4, direction2),
        Some(&TimedResult {
            fail_amount: 0,
            success_amount: 0,
            ..
        })
    ));

    assert!(matches!(
        history.get_result(&channel_outpoint3, rev_direction1),
        Some(&TimedResult {
            fail_amount: 0,
            success_amount: 0,
            ..
        })
    ));

    assert!(matches!(
        history.get_result(&channel_outpoint4, rev_direction2),
        Some(&TimedResult {
            fail_amount: 0,
            success_amount: 0,
            ..
        })
    ));
}

#[test]
fn test_history_interal_success_fail() {
    let mut history = PaymentHistory::new(gen_rand_fiber_public_key(), None, generate_store());
    let from = gen_rand_fiber_public_key();
    let target = gen_rand_fiber_public_key();
    let channel_outpoint = OutPoint::default();
    let (direction, _) = output_direction(from, target);

    let result = TimedResult {
        fail_time: 1,
        fail_amount: 2,
        success_time: 3,
        success_amount: 4,
    };

    history.add_result(channel_outpoint.clone(), direction, result);

    history.apply_pair_result(channel_outpoint.clone(), direction, 10, true, 11);
    assert_eq!(
        history.get_result(&channel_outpoint, direction),
        Some(&TimedResult {
            fail_time: 1,
            fail_amount: 11, // amount + 1
            success_time: 11,
            success_amount: 10,
        })
    );

    // time is too short
    history.apply_pair_result(channel_outpoint.clone(), direction, 12, false, 13);
    assert_eq!(
        history.get_result(&channel_outpoint, direction),
        Some(&TimedResult {
            fail_time: 1,
            fail_amount: 11,
            success_time: 11,
            success_amount: 10,
        })
    );

    history.apply_pair_result(channel_outpoint.clone(), direction, 12, false, 61 * 1000);
    assert_eq!(
        history.get_result(&channel_outpoint, direction),
        Some(&TimedResult {
            fail_time: 61 * 1000,
            fail_amount: 12,
            success_time: 11,   // will not update
            success_amount: 10, // will not update
        })
    );

    history.apply_pair_result(channel_outpoint.clone(), direction, 9, false, 61 * 1000 * 2);
    assert_eq!(
        history.get_result(&channel_outpoint, direction),
        Some(&TimedResult {
            fail_time: 61 * 1000 * 2,
            fail_amount: 9,
            success_time: 11,
            success_amount: 8, // amount - 1
        })
    );
}

#[test]
fn test_history_interal_fuzz_assertion_crash() {
    let mut history = PaymentHistory::new(gen_rand_fiber_public_key(), None, generate_store());
    let from = gen_rand_fiber_public_key();
    let target = gen_rand_fiber_public_key();
    let channel_outpoint = OutPoint::default();
    let (direction, _) = output_direction(from, target);

    let result = TimedResult {
        fail_time: 1,
        fail_amount: 2,
        success_time: 3,
        success_amount: 4,
    };

    history.add_result(channel_outpoint.clone(), direction, result);

    let mut now = 0;
    for _i in 0..10000 {
        let rand_amount = rand::random::<u64>() % 1000;
        let rand_succ = rand::random::<bool>();
        eprintln!("rand_amount: {}, rand_succ: {}", rand_amount, rand_succ);
        now += 60_001;
        history.apply_pair_result(
            channel_outpoint.clone(),
            direction,
            rand_amount.into(),
            rand_succ,
            now,
        );
    }
}

#[test]
fn test_history_interal_fail_zero_after_succ() {
    let mut history = PaymentHistory::new(gen_rand_fiber_public_key(), None, generate_store());
    let from = gen_rand_fiber_public_key();
    let target = gen_rand_fiber_public_key();
    let channel_outpoint = OutPoint::default();
    let (direction, _) = output_direction(from, target);

    let result = TimedResult {
        fail_time: 1,
        fail_amount: 2,
        success_time: 3,
        success_amount: 4,
    };

    history.add_result(channel_outpoint.clone(), direction, result);

    history.apply_pair_result(channel_outpoint.clone(), direction, 0, false, 10);
    assert_eq!(
        history.get_result(&channel_outpoint, direction),
        Some(&TimedResult {
            fail_time: 10,
            fail_amount: 0,
            success_time: 3,
            success_amount: 0, // set to be zero
        })
    );
}

#[test]
fn test_history_interal_keep_valid_range() {
    let mut history = PaymentHistory::new(gen_rand_fiber_public_key(), None, generate_store());
    let from = gen_rand_fiber_public_key();
    let target = gen_rand_fiber_public_key();
    let channel_outpoint = OutPoint::default();
    let (direction, _) = output_direction(from, target);

    let result = TimedResult {
        fail_time: 1,
        fail_amount: 2,
        success_time: 3,
        success_amount: 4,
    };

    history.add_result(channel_outpoint.clone(), direction, result);

    history.apply_pair_result(channel_outpoint.clone(), direction, 100, true, 10);
    history.apply_pair_result(channel_outpoint.clone(), direction, 102, false, 10 + 6001);
    history.apply_pair_result(channel_outpoint.clone(), direction, 90, true, 10 + 6001 * 2);

    assert_eq!(
        history.get_result(&channel_outpoint, direction),
        Some(&TimedResult {
            fail_time: 1,
            fail_amount: 101,
            success_time: 12012,
            success_amount: 100
        })
    );
}

#[test]
fn test_history_probability() {
    let mut history = PaymentHistory::new(gen_rand_fiber_public_key(), None, generate_store());
    let from = gen_rand_fiber_public_key();
    let target = gen_rand_fiber_public_key();
    let channel_outpoint = OutPoint::default();
    let (direction, _) = output_direction(from, target);

    let prob = history.eval_probability(from, target, &channel_outpoint, 10, 100);
    assert_eq!(prob, 1.0);

    let now = now_timestamp_as_millis_u64();
    let result = TimedResult {
        success_time: now,
        success_amount: 5,
        fail_time: now,
        fail_amount: 10,
    };
    history.add_result(channel_outpoint.clone(), direction, result);

    assert_eq!(
        history.eval_probability(from, target, &channel_outpoint, 1, 10),
        1.0
    );
    assert_eq!(
        history.eval_probability(from, target, &channel_outpoint, 1, 8),
        1.0
    );

    // graph of amount is less than history's success_amount and fail_amount
    assert_eq!(
        history.eval_probability(from, target, &channel_outpoint, 1, 4),
        1.0
    );

    let p1 = history
        .eval_probability(from, target, &channel_outpoint, 5, 9)
        .round_to_2();
    assert!(p1 <= 1.0);

    let p2 = history
        .eval_probability(from, target, &channel_outpoint, 6, 9)
        .round_to_2();
    assert!(p2 <= 0.75);
    assert!(p2 < p1);

    let p3 = history
        .eval_probability(from, target, &channel_outpoint, 7, 9)
        .round_to_2();
    assert!(p3 <= 0.50 && p3 < p2);

    let p4 = history
        .eval_probability(from, target, &channel_outpoint, 8, 9)
        .round_to_2();
    assert!(p4 <= 0.25 && p4 < p3);

    let p1 = history
        .eval_probability(from, target, &channel_outpoint, 5, 10)
        .round_to_2();
    assert!(p1 <= 1.0);

    let p2 = history
        .eval_probability(from, target, &channel_outpoint, 6, 10)
        .round_to_2();
    assert!(p2 <= 0.80 && p2 < p1);

    let p3 = history
        .eval_probability(from, target, &channel_outpoint, 7, 10)
        .round_to_2();
    assert!(p3 <= 0.60 && p3 < p2);

    let p4 = history
        .eval_probability(from, target, &channel_outpoint, 8, 10)
        .round_to_2();
    assert!(p4 <= 0.40 && p4 < p3);

    let p5 = history
        .eval_probability(from, target, &channel_outpoint, 9, 10)
        .round_to_2();
    assert!(p5 <= 0.20 && p5 < p4);

    assert_eq!(
        history
            .eval_probability(from, target, &channel_outpoint, 10, 10)
            .round_to_2(),
        0.0
    );
}

#[test]
fn test_history_direct_probability() {
    let mut history = PaymentHistory::new(gen_rand_fiber_public_key(), None, generate_store());
    let from = gen_rand_fiber_public_key();
    let target = gen_rand_fiber_public_key();
    let channel_outpoint = OutPoint::default();
    let (direction, _) = output_direction(from, target);

    let prob = history.get_direct_probability(&channel_outpoint, direction);
    assert_eq!(prob, 1.0);

    let result = TimedResult {
        success_time: 3,
        success_amount: 5,
        fail_time: 0,
        fail_amount: 0,
    };
    history.add_result(channel_outpoint.clone(), direction, result);
    assert_eq!(
        history.get_direct_probability(&channel_outpoint, direction),
        1.0
    );

    let result = TimedResult {
        success_time: 3,
        success_amount: 5,
        fail_time: 10,
        fail_amount: 10,
    };
    history.add_result(channel_outpoint.clone(), direction, result);
    let prob = history.get_direct_probability(&channel_outpoint, direction);
    assert_eq!(prob, 1.0);

    let result = TimedResult {
        success_time: 3,
        success_amount: 5,
        fail_time: now_timestamp_as_millis_u64() - 1000 * 20,
        fail_amount: 10,
    };
    history.add_result(channel_outpoint.clone(), direction, result);
    let prob = history.get_direct_probability(&channel_outpoint, direction);
    assert!(prob < 0.001);

    // if the fail_time is more near, the probability will be lower
    let mut prev_prob = 1.0;
    for i in (1..=10000).rev() {
        let result = TimedResult {
            success_time: 3,
            success_amount: 5,
            fail_time: now_timestamp_as_millis_u64() - 1000 * 60 * i,
            fail_amount: 10,
        };
        history.add_result(channel_outpoint.clone(), direction, result);
        let prob = history.get_direct_probability(&channel_outpoint, direction);
        assert!(prob < prev_prob);
        prev_prob = prob;
    }
    assert!(prev_prob < 0.01);
}

#[test]
fn test_history_small_fail_amount_probability() {
    let mut history = PaymentHistory::new(gen_rand_fiber_public_key(), None, generate_store());
    let from = gen_rand_fiber_public_key();
    let target = gen_rand_fiber_public_key();
    let channel_outpoint = OutPoint::default();
    let (direction, _) = output_direction(from, target);

    let prob = history.eval_probability(from, target, &channel_outpoint, 50000000, 100000000);
    assert_eq!(prob, 1.0);

    let result = TimedResult {
        success_time: 3,
        success_amount: 50000000,
        fail_time: now_timestamp_as_millis_u64(),
        fail_amount: 10,
    };
    history.add_result(channel_outpoint.clone(), direction, result);
    assert_eq!(
        history.eval_probability(from, target, &channel_outpoint, 50000000, 100000000),
        0.0
    );
}

#[test]
fn test_history_channel_probability_range() {
    let mut history = PaymentHistory::new(gen_rand_fiber_public_key(), None, generate_store());
    let from = gen_rand_fiber_public_key();
    let target = gen_rand_fiber_public_key();
    let channel_outpoint = OutPoint::default();
    let (direction, _) = output_direction(from, target);

    let prob = history.eval_probability(from, target, &channel_outpoint, 50000000, 100000000);
    assert_eq!(prob, 1.0);

    let now = now_timestamp_as_millis_u64();
    let result = TimedResult {
        success_time: now,
        success_amount: 10000000,
        fail_time: now,
        fail_amount: 50000000,
    };

    history.add_result(channel_outpoint.clone(), direction, result);

    for amount in (1..10000000).step_by(100000) {
        let prob = history.eval_probability(from, target, &channel_outpoint, amount, 100000000);
        assert_eq!(prob, 1.0);
    }

    let mut prev_prob =
        history.eval_probability(from, target, &channel_outpoint, 10000000, 100000000);
    for amount in (10000005..50000000).step_by(10000) {
        let prob = history.eval_probability(from, target, &channel_outpoint, amount, 100000000);
        assert!(prob < prev_prob);
        prev_prob = prob;
    }

    for amount in (50000001..100000000).step_by(100000) {
        let prob = history.eval_probability(from, target, &channel_outpoint, amount, 100000000);
        assert!(prob < 0.0001);
    }
}

#[test]
fn test_history_eval_probability_range() {
    let mut history = PaymentHistory::new(gen_rand_fiber_public_key(), None, generate_store());
    let from = gen_rand_fiber_public_key();
    let target = gen_rand_fiber_public_key();
    let channel_outpoint = OutPoint::default();
    let (direction, _) = output_direction(from, target);

    let prob = history.eval_probability(from, target, &channel_outpoint, 50000000, 100000000);
    assert_eq!(prob, 1.0);

    let now = now_timestamp_as_millis_u64();
    let result = TimedResult {
        success_time: now,
        success_amount: 10000000,
        fail_time: now,
        fail_amount: 50000000,
    };

    history.add_result(channel_outpoint.clone(), direction, result);
    let prob1 = history.eval_probability(from, target, &channel_outpoint, 50000000, 100000000);
    assert!((0.0..0.001).contains(&prob1));
    let prob2 = history.eval_probability(from, target, &channel_outpoint, 50000000 - 10, 100000000);
    assert!(0.0 < prob2 && prob2 < 0.001);
    assert!(prob2 > prob1);

    let mut prev_prob = prob2;
    for _i in 0..3 {
        std::thread::sleep(std::time::Duration::from_millis(1000));
        let prob =
            history.eval_probability(from, target, &channel_outpoint, 50000000 - 10, 100000000);
        assert!(prob > prev_prob);
        prev_prob = prob;
    }

    history.reset();
    let now = now_timestamp_as_millis_u64();
    let result = TimedResult {
        success_time: now,
        success_amount: 10000000,
        fail_time: now,
        fail_amount: 50000000,
    };
    history.add_result(channel_outpoint.clone(), direction, result);
    prev_prob = 0.0;
    for gap in (10..10000000).step_by(100000) {
        let prob =
            history.eval_probability(from, target, &channel_outpoint, 50000000 - gap, 100000000);
        assert!(prob > prev_prob);
        prev_prob = prob;
    }

    prev_prob = 0.0;
    let now = now_timestamp_as_millis_u64();
    for time in (60 * 1000..DEFAULT_BIMODAL_DECAY_TIME * 2).step_by(60 * 60 * 1000) {
        history.reset();
        let result = TimedResult {
            success_time: now,
            success_amount: 10000000,
            fail_time: now - time,
            fail_amount: 50000000,
        };
        history.add_result(channel_outpoint.clone(), direction, result);
        let prob =
            history.eval_probability(from, target, &channel_outpoint, 50000000 - 10, 100000000);
        assert!(prob > prev_prob);
        prev_prob = prob;
    }
    assert!(prev_prob > 0.0 && prev_prob < 0.55);
}

#[test]
fn test_history_load_store() {
    let temp_path = TempDir::new("test-history-store");
    let store = Store::new(temp_path).expect("created store failed");
    let mut history = PaymentHistory::new(gen_rand_fiber_public_key(), None, store.clone());
    let from = gen_rand_fiber_public_key();
    let target = gen_rand_fiber_public_key();
    let channel_outpoint = OutPoint::default();
    let (direction, _) = output_direction(from, target);

    let result = TimedResult {
        success_time: 3,
        success_amount: 10000000,
        fail_time: 10,
        fail_amount: 50000000,
    };

    history.add_result(channel_outpoint.clone(), direction, result);
    let result = *history.get_result(&channel_outpoint, direction).unwrap();
    history.reset();
    assert_eq!(history.get_result(&channel_outpoint, direction), None);
    history.load_from_store();
    assert_eq!(
        history.get_result(&channel_outpoint, direction),
        Some(&result)
    );

    history.apply_pair_result(channel_outpoint.clone(), direction, 1, false, 11);
    history.reset();
    history.load_from_store();
    assert_eq!(
        history.get_result(&channel_outpoint, direction),
        Some(&TimedResult {
            fail_time: 11,
            fail_amount: 1,
            success_time: 3,
            success_amount: 0,
        })
    );
}

#[test]
fn test_history_can_send_with_time() {
    use crate::fiber::history::DEFAULT_BIMODAL_DECAY_TIME;

    let history = PaymentHistory::new(gen_rand_fiber_public_key(), None, generate_store());
    let now = now_timestamp_as_millis_u64();
    let res = history.can_send(100, now);
    assert_eq!(res, 100);

    let before = now - DEFAULT_BIMODAL_DECAY_TIME / 3;
    let res = history.can_send(100, before);
    assert_eq!(res, 71);

    let before = now - DEFAULT_BIMODAL_DECAY_TIME;
    let res = history.can_send(100, before);
    assert_eq!(res, 36);

    let before = now - DEFAULT_BIMODAL_DECAY_TIME * 3;
    let res = history.can_send(100, before);
    assert_eq!(res, 4);
}

#[test]
fn test_history_can_not_send_with_time() {
    use crate::fiber::history::DEFAULT_BIMODAL_DECAY_TIME;

    let history = PaymentHistory::new(gen_rand_fiber_public_key(), None, generate_store());
    let now = now_timestamp_as_millis_u64();
    let res = history.cannot_send(90, now, 100);
    assert_eq!(res, 90);

    let before = now - DEFAULT_BIMODAL_DECAY_TIME / 3;
    let res = history.cannot_send(90, before, 100);
    assert_eq!(res, 93);

    let before = now - DEFAULT_BIMODAL_DECAY_TIME;
    let res = history.cannot_send(90, before, 100);
    assert_eq!(res, 97);

    let before = now - DEFAULT_BIMODAL_DECAY_TIME * 3;
    let res = history.cannot_send(90, before, 100);
    assert_eq!(res, 100);
}


================================================
File: src/fiber/tests/mod.rs
================================================
mod channel;
mod gossip;
mod graph;
mod hash_algorithm;
mod history;
mod network;
mod path;
mod payment;
mod serde_utils;
pub mod test_utils;
mod tlc_op;
mod types;


================================================
File: src/fiber/tests/network.rs
================================================
use super::test_utils::{init_tracing, NetworkNode};
use crate::{
    fiber::{
        channel::ShutdownInfo,
        config::DEFAULT_TLC_EXPIRY_DELTA,
        graph::ChannelUpdateInfo,
        network::{NetworkActorStateStore, SendPaymentCommand, SendPaymentData},
        tests::test_utils::NetworkNodeConfigBuilder,
        types::{
            BroadcastMessage, ChannelAnnouncement, ChannelUpdateChannelFlags, NodeAnnouncement,
            Privkey, Pubkey,
        },
        NetworkActorCommand, NetworkActorEvent, NetworkActorMessage,
    },
    gen_rand_fiber_public_key, gen_rand_secp256k1_keypair_tuple, gen_rand_sha256_hash,
    invoice::InvoiceBuilder,
    now_timestamp_as_millis_u64, ChannelTestContext, NetworkServiceEvent,
};
use ckb_hash::blake2b_256;
use ckb_jsonrpc_types::Status;
use ckb_types::{
    core::TransactionView,
    packed::{CellOutput, ScriptBuilder},
};
use ckb_types::{
    packed::OutPoint,
    prelude::{Builder, Entity, Pack},
};
use musig2::PartialSignature;
use std::{borrow::Cow, str::FromStr, time::Duration};
use tentacle::{
    multiaddr::{MultiAddr, Multiaddr, Protocol},
    secio::PeerId,
};

fn get_test_priv_key() -> Privkey {
    Privkey::from_slice(&[42u8; 32])
}

fn get_test_pub_key() -> Pubkey {
    get_test_priv_key().pubkey()
}

fn get_test_peer_id() -> PeerId {
    let pub_key = get_test_pub_key().into();
    PeerId::from_public_key(&pub_key)
}

fn get_fake_peer_id_and_address() -> (PeerId, MultiAddr) {
    let peer_id = PeerId::random();
    let mut address = MultiAddr::from_str(&format!(
        "/ip4/{}.{}.{}.{}/tcp/{}",
        rand::random::<u8>(),
        rand::random::<u8>(),
        rand::random::<u8>(),
        rand::random::<u8>(),
        rand::random::<u16>()
    ))
    .expect("valid multiaddr");
    address.push(Protocol::P2P(Cow::Owned(peer_id.clone().into_bytes())));
    (peer_id, address)
}

fn create_fake_channel_announcement_mesage(
    priv_key: Privkey,
    capacity: u64,
    outpoint: OutPoint,
) -> (NodeAnnouncement, NodeAnnouncement, ChannelAnnouncement) {
    let x_only_pub_key = priv_key.x_only_pub_key();
    let sk1 = Privkey::from([1u8; 32]);
    let node_announcement1 = create_node_announcement_mesage_with_priv_key(&sk1);
    let sk2 = Privkey::from([2u8; 32]);
    let node_announcement2 = create_node_announcement_mesage_with_priv_key(&sk2);

    let mut channel_announcement = ChannelAnnouncement::new_unsigned(
        &sk1.pubkey(),
        &sk2.pubkey(),
        outpoint,
        &x_only_pub_key,
        capacity as u128,
        None,
    );
    let message = channel_announcement.message_to_sign();

    channel_announcement.ckb_signature = Some(priv_key.sign_schnorr(message));
    channel_announcement.node1_signature = Some(sk1.sign(message));
    channel_announcement.node2_signature = Some(sk2.sign(message));
    (node_announcement1, node_announcement2, channel_announcement)
}

fn create_node_announcement_mesage_with_priv_key(priv_key: &Privkey) -> NodeAnnouncement {
    let node_name = "fake node";
    let addresses = ["/ip4/1.1.1.1/tcp/8346/p2p/QmaFDJb9CkMrXy7nhTWBY5y9mvuykre3EzzRsCJUAVXprZ"]
        .iter()
        .map(|x| MultiAddr::from_str(x).expect("valid multiaddr"))
        .collect();
    NodeAnnouncement::new(
        node_name.into(),
        addresses,
        priv_key,
        now_timestamp_as_millis_u64(),
        0,
    )
}

fn create_fake_node_announcement_mesage() -> NodeAnnouncement {
    let priv_key = get_test_priv_key();
    create_node_announcement_mesage_with_priv_key(&priv_key)
}

#[tokio::test]
async fn test_save_our_own_node_announcement_to_graph() {
    let mut node = NetworkNode::new().await;
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
    node.stop().await;
    let nodes = node.get_network_graph_nodes().await;
    assert_eq!(nodes.len(), 1);
    assert_eq!(nodes[0].node_id, node.get_public_key());
}

#[tokio::test]
#[should_panic]
async fn test_set_announced_addrs_with_invalid_peer_id() {
    let mut node = NetworkNode::new_with_config(
        NetworkNodeConfigBuilder::new()
            .fiber_config_updater(|config| {
                config.announced_addrs = vec![
                    "/ip4/1.1.1.1/tcp/8346/p2p/QmaFDJb9CkMrXy7nhTWBY5y9mvuykre3EzzRsCJUAVXprZ"
                        .to_string(),
                ];
            })
            .build(),
    )
    .await;
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
    node.stop().await;
    let nodes = node.get_network_graph_nodes().await;
    assert_eq!(nodes.len(), 1);
    assert_eq!(nodes[0].node_id, node.get_public_key());
}

#[tokio::test]
async fn test_set_announced_addrs_with_valid_peer_id() {
    let mut node = NetworkNode::new().await;
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
    node.stop().await;

    let peer_id = node.get_peer_id();
    let addr = format!("/ip4/1.1.1.1/tcp/8346/p2p/{}", peer_id);
    let multiaddr = Multiaddr::from_str(&addr).expect("valid multiaddr");
    let mut node = NetworkNode::new_with_config(
        NetworkNodeConfigBuilder::new()
            .base_dir(node.base_dir.clone())
            .fiber_config_updater(move |config| {
                config.announced_addrs = vec![addr.clone()];
            })
            .build(),
    )
    .await;
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
    node.stop().await;
    let nodes = node.get_network_graph_nodes().await;
    assert_eq!(nodes.len(), 1);
    assert_eq!(nodes[0].node_id, node.get_public_key());
    assert_eq!(
        nodes[0].addresses.iter().find(|x| *x == &multiaddr),
        Some(&multiaddr)
    );
}

#[tokio::test]
async fn test_set_announced_addrs_without_p2p() {
    let addr = "/ip4/1.1.1.1/tcp/8346".to_string();
    let cloned_addr = addr.clone();
    let mut node = NetworkNode::new_with_config(
        NetworkNodeConfigBuilder::new()
            .fiber_config_updater(move |config| {
                config.announced_addrs = vec![cloned_addr];
            })
            .build(),
    )
    .await;
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
    node.stop().await;
    let peer_id = node.get_peer_id();
    let peer_id_bytes = peer_id.clone().into_bytes();
    let multiaddr =
        Multiaddr::from_str(&format!("{}/p2p/{}", addr, peer_id)).expect("valid multiaddr");
    let nodes = node.get_network_graph_nodes().await;
    assert_eq!(nodes.len(), 1);
    assert_eq!(nodes[0].node_id, node.get_public_key());
    assert!(nodes[0].addresses.clone().iter_mut().all(|multiaddr| {
        match multiaddr.pop() {
            Some(Protocol::P2P(peer_id)) => peer_id.as_ref() == peer_id_bytes.as_slice(),
            _ => false,
        }
    }));
    assert_eq!(
        nodes[0].addresses.iter().find(|x| *x == &multiaddr),
        Some(&multiaddr)
    );
}

#[tokio::test]
async fn test_sync_channel_announcement_on_startup() {
    init_tracing();

    let mut node1 = NetworkNode::new_with_node_name("node1").await;
    let mut node2 = NetworkNode::new_with_node_name("node2").await;

    let capacity = 42;
    let priv_key: Privkey = get_test_priv_key();
    let pubkey = priv_key.x_only_pub_key().serialize();
    let pubkey_hash = &blake2b_256(pubkey.as_slice())[0..20];
    let tx = TransactionView::new_advanced_builder()
        .output(
            CellOutput::new_builder()
                .capacity(capacity.pack())
                .lock(ScriptBuilder::default().args(pubkey_hash.pack()).build())
                .build(),
        )
        .output_data([0u8; 8].pack())
        .build();
    let outpoint = tx.output_pts()[0].clone();
    let (node_announcement_1, node_announcement_2, channel_announcement) =
        create_fake_channel_announcement_mesage(priv_key, capacity, outpoint);

    assert_eq!(node1.submit_tx(tx.clone()).await, Status::Committed);

    for message in [
        BroadcastMessage::NodeAnnouncement(node_announcement_1.clone()),
        BroadcastMessage::NodeAnnouncement(node_announcement_2.clone()),
        BroadcastMessage::ChannelAnnouncement(channel_announcement.clone()),
    ] {
        node1
            .network_actor
            .send_message(NetworkActorMessage::Event(
                NetworkActorEvent::GossipMessage(
                    get_test_peer_id(),
                    message.create_broadcast_messages_filter_result(),
                ),
            ))
            .expect("send message to network actor");
    }

    node1.connect_to(&node2).await;

    assert_eq!(node2.submit_tx(tx.clone()).await, Status::Committed);

    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
    let channels = node2.get_network_graph_channels().await;
    assert!(!channels.is_empty());
}

#[tokio::test]
async fn test_node1_node2_channel_update() {
    let channel_context = ChannelTestContext::gen();
    let funding_tx = channel_context.funding_tx.clone();
    let out_point = channel_context.channel_outpoint().clone();
    let channel_announcement = channel_context.channel_announcement.clone();
    let mut node = NetworkNode::new().await;
    node.submit_tx(funding_tx).await;
    node.network_actor
        .send_message(NetworkActorMessage::Event(
            NetworkActorEvent::GossipMessage(
                get_test_peer_id(),
                BroadcastMessage::ChannelAnnouncement(channel_announcement)
                    .create_broadcast_messages_filter_result(),
            ),
        ))
        .expect("send message to network actor");
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    let channel_update_of_node1 =
        channel_context.create_channel_update_of_node1(ChannelUpdateChannelFlags::empty(), 1, 1, 1);
    node.network_actor
        .send_message(NetworkActorMessage::Event(
            NetworkActorEvent::GossipMessage(
                get_test_peer_id(),
                BroadcastMessage::ChannelUpdate(channel_update_of_node1.clone())
                    .create_broadcast_messages_filter_result(),
            ),
        ))
        .expect("send message to network actor");
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    let new_channel_info = node.get_network_graph_channel(&out_point).await.unwrap();
    assert_eq!(
        new_channel_info.update_of_node1,
        Some(ChannelUpdateInfo::from(&channel_update_of_node1))
    );

    let channel_update_of_node2 =
        channel_context.create_channel_update_of_node2(ChannelUpdateChannelFlags::empty(), 2, 2, 2);
    node.network_actor
        .send_message(NetworkActorMessage::Event(
            NetworkActorEvent::GossipMessage(
                get_test_peer_id(),
                BroadcastMessage::ChannelUpdate(channel_update_of_node2.clone())
                    .create_broadcast_messages_filter_result(),
            ),
        ))
        .expect("send message to network actor");
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    let new_channel_info = node.get_network_graph_channel(&out_point).await.unwrap();
    assert_eq!(
        new_channel_info.update_of_node1,
        Some(ChannelUpdateInfo::from(&channel_update_of_node1))
    );
    assert_eq!(
        new_channel_info.update_of_node2,
        Some(ChannelUpdateInfo::from(&channel_update_of_node2))
    );
}

#[tokio::test]
async fn test_channel_update_version() {
    let channel_context = ChannelTestContext::gen();
    let funding_tx = channel_context.funding_tx.clone();
    let out_point = channel_context.channel_outpoint().clone();
    let mut node = NetworkNode::new().await;
    node.submit_tx(funding_tx).await;
    node.network_actor
        .send_message(NetworkActorMessage::Event(
            NetworkActorEvent::GossipMessage(
                get_test_peer_id(),
                BroadcastMessage::ChannelAnnouncement(channel_context.channel_announcement.clone())
                    .create_broadcast_messages_filter_result(),
            ),
        ))
        .expect("send message to network actor");
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    let mut channel_updates = vec![];
    for i in 0u8..3 {
        // Make sure the timestamp is different.
        tokio::time::sleep(tokio::time::Duration::from_millis(3)).await;
        channel_updates.push(channel_context.create_channel_update_of_node1(
            ChannelUpdateChannelFlags::empty(),
            i.into(),
            i.into(),
            i.into(),
        ))
    }
    let [channel_update_1, channel_update_2, channel_update_3] =
        channel_updates.try_into().expect("3 channel updates");

    node.network_actor
        .send_message(NetworkActorMessage::Event(
            NetworkActorEvent::GossipMessage(
                get_test_peer_id(),
                BroadcastMessage::ChannelUpdate(channel_update_2.clone())
                    .create_broadcast_messages_filter_result(),
            ),
        ))
        .expect("send message to network actor");
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
    let new_channel_info = node.get_network_graph_channel(&out_point).await.unwrap();
    assert_eq!(
        new_channel_info.update_of_node1,
        Some(ChannelUpdateInfo::from(&channel_update_2))
    );

    // Old channel update will not replace the new one.
    node.network_actor
        .send_message(NetworkActorMessage::Event(
            NetworkActorEvent::GossipMessage(
                get_test_peer_id(),
                BroadcastMessage::ChannelUpdate(channel_update_1.clone())
                    .create_broadcast_messages_filter_result(),
            ),
        ))
        .expect("send message to network actor");
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
    let new_channel_info = node.get_network_graph_channel(&out_point).await.unwrap();
    assert_eq!(
        new_channel_info.update_of_node1,
        Some(ChannelUpdateInfo::from(&channel_update_2))
    );

    // New channel update will replace the old one.
    node.network_actor
        .send_message(NetworkActorMessage::Event(
            NetworkActorEvent::GossipMessage(
                get_test_peer_id(),
                BroadcastMessage::ChannelUpdate(channel_update_3.clone())
                    .create_broadcast_messages_filter_result(),
            ),
        ))
        .expect("send message to network actor");
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
    let new_channel_info = node.get_network_graph_channel(&out_point).await.unwrap();
    assert_eq!(
        new_channel_info.update_of_node1,
        Some(ChannelUpdateInfo::from(&channel_update_3))
    );
}

#[tokio::test]
async fn test_sync_node_announcement_version() {
    init_tracing();

    let node = NetworkNode::new_with_node_name("node").await;
    let test_pub_key = get_test_pub_key();
    let test_peer_id = get_test_peer_id();

    let [node_announcement_message_version1, node_announcement_message_version2, node_announcement_message_version3] = [
        create_fake_node_announcement_mesage(),
        create_fake_node_announcement_mesage(),
        create_fake_node_announcement_mesage(),
    ];
    let timestamp_version2 = node_announcement_message_version2.timestamp;
    let timestamp_version3 = node_announcement_message_version3.timestamp;

    node.network_actor
        .send_message(NetworkActorMessage::Event(
            NetworkActorEvent::GossipMessage(
                test_peer_id.clone(),
                BroadcastMessage::NodeAnnouncement(node_announcement_message_version2)
                    .create_broadcast_messages_filter_result(),
            ),
        ))
        .expect("send message to network actor");

    // Wait for the broadcast message to be processed.
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
    let node_info = node.get_network_graph_node(&test_pub_key).await;
    match node_info {
        Some(n) if n.timestamp == timestamp_version2 => {}
        _ => panic!(
            "Must have version 2 announcement message, found {:?}",
            &node_info
        ),
    }

    node.network_actor
        .send_message(NetworkActorMessage::Event(
            NetworkActorEvent::GossipMessage(
                test_peer_id.clone(),
                BroadcastMessage::NodeAnnouncement(node_announcement_message_version1)
                    .create_broadcast_messages_filter_result(),
            ),
        ))
        .expect("send message to network actor");

    // Wait for the broadcast message to be processed.
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
    let node_info = node.get_network_graph_node(&test_pub_key).await;
    match node_info {
        Some(n) if n.timestamp == timestamp_version2 => {}
        _ => panic!(
            "Must have version 2 announcement message, found {:?}",
            &node_info
        ),
    }

    node.network_actor
        .send_message(NetworkActorMessage::Event(
            NetworkActorEvent::GossipMessage(
                test_peer_id.clone(),
                BroadcastMessage::NodeAnnouncement(node_announcement_message_version3)
                    .create_broadcast_messages_filter_result(),
            ),
        ))
        .expect("send message to network actor");
    // Wait for the broadcast message to be processed.
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
    let node_info = node.get_network_graph_node(&test_pub_key).await;
    match node_info {
        Some(n) if n.timestamp == timestamp_version3 => {}
        _ => panic!(
            "Must have version 3 announcement message, found {:?}",
            &node_info
        ),
    }
}

// Test that we can sync the network graph with peers.
// We will first create a node and announce a fake node announcement to the network.
// Then we will create another node and connect to the first node.
// We will see if the second node has the fake node announcement.
#[tokio::test]
async fn test_sync_node_announcement_on_startup() {
    init_tracing();

    let mut node1 = NetworkNode::new_with_node_name("node1").await;
    let node2 = NetworkNode::new_with_node_name("node2").await;
    let test_pub_key = get_test_pub_key();
    let test_peer_id = get_test_peer_id();

    node1
        .network_actor
        .send_message(NetworkActorMessage::Event(
            NetworkActorEvent::GossipMessage(
                test_peer_id.clone(),
                BroadcastMessage::NodeAnnouncement(create_fake_node_announcement_mesage())
                    .create_broadcast_messages_filter_result(),
            ),
        ))
        .expect("send message to network actor");

    node1.connect_to(&node2).await;

    // Wait for the broadcast message to be processed.
    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;

    let node_info = node1.get_network_graph_node(&test_pub_key).await;
    assert!(node_info.is_some());

    let node_info = node2.get_network_graph_node(&test_pub_key).await;
    assert!(node_info.is_some());
}

#[tokio::test]
async fn test_sync_node_announcement_of_connected_nodes() {
    let [node1, node2] = NetworkNode::new_n_interconnected_nodes().await;

    // Wait for the broadcast message to be processed.
    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;

    let node_info = node1.get_network_graph_node(&node2.get_public_key()).await;
    assert!(node_info.is_some());

    let node_info = node2.get_network_graph_node(&node1.get_public_key()).await;
    assert!(node_info.is_some());
}

// Test that we can sync the network graph with peers.
// We will first create a node and announce a fake node announcement to the network.
// Then we will create another node and connect to the first node.
// We will see if the second node has the fake node announcement.
#[tokio::test]
async fn test_sync_node_announcement_after_restart() {
    init_tracing();

    let [node1, mut node2] = NetworkNode::new_n_interconnected_nodes().await;

    node2.stop().await;

    let test_pub_key = get_test_pub_key();
    let test_peer_id = get_test_peer_id();
    node1
        .network_actor
        .send_message(NetworkActorMessage::Event(
            NetworkActorEvent::GossipMessage(
                test_peer_id.clone(),
                BroadcastMessage::NodeAnnouncement(create_fake_node_announcement_mesage())
                    .create_broadcast_messages_filter_result(),
            ),
        ))
        .expect("send message to network actor");

    node2.start().await;
    node2.connect_to(&node1).await;

    // Wait for the broadcast message to be processed.
    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;

    let node_info = node1.get_network_graph_node(&test_pub_key).await;
    assert!(node_info.is_some());

    let node_info = node2.get_network_graph_node(&test_pub_key).await;
    assert!(node_info.is_some());
}

#[tokio::test]
async fn test_persisting_network_state() {
    let mut node = NetworkNode::new().await;
    let state = node.store.clone();
    let peer_id = node.peer_id.clone();
    node.stop().await;
    assert!(state.get_network_actor_state(&peer_id).is_some())
}

#[tokio::test]
async fn test_persisting_bootnode() {
    let (boot_peer_id, address) = get_fake_peer_id_and_address();
    let address_string = format!("{}", &address);

    let mut node = NetworkNode::new_with_config(
        NetworkNodeConfigBuilder::new()
            .fiber_config_updater(move |config| config.bootnode_addrs = vec![address_string])
            .build(),
    )
    .await;
    let state = node.store.clone();
    let peer_id = node.peer_id.clone();
    node.stop().await;

    let state = state.get_network_actor_state(&peer_id).unwrap();
    let peers = state.sample_n_peers_to_connect(1);
    assert_eq!(peers.get(&boot_peer_id), Some(&vec![address]));
}

#[tokio::test]
async fn test_persisting_announced_nodes() {
    init_tracing();

    let mut node = NetworkNode::new_with_node_name("test").await;

    let announcement = create_fake_node_announcement_mesage();
    let node_pk = announcement.node_id;
    let peer_id = node_pk.tentacle_peer_id();

    node.network_actor
        .send_message(NetworkActorMessage::Event(
            NetworkActorEvent::GossipMessage(
                peer_id.clone(),
                BroadcastMessage::NodeAnnouncement(announcement)
                    .create_broadcast_messages_filter_result(),
            ),
        ))
        .expect("send message to network actor");

    // Wait for the above message to be processed.
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    node.stop().await;
    let peers = node
        .with_network_graph(|graph| graph.sample_n_peers_to_connect(1))
        .await;
    assert!(peers.contains_key(&peer_id));
}

#[tokio::test]
async fn test_connecting_to_bootnode() {
    let boot_node = NetworkNode::new().await;
    let boot_node_address = format!("{}", boot_node.get_node_address());
    let boot_node_id = &boot_node.peer_id;

    let mut node = NetworkNode::new_with_config(
        NetworkNodeConfigBuilder::new()
            .fiber_config_updater(move |config| config.bootnode_addrs = vec![boot_node_address])
            .build(),
    )
    .await;

    node.expect_event(
        |event| matches!(event, NetworkServiceEvent::PeerConnected(id, _addr) if id == boot_node_id),
    )
    .await;
}

#[tokio::test]
async fn test_saving_and_connecting_to_node() {
    init_tracing();

    let node1 = NetworkNode::new().await;
    let node1_address = node1.get_node_address().clone();
    let node1_id = &node1.peer_id;

    let mut node2 = NetworkNode::new().await;

    node2
        .network_actor
        .send_message(NetworkActorMessage::new_command(
            NetworkActorCommand::SavePeerAddress(node1_address),
        ))
        .expect("send message to network actor");

    // Wait for the above message to be processed.
    tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;

    node2.restart().await;

    node2.expect_event(
        |event| matches!(event, NetworkServiceEvent::PeerConnected(id, _addr) if id == node1_id),
    )
    .await;
}

#[test]
fn test_announcement_message_serialize() {
    let capacity = 42;
    let priv_key: Privkey = get_test_priv_key();
    let pubkey = priv_key.x_only_pub_key().serialize();
    let pubkey_hash = &blake2b_256(pubkey.as_slice())[0..20];
    let tx = TransactionView::new_advanced_builder()
        .output(
            CellOutput::new_builder()
                .capacity(capacity.pack())
                .lock(ScriptBuilder::default().args(pubkey_hash.pack()).build())
                .build(),
        )
        .output_data([0u8; 8].pack())
        .build();
    let outpoint = tx.output_pts()[0].clone();
    let (_, _, mut channel_announcement) =
        create_fake_channel_announcement_mesage(priv_key, capacity, outpoint);

    channel_announcement.udt_type_script = Some(ScriptBuilder::default().build());

    let serialized = bincode::serialize(&channel_announcement).unwrap();
    let deserialized: ChannelAnnouncement = bincode::deserialize(&serialized).unwrap();
    assert_eq!(channel_announcement, deserialized);

    let shutdown_info = ShutdownInfo {
        close_script: ScriptBuilder::default().build(),
        fee_rate: 100_u64,
        signature: Some(PartialSignature::max()),
    };
    let serialized = bincode::serialize(&shutdown_info).unwrap();
    let deserialized: ShutdownInfo = bincode::deserialize(&serialized).unwrap();
    assert_eq!(shutdown_info, deserialized);
}

#[test]
fn test_send_payment_validate_payment_hash() {
    let send_command = SendPaymentCommand {
        target_pubkey: Some(gen_rand_fiber_public_key()),
        amount: Some(10000),
        payment_hash: None,
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,

        invoice: None,
        timeout: None,
        max_fee_amount: None,
        max_parts: None,
        keysend: None,
        udt_type_script: None,
        allow_self_payment: false,
        hop_hints: None,
        dry_run: false,
    };

    let result = SendPaymentData::new(send_command);
    assert!(result.is_err());
    assert!(result.unwrap_err().contains("payment_hash is missing"));
}

#[test]
fn test_send_payment_validate_amount() {
    let send_command = SendPaymentCommand {
        target_pubkey: Some(gen_rand_fiber_public_key()),
        amount: None,
        payment_hash: None,
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,

        invoice: None,
        timeout: None,
        max_fee_amount: None,
        max_parts: None,
        keysend: None,
        udt_type_script: None,
        allow_self_payment: false,
        hop_hints: None,
        dry_run: false,
    };

    let result = SendPaymentData::new(send_command);
    assert!(result.is_err());
    assert!(result.unwrap_err().contains("amount is missing"));
}

#[test]
fn test_send_payment_validate_invoice() {
    use crate::invoice::Attribute;
    use crate::invoice::Currency;
    use secp256k1::Secp256k1;

    let gen_payment_hash = gen_rand_sha256_hash();
    let (private_key, public_key) = gen_rand_secp256k1_keypair_tuple();

    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_hash(gen_payment_hash)
        .fallback_address("address".to_string())
        .expiry_time(Duration::from_secs(1024))
        .payee_pub_key(public_key)
        .add_attr(Attribute::FinalHtlcTimeout(5))
        .add_attr(Attribute::FinalHtlcMinimumExpiryDelta(
            DEFAULT_TLC_EXPIRY_DELTA,
        ))
        .add_attr(Attribute::Description("description".to_string()))
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key))
        .unwrap();

    let invoice_encoded = invoice.to_string();
    let send_command = SendPaymentCommand {
        target_pubkey: Some(gen_rand_fiber_public_key()),
        amount: None,
        payment_hash: None,
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,
        invoice: Some(invoice_encoded.clone()),
        timeout: None,
        max_fee_amount: None,
        max_parts: None,
        keysend: None,
        udt_type_script: None,
        allow_self_payment: false,
        hop_hints: None,
        dry_run: false,
    };

    let result = SendPaymentData::new(send_command);
    assert!(result.is_err());
    assert!(result
        .unwrap_err()
        .contains("target_pubkey does not match the invoice"));

    let send_command = SendPaymentCommand {
        target_pubkey: None,
        amount: Some(10),
        payment_hash: None,
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,
        invoice: Some(invoice_encoded.clone()),
        timeout: None,
        max_fee_amount: None,
        max_parts: None,
        keysend: None,
        udt_type_script: None,
        allow_self_payment: false,
        hop_hints: None,
        dry_run: false,
    };

    // keysend is set with invoice, should be error
    let result = SendPaymentData::new(send_command);
    assert!(result.is_err());
    assert!(result
        .unwrap_err()
        .contains("amount does not match the invoice"));

    let send_command = SendPaymentCommand {
        target_pubkey: None,
        amount: None,
        payment_hash: None,
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,
        invoice: Some(invoice_encoded.clone()),
        timeout: None,
        max_fee_amount: None,
        max_parts: None,
        keysend: Some(true),
        udt_type_script: None,
        allow_self_payment: false,
        hop_hints: None,
        dry_run: false,
    };

    let result = SendPaymentData::new(send_command);
    assert!(result.is_err());

    // normal invoice send payment
    let send_command = SendPaymentCommand {
        target_pubkey: None,
        amount: None,
        payment_hash: None,
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,
        invoice: Some(invoice_encoded.clone()),
        timeout: None,
        max_fee_amount: None,
        max_parts: None,
        keysend: None,
        udt_type_script: None,
        allow_self_payment: false,
        hop_hints: None,
        dry_run: false,
    };

    let result = SendPaymentData::new(send_command);
    assert!(result.is_ok());

    // normal keysend send payment
    let send_command = SendPaymentCommand {
        target_pubkey: Some(gen_rand_fiber_public_key()),
        amount: Some(10),
        payment_hash: None,
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,
        invoice: None,
        timeout: None,
        max_fee_amount: None,
        max_parts: None,
        keysend: Some(true),
        udt_type_script: None,
        allow_self_payment: false,
        hop_hints: None,
        dry_run: false,
    };

    let result = SendPaymentData::new(send_command);
    assert!(result.is_ok());

    // invoice with invalid final_tlc_expiry_delta
    let send_command = SendPaymentCommand {
        target_pubkey: None,
        amount: None,
        payment_hash: None,
        final_tlc_expiry_delta: Some(11),
        tlc_expiry_limit: None,
        invoice: Some(invoice_encoded.clone()),
        timeout: None,
        max_fee_amount: None,
        max_parts: None,
        keysend: None,
        udt_type_script: None,
        allow_self_payment: false,
        hop_hints: None,
        dry_run: false,
    };

    let result = SendPaymentData::new(send_command);
    assert!(result.is_err());
    assert!(result
        .unwrap_err()
        .contains("invalid final_tlc_expiry_delta"));

    // invoice with invalid final_tlc_expiry_delta
    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_hash(gen_payment_hash)
        .fallback_address("address".to_string())
        .expiry_time(Duration::from_secs(1024))
        .payee_pub_key(public_key)
        .add_attr(Attribute::FinalHtlcTimeout(5))
        .add_attr(Attribute::FinalHtlcMinimumExpiryDelta(11))
        .add_attr(Attribute::Description("description".to_string()))
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key))
        .unwrap();
    let invoice_encoded = invoice.to_string();
    let send_command = SendPaymentCommand {
        target_pubkey: None,
        amount: None,
        payment_hash: None,
        final_tlc_expiry_delta: None,
        tlc_expiry_limit: None,
        invoice: Some(invoice_encoded.clone()),
        timeout: None,
        max_fee_amount: None,
        max_parts: None,
        keysend: None,
        udt_type_script: None,
        allow_self_payment: false,
        hop_hints: None,
        dry_run: false,
    };

    let result = SendPaymentData::new(send_command);
    assert!(result.is_err());
    assert!(result
        .unwrap_err()
        .contains("invalid final_tlc_expiry_delta"));
}

#[test]
fn test_send_payment_validate_htlc_expiry_delta() {
    let send_command = SendPaymentCommand {
        target_pubkey: Some(gen_rand_fiber_public_key()),
        amount: Some(1000),
        payment_hash: Some(gen_rand_sha256_hash()),
        final_tlc_expiry_delta: Some(100),
        tlc_expiry_limit: None,
        invoice: None,
        timeout: None,
        max_fee_amount: None,
        max_parts: None,
        keysend: None,
        udt_type_script: None,
        allow_self_payment: false,
        hop_hints: None,
        dry_run: false,
    };

    let result = SendPaymentData::new(send_command);
    assert!(result.is_err());
    assert!(result
        .unwrap_err()
        .contains("invalid final_tlc_expiry_delta"));
}


================================================
File: src/fiber/tests/path.rs
================================================
use secp256k1::{PublicKey, Secp256k1, SecretKey};

use crate::fiber::path::{NodeHeap, NodeHeapElement};

#[test]
fn test_node_heap() {
    let secp = Secp256k1::new();
    let secret_key1 = SecretKey::from_slice(&[0xcd; 32]).expect("32 bytes, within curve order");
    let public_key1 = PublicKey::from_secret_key(&secp, &secret_key1);

    let secret_key2 = SecretKey::from_slice(&[0xab; 32]).expect("32 bytes, within curve order");
    let public_key2 = PublicKey::from_secret_key(&secp, &secret_key2);

    let mut heap = NodeHeap::new(10);
    let node1 = NodeHeapElement {
        node_id: public_key1.into(),
        weight: 0,
        distance: 0,
        amount_to_send: 0,
        fee_charged: 0,
        probability: 0.0,
        next_hop: None,
        incoming_tlc_expiry: 0,
    };
    let node2 = NodeHeapElement {
        node_id: public_key2.into(),
        weight: 0,
        distance: 0,
        amount_to_send: 0,
        fee_charged: 0,
        probability: 0.0,
        next_hop: None,
        incoming_tlc_expiry: 0,
    };
    assert!(heap.is_empty());
    heap.push(node1.clone());
    heap.push(node2.clone());
    assert!(!heap.is_empty());
    assert_eq!(heap.pop(), Some(node1));
    assert_eq!(heap.pop(), Some(node2));
    assert_eq!(heap.pop(), None);
    assert!(heap.is_empty());
}

#[test]
fn test_node_heap_probability() {
    let secp = Secp256k1::new();
    let secret_key1 = SecretKey::from_slice(&[0xcd; 32]).expect("32 bytes, within curve order");
    let public_key1 = PublicKey::from_secret_key(&secp, &secret_key1);

    let secret_key2 = SecretKey::from_slice(&[0xab; 32]).expect("32 bytes, within curve order");
    let public_key2 = PublicKey::from_secret_key(&secp, &secret_key2);

    let mut heap = NodeHeap::new(10);
    let node1 = NodeHeapElement {
        node_id: public_key1.into(),
        weight: 0,
        distance: 0,
        amount_to_send: 0,
        fee_charged: 0,
        probability: 0.0,
        next_hop: None,
        incoming_tlc_expiry: 0,
    };
    let node2 = NodeHeapElement {
        node_id: public_key2.into(),
        weight: 0,
        distance: 0,
        amount_to_send: 0,
        fee_charged: 0,
        probability: 0.5,
        next_hop: None,
        incoming_tlc_expiry: 0,
    };
    heap.push(node1.clone());
    heap.push(node2.clone());
    assert_eq!(heap.pop(), Some(node2));
    assert_eq!(heap.pop(), Some(node1));
    assert_eq!(heap.pop(), None);
}

#[test]
fn test_node_heap_distance() {
    let secp = Secp256k1::new();
    let secret_key1 = SecretKey::from_slice(&[0xcd; 32]).expect("32 bytes, within curve order");
    let public_key1 = PublicKey::from_secret_key(&secp, &secret_key1);

    let secret_key2 = SecretKey::from_slice(&[0xab; 32]).expect("32 bytes, within curve order");
    let public_key2 = PublicKey::from_secret_key(&secp, &secret_key2);

    let mut heap = NodeHeap::new(10);
    let node1 = NodeHeapElement {
        node_id: public_key1.into(),
        weight: 0,
        distance: 10,
        amount_to_send: 0,
        fee_charged: 0,
        probability: 0.0,
        next_hop: None,
        incoming_tlc_expiry: 0,
    };
    let node2 = NodeHeapElement {
        node_id: public_key2.into(),
        weight: 0,
        distance: 2,
        amount_to_send: 0,
        fee_charged: 0,
        probability: 0.0,
        next_hop: None,
        incoming_tlc_expiry: 0,
    };
    heap.push(node1.clone());
    heap.push(node2.clone());
    assert_eq!(heap.pop(), Some(node2));
    assert_eq!(heap.pop(), Some(node1));
    assert_eq!(heap.pop(), None);
}

#[test]
fn test_node_heap_push_or_fix() {
    let secp = Secp256k1::new();
    let secret_key1 = SecretKey::from_slice(&[0xcd; 32]).expect("32 bytes, within curve order");
    let public_key1 = PublicKey::from_secret_key(&secp, &secret_key1);

    let secret_key2 = SecretKey::from_slice(&[0xab; 32]).expect("32 bytes, within curve order");
    let public_key2 = PublicKey::from_secret_key(&secp, &secret_key2);

    let mut heap = NodeHeap::new(10);
    let node1 = NodeHeapElement {
        node_id: public_key1.into(),
        weight: 0,
        distance: 10,
        amount_to_send: 0,
        fee_charged: 0,
        probability: 0.0,
        next_hop: None,
        incoming_tlc_expiry: 0,
    };
    let node2 = NodeHeapElement {
        node_id: public_key2.into(),
        weight: 0,
        distance: 2,
        amount_to_send: 0,
        fee_charged: 0,
        probability: 0.0,
        next_hop: None,
        incoming_tlc_expiry: 0,
    };

    heap.push(node1.clone());
    heap.push(node2.clone());
    assert_eq!(heap.peek(), Some(node2.clone()).as_ref());

    let node1_update = NodeHeapElement {
        node_id: public_key1.into(),
        weight: 0,
        distance: 1,
        amount_to_send: 0,
        fee_charged: 0,
        probability: 0.0,
        next_hop: None,
        incoming_tlc_expiry: 0,
    };

    heap.push_or_fix(node1_update.clone());

    assert_eq!(heap.pop(), Some(node1_update));
    assert_eq!(heap.pop(), Some(node2));
    assert_eq!(heap.pop(), None);
}


================================================
File: src/fiber/tests/payment.rs
================================================
#![allow(clippy::needless_range_loop)]
use super::test_utils::init_tracing;
use crate::fiber::channel::UpdateCommand;
use crate::fiber::graph::PaymentSessionStatus;
use crate::fiber::network::HopHint;
use crate::fiber::network::SendPaymentCommand;
use crate::fiber::tests::test_utils::*;
use crate::fiber::types::Hash256;
use crate::fiber::NetworkActorCommand;
use crate::fiber::NetworkActorMessage;
use ractor::call;
use std::collections::HashSet;

// This test will send two payments from node_0 to node_1, the first payment will run
// with dry_run, the second payment will run without dry_run. Both payments will be successful.
// But only one payment balance will be deducted from node_0.
#[tokio::test]
async fn test_send_payment_for_direct_channel_and_dry_run() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    // from https://github.com/nervosnetwork/fiber/issues/359

    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[((0, 1), (MIN_RESERVED_CKB + 10000000000, MIN_RESERVED_CKB))],
        2,
        true,
    )
    .await;
    let [node_0, node_1] = nodes.try_into().expect("2 nodes");
    let channel = channels[0];
    let source_node = &node_0;

    let res = source_node
        .send_payment_keysend(&node_1, 10000000000, true)
        .await;

    eprintln!("res: {:?}", res);
    assert!(res.is_ok());

    let res = source_node
        .send_payment_keysend(&node_1, 10000000000, false)
        .await;

    eprintln!("res: {:?}", res);
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;
    source_node.wait_until_success(payment_hash).await;

    let node_0_balance = source_node.get_local_balance_from_channel(channel);
    let node_1_balance = node_1.get_local_balance_from_channel(channel);

    // A -> B: 10000000000 use the first channel
    assert_eq!(node_0_balance, 0);
    assert_eq!(node_1_balance, 10000000000);
}

#[tokio::test]
async fn test_send_payment_prefer_newer_channels() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();

    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (MIN_RESERVED_CKB + 10000000000, MIN_RESERVED_CKB)),
            ((0, 1), (MIN_RESERVED_CKB + 10000000000, MIN_RESERVED_CKB)),
        ],
        2,
        true,
    )
    .await;
    let [mut node_0, node_1] = nodes.try_into().expect("2 nodes");
    let source_node = &mut node_0;
    let target_pubkey = node_1.pubkey;

    let res = source_node
        .send_payment(SendPaymentCommand {
            target_pubkey: Some(target_pubkey),
            amount: Some(10000000000),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: None,
            invoice: None,
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: Some(true),
            udt_type_script: None,
            allow_self_payment: false,
            hop_hints: None,
            dry_run: false,
        })
        .await;

    eprintln!("res: {:?}", res);
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;
    source_node.wait_until_success(payment_hash).await;

    // We are using the second (newer) channel, so the first channel's balances are unchanged.
    let node_0_balance = source_node.get_local_balance_from_channel(channels[0]);
    let node_1_balance = node_1.get_local_balance_from_channel(channels[0]);
    assert_eq!(node_0_balance, 10000000000);
    assert_eq!(node_1_balance, 0);

    // We are using the second (newer) channel, so the second channel's balances are changed.
    let node_0_balance = source_node.get_local_balance_from_channel(channels[1]);
    let node_1_balance = node_1.get_local_balance_from_channel(channels[1]);
    assert_eq!(node_0_balance, 0);
    assert_eq!(node_1_balance, 10000000000);
}

#[tokio::test]
async fn test_send_payment_prefer_channels_with_larger_balance() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();

    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            // These two channnels have the same overall capacity, but the second channel has more balance for node_0.
            (
                (0, 1),
                (MIN_RESERVED_CKB + 5000000000, MIN_RESERVED_CKB + 5000000000),
            ),
            ((0, 1), (MIN_RESERVED_CKB + 10000000000, MIN_RESERVED_CKB)),
        ],
        2,
        true,
    )
    .await;
    let [mut node_0, node_1] = nodes.try_into().expect("2 nodes");
    let source_node = &mut node_0;
    let target_pubkey = node_1.pubkey;

    let res = source_node
        .send_payment(SendPaymentCommand {
            target_pubkey: Some(target_pubkey),
            amount: Some(5000000000),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: None,
            invoice: None,
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: Some(true),
            udt_type_script: None,
            allow_self_payment: false,
            hop_hints: None,
            dry_run: false,
        })
        .await;

    eprintln!("res: {:?}", res);
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;
    source_node.wait_until_success(payment_hash).await;

    // We are using the second channel (with larger balance), so the first channel's balances are unchanged.
    let node_0_balance = source_node.get_local_balance_from_channel(channels[0]);
    let node_1_balance = node_1.get_local_balance_from_channel(channels[0]);
    assert_eq!(node_0_balance, 5000000000);
    assert_eq!(node_1_balance, 5000000000);

    // We are using the second channel (with larger balance), so the second channel's balances are changed.
    let node_0_balance = source_node.get_local_balance_from_channel(channels[1]);
    let node_1_balance = node_1.get_local_balance_from_channel(channels[1]);
    assert_eq!(node_0_balance, 5000000000);
    assert_eq!(node_1_balance, 5000000000);
}

#[tokio::test]
async fn test_send_payment_fee_rate() {
    init_tracing();
    let [mut node_0, mut node_1, mut node_2] = NetworkNode::new_n_interconnected_nodes().await;

    let (_new_channel_id, funding_tx_0) = establish_channel_between_nodes(
        &mut node_0,
        &mut node_1,
        true,
        MIN_RESERVED_CKB + 1_000_000_000,
        MIN_RESERVED_CKB,
        None,
        None,
        None,
        None,
        Some(1_000_000),
        None,
        None,
        None,
        None,
        Some(2_000_000),
    )
    .await;
    node_2.submit_tx(funding_tx_0).await;

    let (_new_channel_id, funding_tx_1) = establish_channel_between_nodes(
        &mut node_1,
        &mut node_2,
        true,
        MIN_RESERVED_CKB + 1_000_000_000,
        MIN_RESERVED_CKB,
        None,
        None,
        None,
        None,
        Some(3_000_000),
        None,
        None,
        None,
        None,
        Some(4_000_000),
    )
    .await;
    node_0.submit_tx(funding_tx_1).await;

    // sleep for a while
    tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;

    let res = node_0
        .send_payment_keysend(&node_2, 10_000_000, false)
        .await;
    assert!(res.is_ok(), "Send payment failed: {:?}", res);
    let res = res.unwrap();
    assert!(res.fee > 0);
    let nodes = res.router.nodes;
    assert_eq!(nodes.len(), 3);
    assert_eq!(nodes[2].amount, 10_000_000);
    assert_eq!(nodes[1].amount, 10_000_000);
    // The fee is 10_000_000 * 3_000_000 (fee rate) / 1_000_000 = 30_000_000
    assert_eq!(nodes[0].amount, 40_000_000);
    let payment_hash = res.payment_hash;
    node_0.wait_until_success(payment_hash).await;

    let res = node_2.send_payment_keysend(&node_0, 1_000_000, false).await;
    assert!(res.is_ok(), "Send payment failed: {:?}", res);
    let res = res.unwrap();
    assert!(res.fee > 0);
    let nodes = res.router.nodes;
    assert_eq!(nodes.len(), 3);
    assert_eq!(nodes[2].amount, 1_000_000);
    assert_eq!(nodes[1].amount, 1_000_000);
    // The fee is 1_000_000 * 2_000_000 (fee rate) / 1_000_000 = 2_000_000
    assert_eq!(nodes[0].amount, 3_000_000);

    let payment_hash = res.payment_hash;
    node_2.wait_until_success(payment_hash).await;
}

#[tokio::test]
async fn test_send_payment_over_private_channel() {
    async fn test(amount_to_send: u128, is_payment_ok: bool) {
        let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
            &[((1, 2), (MIN_RESERVED_CKB + 20000000000, MIN_RESERVED_CKB))],
            3,
            true,
        )
        .await;
        let [mut node1, mut node2, node3] = nodes.try_into().expect("3 nodes");

        let (_new_channel_id, _funding_tx) = establish_channel_between_nodes(
            &mut node1,
            &mut node2,
            false,
            MIN_RESERVED_CKB + 20000000000,
            MIN_RESERVED_CKB,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
        )
        .await;

        // sleep for a while
        tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;

        let source_node = &mut node1;
        let target_pubkey = node3.pubkey;

        let res = source_node
            .send_payment(SendPaymentCommand {
                target_pubkey: Some(target_pubkey),
                amount: Some(amount_to_send),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            })
            .await;

        eprintln!("res: {:?}", res);
        if is_payment_ok {
            assert!(res.is_ok());
            source_node
                .wait_until_success(res.unwrap().payment_hash)
                .await;
        } else {
            assert!(res.is_err());
        }
    }

    test(10000000000, true).await;
    test(30000000000, false).await;
}

#[tokio::test]
async fn test_send_payment_for_pay_self() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    // from https://github.com/nervosnetwork/fiber/issues/362

    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (MIN_RESERVED_CKB + 10000000000, MIN_RESERVED_CKB)),
            ((1, 2), (MIN_RESERVED_CKB + 10000000000, MIN_RESERVED_CKB)),
            ((2, 0), (MIN_RESERVED_CKB + 10000000000, MIN_RESERVED_CKB)),
        ],
        3,
        true,
    )
    .await;
    let [node_0, node_1, node_2] = nodes.try_into().expect("3 nodes");

    let node_1_channel0_balance = node_1.get_local_balance_from_channel(channels[0]);
    let node_1_channel1_balance = node_1.get_local_balance_from_channel(channels[1]);
    let node_2_channel1_balance = node_2.get_local_balance_from_channel(channels[1]);
    let node_2_channel2_balance = node_2.get_local_balance_from_channel(channels[2]);

    // now node_0 -> node_2 will be ok only with node_1, so the fee is larger than 0
    let res = node_0.send_payment_keysend(&node_2, 60000000, true).await;

    assert!(res.unwrap().fee > 0);

    // node_0 -> node_0 will be ok for dry_run if `allow_self_payment` is true
    let res = node_0.send_payment_keysend_to_self(60000000, false).await;

    eprintln!("res: {:?}", res);
    assert!(res.is_ok());

    let res = res.unwrap();
    let payment_hash = res.payment_hash;
    node_0.wait_until_success(payment_hash).await;
    node_0
        .assert_payment_status(payment_hash, PaymentSessionStatus::Success, Some(1))
        .await;

    let node_0_balance1 = node_0.get_local_balance_from_channel(channels[0]);
    let node_0_balance2 = node_0.get_local_balance_from_channel(channels[2]);

    assert_eq!(node_0_balance1, 10000000000 - 60000000 - res.fee);
    assert_eq!(node_0_balance2, 60000000);

    eprintln!(
        "node1 left: {:?}, right: {:?}",
        node_1.get_local_balance_from_channel(channels[0]),
        node_1.get_local_balance_from_channel(channels[1])
    );

    let node_1_new_channel0_balance = node_1.get_local_balance_from_channel(channels[0]);
    let node_1_new_channel1_balance = node_1.get_local_balance_from_channel(channels[1]);
    let node_2_new_channel1_balance = node_2.get_local_balance_from_channel(channels[1]);
    let node_2_new_channel2_balance = node_2.get_local_balance_from_channel(channels[2]);

    let node1_fee = (node_1_new_channel0_balance - node_1_channel0_balance)
        - (node_1_channel1_balance - node_1_new_channel1_balance);
    assert!(node1_fee > 0);

    let node2_fee = (node_2_new_channel1_balance - node_2_channel1_balance)
        - (node_2_channel2_balance - node_2_new_channel2_balance);
    assert!(node2_fee > 0);
    assert_eq!(node1_fee + node2_fee, res.fee);

    // node_0 -> node_2 will be ok with direct channel2,
    // since after payself this channel now have enough balance, so the fee is 0
    let res = node_0.send_payment_keysend(&node_2, 60000000, true).await;

    eprintln!("res: {:?}", res);
    assert_eq!(res.unwrap().fee, 0);
}

#[tokio::test]
async fn test_send_payment_for_pay_self_with_two_nodes() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    // from https://github.com/nervosnetwork/fiber/issues/355

    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (MIN_RESERVED_CKB + 10000000000, MIN_RESERVED_CKB)),
            ((1, 0), (MIN_RESERVED_CKB + 10000000000, MIN_RESERVED_CKB)),
        ],
        2,
        true,
    )
    .await;
    let [node_0, node_1] = nodes.try_into().expect("2 nodes");

    let node_1_channel0_balance = node_1.get_local_balance_from_channel(channels[0]);
    let node_1_channel1_balance = node_1.get_local_balance_from_channel(channels[1]);

    // node_0 -> node_0 will be ok for dry_run if `allow_self_payment` is true
    let res = node_0.send_payment_keysend_to_self(60000000, false).await;

    eprintln!("res: {:?}", res);
    assert!(res.is_ok());

    let res = res.unwrap();
    let payment_hash = res.payment_hash;
    node_0.wait_until_success(payment_hash).await;
    node_0
        .assert_payment_status(payment_hash, PaymentSessionStatus::Success, Some(1))
        .await;

    let node_0_balance1 = node_0.get_local_balance_from_channel(channels[0]);
    let node_0_balance2 = node_0.get_local_balance_from_channel(channels[1]);

    assert_eq!(node_0_balance1, 10000000000 - 60000000 - res.fee);
    assert_eq!(node_0_balance2, 60000000);

    let new_node_1_channel0_balance = node_1.get_local_balance_from_channel(channels[0]);
    let new_node_1_channel1_balance = node_1.get_local_balance_from_channel(channels[1]);

    let node1_fee = (new_node_1_channel0_balance - node_1_channel0_balance)
        - (node_1_channel1_balance - new_node_1_channel1_balance);
    eprintln!("fee: {:?}", res.fee);
    assert_eq!(node1_fee, res.fee);
}

#[tokio::test]
async fn test_send_payment_with_more_capacity_for_payself() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    // from https://github.com/nervosnetwork/fiber/issues/362

    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            (
                (0, 1),
                (
                    MIN_RESERVED_CKB + 10000000000,
                    MIN_RESERVED_CKB + 10000000000,
                ),
            ),
            (
                (1, 2),
                (
                    MIN_RESERVED_CKB + 10000000000,
                    MIN_RESERVED_CKB + 10000000000,
                ),
            ),
            (
                (2, 0),
                (
                    MIN_RESERVED_CKB + 10000000000,
                    MIN_RESERVED_CKB + 10000000000,
                ),
            ),
        ],
        3,
        true,
    )
    .await;
    let [node_0, node_1, node_2] = nodes.try_into().expect("3 nodes");

    let node_1_channel0_balance = node_1.get_local_balance_from_channel(channels[0]);
    let node_1_channel1_balance = node_1.get_local_balance_from_channel(channels[1]);
    let node_2_channel1_balance = node_2.get_local_balance_from_channel(channels[1]);
    let node_2_channel2_balance = node_2.get_local_balance_from_channel(channels[2]);

    // node_0 -> node_0 will be ok if `allow_self_payment` is true
    let res = node_0.send_payment_keysend_to_self(60000000, false).await;

    eprintln!("res: {:?}", res);
    assert!(res.is_ok());

    // sleep for a while
    let res = res.unwrap();
    let payment_hash = res.payment_hash;
    node_0.wait_until_success(payment_hash).await;
    node_0
        .assert_payment_status(payment_hash, PaymentSessionStatus::Success, Some(1))
        .await;

    let node_0_balance1 = node_0.get_local_balance_from_channel(channels[0]);
    let node_0_balance2 = node_0.get_local_balance_from_channel(channels[2]);

    eprintln!("fee: {:?}", res.fee);
    // for node0 pay to self, only the fee will be deducted
    assert!(node_0_balance1 + node_0_balance2 == 10000000000 + 10000000000 - res.fee);

    eprintln!(
        "node1 left: {:?}, right: {:?}",
        node_1.get_local_balance_from_channel(channels[0]),
        node_1.get_local_balance_from_channel(channels[1])
    );

    let node_1_new_channel0_balance = node_1.get_local_balance_from_channel(channels[0]);
    let node_1_new_channel1_balance = node_1.get_local_balance_from_channel(channels[1]);
    let node_2_new_channel1_balance = node_2.get_local_balance_from_channel(channels[1]);
    let node_2_new_channel2_balance = node_2.get_local_balance_from_channel(channels[2]);

    // we may route to self from
    //     node0 -> node1 -> node2 -> node0
    // or  node0 -> node2 -> node1 -> node0
    // so the assertion need to be more complex
    let node1_fee = if node_1_new_channel0_balance > node_1_channel0_balance {
        (node_1_new_channel0_balance - node_1_channel0_balance)
            - (node_1_channel1_balance - node_1_new_channel1_balance)
    } else {
        (node_1_new_channel1_balance - node_1_channel1_balance)
            - (node_1_channel0_balance - node_1_new_channel0_balance)
    };
    assert!(node1_fee > 0);

    let node2_fee = if node_2_new_channel1_balance > node_2_channel1_balance {
        (node_2_new_channel1_balance - node_2_channel1_balance)
            - (node_2_channel2_balance - node_2_new_channel2_balance)
    } else {
        (node_2_new_channel2_balance - node_2_channel2_balance)
            - (node_2_channel1_balance - node_2_new_channel1_balance)
    };
    assert_eq!(node1_fee + node2_fee, res.fee);
}

#[tokio::test]
async fn test_send_payment_with_route_to_self_with_hop_hints() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();

    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            (
                (0, 1),
                (
                    MIN_RESERVED_CKB + 10000000000,
                    MIN_RESERVED_CKB + 10000000000,
                ),
            ),
            (
                (1, 2),
                (
                    MIN_RESERVED_CKB + 10000000000,
                    MIN_RESERVED_CKB + 10000000000,
                ),
            ),
            (
                (2, 0),
                (
                    MIN_RESERVED_CKB + 10000000000,
                    MIN_RESERVED_CKB + 10000000000,
                ),
            ),
        ],
        3,
        true,
    )
    .await;
    let [node_0, node_1, node_2] = nodes.try_into().expect("3 nodes");
    eprintln!("node_0: {:?}", node_0.pubkey);
    eprintln!("node_1: {:?}", node_1.pubkey);
    eprintln!("node_2: {:?}", node_2.pubkey);

    let node_1_channel0_balance = node_1.get_local_balance_from_channel(channels[0]);
    let node_1_channel1_balance = node_1.get_local_balance_from_channel(channels[1]);
    let node_2_channel1_balance = node_2.get_local_balance_from_channel(channels[1]);
    let node_2_channel2_balance = node_2.get_local_balance_from_channel(channels[2]);

    let channel_0_funding_tx = node_0.get_channel_funding_tx(&channels[0]).unwrap();

    // node_0 -> node_0 will be ok if `allow_self_payment` is true
    // use hop hints to help find_path use node1 -> node0,
    // then the only valid route will be node0 -> node2 -> node1 -> node0
    let res = node_0
        .send_payment(SendPaymentCommand {
            target_pubkey: Some(node_0.pubkey),
            amount: Some(60000000),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: None,
            invoice: None,
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: Some(true),
            udt_type_script: None,
            allow_self_payment: true,
            hop_hints: Some(vec![HopHint {
                pubkey: node_0.pubkey,
                channel_funding_tx: channel_0_funding_tx,
                inbound: true,
            }]),
            dry_run: false,
        })
        .await;

    eprintln!("res: {:?}", res);
    assert!(res.is_ok());

    let res = res.unwrap();
    let payment_hash = res.payment_hash;
    node_0.wait_until_success(payment_hash).await;
    node_0
        .assert_payment_status(payment_hash, PaymentSessionStatus::Success, Some(1))
        .await;

    let node_0_balance1 = node_0.get_local_balance_from_channel(channels[0]);
    let node_0_balance2 = node_0.get_local_balance_from_channel(channels[2]);

    eprintln!("fee: {:?}", res.fee);
    // for node0 pay to self, only the fee will be deducted
    assert!(node_0_balance1 + node_0_balance2 == 10000000000 + 10000000000 - res.fee);

    eprintln!(
        "node1 left: {:?}, right: {:?}",
        node_1.get_local_balance_from_channel(channels[0]),
        node_1.get_local_balance_from_channel(channels[1])
    );

    let node_1_new_channel0_balance = node_1.get_local_balance_from_channel(channels[0]);
    let node_1_new_channel1_balance = node_1.get_local_balance_from_channel(channels[1]);
    let node_2_new_channel1_balance = node_2.get_local_balance_from_channel(channels[1]);
    let node_2_new_channel2_balance = node_2.get_local_balance_from_channel(channels[2]);

    // node0 can only route to self from
    // node0 -> node2 -> node1 -> node0
    let node1_fee = (node_1_new_channel1_balance - node_1_channel1_balance)
        - (node_1_channel0_balance - node_1_new_channel0_balance);

    assert!(node1_fee > 0);

    let node2_fee = (node_2_new_channel2_balance - node_2_channel2_balance)
        - (node_2_channel1_balance - node_2_new_channel1_balance);

    assert_eq!(node1_fee + node2_fee, res.fee);
}

#[tokio::test]
async fn test_send_payment_with_route_to_self_with_outbound_hop_hints() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();

    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            (
                (0, 1),
                (
                    MIN_RESERVED_CKB + 10000000000,
                    MIN_RESERVED_CKB + 10000000000,
                ),
            ),
            (
                (1, 2),
                (
                    MIN_RESERVED_CKB + 10000000000,
                    MIN_RESERVED_CKB + 10000000000,
                ),
            ),
            (
                (2, 0),
                (
                    MIN_RESERVED_CKB + 10000000000,
                    MIN_RESERVED_CKB + 10000000000,
                ),
            ),
        ],
        3,
        true,
    )
    .await;
    let [node_0, node_1, node_2] = nodes.try_into().expect("3 nodes");
    eprintln!("node_0: {:?}", node_0.pubkey);
    eprintln!("node_1: {:?}", node_1.pubkey);
    eprintln!("node_2: {:?}", node_2.pubkey);

    let node_1_channel0_balance = node_1.get_local_balance_from_channel(channels[0]);
    let node_1_channel1_balance = node_1.get_local_balance_from_channel(channels[1]);
    let node_2_channel1_balance = node_2.get_local_balance_from_channel(channels[1]);
    let node_2_channel2_balance = node_2.get_local_balance_from_channel(channels[2]);

    let channel_0_funding_tx = node_0.get_channel_funding_tx(&channels[0]).unwrap();

    // node_0 -> node_0 will be ok if `allow_self_payment` is true
    // use hop hints to help find_path use node0 -> node1,
    // then the only valid route will be node0 -> node1 -> node2 -> node0
    let res = node_0
        .send_payment(SendPaymentCommand {
            target_pubkey: Some(node_0.pubkey),
            amount: Some(60000000),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: None,
            invoice: None,
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: Some(true),
            udt_type_script: None,
            allow_self_payment: true,
            hop_hints: Some(vec![HopHint {
                pubkey: node_0.pubkey,
                channel_funding_tx: channel_0_funding_tx,
                inbound: false,
            }]),
            dry_run: false,
        })
        .await;

    eprintln!("res: {:?}", res);
    assert!(res.is_ok());

    let res = res.unwrap();
    let payment_hash = res.payment_hash;
    node_0.wait_until_success(payment_hash).await;
    node_0
        .assert_payment_status(payment_hash, PaymentSessionStatus::Success, Some(1))
        .await;

    let node_0_balance1 = node_0.get_local_balance_from_channel(channels[0]);
    let node_0_balance2 = node_0.get_local_balance_from_channel(channels[2]);

    eprintln!("fee: {:?}", res.fee);
    // for node0 pay to self, only the fee will be deducted
    assert!(node_0_balance1 + node_0_balance2 == 10000000000 + 10000000000 - res.fee);

    eprintln!(
        "node1 left: {:?}, right: {:?}",
        node_1.get_local_balance_from_channel(channels[0]),
        node_1.get_local_balance_from_channel(channels[1])
    );

    let node_1_new_channel0_balance = node_1.get_local_balance_from_channel(channels[0]);
    let node_1_new_channel1_balance = node_1.get_local_balance_from_channel(channels[1]);
    let node_2_new_channel1_balance = node_2.get_local_balance_from_channel(channels[1]);
    let node_2_new_channel2_balance = node_2.get_local_balance_from_channel(channels[2]);

    // node0 can only route to self from
    // node0 -> node1 -> node2 -> node0
    let node1_fee = (node_1_new_channel0_balance - node_1_channel0_balance)
        - (node_1_channel1_balance - node_1_new_channel1_balance);

    assert!(node1_fee > 0);

    let node2_fee = (node_2_new_channel1_balance - node_2_channel1_balance)
        - (node_2_channel2_balance - node_2_new_channel2_balance);

    assert_eq!(node1_fee + node2_fee, res.fee);
}

#[tokio::test]
async fn test_send_payment_select_channel_with_hop_hints() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();

    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            // there are 3 channels from node1 -> node2
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((2, 3), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        4,
        true,
    )
    .await;
    let [node_0, node_1, node_2, node_3] = nodes.try_into().expect("4 nodes");
    eprintln!("node_0: {:?}", node_0.pubkey);
    eprintln!("node_1: {:?}", node_1.pubkey);
    eprintln!("node_2: {:?}", node_2.pubkey);
    eprintln!("node_3: {:?}", node_3.pubkey);

    let channel_3_funding_tx = node_0.get_channel_funding_tx(&channels[3]).unwrap();
    eprintln!("channel_3_funding_tx: {:?}", channel_3_funding_tx);
    let res = node_0
        .send_payment(SendPaymentCommand {
            target_pubkey: Some(node_3.pubkey),
            amount: Some(60000000),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: None,
            invoice: None,
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: Some(true),
            udt_type_script: None,
            allow_self_payment: true,
            // at node_1, we must use channel_3 to reach node_2
            hop_hints: Some(vec![HopHint {
                pubkey: node_2.pubkey,
                channel_funding_tx: channel_3_funding_tx,
                inbound: true,
            }]),
            dry_run: false,
        })
        .await;

    eprintln!("res: {:?}", res);
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;
    eprintln!("payment_hash: {:?}", payment_hash);
    let payment_session = node_0
        .get_payment_session(payment_hash)
        .expect("get payment");
    eprintln!("payment_session: {:?}", payment_session);
    let used_channels: Vec<Hash256> = payment_session
        .route
        .nodes
        .iter()
        .map(|x| x.channel_outpoint.tx_hash().into())
        .collect();
    eprintln!("used_channels: {:?}", used_channels);
    assert_eq!(used_channels.len(), 4);
    assert_eq!(used_channels[1], channel_3_funding_tx);

    tokio::time::sleep(tokio::time::Duration::from_millis(2500)).await;

    // try channel_2 with outbound hop hints
    let channel_2_funding_tx = node_0.get_channel_funding_tx(&channels[2]).unwrap();
    eprintln!("channel_2_funding_tx: {:?}", channel_2_funding_tx);
    let res = node_0
        .send_payment(SendPaymentCommand {
            target_pubkey: Some(node_3.pubkey),
            amount: Some(60000000),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: None,
            invoice: None,
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: Some(true),
            udt_type_script: None,
            allow_self_payment: true,
            // at node_1, we must use channel_2 to reach node_2
            hop_hints: Some(vec![HopHint {
                pubkey: node_1.pubkey,
                channel_funding_tx: channel_2_funding_tx,
                inbound: false,
            }]),
            dry_run: false,
        })
        .await;

    eprintln!("res: {:?}", res);
    assert!(res.is_ok());
    let payment_hash = res.unwrap().payment_hash;
    eprintln!("payment_hash: {:?}", payment_hash);
    let payment_session = node_0
        .get_payment_session(payment_hash)
        .expect("get payment");
    eprintln!("payment_session: {:?}", payment_session);
    let used_channels: Vec<Hash256> = payment_session
        .route
        .nodes
        .iter()
        .map(|x| x.channel_outpoint.tx_hash().into())
        .collect();
    eprintln!("used_channels: {:?}", used_channels);
    assert_eq!(used_channels.len(), 4);
    assert_eq!(used_channels[1], channel_2_funding_tx);

    let wrong_channel_hash = Hash256::from([0u8; 32]);
    // if we specify a wrong funding_tx, the payment will fail
    let res = node_0
        .send_payment(SendPaymentCommand {
            target_pubkey: Some(node_3.pubkey),
            amount: Some(60000000),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: None,
            invoice: None,
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: Some(true),
            udt_type_script: None,
            allow_self_payment: true,
            // at node_1, we must use channel_3 to reach node_2
            hop_hints: Some(vec![HopHint {
                pubkey: node_2.pubkey,
                channel_funding_tx: wrong_channel_hash,
                inbound: true,
            }]),
            dry_run: false,
        })
        .await;
    eprintln!("res: {:?}", res);
    assert!(res
        .unwrap_err()
        .to_string()
        .contains("PathFind error: no path found"));
}

#[tokio::test]
async fn test_send_payment_two_nodes_with_hop_hints_and_multiple_channels() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();

    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, MIN_RESERVED_CKB)),
            ((0, 1), (HUGE_CKB_AMOUNT, MIN_RESERVED_CKB)),
            ((1, 0), (HUGE_CKB_AMOUNT, MIN_RESERVED_CKB)),
            ((1, 0), (HUGE_CKB_AMOUNT, MIN_RESERVED_CKB)),
        ],
        2,
        true,
    )
    .await;
    let [node_0, node_1] = nodes.try_into().expect("2 nodes");
    eprintln!("node_0: {:?}", node_0.pubkey);
    eprintln!("node_1: {:?}", node_1.pubkey);

    let channel_1_funding_tx = node_0.get_channel_funding_tx(&channels[1]).unwrap();
    let channel_3_funding_tx = node_0.get_channel_funding_tx(&channels[3]).unwrap();
    let old_balance = node_0.get_local_balance_from_channel(channels[1]);
    let old_node1_balance = node_1.get_local_balance_from_channel(channels[3]);
    eprintln!("channel_1_funding_tx: {:?}", channel_1_funding_tx);
    let res = node_0
        .send_payment(SendPaymentCommand {
            target_pubkey: Some(node_0.pubkey),
            amount: Some(60000000),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: None,
            invoice: None,
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: Some(true),
            udt_type_script: None,
            allow_self_payment: true,
            hop_hints: Some(vec![
                // node1 - channel_1 -> node2
                HopHint {
                    pubkey: node_0.pubkey,
                    channel_funding_tx: channel_1_funding_tx,
                    inbound: false,
                },
                // node2 - channel_3 -> node1
                HopHint {
                    pubkey: node_0.pubkey,
                    channel_funding_tx: channel_3_funding_tx,
                    inbound: true,
                },
            ]),
            dry_run: false,
        })
        .await
        .unwrap();

    let payment_hash = res.payment_hash;
    eprintln!("payment_hash: {:?}", payment_hash);
    let payment_session = node_0
        .get_payment_session(payment_hash)
        .expect("get payment");
    eprintln!("payment_session: {:?}", payment_session);
    let used_channels: Vec<Hash256> = payment_session
        .route
        .nodes
        .iter()
        .map(|x| x.channel_outpoint.tx_hash().into())
        .collect();
    eprintln!("used_channels: {:?}", used_channels);
    assert_eq!(used_channels.len(), 3);
    assert_eq!(used_channels[0], channel_1_funding_tx);
    assert_eq!(used_channels[1], channel_3_funding_tx);

    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;

    let balance = node_0.get_local_balance_from_channel(channels[1]);
    assert_eq!(balance, old_balance - 60000000 - res.fee);

    let node_1_balance = node_1.get_local_balance_from_channel(channels[1]);
    assert_eq!(node_1_balance, 60000000 + res.fee);

    let balance = node_0.get_local_balance_from_channel(channels[3]);
    assert_eq!(balance, 60000000);

    let node_1_balance = node_1.get_local_balance_from_channel(channels[3]);
    assert_eq!(node_1_balance, old_node1_balance - 60000000);
}

#[tokio::test]
async fn test_network_send_payment_randomly_send_each_other() {
    init_tracing();

    let _span = tracing::info_span!("node", node = "test").entered();
    let node_a_funding_amount = 100000000000;
    let node_b_funding_amount = 100000000000;

    let (node_a, node_b, new_channel_id) =
        create_nodes_with_established_channel(node_a_funding_amount, node_b_funding_amount, true)
            .await;
    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
    let node_a_old_balance = node_a.get_local_balance_from_channel(new_channel_id);
    let node_b_old_balance = node_b.get_local_balance_from_channel(new_channel_id);

    let node_a_pubkey = node_a.pubkey;
    let node_b_pubkey = node_b.pubkey;

    let mut node_a_sent = 0;
    let mut node_b_sent = 0;
    let mut all_sent = vec![];
    for _i in 1..8 {
        let rand_wait_time = rand::random::<u64>() % 1000;
        tokio::time::sleep(tokio::time::Duration::from_millis(rand_wait_time)).await;

        let rand_num = rand::random::<u64>() % 2;
        let amount = rand::random::<u128>() % 10000;
        eprintln!("generated ampunt: {}", amount);
        let (source, target) = if rand_num == 0 {
            (&node_a.network_actor, node_b_pubkey)
        } else {
            (&node_b.network_actor, node_a_pubkey)
        };
        let message = |rpc_reply| -> NetworkActorMessage {
            NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
                SendPaymentCommand {
                    target_pubkey: Some(target),
                    amount: Some(amount),
                    payment_hash: None,
                    final_tlc_expiry_delta: None,
                    tlc_expiry_limit: None,
                    invoice: None,
                    timeout: None,
                    max_fee_amount: None,
                    max_parts: None,
                    keysend: Some(true),
                    udt_type_script: None,
                    allow_self_payment: false,
                    hop_hints: None,
                    dry_run: false,
                },
                rpc_reply,
            ))
        };

        let res = call!(source, message).expect("node_a alive").unwrap();

        if rand_num == 0 {
            all_sent.push((true, amount, res.payment_hash, res.status));
        } else {
            all_sent.push((false, amount, res.payment_hash, res.status));
        }
    }

    tokio::time::sleep(tokio::time::Duration::from_millis(4000)).await;
    for (a_sent, amount, payment_hash, create_status) in all_sent {
        let message = |rpc_reply| -> NetworkActorMessage {
            NetworkActorMessage::Command(NetworkActorCommand::GetPayment(payment_hash, rpc_reply))
        };
        let network = if a_sent {
            &node_a.network_actor
        } else {
            &node_b.network_actor
        };
        let res = call!(network, message).expect("node_a alive").unwrap();
        if res.status == PaymentSessionStatus::Success {
            assert!(matches!(
                create_status,
                PaymentSessionStatus::Created | PaymentSessionStatus::Inflight
            ));
            eprintln!(
                "{} payment_hash: {:?} success with amount: {} create_status: {:?}",
                if a_sent { "a -> b" } else { "b -> a" },
                payment_hash,
                amount,
                create_status
            );
            if a_sent {
                node_a_sent += amount;
            } else {
                node_b_sent += amount;
            }
        }
    }

    eprintln!(
        "node_a_old_balance: {}, node_b_old_balance: {}",
        node_a_old_balance, node_b_old_balance
    );
    eprintln!("node_a_sent: {}, node_b_sent: {}", node_a_sent, node_b_sent);
    let new_node_a_balance = node_a.get_local_balance_from_channel(new_channel_id);
    let new_node_b_balance = node_b.get_local_balance_from_channel(new_channel_id);

    eprintln!(
        "new_node_a_balance: {}, new_node_b_balance: {}",
        new_node_a_balance, new_node_b_balance
    );

    assert_eq!(
        node_a_old_balance + node_b_old_balance,
        new_node_a_balance + new_node_b_balance
    );
    assert_eq!(
        new_node_a_balance,
        node_a_old_balance - node_a_sent + node_b_sent
    );
    assert_eq!(
        new_node_b_balance,
        node_b_old_balance - node_b_sent + node_a_sent
    );
}

#[tokio::test]
async fn test_network_three_nodes_two_channels_send_each_other() {
    init_tracing();

    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        3,
        true,
    )
    .await;
    let [node_a, node_b, node_c] = nodes.try_into().expect("3 nodes");

    // Wait for the channel announcement to be broadcasted
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
    let node_b_old_balance_channel_0 = node_b.get_local_balance_from_channel(channels[0]);
    let node_b_old_balance_channel_1 = node_b.get_local_balance_from_channel(channels[1]);

    let amount_a_to_c = 60000;
    let res = node_a
        .send_payment_keysend(&node_c, amount_a_to_c, false)
        .await
        .unwrap();
    let payment_hash1 = res.payment_hash;
    let fee1 = res.fee;
    eprintln!("payment_hash1: {:?}", payment_hash1);

    let amount_c_to_a = 50000;
    let res = node_c
        .send_payment_keysend(&node_a, amount_c_to_a, false)
        .await
        .unwrap();

    let payment_hash2 = res.payment_hash;
    let fee2 = res.fee;
    eprintln!("payment_hash2: {:?}", payment_hash2);

    node_a.wait_until_success(payment_hash1).await;
    node_c.wait_until_success(payment_hash2).await;

    let new_node_b_balance_channel_0 = node_b.get_local_balance_from_channel(channels[0]);
    let new_node_b_balance_channel_1 = node_b.get_local_balance_from_channel(channels[1]);

    let node_b_fee = new_node_b_balance_channel_0 + new_node_b_balance_channel_1
        - node_b_old_balance_channel_0
        - node_b_old_balance_channel_1;

    eprintln!("node_b_fee: {}", node_b_fee);
    eprintln!("fee1: {}, fee2: {}", fee1, fee2);
    assert_eq!(node_b_fee, fee1 + fee2);
}

#[tokio::test]
async fn test_network_three_nodes_send_each_other() {
    init_tracing();

    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((2, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 0), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        3,
        true,
    )
    .await;
    let [node_a, node_b, node_c] = nodes.try_into().expect("3 nodes");

    // Wait for the channel announcement to be broadcasted
    let node_b_old_balance_channel_0 = node_b.get_local_balance_from_channel(channels[0]);
    let node_b_old_balance_channel_1 = node_b.get_local_balance_from_channel(channels[1]);
    let node_b_old_balance_channel_2 = node_b.get_local_balance_from_channel(channels[2]);
    let node_b_old_balance_channel_3 = node_b.get_local_balance_from_channel(channels[3]);

    eprintln!(
        "node_b_old_balance_channel_0: {}, node_b_old_balance_channel_1: {}",
        node_b_old_balance_channel_0, node_b_old_balance_channel_1
    );
    eprintln!(
        "node_b_old_balance_channel_2: {}, node_b_old_balance_channel_3: {}",
        node_b_old_balance_channel_2, node_b_old_balance_channel_3
    );

    let node_a_pubkey = node_a.pubkey;
    let node_c_pubkey = node_c.pubkey;

    let amount_a_to_c = 60000;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_c_pubkey),
                amount: Some(amount_a_to_c),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };

    let res = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .unwrap();
    let payment_hash1 = res.payment_hash;
    let fee1 = res.fee;
    eprintln!("payment_hash1: {:?}", payment_hash1);

    let amount_c_to_a = 60000;
    let message = |rpc_reply| -> NetworkActorMessage {
        NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
            SendPaymentCommand {
                target_pubkey: Some(node_a_pubkey),
                amount: Some(amount_c_to_a),
                payment_hash: None,
                final_tlc_expiry_delta: None,
                tlc_expiry_limit: None,
                invoice: None,
                timeout: None,
                max_fee_amount: None,
                max_parts: None,
                keysend: Some(true),
                udt_type_script: None,
                allow_self_payment: false,
                hop_hints: None,
                dry_run: false,
            },
            rpc_reply,
        ))
    };

    let res = call!(node_c.network_actor, message)
        .expect("node_a alive")
        .unwrap();

    let payment_hash2 = res.payment_hash;
    let fee2 = res.fee;
    eprintln!("payment_hash2: {:?}", payment_hash2);

    node_a.wait_until_success(payment_hash1).await;
    node_c.wait_until_success(payment_hash2).await;

    let new_node_b_balance_channel_0 = node_b.get_local_balance_from_channel(channels[0]);
    let new_node_b_balance_channel_1 = node_b.get_local_balance_from_channel(channels[1]);
    let new_node_b_balance_channel_2 = node_b.get_local_balance_from_channel(channels[2]);
    let new_node_b_balance_channel_3 = node_b.get_local_balance_from_channel(channels[3]);

    let node_b_fee = new_node_b_balance_channel_0
        + new_node_b_balance_channel_1
        + new_node_b_balance_channel_2
        + new_node_b_balance_channel_3
        - node_b_old_balance_channel_0
        - node_b_old_balance_channel_1
        - node_b_old_balance_channel_2
        - node_b_old_balance_channel_3;

    eprintln!("node_b_fee: {}", node_b_fee);
    assert_eq!(node_b_fee, fee1 + fee2);
}

#[tokio::test]
async fn test_send_payment_bench_test() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        3,
        true,
    )
    .await;
    let [node_0, node_1, node_2] = nodes.try_into().expect("3 nodes");

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let mut all_sent = HashSet::new();

    for i in 1..=10 {
        let payment = node_0
            .send_payment_keysend(&node_2, 1000, false)
            .await
            .unwrap();
        eprintln!("payment: {:?}", payment);
        all_sent.insert(payment.payment_hash);
        eprintln!("send: {} payment_hash: {:?} sent", i, payment.payment_hash);
        tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
    }

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    loop {
        for payment_hash in all_sent.clone().iter() {
            let status = node_0.get_payment_status(*payment_hash).await;
            eprintln!("got payment: {:?} status: {:?}", payment_hash, status);
            if status == PaymentSessionStatus::Success {
                eprintln!("payment_hash: {:?} success", payment_hash);
                all_sent.remove(payment_hash);
            }
            tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
        }
        let res = node_0.node_info().await;
        eprintln!("node0 node_info: {:?}", res);
        let res = node_1.node_info().await;
        eprintln!("node1 node_info: {:?}", res);
        let res = node_2.node_info().await;
        eprintln!("node2 node_info: {:?}", res);
        if all_sent.is_empty() {
            break;
        }
    }
}

#[tokio::test]
async fn test_send_payment_three_nodes_wait_succ_bench_test() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        3,
        true,
    )
    .await;
    let [node_0, _node_1, node_2] = nodes.try_into().expect("3 nodes");

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let mut all_sent = vec![];

    for i in 1..=10 {
        let payment = node_0
            .send_payment_keysend(&node_2, 1000, false)
            .await
            .unwrap();
        all_sent.push(payment.payment_hash);
        eprintln!(
            "send: {} payment_hash: {:?} sentxx",
            i, payment.payment_hash
        );
        tokio::time::sleep(tokio::time::Duration::from_millis(1)).await;

        node_0.wait_until_success(payment.payment_hash).await;
    }
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
}

#[tokio::test]
async fn test_send_payment_three_nodes_send_each_other_bench_test() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        3,
        true,
    )
    .await;
    let [node_0, _node_1, node_2] = nodes.try_into().expect("3 nodes");

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let mut all_sent = vec![];

    for i in 1..=5 {
        let payment1 = node_0
            .send_payment_keysend(&node_2, 1000, false)
            .await
            .unwrap();
        all_sent.push(payment1.payment_hash);
        eprintln!("send: {} payment_hash: {:?} sent", i, payment1.payment_hash);

        let payment2 = node_2
            .send_payment_keysend(&node_0, 1000, false)
            .await
            .unwrap();
        all_sent.push(payment2.payment_hash);
        eprintln!("send: {} payment_hash: {:?} sent", i, payment2.payment_hash);
        tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;

        node_0.wait_until_success(payment1.payment_hash).await;
        node_2.wait_until_success(payment2.payment_hash).await;
    }
}

#[tokio::test]
async fn test_send_payment_three_nodes_send_each_other_no_wait() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        3,
        true,
    )
    .await;

    let mut all_sent = vec![];
    let node_0_balance = nodes[0].get_local_balance_from_channel(channels[0]);
    let node_2_balance = nodes[2].get_local_balance_from_channel(channels[1]);

    let amount = 100000;
    let mut node_0_sent_fee = 0;
    let mut node_0_sent_amount = 0;
    let mut node_2_sent_fee = 0;
    let mut node_2_sent_amount = 0;
    for _i in 0..4 {
        for _k in 0..3 {
            let payment1 = nodes[0]
                .send_payment_keysend(&nodes[2], amount, false)
                .await
                .unwrap();
            eprintln!(
                "send: {} payment_hash: {:?} sent, fee: {:?}",
                _i, payment1.payment_hash, payment1.fee
            );
            node_0_sent_fee += payment1.fee;
            node_0_sent_amount += amount;
        }

        let payment2 = nodes[2]
            .send_payment_keysend(&nodes[0], amount, false)
            .await
            .unwrap();
        all_sent.push((2, payment2.payment_hash));
        eprintln!(
            "send: {} payment_hash: {:?} sent, fee: {:?}",
            _i, payment2.payment_hash, payment2.fee
        );
        node_2_sent_fee += payment2.fee;
        node_2_sent_amount += amount;
    }

    loop {
        for (node_index, payment_hash) in all_sent.clone().iter() {
            let node = &nodes[*node_index];
            node.wait_until_success(*payment_hash).await;
            all_sent.retain(|x| x.1 != *payment_hash);
        }
        if all_sent.is_empty() {
            break;
        }
    }
    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;
    let new_node_0_balance = nodes[0].get_local_balance_from_channel(channels[0]);
    let new_node_2_balance = nodes[2].get_local_balance_from_channel(channels[1]);
    eprintln!(
        "node_0_balance: {}, new_node_0_balance: {}, node_0_sent_amount: {}, node_0_sent_fee: {}",
        node_0_balance, new_node_0_balance, node_0_sent_amount, node_0_sent_fee,
    );
    eprintln!(
        "node_2_balance: {}, new_node_2_balance: {}, node_2_sent_amount: {}, node_2_sent_fee: {}",
        node_2_balance, new_node_2_balance, node_2_sent_amount, node_2_sent_fee
    );
    assert_eq!(
        new_node_0_balance,
        node_0_balance - node_0_sent_fee - 8 * amount
    );
    assert_eq!(
        new_node_2_balance,
        node_2_balance - node_2_sent_fee + 8 * amount
    );
}

#[tokio::test]
async fn test_send_payment_three_nodes_bench_test() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        3,
        true,
    )
    .await;

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let mut all_sent = HashSet::new();
    let mut node_2_got_fee = 0;
    let mut node1_got_amount = 0;
    let mut node_1_sent_fee = 0;
    let mut node3_got_amount = 0;
    let mut node_3_sent_fee = 0;
    let mut node_2_ch1_sent_amount = 0;
    let mut node_2_ch2_sent_amount = 0;

    let old_node_1_amount = nodes[0].get_local_balance_from_channel(channels[0]);
    let old_node_2_chnnale1_amount = nodes[1].get_local_balance_from_channel(channels[0]);
    let old_node_2_chnnale2_amount = nodes[1].get_local_balance_from_channel(channels[1]);
    let old_node_3_amount = nodes[2].get_local_balance_from_channel(channels[1]);

    for i in 1..=4 {
        let payment1 = nodes[0]
            .send_payment_keysend(&nodes[2], 1000, false)
            .await
            .unwrap();
        all_sent.insert((1, payment1.payment_hash, payment1.fee));
        eprintln!("send: {} payment_hash: {:?} sent", i, payment1.payment_hash);
        node_1_sent_fee += payment1.fee;
        node_2_got_fee += payment1.fee;

        let payment2 = nodes[1]
            .send_payment_keysend(&nodes[2], 1000, false)
            .await
            .unwrap();
        all_sent.insert((2, payment2.payment_hash, payment2.fee));
        eprintln!("send: {} payment_hash: {:?} sent", i, payment2.payment_hash);
        node_2_ch1_sent_amount += 1000;
        node1_got_amount += 1000;

        let payment3 = nodes[1]
            .send_payment_keysend(&nodes[0], 1000, false)
            .await
            .unwrap();
        all_sent.insert((2, payment3.payment_hash, payment3.fee));
        eprintln!("send: {} payment_hash: {:?} sent", i, payment3.payment_hash);
        node_2_ch2_sent_amount += 1000;
        node3_got_amount += 1000;

        let payment4 = nodes[2]
            .send_payment_keysend(&nodes[0], 1000, false)
            .await
            .unwrap();
        all_sent.insert((3, payment4.payment_hash, payment4.fee));
        eprintln!("send: {} payment_hash: {:?} sent", i, payment4.payment_hash);
        assert!(payment4.fee > 0);
        node_3_sent_fee += payment4.fee;
        node_2_got_fee += payment4.fee;
    }

    loop {
        for (node_index, payment_hash, fee) in all_sent.clone().iter() {
            nodes[*node_index - 1]
                .wait_until_success(*payment_hash)
                .await;
            all_sent.remove(&(*node_index, *payment_hash, *fee));
        }
        let res = nodes[0].node_info().await;
        eprintln!("node1 node_info: {:?}", res);
        let res = nodes[1].node_info().await;
        eprintln!("node2 node_info: {:?}", res);
        let res = nodes[2].node_info().await;
        eprintln!("node3 node_info: {:?}", res);
        if all_sent.is_empty() {
            break;
        }
    }

    eprintln!("node_2_got_fee: {}", node_2_got_fee);
    eprintln!("node1_got_amount: {}", node1_got_amount);
    eprintln!("node3_got_amount: {}", node3_got_amount);

    // node1: sent 4 fee to node2, got 4000 from node2
    // node3: sent 4 fee to node2, got 4000 from node2
    // node2: got 8 from node1 and node3, sent 8000 to node1 and node3

    let node_1_amount = nodes[0].get_local_balance_from_channel(channels[0]);
    let node_2_chnnale1_amount = nodes[1].get_local_balance_from_channel(channels[0]);
    let node_2_chnnale2_amount = nodes[1].get_local_balance_from_channel(channels[1]);
    let node_3_amount = nodes[2].get_local_balance_from_channel(channels[1]);

    let node_1_amount_diff = node_1_amount - old_node_1_amount;
    let node_2_chnnale1_amount_diff = old_node_2_chnnale1_amount - node_2_chnnale1_amount;
    let node_2_chnnale2_amount_diff = old_node_2_chnnale2_amount - node_2_chnnale2_amount;
    let node_3_amount_diff = node_3_amount - old_node_3_amount;

    assert_eq!(node_1_amount_diff, node1_got_amount - node_1_sent_fee);
    // got 3996

    assert_eq!(
        node_2_chnnale1_amount_diff,
        node_2_ch1_sent_amount - node_1_sent_fee
    );
    // sent 3996

    assert_eq!(
        node_2_chnnale2_amount_diff,
        node_2_ch2_sent_amount - node_3_sent_fee
    );
    // sent 3996

    assert_eq!(node_3_amount_diff, node3_got_amount - node_3_sent_fee);
    // got 3996
}

#[tokio::test]
async fn test_send_payment_middle_hop_stopped() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((2, 3), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((0, 4), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((4, 3), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        5,
        true,
    )
    .await;
    let [node_0, _node_1, _node_2, node_3, mut node_4] = nodes.try_into().expect("5 nodes");

    // dry run node_0 -> node_3 will select  0 -> 4 -> 3
    let res = node_0
        .send_payment_keysend(&node_3, 1000, true)
        .await
        .unwrap();
    eprintln!("res: {:?}", res);
    assert_eq!(res.fee, 1);

    // node_4 stopped
    node_4.stop().await;
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    // when node_4 stopped, node 0 learned that channel 0 -> 4 was not available
    // so it will try another path 0 -> 1 -> 2 -> 3
    let res = node_0
        .send_payment_keysend(&node_3, 1000, false)
        .await
        .unwrap();
    eprintln!("res: {:?}", res);
    assert_eq!(res.fee, 3);

    node_0.wait_until_success(res.payment_hash).await;
}

#[tokio::test]
async fn test_send_payment_middle_hop_stopped_retry_longer_path() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((2, 3), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((0, 4), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((4, 5), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((5, 6), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((6, 3), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        7,
        true,
    )
    .await;
    let [node_0, _node_1, mut node_2, mut node_3, _node_4, _node_5, _node_6] =
        nodes.try_into().expect("7 nodes");

    // dry run node_0 -> node_3 will select  0 -> 1 -> 2 -> 3
    let res = node_0
        .send_payment_keysend(&node_3, 1000, true)
        .await
        .unwrap();
    eprintln!("res: {:?}", res);
    assert_eq!(res.fee, 3);
    node_0.expect_router_used_channel(&res, channels[1]).await;

    // node_2 stopped
    node_2.stop().await;
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let res = node_0
        .send_payment_keysend(&node_3, 1000, true)
        .await
        .unwrap();
    eprintln!("res: {:?}", res);
    // when node_2 stopped, the first try path is still 0 -> 1 -> 2 -> 3
    // so the fee is 3
    assert_eq!(res.fee, 3);
    node_0.expect_router_used_channel(&res, channels[1]).await;

    let res = node_0
        .send_payment_keysend(&node_3, 1000, false)
        .await
        .unwrap();
    eprintln!("res: {:?}", res);
    assert_eq!(res.fee, 3);

    node_0.wait_until_success(res.payment_hash).await;
    let payment = node_0.get_payment_result(res.payment_hash).await;
    eprintln!("payment: {:?}", payment);

    // payment success with a longer path 0 -> 4 -> 5 -> 6 -> 3
    assert_eq!(payment.fee, 5);
    node_0
        .expect_payment_used_channel(res.payment_hash, channels[5])
        .await;

    // node_3 stopped, payment will fail
    node_3.stop().await;
    let res = node_0
        .send_payment_keysend(&node_3, 1000, false)
        .await
        .unwrap();

    eprintln!("res: {:?}", res);
    assert_eq!(res.fee, 5);

    node_0.wait_until_failed(res.payment_hash).await;
}

#[tokio::test]
async fn test_send_payment_max_value_in_flight_in_first_hop() {
    // https://github.com/nervosnetwork/fiber/issues/450

    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let nodes = NetworkNode::new_interconnected_nodes(2).await;
    let [mut node_0, mut node_1] = nodes.try_into().expect("2 nodes");
    let (_channel_id, _funding_tx) = {
        establish_channel_between_nodes(
            &mut node_0,
            &mut node_1,
            true,
            HUGE_CKB_AMOUNT,
            HUGE_CKB_AMOUNT,
            None,
            Some(100000000),
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
        )
        .await
    };

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let res = node_0
        .send_payment_keysend(&node_1, 100000000 + 1, false)
        .await
        .unwrap();
    eprintln!("res: {:?}", res);
    assert_eq!(res.fee, 0);

    let payment_hash = res.payment_hash;
    node_0.wait_until_failed(payment_hash).await;

    // now we can not send payment with amount 100000000 + 1 with dry_run
    // since there is already payment history data
    let res = node_0
        .send_payment_keysend(&node_1, 100000000 + 1, true)
        .await;
    eprintln!("res: {:?}", res);
    assert!(res.unwrap_err().to_string().contains("no path found"));

    // if we build a nother channel with higher max_value_in_flight
    // we can send payment with amount 100000000 + 1 with this new channel
    let (channel_id, _funding_tx) = {
        establish_channel_between_nodes(
            &mut node_0,
            &mut node_1,
            true,
            HUGE_CKB_AMOUNT,
            HUGE_CKB_AMOUNT,
            None,
            Some(100000000 + 2),
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
        )
        .await
    };

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let res = node_0
        .send_payment_keysend(&node_1, 100000000 + 1, false)
        .await
        .unwrap();

    let payment_hash = res.payment_hash;
    node_0.wait_until_success(payment_hash).await;
    node_0
        .expect_payment_used_channel(payment_hash, channel_id)
        .await;
}

#[tokio::test]
async fn test_send_payment_target_hop_stopped() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((2, 3), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((3, 4), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        5,
        true,
    )
    .await;
    let [node_0, _node_1, _node_2, _node_3, mut node_4] = nodes.try_into().expect("5 nodes");

    // dry run node_0 -> node_4 will select  0 -> 1 -> 2 -> 3 -> 4
    let res = node_0
        .send_payment_keysend(&node_4, 1000, true)
        .await
        .unwrap();
    eprintln!("res: {:?}", res);
    assert_eq!(res.fee, 5);

    // node_4 stopped
    node_4.stop().await;
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let res = node_0
        .send_payment_keysend(&node_4, 1000, false)
        .await
        .unwrap();
    eprintln!("res: {:?}", res);
    // when node_4 stopped, the first try path is still 0 -> 1 -> 2 -> 3 -> 4
    // so the fee is 5
    assert_eq!(res.fee, 5);

    node_0.wait_until_failed(res.payment_hash).await;
}

#[tokio::test]
async fn test_send_payment_middle_hop_balance_is_not_enough() {
    // https://github.com/nervosnetwork/fiber/issues/286
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((2, 3), (MIN_RESERVED_CKB, HUGE_CKB_AMOUNT)),
        ],
        4,
        true,
    )
    .await;
    let [node_0, _node_1, _node_2, node_3] = nodes.try_into().expect("3 nodes");

    let res = node_0
        .send_payment_keysend(&node_3, 1000, false)
        .await
        .unwrap();
    eprintln!("res: {:?}", res);

    // path is still 0 -> 1 -> 2 -> 3,
    // 2 -> 3 don't have enough balance
    node_0.wait_until_failed(res.payment_hash).await;
    let result = node_0.get_payment_result(res.payment_hash).await;
    eprintln!("debug result: {:?}", result);
    assert!(result
        .failed_error
        .expect("got error")
        .contains("Failed to build route"));
}

#[tokio::test]
async fn test_send_payment_middle_hop_update_fee_send_payment_failed() {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((2, 3), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        4,
        true,
    )
    .await;
    let [node_0, _node_1, node_2, node_3] = nodes.try_into().expect("4 nodes");

    // node_2 update fee rate to a higher one, so the payment will fail
    let res = node_0
        .send_payment_keysend(&node_3, 1000, false)
        .await
        .unwrap();
    eprintln!("res: {:?}", res);
    let payment_hash = res.payment_hash;

    node_2
        .update_channel_with_command(
            channels[2],
            UpdateCommand {
                enabled: None,
                tlc_expiry_delta: None,
                tlc_minimum_value: None,
                tlc_fee_proportional_millionths: Some(100000),
            },
        )
        .await;

    node_0.wait_until_failed(payment_hash).await;
}

#[tokio::test]
async fn test_send_payment_middle_hop_update_fee_multiple_payments() {
    // https://github.com/nervosnetwork/fiber/issues/480
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((2, 3), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        4,
        true,
    )
    .await;

    let mut all_sent = HashSet::new();

    for _i in 0..5 {
        let res = nodes[0]
            .send_payment_keysend(&nodes[3], 1000, false)
            .await
            .unwrap();
        all_sent.insert(res.payment_hash);
        tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
    }

    nodes[2]
        .update_channel_with_command(
            channels[2],
            UpdateCommand {
                enabled: None,
                tlc_expiry_delta: None,
                tlc_minimum_value: None,
                tlc_fee_proportional_millionths: Some(100000),
            },
        )
        .await;

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    loop {
        for i in 0..4 {
            assert!(nodes[i].get_triggered_unexpected_events().await.is_empty());
        }

        for payment_hash in all_sent.clone().iter() {
            let status = nodes[0].get_payment_status(*payment_hash).await;
            //eprintln!("got payment: {:?} status: {:?}", payment_hash, status);
            if status == PaymentSessionStatus::Failed || status == PaymentSessionStatus::Success {
                eprintln!("payment_hash: {:?} got status : {:?}", payment_hash, status);
                all_sent.remove(payment_hash);
            }
            tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
        }
        if all_sent.is_empty() {
            break;
        }
    }
}

#[tokio::test]
async fn test_send_payment_middle_hop_update_fee_should_recovery() {
    // a variant test from
    // https://github.com/nervosnetwork/fiber/issues/480
    // in this test, we will make sure the payment should recovery after the fee is updated by the middle hop
    // there are two channels between node_1 and node_2, they are with the same fee rate
    // path finding will pick the channel with latest time, so channels[2] will be picked
    // but we will update the fee rate of channels[2] to a higher one
    // so the payment will fail, but after the payment failed, the path finding should pick the channels[1] in the next try
    // in the end, all the payments should success
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((1, 2), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
            ((2, 3), (HUGE_CKB_AMOUNT, HUGE_CKB_AMOUNT)),
        ],
        4,
        true,
    )
    .await;
    let mut all_sent = HashSet::new();

    let tx_count = 6;
    for _i in 0..tx_count {
        let res = nodes[0]
            .send_payment_keysend(&nodes[3], 1000, false)
            .await
            .unwrap();
        all_sent.insert(res.payment_hash);
        tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
    }

    nodes[1]
        .update_channel_with_command(
            channels[2],
            UpdateCommand {
                enabled: None,
                tlc_expiry_delta: None,
                tlc_minimum_value: None,
                tlc_fee_proportional_millionths: Some(100000),
            },
        )
        .await;

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;

    let mut succ_count = 0;
    loop {
        for i in 0..4 {
            assert!(nodes[i].get_triggered_unexpected_events().await.is_empty());
        }

        for payment_hash in all_sent.clone().iter() {
            let status = nodes[0].get_payment_status(*payment_hash).await;
            if status == PaymentSessionStatus::Success || status == PaymentSessionStatus::Failed {
                eprintln!("payment_hash: {:?} got status : {:?}", payment_hash, status);
                all_sent.remove(payment_hash);
                if status == PaymentSessionStatus::Success {
                    succ_count += 1;
                }
            }

            tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
        }
        if all_sent.is_empty() {
            break;
        }
    }

    assert_eq!(succ_count, tx_count);
    let channel_state = nodes[0].get_channel_actor_state(channels[0]);
    assert_eq!(channel_state.get_offered_tlc_balance(true), 0);
    assert!(channel_state.get_offered_tlc_balance(false) > 0);
}

async fn run_complex_network_with_params(
    funding_amount: u128,
    payment_amount_gen: impl Fn() -> u128,
) -> Vec<(Hash256, PaymentSessionStatus)> {
    init_tracing();
    let _span = tracing::info_span!("node", node = "test").entered();
    let (nodes, _channels) = create_n_nodes_and_channels_with_index_amounts(
        &[
            ((0, 1), (funding_amount, funding_amount)),
            ((1, 2), (funding_amount, funding_amount)),
            ((3, 4), (funding_amount, funding_amount)),
            ((4, 5), (funding_amount, funding_amount)),
            ((0, 3), (funding_amount, funding_amount)),
            ((1, 4), (funding_amount, funding_amount)),
            ((2, 5), (funding_amount, funding_amount)),
        ],
        6,
        true,
    )
    .await;

    let mut all_sent = HashSet::new();
    for _k in 0..3 {
        for i in 0..6 {
            let payment_amount = payment_amount_gen();
            let res = nodes[i]
                .send_payment_keysend_to_self(payment_amount, false)
                .await;
            if let Ok(res) = res {
                let payment_hash = res.payment_hash;
                all_sent.insert((i, payment_hash));
            }
        }
    }

    let mut result = vec![];
    loop {
        for i in 0..6 {
            let unexpected_events = nodes[i].get_triggered_unexpected_events().await;
            if !unexpected_events.is_empty() {
                eprintln!("node_{} got unexpected events: {:?}", i, unexpected_events);
                unreachable!("unexpected events");
            }
        }

        for (i, payment_hash) in all_sent.clone().into_iter() {
            let status = nodes[i].get_payment_status(payment_hash).await;
            eprintln!("payment_hash: {:?} got status : {:?}", payment_hash, status);
            if matches!(
                status,
                PaymentSessionStatus::Success | PaymentSessionStatus::Failed
            ) {
                result.push((payment_hash, status));
                all_sent.remove(&(i, payment_hash));
            }
            tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
        }
        if all_sent.is_empty() {
            break;
        }
    }

    // make sure all the channels are still workable with small accounts
    for i in 0..6 {
        if let Ok(res) = nodes[i].send_payment_keysend_to_self(500, false).await {
            nodes[i].wait_until_success(res.payment_hash).await;
        }
    }

    result
}

#[tokio::test]
async fn test_send_payment_complex_network_payself_all_succeed() {
    // from issue 475
    // channel amount is enough, so all payments should success
    let res = run_complex_network_with_params(MIN_RESERVED_CKB + 100000000, || 1000).await;
    let failed_count = res
        .iter()
        .filter(|(_, status)| *status == PaymentSessionStatus::Failed)
        .count();

    assert_eq!(failed_count, 0);
}

#[tokio::test]
async fn test_send_payment_complex_network_payself_amount_exceeded() {
    // variant from issue 475
    // the channel amount is not enough, so payments maybe be failed
    let ckb_unit = 100_000_000;
    let res = run_complex_network_with_params(MIN_RESERVED_CKB + 1000 * ckb_unit, || {
        (400_u128 + (rand::random::<u64>() % 100) as u128) * ckb_unit
    })
    .await;

    // some may failed and some may success
    let failed_count = res
        .iter()
        .filter(|(_, status)| *status == PaymentSessionStatus::Failed)
        .count();
    assert!(failed_count > 0);
    let succ_count = res
        .iter()
        .filter(|(_, status)| *status == PaymentSessionStatus::Success)
        .count();
    assert!(succ_count > 0);
}


================================================
File: src/fiber/tests/serde_utils.rs
================================================
use crate::fiber::serde_utils::{EntityHex, SliceHex, U128Hex, U16Hex, U32Hex, U64Hex};
use ckb_types::packed::Script;
use ckb_types::prelude::*;
use serde::{Deserialize, Serialize};
use serde_with::serde_as;

#[serde_as]
#[derive(Debug, PartialEq, Serialize, Deserialize)]
struct Foo {
    #[serde_as(as = "SliceHex")]
    slice: [u8; 4],
    #[serde_as(as = "Option<EntityHex>")]
    enity: Option<Script>,
    #[serde_as(as = "U128Hex")]
    bar_128: u128,
    #[serde_as(as = "U64Hex")]
    bar_64: u64,
    #[serde_as(as = "U32Hex")]
    bar_32: u32,
    #[serde_as(as = "U16Hex")]
    bar_16: u16,
}

#[test]
fn test_serde_utils() {
    let foo = Foo {
        slice: [1, 2, 3, 4],
        enity: Some(Script::new_builder().build()),
        bar_128: 0xdeadbeef,
        bar_64: 0x123,
        bar_32: 0x10,
        bar_16: 0xa,
    };

    let json = r#"{"slice":"0x01020304","enity":"0x3500000010000000300000003100000000000000000000000000000000000000000000000000000000000000000000000000000000","bar_128":"0xdeadbeef","bar_64":"0x123","bar_32":"0x10","bar_16":"0xa"}"#;
    assert_eq!(serde_json::to_string(&foo).unwrap(), json);
    assert_eq!(serde_json::from_str::<Foo>(json).unwrap(), foo);
}


================================================
File: src/fiber/tests/test_utils.rs
================================================
use crate::fiber::channel::ChannelActorState;
use crate::fiber::channel::ChannelActorStateStore;
use crate::fiber::channel::ChannelCommand;
use crate::fiber::channel::ChannelCommandWithId;
use crate::fiber::channel::ReloadParams;
use crate::fiber::channel::UpdateCommand;
use crate::fiber::graph::NetworkGraphStateStore;
use crate::fiber::graph::PaymentSession;
use crate::fiber::graph::PaymentSessionStatus;
use crate::fiber::network::NodeInfoResponse;
use crate::fiber::network::SendPaymentCommand;
use crate::fiber::network::SendPaymentResponse;
use crate::fiber::types::EcdsaSignature;
use crate::fiber::types::Pubkey;
use crate::invoice::CkbInvoice;
use crate::invoice::CkbInvoiceStatus;
use crate::invoice::InvoiceStore;
use ckb_jsonrpc_types::Status;
use ckb_types::packed::OutPoint;
use ckb_types::{core::TransactionView, packed::Byte32};
use ractor::{call, Actor, ActorRef};
use rand::rngs::OsRng;
use secp256k1::{Message, Secp256k1};
use std::collections::HashMap;
use std::collections::HashSet;
use std::{
    env,
    ffi::OsStr,
    mem::ManuallyDrop,
    path::{Path, PathBuf},
    sync::Arc,
    time::Duration,
};
use tempfile::TempDir as OldTempDir;
use tentacle::{multiaddr::MultiAddr, secio::PeerId};
use tokio::sync::RwLock as TokioRwLock;
use tokio::{
    select,
    sync::{mpsc, OnceCell},
    time::sleep,
};

use crate::fiber::graph::ChannelInfo;
use crate::fiber::graph::NodeInfo;
use crate::fiber::network::{AcceptChannelCommand, OpenChannelCommand};
use crate::fiber::types::Privkey;
use crate::store::Store;
use crate::{
    actors::{RootActor, RootActorMessage},
    ckb::tests::test_utils::{
        get_tx_from_hash, submit_tx, trace_tx, trace_tx_hash, MockChainActor,
    },
    ckb::CkbChainMessage,
    fiber::graph::NetworkGraph,
    fiber::network::{
        NetworkActor, NetworkActorCommand, NetworkActorMessage, NetworkActorStartArguments,
    },
    fiber::types::Hash256,
    tasks::{new_tokio_cancellation_token, new_tokio_task_tracker},
    FiberConfig, NetworkServiceEvent,
};

static RETAIN_VAR: &str = "TEST_TEMP_RETAIN";
pub(crate) const MIN_RESERVED_CKB: u128 = 4200000000;
pub(crate) const HUGE_CKB_AMOUNT: u128 = MIN_RESERVED_CKB + 1000000000000_u128;

#[derive(Debug)]
pub struct TempDir(ManuallyDrop<OldTempDir>);

impl TempDir {
    pub fn new<S: AsRef<OsStr>>(prefix: S) -> Self {
        Self(ManuallyDrop::new(
            OldTempDir::with_prefix(prefix).expect("create temp directory"),
        ))
    }

    pub fn to_str(&self) -> &str {
        self.0.path().to_str().expect("path to str")
    }
}

impl AsRef<Path> for TempDir {
    fn as_ref(&self) -> &Path {
        self.0.path()
    }
}

impl Drop for TempDir {
    fn drop(&mut self) {
        let retain = env::var(RETAIN_VAR);
        if retain.is_ok() {
            println!(
                "Keeping temp directory {:?}, as environment variable {RETAIN_VAR} set",
                self.as_ref()
            );
        } else {
            println!(
                "Deleting temp directory {:?}. To keep this directory, set environment variable {RETAIN_VAR} to anything",
                self.as_ref()
            );
            unsafe {
                ManuallyDrop::drop(&mut self.0);
            }
        }
    }
}

pub fn init_tracing() {
    use std::sync::Once;

    static INIT: Once = Once::new();

    INIT.call_once(|| {
        tracing_subscriber::fmt()
            .with_env_filter(tracing_subscriber::EnvFilter::from_default_env())
            .pretty()
            .init();
    });
}

static ROOT_ACTOR: OnceCell<ActorRef<RootActorMessage>> = OnceCell::const_new();

pub async fn get_test_root_actor() -> ActorRef<RootActorMessage> {
    use futures::FutureExt;
    // Only one actor with the same name can be created.
    ROOT_ACTOR
        .get_or_init(|| {
            Actor::spawn(
                Some("test root actor".to_string()),
                RootActor {},
                (new_tokio_task_tracker(), new_tokio_cancellation_token()),
            )
            .map(|r| r.expect("start test root actor").0)
        })
        .await
        .clone()
}

pub fn get_fiber_config<P: AsRef<Path>>(base_dir: P, node_name: Option<&str>) -> FiberConfig {
    let base_dir = base_dir.as_ref();
    FiberConfig {
        announced_node_name: node_name
            .or(base_dir.file_name().unwrap().to_str())
            .map(Into::into),
        announce_listening_addr: Some(true),
        base_dir: Some(PathBuf::from(base_dir)),
        // This config is needed for the timely processing of gossip messages.
        // Without this, some tests may fail due to the delay in processing gossip messages.
        gossip_network_maintenance_interval_ms: Some(50),
        // This config is needed for the timely processing of gossip messages.
        // Without this, some tests may fail due to the delay in processing gossip messages.
        gossip_store_maintenance_interval_ms: Some(50),
        auto_accept_channel_ckb_funding_amount: Some(0), // Disable auto accept for unit tests
        announce_private_addr: Some(true),               // Announce private address for unit tests
        ..Default::default()
    }
}

// Mock function to create a dummy EcdsaSignature
pub fn mock_ecdsa_signature() -> EcdsaSignature {
    let secp = Secp256k1::new();
    let mut rng = OsRng;
    let (secret_key, _public_key) = secp.generate_keypair(&mut rng);
    let message = Message::from_digest_slice(&[0u8; 32]).expect("32 bytes");
    let signature = secp.sign_ecdsa(&message, &secret_key);
    EcdsaSignature(signature)
}

pub fn generate_store() -> Store {
    let temp_dir = TempDir::new("test-fnn-node");
    let store = Store::new(temp_dir.as_ref());
    store.expect("create store")
}

#[derive(Debug)]
pub struct NetworkNode {
    /// The base directory of the node, will be deleted after this struct dropped.
    pub base_dir: Arc<TempDir>,
    pub node_name: Option<String>,
    pub store: Store,
    pub channels_tx_map: HashMap<Hash256, Hash256>,
    pub fiber_config: FiberConfig,
    pub listening_addrs: Vec<MultiAddr>,
    pub network_actor: ActorRef<NetworkActorMessage>,
    pub network_graph: Arc<TokioRwLock<NetworkGraph<Store>>>,
    pub chain_actor: ActorRef<CkbChainMessage>,
    pub private_key: Privkey,
    pub peer_id: PeerId,
    pub event_emitter: mpsc::Receiver<NetworkServiceEvent>,
    pub pubkey: Pubkey,
    pub unexpected_events: Arc<TokioRwLock<HashSet<String>>>,
    pub triggered_unexpected_events: Arc<TokioRwLock<Vec<String>>>,
}

pub struct NetworkNodeConfig {
    base_dir: Arc<TempDir>,
    node_name: Option<String>,
    store: Store,
    fiber_config: FiberConfig,
}

impl NetworkNodeConfig {
    pub fn builder() -> NetworkNodeConfigBuilder {
        NetworkNodeConfigBuilder::new()
    }
}

pub struct NetworkNodeConfigBuilder {
    base_dir: Option<Arc<TempDir>>,
    node_name: Option<String>,
    // We may generate a FiberConfig based on the base_dir and node_name,
    // but allow user to override it.
    #[allow(clippy::type_complexity)]
    fiber_config_updater: Option<Box<dyn FnOnce(&mut FiberConfig) + 'static>>,
}

impl Default for NetworkNodeConfigBuilder {
    fn default() -> Self {
        Self::new()
    }
}

impl NetworkNodeConfigBuilder {
    pub fn new() -> Self {
        Self {
            base_dir: None,
            node_name: None,
            fiber_config_updater: None,
        }
    }

    pub fn base_dir(mut self, base_dir: Arc<TempDir>) -> Self {
        self.base_dir = Some(base_dir);
        self
    }

    pub fn base_dir_prefix(self, prefix: &str) -> Self {
        self.base_dir(Arc::new(TempDir::new(prefix)))
    }

    pub fn node_name(mut self, node_name: Option<String>) -> Self {
        self.node_name = node_name;
        self
    }

    pub fn fiber_config_updater(
        mut self,
        updater: impl FnOnce(&mut FiberConfig) + 'static,
    ) -> Self {
        self.fiber_config_updater = Some(Box::new(updater));
        self
    }

    pub fn build(self) -> NetworkNodeConfig {
        let base_dir = self
            .base_dir
            .clone()
            .unwrap_or_else(|| Arc::new(TempDir::new("test-fnn-node")));
        let node_name = self.node_name.clone();
        let store = generate_store();
        let fiber_config = get_fiber_config(base_dir.as_ref(), node_name.as_deref());
        let mut config = NetworkNodeConfig {
            base_dir,
            node_name,
            store,
            fiber_config,
        };
        if let Some(updater) = self.fiber_config_updater {
            updater(&mut config.fiber_config);
        }
        config
    }
}

#[allow(clippy::too_many_arguments)]
pub(crate) async fn establish_channel_between_nodes(
    node_a: &mut NetworkNode,
    node_b: &mut NetworkNode,
    public: bool,
    node_a_funding_amount: u128,
    node_b_funding_amount: u128,
    a_max_tlc_number_in_flight: Option<u64>,
    a_max_tlc_value_in_flight: Option<u128>,
    a_tlc_expiry_delta: Option<u64>,
    a_tlc_min_value: Option<u128>,
    a_tlc_fee_proportional_millionths: Option<u128>,
    b_max_tlc_number_in_flight: Option<u64>,
    b_max_tlc_value_in_flight: Option<u128>,
    b_tlc_expiry_delta: Option<u64>,
    b_tlc_min_value: Option<u128>,
    b_tlc_fee_proportional_millionths: Option<u128>,
) -> (Hash256, TransactionView) {
    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::OpenChannel(
            OpenChannelCommand {
                peer_id: node_b.peer_id.clone(),
                public,
                shutdown_script: None,
                funding_amount: node_a_funding_amount,
                funding_udt_type_script: None,
                commitment_fee_rate: None,
                commitment_delay_epoch: None,
                funding_fee_rate: None,
                tlc_expiry_delta: a_tlc_expiry_delta,
                tlc_min_value: a_tlc_min_value,
                tlc_fee_proportional_millionths: a_tlc_fee_proportional_millionths,
                max_tlc_number_in_flight: a_max_tlc_number_in_flight,
                max_tlc_value_in_flight: a_max_tlc_value_in_flight,
            },
            rpc_reply,
        ))
    };
    let open_channel_result = call!(node_a.network_actor, message)
        .expect("node_a alive")
        .expect("open channel success");

    node_b
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelPendingToBeAccepted(peer_id, channel_id) => {
                println!("A channel ({:?}) to {:?} create", &channel_id, peer_id);
                assert_eq!(peer_id, &node_a.peer_id);
                true
            }
            _ => false,
        })
        .await;
    let message = |rpc_reply| {
        NetworkActorMessage::Command(NetworkActorCommand::AcceptChannel(
            AcceptChannelCommand {
                temp_channel_id: open_channel_result.channel_id,
                funding_amount: node_b_funding_amount,
                shutdown_script: None,
                max_tlc_number_in_flight: b_max_tlc_number_in_flight,
                max_tlc_value_in_flight: b_max_tlc_value_in_flight,
                min_tlc_value: b_tlc_min_value,
                tlc_fee_proportional_millionths: b_tlc_fee_proportional_millionths,
                tlc_expiry_delta: b_tlc_expiry_delta,
            },
            rpc_reply,
        ))
    };
    let accept_channel_result = call!(node_b.network_actor, message)
        .expect("node_b alive")
        .expect("accept channel success");
    let new_channel_id = accept_channel_result.new_channel_id;

    let funding_tx_outpoint = node_a
        .expect_to_process_event(|event| match event {
            NetworkServiceEvent::ChannelReady(peer_id, channel_id, funding_tx_outpoint) => {
                println!(
                    "A channel ({:?}) to {:?} is now ready",
                    &channel_id, &peer_id
                );
                assert_eq!(peer_id, &node_b.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                Some(funding_tx_outpoint.clone())
            }
            _ => None,
        })
        .await;

    node_b
        .expect_event(|event| match event {
            NetworkServiceEvent::ChannelReady(peer_id, channel_id, _funding_tx_hash) => {
                println!(
                    "A channel ({:?}) to {:?} is now ready",
                    &channel_id, &peer_id
                );
                assert_eq!(peer_id, &node_a.peer_id);
                assert_eq!(channel_id, &new_channel_id);
                true
            }
            _ => false,
        })
        .await;

    let funding_tx = node_a
        .get_tx_from_hash(funding_tx_outpoint.tx_hash())
        .await
        .expect("tx found");

    node_a.add_channel_tx(new_channel_id, funding_tx.clone());
    node_b.add_channel_tx(new_channel_id, funding_tx.clone());

    (new_channel_id, funding_tx)
}

pub(crate) async fn create_nodes_with_established_channel(
    node_a_funding_amount: u128,
    node_b_funding_amount: u128,
    public: bool,
) -> (NetworkNode, NetworkNode, Hash256) {
    let [mut node_a, mut node_b] = NetworkNode::new_n_interconnected_nodes().await;

    let (channel_id, _funding_tx) = establish_channel_between_nodes(
        &mut node_a,
        &mut node_b,
        public,
        node_a_funding_amount,
        node_b_funding_amount,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
    )
    .await;

    (node_a, node_b, channel_id)
}

pub(crate) async fn create_3_nodes_with_established_channel(
    (channel_1_amount_a, channel_1_amount_b): (u128, u128),
    (channel_2_amount_b, channel_2_amount_c): (u128, u128),
    public: bool,
) -> (NetworkNode, NetworkNode, NetworkNode, Hash256, Hash256) {
    let (nodes, channels) = create_n_nodes_with_established_channel(
        &[
            (channel_1_amount_a, channel_1_amount_b),
            (channel_2_amount_b, channel_2_amount_c),
        ],
        3,
        public,
    )
    .await;
    let [node_a, node_b, node_c] = nodes.try_into().expect("3 nodes");
    (node_a, node_b, node_c, channels[0], channels[1])
}

// make a network like A -> B -> C -> D
pub(crate) async fn create_n_nodes_with_established_channel(
    amounts: &[(u128, u128)],
    n: usize,
    public: bool,
) -> (Vec<NetworkNode>, Vec<Hash256>) {
    assert!(n >= 2);
    assert_eq!(amounts.len(), n - 1);

    let nodes_index_map: Vec<((usize, usize), (u128, u128))> = (0..n - 1)
        .map(|i| ((i, i + 1), (amounts[i].0, amounts[i].1)))
        .collect();

    create_n_nodes_and_channels_with_index_amounts(&nodes_index_map, n, public).await
}

#[allow(clippy::type_complexity)]
pub(crate) async fn create_n_nodes_and_channels_with_index_amounts(
    amounts: &[((usize, usize), (u128, u128))],
    n: usize,
    public: bool,
) -> (Vec<NetworkNode>, Vec<Hash256>) {
    assert!(n >= 2);
    let mut nodes = NetworkNode::new_interconnected_nodes(n).await;
    let mut channels = vec![];

    for &((i, j), (node_a_amount, node_b_amount)) in amounts.iter() {
        let (channel_id, funding_tx) = {
            let (node_a, node_b) = {
                // avoid borrow nodes as mutbale more than once
                assert_ne!(i, j);
                if i < j {
                    let (left, right) = nodes.split_at_mut(i + 1);
                    (&mut left[i], &mut right[j - i - 1])
                } else {
                    let (left, right) = nodes.split_at_mut(j + 1);
                    (&mut right[i - j - 1], &mut left[j])
                }
            };
            establish_channel_between_nodes(
                node_a,
                node_b,
                public,
                node_a_amount,
                node_b_amount,
                None,
                None,
                None,
                None,
                None,
                None,
                None,
                None,
                None,
                None,
            )
            .await
        };
        channels.push(channel_id);
        // all the other nodes submit_tx
        for node in nodes.iter_mut() {
            let res = node.submit_tx(funding_tx.clone()).await;
            node.add_channel_tx(channel_id, funding_tx.clone());
            assert_eq!(res, Status::Committed);
        }
    }
    // sleep for a while to make sure network graph is updated
    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
    (nodes, channels)
}

impl NetworkNode {
    pub async fn new() -> Self {
        Self::new_with_node_name_opt(None).await
    }

    pub fn get_private_key(&self) -> &Privkey {
        &self.private_key
    }

    pub fn get_public_key(&self) -> Pubkey {
        self.private_key.pubkey()
    }

    pub fn get_peer_id(&self) -> PeerId {
        self.private_key.pubkey().tentacle_peer_id()
    }

    pub fn get_node_address(&self) -> &MultiAddr {
        &self.listening_addrs[0]
    }

    pub fn get_local_balance_from_channel(&self, channel_id: Hash256) -> u128 {
        self.store
            .get_channel_actor_state(&channel_id)
            .expect("get channel")
            .to_local_amount
    }

    pub fn get_remote_balance_from_channel(&self, channel_id: Hash256) -> u128 {
        self.store
            .get_channel_actor_state(&channel_id)
            .expect("get channel")
            .to_remote_amount
    }

    pub fn get_channel_actor_state(&self, channel_id: Hash256) -> ChannelActorState {
        self.store
            .get_channel_actor_state(&channel_id)
            .expect("get channel")
    }

    pub fn insert_invoice(&mut self, invoice: CkbInvoice, preimage: Option<Hash256>) {
        self.store
            .insert_invoice(invoice, preimage)
            .expect("insert success");
    }

    pub fn get_invoice_status(&mut self, payment_hash: &Hash256) -> Option<CkbInvoiceStatus> {
        self.store.get_invoice_status(payment_hash)
    }

    pub fn cancel_invoice(&mut self, payment_hash: &Hash256) {
        self.store
            .update_invoice_status(payment_hash, CkbInvoiceStatus::Cancelled)
            .expect("cancell success");
    }

    pub async fn send_payment(
        &self,
        command: SendPaymentCommand,
    ) -> std::result::Result<SendPaymentResponse, String> {
        let message = |rpc_reply| -> NetworkActorMessage {
            NetworkActorMessage::Command(NetworkActorCommand::SendPayment(command, rpc_reply))
        };

        let res = call!(self.network_actor, message).expect("source_node alive");
        eprintln!("result: {:?}", res);
        res
    }

    pub async fn send_payment_keysend(
        &self,
        recipient: &NetworkNode,
        amount: u128,
        dry_run: bool,
    ) -> std::result::Result<SendPaymentResponse, String> {
        self.send_payment(SendPaymentCommand {
            target_pubkey: Some(recipient.pubkey),
            amount: Some(amount),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: None,
            invoice: None,
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: Some(true),
            udt_type_script: None,
            allow_self_payment: false,
            dry_run,
            hop_hints: None,
        })
        .await
    }

    pub async fn send_payment_keysend_to_self(
        &self,
        amount: u128,
        dry_run: bool,
    ) -> std::result::Result<SendPaymentResponse, String> {
        let pubkey = self.pubkey;
        self.send_payment(SendPaymentCommand {
            target_pubkey: Some(pubkey),
            amount: Some(amount),
            payment_hash: None,
            final_tlc_expiry_delta: None,
            tlc_expiry_limit: None,
            invoice: None,
            timeout: None,
            max_fee_amount: None,
            max_parts: None,
            keysend: Some(true),
            udt_type_script: None,
            allow_self_payment: true,
            dry_run,
            hop_hints: None,
        })
        .await
    }

    pub async fn assert_payment_status(
        &self,
        payment_hash: Hash256,
        expected_status: PaymentSessionStatus,
        expected_retried: Option<u32>,
    ) {
        let status = self.get_payment_status(payment_hash).await;
        assert_eq!(status, expected_status);

        if let Some(expected_retried) = expected_retried {
            let payment_session = self.get_payment_session(payment_hash).unwrap();
            assert_eq!(payment_session.retried_times, expected_retried);
        }
    }

    pub async fn get_payment_status(&self, payment_hash: Hash256) -> PaymentSessionStatus {
        self.get_payment_result(payment_hash).await.status
    }

    pub async fn get_payment_result(&self, payment_hash: Hash256) -> SendPaymentResponse {
        let message = |rpc_reply| -> NetworkActorMessage {
            NetworkActorMessage::Command(NetworkActorCommand::GetPayment(payment_hash, rpc_reply))
        };
        call!(self.network_actor, message)
            .expect("node_a alive")
            .unwrap()
    }

    pub async fn expect_payment_used_channel(&self, payment_hash: Hash256, channel_id: Hash256) {
        let payment_result = self.get_payment_result(payment_hash).await;
        self.expect_router_used_channel(&payment_result, channel_id)
            .await;
    }

    pub async fn expect_router_used_channel(
        &self,
        payment_result: &SendPaymentResponse,
        channel_id: Hash256,
    ) {
        let used_channes = payment_result
            .router
            .nodes
            .iter()
            .map(|r| r.channel_outpoint.clone())
            .collect::<Vec<_>>();
        let funding_tx = self
            .get_channel_funding_tx(&channel_id)
            .expect("funding tx");
        let channel_outpoint = OutPoint::new(funding_tx.into(), 0);
        assert!(used_channes.contains(&channel_outpoint));
    }

    pub async fn wait_until_success(&self, payment_hash: Hash256) {
        loop {
            assert!(self.get_triggered_unexpected_events().await.is_empty());
            let status = self.get_payment_status(payment_hash).await;
            if status == PaymentSessionStatus::Success {
                eprintln!("Payment success: {:?}\n\n", payment_hash);
                break;
            } else if status == PaymentSessionStatus::Failed {
                eprintln!("Payment failed: {:?}\n\n", payment_hash);
                // report error
                assert_eq!(status, PaymentSessionStatus::Success);
            }
            tokio::time::sleep(Duration::from_millis(500)).await;
        }
    }

    pub async fn wait_until_failed(&self, payment_hash: Hash256) {
        loop {
            assert!(self.get_triggered_unexpected_events().await.is_empty());
            let status = self.get_payment_status(payment_hash).await;
            if status == PaymentSessionStatus::Failed {
                eprintln!("Payment failed: {:?}\n\n", payment_hash);
                break;
            } else if status == PaymentSessionStatus::Success {
                eprintln!("Payment success: {:?}\n\n", payment_hash);
                // report error
                assert_eq!(status, PaymentSessionStatus::Failed);
            }
            tokio::time::sleep(Duration::from_millis(500)).await;
        }
    }

    pub async fn node_info(&self) -> NodeInfoResponse {
        let message =
            |rpc_reply| NetworkActorMessage::Command(NetworkActorCommand::NodeInfo((), rpc_reply));
        eprintln!("query node_info ...");

        call!(self.network_actor, message)
            .expect("node_a alive")
            .unwrap()
    }

    pub async fn update_channel_actor_state(
        &self,
        state: ChannelActorState,
        reload_params: Option<ReloadParams>,
    ) {
        let channel_id = state.id;
        self.store.insert_channel_actor_state(state);
        self.network_actor
            .send_message(NetworkActorMessage::Command(
                NetworkActorCommand::ControlFiberChannel(ChannelCommandWithId {
                    channel_id,
                    command: ChannelCommand::ReloadState(reload_params.unwrap_or_default()),
                }),
            ))
            .expect("network actor is live");
        tokio::time::sleep(Duration::from_millis(200)).await;
    }

    pub async fn update_channel_local_balance(
        &self,
        channel_id: Hash256,
        new_to_local_amount: u128,
    ) {
        let mut channel_actor_state = self.get_channel_actor_state(channel_id);
        channel_actor_state.to_local_amount = new_to_local_amount;
        self.update_channel_actor_state(channel_actor_state, None)
            .await;
    }

    pub async fn update_channel_remote_balance(
        &self,
        channel_id: Hash256,
        new_to_remote_amount: u128,
    ) {
        let mut channel_actor_state = self.get_channel_actor_state(channel_id);
        channel_actor_state.to_remote_amount = new_to_remote_amount;
        self.update_channel_actor_state(channel_actor_state, None)
            .await;
    }

    pub async fn disable_channel(&mut self, channel_id: Hash256) {
        let mut channel_actor_state = self.get_channel_actor_state(channel_id);
        channel_actor_state.local_tlc_info.enabled = false;
        self.update_channel_actor_state(channel_actor_state, None)
            .await;
    }

    pub async fn disable_channel_stealthy(&self, channel_id: Hash256) {
        let mut channel_actor_state = self.get_channel_actor_state(channel_id);
        channel_actor_state.local_tlc_info.enabled = false;
        self.update_channel_actor_state(
            channel_actor_state,
            Some(ReloadParams {
                notify_changes: false,
            }),
        )
        .await;
    }

    pub async fn update_channel_with_command(&self, channel_id: Hash256, command: UpdateCommand) {
        let message = |rpc_reply| -> NetworkActorMessage {
            NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                ChannelCommandWithId {
                    channel_id,
                    command: ChannelCommand::Update(command, rpc_reply),
                },
            ))
        };
        call!(self.network_actor, message)
            .expect("node_a alive")
            .expect("update channel success");
    }

    pub fn get_payment_session(&self, payment_hash: Hash256) -> Option<PaymentSession> {
        self.store.get_payment_session(payment_hash)
    }

    pub async fn new_with_node_name(node_name: &str) -> Self {
        let config = NetworkNodeConfigBuilder::new()
            .node_name(Some(node_name.to_string()))
            .build();
        Self::new_with_config(config).await
    }

    pub async fn new_with_node_name_opt(node_name: Option<String>) -> Self {
        let config = NetworkNodeConfigBuilder::new().node_name(node_name).build();
        Self::new_with_config(config).await
    }

    pub async fn new_with_config(config: NetworkNodeConfig) -> Self {
        let NetworkNodeConfig {
            base_dir,
            node_name,
            store,
            fiber_config,
        } = config;

        let _span = tracing::info_span!("NetworkNode", node_name = &node_name).entered();

        let root = get_test_root_actor().await;
        let (event_sender, mut event_receiver) = mpsc::channel(10000);

        let chain_actor = Actor::spawn_linked(None, MockChainActor::new(), (), root.get_cell())
            .await
            .expect("start mock chain actor")
            .0;

        let secret_key: Privkey = fiber_config
            .read_or_generate_secret_key()
            .expect("must generate key")
            .into();
        let public_key = secret_key.pubkey();

        let network_graph = Arc::new(TokioRwLock::new(NetworkGraph::new(
            store.clone(),
            public_key,
            true,
        )));

        let network_actor = Actor::spawn_linked(
            Some(format!("network actor at {}", base_dir.to_str())),
            NetworkActor::new(
                event_sender,
                chain_actor.clone(),
                store.clone(),
                network_graph.clone(),
            ),
            NetworkActorStartArguments {
                config: fiber_config.clone(),
                tracker: new_tokio_task_tracker(),
                channel_subscribers: Default::default(),
                default_shutdown_script: Default::default(),
            },
            root.get_cell(),
        )
        .await
        .expect("start network actor")
        .0;

        #[allow(clippy::never_loop)]
        let (peer_id, _listening_addr, announced_addrs) = loop {
            select! {
                Some(NetworkServiceEvent::NetworkStarted(peer_id, listening_addr, announced_addrs)) = event_receiver.recv() => {
                    break (peer_id, listening_addr, announced_addrs);
                }
                _ = sleep(Duration::from_secs(5)) => {
                    panic!("Failed to start network actor");
                }
            }
        };

        let mut unexpected_events: HashSet<String> = HashSet::new();

        // Some usual unexpected events that we want to not happended
        // use `assert!(node.get_triggered_unexpected_events().await.is_empty())` to check it
        let default_unexpected_events = vec![
            "Musig2VerifyError",
            "Musig2RoundFinalizeError",
            "InvalidOnionError",
        ];
        for event in default_unexpected_events {
            unexpected_events.insert(event.to_string());
        }

        let unexpected_events = Arc::new(TokioRwLock::new(unexpected_events));
        let triggered_unexpected_events = Arc::new(TokioRwLock::new(Vec::<String>::new()));
        let (self_event_sender, self_event_receiver) = mpsc::channel(10000);
        let unexpected_events_clone = unexpected_events.clone();
        let triggered_unexpected_events_clone = triggered_unexpected_events.clone();
        // spwan a new thread to collect all the events from event_receiver
        tokio::spawn(async move {
            while let Some(event) = event_receiver.recv().await {
                self_event_sender
                    .send(event.clone())
                    .await
                    .expect("send event");
                let unexpected_events = unexpected_events_clone.read().await;
                let event_content = format!("{:?}", event);
                for unexpected_event in unexpected_events.iter() {
                    if event_content.contains(unexpected_event) {
                        triggered_unexpected_events_clone
                            .write()
                            .await
                            .push(unexpected_event.clone());
                    }
                }
            }
        });

        println!(
            "Network node started for peer_id {:?} in directory {:?}",
            &peer_id,
            base_dir.as_ref()
        );

        Self {
            base_dir,
            node_name,
            store,
            fiber_config,
            channels_tx_map: Default::default(),
            listening_addrs: announced_addrs,
            network_actor,
            network_graph,
            chain_actor,
            private_key: secret_key,
            peer_id,
            event_emitter: self_event_receiver,
            pubkey: public_key,
            unexpected_events,
            triggered_unexpected_events,
        }
    }

    pub fn get_node_config(&self) -> NetworkNodeConfig {
        NetworkNodeConfig {
            base_dir: self.base_dir.clone(),
            node_name: self.node_name.clone(),
            store: self.store.clone(),
            fiber_config: self.fiber_config.clone(),
        }
    }

    pub async fn add_unexpected_events(&self, events: Vec<String>) {
        let mut unexpected_events = self.unexpected_events.write().await;
        for event in events {
            unexpected_events.insert(event);
        }
    }

    pub async fn get_triggered_unexpected_events(&self) -> Vec<String> {
        self.triggered_unexpected_events.read().await.clone()
    }

    pub async fn get_network_channels(&self) -> Vec<ChannelInfo> {
        self.network_graph
            .read()
            .await
            .get_channels_with_params(1000, None)
    }

    pub async fn get_network_nodes(&self) -> Vec<NodeInfo> {
        self.network_graph
            .read()
            .await
            .get_nodes_with_params(1000, None)
    }

    pub async fn start(&mut self) {
        let config = self.get_node_config();
        let new = Self::new_with_config(config).await;
        *self = new;
    }

    pub async fn stop(&mut self) {
        self.network_actor
            .stop(Some("stopping actor on request".to_string()));
        let my_peer_id = self.peer_id.clone();
        self.expect_event(
            |event| matches!(event, NetworkServiceEvent::NetworkStopped(id) if id == &my_peer_id),
        )
        .await;
    }

    pub async fn restart(&mut self) {
        self.stop().await;
        // Tentacle shutdown may require some time to propagate to other nodes.
        // If we start the node immediately, other nodes may deem our new connection
        // as a duplicate connection and report RepeatedConnection error.
        // And we will receive `ProtocolSelectError` error from tentacle.
        tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
        tracing::debug!("Node stopped, restarting");
        self.start().await;
    }

    pub async fn new_n_interconnected_nodes<const N: usize>() -> [Self; N] {
        let nodes = Self::new_interconnected_nodes(N).await;
        match nodes.try_into() {
            Ok(nodes) => nodes,
            Err(_) => unreachable!(),
        }
    }

    pub async fn new_interconnected_nodes(n: usize) -> Vec<Self> {
        let mut nodes: Vec<NetworkNode> = Vec::with_capacity(n);
        for i in 0..n {
            let new = Self::new_with_config(
                NetworkNodeConfigBuilder::new()
                    .node_name(Some(format!("node-{}", i)))
                    .base_dir_prefix(&format!("test-fnn-node-{}-", i))
                    .build(),
            )
            .await;
            for node in nodes.iter_mut() {
                node.connect_to(&new).await;
            }
            nodes.push(new);
        }
        #[allow(clippy::useless_conversion)]
        match nodes.try_into() {
            Ok(nodes) => nodes,
            Err(_) => unreachable!(),
        }
    }

    pub async fn new_2_nodes_with_established_channel(
        node_a_funding_amount: u128,
        node_b_funding_amount: u128,
        public: bool,
    ) -> (NetworkNode, NetworkNode, Hash256, TransactionView) {
        let [mut node_a, mut node_b] = NetworkNode::new_n_interconnected_nodes().await;

        let (channel_id, funding_tx) = establish_channel_between_nodes(
            &mut node_a,
            &mut node_b,
            public,
            node_a_funding_amount,
            node_b_funding_amount,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
        )
        .await;

        (node_a, node_b, channel_id, funding_tx)
    }

    // Create n nodes and connect them. The config_gen function
    // (function that creates a NetworkNodeConfig from an index)
    // will be called to generate the config for each node.
    pub async fn new_n_interconnected_nodes_with_config(
        n: usize,
        config_gen: impl Fn(usize) -> NetworkNodeConfig,
    ) -> Vec<Self> {
        let mut nodes: Vec<NetworkNode> = Vec::with_capacity(n);
        for i in 0..n {
            let new = Self::new_with_config(config_gen(i)).await;
            for node in nodes.iter_mut() {
                node.connect_to(&new).await;
            }
            nodes.push(new);
        }
        nodes
    }

    pub async fn connect_to_nonblocking(&mut self, other: &Self) {
        let peer_addr = other.listening_addrs[0].clone();
        println!(
            "Trying to connect to {:?} from {:?}",
            other.listening_addrs, &self.listening_addrs
        );

        self.network_actor
            .send_message(NetworkActorMessage::new_command(
                NetworkActorCommand::ConnectPeer(peer_addr.clone()),
            ))
            .expect("self alive");
    }

    pub async fn connect_to(&mut self, other: &Self) {
        self.connect_to_nonblocking(other).await;
        let peer_id = &other.peer_id;
        self.expect_event(
            |event| matches!(event, NetworkServiceEvent::PeerConnected(id, _addr) if id == peer_id),
        )
        .await;
    }

    pub async fn expect_to_process_event<F, T>(&mut self, event_processor: F) -> T
    where
        F: Fn(&NetworkServiceEvent) -> Option<T>,
    {
        loop {
            select! {
                event = self.event_emitter.recv() => {
                    match event {
                        None => panic!("Event emitter unexpectedly stopped"),
                        Some(event) => {
                            println!("Recevied event when waiting for specific event: {:?}", &event);
                            if let Some(r) = event_processor(&event) {
                                println!("Event ({:?}) matching filter received, exiting waiting for event loop", &event);
                                return r;
                            }
                        }
                    }
                }
                _ = sleep(Duration::from_secs(5)) => {
                    panic!("Waiting for event timeout");
                }
            }
        }
    }

    pub async fn expect_event<F>(&mut self, event_filter: F)
    where
        F: Fn(&NetworkServiceEvent) -> bool,
    {
        self.expect_to_process_event(|event| if event_filter(event) { Some(()) } else { None })
            .await;
    }

    pub async fn submit_tx(&mut self, tx: TransactionView) -> ckb_jsonrpc_types::Status {
        submit_tx(self.chain_actor.clone(), tx).await
    }

    pub fn add_channel_tx(&mut self, channel_id: Hash256, tx: TransactionView) {
        self.channels_tx_map.insert(channel_id, tx.hash().into());
    }

    pub fn get_channel_funding_tx(&self, channel_id: &Hash256) -> Option<Hash256> {
        self.channels_tx_map.get(channel_id).cloned()
    }

    pub async fn trace_tx(&mut self, tx: TransactionView) -> ckb_jsonrpc_types::Status {
        trace_tx(self.chain_actor.clone(), tx).await
    }

    pub async fn trace_tx_hash(&mut self, tx_hash: Byte32) -> ckb_jsonrpc_types::Status {
        trace_tx_hash(self.chain_actor.clone(), tx_hash).await
    }

    pub async fn get_tx_from_hash(
        &mut self,
        tx_hash: Byte32,
    ) -> Result<TransactionView, anyhow::Error> {
        get_tx_from_hash(self.chain_actor.clone(), tx_hash).await
    }

    pub fn get_network_graph(&self) -> &Arc<TokioRwLock<NetworkGraph<Store>>> {
        &self.network_graph
    }

    pub async fn with_network_graph<F, T>(&self, f: F) -> T
    where
        F: FnOnce(&NetworkGraph<Store>) -> T,
    {
        let graph = self.get_network_graph().read().await;
        f(&graph)
    }

    pub async fn with_network_graph_mut<F, T>(&self, f: F) -> T
    where
        F: FnOnce(&mut NetworkGraph<Store>) -> T,
    {
        let mut graph = self.get_network_graph().write().await;
        f(&mut graph)
    }

    pub async fn get_network_graph_nodes(&self) -> Vec<NodeInfo> {
        self.with_network_graph(|graph| graph.nodes().cloned().collect())
            .await
    }

    pub async fn get_network_graph_node(&self, pubkey: &Pubkey) -> Option<NodeInfo> {
        self.with_network_graph(|graph| graph.get_node(pubkey).cloned())
            .await
    }

    pub async fn get_network_graph_channels(&self) -> Vec<ChannelInfo> {
        self.with_network_graph(|graph| graph.channels().cloned().collect())
            .await
    }

    pub async fn get_network_graph_channel(&self, channel_id: &OutPoint) -> Option<ChannelInfo> {
        self.with_network_graph(|graph| {
            tracing::debug!("Getting channel info for {:?}", channel_id);
            tracing::debug!("Channels: {:?}", graph.channels().collect::<Vec<_>>());
            graph.get_channel(channel_id).cloned()
        })
        .await
    }
}

#[tokio::test]
async fn test_connect_to_other_node() {
    let mut node_a = NetworkNode::new().await;
    let node_b = NetworkNode::new().await;
    node_a.connect_to(&node_b).await;
}

#[tokio::test]
async fn test_restart_network_node() {
    let mut node = NetworkNode::new().await;
    node.restart().await;
}


================================================
File: src/fiber/tests/tlc_op.rs
================================================
use crate::fiber::channel::TlcInfo;
use crate::fiber::channel::{
    CommitmentNumbers, InboundTlcStatus, OutboundTlcStatus, TLCId, TlcState, TlcStatus,
};
use crate::fiber::hash_algorithm::HashAlgorithm;
use crate::fiber::types::RemoveTlcFulfill;
use crate::fiber::types::{Hash256, NO_SHARED_SECRET};
use crate::fiber::types::{PaymentOnionPacket, RemoveTlcReason};
use crate::gen_rand_sha256_hash;
use crate::now_timestamp_as_millis_u64;
use ckb_hash::new_blake2b;
use ckb_types::packed::Byte32;
use ractor::{async_trait as rasync_trait, Actor, ActorProcessingErr, ActorRef};
use std::collections::HashMap;

fn sign_tlcs<'a>(tlcs: impl Iterator<Item = &'a TlcInfo>) -> Hash256 {
    // serialize active_tls to ge a hash
    let mut keyparts = tlcs
        .map(|tlc| (tlc.amount, tlc.payment_hash))
        .collect::<Vec<_>>();

    keyparts.sort_by(|a, b| {
        let a: Byte32 = a.1.into();
        let b: Byte32 = b.1.into();
        a.cmp(&b)
    });

    eprintln!("keyparts: {:?}", keyparts);
    let serialized = serde_json::to_string(&keyparts).expect("Failed to serialize tls");

    // Hash the serialized data using SHA-256
    let mut hasher = new_blake2b();
    hasher.update(serialized.to_string().as_bytes());
    let mut result = [0u8; 32];
    hasher.finalize(&mut result);

    result.into()
}

pub struct TlcActorState {
    pub tlc_state: TlcState,
    pub peer_id: String,
}

impl TlcActorState {
    pub fn get_peer(&self) -> String {
        if self.peer_id == "peer_a" {
            "peer_b".to_string()
        } else {
            "peer_a".to_string()
        }
    }
}

pub struct NetworkActorState {
    network: ActorRef<NetworkActorMessage>,
    pub peers: HashMap<String, ActorRef<TlcActorMessage>>,
}

impl NetworkActorState {
    pub async fn add_peer(&mut self, peer_id: String) {
        let network = self.network.clone();
        let actor = Actor::spawn_linked(
            Some(peer_id.clone()),
            TlcActor::new(network.clone()),
            peer_id.clone(),
            network.clone().get_cell(),
        )
        .await
        .expect("Failed to start tlc actor")
        .0;
        self.peers.insert(peer_id.clone(), actor);
        eprintln!("add_peer: {:?} added successfully ...", peer_id);
    }
}

pub struct TlcActor {
    network: ActorRef<NetworkActorMessage>,
}

impl TlcActor {
    pub fn new(network: ActorRef<NetworkActorMessage>) -> Self {
        Self { network }
    }
}

#[derive(Debug, Clone)]
pub struct AddTlcCommand {
    pub amount: u128,
    pub payment_hash: Hash256,
    pub expiry: u64,
    pub hash_algorithm: HashAlgorithm,
    pub onion_packet: Option<PaymentOnionPacket>,
    pub shared_secret: [u8; 32],
    #[allow(dead_code)]
    pub previous_tlc: Option<(Hash256, u64)>,
}

pub struct NetworkActor {}

#[derive(Debug)]
pub enum TlcActorMessage {
    Debug,
    CommandAddTlc(AddTlcCommand),
    CommandRemoveTlc(u64),
    PeerAddTlc(TlcInfo),
    PeerRemoveTlc(u64),
    PeerCommitmentSigned(Hash256),
    PeerRevokeAndAck(Hash256),
    //PeerRemoveTlc,
}

#[derive(Debug)]
pub enum NetworkActorMessage {
    RegisterPeer(String),
    AddTlc(String, AddTlcCommand),
    RemoveTlc(String, u64),
    PeerMsg(String, TlcActorMessage),
}

#[rasync_trait]
impl Actor for NetworkActor {
    type Msg = NetworkActorMessage;
    type State = NetworkActorState;
    type Arguments = ();

    async fn handle(
        &self,
        _myself: ActorRef<Self::Msg>,
        message: Self::Msg,
        state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        match message {
            NetworkActorMessage::RegisterPeer(peer_id) => {
                state.add_peer(peer_id).await;
            }
            NetworkActorMessage::AddTlc(peer_id, add_tlc) => {
                eprintln!("NetworkActorMessage::AddTlc");
                if let Some(actor) = state.peers.get(&peer_id) {
                    actor
                        .send_message(TlcActorMessage::CommandAddTlc(add_tlc))
                        .expect("send ok");
                }
            }
            NetworkActorMessage::RemoveTlc(peer_id, tlc_id) => {
                if let Some(actor) = state.peers.get(&peer_id) {
                    actor
                        .send_message(TlcActorMessage::CommandRemoveTlc(tlc_id))
                        .expect("send ok");
                }
            }
            NetworkActorMessage::PeerMsg(peer_id, peer_msg) => {
                if let Some(actor) = state.peers.get(&peer_id) {
                    eprintln!("NetworkActorMessage::PeerMsg: {:?}", peer_msg);
                    actor.send_message(peer_msg).expect("send ok");
                }
            }
        }
        Ok(())
    }

    async fn pre_start(
        &self,
        myself: ActorRef<Self::Msg>,
        _args: Self::Arguments,
    ) -> Result<Self::State, ActorProcessingErr> {
        eprintln!("NetworkActor pre_start");
        Ok(NetworkActorState {
            peers: Default::default(),
            network: myself.clone(),
        })
    }
}

#[rasync_trait]
impl Actor for TlcActor {
    type Msg = TlcActorMessage;
    type State = TlcActorState;
    type Arguments = String;

    async fn handle(
        &self,
        _myself: ActorRef<Self::Msg>,
        message: Self::Msg,
        state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        match message {
            TlcActorMessage::Debug => {
                eprintln!("Peer {} Debug", state.peer_id);
                for tlc in state.tlc_state.offered_tlcs.tlcs.iter() {
                    eprintln!("offered_tlc: {:?}", tlc.log());
                }
                for tlc in state.tlc_state.received_tlcs.tlcs.iter() {
                    eprintln!("received_tlc: {:?}", tlc.log());
                }
            }
            TlcActorMessage::CommandAddTlc(command) => {
                eprintln!(
                    "Peer {} TlcActorMessage::Command_AddTlc: {:?}",
                    state.peer_id, command
                );
                let next_offer_id = state.tlc_state.get_next_offering();
                let add_tlc = TlcInfo {
                    channel_id: gen_rand_sha256_hash(),
                    tlc_id: TLCId::Offered(next_offer_id),
                    amount: command.amount,
                    payment_hash: command.payment_hash,
                    expiry: command.expiry,
                    hash_algorithm: command.hash_algorithm,
                    created_at: CommitmentNumbers::default(),
                    removed_reason: None,
                    onion_packet: command.onion_packet,
                    shared_secret: command.shared_secret,
                    previous_tlc: None,
                    status: TlcStatus::Outbound(OutboundTlcStatus::LocalAnnounced),
                    removed_confirmed_at: None,
                };
                state.tlc_state.add_offered_tlc(add_tlc.clone());
                state.tlc_state.increment_offering();
                let peer = state.get_peer();
                self.network
                    .send_message(NetworkActorMessage::PeerMsg(
                        peer.clone(),
                        TlcActorMessage::PeerAddTlc(add_tlc),
                    ))
                    .expect("send ok");

                // send commitment signed
                let tlcs = state.tlc_state.commitment_signed_tlcs(false);
                let hash = sign_tlcs(tlcs);
                eprintln!("got hash: {:?}", hash);
                self.network
                    .send_message(NetworkActorMessage::PeerMsg(
                        peer,
                        TlcActorMessage::PeerCommitmentSigned(hash),
                    ))
                    .expect("send ok");
            }
            TlcActorMessage::CommandRemoveTlc(tlc_id) => {
                eprintln!("Peer {} process remove tlc ....", state.peer_id);
                state.tlc_state.set_received_tlc_removed(
                    tlc_id,
                    RemoveTlcReason::RemoveTlcFulfill(RemoveTlcFulfill {
                        payment_preimage: Default::default(),
                    }),
                );
                let peer = state.get_peer();
                self.network
                    .send_message(NetworkActorMessage::PeerMsg(
                        peer.clone(),
                        TlcActorMessage::PeerRemoveTlc(tlc_id),
                    ))
                    .expect("send ok");

                // send commitment signed
                let tlcs = state.tlc_state.commitment_signed_tlcs(false);
                let hash = sign_tlcs(tlcs);
                eprintln!("got hash: {:?}", hash);
                self.network
                    .send_message(NetworkActorMessage::PeerMsg(
                        peer,
                        TlcActorMessage::PeerCommitmentSigned(hash),
                    ))
                    .expect("send ok");
            }
            TlcActorMessage::PeerAddTlc(add_tlc) => {
                eprintln!(
                    "Peer {} process peer add_tlc .... with tlc_id: {:?}",
                    state.peer_id, add_tlc.tlc_id
                );
                let mut tlc = add_tlc.clone();
                tlc.flip_mut();
                tlc.status = TlcStatus::Inbound(InboundTlcStatus::RemoteAnnounced);
                state.tlc_state.add_received_tlc(tlc);
                eprintln!("add peer tlc successfully: {:?}", add_tlc);
            }
            TlcActorMessage::PeerRemoveTlc(tlc_id) => {
                eprintln!(
                    "Peer {} process peer remove tlc .... with tlc_id: {}",
                    state.peer_id, tlc_id
                );
                state.tlc_state.set_offered_tlc_removed(
                    tlc_id,
                    RemoveTlcReason::RemoveTlcFulfill(RemoveTlcFulfill {
                        payment_preimage: Default::default(),
                    }),
                );
            }
            TlcActorMessage::PeerCommitmentSigned(peer_hash) => {
                eprintln!(
                    "\nPeer {} processed peer commitment_signed ....",
                    state.peer_id
                );
                let tlcs = state.tlc_state.commitment_signed_tlcs(true);
                let hash = sign_tlcs(tlcs);
                assert_eq!(hash, peer_hash);

                let peer = state.get_peer();

                state.tlc_state.update_for_commitment_signed();

                eprintln!("sending peer revoke and ack ....");
                let tlcs = state.tlc_state.commitment_signed_tlcs(false);
                let hash = sign_tlcs(tlcs);
                self.network
                    .send_message(NetworkActorMessage::PeerMsg(
                        peer.clone(),
                        TlcActorMessage::PeerRevokeAndAck(hash),
                    ))
                    .expect("send ok");

                // send commitment signed from our side if necessary
                if state.tlc_state.need_another_commitment_signed() {
                    eprintln!("sending another commitment signed ....");
                    let tlcs = state.tlc_state.commitment_signed_tlcs(false);
                    let hash = sign_tlcs(tlcs);
                    self.network
                        .send_message(NetworkActorMessage::PeerMsg(
                            peer,
                            TlcActorMessage::PeerCommitmentSigned(hash),
                        ))
                        .expect("send ok");
                }
            }
            TlcActorMessage::PeerRevokeAndAck(peer_hash) => {
                eprintln!("Peer {} processed peer revoke and ack ....", state.peer_id);
                let tlcs = state.tlc_state.commitment_signed_tlcs(true);
                let hash = sign_tlcs(tlcs);
                assert_eq!(hash, peer_hash);

                state
                    .tlc_state
                    .update_for_revoke_and_ack(CommitmentNumbers::default());
            }
        }
        Ok(())
    }

    async fn pre_start(
        &self,
        _myself: ActorRef<Self::Msg>,
        args: Self::Arguments,
    ) -> Result<Self::State, ActorProcessingErr> {
        let peer_id = args;
        {
            Ok(TlcActorState {
                tlc_state: Default::default(),
                peer_id,
            })
        }
    }
}

#[tokio::test]
async fn test_tlc_actor() {
    let (network_actor, _handle) = Actor::spawn(None, NetworkActor {}, ())
        .await
        .expect("Failed to start tlc actor");
    network_actor
        .send_message(NetworkActorMessage::RegisterPeer("peer_a".to_string()))
        .unwrap();
    network_actor
        .send_message(NetworkActorMessage::RegisterPeer("peer_b".to_string()))
        .unwrap();

    network_actor
        .send_message(NetworkActorMessage::AddTlc(
            "peer_a".to_string(),
            AddTlcCommand {
                amount: 10000,
                payment_hash: gen_rand_sha256_hash(),
                expiry: now_timestamp_as_millis_u64() + 1000,
                hash_algorithm: HashAlgorithm::Sha256,
                onion_packet: None,
                shared_secret: NO_SHARED_SECRET,
                previous_tlc: None,
            },
        ))
        .unwrap();

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
    network_actor
        .send_message(NetworkActorMessage::AddTlc(
            "peer_a".to_string(),
            AddTlcCommand {
                amount: 20000,
                payment_hash: gen_rand_sha256_hash(),
                expiry: now_timestamp_as_millis_u64() + 1000,
                hash_algorithm: HashAlgorithm::Sha256,
                onion_packet: None,
                shared_secret: NO_SHARED_SECRET,
                previous_tlc: None,
            },
        ))
        .unwrap();

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
    network_actor
        .send_message(NetworkActorMessage::AddTlc(
            "peer_b".to_string(),
            AddTlcCommand {
                amount: 30000,
                payment_hash: gen_rand_sha256_hash(),
                expiry: now_timestamp_as_millis_u64() + 1000,
                hash_algorithm: HashAlgorithm::Sha256,
                onion_packet: None,
                shared_secret: NO_SHARED_SECRET,
                previous_tlc: None,
            },
        ))
        .unwrap();

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
    network_actor
        .send_message(NetworkActorMessage::AddTlc(
            "peer_b".to_string(),
            AddTlcCommand {
                amount: 50000,
                payment_hash: gen_rand_sha256_hash(),
                expiry: now_timestamp_as_millis_u64() + 1000,
                hash_algorithm: HashAlgorithm::Sha256,
                onion_packet: None,
                shared_secret: NO_SHARED_SECRET,
                previous_tlc: None,
            },
        ))
        .unwrap();

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
    // remove tlc from peer_b
    network_actor
        .send_message(NetworkActorMessage::RemoveTlc("peer_b".to_string(), 0))
        .unwrap();

    tokio::time::sleep(tokio::time::Duration::from_millis(1000)).await;
    network_actor
        .send_message(NetworkActorMessage::PeerMsg(
            "peer_a".to_string(),
            TlcActorMessage::Debug,
        ))
        .unwrap();

    tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
    network_actor
        .send_message(NetworkActorMessage::PeerMsg(
            "peer_b".to_string(),
            TlcActorMessage::Debug,
        ))
        .unwrap();

    tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;
}

#[test]
fn test_tlc_state_v2() {
    let mut tlc_state = TlcState::default();
    let mut add_tlc1 = TlcInfo {
        amount: 10000,
        status: TlcStatus::Outbound(OutboundTlcStatus::LocalAnnounced),
        channel_id: gen_rand_sha256_hash(),
        payment_hash: gen_rand_sha256_hash(),
        expiry: now_timestamp_as_millis_u64() + 1000,
        hash_algorithm: HashAlgorithm::Sha256,
        onion_packet: None,
        shared_secret: NO_SHARED_SECRET,
        tlc_id: TLCId::Offered(0),
        created_at: CommitmentNumbers::default(),
        removed_reason: None,
        previous_tlc: None,
        removed_confirmed_at: None,
    };
    let mut add_tlc2 = TlcInfo {
        amount: 20000,
        status: TlcStatus::Outbound(OutboundTlcStatus::LocalAnnounced),
        channel_id: gen_rand_sha256_hash(),
        payment_hash: gen_rand_sha256_hash(),
        expiry: now_timestamp_as_millis_u64() + 2000,
        hash_algorithm: HashAlgorithm::Sha256,
        onion_packet: None,
        shared_secret: NO_SHARED_SECRET,
        tlc_id: TLCId::Offered(1),
        created_at: CommitmentNumbers::default(),
        removed_reason: None,
        previous_tlc: None,
        removed_confirmed_at: None,
    };
    tlc_state.add_offered_tlc(add_tlc1.clone());
    tlc_state.add_offered_tlc(add_tlc2.clone());

    let mut tlc_state_2 = TlcState::default();
    add_tlc1.flip_mut();
    add_tlc2.flip_mut();
    add_tlc1.status = TlcStatus::Inbound(InboundTlcStatus::RemoteAnnounced);
    add_tlc2.status = TlcStatus::Inbound(InboundTlcStatus::RemoteAnnounced);
    tlc_state_2.add_received_tlc(add_tlc1);
    tlc_state_2.add_received_tlc(add_tlc2);

    let hash1 = sign_tlcs(tlc_state.commitment_signed_tlcs(true));
    eprintln!("hash1: {:?}", hash1);

    let hash2 = sign_tlcs(tlc_state_2.commitment_signed_tlcs(false));
    eprintln!("hash2: {:?}", hash2);
    assert_eq!(hash1, hash2);
}


================================================
File: src/fiber/tests/types.rs
================================================
use crate::{
    fiber::{
        config::AnnouncedNodeName,
        gen::{fiber as molecule_fiber, gossip},
        hash_algorithm::HashAlgorithm,
        types::{
            secp256k1_instance, AddTlc, BroadcastMessage, BroadcastMessageID, Cursor, Hash256,
            NodeAnnouncement, PaymentHopData, PeeledOnionPacket, Privkey, Pubkey, TlcErr,
            TlcErrPacket, TlcErrorCode, NO_SHARED_SECRET,
        },
    },
    gen_rand_channel_outpoint, gen_rand_fiber_private_key, gen_rand_fiber_public_key,
    now_timestamp_as_millis_u64,
};
use fiber_sphinx::OnionSharedSecretIter;
use secp256k1::{PublicKey, Secp256k1, SecretKey};
use std::str::FromStr;

#[test]
fn test_serde_public_key() {
    let sk = SecretKey::from_slice(&[42; 32]).unwrap();
    let public_key = Pubkey::from(sk.public_key(secp256k1_instance()));
    let pk_str = serde_json::to_string(&public_key).unwrap();
    assert_eq!(
        "\"035be5e9478209674a96e60f1f037f6176540fd001fa1d64694770c56a7709c42c\"",
        &pk_str
    );
    let pubkey: Pubkey = serde_json::from_str(&pk_str).unwrap();
    assert_eq!(pubkey, public_key)
}

#[test]
fn test_serde_cursor_node_announcement() {
    let now = 0u64;
    let node_id = gen_rand_fiber_public_key();
    let cursor = Cursor::new(now, BroadcastMessageID::NodeAnnouncement(node_id));
    let moleculed_cursor: gossip::Cursor = cursor.clone().into();
    let unmoleculed_cursor: Cursor = moleculed_cursor.try_into().expect("decode");
    assert_eq!(cursor, unmoleculed_cursor);
}

#[test]
fn test_serde_cursor_channel_announcement() {
    let now = 0u64;
    let channel_announcement_id = gen_rand_channel_outpoint();
    let cursor = Cursor::new(
        now,
        BroadcastMessageID::ChannelAnnouncement(channel_announcement_id),
    );
    let moleculed_cursor: gossip::Cursor = cursor.clone().into();
    let unmoleculed_cursor: Cursor = moleculed_cursor.try_into().expect("decode");
    assert_eq!(cursor, unmoleculed_cursor);
}

#[test]
fn test_serde_cursor_channel_update() {
    let now = 0u64;
    let channel_update_id = gen_rand_channel_outpoint();
    let cursor = Cursor::new(now, BroadcastMessageID::ChannelUpdate(channel_update_id));
    let moleculed_cursor: gossip::Cursor = cursor.clone().into();
    let unmoleculed_cursor: Cursor = moleculed_cursor.try_into().expect("decode");
    assert_eq!(cursor, unmoleculed_cursor);
}

#[test]
fn test_cursor_timestamp() {
    let node_id = gen_rand_fiber_public_key();
    // 255 is larger than 256 in little endian.
    assert!(
        Cursor::new(255, BroadcastMessageID::NodeAnnouncement(node_id))
            < Cursor::new(256, BroadcastMessageID::NodeAnnouncement(node_id))
    );
}

#[test]
fn test_cursor_types() {
    let node_id = gen_rand_fiber_public_key();
    let channel_outpoint = gen_rand_channel_outpoint();
    assert!(
        Cursor::new(
            0,
            BroadcastMessageID::ChannelAnnouncement(channel_outpoint.clone())
        ) < Cursor::new(0, BroadcastMessageID::NodeAnnouncement(node_id))
    );
    assert!(
        Cursor::new(
            0,
            BroadcastMessageID::ChannelAnnouncement(channel_outpoint.clone())
        ) < Cursor::new(
            0,
            BroadcastMessageID::ChannelUpdate(channel_outpoint.clone())
        )
    );
    assert!(
        Cursor::new(
            0,
            BroadcastMessageID::ChannelUpdate(channel_outpoint.clone())
        ) < Cursor::new(0, BroadcastMessageID::NodeAnnouncement(node_id))
    );
}

#[test]
fn test_add_tlc_serialization() {
    let add_tlc = AddTlc {
        channel_id: [42; 32].into(),
        tlc_id: 42,
        amount: 42,
        payment_hash: [42; 32].into(),
        expiry: 42,
        hash_algorithm: HashAlgorithm::Sha256,
        onion_packet: None,
    };
    let add_tlc_mol: molecule_fiber::AddTlc = add_tlc.clone().into();
    let add_tlc2 = add_tlc_mol.try_into().expect("decode");
    assert_eq!(add_tlc, add_tlc2);
}

#[test]
fn test_peeled_onion_packet() {
    let secp = Secp256k1::new();
    let keys: Vec<Privkey> = std::iter::repeat_with(gen_rand_fiber_private_key)
        .take(3)
        .collect();
    let hops_infos = vec![
        PaymentHopData {
            amount: 2,
            expiry: 3,
            next_hop: Some(keys[1].pubkey()),
            funding_tx_hash: Hash256::default(),
            hash_algorithm: HashAlgorithm::Sha256,
            payment_preimage: None,
        },
        PaymentHopData {
            amount: 5,
            expiry: 6,
            next_hop: Some(keys[2].pubkey()),
            funding_tx_hash: Hash256::default(),
            hash_algorithm: HashAlgorithm::Sha256,
            payment_preimage: None,
        },
        PaymentHopData {
            amount: 8,
            expiry: 9,
            next_hop: None,
            funding_tx_hash: Hash256::default(),
            hash_algorithm: HashAlgorithm::Sha256,
            payment_preimage: None,
        },
    ];
    let packet = PeeledOnionPacket::create(
        gen_rand_fiber_private_key(),
        hops_infos.clone(),
        None,
        &secp,
    )
    .expect("create peeled packet");

    let serialized = packet.serialize();
    let deserialized = PeeledOnionPacket::deserialize(&serialized).expect("deserialize");

    assert_eq!(packet, deserialized);

    assert_eq!(packet.current, hops_infos[0]);
    assert!(!packet.is_last());

    let packet = packet.peel(&keys[1], &secp).expect("peel");
    assert_eq!(packet.current, hops_infos[1]);
    assert!(!packet.is_last());

    let packet = packet.peel(&keys[2], &secp).expect("peel");
    assert_eq!(packet.current, hops_infos[2]);
    assert!(packet.is_last());
}

#[test]
fn test_tlc_fail_error() {
    let tlc_fail_detail = TlcErr::new(TlcErrorCode::InvalidOnionVersion);
    assert!(!tlc_fail_detail.error_code.is_node());
    assert!(tlc_fail_detail.error_code.is_bad_onion());
    assert!(tlc_fail_detail.error_code.is_perm());
    let tlc_fail = TlcErrPacket::new(tlc_fail_detail.clone(), &NO_SHARED_SECRET);

    let convert_back: TlcErr = tlc_fail.decode(&[0u8; 32], vec![]).expect("decoded fail");
    assert_eq!(tlc_fail_detail, convert_back);

    let node_fail = TlcErr::new_node_fail(
        TlcErrorCode::PermanentNodeFailure,
        gen_rand_fiber_public_key(),
    );
    assert!(node_fail.error_code.is_node());
    let tlc_fail = TlcErrPacket::new(node_fail.clone(), &NO_SHARED_SECRET);
    let convert_back = tlc_fail.decode(&[0u8; 32], vec![]).expect("decoded fail");
    assert_eq!(node_fail, convert_back);

    let error_code = TlcErrorCode::PermanentNodeFailure;
    let convert = TlcErrorCode::from_str("PermanentNodeFailure").expect("convert error");
    assert_eq!(error_code, convert);
}

#[test]
fn test_tlc_err_packet_encryption() {
    // Setup
    let secp = Secp256k1::new();
    let hops_path = [
        "02eec7245d6b7d2ccb30380bfbe2a3648cd7a942653f5aa340edcea1f283686619",
        "0324653eac434488002cc06bbfb7f10fe18991e35f9fe4302dbea6d2353dc0ab1c",
        "027f31ebc5462c1fdce1b737ecff52d37d75dea43ce11c74d25aa297165faa2007",
    ]
    .iter()
    .map(|s| Pubkey(PublicKey::from_str(s).expect("valid public key")))
    .collect::<Vec<_>>();

    let session_key = SecretKey::from_slice(&[0x41; 32]).expect("32 bytes, within curve order");
    let hops_ss: Vec<[u8; 32]> =
        OnionSharedSecretIter::new(hops_path.iter().map(|k| &k.0), session_key, &secp).collect();

    let tlc_fail_detail = TlcErr::new(TlcErrorCode::InvalidOnionVersion);
    {
        // Error from the first hop
        let tlc_fail = TlcErrPacket::new(tlc_fail_detail.clone(), &hops_ss[0]);
        let decrypted_tlc_fail_detail = tlc_fail
            .decode(session_key.as_ref(), hops_path.clone())
            .expect("decrypted");
        assert_eq!(decrypted_tlc_fail_detail, tlc_fail_detail);
    }

    {
        // Error from the the last hop
        let mut tlc_fail = TlcErrPacket::new(tlc_fail_detail.clone(), &hops_ss[2]);
        tlc_fail = tlc_fail.backward(&hops_ss[1]);
        tlc_fail = tlc_fail.backward(&hops_ss[0]);
        let decrypted_tlc_fail_detail = tlc_fail
            .decode(session_key.as_ref(), hops_path.clone())
            .expect("decrypted");
        assert_eq!(decrypted_tlc_fail_detail, tlc_fail_detail);
    }
}

#[test]
fn test_tlc_error_code() {
    let code = TlcErrorCode::PermanentNodeFailure;
    let str = code.as_ref().to_string();
    let code2 = TlcErrorCode::from_str(&str).expect("parse");
    assert_eq!(code, code2);

    let code = TlcErrorCode::IncorrectOrUnknownPaymentDetails;
    let code_int: u16 = code.into();
    let code = TlcErrorCode::try_from(code_int).expect("invalid code");
    assert_eq!(code, TlcErrorCode::IncorrectOrUnknownPaymentDetails);
}

#[test]
fn test_create_and_verify_node_announcement() {
    let privkey = gen_rand_fiber_private_key();
    let node_announcement = NodeAnnouncement::new(
        AnnouncedNodeName::from_string("node1").expect("valid name"),
        vec![],
        &privkey,
        now_timestamp_as_millis_u64(),
        0,
    );
    assert!(
        node_announcement.verify(),
        "Node announcement message signature verification failed: {:?}",
        &node_announcement
    );
}

#[test]
fn test_serde_node_announcement() {
    let privkey = gen_rand_fiber_private_key();
    let node_announcement = NodeAnnouncement::new(
        AnnouncedNodeName::from_string("node1").expect("valid name"),
        vec![],
        &privkey,
        now_timestamp_as_millis_u64(),
        0,
    );
    assert!(
        node_announcement.verify(),
        "Node announcement verification failed: {:?}",
        &node_announcement
    );
    let serialized = bincode::serialize(&node_announcement).expect("serialize");
    let deserialized: NodeAnnouncement = bincode::deserialize(&serialized).expect("deserialize");
    assert_eq!(node_announcement, deserialized);
    assert!(
        deserialized.verify(),
        "Node announcement verification failed: {:?}",
        &deserialized
    );
}

// There was a bug in the node announcement verification logic which uses local udt whitelist to
// verify the signature. This bug causes different nodes to have different results on signature verification.
// We add a few hard coded node announcements with different udt_cfg_infos to ensure the verification logic is correct.
#[test]
fn test_verify_hard_coded_node_announcement() {
    for s in [
        "000000000146000000000000003044022015c1b36c0f5d08cbcb7ac77939506495cbe6dbd4bdd6076de54e8cabe707f894022003c4e84c69e88906499e00e0bc9e601c727bead819233c0e1a2f66c59385f11f0000000000000000e67330889401000002a64b8993f33b2ebd37a4de1c9441f491291a4e779da8e519bcfb7c1f3f56c9c0200000000000000066696265722d310000000000000000000000000000000000000000000000000001000000000000002d00000000000000047f000001062098a503221220c9cf006bbaa881b6962c3a61f4dc7100aaedd875253d1bbb78408e2be7f5c93f420000000000000030783963306138666666323461376265333339623932303838373330633264633766616336646663626466306137333737346436643264366232393532336661356200e40b540200000002000000000000000a0000000000000053494d504c455f554454420000000000000030786531653335346436643634336164343237323464343039363765333334393834353334653033363734303563356165343261396437643633643737646634313905000000000000006461746131040000000000000030782e2a01e803000000000000000000000000000001000000000000000400000000000000636f6465420000000000000030786638393762666335313736366565396364623262393237396536336338616264626134623335623665653764646535666564396230613561343163393564633408000000040000000000000058554454420000000000000030783530626438643636383062386239636639386237336633633038666166386232613231393134333131393534313138616436363039626536653738613162393505000000000000006461746131040000000000000030782e2a01e803000000000000000000000000000001000000000000000400000000000000636f6465420000000000000030786638393762666335313736366565396364623262393237396536336338616264626134623335623665653764646535666564396230613561343163393564633409000000",
        "000000000146000000000000003044022052158ADBFCEA30AEAF89CA00200DF0CC3D1E593EE635DB7FBFF01A28A34D07CF022065FD67E565540A1EFE99B939D2F084CBACEFCF15F2B17AA52CFFEE0614819C7B00000000000000004F3B0F889401000003781A50829680593CD47EDCCB646E62625212CF9AEA83EF4BE421A2B2C08872102000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000002D0000000000000004DDBB3DA2064734A50322122042F6793087F4481CEA9768D563FD8EBE6FEDA11E6A409CD84E92094CA69CE955420000000000000030783130363339653038393535303262353638386136626538636636393436306437363534316266613438323136323964383664363262613061616533663936303600E40B54020000000100000000000000040000000000000052555344420000000000000030783131343237353561303434626632656533353863626139663264613138376365393238633931636434646338363932646564303333376566613637376432316104000000000000007479706542000000000000003078383738666363366631663038643438653837626231633362336435303833663233663861333963356435633736346632353362353562393938353236343339620100CA9A3B00000000000000000000000001000000000000000400000000000000636F6465420000000000000030786564376436356239616433643939363537653337633432383564353835666561386135666361663538313635643534646163663930323433663931313534386200000000"
    ] {
        let bytes = hex::decode(s).expect("decode");

        let node_announcement = match bincode::deserialize(&bytes).expect("deserialize") {
            BroadcastMessage::NodeAnnouncement(node_announcement) => node_announcement,
            _ => panic!("deserialize failed"),
        };
        assert!(node_announcement.verify())
    }
}


================================================
File: src/invoice/command.rs
================================================
use super::invoice_impl::Currency;
use crate::fiber::types::Hash256;
use serde::Deserialize;

#[derive(Clone, Debug, Deserialize)]
pub enum InvoiceCommand {
    NewInvoice(NewInvoiceParams),
    ParseInvoice(String),
}

impl InvoiceCommand {
    pub fn name(&self) -> &'static str {
        match self {
            InvoiceCommand::NewInvoice(_) => "NewInvoice",
            InvoiceCommand::ParseInvoice(_) => "ParseInvoice",
        }
    }
}

#[derive(Clone, Debug, Deserialize)]
pub struct NewInvoiceParams {
    pub amount: u128,
    pub description: Option<String>,
    pub currency: Currency,
    pub payment_hash: Option<Hash256>,
    pub payment_preimage: Option<Hash256>,
    pub expiry: Option<u64>,
    pub fallback_address: Option<String>,
    pub final_expiry_delta: Option<u64>,
}


================================================
File: src/invoice/errors.rs
================================================
use std::fmt::Display;
use std::num::ParseIntError;
use thiserror::Error;

#[derive(Error, Debug)]
pub struct VerificationError(pub molecule::error::VerificationError);

impl PartialEq for VerificationError {
    fn eq(&self, _other: &Self) -> bool {
        false
    }
}
impl Display for VerificationError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        self.0.fmt(f)
    }
}

#[derive(Error, PartialEq, Debug)]
pub enum InvoiceError {
    #[error("Bech32 error: {0}")]
    Bech32Error(bech32::Error),
    #[error("Molecule error: {0}")]
    MoleculeError(VerificationError),
    #[error("Failed to parse amount: {0}")]
    ParseAmountError(ParseIntError),
    #[error("Unknown currency: {0}")]
    UnknownCurrency(String),
    #[error("Unknown si prefix: {0}")]
    UnknownSiPrefix(String),
    #[error("Parsing failed with malformed HRP: {0}")]
    MalformedHRP(String),
    #[error("Too short data part")]
    TooShortDataPart,
    #[error("Unexpected end of tagged fields")]
    UnexpectedEndOfTaggedFields,
    #[error("Integer overflow error")]
    IntegerOverflowError,
    #[error("Invalid recovery id")]
    InvalidRecoveryId,
    #[error("Invalid slice length: {0}")]
    InvalidSliceLength(String),
    #[error("Invalid signature")]
    InvalidSignature,
    /// Duplicated attribute key
    #[error("Duplicated attribute key: {0}")]
    DuplicatedAttributeKey(String),
    /// Both set payment_hash and payment_preimage
    #[error("Both payment_hash and payment_preimage are set")]
    BothPaymenthashAndPreimage,
    /// An error occurred during signing
    #[error("Sign error")]
    SignError,
    #[error("Hex decode error: {0}")]
    HexDecodeError(#[from] hex::FromHexError),
    #[error("Duplicated invoice found: {0}")]
    DuplicatedInvoice(String),
    #[error("Description with length of {0} is too long, max length is 639")]
    DescriptionTooLong(usize),
    #[error("Invoice not found")]
    InvoiceNotFound,
}


================================================
File: src/invoice/invoice_impl.rs
================================================
use super::errors::VerificationError;
use super::utils::*;
use crate::fiber::gen::invoice::{self as gen_invoice, *};
use crate::fiber::hash_algorithm::HashAlgorithm;
use crate::fiber::serde_utils::EntityHex;
use crate::fiber::serde_utils::U128Hex;
use crate::fiber::types::Hash256;
use crate::gen_rand_sha256_hash;
use crate::invoice::InvoiceError;
use bech32::{encode, u5, FromBase32, ToBase32, Variant, WriteBase32};
use bitcoin::hashes::{sha256::Hash as Sha256, Hash as _};
use ckb_types::{
    packed::{Byte, Script},
    prelude::{Pack, Unpack},
};
use core::time::Duration;
use molecule::prelude::{Builder, Entity};
use secp256k1::{
    self,
    ecdsa::{RecoverableSignature, RecoveryId},
    Message, PublicKey, Secp256k1,
};
use std::fmt::Display;

use serde::{Deserialize, Serialize};
use serde_with::serde_as;
use std::{cmp::Ordering, str::FromStr};

pub(crate) const SIGNATURE_U5_SIZE: usize = 104;
pub(crate) const MAX_DESCRIPTION_LENGTH: usize = 639;

/// The currency of the invoice, can also used to represent the CKB network chain.
#[derive(Debug, Clone, Copy, Eq, PartialEq, Serialize, Deserialize)]
pub enum CkbInvoiceStatus {
    /// The invoice is open and can be paid.
    Open,
    /// The invoice is cancelled.
    Cancelled,
    /// The invoice is expired.
    Expired,
    /// The invoice is received, but not settled yet.
    Received,
    /// The invoice is paid.
    Paid,
}

impl Display for CkbInvoiceStatus {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            CkbInvoiceStatus::Open => write!(f, "Open"),
            CkbInvoiceStatus::Cancelled => write!(f, "Cancelled"),
            CkbInvoiceStatus::Expired => write!(f, "Expired"),
            CkbInvoiceStatus::Received => write!(f, "Received"),
            CkbInvoiceStatus::Paid => write!(f, "Paid"),
        }
    }
}

/// The currency of the invoice, can also used to represent the CKB network chain.
#[derive(Debug, Clone, Copy, Eq, PartialEq, Serialize, Deserialize)]
pub enum Currency {
    /// The mainnet currency of CKB.
    Fibb,
    /// The testnet currency of the CKB network.
    Fibt,
    /// The devnet currency of the CKB network.
    Fibd,
}

impl TryFrom<u8> for Currency {
    type Error = InvoiceError;

    fn try_from(byte: u8) -> Result<Self, Self::Error> {
        match byte {
            0 => Ok(Self::Fibb),
            1 => Ok(Self::Fibt),
            2 => Ok(Self::Fibd),
            _ => Err(InvoiceError::UnknownCurrency(byte.to_string())),
        }
    }
}

impl Display for Currency {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Currency::Fibb => write!(f, "fibb"),
            Currency::Fibt => write!(f, "fibt"),
            Currency::Fibd => write!(f, "fibd"),
        }
    }
}

impl FromStr for Currency {
    type Err = InvoiceError;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s {
            "fibb" => Ok(Self::Fibb),
            "fibt" => Ok(Self::Fibt),
            "fibd" => Ok(Self::Fibd),
            _ => Err(InvoiceError::UnknownCurrency(s.to_string())),
        }
    }
}

#[serde_as]
#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
pub struct CkbScript(#[serde_as(as = "EntityHex")] pub Script);

#[serde_as]
#[derive(Debug, Clone, Eq, PartialEq, Serialize, Deserialize)]
pub enum Attribute {
    FinalHtlcTimeout(u64),
    FinalHtlcMinimumExpiryDelta(u64),
    ExpiryTime(Duration),
    Description(String),
    FallbackAddr(String),
    UdtScript(CkbScript),
    PayeePublicKey(PublicKey),
    HashAlgorithm(HashAlgorithm),
    Feature(u64),
}

#[serde_as]
#[derive(Debug, Clone, Eq, PartialEq, Serialize, Deserialize)]
pub struct InvoiceData {
    #[serde_as(as = "U128Hex")]
    pub timestamp: u128,
    pub payment_hash: Hash256,
    pub attrs: Vec<Attribute>,
}

/// Represents a syntactically and semantically correct lightning BOLT11 invoice
///
/// There are three ways to construct a `CkbInvoice`:
///  1. using [`CkbInvoiceBuilder`]
///  2. using `str::parse::<CkbInvoice>(&str)` (see [`CkbInvoice::from_str`])
///
#[serde_as]
#[derive(Debug, Clone, Eq, PartialEq, Serialize, Deserialize)]
pub struct CkbInvoice {
    /// The currency of the invoice
    pub currency: Currency,
    #[serde_as(as = "Option<U128Hex>")]
    /// The amount of the invoice
    pub amount: Option<u128>,
    /// The signature of the invoice
    pub signature: Option<InvoiceSignature>,
    /// The invoice data, including the payment hash, timestamp and other attributes
    pub data: InvoiceData,
}

macro_rules! attr_getter {
    ($name:ident, $attr_name:ident, $attr:ty) => {
        pub fn $name(&self) -> Option<&$attr> {
            self.data
                .attrs
                .iter()
                .filter_map(|attr| match attr {
                    Attribute::$attr_name(val) => Some(val),
                    _ => None,
                })
                .next()
        }
    };
}

impl CkbInvoice {
    fn hrp_part(&self) -> String {
        format!(
            "{}{}",
            self.currency,
            self.amount
                .map_or_else(|| "".to_string(), |x| x.to_string()),
        )
    }

    // Use the lostless compression algorithm to compress the invoice data.
    // To make sure the final encoded invoice address is shorter
    fn data_part(&self) -> Vec<u5> {
        let invoice_data = RawInvoiceData::from(self.data.clone());
        let compressed = ar_encompress(invoice_data.as_slice()).expect("compress invoice data");
        let mut base32 = Vec::with_capacity(compressed.len());
        compressed
            .write_base32(&mut base32)
            .expect("encode in base32");
        base32
    }

    fn hash(&self) -> [u8; 32] {
        let hrp = self.hrp_part();
        let data = self.data_part();
        let preimage = construct_invoice_preimage(hrp.as_bytes(), &data);
        let mut hash: [u8; 32] = Default::default();
        hash.copy_from_slice(&Sha256::hash(&preimage).to_byte_array());
        hash
    }

    /// Checks if the signature is valid for the included payee public key
    /// and also check the invoice data is consistent with the signature
    fn validate_signature(&self) -> bool {
        if self.signature.is_none() {
            return true;
        }
        let signature = self.signature.as_ref().expect("expect signature");
        let included_pub_key = self.payee_pub_key();

        let mut recovered_pub_key = Option::None;
        if included_pub_key.is_none() {
            let recovered = match self.recover_payee_pub_key() {
                Ok(pk) => pk,
                Err(_) => return false,
            };
            recovered_pub_key = Some(recovered);
        }

        let pub_key = included_pub_key
            .or(recovered_pub_key.as_ref())
            .expect("One is always present");

        let hash = Message::from_digest_slice(&self.hash()[..])
            .expect("Hash is 32 bytes long, same as MESSAGE_SIZE");

        let secp_context = Secp256k1::new();
        let verification_result =
            secp_context.verify_ecdsa(&hash, &signature.0.to_standard(), pub_key);
        match verification_result {
            Ok(()) => true,
            Err(_) => false,
        }
    }

    pub(crate) fn update_signature<F>(&mut self, sign_function: F) -> Result<(), InvoiceError>
    where
        F: FnOnce(&Message) -> RecoverableSignature,
    {
        let hash = self.hash();
        let message = Message::from_digest_slice(&hash).expect("message from digest slice");
        let signature = sign_function(&message);
        self.signature = Some(InvoiceSignature(signature));
        self.check_signature()?;
        Ok(())
    }

    /// Recovers the public key used for signing the invoice from the recoverable signature.
    pub fn recover_payee_pub_key(&self) -> Result<PublicKey, secp256k1::Error> {
        let hash = Message::from_digest_slice(&self.hash()[..])
            .expect("Hash is 32 bytes long, same as MESSAGE_SIZE");

        let res = secp256k1::Secp256k1::new()
            .recover_ecdsa(
                &hash,
                &self
                    .signature
                    .as_ref()
                    .expect("signature must be present")
                    .0,
            )
            .expect("payee pub key recovered");
        Ok(res)
    }

    pub fn is_signed(&self) -> bool {
        self.signature.is_some()
    }

    pub fn payment_hash(&self) -> &Hash256 {
        &self.data.payment_hash
    }

    pub fn is_expired(&self) -> bool {
        self.expiry_time().map_or(false, |expiry| {
            self.data.timestamp + expiry.as_millis()
                < std::time::UNIX_EPOCH
                    .elapsed()
                    .expect("Duration since unix epoch")
                    .as_millis()
        })
    }

    /// Check that the invoice is signed correctly and that key recovery works
    pub fn check_signature(&self) -> Result<(), InvoiceError> {
        if self.signature.is_none() {
            return Ok(());
        }
        match self.recover_payee_pub_key() {
            Err(secp256k1::Error::InvalidRecoveryId) => {
                return Err(InvoiceError::InvalidRecoveryId)
            }
            Err(secp256k1::Error::InvalidSignature) => return Err(InvoiceError::InvalidSignature),
            Err(e) => panic!("no other error may occur, got {:?}", e),
            Ok(_) => {}
        }

        if !self.validate_signature() {
            return Err(InvoiceError::InvalidSignature);
        }

        Ok(())
    }

    pub fn amount(&self) -> Option<u128> {
        self.amount
    }

    pub fn udt_type_script(&self) -> Option<&Script> {
        self.data
            .attrs
            .iter()
            .filter_map(|attr| match attr {
                Attribute::UdtScript(script) => Some(&script.0),
                _ => None,
            })
            .next()
    }

    attr_getter!(payee_pub_key, PayeePublicKey, PublicKey);
    attr_getter!(expiry_time, ExpiryTime, Duration);
    attr_getter!(description, Description, String);
    attr_getter!(
        final_tlc_minimum_expiry_delta,
        FinalHtlcMinimumExpiryDelta,
        u64
    );
    attr_getter!(fallback_address, FallbackAddr, String);
    attr_getter!(hash_algorithm, HashAlgorithm, HashAlgorithm);
}

/// Recoverable signature
#[derive(Clone, Debug, Eq, PartialEq)]
pub struct InvoiceSignature(pub RecoverableSignature);

impl PartialOrd for InvoiceSignature {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for InvoiceSignature {
    fn cmp(&self, other: &Self) -> Ordering {
        self.0
            .serialize_compact()
            .1
            .cmp(&other.0.serialize_compact().1)
    }
}

impl Serialize for InvoiceSignature {
    fn serialize<S>(
        &self,
        serializer: S,
    ) -> Result<<S as serde::Serializer>::Ok, <S as serde::Serializer>::Error>
    where
        S: serde::Serializer,
    {
        let base32: Vec<u8> = self.to_base32().iter().map(|x| x.to_u8()).collect();
        let hex = hex::encode(base32);
        hex.serialize(serializer)
    }
}

impl<'de> Deserialize<'de> for InvoiceSignature {
    fn deserialize<D>(deserializer: D) -> Result<Self, <D as serde::Deserializer<'de>>::Error>
    where
        D: serde::Deserializer<'de>,
    {
        let signature_hex: String = String::deserialize(deserializer)?;
        let signature_bytes = hex::decode(signature_hex).map_err(serde::de::Error::custom)?;
        let signature = InvoiceSignature::from_base32(
            &signature_bytes
                .iter()
                .map(|x| u5::try_from_u8(*x).expect("u5 from u8"))
                .collect::<Vec<u5>>(),
        );
        signature.map_err(serde::de::Error::custom)
    }
}

impl ToBase32 for InvoiceSignature {
    fn write_base32<W: WriteBase32>(&self, writer: &mut W) -> Result<(), <W as WriteBase32>::Err> {
        let mut converter = BytesToBase32::new(writer);
        let (recovery_id, signature) = self.0.serialize_compact();
        converter.append(&signature[..])?;
        converter.append_u8(recovery_id.to_i32() as u8)?;
        converter.finalize()
    }
}

impl InvoiceSignature {
    pub(crate) fn from_base32(signature: &[u5]) -> Result<Self, InvoiceError> {
        if signature.len() != SIGNATURE_U5_SIZE {
            return Err(InvoiceError::InvalidSliceLength(
                "InvoiceSignature::from_base32()".into(),
            ));
        }
        let recoverable_signature_bytes =
            Vec::<u8>::from_base32(signature).expect("bytes from base32");
        let signature = &recoverable_signature_bytes[0..64];
        let recovery_id = RecoveryId::from_i32(recoverable_signature_bytes[64] as i32)
            .expect("Recovery ID from i32");

        Ok(InvoiceSignature(
            RecoverableSignature::from_compact(signature, recovery_id)
                .expect("signature from compact"),
        ))
    }
}

impl Display for CkbInvoice {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let hrp = self.hrp_part();
        let mut data = self.data_part();
        data.insert(
            0,
            u5::try_from_u8(if self.signature.is_some() { 1 } else { 0 }).expect("u5 from u8"),
        );
        if let Some(signature) = &self.signature {
            data.extend_from_slice(&signature.to_base32());
        }
        write!(
            f,
            "{}",
            encode(&hrp, data, Variant::Bech32m).expect("encode invoice using Bech32m")
        )
    }
}

impl FromStr for CkbInvoice {
    type Err = InvoiceError;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        let (hrp, data, var) = bech32::decode(s).map_err(InvoiceError::Bech32Error)?;

        if var == bech32::Variant::Bech32 {
            return Err(InvoiceError::Bech32Error(bech32::Error::InvalidChecksum));
        }

        if data.len() < SIGNATURE_U5_SIZE {
            return Err(InvoiceError::TooShortDataPart);
        }
        let (currency, amount) = parse_hrp(&hrp)?;
        let is_signed = data[0].to_u8() == 1;
        let data_end = if is_signed {
            data.len() - SIGNATURE_U5_SIZE
        } else {
            data.len()
        };
        let data_part =
            Vec::<u8>::from_base32(&data[1..data_end]).map_err(InvoiceError::Bech32Error)?;
        let data_part = ar_decompress(&data_part).expect("decompress invoice data");
        let invoice_data = RawInvoiceData::from_slice(&data_part)
            .map_err(|err| InvoiceError::MoleculeError(VerificationError(err)))?;
        let signature = if is_signed {
            Some(InvoiceSignature::from_base32(
                &data[data.len() - SIGNATURE_U5_SIZE..],
            )?)
        } else {
            None
        };

        let invoice = CkbInvoice {
            currency,
            amount,
            signature,
            data: invoice_data.try_into().expect("pack invoice data"),
        };
        invoice.check_signature()?;
        Ok(invoice)
    }
}

impl From<Attribute> for InvoiceAttr {
    fn from(attr: Attribute) -> Self {
        let a = match attr {
            Attribute::ExpiryTime(x) => {
                let seconds = x.as_secs();
                let nanos = x.subsec_nanos() as u64;
                let value = gen_invoice::Duration::new_builder()
                    .seconds(seconds.pack())
                    .nanos(nanos.pack())
                    .build();
                InvoiceAttrUnion::ExpiryTime(ExpiryTime::new_builder().value(value).build())
            }
            Attribute::Description(value) => InvoiceAttrUnion::Description(
                Description::new_builder().value(value.pack()).build(),
            ),
            Attribute::FinalHtlcTimeout(value) => InvoiceAttrUnion::FinalHtlcTimeout(
                FinalHtlcTimeout::new_builder().value(value.pack()).build(),
            ),
            Attribute::FinalHtlcMinimumExpiryDelta(value) => {
                InvoiceAttrUnion::FinalHtlcMinimumExpiryDelta(
                    FinalHtlcMinimumExpiryDelta::new_builder()
                        .value(value.pack())
                        .build(),
                )
            }
            Attribute::FallbackAddr(value) => InvoiceAttrUnion::FallbackAddr(
                FallbackAddr::new_builder().value(value.pack()).build(),
            ),
            Attribute::Feature(value) => {
                InvoiceAttrUnion::Feature(Feature::new_builder().value(value.pack()).build())
            }
            Attribute::UdtScript(script) => {
                InvoiceAttrUnion::UdtScript(UdtScript::new_builder().value(script.0).build())
            }
            Attribute::PayeePublicKey(pubkey) => InvoiceAttrUnion::PayeePublicKey(
                PayeePublicKey::new_builder()
                    .value(pubkey.serialize().pack())
                    .build(),
            ),
            Attribute::HashAlgorithm(hash_algorithm) => InvoiceAttrUnion::HashAlgorithm(
                gen_invoice::HashAlgorithm::new_builder()
                    .value(Byte::new(hash_algorithm as u8))
                    .build(),
            ),
        };
        InvoiceAttr::new_builder().set(a).build()
    }
}

impl From<InvoiceAttr> for Attribute {
    fn from(attr: InvoiceAttr) -> Self {
        match attr.to_enum() {
            InvoiceAttrUnion::Description(x) => {
                let value: Vec<u8> = x.value().unpack();
                Attribute::Description(
                    String::from_utf8(value).expect("decode utf8 string from bytes"),
                )
            }
            InvoiceAttrUnion::ExpiryTime(x) => {
                let seconds: u64 = x.value().seconds().unpack();
                let nanos: u64 = x.value().nanos().unpack();
                Attribute::ExpiryTime(
                    Duration::from_secs(seconds).saturating_add(Duration::from_nanos(nanos)),
                )
            }
            InvoiceAttrUnion::FinalHtlcTimeout(x) => {
                Attribute::FinalHtlcTimeout(x.value().unpack())
            }
            InvoiceAttrUnion::FinalHtlcMinimumExpiryDelta(x) => {
                Attribute::FinalHtlcMinimumExpiryDelta(x.value().unpack())
            }
            InvoiceAttrUnion::FallbackAddr(x) => {
                let value: Vec<u8> = x.value().unpack();
                Attribute::FallbackAddr(
                    String::from_utf8(value).expect("decode utf8 string from bytes"),
                )
            }
            InvoiceAttrUnion::Feature(x) => Attribute::Feature(x.value().unpack()),
            InvoiceAttrUnion::UdtScript(x) => Attribute::UdtScript(CkbScript(x.value())),
            InvoiceAttrUnion::PayeePublicKey(x) => {
                let value: Vec<u8> = x.value().unpack();
                Attribute::PayeePublicKey(
                    PublicKey::from_slice(&value).expect("Public key from slice"),
                )
            }
            InvoiceAttrUnion::HashAlgorithm(x) => {
                let value = x.value();
                // Consider unknown algorithm as the default one.
                let hash_algorithm = value.try_into().unwrap_or_default();
                Attribute::HashAlgorithm(hash_algorithm)
            }
        }
    }
}

pub struct InvoiceBuilder {
    currency: Currency,
    amount: Option<u128>,
    payment_hash: Option<Hash256>,
    payment_preimage: Option<Hash256>,
    attrs: Vec<Attribute>,
}

impl Default for InvoiceBuilder {
    fn default() -> Self {
        Self::new(Currency::Fibb)
    }
}

macro_rules! attr_setter {
    ($name:ident, $attr:ident, $param:ty) => {
        pub fn $name(self, value: $param) -> Self {
            self.add_attr(Attribute::$attr(value))
        }
    };
}

impl InvoiceBuilder {
    pub fn new(currency: Currency) -> Self {
        Self {
            currency,
            amount: None,
            payment_hash: None,
            payment_preimage: None,
            attrs: Vec::new(),
        }
    }

    pub fn currency(mut self, currency: Currency) -> Self {
        self.currency = currency;
        self
    }

    pub fn amount(mut self, amount: Option<u128>) -> Self {
        self.amount = amount;
        self
    }

    pub fn add_attr(mut self, attr: Attribute) -> Self {
        self.attrs.push(attr);
        self
    }

    pub fn payment_hash(mut self, payment_hash: Hash256) -> Self {
        self.payment_hash = Some(payment_hash);
        self
    }

    pub fn payment_preimage(mut self, payment_preimage: Hash256) -> Self {
        self.payment_preimage = Some(payment_preimage);
        self
    }

    pub fn udt_type_script(self, script: Script) -> Self {
        self.add_attr(Attribute::UdtScript(CkbScript(script)))
    }

    pub fn hash_algorithm(self, algorithm: HashAlgorithm) -> Self {
        self.add_attr(Attribute::HashAlgorithm(algorithm))
    }

    attr_setter!(description, Description, String);
    attr_setter!(payee_pub_key, PayeePublicKey, PublicKey);
    attr_setter!(expiry_time, ExpiryTime, Duration);
    attr_setter!(fallback_address, FallbackAddr, String);
    attr_setter!(final_expiry_delta, FinalHtlcMinimumExpiryDelta, u64);

    pub fn build(self) -> Result<CkbInvoice, InvoiceError> {
        let preimage = self.payment_preimage;

        if self.payment_hash.is_some() && preimage.is_some() {
            return Err(InvoiceError::BothPaymenthashAndPreimage);
        }
        let payment_hash: Hash256 = if let Some(preimage) = preimage {
            let algo = self
                .attrs
                .iter()
                .find_map(|attr| match attr {
                    Attribute::HashAlgorithm(algo) => Some(algo),
                    _ => None,
                })
                .copied()
                .unwrap_or_default();
            algo.hash(preimage.as_ref()).into()
        } else if let Some(payment_hash) = self.payment_hash {
            payment_hash
        } else {
            // generate a random payment hash if not provided
            gen_rand_sha256_hash()
        };

        self.check_attrs_valid()?;
        let timestamp = std::time::UNIX_EPOCH
            .elapsed()
            .expect("Duration since unix epoch")
            .as_millis();
        Ok(CkbInvoice {
            currency: self.currency,
            amount: self.amount,
            signature: None,
            data: InvoiceData {
                timestamp,
                payment_hash,
                attrs: self.attrs,
            },
        })
    }

    pub fn build_with_sign<F>(self, sign_function: F) -> Result<CkbInvoice, InvoiceError>
    where
        F: FnOnce(&Message) -> RecoverableSignature,
    {
        let mut invoice = self.build()?;
        invoice.update_signature(sign_function)?;
        Ok(invoice)
    }

    fn check_attrs_valid(&self) -> Result<(), InvoiceError> {
        // check is there any duplicate attribute key set
        for (i, attr) in self.attrs.iter().enumerate() {
            for other in self.attrs.iter().skip(i + 1) {
                if std::mem::discriminant(attr) == std::mem::discriminant(other) {
                    return Err(InvoiceError::DuplicatedAttributeKey(format!("{:?}", attr)));
                }
            }
        }

        if let Some(len) = self.attrs.iter().find_map(|attr| match attr {
            Attribute::Description(desc) if desc.len() > MAX_DESCRIPTION_LENGTH => Some(desc.len()),
            _ => None,
        }) {
            return Err(InvoiceError::DescriptionTooLong(len));
        }

        Ok(())
    }
}

impl TryFrom<gen_invoice::RawCkbInvoice> for CkbInvoice {
    type Error = InvoiceError;

    fn try_from(invoice: gen_invoice::RawCkbInvoice) -> Result<Self, Self::Error> {
        Ok(CkbInvoice {
            currency: (u8::from(invoice.currency()))
                .try_into()
                .expect("currency from u8"),
            amount: invoice.amount().to_opt().map(|x| x.unpack()),
            signature: invoice.signature().to_opt().map(|x| {
                InvoiceSignature::from_base32(
                    &x.as_bytes()
                        .into_iter()
                        .map(|x| u5::try_from_u8(x).expect("u5 from u8"))
                        .collect::<Vec<u5>>(),
                )
                .expect("signature must be present")
            }),
            data: InvoiceData::try_from(invoice.data()).map_err(InvoiceError::MoleculeError)?,
        })
    }
}

impl From<CkbInvoice> for RawCkbInvoice {
    fn from(invoice: CkbInvoice) -> Self {
        RawCkbInvoiceBuilder::default()
            .currency((invoice.currency as u8).into())
            .amount(
                AmountOpt::new_builder()
                    .set(invoice.amount.map(|x| x.pack()))
                    .build(),
            )
            .signature(
                SignatureOpt::new_builder()
                    .set({
                        invoice.signature.map(|x| {
                            let bytes: [Byte; SIGNATURE_U5_SIZE] = x
                                .to_base32()
                                .iter()
                                .map(|x| u8_to_byte(x.to_u8()))
                                .collect::<Vec<_>>()
                                .as_slice()
                                .try_into()
                                .expect("[Byte; 104] from [Byte] slice");
                            Signature::new_builder().set(bytes).build()
                        })
                    })
                    .build(),
            )
            .data(invoice.data.into())
            .build()
    }
}

impl From<InvoiceData> for gen_invoice::RawInvoiceData {
    fn from(data: InvoiceData) -> Self {
        RawInvoiceDataBuilder::default()
            .timestamp(data.timestamp.pack())
            .payment_hash(
                PaymentHash::new_builder()
                    .set(
                        u8_slice_to_bytes(data.payment_hash.as_ref()).expect("bytes from u8 slice"),
                    )
                    .build(),
            )
            .attrs(
                InvoiceAttrsVec::new_builder()
                    .set(
                        data.attrs
                            .iter()
                            .map(|a| a.to_owned().into())
                            .collect::<Vec<InvoiceAttr>>(),
                    )
                    .build(),
            )
            .build()
    }
}

impl TryFrom<gen_invoice::RawInvoiceData> for InvoiceData {
    type Error = VerificationError;

    fn try_from(data: gen_invoice::RawInvoiceData) -> Result<Self, Self::Error> {
        Ok(InvoiceData {
            timestamp: data.timestamp().unpack(),
            payment_hash: bytes_to_u8_array(&data.payment_hash().as_bytes()).into(),
            attrs: data
                .attrs()
                .into_iter()
                .map(|a| a.into())
                .collect::<Vec<Attribute>>(),
        })
    }
}


================================================
File: src/invoice/mod.rs
================================================
mod command;
mod errors;
mod invoice_impl;
mod store;
mod utils;

#[cfg(test)]
mod tests;

pub use command::*;
pub use errors::InvoiceError;
pub use invoice_impl::{
    Attribute, CkbInvoice, CkbInvoiceStatus, Currency, InvoiceBuilder, InvoiceSignature,
};
pub use store::*;


================================================
File: src/invoice/store.rs
================================================
use super::{CkbInvoiceStatus, InvoiceError};
use crate::{fiber::types::Hash256, invoice::CkbInvoice};

pub trait InvoiceStore {
    fn get_invoice(&self, id: &Hash256) -> Option<CkbInvoice>;
    fn insert_invoice(
        &self,
        invoice: CkbInvoice,
        preimage: Option<Hash256>,
    ) -> Result<(), InvoiceError>;
    fn get_invoice_preimage(&self, id: &Hash256) -> Option<Hash256>;
    fn update_invoice_status(
        &self,
        id: &Hash256,
        status: CkbInvoiceStatus,
    ) -> Result<(), InvoiceError>;
    fn get_invoice_status(&self, id: &Hash256) -> Option<CkbInvoiceStatus>;
    fn insert_payment_preimage(
        &self,
        payment_hash: Hash256,
        preimage: Hash256,
    ) -> Result<(), InvoiceError>;
}


================================================
File: src/invoice/utils.rs
================================================
use arcode::bitbit::{BitReader, BitWriter, MSB};
use arcode::{ArithmeticDecoder, ArithmeticEncoder, EOFKind, Model};
use bech32::{u5, FromBase32, WriteBase32};
use ckb_types::packed::Byte;
use nom::{branch::alt, combinator::opt};
use nom::{
    bytes::{complete::take_while1, streaming::tag},
    IResult,
};

use std::io::{Cursor, Result as IoResult};
use std::str::FromStr;

use super::invoice_impl::Currency;
use super::InvoiceError;

/// Encodes bytes and returns the compressed form
/// This is used for encoding the invoice data, to make the final Invoice encoded address shorter
pub(crate) fn ar_encompress(data: &[u8]) -> IoResult<Vec<u8>> {
    let mut model = Model::builder().num_bits(8).eof(EOFKind::EndAddOne).build();
    let mut compressed_writer = BitWriter::new(Cursor::new(vec![]));
    let mut encoder = ArithmeticEncoder::new(48);
    for &sym in data {
        encoder.encode(sym as u32, &model, &mut compressed_writer)?;
        model.update_symbol(sym as u32);
    }

    encoder.encode(model.eof(), &model, &mut compressed_writer)?;
    encoder.finish_encode(&mut compressed_writer)?;
    compressed_writer.pad_to_byte()?;

    Ok(compressed_writer.get_ref().get_ref().clone())
}

/// Decompresses the data
pub(crate) fn ar_decompress(data: &[u8]) -> IoResult<Vec<u8>> {
    let mut model = Model::builder().num_bits(8).eof(EOFKind::EndAddOne).build();
    let mut input_reader = BitReader::<_, MSB>::new(data);
    let mut decoder = ArithmeticDecoder::new(48);
    let mut decompressed_data = vec![];

    while !decoder.finished() {
        let sym = decoder.decode(&model, &mut input_reader)?;
        model.update_symbol(sym);
        decompressed_data.push(sym as u8);
    }

    decompressed_data.pop(); // remove the EOF
    Ok(decompressed_data)
}

/// Construct the invoice's HRP and signatureless data into a preimage to be hashed.
pub(crate) fn construct_invoice_preimage(
    hrp_bytes: &[u8],
    data_without_signature: &[u5],
) -> Vec<u8> {
    let mut preimage = Vec::<u8>::from(hrp_bytes);

    let mut data_part = Vec::from(data_without_signature);
    let overhang = (data_part.len() * 5) % 8;
    if overhang > 0 {
        // add padding if data does not end at a byte boundary
        data_part.push(u5::try_from_u8(0).expect("u5 from u8"));

        // if overhang is in (1..3) we need to add u5(0) padding two times
        if overhang < 3 {
            data_part.push(u5::try_from_u8(0).expect("u5 from u8"));
        }
    }

    preimage.extend_from_slice(
        &Vec::<u8>::from_base32(&data_part)
            .expect("No padding error may occur due to appended zero above."),
    );
    preimage
}

/// Converts a stream of bytes written to it to base32. On finalization the according padding will
/// be applied. That means the results of writing two data blocks with one or two `BytesToBase32`
/// converters will differ.
pub(crate) struct BytesToBase32<'a, W: WriteBase32 + 'a> {
    /// Target for writing the resulting `u5`s resulting from the written bytes
    writer: &'a mut W,
    /// Holds all unwritten bits left over from last round. The bits are stored beginning from
    /// the most significant bit. E.g. if buffer_bits=3, then the byte with bits a, b and c will
    /// look as follows: [a, b, c, 0, 0, 0, 0, 0]
    buffer: u8,
    /// Amount of bits left over from last round, stored in buffer.
    buffer_bits: u8,
}

impl<'a, W: WriteBase32> BytesToBase32<'a, W> {
    /// Create a new bytes-to-base32 converter with `writer` as  a sink for the resulting base32
    /// data.
    pub fn new(writer: &'a mut W) -> BytesToBase32<'a, W> {
        BytesToBase32 {
            writer,
            buffer: 0,
            buffer_bits: 0,
        }
    }

    /// Add more bytes to the current conversion unit
    pub fn append(&mut self, bytes: &[u8]) -> Result<(), W::Err> {
        for b in bytes {
            self.append_u8(*b)?;
        }
        Ok(())
    }

    pub fn append_u8(&mut self, byte: u8) -> Result<(), W::Err> {
        // Write first u5 if we have to write two u5s this round. That only happens if the
        // buffer holds too many bits, so we don't have to combine buffer bits with new bits
        // from this rounds byte.
        if self.buffer_bits >= 5 {
            self.writer
                .write_u5(u5::try_from_u8((self.buffer & 0b11111000) >> 3).expect("<32"))?;
            self.buffer <<= 5;
            self.buffer_bits -= 5;
        }

        // Combine all bits from buffer with enough bits from this rounds byte so that they fill
        // a u5. Save remaining bits from byte to buffer.
        let from_buffer = self.buffer >> 3;
        let from_byte = byte >> (3 + self.buffer_bits); // buffer_bits <= 4

        self.writer
            .write_u5(u5::try_from_u8(from_buffer | from_byte).expect("<32"))?;
        self.buffer = byte << (5 - self.buffer_bits);
        self.buffer_bits += 3;

        Ok(())
    }

    pub fn finalize(mut self) -> Result<(), W::Err> {
        self.inner_finalize()?;
        core::mem::forget(self);
        Ok(())
    }

    fn inner_finalize(&mut self) -> Result<(), W::Err> {
        // There can be at most two u5s left in the buffer after processing all bytes, write them.
        if self.buffer_bits >= 5 {
            self.writer
                .write_u5(u5::try_from_u8((self.buffer & 0b11111000) >> 3).expect("<32"))?;
            self.buffer <<= 5;
            self.buffer_bits -= 5;
        }

        if self.buffer_bits != 0 {
            self.writer
                .write_u5(u5::try_from_u8(self.buffer >> 3).expect("<32"))?;
        }

        Ok(())
    }
}

impl<'a, W: WriteBase32> Drop for BytesToBase32<'a, W> {
    fn drop(&mut self) {
        self.inner_finalize()
            .expect("Unhandled error when finalizing conversion on drop. User finalize to handle.")
    }
}

fn nom_scan_hrp(input: &str) -> IResult<&str, (&str, Option<&str>)> {
    let (input, currency) = alt((tag("fibb"), tag("fibt"), tag("fibd")))(input)?;
    let (input, amount) = opt(take_while1(|c: char| c.is_numeric()))(input)?;
    Ok((input, (currency, amount)))
}

pub(crate) fn parse_hrp(input: &str) -> Result<(Currency, Option<u128>), InvoiceError> {
    match nom_scan_hrp(input) {
        Ok((left, (currency, amount))) => {
            if !left.is_empty() {
                return Err(InvoiceError::MalformedHRP(format!(
                    "{}, unexpected ending `{}`",
                    input, left
                )));
            }
            let currency = Currency::from_str(currency)?;
            let amount = amount
                .map(|x| x.parse().map_err(InvoiceError::ParseAmountError))
                .transpose()?;
            Ok((currency, amount))
        }
        Err(_) => Err(InvoiceError::MalformedHRP(input.to_string())),
    }
}

/// FIXME: remove these 3 converters after updating molecule to 0.8.0
pub(crate) fn u8_to_byte(u: u8) -> Byte {
    Byte::new(u)
}

pub(crate) fn u8_slice_to_bytes(slice: &[u8]) -> Result<[Byte; 32], &'static str> {
    let vec: Vec<Byte> = slice.iter().map(|&x| Byte::new(x)).collect();
    let boxed_slice = vec.into_boxed_slice();
    let boxed_array: Box<[Byte; 32]> = match boxed_slice.try_into() {
        Ok(ba) => ba,
        Err(_) => return Err("Slice length doesn't match array length"),
    };
    Ok(*boxed_array)
}

pub(crate) fn bytes_to_u8_array(array: &molecule::bytes::Bytes) -> [u8; 32] {
    let mut res = [0u8; 32];
    res.copy_from_slice(array);
    res
}

#[test]
fn test_parse_hrp() {
    let res = parse_hrp("fibb1280");
    assert_eq!(res, Ok((Currency::Fibb, Some(1280))));

    let res = parse_hrp("fibb");
    assert_eq!(res, Ok((Currency::Fibb, None)));

    let res = parse_hrp("fibt1023");
    assert_eq!(res, Ok((Currency::Fibt, Some(1023))));

    let res = parse_hrp("fibt10");
    assert_eq!(res, Ok((Currency::Fibt, Some(10))));

    let res = parse_hrp("fibt");
    assert_eq!(res, Ok((Currency::Fibt, None)));

    let res = parse_hrp("xnfibb");
    assert_eq!(res, Err(InvoiceError::MalformedHRP("xnfibb".to_string())));

    let res = parse_hrp("lxfibt");
    assert_eq!(res, Err(InvoiceError::MalformedHRP("lxfibt".to_string())));

    let res = parse_hrp("fibt");
    assert_eq!(res, Ok((Currency::Fibt, None)));

    let res = parse_hrp("fixt");
    assert_eq!(res, Err(InvoiceError::MalformedHRP("fixt".to_string())));

    let res = parse_hrp("fibtt");
    assert_eq!(
        res,
        Err(InvoiceError::MalformedHRP(
            "fibtt, unexpected ending `t`".to_string()
        ))
    );

    let res = parse_hrp("fibt1x24");
    assert_eq!(
        res,
        Err(InvoiceError::MalformedHRP(
            "fibt1x24, unexpected ending `x24`".to_string()
        ))
    );

    let res = parse_hrp("fibt000");
    assert_eq!(res, Ok((Currency::Fibt, Some(0))));

    let res = parse_hrp("fibt1024444444444444444444444444444444444444444444444444444444444444");
    assert!(matches!(res, Err(InvoiceError::ParseAmountError(_))));

    let res = parse_hrp("fibt0x");
    assert!(matches!(res, Err(InvoiceError::MalformedHRP(_))));

    let res = parse_hrp("");
    assert!(matches!(res, Err(InvoiceError::MalformedHRP(_))));
}


================================================
File: src/invoice/tests/invoice_impl.rs
================================================
use bech32::ToBase32;
use ckb_hash::blake2b_256;
use ckb_types::packed::Script;
use secp256k1::{Message, Secp256k1};
use std::time::{Duration, SystemTime, UNIX_EPOCH};

use crate::{
    fiber::{gen::invoice::RawCkbInvoice, types::Hash256},
    invoice::{
        invoice_impl::{CkbScript, InvoiceData, SIGNATURE_U5_SIZE},
        utils::{ar_decompress, ar_encompress},
        Attribute, CkbInvoice, Currency, InvoiceBuilder, InvoiceError, InvoiceSignature,
    },
};
use crate::{
    gen_rand_fiber_public_key, gen_rand_secp256k1_keypair_tuple, gen_rand_secp256k1_private_key,
    gen_rand_sha256_hash,
};

fn mock_invoice() -> CkbInvoice {
    let (private_key, public_key) = gen_rand_secp256k1_keypair_tuple();
    let mut invoice = CkbInvoice {
        currency: Currency::Fibb,
        amount: Some(1280),
        signature: None,
        data: InvoiceData {
            payment_hash: gen_rand_sha256_hash(),
            timestamp: SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .unwrap()
                .as_millis(),
            attrs: vec![
                Attribute::FinalHtlcTimeout(5),
                Attribute::FinalHtlcMinimumExpiryDelta(12),
                Attribute::Description("description".to_string()),
                Attribute::ExpiryTime(Duration::from_secs(1024)),
                Attribute::FallbackAddr("address".to_string()),
                Attribute::UdtScript(CkbScript(Script::default())),
                Attribute::PayeePublicKey(public_key),
            ],
        },
    };
    invoice
        .update_signature(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key))
        .unwrap();
    invoice
}

#[test]
fn test_signature() {
    let private_key = gen_rand_secp256k1_private_key();
    let signature = Secp256k1::new().sign_ecdsa_recoverable(
        &Message::from_digest_slice(&[0u8; 32]).unwrap(),
        &private_key,
    );
    let signature = InvoiceSignature(signature);
    let base32 = signature.to_base32();
    assert_eq!(base32.len(), SIGNATURE_U5_SIZE);

    let decoded_signature = InvoiceSignature::from_base32(&base32).unwrap();
    assert_eq!(decoded_signature, signature);
}

#[test]
fn test_ckb_invoice() {
    let ckb_invoice = mock_invoice();
    let ckb_invoice_clone = ckb_invoice.clone();
    let raw_invoice: RawCkbInvoice = ckb_invoice.into();
    let decoded_invoice: CkbInvoice = raw_invoice.try_into().unwrap();
    assert_eq!(decoded_invoice, ckb_invoice_clone);
    let address = ckb_invoice_clone.to_string();
    assert!(address.starts_with("fibb1280"));
}

#[test]
fn test_invoice_bc32m() {
    let invoice = mock_invoice();
    assert!(invoice.is_signed());
    assert_eq!(invoice.check_signature(), Ok(()));

    let address = invoice.to_string();
    assert!(address.starts_with("fibb1280"));

    let decoded_invoice = address.parse::<CkbInvoice>().unwrap();
    assert_eq!(decoded_invoice, invoice);
    assert!(decoded_invoice.is_signed());
    assert_eq!(decoded_invoice.amount(), Some(1280));
}

#[test]
fn test_invoice_from_str_err() {
    let invoice = mock_invoice();

    let address = invoice.to_string();
    assert!(address.starts_with("fibb1280"));

    let mut wrong = address.clone();
    wrong.push('1');
    let decoded_invoice = wrong.parse::<CkbInvoice>();
    assert_eq!(
        decoded_invoice.err(),
        Some(InvoiceError::Bech32Error(bech32::Error::InvalidLength))
    );

    let mut wrong = address.clone();
    // modify the values of wrong
    wrong.replace_range(10..12, "hi");
    let decoded_invoice = wrong.parse::<CkbInvoice>();
    assert_eq!(
        decoded_invoice.err(),
        Some(InvoiceError::Bech32Error(bech32::Error::InvalidChar('i')))
    );

    let mut wrong = address;
    // modify the values of wrong
    wrong.replace_range(10..12, "aa");
    let decoded_invoice = wrong.parse::<CkbInvoice>();
    assert_eq!(
        decoded_invoice.err(),
        Some(InvoiceError::Bech32Error(bech32::Error::InvalidChecksum))
    );

    wrong = wrong.replace("1280", "1281");
    let decoded_invoice = wrong.parse::<CkbInvoice>();
    assert_eq!(
        decoded_invoice.err(),
        Some(InvoiceError::Bech32Error(bech32::Error::InvalidChecksum))
    );
}

#[test]
fn test_invoice_bc32m_not_same() {
    let private_key = gen_rand_secp256k1_private_key();
    let signature = Secp256k1::new().sign_ecdsa_recoverable(
        &Message::from_digest_slice(&[0u8; 32]).unwrap(),
        &private_key,
    );
    let invoice = CkbInvoice {
        currency: Currency::Fibb,
        amount: Some(1280),
        signature: Some(InvoiceSignature(signature)),
        data: InvoiceData {
            payment_hash: [0u8; 32].into(),
            timestamp: 0,
            attrs: vec![
                Attribute::FinalHtlcTimeout(5),
                Attribute::FinalHtlcMinimumExpiryDelta(12),
                Attribute::Description("description hello".to_string()),
                Attribute::ExpiryTime(Duration::from_secs(1024)),
                Attribute::FallbackAddr("address".to_string()),
            ],
        },
    };

    let address = invoice.to_string();
    let decoded_invoice = address.parse::<CkbInvoice>().unwrap();
    assert_eq!(decoded_invoice, invoice);

    let mock_invoice = mock_invoice();
    let mock_address = mock_invoice.to_string();
    assert_ne!(mock_address, address);
}

#[test]
fn test_compress() {
    let input = "hrp1gyqsqqq5qqqqq9gqqqqp6qqqqq0qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq2qqqqqqqqqqqyvqsqqqsqqqqqvqqqqq8";
    let bytes = input.as_bytes();
    let compressed = ar_encompress(input.as_bytes()).unwrap();

    let decompressed = ar_decompress(&compressed).unwrap();
    let decompressed_str = std::str::from_utf8(&decompressed).unwrap();
    assert_eq!(input, decompressed_str);
    assert!(compressed.len() < bytes.len());
}

#[test]
fn test_invoice_builder() {
    let gen_payment_hash = gen_rand_sha256_hash();
    let (private_key, public_key) = gen_rand_secp256k1_keypair_tuple();

    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_hash(gen_payment_hash)
        .fallback_address("address".to_string())
        .expiry_time(Duration::from_secs(1024))
        .payee_pub_key(public_key)
        .add_attr(Attribute::FinalHtlcTimeout(5))
        .add_attr(Attribute::FinalHtlcMinimumExpiryDelta(12))
        .add_attr(Attribute::Description("description".to_string()))
        .add_attr(Attribute::UdtScript(CkbScript(Script::default())))
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key))
        .unwrap();

    let address = invoice.to_string();

    assert_eq!(invoice, address.parse::<CkbInvoice>().unwrap());

    assert_eq!(invoice.currency, Currency::Fibb);
    assert_eq!(invoice.amount, Some(1280));
    assert_eq!(invoice.payment_hash(), &gen_payment_hash);
    assert_eq!(invoice.data.attrs.len(), 7);
    assert!(invoice.check_signature().is_ok());
}

#[test]
fn test_invoice_check_signature() {
    let gen_payment_hash = gen_rand_sha256_hash();
    let (private_key, public_key) = gen_rand_secp256k1_keypair_tuple();

    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_hash(gen_payment_hash)
        .fallback_address("address".to_string())
        .expiry_time(Duration::from_secs(1024))
        .payee_pub_key(public_key)
        .add_attr(Attribute::FinalHtlcTimeout(5))
        .add_attr(Attribute::FinalHtlcMinimumExpiryDelta(12))
        .add_attr(Attribute::Description("description".to_string()))
        .add_attr(Attribute::UdtScript(CkbScript(Script::default())))
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key))
        .unwrap();

    assert_eq!(invoice.check_signature(), Ok(()));
    let payee_pubkey = invoice.payee_pub_key();
    assert_eq!(payee_pubkey, Some(&public_key));

    // modify the some element then check signature will fail
    let mut invoice_clone = invoice.clone();
    invoice_clone.data.attrs[0] = Attribute::FinalHtlcTimeout(6);
    assert_eq!(
        invoice_clone.check_signature(),
        Err(InvoiceError::InvalidSignature)
    );

    let mut invoice_clone = invoice.clone();
    invoice_clone.amount = Some(1281);
    assert_eq!(
        invoice_clone.check_signature(),
        Err(InvoiceError::InvalidSignature)
    );

    // if the invoice is not signed, check_signature will skipped
    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_hash(gen_payment_hash)
        .fallback_address("address".to_string())
        .expiry_time(Duration::from_secs(1024))
        .payee_pub_key(public_key)
        .add_attr(Attribute::FinalHtlcTimeout(5))
        .add_attr(Attribute::FinalHtlcMinimumExpiryDelta(12))
        .build()
        .unwrap();

    assert_eq!(invoice.check_signature(), Ok(()));
    // modify the some element then check signature will also skip
    let mut invoice_clone = invoice.clone();
    invoice_clone.amount = Some(1281);
    assert_eq!(invoice_clone.check_signature(), Ok(()));
}

#[test]
fn test_invoice_signature_check() {
    let gen_payment_hash = gen_rand_sha256_hash();
    let (private_key, _) = gen_rand_secp256k1_keypair_tuple();
    let public_key = gen_rand_fiber_public_key();

    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_hash(gen_payment_hash)
        .fallback_address("address".to_string())
        .expiry_time(Duration::from_secs(1024))
        .payee_pub_key(public_key.into())
        .add_attr(Attribute::FinalHtlcTimeout(5))
        .add_attr(Attribute::FinalHtlcMinimumExpiryDelta(12))
        .add_attr(Attribute::Description("description".to_string()))
        .add_attr(Attribute::UdtScript(CkbScript(Script::default())))
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key));

    assert_eq!(invoice.err(), Some(InvoiceError::InvalidSignature));
}

#[test]
fn test_invoice_builder_duplicated_attr() {
    let gen_payment_hash = gen_rand_sha256_hash();
    let private_key = gen_rand_secp256k1_private_key();
    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_hash(gen_payment_hash)
        .add_attr(Attribute::FinalHtlcTimeout(5))
        .add_attr(Attribute::FinalHtlcTimeout(6))
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key));

    assert_eq!(
        invoice.err(),
        Some(InvoiceError::DuplicatedAttributeKey(format!(
            "{:?}",
            Attribute::FinalHtlcTimeout(5)
        )))
    );
}

#[test]
fn test_invoice_check_description_length() {
    let gen_payment_hash = gen_rand_sha256_hash();
    let private_key = gen_rand_secp256k1_private_key();
    const MAX_DESCRIPTION_LEN: usize = 639;
    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_hash(gen_payment_hash)
        .description("a".repeat(MAX_DESCRIPTION_LEN + 1))
        .add_attr(Attribute::FinalHtlcTimeout(5))
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key));

    assert!(invoice.is_err());
    let message = invoice.err().unwrap().to_string();
    assert_eq!(
        message,
        "Description with length of 640 is too long, max length is 639"
    );
}

#[test]
fn test_invoice_builder_missing() {
    let private_key = gen_rand_secp256k1_private_key();
    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_preimage(gen_rand_sha256_hash())
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key));

    assert_eq!(invoice.err(), None);

    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_hash(gen_rand_sha256_hash())
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key));

    assert_eq!(invoice.err(), None);
}

#[test]
fn test_invoice_builder_preimage() {
    let preimage = gen_rand_sha256_hash();
    let private_key = gen_rand_secp256k1_private_key();
    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_preimage(preimage)
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key))
        .unwrap();
    let clone_invoice = invoice.clone();
    assert_eq!(hex::encode(invoice.payment_hash()).len(), 64);

    let raw_invoice: RawCkbInvoice = invoice.into();
    let decoded_invoice: CkbInvoice = raw_invoice.try_into().unwrap();
    assert_eq!(decoded_invoice, clone_invoice);
}

#[test]
fn test_invoice_builder_both_payment_hash_preimage() {
    let preimage = gen_rand_sha256_hash();
    let payment_hash = gen_rand_sha256_hash();
    let private_key = gen_rand_secp256k1_private_key();
    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_hash(payment_hash)
        .payment_preimage(preimage)
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key));

    assert_eq!(
        invoice.err(),
        Some(InvoiceError::BothPaymenthashAndPreimage)
    );
}

#[test]
fn test_invoice_serialize() {
    let invoice = mock_invoice();
    let res = serde_json::to_string(&invoice);
    assert!(res.is_ok());
    let decoded = serde_json::from_str::<CkbInvoice>(&res.unwrap()).unwrap();
    assert_eq!(decoded, invoice);
}

#[test]
fn test_invoice_timestamp() {
    let payment_hash = gen_rand_sha256_hash();
    let private_key = gen_rand_secp256k1_private_key();
    let invoice1 = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_hash(payment_hash)
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key))
        .unwrap();

    // sleep 1 milisecond to make sure the timestamp is different
    std::thread::sleep(Duration::from_millis(1));

    let invoice2 = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_hash(payment_hash)
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key))
        .unwrap();

    assert_ne!(invoice1.data.timestamp, invoice2.data.timestamp);
    assert_ne!(invoice1.to_string(), invoice2.to_string());
}

#[test]
fn test_invoice_gen_payment_hash() {
    let private_key = gen_rand_secp256k1_private_key();
    let payment_preimage = gen_rand_sha256_hash();
    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_preimage(payment_preimage)
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key))
        .unwrap();
    let payment_hash = invoice.payment_hash();
    let expected_hash: Hash256 = blake2b_256(payment_preimage.as_ref()).into();
    assert_eq!(expected_hash, *payment_hash);
}

#[test]
fn test_invoice_rand_payment_hash() {
    let private_key = gen_rand_secp256k1_private_key();
    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key));
    assert!(invoice.is_ok());
}

#[test]
fn test_invoice_udt_script() {
    let script = Script::default();
    let private_key = gen_rand_secp256k1_private_key();
    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_hash(gen_rand_sha256_hash())
        .udt_type_script(script.clone())
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key))
        .unwrap();
    assert_eq!(invoice.udt_type_script().unwrap(), &script);

    let res = serde_json::to_string(&invoice);
    assert!(res.is_ok());
    let decoded = serde_json::from_str::<CkbInvoice>(&res.unwrap()).unwrap();
    assert_eq!(decoded, invoice);
}

#[test]
fn test_invoice_check_expired() {
    let private_key = gen_rand_secp256k1_private_key();
    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_hash(gen_rand_sha256_hash())
        .expiry_time(Duration::from_secs(1))
        .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, &private_key))
        .unwrap();

    assert!(!invoice.is_expired());
    std::thread::sleep(Duration::from_secs(2));
    assert!(invoice.is_expired());
}


================================================
File: src/invoice/tests/mod.rs
================================================
mod invoice_impl;


================================================
File: src/rpc/README.md
================================================

# Fiber Network Node RPC

The RPC module provides a set of APIs for developers to interact with FNN. Please note that APIs are not stable yet and may change in the future.

Allowing arbitrary machines to access the JSON-RPC port (using the `rpc.listening_addr` configuration option) is **dangerous and strongly discouraged**. Please strictly limit the access to only trusted machines.

You may refer to the e2e test cases in the `tests/bruno/e2e` directory for examples of how to use the RPC.

**We are in a actively developing stage, don't hesitate to [report issues](https://github.com/nervosnetwork/fiber/issues) or ask for help in the [channel of the Nervos dev community](https://discord.gg/c5gntbFd).**

<!--**NOTE:** the content below is generated by gen_doc -->

* [RPC Methods](#rpc-methods)


    * [Module Cch](#module-cch)
        * [Method `send_btc`](#cch-send_btc)
        * [Method `receive_btc`](#cch-receive_btc)
        * [Method `get_receive_btc_order`](#cch-get_receive_btc_order)
    * [Module Channel](#module-channel)
        * [Method `open_channel`](#channel-open_channel)
        * [Method `accept_channel`](#channel-accept_channel)
        * [Method `list_channels`](#channel-list_channels)
        * [Method `shutdown_channel`](#channel-shutdown_channel)
        * [Method `update_channel`](#channel-update_channel)
    * [Module Dev](#module-dev)
        * [Method `commitment_signed`](#dev-commitment_signed)
        * [Method `add_tlc`](#dev-add_tlc)
        * [Method `remove_tlc`](#dev-remove_tlc)
        * [Method `submit_commitment_transaction`](#dev-submit_commitment_transaction)
    * [Module Graph](#module-graph)
        * [Method `graph_nodes`](#graph-graph_nodes)
        * [Method `graph_channels`](#graph-graph_channels)
    * [Module Info](#module-info)
        * [Method `node_info`](#info-node_info)
    * [Module Invoice](#module-invoice)
        * [Method `new_invoice`](#invoice-new_invoice)
        * [Method `parse_invoice`](#invoice-parse_invoice)
        * [Method `get_invoice`](#invoice-get_invoice)
        * [Method `cancel_invoice`](#invoice-cancel_invoice)
    * [Module Payment](#module-payment)
        * [Method `send_payment`](#payment-send_payment)
        * [Method `get_payment`](#payment-get_payment)
    * [Module Peer](#module-peer)
        * [Method `connect_peer`](#peer-connect_peer)
        * [Method `disconnect_peer`](#peer-disconnect_peer)
* [RPC Types](#rpc-types)

    * [Type `CchOrderStatus`](#type-cchorderstatus)
    * [Type `Channel`](#type-channel)
    * [Type `ChannelInfo`](#type-channelinfo)
    * [Type `CkbInvoice`](#type-ckbinvoice)
    * [Type `CkbInvoiceStatus`](#type-ckbinvoicestatus)
    * [Type `Currency`](#type-currency)
    * [Type `Hash256`](#type-hash256)
    * [Type `HashAlgorithm`](#type-hashalgorithm)
    * [Type `HopHint`](#type-hophint)
    * [Type `NodeInfo`](#type-nodeinfo)
    * [Type `PaymentSessionStatus`](#type-paymentsessionstatus)
    * [Type `Pubkey`](#type-pubkey)
    * [Type `RemoveTlcReason`](#type-removetlcreason)
    * [Type `SessionRoute`](#type-sessionroute)
    * [Type `UdtCfgInfos`](#type-udtcfginfos)

## RPC Modules

<a id="cch"></a>
### Module `Cch`
RPC module for cross chain hub demonstration.


<a id="cch-send_btc"></a>
#### Method `send_btc`

Send BTC to a address.

##### Params

* `btc_pay_req` - <em>`String`</em>, Bitcoin payment request string
* `currency` - <em>[Currency](#type-currency)</em>, Request currency

##### Returns

* `timestamp` - <em>`u64`</em>, Seconds since epoch when the order is created
* `expiry` - <em>`u64`</em>, Seconds after timestamp that the order expires
* `ckb_final_tlc_expiry_delta` - <em>`u64`</em>, The minimal expiry in seconds of the final TLC in the CKB network
* `currency` - <em>[Currency](#type-currency)</em>, Request currency
* `wrapped_btc_type_script` - <em>`ckb_jsonrpc_types::Script`</em>, Wrapped BTC type script
* `btc_pay_req` - <em>`String`</em>, Payment request for BTC
* `ckb_pay_req` - <em>`String`</em>, Payment request for CKB
* `payment_hash` - <em>`String`</em>, Payment hash for the HTLC for both CKB and BTC.
* `amount_sats` - <em>`u128`</em>, Amount required to pay in Satoshis, including fee
* `fee_sats` - <em>`u128`</em>, Fee in Satoshis
* `status` - <em>[CchOrderStatus](#type-cchorderstatus)</em>, Order status

---



<a id="cch-receive_btc"></a>
#### Method `receive_btc`

Receive BTC from a payment hash.

##### Params

* `payment_hash` - <em>`String`</em>, Payment hash for the HTLC for both CKB and BTC.
* `channel_id` - <em>[Hash256](#type-hash256)</em>, Channel ID for the CKB payment.
* `amount_sats` - <em>`u128`</em>, How many satoshis to receive, excluding cross-chain hub fee.
* `final_tlc_expiry` - <em>`u64`</em>, Expiry set for the HTLC for the CKB payment to the payee.

##### Returns

* `timestamp` - <em>`u64`</em>, Seconds since epoch when the order is created
* `expiry` - <em>`u64`</em>, Seconds after timestamp that the order expires
* `ckb_final_tlc_expiry_delta` - <em>`u64`</em>, The minimal expiry in seconds of the final TLC in the CKB network
* `wrapped_btc_type_script` - <em>`ckb_jsonrpc_types::Script`</em>, Wrapped BTC type script
* `btc_pay_req` - <em>`String`</em>, Payment request for BTC
* `payment_hash` - <em>`String`</em>, Payment hash for the HTLC for both CKB and BTC.
* `channel_id` - <em>[Hash256](#type-hash256)</em>, Channel ID for the CKB payment.
* `tlc_id` - <em>`Option<u64>`</em>, TLC ID for the CKB payment.
* `amount_sats` - <em>`u128`</em>, Amount will be received by the payee
* `fee_sats` - <em>`u128`</em>, Fee in Satoshis
* `status` - <em>[CchOrderStatus](#type-cchorderstatus)</em>, Order status

---



<a id="cch-get_receive_btc_order"></a>
#### Method `get_receive_btc_order`

Get receive BTC order by payment hash.

##### Params

* `payment_hash` - <em>`String`</em>, Payment hash for the HTLC for both CKB and BTC.

##### Returns

* `timestamp` - <em>`u64`</em>, Seconds since epoch when the order is created
* `expiry` - <em>`u64`</em>, Seconds after timestamp that the order expires
* `ckb_final_tlc_expiry_delta` - <em>`u64`</em>, The minimal expiry in seconds of the final TLC in the CKB network
* `wrapped_btc_type_script` - <em>`ckb_jsonrpc_types::Script`</em>, Wrapped BTC type script
* `btc_pay_req` - <em>`String`</em>, Payment request for BTC
* `payment_hash` - <em>`String`</em>, Payment hash for the HTLC for both CKB and BTC.
* `channel_id` - <em>[Hash256](#type-hash256)</em>, Channel ID for the CKB payment.
* `tlc_id` - <em>`Option<u64>`</em>, TLC ID for the CKB payment.
* `amount_sats` - <em>`u128`</em>, Amount will be received by the payee
* `fee_sats` - <em>`u128`</em>, Fee in Satoshis
* `status` - <em>[CchOrderStatus](#type-cchorderstatus)</em>, Order status

---



<a id="channel"></a>
### Module `Channel`
RPC module for channel management.


<a id="channel-open_channel"></a>
#### Method `open_channel`

Attempts to open a channel with a peer.

##### Params

* `peer_id` - <em>`PeerId`</em>, The peer ID to open a channel with, the peer must be connected through the [connect_peer](#peer-connect_peer) rpc first.
* `funding_amount` - <em>`u128`</em>, The amount of CKB or UDT to fund the channel with.
* `public` - <em>`Option<bool>`</em>, Whether this is a public channel (will be broadcasted to network, and can be used to forward TLCs), an optional parameter, default value is true.
* `funding_udt_type_script` - <em>`Option<Script>`</em>, The type script of the UDT to fund the channel with, an optional parameter.
* `shutdown_script` - <em>`Option<Script>`</em>, The script used to receive the channel balance, an optional parameter, default value is the secp256k1_blake160_sighash_all script corresponding to the configured private key.
* `commitment_delay_epoch` - <em>`Option<EpochNumberWithFraction>`</em>, The delay time for the commitment transaction, must be an [EpochNumberWithFraction](https://github.com/nervosnetwork/rfcs/blob/master/rfcs/0017-tx-valid-since/e-i-l-encoding.png) in u64 format, an optional parameter, default value is 24 hours.
* `commitment_fee_rate` - <em>`Option<u64>`</em>, The fee rate for the commitment transaction, an optional parameter.
* `funding_fee_rate` - <em>`Option<u64>`</em>, The fee rate for the funding transaction, an optional parameter.
* `tlc_expiry_delta` - <em>`Option<u64>`</em>, The expiry delta to forward a tlc, in milliseconds, default to 1 day, which is 24 * 60 * 60 * 1000 milliseconds
 This parameter can be updated with rpc `update_channel` later.
* `tlc_min_value` - <em>`Option<u128>`</em>, The minimum value for a TLC our side can send,
 an optional parameter, default is 0, which means we can send any TLC is larger than 0.
 This parameter can be updated with rpc `update_channel` later.
* `tlc_fee_proportional_millionths` - <em>`Option<u128>`</em>, The fee proportional millionths for a TLC, proportional to the amount of the forwarded tlc.
 The unit is millionths of the amount. default is 1000 which means 0.1%.
 This parameter can be updated with rpc `update_channel` later.
 Not that, we use outbound channel to calculate the fee for TLC forwarding. For example,
 if we have a path A -> B -> C, then the fee B requires for TLC forwarding, is calculated
 the channel configuration of B and C, not A and B.
* `max_tlc_value_in_flight` - <em>`Option<u128>`</em>, The maximum value in flight for TLCs, an optional parameter.
 This parameter can not be updated after channel is opened.
* `max_tlc_number_in_flight` - <em>`Option<u64>`</em>, The maximum number of TLCs that can be accepted, an optional parameter, default is 125
 This parameter can not be updated after channel is opened.

##### Returns

* `temporary_channel_id` - <em>[Hash256](#type-hash256)</em>, The temporary channel ID of the channel being opened

---



<a id="channel-accept_channel"></a>
#### Method `accept_channel`

Accepts a channel opening request from a peer.

##### Params

* `temporary_channel_id` - <em>[Hash256](#type-hash256)</em>, The temporary channel ID of the channel to accept
* `funding_amount` - <em>`u128`</em>, The amount of CKB or UDT to fund the channel with
* `shutdown_script` - <em>`Option<Script>`</em>, The script used to receive the channel balance, an optional parameter,
 default value is the secp256k1_blake160_sighash_all script corresponding to the configured private key
* `max_tlc_value_in_flight` - <em>`Option<u128>`</em>, The max tlc sum value in flight for the channel, default is u128::MAX
 This parameter can not be updated after channel is opened.
* `max_tlc_number_in_flight` - <em>`Option<u64>`</em>, The max tlc number in flight send from our side, default is 125
 This parameter can not be updated after channel is opened.
* `tlc_min_value` - <em>`Option<u128>`</em>, The minimum value for a TLC our side can send,
 an optional parameter, default is 0, which means we can send any TLC is larger than 0.
 This parameter can be updated with rpc `update_channel` later.
* `tlc_fee_proportional_millionths` - <em>`Option<u128>`</em>, The fee proportional millionths for a TLC, proportional to the amount of the forwarded tlc.
 The unit is millionths of the amount. default is 1000 which means 0.1%.
 This parameter can be updated with rpc `update_channel` later.
 Not that, we use outbound channel to calculate the fee for TLC forwarding. For example,
 if we have a path A -> B -> C, then the fee B requires for TLC forwarding, is calculated
 the channel configuration of B and C, not A and B.
* `tlc_expiry_delta` - <em>`Option<u64>`</em>, The expiry delta to forward a tlc, in milliseconds, default to 1 day, which is 24 * 60 * 60 * 1000 milliseconds
 This parameter can be updated with rpc `update_channel` later.

##### Returns

* `channel_id` - <em>[Hash256](#type-hash256)</em>, The final ID of the channel that was accepted, it's different from the temporary channel ID

---



<a id="channel-list_channels"></a>
#### Method `list_channels`

Lists all channels.

##### Params

* `peer_id` - <em>`Option<PeerId>`</em>, The peer ID to list channels for, an optional parameter, if not provided, all channels will be listed
* `include_closed` - <em>`Option<bool>`</em>, Whether to include closed channels in the list, an optional parameter, default value is false

##### Returns

* `channels` - <em>Vec<[Channel](#type-channel)></em>, The list of channels

---



<a id="channel-shutdown_channel"></a>
#### Method `shutdown_channel`

Shuts down a channel.

##### Params

* `channel_id` - <em>[Hash256](#type-hash256)</em>, The channel ID of the channel to shut down
* `close_script` - <em>`Script`</em>, The script used to receive the channel balance, only support secp256k1_blake160_sighash_all script for now
* `force` - <em>`Option<bool>`</em>, Whether to force the channel to close
* `fee_rate` - <em>`u64`</em>, The fee rate for the closing transaction, the fee will be deducted from the closing initiator's channel balance

##### Returns

* None

---



<a id="channel-update_channel"></a>
#### Method `update_channel`

Updates a channel.

##### Params

* `channel_id` - <em>[Hash256](#type-hash256)</em>, The channel ID of the channel to update
* `enabled` - <em>`Option<bool>`</em>, Whether the channel is enabled
* `tlc_expiry_delta` - <em>`Option<u64>`</em>, The CLTV delta from the current height that should be used to set the timelock for the final hop

 The expiry delta for the TLC locktime
* `tlc_minimum_value` - <em>`Option<u128>`</em>, The minimum value for a TLC
* `tlc_fee_proportional_millionths` - <em>`Option<u128>`</em>, The fee proportional millionths for a TLC

##### Returns

* None

---



<a id="dev"></a>
### Module `Dev`
RPC module for development purposes, this module is not intended to be used in production.
 This module will be disabled in release build.


<a id="dev-commitment_signed"></a>
#### Method `commitment_signed`

Sends a commitment_signed message to the peer.

##### Params

* `channel_id` - <em>[Hash256](#type-hash256)</em>, The channel ID of the channel to send the commitment_signed message to

##### Returns

* None

---



<a id="dev-add_tlc"></a>
#### Method `add_tlc`

Adds a TLC to a channel.

##### Params

* `channel_id` - <em>[Hash256](#type-hash256)</em>, The channel ID of the channel to add the TLC to
* `amount` - <em>`u128`</em>, The amount of the TLC
* `payment_hash` - <em>[Hash256](#type-hash256)</em>, The payment hash of the TLC
* `expiry` - <em>`u64`</em>, The expiry of the TLC
* `hash_algorithm` - <em>Option<[HashAlgorithm](#type-hashalgorithm)></em>, The hash algorithm of the TLC

##### Returns

* `tlc_id` - <em>`u64`</em>, The ID of the TLC

---



<a id="dev-remove_tlc"></a>
#### Method `remove_tlc`

Removes a TLC from a channel.

##### Params

* `channel_id` - <em>[Hash256](#type-hash256)</em>, The channel ID of the channel to remove the TLC from
* `tlc_id` - <em>`u64`</em>, The ID of the TLC to remove
* `reason` - <em>[RemoveTlcReason](#type-removetlcreason)</em>, The reason for removing the TLC, either a 32-byte hash for preimage fulfillment or an u32 error code for removal

##### Returns

* None

---



<a id="dev-submit_commitment_transaction"></a>
#### Method `submit_commitment_transaction`

Submit a commitment transaction to the chain

##### Params

* `channel_id` - <em>[Hash256](#type-hash256)</em>, Channel ID
* `commitment_number` - <em>`u64`</em>, Commitment number

##### Returns

* `tx_hash` - <em>[Hash256](#type-hash256)</em>, Submitted commitment transaction hash

---



<a id="graph"></a>
### Module `Graph`
RPC module for graph management.


<a id="graph-graph_nodes"></a>
#### Method `graph_nodes`

Get the list of nodes in the network graph.

##### Params

* `limit` - <em>`Option<u64>`</em>, The maximum number of nodes to return.
* `after` - <em>`Option<JsonBytes>`</em>, The cursor to start returning nodes from.

##### Returns

* `nodes` - <em>Vec<[NodeInfo](#type-nodeinfo)></em>, The list of nodes.
* `last_cursor` - <em>`JsonBytes`</em>, The last cursor.

---



<a id="graph-graph_channels"></a>
#### Method `graph_channels`

Get the list of channels in the network graph.

##### Params

* `limit` - <em>`Option<u64>`</em>, The maximum number of channels to return.
* `after` - <em>`Option<JsonBytes>`</em>, The cursor to start returning channels from.

##### Returns

* `channels` - <em>Vec<[ChannelInfo](#type-channelinfo)></em>, A list of channels.
* `last_cursor` - <em>`JsonBytes`</em>, The last cursor for pagination.

---



<a id="info"></a>
### Module `Info`
The RPC module for node information.


<a id="info-node_info"></a>
#### Method `node_info`

Get the node information.

##### Params
* None

##### Returns

* `version` - <em>`String`</em>, The version of the node software.
* `commit_hash` - <em>`String`</em>, The commit hash of the node software.
* `node_id` - <em>[Pubkey](#type-pubkey)</em>, The identity public key of the node.
* `node_name` - <em>`Option<String>`</em>, The optional name of the node.
* `addresses` - <em>`Vec<MultiAddr>`</em>, A list of multi-addresses associated with the node.
* `chain_hash` - <em>[Hash256](#type-hash256)</em>, The hash of the blockchain that the node is connected to.
* `open_channel_auto_accept_min_ckb_funding_amount` - <em>`u64`</em>, The minimum CKB funding amount for automatically accepting open channel requests, serialized as a hexadecimal string.
* `auto_accept_channel_ckb_funding_amount` - <em>`u64`</em>, The CKB funding amount for automatically accepting channel requests, serialized as a hexadecimal string.
* `default_funding_lock_script` - <em>`Script`</em>, The default funding lock script for the node.
* `tlc_expiry_delta` - <em>`u64`</em>, The locktime expiry delta for Time-Locked Contracts (TLC), serialized as a hexadecimal string.
* `tlc_min_value` - <em>`u128`</em>, The minimum value for Time-Locked Contracts (TLC) we can send, serialized as a hexadecimal string.
* `tlc_max_value` - <em>`u128`</em>, The maximum value for Time-Locked Contracts (TLC) we can send, serialized as a hexadecimal string, `0` means no maximum value limit.
* `tlc_fee_proportional_millionths` - <em>`u128`</em>, The fee (to forward payments) proportional to the value of Time-Locked Contracts (TLC), expressed in millionths and serialized as a hexadecimal string.
* `channel_count` - <em>`u32`</em>, The number of channels associated with the node, serialized as a hexadecimal string.
* `pending_channel_count` - <em>`u32`</em>, The number of pending channels associated with the node, serialized as a hexadecimal string.
* `peers_count` - <em>`u32`</em>, The number of peers connected to the node, serialized as a hexadecimal string.
* `udt_cfg_infos` - <em>[UdtCfgInfos](#type-udtcfginfos)</em>, Configuration information for User-Defined Tokens (UDT) associated with the node.

---



<a id="invoice"></a>
### Module `Invoice`
RPC module for invoice management.


<a id="invoice-new_invoice"></a>
#### Method `new_invoice`

Generates a new invoice.

##### Params

* `amount` - <em>`u128`</em>, The amount of the invoice.
* `description` - <em>`Option<String>`</em>, The description of the invoice.
* `currency` - <em>[Currency](#type-currency)</em>, The currency of the invoice.
* `payment_preimage` - <em>[Hash256](#type-hash256)</em>, The payment preimage of the invoice.
* `expiry` - <em>`Option<u64>`</em>, The expiry time of the invoice.
* `fallback_address` - <em>`Option<String>`</em>, The fallback address of the invoice.
* `final_expiry_delta` - <em>`Option<u64>`</em>, The final HTLC timeout of the invoice.
* `udt_type_script` - <em>`Option<Script>`</em>, The UDT type script of the invoice.
* `hash_algorithm` - <em>Option<[HashAlgorithm](#type-hashalgorithm)></em>, The hash algorithm of the invoice.

##### Returns

* `invoice_address` - <em>`String`</em>, The encoded invoice address.
* `invoice` - <em>[CkbInvoice](#type-ckbinvoice)</em>, The invoice.

---



<a id="invoice-parse_invoice"></a>
#### Method `parse_invoice`

Parses a encoded invoice.

##### Params

* `invoice` - <em>`String`</em>, The encoded invoice address.

##### Returns

* `invoice` - <em>[CkbInvoice](#type-ckbinvoice)</em>, The invoice.

---



<a id="invoice-get_invoice"></a>
#### Method `get_invoice`

Retrieves an invoice.

##### Params

* `payment_hash` - <em>[Hash256](#type-hash256)</em>, The payment hash of the invoice.

##### Returns

* `invoice_address` - <em>`String`</em>, The encoded invoice address.
* `invoice` - <em>[CkbInvoice](#type-ckbinvoice)</em>, The invoice.
* `status` - <em>[CkbInvoiceStatus](#type-ckbinvoicestatus)</em>, The invoice status

---



<a id="invoice-cancel_invoice"></a>
#### Method `cancel_invoice`

Cancels an invoice, only when invoice is in status `Open` can be canceled.

##### Params

* `payment_hash` - <em>[Hash256](#type-hash256)</em>, The payment hash of the invoice.

##### Returns

* `invoice_address` - <em>`String`</em>, The encoded invoice address.
* `invoice` - <em>[CkbInvoice](#type-ckbinvoice)</em>, The invoice.
* `status` - <em>[CkbInvoiceStatus](#type-ckbinvoicestatus)</em>, The invoice status

---



<a id="payment"></a>
### Module `Payment`
RPC module for channel management.


<a id="payment-send_payment"></a>
#### Method `send_payment`

Sends a payment to a peer.

##### Params

* `target_pubkey` - <em>Option<[Pubkey](#type-pubkey)></em>, the identifier of the payment target
* `amount` - <em>`Option<u128>`</em>, the amount of the payment
* `payment_hash` - <em>Option<[Hash256](#type-hash256)></em>, the hash to use within the payment's HTLC
* `final_tlc_expiry_delta` - <em>`Option<u64>`</em>, the TLC expiry delta should be used to set the timelock for the final hop, in milliseconds
* `tlc_expiry_limit` - <em>`Option<u64>`</em>, the TLC expiry limit for the whole payment, in milliseconds, each hop is with a default tlc delta of 1 day
 suppose the payment router is with N hops, the total tlc expiry limit is at least (N-1) days
 this is also the default value for the payment if this parameter is not provided
* `invoice` - <em>`Option<String>`</em>, the encoded invoice to send to the recipient
* `timeout` - <em>`Option<u64>`</em>, the payment timeout in seconds, if the payment is not completed within this time, it will be cancelled
* `max_fee_amount` - <em>`Option<u128>`</em>, the maximum fee amounts in shannons that the sender is willing to pay
* `max_parts` - <em>`Option<u64>`</em>, max parts for the payment, only used for multi-part payments
* `keysend` - <em>`Option<bool>`</em>, keysend payment
* `udt_type_script` - <em>`Option<Script>`</em>, udt type script for the payment
* `allow_self_payment` - <em>`Option<bool>`</em>, allow self payment, default is false
* `hop_hints` - <em>Option<Vec<[HopHint](#type-hophint)>></em>, Optional route hints to reach the destination through private channels.
 A hop hint is a hint for a node to use a specific channel, for example
 (pubkey, funding_txid, inbound) where pubkey is the public key of the node,
 funding_txid is the funding transaction hash of the channel outpoint, and
 inbound is a boolean indicating whether to use the channel to send or receive.
 Note: an inproper hint may cause the payment to fail, and hop_hints maybe helpful for self payment scenario
 for helping the routing algorithm to find the correct path
* `dry_run` - <em>`Option<bool>`</em>, dry_run for payment, used for check whether we can build valid router and the fee for this payment,
 it's useful for the sender to double check the payment before sending it to the network,
 default is false

##### Returns

* `payment_hash` - <em>[Hash256](#type-hash256)</em>, The payment hash of the payment
* `status` - <em>[PaymentSessionStatus](#type-paymentsessionstatus)</em>, The status of the payment
* `created_at` - <em>`u64`</em>, The time the payment was created at, in milliseconds from UNIX epoch
* `last_updated_at` - <em>`u64`</em>, The time the payment was last updated at, in milliseconds from UNIX epoch
* `failed_error` - <em>`Option<String>`</em>, The error message if the payment failed
* `fee` - <em>`u128`</em>, fee paid for the payment
* `router` - <em>[SessionRoute](#type-sessionroute)</em>, The route information for the payment

---



<a id="payment-get_payment"></a>
#### Method `get_payment`

Retrieves a payment.

##### Params

* `payment_hash` - <em>[Hash256](#type-hash256)</em>, The payment hash of the payment to retrieve

##### Returns

* `payment_hash` - <em>[Hash256](#type-hash256)</em>, The payment hash of the payment
* `status` - <em>[PaymentSessionStatus](#type-paymentsessionstatus)</em>, The status of the payment
* `created_at` - <em>`u64`</em>, The time the payment was created at, in milliseconds from UNIX epoch
* `last_updated_at` - <em>`u64`</em>, The time the payment was last updated at, in milliseconds from UNIX epoch
* `failed_error` - <em>`Option<String>`</em>, The error message if the payment failed
* `fee` - <em>`u128`</em>, fee paid for the payment
* `router` - <em>[SessionRoute](#type-sessionroute)</em>, The route information for the payment

---



<a id="peer"></a>
### Module `Peer`
RPC module for peer management.


<a id="peer-connect_peer"></a>
#### Method `connect_peer`

Connect to a peer.

##### Params

* `address` - <em>`MultiAddr`</em>, The address of the peer to connect to.
* `save` - <em>`Option<bool>`</em>, Whether to save the peer address to the peer store.

##### Returns

* None

---



<a id="peer-disconnect_peer"></a>
#### Method `disconnect_peer`

Disconnect from a peer.

##### Params

* `peer_id` - <em>`PeerId`</em>, The peer ID of the peer to disconnect.

##### Returns

* None

---




## RPC Types


<a id="#type-cchorderstatus"></a>
### Type `CchOrderStatus`

The status of a cross-chain hub order, will update as the order progresses.


#### Enum with values of

* `Pending` - Order is created and has not send out payments yet.
* `Accepted` - HTLC in the first half is accepted.
* `InFlight` - There's an outgoing payment in flight for the second half.
* `Succeeded` - Order is settled.
* `Failed` - Order is failed.
---

<a id="#type-channel"></a>
### Type `Channel`

The channel data structure


#### Fields

* `channel_id` - <em>Hash256</em>, The channel ID
* `is_public` - <em>bool</em>, Whether the channel is public
* `channel_outpoint` - <em>`Option<OutPoint>`</em>, The outpoint of the channel
* `peer_id` - <em>PeerId</em>, The peer ID of the channel
* `funding_udt_type_script` - <em>`Option<Script>`</em>, The UDT type script of the channel
* `state` - <em>ChannelState</em>, The state of the channel
* `local_balance` - <em>u128</em>, The local balance of the channel
* `offered_tlc_balance` - <em>u128</em>, The offered balance of the channel
* `remote_balance` - <em>u128</em>, The remote balance of the channel
* `received_tlc_balance` - <em>u128</em>, The received balance of the channel
* `latest_commitment_transaction_hash` - <em>`Option<H256>`</em>, The hash of the latest commitment transaction
* `created_at` - <em>u64</em>, The time the channel was created at, in milliseconds from UNIX epoch
---

<a id="#type-channelinfo"></a>
### Type `ChannelInfo`

The Channel information.


#### Fields

* `channel_outpoint` - <em>OutPoint</em>, The outpoint of the channel.
* `node1` - <em>Pubkey</em>, The identity public key of the first node.
* `node2` - <em>Pubkey</em>, The identity public key of the second node.
* `created_timestamp` - <em>u64</em>, The created timestamp of the channel, which is the block header timestamp of the block
 that contains the channel funding transaction.
* `last_updated_timestamp_of_node1` - <em>`Option<u64>`</em>, The timestamp of the last update to channel by node 1 (e.g. updating fee rate).
* `last_updated_timestamp_of_node2` - <em>`Option<u64>`</em>, The timestamp of the last update to channel by node 2 (e.g. updating fee rate).
* `fee_rate_of_node1` - <em>`Option<u64>`</em>, The fee rate set by node 1. This is the fee rate for node 1 to forward tlcs sent from node 2 to node 1.
* `fee_rate_of_node2` - <em>`Option<u64>`</em>, The fee rate set by node 2. This is the fee rate for node 2 to forward tlcs sent from node 1 to node 2.
* `capacity` - <em>u128</em>, The capacity of the channel.
* `chain_hash` - <em>Hash256</em>, The chain hash of the channel.
* `udt_type_script` - <em>`Option<Script>`</em>, The UDT type script of the channel.
---

<a id="#type-ckbinvoice"></a>
### Type `CkbInvoice`

Represents a syntactically and semantically correct lightning BOLT11 invoice

 There are three ways to construct a `CkbInvoice`:
  1. using [`CkbInvoiceBuilder`]
  2. using `str::parse::<CkbInvoice>(&str)` (see [`CkbInvoice::from_str`])


#### Fields

* `currency` - <em>Currency</em>, The currency of the invoice
* `amount` - <em>`Option<u128>`</em>, The amount of the invoice
* `signature` - <em>`Option<InvoiceSignature>`</em>, The signature of the invoice
* `data` - <em>InvoiceData</em>, The invoice data, including the payment hash, timestamp and other attributes
---

<a id="#type-ckbinvoicestatus"></a>
### Type `CkbInvoiceStatus`

The currency of the invoice, can also used to represent the CKB network chain.


#### Enum with values of

* `Open` - The invoice is open and can be paid.
* `Cancelled` - The invoice is cancelled.
* `Expired` - The invoice is expired.
* `Received` - The invoice is received, but not settled yet.
* `Paid` - The invoice is paid.
---

<a id="#type-currency"></a>
### Type `Currency`

The currency of the invoice, can also used to represent the CKB network chain.


#### Enum with values of

* `Fibb` - The mainnet currency of CKB.
* `Fibt` - The testnet currency of the CKB network.
* `Fibd` - The devnet currency of the CKB network.
---

<a id="#type-hash256"></a>
### Type `Hash256`

A 256-bit hash digest, used as identifier of channnel, payment, transaction hash etc.



---

<a id="#type-hashalgorithm"></a>
### Type `HashAlgorithm`

HashAlgorithm is the hash algorithm used in the hash lock.


#### Enum with values of

* `CkbHash` - The default hash algorithm, CkbHash
* `Sha256` - The sha256 hash algorithm
---

<a id="#type-hophint"></a>
### Type `HopHint`

A hop hint is a hint for a node to use a specific channel.


#### Fields

* `pubkey` - <em>Pubkey</em>, The public key of the node
* `channel_funding_tx` - <em>Hash256</em>, The funding transaction hash of the channel outpoint
* `inbound` - <em>bool</em>, inbound or outbound to use this channel
---

<a id="#type-nodeinfo"></a>
### Type `NodeInfo`

The Node information.


#### Fields

* `node_name` - <em>String</em>, The name of the node.
* `addresses` - <em>`Vec<MultiAddr>`</em>, The addresses of the node.
* `node_id` - <em>Pubkey</em>, The identity public key of the node.
* `timestamp` - <em>u64</em>, The timestamp of the node.
* `chain_hash` - <em>Hash256</em>, The chain hash of the node.
* `auto_accept_min_ckb_funding_amount` - <em>u64</em>, The minimum CKB funding amount for automatically accepting open channel requests.
* `udt_cfg_infos` - <em>UdtCfgInfos</em>, The UDT configuration infos of the node.
---

<a id="#type-paymentsessionstatus"></a>
### Type `PaymentSessionStatus`

The status of a payment, will update as the payment progresses.


#### Enum with values of

* `Created` - initial status, payment session is created, no HTLC is sent
* `Inflight` - the first hop AddTlc is sent successfully and waiting for the response
* `Success` - related HTLC is successfully settled
* `Failed` - related HTLC is failed
---

<a id="#type-pubkey"></a>
### Type `Pubkey`

The public key for a Node



---

<a id="#type-removetlcreason"></a>
### Type `RemoveTlcReason`

The reason for removing a TLC


#### Enum with values of

* `RemoveTlcFulfill` - The reason for removing the TLC is that it was fulfilled
* `RemoveTlcFail` - The reason for removing the TLC is that it failed
---

<a id="#type-sessionroute"></a>
### Type `SessionRoute`

The router is a list of nodes that the payment will go through.
 We store in the payment session and then will use it to track the payment history.
 The router is a list of nodes that the payment will go through.
 For example:
    A(amount, channel) -> B -> C -> D means A will send `amount` with `channel` to B.


#### Fields

* `nodes` - <em>`Vec<SessionRouteNode>`</em>, the nodes in the route
---

<a id="#type-udtcfginfos"></a>
### Type `UdtCfgInfos`

The UDT configurations



---



================================================
File: src/rpc/cch.rs
================================================
use crate::{
    cch::{CchMessage, CchOrderStatus, ReceiveBTCOrder},
    fiber::{
        serde_utils::{U128Hex, U64Hex},
        types::Hash256,
    },
    invoice::Currency,
};
use jsonrpsee::{
    core::async_trait,
    proc_macros::rpc,
    types::{error::CALL_EXECUTION_FAILED_CODE, ErrorObjectOwned},
};
use ractor::{call_t, ActorRef};
use serde::{Deserialize, Serialize};
use serde_with::serde_as;

#[derive(Serialize, Deserialize)]
pub(crate) struct SendBtcParams {
    /// Bitcoin payment request string
    btc_pay_req: String,
    /// Request currency
    currency: Currency,
}

#[serde_as]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub(crate) struct SendBTCResponse {
    /// Seconds since epoch when the order is created
    #[serde_as(as = "U64Hex")]
    timestamp: u64,
    /// Seconds after timestamp that the order expires
    #[serde_as(as = "U64Hex")]
    expiry: u64,
    /// The minimal expiry in seconds of the final TLC in the CKB network
    #[serde_as(as = "U64Hex")]
    ckb_final_tlc_expiry_delta: u64,

    /// Request currency
    currency: Currency,
    /// Wrapped BTC type script
    wrapped_btc_type_script: ckb_jsonrpc_types::Script,

    /// Payment request for BTC
    btc_pay_req: String,
    /// Payment request for CKB
    ckb_pay_req: String,
    /// Payment hash for the HTLC for both CKB and BTC.
    payment_hash: String,
    /// Amount required to pay in Satoshis, including fee
    #[serde_as(as = "U128Hex")]
    amount_sats: u128,
    /// Fee in Satoshis
    #[serde_as(as = "U128Hex")]
    fee_sats: u128,
    /// Order status
    status: CchOrderStatus,
}

#[serde_as]
#[derive(Serialize, Deserialize)]
pub(crate) struct ReceiveBtcParams {
    /// Payment hash for the HTLC for both CKB and BTC.
    payment_hash: String,
    /// Channel ID for the CKB payment.
    channel_id: Hash256,
    /// How many satoshis to receive, excluding cross-chain hub fee.
    #[serde_as(as = "U128Hex")]
    amount_sats: u128,
    /// Expiry set for the HTLC for the CKB payment to the payee.
    #[serde_as(as = "U64Hex")]
    final_tlc_expiry: u64,
}

#[derive(Serialize, Deserialize)]
pub(crate) struct GetReceiveBtcOrderParams {
    /// Payment hash for the HTLC for both CKB and BTC.
    payment_hash: String,
}

#[serde_as]
#[derive(Debug, Clone, Serialize, Deserialize)]
pub(crate) struct ReceiveBTCResponse {
    /// Seconds since epoch when the order is created
    #[serde_as(as = "U64Hex")]
    timestamp: u64,
    /// Seconds after timestamp that the order expires
    #[serde_as(as = "U64Hex")]
    expiry: u64,
    /// The minimal expiry in seconds of the final TLC in the CKB network
    #[serde_as(as = "U64Hex")]
    ckb_final_tlc_expiry_delta: u64,

    /// Wrapped BTC type script
    wrapped_btc_type_script: ckb_jsonrpc_types::Script,

    /// Payment request for BTC
    btc_pay_req: String,
    /// Payment hash for the HTLC for both CKB and BTC.
    payment_hash: String,
    /// Channel ID for the CKB payment.
    channel_id: Hash256,
    /// TLC ID for the CKB payment.
    #[serde_as(as = "Option<U64Hex>")]
    tlc_id: Option<u64>,

    /// Amount will be received by the payee
    #[serde_as(as = "U128Hex")]
    amount_sats: u128,
    /// Fee in Satoshis
    #[serde_as(as = "U128Hex")]
    fee_sats: u128,

    /// Order status
    status: CchOrderStatus,
}

/// RPC module for cross chain hub demonstration.
#[rpc(server)]
trait CchRpc {
    /// Send BTC to a address.
    #[method(name = "send_btc")]
    async fn send_btc(&self, params: SendBtcParams) -> Result<SendBTCResponse, ErrorObjectOwned>;

    /// Receive BTC from a payment hash.
    #[method(name = "receive_btc")]
    async fn receive_btc(
        &self,
        params: ReceiveBtcParams,
    ) -> Result<ReceiveBTCResponse, ErrorObjectOwned>;

    /// Get receive BTC order by payment hash.
    #[method(name = "get_receive_btc_order")]
    async fn get_receive_btc_order(
        &self,
        params: GetReceiveBtcOrderParams,
    ) -> Result<ReceiveBTCResponse, ErrorObjectOwned>;
}

pub(crate) struct CchRpcServerImpl {
    cch_actor: ActorRef<CchMessage>,
}

impl CchRpcServerImpl {
    pub(crate) fn new(cch_actor: ActorRef<CchMessage>) -> Self {
        CchRpcServerImpl { cch_actor }
    }
}

const TIMEOUT: u64 = 1000;

#[async_trait]
impl CchRpcServer for CchRpcServerImpl {
    async fn send_btc(&self, params: SendBtcParams) -> Result<SendBTCResponse, ErrorObjectOwned> {
        let result = call_t!(
            self.cch_actor,
            CchMessage::SendBTC,
            TIMEOUT,
            crate::cch::SendBTC {
                btc_pay_req: params.btc_pay_req,
                currency: params.currency,
            }
        )
        .map_err(|ractor_error| {
            ErrorObjectOwned::owned(
                CALL_EXECUTION_FAILED_CODE,
                ractor_error.to_string(),
                Option::<()>::None,
            )
        })?;

        result
            .map(|order| SendBTCResponse {
                timestamp: order.created_at,
                expiry: order.expires_after,
                ckb_final_tlc_expiry_delta: order.ckb_final_tlc_expiry_delta,
                currency: order.currency,
                wrapped_btc_type_script: order.wrapped_btc_type_script,
                btc_pay_req: order.btc_pay_req,
                ckb_pay_req: order.ckb_pay_req,
                payment_hash: order.payment_hash,
                amount_sats: order.amount_sats,
                fee_sats: order.fee_sats,
                status: order.status,
            })
            .map_err(Into::into)
    }

    async fn receive_btc(
        &self,
        params: ReceiveBtcParams,
    ) -> Result<ReceiveBTCResponse, ErrorObjectOwned> {
        let result = call_t!(
            self.cch_actor,
            CchMessage::ReceiveBTC,
            TIMEOUT,
            crate::cch::ReceiveBTC {
                payment_hash: params.payment_hash,
                channel_id: params.channel_id,
                amount_sats: params.amount_sats,
                final_tlc_expiry: params.final_tlc_expiry,
            }
        )
        .map_err(|ractor_error| {
            ErrorObjectOwned::owned(
                CALL_EXECUTION_FAILED_CODE,
                ractor_error.to_string(),
                Option::<()>::None,
            )
        })?;

        result.map(Into::into).map_err(Into::into)
    }

    async fn get_receive_btc_order(
        &self,
        params: GetReceiveBtcOrderParams,
    ) -> Result<ReceiveBTCResponse, ErrorObjectOwned> {
        let result = call_t!(
            self.cch_actor,
            CchMessage::GetReceiveBTCOrder,
            TIMEOUT,
            params.payment_hash
        )
        .map_err(|ractor_error| {
            ErrorObjectOwned::owned(
                CALL_EXECUTION_FAILED_CODE,
                ractor_error.to_string(),
                Option::<()>::None,
            )
        })?;

        result.map(Into::into).map_err(Into::into)
    }
}

impl From<ReceiveBTCOrder> for ReceiveBTCResponse {
    fn from(value: ReceiveBTCOrder) -> Self {
        Self {
            timestamp: value.created_at,
            expiry: value.expires_after,
            ckb_final_tlc_expiry_delta: value.ckb_final_tlc_expiry_delta,
            wrapped_btc_type_script: value.wrapped_btc_type_script,
            btc_pay_req: value.btc_pay_req,
            payment_hash: value.payment_hash,
            channel_id: value.channel_id,
            tlc_id: value.tlc_id,
            amount_sats: value.amount_sats,
            fee_sats: value.fee_sats,
            status: value.status,
        }
    }
}


================================================
File: src/rpc/channel.rs
================================================
use crate::fiber::{
    channel::{
        AwaitingChannelReadyFlags, AwaitingTxSignaturesFlags, ChannelActorStateStore,
        ChannelCommand, ChannelCommandWithId, ChannelState as RawChannelState, CloseFlags,
        CollaboratingFundingTxFlags, NegotiatingFundingFlags, ShutdownCommand, ShuttingDownFlags,
        SigningCommitmentFlags, UpdateCommand,
    },
    network::{AcceptChannelCommand, OpenChannelCommand},
    serde_utils::{EntityHex, U128Hex, U64Hex},
    types::Hash256,
    NetworkActorCommand, NetworkActorMessage,
};
use crate::{handle_actor_call, log_and_error};
use ckb_jsonrpc_types::{EpochNumberWithFraction, Script};
use ckb_types::{
    core::{EpochNumberWithFraction as EpochNumberWithFractionCore, FeeRate},
    packed::OutPoint,
    prelude::{IntoTransactionView, Unpack},
    H256,
};
use jsonrpsee::{
    core::async_trait,
    proc_macros::rpc,
    types::{error::CALL_EXECUTION_FAILED_CODE, ErrorObjectOwned},
};
use ractor::{call, ActorRef};
use serde::{Deserialize, Serialize};
use serde_with::{serde_as, DisplayFromStr};
use std::cmp::Reverse;
use tentacle::secio::PeerId;

#[serde_as]
#[derive(Serialize, Deserialize, Debug)]
pub(crate) struct OpenChannelParams {
    /// The peer ID to open a channel with, the peer must be connected through the [connect_peer](#peer-connect_peer) rpc first.
    #[serde_as(as = "DisplayFromStr")]
    peer_id: PeerId,

    /// The amount of CKB or UDT to fund the channel with.
    #[serde_as(as = "U128Hex")]
    funding_amount: u128,

    /// Whether this is a public channel (will be broadcasted to network, and can be used to forward TLCs), an optional parameter, default value is true.
    public: Option<bool>,

    /// The type script of the UDT to fund the channel with, an optional parameter.
    funding_udt_type_script: Option<Script>,

    /// The script used to receive the channel balance, an optional parameter, default value is the secp256k1_blake160_sighash_all script corresponding to the configured private key.
    shutdown_script: Option<Script>,

    /// The delay time for the commitment transaction, must be an [EpochNumberWithFraction](https://github.com/nervosnetwork/rfcs/blob/master/rfcs/0017-tx-valid-since/e-i-l-encoding.png) in u64 format, an optional parameter, default value is 24 hours.
    commitment_delay_epoch: Option<EpochNumberWithFraction>,

    /// The fee rate for the commitment transaction, an optional parameter.
    #[serde_as(as = "Option<U64Hex>")]
    commitment_fee_rate: Option<u64>,

    /// The fee rate for the funding transaction, an optional parameter.
    #[serde_as(as = "Option<U64Hex>")]
    funding_fee_rate: Option<u64>,

    /// The expiry delta to forward a tlc, in milliseconds, default to 1 day, which is 24 * 60 * 60 * 1000 milliseconds
    /// This parameter can be updated with rpc `update_channel` later.
    #[serde_as(as = "Option<U64Hex>")]
    tlc_expiry_delta: Option<u64>,

    /// The minimum value for a TLC our side can send,
    /// an optional parameter, default is 0, which means we can send any TLC is larger than 0.
    /// This parameter can be updated with rpc `update_channel` later.
    #[serde_as(as = "Option<U128Hex>")]
    tlc_min_value: Option<u128>,

    /// The fee proportional millionths for a TLC, proportional to the amount of the forwarded tlc.
    /// The unit is millionths of the amount. default is 1000 which means 0.1%.
    /// This parameter can be updated with rpc `update_channel` later.
    /// Not that, we use outbound channel to calculate the fee for TLC forwarding. For example,
    /// if we have a path A -> B -> C, then the fee B requires for TLC forwarding, is calculated
    /// the channel configuration of B and C, not A and B.
    #[serde_as(as = "Option<U128Hex>")]
    tlc_fee_proportional_millionths: Option<u128>,

    /// The maximum value in flight for TLCs, an optional parameter.
    /// This parameter can not be updated after channel is opened.
    #[serde_as(as = "Option<U128Hex>")]
    max_tlc_value_in_flight: Option<u128>,

    /// The maximum number of TLCs that can be accepted, an optional parameter, default is 125
    /// This parameter can not be updated after channel is opened.
    #[serde_as(as = "Option<U64Hex>")]
    max_tlc_number_in_flight: Option<u64>,
}
#[derive(Clone, Serialize)]
pub(crate) struct OpenChannelResult {
    /// The temporary channel ID of the channel being opened
    temporary_channel_id: Hash256,
}

#[serde_as]
#[derive(Serialize, Deserialize, Debug)]
pub(crate) struct AcceptChannelParams {
    /// The temporary channel ID of the channel to accept
    temporary_channel_id: Hash256,

    /// The amount of CKB or UDT to fund the channel with
    #[serde_as(as = "U128Hex")]
    funding_amount: u128,

    /// The script used to receive the channel balance, an optional parameter,
    /// default value is the secp256k1_blake160_sighash_all script corresponding to the configured private key
    shutdown_script: Option<Script>,

    /// The max tlc sum value in flight for the channel, default is u128::MAX
    /// This parameter can not be updated after channel is opened.
    #[serde_as(as = "Option<U128Hex>")]
    max_tlc_value_in_flight: Option<u128>,

    /// The max tlc number in flight send from our side, default is 125
    /// This parameter can not be updated after channel is opened.
    #[serde_as(as = "Option<U64Hex>")]
    max_tlc_number_in_flight: Option<u64>,

    /// The minimum value for a TLC our side can send,
    /// an optional parameter, default is 0, which means we can send any TLC is larger than 0.
    /// This parameter can be updated with rpc `update_channel` later.
    #[serde_as(as = "Option<U128Hex>")]
    tlc_min_value: Option<u128>,

    /// The fee proportional millionths for a TLC, proportional to the amount of the forwarded tlc.
    /// The unit is millionths of the amount. default is 1000 which means 0.1%.
    /// This parameter can be updated with rpc `update_channel` later.
    /// Not that, we use outbound channel to calculate the fee for TLC forwarding. For example,
    /// if we have a path A -> B -> C, then the fee B requires for TLC forwarding, is calculated
    /// the channel configuration of B and C, not A and B.
    #[serde_as(as = "Option<U128Hex>")]
    tlc_fee_proportional_millionths: Option<u128>,

    /// The expiry delta to forward a tlc, in milliseconds, default to 1 day, which is 24 * 60 * 60 * 1000 milliseconds
    /// This parameter can be updated with rpc `update_channel` later.
    tlc_expiry_delta: Option<u64>,
}

#[derive(Clone, Serialize)]
pub(crate) struct AcceptChannelResult {
    /// The final ID of the channel that was accepted, it's different from the temporary channel ID
    channel_id: Hash256,
}

#[serde_as]
#[derive(Serialize, Deserialize)]
pub(crate) struct ListChannelsParams {
    /// The peer ID to list channels for, an optional parameter, if not provided, all channels will be listed
    #[serde_as(as = "Option<DisplayFromStr>")]
    peer_id: Option<PeerId>,
    /// Whether to include closed channels in the list, an optional parameter, default value is false
    include_closed: Option<bool>,
}

#[derive(Clone, Serialize)]
pub(crate) struct ListChannelsResult {
    /// The list of channels
    channels: Vec<Channel>,
}

/// The state of a channel
// `ChannelState` is a copy of `ChannelState` with `#[serde(...)]` attributes for compatibility
// `bincode` does not support deserialize_identifier
#[derive(Copy, Clone, Debug, PartialEq, Eq, Serialize, Deserialize)]
#[serde(
    rename_all = "SCREAMING_SNAKE_CASE",
    tag = "state_name",
    content = "state_flags"
)]
pub enum ChannelState {
    /// We are negotiating the parameters required for the channel prior to funding it.
    NegotiatingFunding(NegotiatingFundingFlags),
    /// We're collaborating with the other party on the funding transaction.
    CollaboratingFundingTx(CollaboratingFundingTxFlags),
    /// We have collaborated over the funding and are now waiting for CommitmentSigned messages.
    SigningCommitment(SigningCommitmentFlags),
    /// We've received and sent `commitment_signed` and are now waiting for both
    /// party to collaborate on creating a valid funding transaction.
    AwaitingTxSignatures(AwaitingTxSignaturesFlags),
    /// We've received/sent `funding_created` and `funding_signed` and are thus now waiting on the
    /// funding transaction to confirm.
    AwaitingChannelReady(AwaitingChannelReadyFlags),
    /// Both we and our counterparty consider the funding transaction confirmed and the channel is
    /// now operational.
    ChannelReady(),
    /// We've successfully negotiated a `closing_signed` dance. At this point, the `ChannelManager`
    /// is about to drop us, but we store this anyway.
    ShuttingDown(ShuttingDownFlags),
    /// This channel is closed.
    Closed(CloseFlags),
}

impl From<RawChannelState> for ChannelState {
    fn from(state: RawChannelState) -> Self {
        match state {
            RawChannelState::NegotiatingFunding(flags) => ChannelState::NegotiatingFunding(flags),
            RawChannelState::CollaboratingFundingTx(flags) => {
                ChannelState::CollaboratingFundingTx(flags)
            }
            RawChannelState::SigningCommitment(flags) => ChannelState::SigningCommitment(flags),
            RawChannelState::AwaitingTxSignatures(flags) => {
                ChannelState::AwaitingTxSignatures(flags)
            }
            RawChannelState::AwaitingChannelReady(flags) => {
                ChannelState::AwaitingChannelReady(flags)
            }
            RawChannelState::ChannelReady() => ChannelState::ChannelReady(),
            RawChannelState::ShuttingDown(flags) => ChannelState::ShuttingDown(flags),
            RawChannelState::Closed(flags) => ChannelState::Closed(flags),
        }
    }
}

/// The channel data structure
#[serde_as]
#[derive(Clone, Serialize)]
pub(crate) struct Channel {
    /// The channel ID
    channel_id: Hash256,
    /// Whether the channel is public
    is_public: bool,
    #[serde_as(as = "Option<EntityHex>")]
    /// The outpoint of the channel
    channel_outpoint: Option<OutPoint>,
    /// The peer ID of the channel
    #[serde_as(as = "DisplayFromStr")]
    peer_id: PeerId,
    /// The UDT type script of the channel
    funding_udt_type_script: Option<Script>,
    /// The state of the channel
    state: ChannelState,
    /// The local balance of the channel
    #[serde_as(as = "U128Hex")]
    local_balance: u128,
    /// The offered balance of the channel
    #[serde_as(as = "U128Hex")]
    offered_tlc_balance: u128,
    /// The remote balance of the channel
    #[serde_as(as = "U128Hex")]
    remote_balance: u128,
    /// The received balance of the channel
    #[serde_as(as = "U128Hex")]
    received_tlc_balance: u128,
    /// The hash of the latest commitment transaction
    latest_commitment_transaction_hash: Option<H256>,
    /// The time the channel was created at, in milliseconds from UNIX epoch
    #[serde_as(as = "U64Hex")]
    created_at: u64,
}

#[serde_as]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub(crate) struct ShutdownChannelParams {
    /// The channel ID of the channel to shut down
    channel_id: Hash256,
    /// The script used to receive the channel balance, only support secp256k1_blake160_sighash_all script for now
    close_script: Script,
    /// Whether to force the channel to close
    force: Option<bool>,
    /// The fee rate for the closing transaction, the fee will be deducted from the closing initiator's channel balance
    #[serde_as(as = "U64Hex")]
    fee_rate: u64,
}

#[serde_as]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct UpdateChannelParams {
    /// The channel ID of the channel to update
    channel_id: Hash256,
    /// Whether the channel is enabled
    enabled: Option<bool>,
    /// The CLTV delta from the current height that should be used to set the timelock for the final hop
    #[serde_as(as = "Option<U64Hex>")]
    /// The expiry delta for the TLC locktime
    tlc_expiry_delta: Option<u64>,
    /// The minimum value for a TLC
    #[serde_as(as = "Option<U128Hex>")]
    tlc_minimum_value: Option<u128>,
    /// The fee proportional millionths for a TLC
    #[serde_as(as = "Option<U128Hex>")]
    tlc_fee_proportional_millionths: Option<u128>,
}

/// RPC module for channel management.
#[rpc(server)]
trait ChannelRpc {
    /// Attempts to open a channel with a peer.
    #[method(name = "open_channel")]
    async fn open_channel(
        &self,
        params: OpenChannelParams,
    ) -> Result<OpenChannelResult, ErrorObjectOwned>;

    /// Accepts a channel opening request from a peer.
    #[method(name = "accept_channel")]
    async fn accept_channel(
        &self,
        params: AcceptChannelParams,
    ) -> Result<AcceptChannelResult, ErrorObjectOwned>;

    /// Lists all channels.
    #[method(name = "list_channels")]
    async fn list_channels(
        &self,
        params: ListChannelsParams,
    ) -> Result<ListChannelsResult, ErrorObjectOwned>;

    /// Shuts down a channel.
    #[method(name = "shutdown_channel")]
    async fn shutdown_channel(&self, params: ShutdownChannelParams)
        -> Result<(), ErrorObjectOwned>;

    /// Updates a channel.
    #[method(name = "update_channel")]
    async fn update_channel(&self, params: UpdateChannelParams) -> Result<(), ErrorObjectOwned>;
}

pub(crate) struct ChannelRpcServerImpl<S> {
    actor: ActorRef<NetworkActorMessage>,
    store: S,
}

impl<S> ChannelRpcServerImpl<S> {
    pub(crate) fn new(actor: ActorRef<NetworkActorMessage>, store: S) -> Self {
        ChannelRpcServerImpl { actor, store }
    }
}

#[async_trait]
impl<S> ChannelRpcServer for ChannelRpcServerImpl<S>
where
    S: ChannelActorStateStore + Send + Sync + 'static,
{
    async fn open_channel(
        &self,
        params: OpenChannelParams,
    ) -> Result<OpenChannelResult, ErrorObjectOwned> {
        let message = |rpc_reply| {
            NetworkActorMessage::Command(NetworkActorCommand::OpenChannel(
                OpenChannelCommand {
                    peer_id: params.peer_id.clone(),
                    funding_amount: params.funding_amount,
                    public: params.public.unwrap_or(true),
                    shutdown_script: params.shutdown_script.clone().map(|s| s.into()),
                    commitment_delay_epoch: params
                        .commitment_delay_epoch
                        .map(|e| EpochNumberWithFractionCore::from_full_value(e.value())),
                    funding_udt_type_script: params
                        .funding_udt_type_script
                        .clone()
                        .map(|s| s.into()),
                    commitment_fee_rate: params.commitment_fee_rate,
                    funding_fee_rate: params.funding_fee_rate,
                    tlc_expiry_delta: params.tlc_expiry_delta,
                    tlc_min_value: params.tlc_min_value,
                    tlc_fee_proportional_millionths: params.tlc_fee_proportional_millionths,
                    max_tlc_value_in_flight: params.max_tlc_value_in_flight,
                    max_tlc_number_in_flight: params.max_tlc_number_in_flight,
                },
                rpc_reply,
            ))
        };
        handle_actor_call!(self.actor, message, params).map(|response| OpenChannelResult {
            temporary_channel_id: response.channel_id,
        })
    }

    async fn accept_channel(
        &self,
        params: AcceptChannelParams,
    ) -> Result<AcceptChannelResult, ErrorObjectOwned> {
        let message = |rpc_reply| {
            NetworkActorMessage::Command(NetworkActorCommand::AcceptChannel(
                AcceptChannelCommand {
                    temp_channel_id: params.temporary_channel_id,
                    funding_amount: params.funding_amount,
                    shutdown_script: params.shutdown_script.clone().map(|s| s.into()),
                    max_tlc_number_in_flight: params.max_tlc_number_in_flight,
                    max_tlc_value_in_flight: params.max_tlc_value_in_flight,
                    min_tlc_value: params.tlc_min_value,
                    tlc_fee_proportional_millionths: params.tlc_fee_proportional_millionths,
                    tlc_expiry_delta: params.tlc_expiry_delta,
                },
                rpc_reply,
            ))
        };

        handle_actor_call!(self.actor, message, params).map(|response| AcceptChannelResult {
            channel_id: response.new_channel_id,
        })
    }

    async fn list_channels(
        &self,
        params: ListChannelsParams,
    ) -> Result<ListChannelsResult, ErrorObjectOwned> {
        let channel_states = if params.include_closed.unwrap_or_default() {
            self.store.get_channel_states(params.peer_id)
        } else {
            self.store.get_active_channel_states(params.peer_id)
        };
        let mut channels: Vec<_> = channel_states
            .into_iter()
            .filter_map(|(peer_id, channel_id, _state)| {
                self.store
                    .get_channel_actor_state(&channel_id)
                    .map(|state| Channel {
                        channel_id,
                        is_public: state.is_public(),
                        channel_outpoint: state.get_funding_transaction_outpoint(),
                        peer_id,
                        funding_udt_type_script: state
                            .funding_udt_type_script
                            .clone()
                            .map(Into::into),
                        state: state.state.into(),
                        local_balance: state.get_local_balance(),
                        remote_balance: state.get_remote_balance(),
                        offered_tlc_balance: state.get_offered_tlc_balance(true),
                        received_tlc_balance: state.get_received_tlc_balance(true),
                        latest_commitment_transaction_hash: state
                            .latest_commitment_transaction
                            .as_ref()
                            .map(|tx| tx.clone().into_view().hash().unpack()),
                        created_at: state.get_created_at_in_millis(),
                    })
            })
            .collect();
        // Sort by created_at in descending order
        channels.sort_by_key(|channel| Reverse(channel.created_at));
        Ok(ListChannelsResult { channels })
    }

    async fn shutdown_channel(
        &self,
        params: ShutdownChannelParams,
    ) -> Result<(), ErrorObjectOwned> {
        let message = |rpc_reply| -> NetworkActorMessage {
            NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                ChannelCommandWithId {
                    channel_id: params.channel_id,
                    command: ChannelCommand::Shutdown(
                        ShutdownCommand {
                            close_script: params.close_script.clone().into(),
                            fee_rate: FeeRate::from_u64(params.fee_rate),
                            force: params.force.unwrap_or(false),
                        },
                        rpc_reply,
                    ),
                },
            ))
        };
        handle_actor_call!(self.actor, message, params)
    }

    async fn update_channel(&self, params: UpdateChannelParams) -> Result<(), ErrorObjectOwned> {
        let message = |rpc_reply| -> NetworkActorMessage {
            NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                ChannelCommandWithId {
                    channel_id: params.channel_id,
                    command: ChannelCommand::Update(
                        UpdateCommand {
                            enabled: params.enabled,
                            tlc_expiry_delta: params.tlc_expiry_delta,
                            tlc_minimum_value: params.tlc_minimum_value,
                            tlc_fee_proportional_millionths: params.tlc_fee_proportional_millionths,
                        },
                        rpc_reply,
                    ),
                },
            ))
        };
        handle_actor_call!(self.actor, message, params)
    }
}


================================================
File: src/rpc/config.rs
================================================
use clap_serde_derive::ClapSerde;

const DEFAULT_ENABLED_MODULES: &str = "cch,channel,graph,payment,info,invoice,peer";

#[derive(ClapSerde, Debug, Clone)]
pub struct RpcConfig {
    // Don't use default_value here. Otherwise the default value will override config from file
    /// listening port for rpc service
    #[arg(name = "RPC_LISTENING_ADDR", long = "rpc-listening-addr", env)]
    pub listening_addr: Option<String>,

    #[default(DEFAULT_ENABLED_MODULES.split(',').map(ToString::to_string).collect())]
    #[arg(name = "RPC_ENABLED_MODULES", long = "rpc-enabled-modules", env, value_parser, num_args = 0.., value_delimiter = ',')]
    pub enabled_modules: Vec<String>,
}

impl RpcConfig {
    pub fn is_module_enabled(&self, module: &str) -> bool {
        self.enabled_modules.iter().any(|m| m == module)
    }
}


================================================
File: src/rpc/dev.rs
================================================
use crate::{
    fiber::{
        channel::{AddTlcCommand, ChannelCommand, ChannelCommandWithId, RemoveTlcCommand},
        hash_algorithm::HashAlgorithm,
        serde_utils::{U128Hex, U64Hex},
        types::{Hash256, RemoveTlcFulfill, TlcErr, TlcErrPacket, TlcErrorCode, NO_SHARED_SECRET},
        NetworkActorCommand, NetworkActorMessage,
    },
    handle_actor_cast,
};
use ckb_types::core::TransactionView;
use jsonrpsee::{
    core::async_trait,
    proc_macros::rpc,
    types::{error::CALL_EXECUTION_FAILED_CODE, ErrorObjectOwned},
};
use ractor::call;
use std::str::FromStr;
use std::{collections::HashMap, sync::Arc};

use ractor::{call_t, ActorRef};
use serde::{Deserialize, Serialize};
use serde_with::serde_as;
use tokio::sync::RwLock;

use crate::{
    ckb::CkbChainMessage, fiber::network::DEFAULT_CHAIN_ACTOR_TIMEOUT, handle_actor_call,
    log_and_error,
};

// TODO @quake remove this unnecessary pub(crate) struct and rpc after refactoring
#[derive(Serialize, Deserialize, Debug)]
pub(crate) struct CommitmentSignedParams {
    /// The channel ID of the channel to send the commitment_signed message to
    channel_id: Hash256,
}

#[serde_as]
#[derive(Serialize, Deserialize, Debug)]
pub(crate) struct AddTlcParams {
    /// The channel ID of the channel to add the TLC to
    channel_id: Hash256,
    /// The amount of the TLC
    #[serde_as(as = "U128Hex")]
    amount: u128,
    /// The payment hash of the TLC
    payment_hash: Hash256,
    /// The expiry of the TLC
    #[serde_as(as = "U64Hex")]
    expiry: u64,
    /// The hash algorithm of the TLC
    hash_algorithm: Option<HashAlgorithm>,
}

#[serde_as]
#[derive(Clone, Serialize)]
pub(crate) struct AddTlcResult {
    /// The ID of the TLC
    #[serde_as(as = "U64Hex")]
    tlc_id: u64,
}

#[serde_as]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub(crate) struct RemoveTlcParams {
    /// The channel ID of the channel to remove the TLC from
    channel_id: Hash256,
    #[serde_as(as = "U64Hex")]
    /// The ID of the TLC to remove
    tlc_id: u64,
    /// The reason for removing the TLC, either a 32-byte hash for preimage fulfillment or an u32 error code for removal
    reason: RemoveTlcReason,
}

/// The reason for removing a TLC
#[serde_as]
#[derive(Serialize, Deserialize, Debug, Clone)]
#[serde(untagged)]
enum RemoveTlcReason {
    /// The reason for removing the TLC is that it was fulfilled
    RemoveTlcFulfill { payment_preimage: Hash256 },
    /// The reason for removing the TLC is that it failed
    RemoveTlcFail { error_code: String },
}

#[serde_as]
#[derive(Serialize, Deserialize, Debug, Clone)]
pub(crate) struct SubmitCommitmentTransactionParams {
    /// Channel ID
    channel_id: Hash256,
    /// Commitment number
    #[serde_as(as = "U64Hex")]
    commitment_number: u64,
}

#[serde_as]
#[derive(Serialize, Deserialize, Debug, Clone)]

pub(crate) struct SubmitCommitmentTransactionResult {
    /// Submitted commitment transaction hash
    tx_hash: Hash256,
}

/// RPC module for development purposes, this module is not intended to be used in production.
/// This module will be disabled in release build.
#[rpc(server)]
trait DevRpc {
    /// Sends a commitment_signed message to the peer.
    #[method(name = "commitment_signed")]
    async fn commitment_signed(
        &self,
        params: CommitmentSignedParams,
    ) -> Result<(), ErrorObjectOwned>;

    /// Adds a TLC to a channel.
    #[method(name = "add_tlc")]
    async fn add_tlc(&self, params: AddTlcParams) -> Result<AddTlcResult, ErrorObjectOwned>;

    /// Removes a TLC from a channel.
    #[method(name = "remove_tlc")]
    async fn remove_tlc(&self, params: RemoveTlcParams) -> Result<(), ErrorObjectOwned>;

    /// Submit a commitment transaction to the chain
    #[method(name = "submit_commitment_transaction")]
    async fn submit_commitment_transaction(
        &self,
        params: SubmitCommitmentTransactionParams,
    ) -> Result<SubmitCommitmentTransactionResult, ErrorObjectOwned>;
}

pub(crate) struct DevRpcServerImpl {
    ckb_chain_actor: ActorRef<CkbChainMessage>,
    network_actor: ActorRef<NetworkActorMessage>,
    commitment_txs: Arc<RwLock<HashMap<(Hash256, u64), TransactionView>>>,
}

impl DevRpcServerImpl {
    pub(crate) fn new(
        ckb_chain_actor: ActorRef<CkbChainMessage>,
        network_actor: ActorRef<NetworkActorMessage>,
        commitment_txs: Arc<RwLock<HashMap<(Hash256, u64), TransactionView>>>,
    ) -> Self {
        Self {
            ckb_chain_actor,
            network_actor,
            commitment_txs,
        }
    }
}

#[async_trait]
impl DevRpcServer for DevRpcServerImpl {
    async fn commitment_signed(
        &self,
        params: CommitmentSignedParams,
    ) -> Result<(), ErrorObjectOwned> {
        let message = NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
            ChannelCommandWithId {
                channel_id: params.channel_id,
                command: ChannelCommand::CommitmentSigned(),
            },
        ));
        handle_actor_cast!(self.network_actor, message, params)
    }

    async fn add_tlc(&self, params: AddTlcParams) -> Result<AddTlcResult, ErrorObjectOwned> {
        let message = |rpc_reply| -> NetworkActorMessage {
            NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                ChannelCommandWithId {
                    channel_id: params.channel_id,
                    command: ChannelCommand::AddTlc(
                        AddTlcCommand {
                            amount: params.amount,
                            payment_hash: params.payment_hash,
                            expiry: params.expiry,
                            hash_algorithm: params.hash_algorithm.unwrap_or_default(),
                            onion_packet: None,
                            shared_secret: NO_SHARED_SECRET,
                            previous_tlc: None,
                        },
                        rpc_reply,
                    ),
                },
            ))
        };
        handle_actor_call!(self.network_actor, message, params).map(|response| AddTlcResult {
            tlc_id: response.tlc_id,
        })
    }

    async fn remove_tlc(&self, params: RemoveTlcParams) -> Result<(), ErrorObjectOwned> {
        let err_code = match &params.reason {
            RemoveTlcReason::RemoveTlcFail { error_code } => {
                let Ok(err) = TlcErrorCode::from_str(error_code) else {
                    return log_and_error!(params, format!("invalid error code: {}", error_code));
                };
                Some(err)
            }
            _ => None,
        };
        let message = |rpc_reply| -> NetworkActorMessage {
            NetworkActorMessage::Command(NetworkActorCommand::ControlFiberChannel(
                ChannelCommandWithId {
                    channel_id: params.channel_id,
                    command: ChannelCommand::RemoveTlc(
                        RemoveTlcCommand {
                            id: params.tlc_id,
                            reason: match &params.reason {
                                RemoveTlcReason::RemoveTlcFulfill { payment_preimage } => {
                                    crate::fiber::types::RemoveTlcReason::RemoveTlcFulfill(
                                        RemoveTlcFulfill {
                                            payment_preimage: *payment_preimage,
                                        },
                                    )
                                }
                                RemoveTlcReason::RemoveTlcFail { .. } => {
                                    // TODO: maybe we should remove this PRC or move add_tlc and remove_tlc to `test` module?
                                    crate::fiber::types::RemoveTlcReason::RemoveTlcFail(
                                        TlcErrPacket::new(
                                            TlcErr::new(err_code.expect("expect error code")),
                                            // Do not encrypt the error message when removing the TLC via RPC.
                                            // TODO: use tlc id to look up the shared secret in the store
                                            &NO_SHARED_SECRET,
                                        ),
                                    )
                                }
                            },
                        },
                        rpc_reply,
                    ),
                },
            ))
        };

        handle_actor_call!(self.network_actor, message, params)
    }

    async fn submit_commitment_transaction(
        &self,
        params: SubmitCommitmentTransactionParams,
    ) -> Result<SubmitCommitmentTransactionResult, ErrorObjectOwned> {
        if let Some(tx) = self
            .commitment_txs
            .read()
            .await
            .get(&(params.channel_id, params.commitment_number))
        {
            if let Err(err) = call_t!(
                &self.ckb_chain_actor,
                CkbChainMessage::SendTx,
                DEFAULT_CHAIN_ACTOR_TIMEOUT,
                tx.clone()
            )
            .unwrap()
            {
                Err(ErrorObjectOwned::owned(
                    CALL_EXECUTION_FAILED_CODE,
                    err.to_string(),
                    Some(params),
                ))
            } else {
                Ok(SubmitCommitmentTransactionResult {
                    tx_hash: tx.hash().into(),
                })
            }
        } else {
            Err(ErrorObjectOwned::owned(
                CALL_EXECUTION_FAILED_CODE,
                "Commitment transaction not found".to_string(),
                Some(params),
            ))
        }
    }
}


================================================
File: src/rpc/graph.rs
================================================
use crate::ckb::config::UdtCfgInfos as ConfigUdtCfgInfos;
use crate::fiber::channel::ChannelActorStateStore;
use crate::fiber::gossip::GossipMessageStore;
use crate::fiber::graph::{NetworkGraph, NetworkGraphStateStore};
use crate::fiber::network::get_chain_hash;
use crate::fiber::serde_utils::EntityHex;
use crate::fiber::serde_utils::{U128Hex, U32Hex, U64Hex};
use crate::fiber::types::{Cursor, Hash256, Pubkey};
use ckb_jsonrpc_types::{DepType, JsonBytes, Script, ScriptHashType};
use ckb_types::packed::OutPoint;
use ckb_types::H256;
use jsonrpsee::types::error::INVALID_PARAMS_CODE;
use jsonrpsee::{core::async_trait, proc_macros::rpc, types::ErrorObjectOwned};
use serde::{Deserialize, Serialize};
use serde_with::serde_as;
use std::sync::Arc;
use tentacle::multiaddr::MultiAddr;
use tokio::sync::RwLock;

#[serde_as]
#[derive(Debug, Serialize, Deserialize, Clone)]
pub(crate) struct GraphNodesParams {
    #[serde_as(as = "Option<U64Hex>")]
    /// The maximum number of nodes to return.
    limit: Option<u64>,
    /// The cursor to start returning nodes from.
    after: Option<JsonBytes>,
}

/// The UDT script which is used to identify the UDT configuration for a Fiber Node
#[derive(Serialize, Deserialize, Clone, Debug)]
struct UdtScript {
    /// The code hash of the script.
    code_hash: H256,
    /// The hash type of the script.
    hash_type: ScriptHashType,
    /// The arguments of the script.
    args: String,
}

/// The UDT cell dep which is used to identify the UDT configuration for a Fiber Node
#[serde_as]
#[derive(Serialize, Deserialize, Clone, Debug)]
struct UdtCellDep {
    /// The type of the cell dep.
    dep_type: DepType,
    /// The transaction hash of the cell dep.
    tx_hash: H256,
    /// The index of the cell dep.
    #[serde_as(as = "U32Hex")]
    index: u32,
}

/// The UDT argument info which is used to identify the UDT configuration
#[serde_as]
#[derive(Serialize, Deserialize, Clone, Debug)]
pub(crate) struct UdtArgInfo {
    /// The name of the UDT.
    name: String,
    /// The script of the UDT.
    script: UdtScript,
    #[serde_as(as = "Option<U128Hex>")]
    /// The minimum amount of the UDT that can be automatically accepted.
    auto_accept_amount: Option<u128>,
    /// The cell deps of the UDT.
    cell_deps: Vec<UdtCellDep>,
}

/// A list of UDT configuration infos.
#[derive(Serialize, Deserialize, Clone, Debug)]
pub(crate) struct UdtCfgInfos(
    /// The list of UDT configuration infos.
    Vec<UdtArgInfo>,
);

impl From<ConfigUdtCfgInfos> for UdtCfgInfos {
    fn from(cfg: ConfigUdtCfgInfos) -> Self {
        UdtCfgInfos(
            cfg.0
                .into_iter()
                .map(|info| UdtArgInfo {
                    name: info.name,
                    script: UdtScript {
                        code_hash: info.script.code_hash,
                        hash_type: info.script.hash_type.into(),
                        args: info.script.args,
                    },
                    cell_deps: info
                        .cell_deps
                        .into_iter()
                        .map(|cell_dep| UdtCellDep {
                            dep_type: cell_dep.dep_type.into(),
                            tx_hash: cell_dep.tx_hash,
                            index: cell_dep.index,
                        })
                        .collect(),
                    auto_accept_amount: info.auto_accept_amount,
                })
                .collect::<Vec<UdtArgInfo>>(),
        )
    }
}

/// The Node information.
#[serde_as]
#[derive(Serialize, Deserialize, Clone)]
struct NodeInfo {
    /// The name of the node.
    node_name: String,
    /// The addresses of the node.
    addresses: Vec<MultiAddr>,
    /// The identity public key of the node.
    node_id: Pubkey,
    #[serde_as(as = "U64Hex")]
    /// The timestamp of the node.
    timestamp: u64,
    /// The chain hash of the node.
    chain_hash: Hash256,
    #[serde_as(as = "U64Hex")]
    /// The minimum CKB funding amount for automatically accepting open channel requests.
    auto_accept_min_ckb_funding_amount: u64,
    /// The UDT configuration infos of the node.
    udt_cfg_infos: UdtCfgInfos,
}

impl From<super::super::fiber::graph::NodeInfo> for NodeInfo {
    fn from(value: super::super::fiber::graph::NodeInfo) -> Self {
        NodeInfo {
            node_name: value.node_name.to_string(),
            addresses: value.addresses,
            node_id: value.node_id,
            timestamp: value.timestamp,
            chain_hash: get_chain_hash(),
            auto_accept_min_ckb_funding_amount: value.auto_accept_min_ckb_funding_amount,
            udt_cfg_infos: value.udt_cfg_infos.clone().into(),
        }
    }
}

#[derive(Serialize, Deserialize, Clone)]
pub(crate) struct GraphNodesResult {
    /// The list of nodes.
    nodes: Vec<NodeInfo>,
    /// The last cursor.
    last_cursor: JsonBytes,
}

#[serde_as]
#[derive(Debug, Serialize, Deserialize, Clone)]
pub(crate) struct GraphChannelsParams {
    /// The maximum number of channels to return.
    #[serde_as(as = "Option<U64Hex>")]
    limit: Option<u64>,
    /// The cursor to start returning channels from.
    after: Option<JsonBytes>,
}

/// The Channel information.
#[serde_as]
#[derive(Serialize, Deserialize, Clone)]
struct ChannelInfo {
    /// The outpoint of the channel.
    #[serde_as(as = "EntityHex")]
    channel_outpoint: OutPoint,
    /// The identity public key of the first node.
    node1: Pubkey,
    /// The identity public key of the second node.
    node2: Pubkey,
    /// The created timestamp of the channel, which is the block header timestamp of the block
    /// that contains the channel funding transaction.
    created_timestamp: u64,
    /// The timestamp of the last update to channel by node 1 (e.g. updating fee rate).
    #[serde_as(as = "Option<U64Hex>")]
    last_updated_timestamp_of_node1: Option<u64>,
    /// The timestamp of the last update to channel by node 2 (e.g. updating fee rate).
    #[serde_as(as = "Option<U64Hex>")]
    last_updated_timestamp_of_node2: Option<u64>,
    /// The fee rate set by node 1. This is the fee rate for node 1 to forward tlcs sent from node 2 to node 1.
    #[serde_as(as = "Option<U64Hex>")]
    fee_rate_of_node1: Option<u64>,
    #[serde_as(as = "Option<U64Hex>")]
    /// The fee rate set by node 2. This is the fee rate for node 2 to forward tlcs sent from node 1 to node 2.
    fee_rate_of_node2: Option<u64>,
    /// The capacity of the channel.
    #[serde_as(as = "U128Hex")]
    capacity: u128,
    /// The chain hash of the channel.
    chain_hash: Hash256,
    /// The UDT type script of the channel.
    udt_type_script: Option<Script>,
}

impl From<super::super::fiber::graph::ChannelInfo> for ChannelInfo {
    fn from(channel_info: super::super::fiber::graph::ChannelInfo) -> Self {
        ChannelInfo {
            channel_outpoint: channel_info.out_point().clone(),
            node1: channel_info.node1(),
            node2: channel_info.node2(),
            created_timestamp: channel_info.timestamp,
            last_updated_timestamp_of_node1: channel_info
                .update_of_node1
                .as_ref()
                .map(|cu| cu.timestamp),
            last_updated_timestamp_of_node2: channel_info
                .update_of_node2
                .as_ref()
                .map(|cu| cu.timestamp),
            fee_rate_of_node1: channel_info.update_of_node1.as_ref().map(|cu| cu.fee_rate),
            fee_rate_of_node2: channel_info.update_of_node2.as_ref().map(|cu| cu.fee_rate),
            capacity: channel_info.capacity(),
            chain_hash: get_chain_hash(),
            udt_type_script: channel_info.udt_type_script().clone().map(|s| s.into()),
        }
    }
}

#[derive(Serialize, Deserialize, Clone)]
pub(crate) struct GraphChannelsResult {
    /// A list of channels.
    channels: Vec<ChannelInfo>,
    /// The last cursor for pagination.
    last_cursor: JsonBytes,
}

/// RPC module for graph management.
#[rpc(server)]
trait GraphRpc {
    /// Get the list of nodes in the network graph.
    #[method(name = "graph_nodes")]
    async fn graph_nodes(
        &self,
        params: GraphNodesParams,
    ) -> Result<GraphNodesResult, ErrorObjectOwned>;

    /// Get the list of channels in the network graph.
    #[method(name = "graph_channels")]
    async fn graph_channels(
        &self,
        params: GraphChannelsParams,
    ) -> Result<GraphChannelsResult, ErrorObjectOwned>;
}

pub(crate) struct GraphRpcServerImpl<S>
where
    S: NetworkGraphStateStore + GossipMessageStore,
{
    _store: S,
    network_graph: Arc<RwLock<NetworkGraph<S>>>,
}

impl<S> GraphRpcServerImpl<S>
where
    S: NetworkGraphStateStore + GossipMessageStore,
{
    pub(crate) fn new(network_graph: Arc<RwLock<NetworkGraph<S>>>, store: S) -> Self {
        GraphRpcServerImpl {
            _store: store,
            network_graph,
        }
    }
}

#[async_trait]
impl<S> GraphRpcServer for GraphRpcServerImpl<S>
where
    S: NetworkGraphStateStore
        + ChannelActorStateStore
        + GossipMessageStore
        + Clone
        + Send
        + Sync
        + 'static,
{
    async fn graph_nodes(
        &self,
        params: GraphNodesParams,
    ) -> Result<GraphNodesResult, ErrorObjectOwned> {
        let network_graph = self.network_graph.read().await;
        let default_max_limit = 500;
        let limit = params.limit.unwrap_or(default_max_limit) as usize;
        let cursor = params
            .after
            .as_ref()
            .map(|cursor| Cursor::from_bytes(cursor.as_bytes()))
            .transpose()
            .map_err(|e| {
                ErrorObjectOwned::owned(INVALID_PARAMS_CODE, e.to_string(), Some(params))
            })?;
        let nodes = network_graph.get_nodes_with_params(limit, cursor);
        let last_cursor = nodes
            .last()
            .map(|node| JsonBytes::from_vec(node.cursor().to_bytes().into()))
            .unwrap_or_default();
        let nodes = nodes.into_iter().map(Into::into).collect();

        Ok(GraphNodesResult { nodes, last_cursor })
    }

    async fn graph_channels(
        &self,
        params: GraphChannelsParams,
    ) -> Result<GraphChannelsResult, ErrorObjectOwned> {
        let default_max_limit = 500;
        let network_graph = self.network_graph.read().await;
        let limit = params.limit.unwrap_or(default_max_limit) as usize;
        let cursor = params
            .after
            .as_ref()
            .map(|cursor| Cursor::from_bytes(cursor.as_bytes()))
            .transpose()
            .map_err(|e| {
                ErrorObjectOwned::owned(INVALID_PARAMS_CODE, e.to_string(), Some(params))
            })?;

        let channels = network_graph.get_channels_with_params(limit, cursor);
        let last_cursor = channels
            .last()
            .map(|node| JsonBytes::from_vec(node.cursor().to_bytes().into()))
            .unwrap_or_default();

        let channels = channels.into_iter().map(Into::into).collect();
        Ok(GraphChannelsResult {
            channels,
            last_cursor,
        })
    }
}


================================================
File: src/rpc/info.rs
================================================
use super::graph::UdtCfgInfos;
use crate::ckb::CkbConfig;
use crate::fiber::serde_utils::U32Hex;
use crate::fiber::{
    serde_utils::{U128Hex, U64Hex},
    types::{Hash256, Pubkey},
    NetworkActorCommand, NetworkActorMessage,
};
use crate::{handle_actor_call, log_and_error};
use ckb_jsonrpc_types::Script;
use jsonrpsee::{
    core::async_trait,
    proc_macros::rpc,
    types::{error::CALL_EXECUTION_FAILED_CODE, ErrorObjectOwned},
};
use ractor::{call, ActorRef};
use serde::{Deserialize, Serialize};
use serde_with::serde_as;
use tentacle::multiaddr::MultiAddr;

#[serde_as]
#[derive(Clone, Serialize, Deserialize)]
pub(crate) struct NodeInfoResult {
    /// The version of the node software.
    version: String,

    /// The commit hash of the node software.
    commit_hash: String,

    /// The identity public key of the node.
    node_id: Pubkey,

    /// The optional name of the node.
    node_name: Option<String>,

    /// A list of multi-addresses associated with the node.
    addresses: Vec<MultiAddr>,

    /// The hash of the blockchain that the node is connected to.
    chain_hash: Hash256,

    /// The minimum CKB funding amount for automatically accepting open channel requests, serialized as a hexadecimal string.
    #[serde_as(as = "U64Hex")]
    open_channel_auto_accept_min_ckb_funding_amount: u64,

    /// The CKB funding amount for automatically accepting channel requests, serialized as a hexadecimal string.
    #[serde_as(as = "U64Hex")]
    auto_accept_channel_ckb_funding_amount: u64,

    /// The default funding lock script for the node.
    default_funding_lock_script: Script,

    /// The locktime expiry delta for Time-Locked Contracts (TLC), serialized as a hexadecimal string.
    #[serde_as(as = "U64Hex")]
    tlc_expiry_delta: u64,

    /// The minimum value for Time-Locked Contracts (TLC) we can send, serialized as a hexadecimal string.
    #[serde_as(as = "U128Hex")]
    tlc_min_value: u128,

    /// The maximum value for Time-Locked Contracts (TLC) we can send, serialized as a hexadecimal string, `0` means no maximum value limit.
    #[serde_as(as = "U128Hex")]
    tlc_max_value: u128,

    /// The fee (to forward payments) proportional to the value of Time-Locked Contracts (TLC), expressed in millionths and serialized as a hexadecimal string.
    #[serde_as(as = "U128Hex")]
    tlc_fee_proportional_millionths: u128,

    /// The number of channels associated with the node, serialized as a hexadecimal string.
    #[serde_as(as = "U32Hex")]
    channel_count: u32,

    /// The number of pending channels associated with the node, serialized as a hexadecimal string.
    #[serde_as(as = "U32Hex")]
    pending_channel_count: u32,

    /// The number of peers connected to the node, serialized as a hexadecimal string.
    #[serde_as(as = "U32Hex")]
    peers_count: u32,

    /// Configuration information for User-Defined Tokens (UDT) associated with the node.
    udt_cfg_infos: UdtCfgInfos,
}

pub(crate) struct InfoRpcServerImpl {
    actor: ActorRef<NetworkActorMessage>,
    default_funding_lock_script: Script,
}

impl InfoRpcServerImpl {
    pub(crate) fn new(actor: ActorRef<NetworkActorMessage>, config: CkbConfig) -> Self {
        let default_funding_lock_script = config
            .get_default_funding_lock_script()
            .expect("get default funding lock script should be ok")
            .into();
        InfoRpcServerImpl {
            actor,
            default_funding_lock_script,
        }
    }
}

/// The RPC module for node information.
#[rpc(server)]
trait InfoRpc {
    /// Get the node information.
    #[method(name = "node_info")]
    async fn node_info(&self) -> Result<NodeInfoResult, ErrorObjectOwned>;
}

#[async_trait]
impl InfoRpcServer for InfoRpcServerImpl {
    async fn node_info(&self) -> Result<NodeInfoResult, ErrorObjectOwned> {
        let version = env!("CARGO_PKG_VERSION").to_string();
        let commit_hash = crate::get_git_version().to_string();

        let message =
            |rpc_reply| NetworkActorMessage::Command(NetworkActorCommand::NodeInfo((), rpc_reply));

        handle_actor_call!(self.actor, message, ()).map(|response| NodeInfoResult {
            version,
            commit_hash,
            node_id: response.node_id,
            node_name: response.node_name.map(|name| name.to_string()),
            addresses: response.addresses,
            chain_hash: response.chain_hash,
            open_channel_auto_accept_min_ckb_funding_amount: response
                .open_channel_auto_accept_min_ckb_funding_amount,
            auto_accept_channel_ckb_funding_amount: response.auto_accept_channel_ckb_funding_amount,
            default_funding_lock_script: self.default_funding_lock_script.clone(),
            tlc_expiry_delta: response.tlc_expiry_delta,
            tlc_min_value: response.tlc_min_value,
            tlc_max_value: response.tlc_max_value,
            tlc_fee_proportional_millionths: response.tlc_fee_proportional_millionths,
            channel_count: response.channel_count,
            pending_channel_count: response.pending_channel_count,
            peers_count: response.peers_count,
            udt_cfg_infos: response.udt_cfg_infos.into(),
        })
    }
}


================================================
File: src/rpc/invoice.rs
================================================
use crate::fiber::config::MIN_TLC_EXPIRY_DELTA;
use crate::fiber::hash_algorithm::HashAlgorithm;
use crate::fiber::serde_utils::{U128Hex, U64Hex};
use crate::fiber::types::{Hash256, Privkey};
use crate::invoice::{CkbInvoice, CkbInvoiceStatus, Currency, InvoiceBuilder, InvoiceStore};
use crate::FiberConfig;
use ckb_jsonrpc_types::Script;
use jsonrpsee::types::error::CALL_EXECUTION_FAILED_CODE;
use jsonrpsee::{core::async_trait, proc_macros::rpc, types::ErrorObjectOwned};
use secp256k1::{PublicKey, Secp256k1, SecretKey};
use serde::{Deserialize, Serialize};
use serde_with::serde_as;
use std::time::Duration;
use tentacle::secio::SecioKeyPair;

/// The parameter struct for generating a new invoice.
#[serde_as]
#[derive(Serialize, Deserialize)]
pub(crate) struct NewInvoiceParams {
    /// The amount of the invoice.
    #[serde_as(as = "U128Hex")]
    amount: u128,
    /// The description of the invoice.
    description: Option<String>,
    /// The currency of the invoice.
    currency: Currency,
    /// The payment preimage of the invoice.
    payment_preimage: Hash256,
    /// The expiry time of the invoice.
    #[serde_as(as = "Option<U64Hex>")]
    expiry: Option<u64>,
    /// The fallback address of the invoice.
    fallback_address: Option<String>,
    /// The final HTLC timeout of the invoice.
    #[serde_as(as = "Option<U64Hex>")]
    final_expiry_delta: Option<u64>,
    /// The UDT type script of the invoice.
    udt_type_script: Option<Script>,
    /// The hash algorithm of the invoice.
    hash_algorithm: Option<HashAlgorithm>,
}

#[derive(Clone, Serialize, Deserialize)]
pub(crate) struct InvoiceResult {
    /// The encoded invoice address.
    invoice_address: String,
    /// The invoice.
    invoice: CkbInvoice,
}

#[derive(Serialize, Deserialize)]
pub(crate) struct ParseInvoiceParams {
    /// The encoded invoice address.
    invoice: String,
}

#[derive(Clone, Serialize, Deserialize)]
pub(crate) struct ParseInvoiceResult {
    /// The invoice.
    invoice: CkbInvoice,
}

#[derive(Serialize, Deserialize, Debug)]
pub struct InvoiceParams {
    /// The payment hash of the invoice.
    payment_hash: Hash256,
}

/// The status of the invoice.
#[derive(Clone, Serialize, Deserialize)]
pub(crate) struct GetInvoiceResult {
    /// The encoded invoice address.
    invoice_address: String,
    /// The invoice.
    invoice: CkbInvoice,
    /// The invoice status
    status: CkbInvoiceStatus,
}

/// RPC module for invoice management.
#[rpc(server)]
trait InvoiceRpc {
    /// Generates a new invoice.
    #[method(name = "new_invoice")]
    async fn new_invoice(
        &self,
        params: NewInvoiceParams,
    ) -> Result<InvoiceResult, ErrorObjectOwned>;

    /// Parses a encoded invoice.
    #[method(name = "parse_invoice")]
    async fn parse_invoice(
        &self,
        params: ParseInvoiceParams,
    ) -> Result<ParseInvoiceResult, ErrorObjectOwned>;

    /// Retrieves an invoice.
    #[method(name = "get_invoice")]
    async fn get_invoice(
        &self,
        payment_hash: InvoiceParams,
    ) -> Result<GetInvoiceResult, ErrorObjectOwned>;

    /// Cancels an invoice, only when invoice is in status `Open` can be canceled.
    #[method(name = "cancel_invoice")]
    async fn cancel_invoice(
        &self,
        payment_hash: InvoiceParams,
    ) -> Result<GetInvoiceResult, ErrorObjectOwned>;
}

pub(crate) struct InvoiceRpcServerImpl<S> {
    store: S,
    keypair: Option<(PublicKey, SecretKey)>,
    currency: Option<Currency>,
}

impl<S> InvoiceRpcServerImpl<S> {
    pub(crate) fn new(store: S, config: Option<FiberConfig>) -> Self {
        let config = config.map(|config| {
            let kp = config
                .read_or_generate_secret_key()
                .expect("read or generate secret key");
            let private_key: Privkey = <[u8; 32]>::try_from(kp.as_ref())
                .expect("valid length for key")
                .into();
            let secio_kp = SecioKeyPair::from(kp);
            let keypair = (
                PublicKey::from_slice(secio_kp.public_key().inner_ref()).expect("valid public key"),
                private_key.into(),
            );

            // restrict currency to be the same as network
            let currency = match config.chain.as_str() {
                "mainnet" => Currency::Fibb,
                "testnet" => Currency::Fibt,
                _ => Currency::Fibd,
            };

            (keypair, currency)
        });
        Self {
            store,
            keypair: config.as_ref().map(|(kp, _)| *kp),
            currency: config.as_ref().map(|(_, currency)| *currency),
        }
    }
}

#[async_trait]
impl<S> InvoiceRpcServer for InvoiceRpcServerImpl<S>
where
    S: InvoiceStore + Send + Sync + 'static,
{
    async fn new_invoice(
        &self,
        params: NewInvoiceParams,
    ) -> Result<InvoiceResult, ErrorObjectOwned> {
        if let Some(currency) = self.currency {
            if currency != params.currency {
                return Err(ErrorObjectOwned::owned(
                    CALL_EXECUTION_FAILED_CODE,
                    format!("Currency must be {:?} with the chain network", currency),
                    Some(params),
                ));
            }
        }
        let mut invoice_builder = InvoiceBuilder::new(params.currency)
            .amount(Some(params.amount))
            .payment_preimage(params.payment_preimage);
        if let Some(description) = params.description.clone() {
            invoice_builder = invoice_builder.description(description);
        };
        if let Some(expiry) = params.expiry {
            let duration: Duration = Duration::from_secs(expiry);
            invoice_builder = invoice_builder.expiry_time(duration);
        };
        if let Some(fallback_address) = params.fallback_address.clone() {
            invoice_builder = invoice_builder.fallback_address(fallback_address);
        };
        if let Some(final_expiry_delta) = params.final_expiry_delta {
            if final_expiry_delta < MIN_TLC_EXPIRY_DELTA {
                return Err(ErrorObjectOwned::owned(
                    CALL_EXECUTION_FAILED_CODE,
                    format!(
                        "final_expiry_delta must be greater than or equal to {}",
                        MIN_TLC_EXPIRY_DELTA
                    ),
                    Some(params),
                ));
            }
            invoice_builder = invoice_builder.final_expiry_delta(final_expiry_delta);
        };
        if let Some(udt_type_script) = &params.udt_type_script {
            invoice_builder = invoice_builder.udt_type_script(udt_type_script.clone().into());
        };
        if let Some(hash_algorithm) = params.hash_algorithm {
            invoice_builder = invoice_builder.hash_algorithm(hash_algorithm);
        };

        let invoice = if let Some((public_key, secret_key)) = &self.keypair {
            invoice_builder = invoice_builder.payee_pub_key(*public_key);
            invoice_builder
                .build_with_sign(|hash| Secp256k1::new().sign_ecdsa_recoverable(hash, secret_key))
        } else {
            invoice_builder.build()
        };

        match invoice {
            Ok(invoice) => match self
                .store
                .insert_invoice(invoice.clone(), Some(params.payment_preimage))
            {
                Ok(_) => Ok(InvoiceResult {
                    invoice_address: invoice.to_string(),
                    invoice,
                }),
                Err(e) => {
                    return Err(ErrorObjectOwned::owned(
                        CALL_EXECUTION_FAILED_CODE,
                        e.to_string(),
                        Some(params),
                    ))
                }
            },
            Err(e) => Err(ErrorObjectOwned::owned(
                CALL_EXECUTION_FAILED_CODE,
                e.to_string(),
                Some(params),
            )),
        }
    }

    async fn parse_invoice(
        &self,
        params: ParseInvoiceParams,
    ) -> Result<ParseInvoiceResult, ErrorObjectOwned> {
        let result: Result<CkbInvoice, _> = params.invoice.parse();
        match result {
            Ok(invoice) => Ok(ParseInvoiceResult { invoice }),
            Err(e) => Err(ErrorObjectOwned::owned(
                CALL_EXECUTION_FAILED_CODE,
                e.to_string(),
                Some(params),
            )),
        }
    }

    async fn get_invoice(
        &self,
        params: InvoiceParams,
    ) -> Result<GetInvoiceResult, ErrorObjectOwned> {
        let payment_hash = params.payment_hash;
        match self.store.get_invoice(&payment_hash) {
            Some(invoice) => {
                let status = match self
                    .store
                    .get_invoice_status(&payment_hash)
                    .expect("no invoice status found")
                {
                    CkbInvoiceStatus::Open if invoice.is_expired() => CkbInvoiceStatus::Expired,
                    status => status,
                };

                Ok(GetInvoiceResult {
                    invoice_address: invoice.to_string(),
                    invoice,
                    status,
                })
            }
            None => Err(ErrorObjectOwned::owned(
                CALL_EXECUTION_FAILED_CODE,
                "invoice not found".to_string(),
                Some(payment_hash),
            )),
        }
    }

    async fn cancel_invoice(
        &self,
        params: InvoiceParams,
    ) -> Result<GetInvoiceResult, ErrorObjectOwned> {
        let payment_hash = params.payment_hash;
        match self.store.get_invoice(&payment_hash) {
            Some(invoice) => {
                let status = match self
                    .store
                    .get_invoice_status(&payment_hash)
                    .expect("no invoice status found")
                {
                    CkbInvoiceStatus::Open if invoice.is_expired() => CkbInvoiceStatus::Expired,
                    status => status,
                };

                let new_status = match status {
                    CkbInvoiceStatus::Paid | CkbInvoiceStatus::Cancelled => {
                        return Err(ErrorObjectOwned::owned(
                            CALL_EXECUTION_FAILED_CODE,
                            format!("invoice can not be canceled, current status: {}", status),
                            Some(payment_hash),
                        ));
                    }
                    _ => CkbInvoiceStatus::Cancelled,
                };
                self.store
                    .update_invoice_status(&payment_hash, new_status)
                    .map_err(|e| {
                        ErrorObjectOwned::owned(
                            CALL_EXECUTION_FAILED_CODE,
                            e.to_string(),
                            Some(payment_hash),
                        )
                    })?;
                Ok(GetInvoiceResult {
                    invoice_address: invoice.to_string(),
                    invoice,
                    status: new_status,
                })
            }
            None => Err(ErrorObjectOwned::owned(
                CALL_EXECUTION_FAILED_CODE,
                "invoice not found".to_string(),
                Some(payment_hash),
            )),
        }
    }
}


================================================
File: src/rpc/mod.rs
================================================
mod cch;
mod channel;
mod config;
#[cfg(debug_assertions)]
mod dev;
mod graph;
mod info;
mod invoice;
mod payment;
mod peer;
mod utils;

use crate::ckb::CkbConfig;
use crate::fiber::gossip::GossipMessageStore;
use crate::rpc::info::InfoRpcServer;
use crate::rpc::payment::PaymentRpcServer;
use crate::{
    cch::CchMessage,
    fiber::{
        channel::ChannelActorStateStore,
        graph::{NetworkGraph, NetworkGraphStateStore},
        NetworkActorMessage,
    },
    invoice::InvoiceStore,
    FiberConfig,
};
#[cfg(debug_assertions)]
use crate::{ckb::CkbChainMessage, fiber::types::Hash256};
use cch::{CchRpcServer, CchRpcServerImpl};
use channel::{ChannelRpcServer, ChannelRpcServerImpl};
#[cfg(debug_assertions)]
use ckb_types::core::TransactionView;
pub use config::RpcConfig;
#[cfg(debug_assertions)]
use dev::{DevRpcServer, DevRpcServerImpl};
use graph::{GraphRpcServer, GraphRpcServerImpl};
use info::InfoRpcServerImpl;
use invoice::{InvoiceRpcServer, InvoiceRpcServerImpl};
use jsonrpsee::server::{Server, ServerHandle};
use jsonrpsee::RpcModule;
use payment::PaymentRpcServerImpl;
use peer::{PeerRpcServer, PeerRpcServerImpl};
use ractor::ActorRef;
#[cfg(debug_assertions)]
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;

async fn build_server(addr: &str) -> Server {
    #[cfg(debug_assertions)]
    {
        // Use socket2 to set reuse address and reuse port,
        // so that we can restart the server without waiting for the port to be released.
        // it will avoid the error: "Address already in use" in CI.
        use socket2::{Domain, Socket, Type};
        let addr = addr.parse().expect("valid address");
        let domain = Domain::for_address(addr);
        let socket = Socket::new(domain, Type::STREAM, None).expect("new socket");
        socket
            .set_nonblocking(true)
            .expect("set socket nonblocking");
        socket.set_reuse_address(true).expect("set reuse address");
        #[cfg(all(unix, not(any(target_os = "solaris", target_os = "illumos"))))]
        socket.set_reuse_port(true).expect("set reuse port");

        socket.bind(&addr.into()).expect("bind socket to address");
        socket.listen(4096).expect("listen socket at the port");

        jsonrpsee::server::Server::builder()
            .build_from_tcp(socket)
            .expect("JsonRPC server built from TCP")
    }
    #[cfg(not(debug_assertions))]
    {
        Server::builder()
            .build(addr)
            .await
            .expect("JsonRPC server built")
    }
}

#[allow(clippy::type_complexity)]
#[allow(clippy::too_many_arguments)]
pub async fn start_rpc<
    S: ChannelActorStateStore
        + InvoiceStore
        + NetworkGraphStateStore
        + GossipMessageStore
        + Clone
        + Send
        + Sync
        + 'static,
>(
    config: RpcConfig,
    ckb_config: Option<CkbConfig>,
    fiber_config: Option<FiberConfig>,
    network_actor: Option<ActorRef<NetworkActorMessage>>,
    cch_actor: Option<ActorRef<CchMessage>>,
    store: S,
    network_graph: Arc<RwLock<NetworkGraph<S>>>,
    #[cfg(debug_assertions)] ckb_chain_actor: Option<ActorRef<CkbChainMessage>>,
    #[cfg(debug_assertions)] rpc_dev_module_commitment_txs: Option<
        Arc<RwLock<HashMap<(Hash256, u64), TransactionView>>>,
    >,
) -> ServerHandle {
    let listening_addr = config.listening_addr.as_deref().unwrap_or("[::]:0");
    let server = build_server(listening_addr).await;
    let mut modules = RpcModule::new(());
    if config.is_module_enabled("invoice") {
        modules
            .merge(InvoiceRpcServerImpl::new(store.clone(), fiber_config).into_rpc())
            .unwrap();
    }
    if config.is_module_enabled("graph") {
        modules
            .merge(GraphRpcServerImpl::new(network_graph, store.clone()).into_rpc())
            .unwrap();
    }
    if let Some(network_actor) = network_actor {
        if config.is_module_enabled("info") {
            modules
                .merge(
                    InfoRpcServerImpl::new(
                        network_actor.clone(),
                        ckb_config.expect("ckb config should be set"),
                    )
                    .into_rpc(),
                )
                .unwrap();
        }

        if config.is_module_enabled("peer") {
            modules
                .merge(PeerRpcServerImpl::new(network_actor.clone()).into_rpc())
                .unwrap();
        }

        if config.is_module_enabled("channel") {
            modules
                .merge(ChannelRpcServerImpl::new(network_actor.clone(), store.clone()).into_rpc())
                .unwrap();
        }

        if config.is_module_enabled("payment") {
            modules
                .merge(PaymentRpcServerImpl::new(network_actor.clone(), store.clone()).into_rpc())
                .unwrap();
        }

        #[cfg(debug_assertions)]
        if config.is_module_enabled("dev") {
            modules
                .merge(
                    DevRpcServerImpl::new(
                        ckb_chain_actor.expect("ckb_chain_actor should be set"),
                        network_actor.clone(),
                        rpc_dev_module_commitment_txs
                            .expect("rpc_dev_module_commitment_txs should be set"),
                    )
                    .into_rpc(),
                )
                .unwrap();
        }
    }
    if let Some(cch_actor) = cch_actor {
        if config.is_module_enabled("cch") {
            modules
                .merge(CchRpcServerImpl::new(cch_actor).into_rpc())
                .unwrap();
        }
    }
    server.start(modules)
}


================================================
File: src/rpc/payment.rs
================================================
#[cfg(debug_assertions)]
use crate::fiber::graph::SessionRoute;
use crate::fiber::{
    channel::ChannelActorStateStore,
    graph::PaymentSessionStatus,
    network::{HopHint as NetworkHopHint, SendPaymentCommand},
    serde_utils::{U128Hex, U64Hex},
    types::{Hash256, Pubkey},
    NetworkActorCommand, NetworkActorMessage,
};
use crate::{handle_actor_call, log_and_error};
use ckb_jsonrpc_types::Script;
use jsonrpsee::{
    core::async_trait,
    proc_macros::rpc,
    types::{error::CALL_EXECUTION_FAILED_CODE, ErrorObjectOwned},
};
use ractor::{call, ActorRef};
use serde::{Deserialize, Serialize};
use serde_with::serde_as;

#[serde_as]
#[derive(Serialize, Deserialize, Debug)]
pub struct GetPaymentCommandParams {
    /// The payment hash of the payment to retrieve
    pub payment_hash: Hash256,
}

#[serde_as]
#[derive(Serialize, Deserialize, Clone)]
pub struct GetPaymentCommandResult {
    /// The payment hash of the payment
    pub payment_hash: Hash256,
    /// The status of the payment
    pub status: PaymentSessionStatus,
    #[serde_as(as = "U64Hex")]
    /// The time the payment was created at, in milliseconds from UNIX epoch
    created_at: u64,
    #[serde_as(as = "U64Hex")]
    /// The time the payment was last updated at, in milliseconds from UNIX epoch
    pub last_updated_at: u64,
    /// The error message if the payment failed
    pub failed_error: Option<String>,
    /// fee paid for the payment
    #[serde_as(as = "U128Hex")]
    pub fee: u128,

    #[cfg(debug_assertions)]
    /// The route information for the payment
    router: SessionRoute,
}

#[serde_as]
#[derive(Clone, Debug, Serialize, Deserialize)]
pub(crate) struct SendPaymentCommandParams {
    /// the identifier of the payment target
    target_pubkey: Option<Pubkey>,

    /// the amount of the payment
    #[serde_as(as = "Option<U128Hex>")]
    amount: Option<u128>,

    /// the hash to use within the payment's HTLC
    payment_hash: Option<Hash256>,

    /// the TLC expiry delta should be used to set the timelock for the final hop, in milliseconds
    #[serde_as(as = "Option<U64Hex>")]
    final_tlc_expiry_delta: Option<u64>,

    /// the TLC expiry limit for the whole payment, in milliseconds, each hop is with a default tlc delta of 1 day
    /// suppose the payment router is with N hops, the total tlc expiry limit is at least (N-1) days
    /// this is also the default value for the payment if this parameter is not provided
    #[serde_as(as = "Option<U64Hex>")]
    tlc_expiry_limit: Option<u64>,

    /// the encoded invoice to send to the recipient
    invoice: Option<String>,

    /// the payment timeout in seconds, if the payment is not completed within this time, it will be cancelled
    #[serde_as(as = "Option<U64Hex>")]
    timeout: Option<u64>,

    /// the maximum fee amounts in shannons that the sender is willing to pay
    #[serde_as(as = "Option<U128Hex>")]
    max_fee_amount: Option<u128>,

    /// max parts for the payment, only used for multi-part payments
    #[serde_as(as = "Option<U64Hex>")]
    max_parts: Option<u64>,

    /// keysend payment
    keysend: Option<bool>,

    /// udt type script for the payment
    udt_type_script: Option<Script>,

    /// allow self payment, default is false
    allow_self_payment: Option<bool>,

    /// Optional route hints to reach the destination through private channels.
    /// A hop hint is a hint for a node to use a specific channel, for example
    /// (pubkey, funding_txid, inbound) where pubkey is the public key of the node,
    /// funding_txid is the funding transaction hash of the channel outpoint, and
    /// inbound is a boolean indicating whether to use the channel to send or receive.
    /// Note: an inproper hint may cause the payment to fail, and hop_hints maybe helpful for self payment scenario
    /// for helping the routing algorithm to find the correct path
    hop_hints: Option<Vec<HopHint>>,

    /// dry_run for payment, used for check whether we can build valid router and the fee for this payment,
    /// it's useful for the sender to double check the payment before sending it to the network,
    /// default is false
    dry_run: Option<bool>,
}

/// A hop hint is a hint for a node to use a specific channel.
#[serde_as]
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct HopHint {
    /// The public key of the node
    pub pubkey: Pubkey,
    /// The funding transaction hash of the channel outpoint
    pub channel_funding_tx: Hash256,
    /// inbound or outbound to use this channel
    pub inbound: bool,
}

impl From<HopHint> for NetworkHopHint {
    fn from(hop_hint: HopHint) -> Self {
        NetworkHopHint {
            pubkey: hop_hint.pubkey,
            channel_funding_tx: hop_hint.channel_funding_tx,
            inbound: hop_hint.inbound,
        }
    }
}

/// RPC module for channel management.
#[rpc(server)]
trait PaymentRpc {
    /// Sends a payment to a peer.
    #[method(name = "send_payment")]
    async fn send_payment(
        &self,
        params: SendPaymentCommandParams,
    ) -> Result<GetPaymentCommandResult, ErrorObjectOwned>;

    /// Retrieves a payment.
    #[method(name = "get_payment")]
    async fn get_payment(
        &self,
        params: GetPaymentCommandParams,
    ) -> Result<GetPaymentCommandResult, ErrorObjectOwned>;
}

pub(crate) struct PaymentRpcServerImpl<S> {
    actor: ActorRef<NetworkActorMessage>,
    _store: S,
}

impl<S> PaymentRpcServerImpl<S> {
    pub(crate) fn new(actor: ActorRef<NetworkActorMessage>, _store: S) -> Self {
        PaymentRpcServerImpl { actor, _store }
    }
}

#[async_trait]
impl<S> PaymentRpcServer for PaymentRpcServerImpl<S>
where
    S: ChannelActorStateStore + Send + Sync + 'static,
{
    async fn send_payment(
        &self,
        params: SendPaymentCommandParams,
    ) -> Result<GetPaymentCommandResult, ErrorObjectOwned> {
        let message = |rpc_reply| -> NetworkActorMessage {
            NetworkActorMessage::Command(NetworkActorCommand::SendPayment(
                SendPaymentCommand {
                    target_pubkey: params.target_pubkey,
                    amount: params.amount,
                    payment_hash: params.payment_hash,
                    final_tlc_expiry_delta: params.final_tlc_expiry_delta,
                    tlc_expiry_limit: params.tlc_expiry_limit,
                    invoice: params.invoice.clone(),
                    timeout: params.timeout,
                    max_fee_amount: params.max_fee_amount,
                    max_parts: params.max_parts,
                    keysend: params.keysend,
                    udt_type_script: params.udt_type_script.clone().map(|s| s.into()),
                    allow_self_payment: params.allow_self_payment.unwrap_or(false),
                    hop_hints: params
                        .hop_hints
                        .clone()
                        .map(|hints| hints.into_iter().map(|hint| hint.into()).collect()),
                    dry_run: params.dry_run.unwrap_or(false),
                },
                rpc_reply,
            ))
        };
        handle_actor_call!(self.actor, message, params).map(|response| GetPaymentCommandResult {
            payment_hash: response.payment_hash,
            status: response.status,
            created_at: response.created_at,
            last_updated_at: response.last_updated_at,
            failed_error: response.failed_error,
            fee: response.fee,
            #[cfg(debug_assertions)]
            router: response.router,
        })
    }

    async fn get_payment(
        &self,
        params: GetPaymentCommandParams,
    ) -> Result<GetPaymentCommandResult, ErrorObjectOwned> {
        let message = |rpc_reply| -> NetworkActorMessage {
            NetworkActorMessage::Command(NetworkActorCommand::GetPayment(
                params.payment_hash,
                rpc_reply,
            ))
        };
        handle_actor_call!(self.actor, message, params).map(|response| GetPaymentCommandResult {
            payment_hash: response.payment_hash,
            status: response.status,
            last_updated_at: response.last_updated_at,
            created_at: response.created_at,
            failed_error: response.failed_error,
            fee: response.fee,
            #[cfg(debug_assertions)]
            router: response.router,
        })
    }
}


================================================
File: src/rpc/peer.rs
================================================
use crate::fiber::{NetworkActorCommand, NetworkActorMessage};
use crate::log_and_error;
use jsonrpsee::{
    core::async_trait, proc_macros::rpc, types::error::CALL_EXECUTION_FAILED_CODE,
    types::ErrorObjectOwned,
};
use ractor::ActorRef;
use serde::{Deserialize, Serialize};
use serde_with::{serde_as, DisplayFromStr};
use tentacle::{multiaddr::MultiAddr, secio::PeerId};

#[derive(Serialize, Deserialize, Debug, Clone)]
pub(crate) struct ConnectPeerParams {
    /// The address of the peer to connect to.
    address: MultiAddr,
    /// Whether to save the peer address to the peer store.
    save: Option<bool>,
}

#[serde_as]
#[derive(Serialize, Deserialize, Debug)]
pub(crate) struct DisconnectPeerParams {
    /// The peer ID of the peer to disconnect.
    #[serde_as(as = "DisplayFromStr")]
    peer_id: PeerId,
}

/// RPC module for peer management.
#[rpc(server)]
trait PeerRpc {
    /// Connect to a peer.
    #[method(name = "connect_peer")]
    async fn connect_peer(&self, params: ConnectPeerParams) -> Result<(), ErrorObjectOwned>;

    /// Disconnect from a peer.
    #[method(name = "disconnect_peer")]
    async fn disconnect_peer(&self, params: DisconnectPeerParams) -> Result<(), ErrorObjectOwned>;
}

pub(crate) struct PeerRpcServerImpl {
    actor: ActorRef<NetworkActorMessage>,
}

impl PeerRpcServerImpl {
    pub(crate) fn new(actor: ActorRef<NetworkActorMessage>) -> Self {
        PeerRpcServerImpl { actor }
    }
}

#[async_trait]
impl PeerRpcServer for PeerRpcServerImpl {
    async fn connect_peer(&self, params: ConnectPeerParams) -> Result<(), ErrorObjectOwned> {
        let message =
            NetworkActorMessage::Command(NetworkActorCommand::ConnectPeer(params.address.clone()));
        if params.save.unwrap_or(true) {
            crate::handle_actor_cast!(
                self.actor,
                NetworkActorMessage::Command(NetworkActorCommand::SavePeerAddress(
                    params.address.clone()
                )),
                params.clone()
            )?;
        }
        crate::handle_actor_cast!(self.actor, message, params)
    }

    async fn disconnect_peer(&self, params: DisconnectPeerParams) -> Result<(), ErrorObjectOwned> {
        let message = NetworkActorMessage::Command(NetworkActorCommand::DisconnectPeer(
            params.peer_id.clone(),
        ));
        crate::handle_actor_cast!(self.actor, message, params)
    }
}


================================================
File: src/rpc/utils.rs
================================================
#[macro_export]
macro_rules! log_and_error {
    ($params:expr, $err:expr) => {{
        tracing::error!("channel request params {:?} => error: {:?}", $params, $err);
        Err(ErrorObjectOwned::owned(
            CALL_EXECUTION_FAILED_CODE,
            $err,
            Some($params),
        ))
    }};
}

#[macro_export]
macro_rules! handle_actor_call {
    ($actor:expr, $message:expr, $params:expr) => {
        match call!($actor, $message) {
            Ok(result) => match result {
                Ok(res) => Ok(res),
                Err(e) => log_and_error!($params, e.to_string()),
            },
            Err(e) => log_and_error!($params, e.to_string()),
        }
    };
    ($actor:expr, $message:expr) => {
        match call!($actor, $message) {
            Ok(result) => match result {
                Ok(res) => Ok(res),
                Err(e) => {
                    error!("Error: {:?}", e);
                    Err(e)
                }
            },
            Err(e) => {
                error!("Error: {:?}", e);
                Err(e)
            }
        }
    };
}

#[macro_export]
macro_rules! handle_actor_cast {
    ($actor:expr, $message:expr, $params:expr) => {
        match $actor.cast($message) {
            Ok(_) => Ok(()),
            Err(err) => log_and_error!($params, format!("{}", err)),
        }
    };
}


================================================
File: src/store/db_migrate.rs
================================================
use super::migration::{DefaultMigration, Migration, Migrations};
use crate::Error;
use rocksdb::DB;
use std::{cmp::Ordering, path::Path, sync::Arc};
use tracing::warn;
use tracing::{error, info};

/// migrate helper
pub struct DbMigrate {
    migrations: Migrations,
    db: Arc<DB>,
}

impl DbMigrate {
    /// Construct new migrate
    pub fn new(db: Arc<DB>) -> Self {
        let mut migrations = Migrations::default();
        migrations.add_migration(Arc::new(DefaultMigration::new()));
        DbMigrate { migrations, db }
    }

    pub fn add_migration(&mut self, migration: Arc<dyn Migration>) {
        self.migrations.add_migration(migration);
    }

    /// Check if database's version is matched with the executable binary version.
    ///
    /// Returns
    /// - Less: The database version is less than the matched version of the executable binary.
    ///   Requires migration.
    /// - Equal: The database version is matched with the executable binary version.
    /// - Greater: The database version is greater than the matched version of the executable binary.
    ///   Requires upgrade the executable binary.
    pub fn check(&self) -> Ordering {
        self.migrations.check(self.db.clone())
    }

    /// Perform migrate.
    pub fn migrate(&self) -> Result<Arc<DB>, Error> {
        self.migrations.migrate(self.db.clone())
    }

    /// Perform init_db_version.
    pub fn init_db_version(&self) -> Result<(), Error> {
        self.migrations.init_db_version(self.db.clone())
    }

    pub fn db(&self) -> Arc<DB> {
        self.db.clone()
    }

    pub fn need_init(&self) -> bool {
        self.migrations.need_init(&self.db)
    }

    pub fn init_or_check<P: AsRef<Path>>(&self, path: P) -> Result<Arc<DB>, String> {
        if self.need_init() {
            info!("begin to init db version ...");
            self.init_db_version().expect("failed to init db version");
            Ok(self.db())
        } else {
            match self.check() {
                Ordering::Greater => {
                    error!(
                        "The database was created by a higher version fiber executable binary \n\
                     and cannot be opened by the current binary.\n\
                     Please download the latest fiber executable binary."
                    );
                    return Err("incompatible database, need to upgrade fiber binary".to_string());
                }
                Ordering::Equal => {
                    warn!("no need to migrate, everything is OK ...");
                    return Ok(self.db());
                }
                Ordering::Less => {
                    return Err(format!("Fiber need to run some database migrations, please run `fnn-migrate -p {}` to start migrations.", path.as_ref().display()));
                }
            }
        }
    }
}


================================================
File: src/store/migration.rs
================================================
use crate::Error;
use console::Term;
use indicatif::MultiProgress;
use indicatif::ProgressBar;
use indicatif::ProgressDrawTarget;
use rocksdb::ops::Get;
use rocksdb::ops::Put;
use rocksdb::DB;
use std::cmp::Ordering;
use std::collections::BTreeMap;
use std::sync::Arc;
use tracing::{debug, error, info};

pub const MIGRATION_VERSION_KEY: &[u8] = b"db-version";
pub const INIT_DB_VERSION: &str = "20241116135521";
include!(concat!(env!("OUT_DIR"), "/latest_db_version.rs"));

fn internal_error(reason: String) -> Error {
    Error::DBInternalError(reason)
}

#[derive(Default)]
pub struct Migrations {
    migrations: BTreeMap<String, Arc<dyn Migration>>,
}

impl Migrations {
    pub fn add_migration(&mut self, migration: Arc<dyn Migration>) {
        self.migrations
            .insert(migration.version().to_string(), migration);
    }

    /// Check if database's version is matched with the executable binary version.
    ///
    /// Returns
    /// - Less: The database version is less than the matched version of the executable binary.
    ///   Requires migration.
    /// - Equal: The database version is matched with the executable binary version.
    /// - Greater: The database version is greater than the matched version of the executable binary.
    ///   Requires upgrade the executable binary.
    pub fn check(&self, db: Arc<DB>) -> Ordering {
        let db_version = match db
            .get(MIGRATION_VERSION_KEY)
            .expect("get the version of database")
        {
            Some(version_bytes) => {
                String::from_utf8(version_bytes.to_vec()).expect("version bytes to utf8")
            }
            None => {
                return Ordering::Less;
            }
        };

        debug!(
            "Current database version: [{}], latest db version: [{}]",
            db_version, LATEST_DB_VERSION
        );
        db_version.as_str().cmp(LATEST_DB_VERSION)
    }

    // will only invoked in fnn-migrate binary
    fn run_migrate(&self, mut db: Arc<DB>, v: &str) -> Result<Arc<DB>, Error> {
        let mpb = Arc::new(MultiProgress::new());

        // make sure the latest migration is the last one
        // this may only happend the fnn-migrate binary is not compiled with
        // the correct fiber code base
        {
            let migrations = self.migrations.values();
            let latest_version_from_migratons = migrations
                .last()
                .unwrap_or_else(|| panic!("should have at least one version"))
                .version();
            if latest_version_from_migratons != LATEST_DB_VERSION {
                error!(
                    "The latest migration version is not equal to the latest db version, \
                please check the migration version: {}",
                    latest_version_from_migratons
                );
                return Err(internal_error(
                    "The latest migration version is not equal to the latest db version"
                        .to_string(),
                ));
            }
        }

        let migrations: BTreeMap<_, _> = self
            .migrations
            .iter()
            .filter(|(mv, _)| mv.as_str() > v)
            .collect();
        let migrations_count = migrations.len();

        for (idx, (_, m)) in migrations.iter().enumerate() {
            let mpbc = Arc::clone(&mpb);
            let pb = move |count: u64| -> ProgressBar {
                let pb = mpbc.add(ProgressBar::new(count));
                pb.set_draw_target(ProgressDrawTarget::term(Term::stdout(), None));
                pb.set_prefix(format!("[{}/{}]", idx + 1, migrations_count));
                pb
            };
            db = m.migrate(db, Arc::new(pb))?;
            db.put(MIGRATION_VERSION_KEY, m.version())
                .map_err(|err| internal_error(format!("failed to migrate the database: {err}")))?;
        }
        mpb.join_and_clear().expect("MultiProgress join");
        Ok(db)
    }

    fn get_migration_version(&self, db: &Arc<DB>) -> Result<Option<String>, Error> {
        let raw = db.get(MIGRATION_VERSION_KEY).map_err(|err| {
            internal_error(format!("failed to get the version of database: {err}"))
        })?;

        Ok(raw.map(|version_bytes| {
            String::from_utf8(version_bytes.to_vec()).expect("version bytes to utf8")
        }))
    }

    /// Initial db version
    pub fn init_db_version(&self, db: Arc<DB>) -> Result<(), Error> {
        if self.need_init(&db) {
            eprintln!("Init database version {}", LATEST_DB_VERSION);
            db.put(MIGRATION_VERSION_KEY, LATEST_DB_VERSION)
                .map_err(|err| internal_error(format!("failed to migrate the database: {err}")))?;
        }
        Ok(())
    }

    pub fn need_init(&self, db: &Arc<DB>) -> bool {
        self.get_migration_version(db)
            .expect("get migration failed")
            .is_none()
    }

    pub fn migrate(&self, db: Arc<DB>) -> Result<Arc<DB>, Error> {
        let db_version = self.get_migration_version(&db)?;
        match db_version {
            Some(ref v) => {
                info!("Current database version {}", v);
                self.check_migration_downgrade(v)?;
                let db = self.run_migrate(db, v.as_str())?;
                Ok(db)
            }
            None => Ok(db),
        }
    }

    fn check_migration_downgrade(&self, cur_version: &str) -> Result<(), Error> {
        if let Some(m) = self.migrations.values().last() {
            if m.version() < cur_version {
                error!(
                    "Database downgrade detected. \
                    The database schema version is newer than `fiber` schema version,\
                    please upgrade `fiber` to the latest version"
                );
                return Err(internal_error(
                    "Database downgrade is not supported".to_string(),
                ));
            }
        }
        Ok(())
    }
}

pub trait Migration: Send + Sync {
    fn migrate(
        &self,
        _db: Arc<DB>,
        _pb: Arc<dyn Fn(u64) -> ProgressBar + Send + Sync>,
    ) -> Result<Arc<DB>, Error>;

    /// returns migration version, use `date +'%Y%m%d%H%M%S'` timestamp format
    fn version(&self) -> &str;
}

pub struct DefaultMigration {
    version: String,
}

impl Default for DefaultMigration {
    fn default() -> Self {
        Self::new()
    }
}

impl DefaultMigration {
    pub fn new() -> Self {
        Self {
            version: INIT_DB_VERSION.to_string(),
        }
    }
}

impl Migration for DefaultMigration {
    fn migrate(
        &self,
        db: Arc<DB>,
        _pb: Arc<dyn Fn(u64) -> ProgressBar + Send + Sync>,
    ) -> Result<Arc<DB>, Error> {
        Ok(db)
    }

    fn version(&self) -> &str {
        &self.version
    }
}


================================================
File: src/store/mod.rs
================================================
pub mod db_migrate;
pub mod migration;
mod schema;
pub mod store;
pub use store::Store;
#[cfg(test)]
mod tests;


================================================
File: src/store/schema.rs
================================================
///
/// +--------------+----------------------+-----------------------------+
/// | KeyPrefix::  | Key::                | Value::                     |
/// +--------------+----------------------+-----------------------------+
/// | 0            | Hash256              | ChannelActorState           |
/// | 16           | PeerId               | PersistentNetworkActorState |
/// | 32           | Hash256              | CkbInvoice                  |
/// | 33           | Payment_hash         | CkbInvoice Preimage         |
/// | 34           | Payment_hash         | CkbInvoice Status           |
/// | 64           | PeerId | Hash256     | ChannelState                |
/// | 65...........| OutPoint             | ChannelId                   |
/// | 96           | Cursor               | BroadcastMessage            |
/// | 97           | BroadcastMessageID   | u64                         |
/// | 192          | Hash256              | PaymentSession              |
/// | 193          | OutPoint | Direction | TimedResult                 |
/// | 224          | Hash256              | ChannelData                 |
/// +--------------+----------------------+-----------------------------+
///

pub(crate) const CHANNEL_ACTOR_STATE_PREFIX: u8 = 0;
pub(crate) const PEER_ID_NETWORK_ACTOR_STATE_PREFIX: u8 = 16;
pub(crate) const CKB_INVOICE_PREFIX: u8 = 32;
pub(crate) const CKB_INVOICE_PREIMAGE_PREFIX: u8 = 33;
pub(crate) const CKB_INVOICE_STATUS_PREFIX: u8 = 34;
pub(crate) const PEER_ID_CHANNEL_ID_PREFIX: u8 = 64;
pub(crate) const CHANNEL_OUTPOINT_CHANNEL_ID_PREFIX: u8 = 65;
pub(crate) const BROADCAST_MESSAGE_PREFIX: u8 = 96;
pub(crate) const BROADCAST_MESSAGE_TIMESTAMP_PREFIX: u8 = 97;
pub(crate) const PAYMENT_SESSION_PREFIX: u8 = 192;
pub(crate) const PAYMENT_HISTORY_TIMED_RESULT_PREFIX: u8 = 193;
pub(crate) const WATCHTOWER_CHANNEL_PREFIX: u8 = 224;


================================================
File: src/store/store.rs
================================================
use super::db_migrate::DbMigrate;
use super::schema::*;
use crate::{
    fiber::{
        channel::{
            ChannelActorState, ChannelActorStateStore, ChannelState, RevocationData, SettlementData,
        },
        gossip::GossipMessageStore,
        graph::{NetworkGraphStateStore, PaymentSession},
        history::{Direction, TimedResult},
        network::{NetworkActorStateStore, PersistentNetworkActorState},
        types::{BroadcastMessage, BroadcastMessageID, Cursor, Hash256, CURSOR_SIZE},
    },
    invoice::{CkbInvoice, CkbInvoiceStatus, InvoiceError, InvoiceStore},
    watchtower::{ChannelData, WatchtowerStore},
};
use ckb_types::packed::{OutPoint, Script};
use ckb_types::prelude::Entity;
use rocksdb::{
    prelude::*, DBCompressionType, DBIterator, Direction as DbDirection, IteratorMode, WriteBatch,
    DB,
};
use serde::Serialize;
use std::{path::Path, sync::Arc};
use tentacle::secio::PeerId;

#[derive(Clone, Debug)]
pub struct Store {
    pub(crate) db: Arc<DB>,
}

#[derive(Copy, Clone)]
enum ChannelTimestamp {
    ChannelAnnouncement(),
    ChannelUpdateOfNode1(),
    ChannelUpdateOfNode2(),
}

fn update_channel_timestamp(
    batch: &mut Batch,
    outpoint: &OutPoint,
    timestamp: u64,
    channel_timestamp: ChannelTimestamp,
) {
    let offset = match channel_timestamp {
        ChannelTimestamp::ChannelAnnouncement() => 0,
        ChannelTimestamp::ChannelUpdateOfNode1() => 8,
        ChannelTimestamp::ChannelUpdateOfNode2() => 16,
    };
    let message_id = match channel_timestamp {
        ChannelTimestamp::ChannelAnnouncement() => {
            BroadcastMessageID::ChannelAnnouncement(outpoint.clone())
        }
        ChannelTimestamp::ChannelUpdateOfNode1() => {
            BroadcastMessageID::ChannelUpdate(outpoint.clone())
        }
        ChannelTimestamp::ChannelUpdateOfNode2() => {
            BroadcastMessageID::ChannelUpdate(outpoint.clone())
        }
    };

    let timestamp_key = [
        &[BROADCAST_MESSAGE_TIMESTAMP_PREFIX],
        message_id.to_bytes().as_slice(),
    ]
    .concat();
    let mut timestamps = batch
        .get(&timestamp_key)
        .map(|v| v.try_into().expect("Invalid timestamp value length"))
        .unwrap_or([0u8; 24]);
    timestamps[offset..offset + 8].copy_from_slice(&timestamp.to_be_bytes());
    batch.put(timestamp_key, timestamps);
}

impl Store {
    pub fn new<P: AsRef<Path>>(path: P) -> Result<Self, String> {
        let db = Self::open_db(path.as_ref())?;
        let db = Self::check_migrate(path, db)?;
        Ok(Self { db })
    }

    fn open_db(path: &Path) -> Result<Arc<DB>, String> {
        // add more migrations here
        let mut options = Options::default();
        options.create_if_missing(true);
        options.set_compression_type(DBCompressionType::Lz4);
        let db = Arc::new(DB::open(&options, path).map_err(|e| e.to_string())?);
        Ok(db)
    }

    fn get<K: AsRef<[u8]>>(&self, key: K) -> Option<Vec<u8>> {
        self.db
            .get(key.as_ref())
            .map(|v| v.map(|vi| vi.to_vec()))
            .expect("get should be OK")
    }

    #[allow(dead_code)]
    fn get_range<K: AsRef<[u8]>>(
        &self,
        lower_bound: Option<K>,
        upper_bound: Option<K>,
    ) -> DBIterator {
        assert!(lower_bound.is_some() || upper_bound.is_some());
        let mut read_options = ReadOptions::default();
        if let Some(lower_bound) = lower_bound {
            read_options.set_iterate_lower_bound(lower_bound.as_ref());
        }
        if let Some(upper_bound) = upper_bound {
            read_options.set_iterate_upper_bound(upper_bound.as_ref());
        }
        let mode = IteratorMode::Start;
        self.db.get_iter(&read_options, mode)
    }

    fn batch(&self) -> Batch {
        Batch {
            db: Arc::clone(&self.db),
            wb: WriteBatch::default(),
        }
    }

    fn prefix_iterator<'a>(
        &'a self,
        prefix: &'a [u8],
    ) -> impl Iterator<Item = (Box<[u8]>, Box<[u8]>)> + 'a {
        self.db
            .prefix_iterator(prefix)
            .take_while(move |(col_key, _)| col_key.starts_with(prefix))
    }

    /// Open or create a rocksdb
    fn check_migrate<P: AsRef<Path>>(path: P, db: Arc<DB>) -> Result<Arc<DB>, String> {
        let migrate = DbMigrate::new(db);
        migrate.init_or_check(path)
    }
}

pub struct Batch {
    db: Arc<DB>,
    wb: WriteBatch,
}

enum KeyValue {
    ChannelActorState(Hash256, ChannelActorState),
    CkbInvoice(Hash256, CkbInvoice),
    CkbInvoicePreimage(Hash256, Hash256),
    CkbInvoiceStatus(Hash256, CkbInvoiceStatus),
    PeerIdChannelId((PeerId, Hash256), ChannelState),
    OutPointChannelId(OutPoint, Hash256),
    BroadcastMessageTimestamp(BroadcastMessageID, u64),
    BroadcastMessage(Cursor, BroadcastMessage),
    WatchtowerChannel(Hash256, ChannelData),
    PaymentSession(Hash256, PaymentSession),
    PaymentHistoryTimedResult((OutPoint, Direction), TimedResult),
    NetworkActorState(PeerId, PersistentNetworkActorState),
}

pub trait StoreKeyValue {
    fn key(&self) -> Vec<u8>;
    fn value(&self) -> Vec<u8>;
}

pub(crate) fn serialize_to_vec<T: ?Sized + Serialize>(value: &T, field_name: &str) -> Vec<u8> {
    bincode::serialize(value)
        .unwrap_or_else(|e| panic!("serialization of {} failed: {}", field_name, e))
}

pub(crate) fn deserialize_from<'a, T>(slice: &'a [u8], field_name: &str) -> T
where
    T: serde::Deserialize<'a>,
{
    bincode::deserialize(slice)
        .unwrap_or_else(|e| panic!("deserialization of {} failed: {}", field_name, e))
}

impl StoreKeyValue for KeyValue {
    fn key(&self) -> Vec<u8> {
        match self {
            KeyValue::ChannelActorState(id, _) => {
                [&[CHANNEL_ACTOR_STATE_PREFIX], id.as_ref()].concat()
            }
            KeyValue::CkbInvoice(id, _) => [&[CKB_INVOICE_PREFIX], id.as_ref()].concat(),
            KeyValue::CkbInvoicePreimage(id, _) => {
                [&[CKB_INVOICE_PREIMAGE_PREFIX], id.as_ref()].concat()
            }
            KeyValue::CkbInvoiceStatus(id, _) => {
                [&[CKB_INVOICE_STATUS_PREFIX], id.as_ref()].concat()
            }
            KeyValue::PeerIdChannelId((peer_id, channel_id), _) => [
                &[PEER_ID_CHANNEL_ID_PREFIX],
                peer_id.as_bytes(),
                channel_id.as_ref(),
            ]
            .concat(),
            KeyValue::OutPointChannelId(outpoint, _) => {
                [&[CHANNEL_OUTPOINT_CHANNEL_ID_PREFIX], outpoint.as_slice()].concat()
            }
            KeyValue::PaymentSession(payment_hash, _) => {
                [&[PAYMENT_SESSION_PREFIX], payment_hash.as_ref()].concat()
            }
            KeyValue::WatchtowerChannel(channel_id, _) => {
                [&[WATCHTOWER_CHANNEL_PREFIX], channel_id.as_ref()].concat()
            }
            KeyValue::NetworkActorState(peer_id, _) => {
                [&[PEER_ID_NETWORK_ACTOR_STATE_PREFIX], peer_id.as_bytes()].concat()
            }
            KeyValue::PaymentHistoryTimedResult((channel_outpoint, direction), _) => [
                &[PAYMENT_HISTORY_TIMED_RESULT_PREFIX],
                channel_outpoint.as_slice(),
                serialize_to_vec(direction, "Direction").as_slice(),
            ]
            .concat(),
            KeyValue::BroadcastMessageTimestamp(broadcast_message_id, _) => [
                &[BROADCAST_MESSAGE_TIMESTAMP_PREFIX],
                broadcast_message_id.to_bytes().as_slice(),
            ]
            .concat(),
            KeyValue::BroadcastMessage(cursor, _) => {
                [&[BROADCAST_MESSAGE_PREFIX], cursor.to_bytes().as_slice()].concat()
            }
        }
    }

    fn value(&self) -> Vec<u8> {
        match self {
            KeyValue::ChannelActorState(_, state) => serialize_to_vec(state, "ChannelActorState"),
            KeyValue::CkbInvoice(_, invoice) => serialize_to_vec(invoice, "CkbInvoice"),
            KeyValue::CkbInvoicePreimage(_, preimage) => serialize_to_vec(preimage, "Hash256"),
            KeyValue::CkbInvoiceStatus(_, status) => serialize_to_vec(status, "CkbInvoiceStatus"),
            KeyValue::PeerIdChannelId(_, state) => serialize_to_vec(state, "ChannelState"),
            KeyValue::OutPointChannelId(_, channel_id) => serialize_to_vec(channel_id, "ChannelId"),
            KeyValue::PaymentSession(_, payment_session) => {
                serialize_to_vec(payment_session, "PaymentSession")
            }
            KeyValue::WatchtowerChannel(_, channel_data) => {
                serialize_to_vec(channel_data, "ChannelData")
            }
            KeyValue::NetworkActorState(_, persistent_network_actor_state) => serialize_to_vec(
                persistent_network_actor_state,
                "PersistentNetworkActorState",
            ),
            KeyValue::BroadcastMessageTimestamp(_, value) => value.to_be_bytes().into(),
            KeyValue::BroadcastMessage(_cursor, broadcast_message) => {
                serialize_to_vec(broadcast_message, "BroadcastMessage")
            }
            KeyValue::PaymentHistoryTimedResult(_, result) => {
                serialize_to_vec(result, "TimedResult")
            }
        }
    }
}

impl Batch {
    fn get<K: AsRef<[u8]>>(&self, key: K) -> Option<Vec<u8>> {
        self.db
            .get(key.as_ref())
            .map(|v| v.map(|vi| vi.to_vec()))
            .expect("get should be OK")
    }

    fn put_kv(&mut self, key_value: KeyValue) {
        self.put(key_value.key(), key_value.value());
    }

    fn put<K: AsRef<[u8]>, V: AsRef<[u8]>>(&mut self, key: K, value: V) {
        self.wb.put(key, value).expect("put should be OK")
    }

    fn delete<K: AsRef<[u8]>>(&mut self, key: K) {
        self.wb.delete(key.as_ref()).expect("delete should be OK")
    }

    fn commit(self) {
        self.db.write(&self.wb).expect("commit should be OK")
    }
}

impl NetworkActorStateStore for Store {
    fn get_network_actor_state(&self, id: &PeerId) -> Option<PersistentNetworkActorState> {
        let key = [&[PEER_ID_NETWORK_ACTOR_STATE_PREFIX], id.as_bytes()].concat();
        self.get(key)
            .map(|value| deserialize_from(value.as_ref(), "PersistentNetworkActorState"))
    }

    fn insert_network_actor_state(&self, id: &PeerId, state: PersistentNetworkActorState) {
        let mut batch = self.batch();
        batch.put_kv(KeyValue::NetworkActorState(id.clone(), state));
        batch.commit();
    }
}

impl ChannelActorStateStore for Store {
    fn get_channel_actor_state(&self, id: &Hash256) -> Option<ChannelActorState> {
        let key = [&[CHANNEL_ACTOR_STATE_PREFIX], id.as_ref()].concat();
        self.get(key)
            .map(|v| deserialize_from(v.as_ref(), "ChannelActorState"))
    }

    fn insert_channel_actor_state(&self, state: ChannelActorState) {
        let mut batch = self.batch();
        batch.put_kv(KeyValue::ChannelActorState(state.id, state.clone()));
        batch.put_kv(KeyValue::PeerIdChannelId(
            (state.get_remote_peer_id(), state.id),
            state.state,
        ));
        if let Some(outpoint) = state.get_funding_transaction_outpoint() {
            batch.put_kv(KeyValue::OutPointChannelId(outpoint, state.id));
        }
        batch.commit();
    }

    fn delete_channel_actor_state(&self, id: &Hash256) {
        if let Some(state) = self.get_channel_actor_state(id) {
            let mut batch = self.batch();
            batch.delete([&[CHANNEL_ACTOR_STATE_PREFIX], id.as_ref()].concat());
            batch.delete(
                [
                    &[PEER_ID_CHANNEL_ID_PREFIX],
                    state.get_remote_peer_id().as_bytes(),
                    id.as_ref(),
                ]
                .concat(),
            );
            batch.delete(
                [
                    &[CHANNEL_OUTPOINT_CHANNEL_ID_PREFIX],
                    state.must_get_funding_transaction_outpoint().as_slice(),
                ]
                .concat(),
            );
            batch.commit();
        }
    }

    fn get_channel_ids_by_peer(&self, peer_id: &tentacle::secio::PeerId) -> Vec<Hash256> {
        let prefix = [&[PEER_ID_CHANNEL_ID_PREFIX], peer_id.as_bytes()].concat();
        let iter = self.prefix_iterator(&prefix);
        iter.map(|(key, _)| {
            let channel_id: [u8; 32] = key[prefix.len()..]
                .try_into()
                .expect("channel id should be 32 bytes");
            channel_id.into()
        })
        .collect()
    }

    fn get_channel_states(&self, peer_id: Option<PeerId>) -> Vec<(PeerId, Hash256, ChannelState)> {
        let prefix = match peer_id {
            Some(peer_id) => [&[PEER_ID_CHANNEL_ID_PREFIX], peer_id.as_bytes()].concat(),
            None => vec![PEER_ID_CHANNEL_ID_PREFIX],
        };
        self.prefix_iterator(&prefix)
            .map(|(key, value)| {
                let key_len = key.len();
                let peer_id = PeerId::from_bytes(key[1..key_len - 32].into())
                    .expect("deserialize peer id should be OK");
                let channel_id: [u8; 32] = key[key_len - 32..]
                    .try_into()
                    .expect("channel id should be 32 bytes");
                let state = deserialize_from(value.as_ref(), "ChannelState");
                (peer_id, channel_id.into(), state)
            })
            .collect()
    }

    fn get_channel_state_by_outpoint(&self, outpoint: &OutPoint) -> Option<ChannelActorState> {
        let key = [&[CHANNEL_OUTPOINT_CHANNEL_ID_PREFIX], outpoint.as_slice()].concat();
        self.get(key)
            .map(|channel_id| deserialize_from(channel_id.as_ref(), "Hash256"))
            .and_then(|channel_id: Hash256| self.get_channel_actor_state(&channel_id))
    }
}

impl InvoiceStore for Store {
    fn get_invoice(&self, id: &Hash256) -> Option<CkbInvoice> {
        let key = [&[CKB_INVOICE_PREFIX], id.as_ref()].concat();
        self.get(key).map(|v| deserialize_from(&v, "CkbInvoice"))
    }

    fn insert_invoice(
        &self,
        invoice: CkbInvoice,
        preimage: Option<Hash256>,
    ) -> Result<(), InvoiceError> {
        let payment_hash = invoice.payment_hash();
        if self.get_invoice(payment_hash).is_some() {
            return Err(InvoiceError::DuplicatedInvoice(payment_hash.to_string()));
        }

        let mut batch = self.batch();
        if let Some(preimage) = preimage {
            batch.put_kv(KeyValue::CkbInvoicePreimage(*payment_hash, preimage));
        }
        let payment_hash = *invoice.payment_hash();
        batch.put_kv(KeyValue::CkbInvoice(payment_hash, invoice));
        batch.put_kv(KeyValue::CkbInvoiceStatus(
            payment_hash,
            CkbInvoiceStatus::Open,
        ));
        batch.commit();
        return Ok(());
    }

    fn get_invoice_preimage(&self, id: &Hash256) -> Option<Hash256> {
        let key = [&[CKB_INVOICE_PREIMAGE_PREFIX], id.as_ref()].concat();
        self.get(key)
            .map(|v| deserialize_from(v.as_ref(), "Hash256"))
    }

    fn update_invoice_status(
        &self,
        id: &Hash256,
        status: crate::invoice::CkbInvoiceStatus,
    ) -> Result<(), InvoiceError> {
        self.get_invoice(id).ok_or(InvoiceError::InvoiceNotFound)?;
        let mut batch = self.batch();
        batch.put_kv(KeyValue::CkbInvoiceStatus(*id, status));
        batch.commit();
        Ok(())
    }

    fn get_invoice_status(&self, id: &Hash256) -> Option<CkbInvoiceStatus> {
        let key = [&[CKB_INVOICE_STATUS_PREFIX], id.as_ref()].concat();
        self.get(key)
            .map(|v| deserialize_from(v.as_ref(), "CkbInvoiceStatus"))
    }

    fn insert_payment_preimage(
        &self,
        payment_hash: Hash256,
        preimage: Hash256,
    ) -> Result<(), InvoiceError> {
        let mut batch = self.batch();
        batch.put_kv(KeyValue::CkbInvoicePreimage(payment_hash, preimage));
        batch.commit();
        Ok(())
    }
}

impl NetworkGraphStateStore for Store {
    fn get_payment_session(&self, payment_hash: Hash256) -> Option<PaymentSession> {
        let prefix = [&[PAYMENT_SESSION_PREFIX], payment_hash.as_ref()].concat();
        self.get(prefix)
            .map(|v| deserialize_from(v.as_ref(), "PaymentSession"))
    }

    fn insert_payment_session(&self, session: PaymentSession) {
        let mut batch = self.batch();
        batch.put_kv(KeyValue::PaymentSession(session.payment_hash(), session));
        batch.commit();
    }

    fn insert_payment_history_result(
        &mut self,
        channel_outpoint: OutPoint,
        direction: Direction,
        result: TimedResult,
    ) {
        let mut batch = self.batch();
        batch.put_kv(KeyValue::PaymentHistoryTimedResult(
            (channel_outpoint, direction),
            result,
        ));
        batch.commit();
    }

    fn get_payment_history_results(&self) -> Vec<(OutPoint, Direction, TimedResult)> {
        let prefix = vec![PAYMENT_HISTORY_TIMED_RESULT_PREFIX];
        let iter = self.prefix_iterator(&prefix);
        iter.map(|(key, value)| {
            let channel_outpoint: OutPoint =
                OutPoint::from_slice(&key[1..=36]).expect("deserialize OutPoint should be OK");
            let direction = deserialize_from(&key[37..], "Direction");
            let result = deserialize_from(value.as_ref(), "TimedResult");
            (channel_outpoint, direction, result)
        })
        .collect()
    }
}

impl GossipMessageStore for Store {
    fn get_broadcast_messages_iter(
        &self,
        after_cursor: &Cursor,
    ) -> impl IntoIterator<Item = crate::fiber::types::BroadcastMessageWithTimestamp> {
        let cursor = after_cursor.to_bytes();
        let prefix = [BROADCAST_MESSAGE_PREFIX];
        let start = [&prefix, cursor.as_slice()].concat();
        let mode = IteratorMode::From(&start, DbDirection::Forward);
        self.db
            .iterator(mode)
            // We should skip the value with the same cursor (after_cursor is exclusive).
            .skip_while(move |(key, _)| key.as_ref() == start)
            .take_while(move |(key, _)| key.starts_with(&prefix))
            .map(|(key, value)| {
                debug_assert_eq!(key.len(), 1 + CURSOR_SIZE);
                let mut timestamp_bytes = [0u8; 8];
                timestamp_bytes.copy_from_slice(&key[1..9]);
                let timestamp = u64::from_be_bytes(timestamp_bytes);
                let message: BroadcastMessage =
                    deserialize_from(value.as_ref(), "BroadcastMessage");
                (message, timestamp).into()
            })
    }

    fn get_broadcast_message_with_cursor(
        &self,
        cursor: &Cursor,
    ) -> Option<crate::fiber::types::BroadcastMessageWithTimestamp> {
        let key = [&[BROADCAST_MESSAGE_PREFIX], cursor.to_bytes().as_slice()].concat();
        self.get(key).map(|v| {
            let message: BroadcastMessage = deserialize_from(v.as_ref(), "BroadcastMessage");
            (message, cursor.timestamp).into()
        })
    }

    fn get_latest_broadcast_message_cursor(&self) -> Option<Cursor> {
        let prefix = vec![BROADCAST_MESSAGE_PREFIX];
        let mode = IteratorMode::End;
        self.db
            .iterator(mode)
            .take_while(|(key, _)| key.starts_with(&prefix))
            .last()
            .map(|(key, _)| {
                let last_key = key.to_vec();
                Cursor::from_bytes(&last_key[1..]).expect("deserialize Cursor should be OK")
            })
    }

    fn get_latest_channel_announcement_timestamp(&self, outpoint: &OutPoint) -> Option<u64> {
        self.get(
            [
                [BROADCAST_MESSAGE_TIMESTAMP_PREFIX].as_slice(),
                BroadcastMessageID::ChannelAnnouncement(outpoint.clone())
                    .to_bytes()
                    .as_slice(),
            ]
            .concat(),
        )
        .map(|v| {
            let v: [u8; 24] = v.try_into().expect("Invalid timestamp value length");
            u64::from_be_bytes(
                v[..8]
                    .try_into()
                    .expect("timestamp length valid, shown above"),
            )
        })
    }

    fn get_latest_channel_update_timestamp(
        &self,
        outpoint: &OutPoint,
        is_node1: bool,
    ) -> Option<u64> {
        self.get(
            [
                [BROADCAST_MESSAGE_TIMESTAMP_PREFIX].as_slice(),
                BroadcastMessageID::ChannelUpdate(outpoint.clone())
                    .to_bytes()
                    .as_slice(),
            ]
            .concat(),
        )
        .map(|v| {
            let v: [u8; 24] = v.try_into().expect("Invalid timestamp value length");
            let start_index = if is_node1 { 8 } else { 16 };
            u64::from_be_bytes(
                v[start_index..start_index + 8]
                    .try_into()
                    .expect("timestamp length valid, shown above"),
            )
        })
    }

    fn get_latest_node_announcement_timestamp(
        &self,
        pk: &crate::fiber::types::Pubkey,
    ) -> Option<u64> {
        self.get(
            [
                [BROADCAST_MESSAGE_TIMESTAMP_PREFIX].as_slice(),
                BroadcastMessageID::NodeAnnouncement(*pk)
                    .to_bytes()
                    .as_slice(),
            ]
            .concat(),
        )
        .map(|v| u64::from_be_bytes(v.try_into().expect("Invalid timestamp value length")))
    }

    fn save_channel_announcement(
        &self,
        timestamp: u64,
        channel_announcement: crate::fiber::types::ChannelAnnouncement,
    ) {
        if let Some(_old_timestamp) =
            self.get_latest_channel_announcement_timestamp(&channel_announcement.channel_outpoint)
        {
            // Channel announcement is immutable. If we have already saved one channel announcement,
            // we can early return now.
            return;
        }

        let mut batch = self.batch();

        update_channel_timestamp(
            &mut batch,
            &channel_announcement.channel_outpoint,
            timestamp,
            ChannelTimestamp::ChannelAnnouncement(),
        );

        batch.put_kv(KeyValue::BroadcastMessage(
            Cursor::new(
                timestamp,
                BroadcastMessageID::ChannelAnnouncement(
                    channel_announcement.channel_outpoint.clone(),
                ),
            ),
            BroadcastMessage::ChannelAnnouncement(channel_announcement),
        ));

        batch.commit();
    }

    fn save_channel_update(&self, channel_update: crate::fiber::types::ChannelUpdate) {
        let mut batch = self.batch();
        let message_id = BroadcastMessageID::ChannelUpdate(channel_update.channel_outpoint.clone());

        // Remove old channel update if exists
        if let Some(old_timestamp) = self.get_latest_channel_update_timestamp(
            &channel_update.channel_outpoint,
            channel_update.is_update_of_node_1(),
        ) {
            if channel_update.timestamp <= old_timestamp {
                // This is an outdated channel update, early return
                return;
            }
            // Delete old channel update
            batch.delete(
                [
                    &[BROADCAST_MESSAGE_PREFIX],
                    Cursor::new(old_timestamp, message_id.clone())
                        .to_bytes()
                        .as_slice(),
                ]
                .concat(),
            );
        }

        update_channel_timestamp(
            &mut batch,
            &channel_update.channel_outpoint,
            channel_update.timestamp,
            if channel_update.is_update_of_node_1() {
                ChannelTimestamp::ChannelUpdateOfNode1()
            } else {
                ChannelTimestamp::ChannelUpdateOfNode2()
            },
        );

        // Save the channel update
        batch.put_kv(KeyValue::BroadcastMessage(
            Cursor::new(channel_update.timestamp, message_id),
            BroadcastMessage::ChannelUpdate(channel_update),
        ));
        batch.commit();
    }

    fn save_node_announcement(&self, node_announcement: crate::fiber::types::NodeAnnouncement) {
        debug_assert!(
            node_announcement.verify(),
            "Node announcement must be verified: {:?}",
            node_announcement
        );
        let mut batch = self.batch();
        let message_id = BroadcastMessageID::NodeAnnouncement(node_announcement.node_id);

        if let Some(old_timestamp) =
            self.get_latest_node_announcement_timestamp(&node_announcement.node_id)
        {
            if node_announcement.timestamp <= old_timestamp {
                // This is an outdated node announcement. Early return.
                return;
            }

            // Delete old node announcement
            batch.delete(
                [
                    &[BROADCAST_MESSAGE_PREFIX],
                    Cursor::new(old_timestamp, message_id.clone())
                        .to_bytes()
                        .as_slice(),
                ]
                .concat(),
            );
        }
        batch.put_kv(KeyValue::BroadcastMessageTimestamp(
            BroadcastMessageID::NodeAnnouncement(node_announcement.node_id),
            node_announcement.timestamp,
        ));

        batch.put_kv(KeyValue::BroadcastMessage(
            Cursor::new(node_announcement.timestamp, message_id.clone()),
            BroadcastMessage::NodeAnnouncement(node_announcement.clone()),
        ));
        batch.commit();
    }
}

impl WatchtowerStore for Store {
    fn get_watch_channels(&self) -> Vec<ChannelData> {
        let prefix = vec![WATCHTOWER_CHANNEL_PREFIX];
        self.prefix_iterator(&prefix)
            .map(|(_key, value)| deserialize_from(value.as_ref(), "ChannelData"))
            .collect()
    }

    fn insert_watch_channel(
        &self,
        channel_id: Hash256,
        funding_tx_lock: Script,
        remote_settlement_data: SettlementData,
    ) {
        let key = [&[WATCHTOWER_CHANNEL_PREFIX], channel_id.as_ref()].concat();
        let value = serialize_to_vec(
            &ChannelData {
                channel_id,
                funding_tx_lock,
                remote_settlement_data,
                local_settlement_data: None,
                revocation_data: None,
            },
            "ChannelData",
        );
        let mut batch = self.batch();
        batch.put(key, value);
        batch.commit();
    }

    fn remove_watch_channel(&self, channel_id: Hash256) {
        let key = [&[WATCHTOWER_CHANNEL_PREFIX], channel_id.as_ref()].concat();
        self.db.delete(key).expect("delete should be OK");
    }

    fn update_revocation(
        &self,
        channel_id: Hash256,
        revocation_data: RevocationData,
        remote_settlement_data: SettlementData,
    ) {
        let key = [&[WATCHTOWER_CHANNEL_PREFIX], channel_id.as_ref()].concat();
        if let Some(mut channel_data) = self
            .get(key)
            .map(|v| deserialize_from::<ChannelData>(v.as_ref(), "ChannelData"))
        {
            channel_data.remote_settlement_data = remote_settlement_data;
            channel_data.revocation_data = Some(revocation_data);
            let mut batch = self.batch();
            batch.put_kv(KeyValue::WatchtowerChannel(channel_id, channel_data));
            batch.commit();
        }
    }

    fn update_local_settlement(&self, channel_id: Hash256, local_settlement_data: SettlementData) {
        let key = [&[WATCHTOWER_CHANNEL_PREFIX], channel_id.as_ref()].concat();
        if let Some(mut channel_data) = self
            .get(key)
            .map(|v| deserialize_from::<ChannelData>(v.as_ref(), "ChannelData"))
        {
            channel_data.local_settlement_data = Some(local_settlement_data);
            let mut batch = self.batch();
            batch.put_kv(KeyValue::WatchtowerChannel(channel_id, channel_data));
            batch.commit();
        }
    }
}


================================================
File: src/store/tests/migrate.rs
================================================
use crate::store::db_migrate::DbMigrate;
use crate::store::migration::DefaultMigration;
use crate::store::migration::Migration;
use crate::store::migration::Migrations;
use crate::store::migration::LATEST_DB_VERSION;
use crate::store::migration::MIGRATION_VERSION_KEY;
use crate::Error;
use indicatif::ProgressBar;
use rocksdb::ops::Open;
use rocksdb::ops::Put;
use rocksdb::DBCompressionType;
use rocksdb::Options;
use rocksdb::DB;
use std::cmp::Ordering;
use std::sync::{Arc, RwLock};

fn gen_path() -> std::path::PathBuf {
    let tmp_dir = tempfile::Builder::new()
        .prefix("test-store")
        .tempdir()
        .unwrap();
    tmp_dir.as_ref().to_path_buf()
}

fn gen_migrate() -> DbMigrate {
    let path = gen_path();
    let mut options = Options::default();
    options.create_if_missing(true);
    options.set_compression_type(DBCompressionType::Lz4);
    let db = Arc::new(DB::open(&options, path).unwrap());
    DbMigrate::new(db)
}

#[test]
fn test_default_migration() {
    let migrate = gen_migrate();
    assert!(migrate.need_init());
    assert_eq!(migrate.check(), Ordering::Less);
    migrate.init_db_version().unwrap();
    assert!(!migrate.need_init());
    assert_eq!(migrate.check(), Ordering::Equal);
}

#[test]
fn test_run_migration() {
    let run_count = Arc::new(RwLock::new(0));

    pub struct DummyMigration {
        version: String,
        run_count: Arc<RwLock<usize>>,
    }

    impl DummyMigration {
        pub fn new(version: &str, run_count: Arc<RwLock<usize>>) -> Self {
            Self {
                version: version.to_string(),
                run_count,
            }
        }
    }

    impl Migration for DummyMigration {
        fn migrate(
            &self,
            db: Arc<DB>,
            _pb: Arc<dyn Fn(u64) -> ProgressBar + Send + Sync>,
        ) -> Result<Arc<DB>, Error> {
            eprintln!("DummyMigration::migrate {} ... ", self.version);
            let mut count = self.run_count.write().unwrap();
            *count += 1;
            Ok(db)
        }

        fn version(&self) -> &str {
            &self.version
        }
    }

    let migrate = gen_migrate();
    migrate.init_db_version().unwrap();
    let db = migrate.db();

    let mut migrations = Migrations::default();
    // a smaller version
    migrations.add_migration(Arc::new(DummyMigration::new(
        "20221116135521",
        run_count.clone(),
    )));

    migrations.add_migration(Arc::new(DummyMigration::new(
        "20241216135521",
        run_count.clone(),
    )));
    migrations.add_migration(Arc::new(DummyMigration::new(
        "20241216135522",
        run_count.clone(),
    )));
    migrations.add_migration(Arc::new(DummyMigration::new(
        LATEST_DB_VERSION,
        run_count.clone(),
    )));
    assert_eq!(migrations.check(db.clone()), Ordering::Equal);

    // now manually set db version to a lower one
    db.put(MIGRATION_VERSION_KEY, "20221116135521")
        .expect("failed to set db version");
    assert_eq!(migrations.check(db.clone()), Ordering::Less);

    migrations.migrate(db.clone()).unwrap();
    assert_eq!(*run_count.read().unwrap(), 3);
    assert_eq!(migrations.check(db.clone()), Ordering::Equal);

    let mut migrations = Migrations::default();
    migrations.add_migration(Arc::new(DefaultMigration::new()));
    // checked by the LATEST_DB_VERSION
    assert_eq!(migrations.check(db), Ordering::Equal);
}


================================================
File: src/store/tests/mod.rs
================================================
mod migrate;
mod store;


================================================
File: src/store/tests/store.rs
================================================
use crate::fiber::channel::*;
use crate::fiber::config::AnnouncedNodeName;
use crate::fiber::config::DEFAULT_TLC_EXPIRY_DELTA;
use crate::fiber::config::MAX_PAYMENT_TLC_EXPIRY_LIMIT;
use crate::fiber::gossip::GossipMessageStore;
use crate::fiber::graph::*;
use crate::fiber::history::Direction;
use crate::fiber::history::TimedResult;
use crate::fiber::network::SendPaymentData;
use crate::fiber::tests::test_utils::*;
use crate::fiber::types::*;
use crate::gen_rand_fiber_private_key;
use crate::gen_rand_fiber_public_key;
use crate::gen_rand_sha256_hash;
use crate::invoice::*;
use crate::now_timestamp_as_millis_u64;
use crate::store::store::deserialize_from;
use crate::store::store::serialize_to_vec;
use crate::store::Store;
use crate::watchtower::*;
use ckb_hash::new_blake2b;
use ckb_types::packed::*;
use ckb_types::prelude::*;
use ckb_types::H256;
use core::cmp::Ordering;
use musig2::secp::MaybeScalar;
use musig2::CompactSignature;
use musig2::SecNonce;
use secp256k1::SecretKey;
use secp256k1::{Keypair, Secp256k1};
use std::time::SystemTime;

fn gen_rand_key_pair() -> Keypair {
    let secp = Secp256k1::new();
    Keypair::new(&secp, &mut rand::thread_rng())
}

fn gen_rand_private_key() -> SecretKey {
    gen_rand_key_pair().secret_key()
}

fn mock_node() -> (Privkey, NodeAnnouncement) {
    let sk: Privkey = gen_rand_private_key().into();
    (
        sk.clone(),
        NodeAnnouncement::new(
            AnnouncedNodeName::from_string("node1").expect("invalid name"),
            vec![],
            &sk,
            now_timestamp_as_millis_u64(),
            0,
        ),
    )
}

fn mock_channel() -> ChannelAnnouncement {
    let sk1: Privkey = gen_rand_private_key().into();
    let sk2: Privkey = gen_rand_private_key().into();
    let keypair = gen_rand_key_pair();
    let (xonly, _parity) = keypair.x_only_public_key();
    let rand_hash256 = gen_rand_sha256_hash();
    ChannelAnnouncement::new_unsigned(
        &sk1.pubkey(),
        &sk2.pubkey(),
        OutPoint::new_builder()
            .tx_hash(rand_hash256.into())
            .index(0u32.pack())
            .build(),
        &xonly,
        0,
        None,
    )
}

#[test]
fn test_store_invoice() {
    let path = TempDir::new("invoice_store");

    let store = Store::new(path).expect("created store failed");

    let preimage = gen_rand_sha256_hash();
    let invoice = InvoiceBuilder::new(Currency::Fibb)
        .amount(Some(1280))
        .payment_preimage(preimage)
        .fallback_address("address".to_string())
        .add_attr(Attribute::FinalHtlcTimeout(5))
        .build()
        .unwrap();

    let hash = invoice.payment_hash();
    store
        .insert_invoice(invoice.clone(), Some(preimage))
        .unwrap();
    assert_eq!(store.get_invoice(hash), Some(invoice.clone()));
    assert_eq!(store.get_invoice_preimage(hash), Some(preimage));

    let invalid_hash = gen_rand_sha256_hash();
    assert_eq!(store.get_invoice_preimage(&invalid_hash), None);

    assert_eq!(store.get_invoice_status(hash), Some(CkbInvoiceStatus::Open));
    assert_eq!(store.get_invoice_status(&gen_rand_sha256_hash()), None);

    let status = CkbInvoiceStatus::Paid;
    store.update_invoice_status(hash, status).unwrap();
    assert_eq!(store.get_invoice_status(hash), Some(status));
}

#[test]
fn test_store_get_broadcast_messages_iter() {
    let path = TempDir::new("test-gossip-store");
    let store = Store::new(path).expect("created store failed");

    let timestamp = now_timestamp_as_millis_u64();
    let channel_announcement = mock_channel();
    let outpoint = channel_announcement.out_point().clone();
    store.save_channel_announcement(timestamp, channel_announcement.clone());
    let default_cursor = Cursor::default();
    let mut iter = store
        .get_broadcast_messages_iter(&default_cursor)
        .into_iter();
    assert_eq!(
        iter.next(),
        Some(BroadcastMessageWithTimestamp::ChannelAnnouncement(
            timestamp,
            channel_announcement
        )),
    );
    assert_eq!(iter.next(), None);
    let cursor = Cursor::new(timestamp, BroadcastMessageID::ChannelAnnouncement(outpoint));
    let mut iter = store.get_broadcast_messages_iter(&cursor).into_iter();
    assert_eq!(iter.next(), None);
}

#[test]
fn test_store_get_broadcast_messages() {
    let path = TempDir::new("test-gossip-store");
    let store = Store::new(path).expect("created store failed");

    let timestamp = now_timestamp_as_millis_u64();
    let channel_announcement = mock_channel();
    let outpoint = channel_announcement.out_point().clone();
    store.save_channel_announcement(timestamp, channel_announcement.clone());
    let default_cursor = Cursor::default();
    let result = store.get_broadcast_messages(&default_cursor, None);
    assert_eq!(
        result,
        vec![BroadcastMessageWithTimestamp::ChannelAnnouncement(
            timestamp,
            channel_announcement
        )],
    );
    let cursor = Cursor::new(timestamp, BroadcastMessageID::ChannelAnnouncement(outpoint));
    let result = store.get_broadcast_messages(&cursor, None);
    assert_eq!(result, vec![]);
}

#[test]
fn test_store_save_channel_announcement() {
    let path = TempDir::new("test-gossip-store");
    let store = Store::new(path).expect("created store failed");

    let timestamp = now_timestamp_as_millis_u64();
    let channel_announcement = mock_channel();
    store.save_channel_announcement(timestamp, channel_announcement.clone());
    let new_channel_announcement =
        store.get_latest_channel_announcement(channel_announcement.out_point());
    assert_eq!(
        new_channel_announcement,
        Some((timestamp, channel_announcement))
    );
}

#[test]
fn test_store_save_channel_update() {
    let path = TempDir::new("test-gossip-store");
    let store = Store::new(path).expect("created store failed");

    let flags_for_update_of_node1 = ChannelUpdateMessageFlags::UPDATE_OF_NODE1;
    let channel_update_of_node1 = ChannelUpdate::new_unsigned(
        OutPoint::new_builder()
            .tx_hash(gen_rand_sha256_hash().into())
            .index(0u32.pack())
            .build(),
        now_timestamp_as_millis_u64(),
        flags_for_update_of_node1,
        ChannelUpdateChannelFlags::empty(),
        0,
        0,
        0,
    );
    let out_point = channel_update_of_node1.channel_outpoint.clone();
    store.save_channel_update(channel_update_of_node1.clone());
    assert_eq!(
        store.get_latest_channel_update(&out_point, true).as_ref(),
        Some(&channel_update_of_node1)
    );
    assert_eq!(store.get_latest_channel_update(&out_point, false), None);

    let mut channel_update_of_node2 = channel_update_of_node1.clone();
    let flags_for_update_of_node2 = ChannelUpdateMessageFlags::UPDATE_OF_NODE2;
    channel_update_of_node2.message_flags = flags_for_update_of_node2;
    // Note that per discussion in Notion, we don't handle the rare case of two channel updates having the same timestamp.
    // In the current implementation, channel update from one side with the same timestamp will not overwrite the existing one
    // from the other side. So we have to set the timestamp to be different.
    channel_update_of_node2.timestamp = 2;
    store.save_channel_update(channel_update_of_node2.clone());
    assert_eq!(
        store.get_latest_channel_update(&out_point, false).as_ref(),
        Some(&channel_update_of_node2)
    );
    assert_eq!(
        store.get_latest_channel_update(&out_point, true).as_ref(),
        Some(&channel_update_of_node1)
    );
}

#[test]
fn test_store_save_node_announcement() {
    let path = TempDir::new("test-gossip-store");
    let store = Store::new(path).expect("created store failed");

    let (sk, node_announcement) = mock_node();
    let pk = sk.pubkey();
    store.save_node_announcement(node_announcement.clone());
    let new_node_announcement = store.get_latest_node_announcement(&pk);
    assert_eq!(new_node_announcement, Some(node_announcement));
}

#[test]
fn test_store_wacthtower() {
    let path = TempDir::new("test-watchtower-store");
    let store = Store::new(path).expect("created store failed");

    let channel_id = gen_rand_sha256_hash();
    let funding_tx_lock = Script::default();

    let settlement_data = SettlementData {
        x_only_aggregated_pubkey: [0u8; 32],
        aggregated_signature: CompactSignature::from_bytes(&[0u8; 64]).unwrap(),
        to_local_output: CellOutput::default(),
        to_local_output_data: Bytes::default(),
        to_remote_output: CellOutput::default(),
        to_remote_output_data: Bytes::default(),
    };

    store.insert_watch_channel(channel_id, funding_tx_lock.clone(), settlement_data.clone());
    assert_eq!(
        store.get_watch_channels(),
        vec![ChannelData {
            channel_id,
            funding_tx_lock: funding_tx_lock.clone(),
            revocation_data: None,
            local_settlement_data: None,
            remote_settlement_data: settlement_data.clone(),
        }]
    );

    let revocation_data = RevocationData {
        commitment_number: 0,
        x_only_aggregated_pubkey: [0u8; 32],
        aggregated_signature: CompactSignature::from_bytes(&[0u8; 64]).unwrap(),
        output: CellOutput::default(),
        output_data: Bytes::default(),
    };

    store.update_revocation(channel_id, revocation_data.clone(), settlement_data.clone());
    assert_eq!(
        store.get_watch_channels(),
        vec![ChannelData {
            channel_id,
            funding_tx_lock,
            local_settlement_data: None,
            revocation_data: Some(revocation_data),
            remote_settlement_data: settlement_data,
        }]
    );

    store.remove_watch_channel(channel_id);
    assert_eq!(store.get_watch_channels(), vec![]);
}

#[test]
fn test_channel_state_serialize() {
    let state = ChannelState::AwaitingChannelReady(AwaitingChannelReadyFlags::CHANNEL_READY);
    let bincode_encoded = bincode::serialize(&state).unwrap();
    let new_state: ChannelState = bincode::deserialize(&bincode_encoded).unwrap();
    assert_eq!(state, new_state);

    let flags = SigningCommitmentFlags::COMMITMENT_SIGNED_SENT;
    let bincode_encoded = bincode::serialize(&flags).unwrap();
    let new_flags: SigningCommitmentFlags = bincode::deserialize(&bincode_encoded).unwrap();
    assert_eq!(flags, new_flags);
}

fn blake2b_hash_with_salt(data: &[u8], salt: &[u8]) -> [u8; 32] {
    let mut hasher = new_blake2b();
    hasher.update(salt);
    hasher.update(data);
    let mut result = [0u8; 32];
    hasher.finalize(&mut result);
    result
}

#[test]
fn test_channel_actor_state_store() {
    let seed = [0u8; 32];
    let signer = InMemorySigner::generate_from_seed(&seed);

    let seckey = blake2b_hash_with_salt(
        signer.musig2_base_nonce.as_ref(),
        b"channel_announcement".as_slice(),
    );
    let sec_nonce = SecNonce::build(seckey).build();
    let pub_nonce = sec_nonce.public_nonce();

    let state = ChannelActorState {
        state: ChannelState::NegotiatingFunding(NegotiatingFundingFlags::THEIR_INIT_SENT),
        public_channel_info: Some(PublicChannelInfo {
            local_channel_announcement_signature: Some((
                mock_ecdsa_signature(),
                MaybeScalar::two(),
            )),
            remote_channel_announcement_signature: Some((
                mock_ecdsa_signature(),
                MaybeScalar::two(),
            )),
            remote_channel_announcement_nonce: Some(pub_nonce.clone()),
            channel_announcement: None,
            channel_update: None,
        }),
        local_tlc_info: ChannelTlcInfo {
            enabled: false,
            timestamp: 0,
            tlc_fee_proportional_millionths: 123,
            tlc_expiry_delta: 3,
            tlc_minimum_value: 10,
            tlc_maximum_value: 0,
        },
        remote_tlc_info: None,
        local_pubkey: gen_rand_fiber_public_key(),
        remote_pubkey: gen_rand_fiber_public_key(),
        funding_tx: Some(Transaction::default()),
        funding_tx_confirmed_at: Some((H256::default(), 1, 1)),
        is_acceptor: true,
        funding_udt_type_script: Some(Script::default()),
        to_local_amount: 100,
        to_remote_amount: 100,
        commitment_fee_rate: 100,
        commitment_delay_epoch: 100,
        funding_fee_rate: 100,
        id: gen_rand_sha256_hash(),
        tlc_state: Default::default(),
        local_shutdown_script: Script::default(),
        local_channel_public_keys: ChannelBasePublicKeys {
            funding_pubkey: gen_rand_fiber_public_key(),
            tlc_base_key: gen_rand_fiber_public_key(),
        },
        signer,
        remote_channel_public_keys: Some(ChannelBasePublicKeys {
            funding_pubkey: gen_rand_fiber_public_key(),
            tlc_base_key: gen_rand_fiber_public_key(),
        }),
        commitment_numbers: Default::default(),
        remote_shutdown_script: Some(Script::default()),
        last_committed_remote_nonce: None,
        last_revoke_and_ack_remote_nonce: None,
        last_commitment_signed_remote_nonce: None,
        remote_commitment_points: vec![
            (0, gen_rand_fiber_public_key()),
            (1, gen_rand_fiber_public_key()),
        ],
        local_shutdown_info: None,
        remote_shutdown_info: None,
        local_reserved_ckb_amount: 100,
        remote_reserved_ckb_amount: 100,
        latest_commitment_transaction: None,
        local_constraints: ChannelConstraints::default(),
        remote_constraints: ChannelConstraints::default(),
        reestablishing: false,
        created_at: SystemTime::now(),
    };

    let bincode_encoded = bincode::serialize(&state).unwrap();
    let _new_state: ChannelActorState = bincode::deserialize(&bincode_encoded).unwrap();

    let path = TempDir::new("channel_actore_store");

    let store = Store::new(path).expect("create store failed");
    assert!(store.get_channel_actor_state(&state.id).is_none());
    store.insert_channel_actor_state(state.clone());

    let get_state = store.get_channel_actor_state(&state.id);
    assert!(get_state.is_some());
    assert!(!get_state.unwrap().is_tlc_forwarding_enabled());

    let remote_peer_id = state.get_remote_peer_id();
    assert_eq!(
        store.get_channel_ids_by_peer(&remote_peer_id),
        vec![state.id]
    );
    let channel_point = state.must_get_funding_transaction_outpoint();
    assert!(store
        .get_channel_state_by_outpoint(&channel_point)
        .is_some());

    store.delete_channel_actor_state(&state.id);
    assert!(store.get_channel_actor_state(&state.id).is_none());
    assert_eq!(store.get_channel_ids_by_peer(&remote_peer_id), vec![]);
    let channel_point = state.must_get_funding_transaction_outpoint();
    assert!(store
        .get_channel_state_by_outpoint(&channel_point)
        .is_none());
}

#[test]
fn test_serde_channel_actor_state_ciborium() {
    let seed = [0u8; 32];
    let signer = InMemorySigner::generate_from_seed(&seed);

    let seckey = blake2b_hash_with_salt(
        signer.musig2_base_nonce.as_ref(),
        b"channel_announcement".as_slice(),
    );
    let sec_nonce = SecNonce::build(seckey).build();
    let pub_nonce = sec_nonce.public_nonce();

    let state = ChannelActorState {
        state: ChannelState::NegotiatingFunding(NegotiatingFundingFlags::THEIR_INIT_SENT),
        public_channel_info: Some(PublicChannelInfo {
            local_channel_announcement_signature: Some((
                mock_ecdsa_signature(),
                MaybeScalar::two(),
            )),
            remote_channel_announcement_signature: Some((
                mock_ecdsa_signature(),
                MaybeScalar::two(),
            )),
            remote_channel_announcement_nonce: Some(pub_nonce.clone()),
            channel_announcement: None,
            channel_update: None,
        }),
        local_tlc_info: ChannelTlcInfo {
            enabled: false,
            timestamp: 0,
            tlc_fee_proportional_millionths: 123,
            tlc_expiry_delta: 3,
            tlc_minimum_value: 10,
            tlc_maximum_value: 0,
        },
        remote_tlc_info: None,
        local_pubkey: gen_rand_fiber_public_key(),
        remote_pubkey: gen_rand_fiber_public_key(),
        funding_tx: Some(Transaction::default()),
        funding_tx_confirmed_at: Some((H256::default(), 1, 1)),
        is_acceptor: true,
        funding_udt_type_script: Some(Script::default()),
        to_local_amount: 100,
        to_remote_amount: 100,
        commitment_fee_rate: 100,
        commitment_delay_epoch: 100,
        funding_fee_rate: 100,
        id: gen_rand_sha256_hash(),
        tlc_state: Default::default(),
        local_shutdown_script: Script::default(),
        local_channel_public_keys: ChannelBasePublicKeys {
            funding_pubkey: gen_rand_fiber_public_key(),
            tlc_base_key: gen_rand_fiber_public_key(),
        },
        signer,
        remote_channel_public_keys: Some(ChannelBasePublicKeys {
            funding_pubkey: gen_rand_fiber_public_key(),
            tlc_base_key: gen_rand_fiber_public_key(),
        }),
        commitment_numbers: Default::default(),
        remote_shutdown_script: Some(Script::default()),
        last_committed_remote_nonce: None,
        last_revoke_and_ack_remote_nonce: None,
        last_commitment_signed_remote_nonce: None,
        remote_commitment_points: vec![
            (0, gen_rand_fiber_public_key()),
            (1, gen_rand_fiber_public_key()),
        ],
        local_shutdown_info: None,
        remote_shutdown_info: None,
        local_reserved_ckb_amount: 100,
        remote_reserved_ckb_amount: 100,
        latest_commitment_transaction: None,
        local_constraints: ChannelConstraints::default(),
        remote_constraints: ChannelConstraints::default(),
        reestablishing: false,
        created_at: SystemTime::now(),
    };

    let mut serialized = Vec::new();
    ciborium::into_writer(&state, &mut serialized).unwrap();
    let _new_channel_state: ChannelActorState =
        ciborium::from_reader(serialized.as_slice()).expect("deserialize to new state");
}

#[test]
fn test_store_payment_session() {
    let path = TempDir::new("payment-history-store-test");
    let store = Store::new(path).expect("created store failed");
    let payment_hash = gen_rand_sha256_hash();
    let payment_data = SendPaymentData {
        target_pubkey: gen_rand_fiber_public_key(),
        amount: 100,
        payment_hash,
        invoice: None,
        final_tlc_expiry_delta: DEFAULT_TLC_EXPIRY_DELTA,
        tlc_expiry_limit: MAX_PAYMENT_TLC_EXPIRY_LIMIT,
        timeout: Some(10),
        max_fee_amount: Some(1000),
        max_parts: None,
        keysend: false,
        udt_type_script: None,
        preimage: None,
        allow_self_payment: false,
        hop_hints: vec![],
        dry_run: false,
    };
    let payment_session = PaymentSession::new(payment_data.clone(), 10);
    store.insert_payment_session(payment_session.clone());
    let res = store.get_payment_session(payment_hash).unwrap();
    assert_eq!(res.payment_hash(), payment_hash);
    assert_eq!(res.request.max_fee_amount, Some(1000));
    assert_eq!(res.status, PaymentSessionStatus::Created);
}

#[test]
fn test_store_payment_history() {
    let mut store = generate_store();
    let result = TimedResult {
        fail_amount: 1,
        fail_time: 2,
        success_time: 3,
        success_amount: 4,
    };
    let channel_outpoint = OutPoint::default();
    let direction = Direction::Forward;
    store.insert_payment_history_result(channel_outpoint.clone(), direction, result);
    assert_eq!(
        store.get_payment_history_results(),
        vec![(channel_outpoint.clone(), direction, result)]
    );

    fn sort_results(results: &mut [(OutPoint, Direction, TimedResult)]) {
        results.sort_by(|a, b| match a.0.cmp(&b.0) {
            Ordering::Equal => a.1.cmp(&b.1),
            other => other,
        });
    }

    let result_2 = TimedResult {
        fail_amount: 2,
        fail_time: 3,
        success_time: 4,
        success_amount: 5,
    };
    let direction_2 = Direction::Backward;
    store.insert_payment_history_result(channel_outpoint.clone(), direction_2, result_2);
    let mut r1 = store.get_payment_history_results();
    sort_results(&mut r1);
    let mut r2: Vec<(OutPoint, Direction, TimedResult)> = vec![
        (channel_outpoint.clone(), direction, result),
        (channel_outpoint.clone(), direction_2, result_2),
    ];
    sort_results(&mut r2);
    assert_eq!(r1, r2);

    let outpoint_3 = OutPoint::new_builder()
        .tx_hash(gen_rand_sha256_hash().into())
        .index(1u32.pack())
        .build();
    let direction_3 = Direction::Forward;
    let result_3 = TimedResult {
        fail_amount: 3,
        fail_time: 4,
        success_time: 5,
        success_amount: 6,
    };

    store.insert_payment_history_result(outpoint_3.clone(), direction_3, result_3);
    let mut r1 = store.get_payment_history_results();
    sort_results(&mut r1);

    let mut r2: Vec<(OutPoint, Direction, TimedResult)> = vec![
        (channel_outpoint.clone(), direction, result),
        (channel_outpoint.clone(), direction_2, result_2),
        (outpoint_3, direction_3, result_3),
    ];
    sort_results(&mut r2);
    assert_eq!(r1, r2);
}

#[test]
fn test_serde_node_announcement_as_broadcast_message() {
    let privkey = gen_rand_fiber_private_key();
    let node_announcement = NodeAnnouncement::new(
        AnnouncedNodeName::from_string("node1").expect("valid name"),
        vec![],
        &privkey,
        now_timestamp_as_millis_u64(),
        0,
    );
    assert!(
        node_announcement.verify(),
        "Node announcement verification failed: {:?}",
        &node_announcement
    );
    let broadcast_message = BroadcastMessage::NodeAnnouncement(node_announcement.clone());
    let serialized = serialize_to_vec(&broadcast_message, "BroadcastMessage");
    dbg!("serialized", hex::encode(&serialized));
    let deserialized: BroadcastMessage = deserialize_from(serialized.as_ref(), "BroadcastMessage");
    assert_eq!(
        BroadcastMessage::NodeAnnouncement(node_announcement),
        deserialized
    );
}


================================================
File: src/tests/mod.rs
================================================
use ckb_hash::blake2b_256;
use ckb_types::core::TransactionView;
use ckb_types::packed::CellOutput;
use ckb_types::prelude::{Builder, Entity, Unpack};
use ckb_types::{packed::OutPoint, prelude::Pack};
use secp256k1::{Keypair, PublicKey, Secp256k1, SecretKey, XOnlyPublicKey};

use crate::ckb::contracts::{get_cell_deps_by_contracts, get_script_by_contract, Contract};
use crate::fiber::types::{
    ChannelUpdate, ChannelUpdateChannelFlags, ChannelUpdateMessageFlags, EcdsaSignature,
};
use crate::{
    fiber::{
        config::AnnouncedNodeName,
        types::{ChannelAnnouncement, NodeAnnouncement, Privkey, Pubkey},
    },
    now_timestamp_as_millis_u64,
};

pub fn gen_rand_fiber_public_key() -> Pubkey {
    gen_rand_secp256k1_public_key().into()
}

pub fn gen_rand_fiber_private_key() -> Privkey {
    gen_rand_secp256k1_private_key().into()
}

pub fn gen_rand_secp256k1_private_key() -> SecretKey {
    gen_rand_secp256k1_keypair_tuple().0
}

pub fn gen_rand_secp256k1_public_key() -> PublicKey {
    gen_rand_secp256k1_keypair_tuple().1
}

pub fn gen_rand_secp256k1_keypair() -> Keypair {
    let secp = Secp256k1::new();
    Keypair::new(&secp, &mut rand::thread_rng())
}

pub fn gen_rand_secp256k1_keypair_tuple() -> (SecretKey, PublicKey) {
    let key_pair = gen_rand_secp256k1_keypair();
    (
        SecretKey::from_keypair(&key_pair),
        PublicKey::from_keypair(&key_pair),
    )
}

pub fn gen_rand_channel_outpoint() -> OutPoint {
    let rand_slice = (0..36).map(|_| rand::random::<u8>()).collect::<Vec<u8>>();
    OutPoint::from_slice(&rand_slice).unwrap()
}

pub fn gen_rand_node_announcement() -> (Privkey, NodeAnnouncement) {
    let sk = gen_rand_fiber_private_key();
    let node_announcement = gen_node_announcement_from_privkey(&sk);
    (sk, node_announcement)
}

pub fn gen_node_announcement_from_privkey(sk: &Privkey) -> NodeAnnouncement {
    NodeAnnouncement::new(
        AnnouncedNodeName::from_string("node1").expect("valid name"),
        vec![],
        sk,
        now_timestamp_as_millis_u64(),
        0,
    )
}

pub fn create_funding_tx(x_only: &XOnlyPublicKey) -> TransactionView {
    let capacity = 100u64;
    let commitment_lock_script_args = [&blake2b_256(x_only.serialize())[0..20]].concat();

    TransactionView::new_advanced_builder()
        .cell_deps(get_cell_deps_by_contracts(vec![Contract::Secp256k1Lock]))
        .output(
            CellOutput::new_builder()
                .capacity(capacity.pack())
                .lock(get_script_by_contract(
                    Contract::CommitmentLock,
                    commitment_lock_script_args.as_slice(),
                ))
                .build(),
        )
        .output_data(Default::default())
        .build()
}

pub struct ChannelTestContext {
    pub funding_tx_sk: Privkey,
    pub node1_sk: Privkey,
    pub node2_sk: Privkey,
    pub funding_tx: TransactionView,
    pub channel_announcement: ChannelAnnouncement,
}

impl ChannelTestContext {
    pub fn gen() -> ChannelTestContext {
        let funding_tx_sk = gen_rand_fiber_private_key();
        let node1_sk = gen_rand_fiber_private_key();
        let node2_sk = gen_rand_fiber_private_key();
        let xonly = funding_tx_sk.x_only_pub_key();
        let funding_tx = create_funding_tx(&xonly);
        let outpoint = funding_tx.output_pts_iter().next().unwrap();
        let capacity: u64 = funding_tx.output(0).unwrap().capacity().unpack();
        let mut channel_announcement = ChannelAnnouncement::new_unsigned(
            &node1_sk.pubkey(),
            &node2_sk.pubkey(),
            outpoint.clone(),
            &xonly,
            capacity as u128,
            None,
        );
        let message = channel_announcement.message_to_sign();

        channel_announcement.ckb_signature = Some(funding_tx_sk.sign_schnorr(message));
        channel_announcement.node1_signature = Some(node1_sk.sign(message));
        channel_announcement.node2_signature = Some(node2_sk.sign(message));

        ChannelTestContext {
            funding_tx_sk,
            node1_sk,
            node2_sk,
            funding_tx,
            channel_announcement,
        }
    }

    pub fn channel_outpoint(&self) -> &OutPoint {
        &self.channel_announcement.channel_outpoint
    }

    pub fn create_channel_update_of_node1(
        &self,
        channel_flags: ChannelUpdateChannelFlags,
        tlc_expiry_delta: u64,
        tlc_minimum_value: u128,
        tlc_fee_proportional_millionths: u128,
    ) -> ChannelUpdate {
        let mut unsigned_channel_update = ChannelUpdate::new_unsigned(
            self.channel_announcement.channel_outpoint.clone(),
            now_timestamp_as_millis_u64(),
            ChannelUpdateMessageFlags::UPDATE_OF_NODE1,
            channel_flags,
            tlc_expiry_delta,
            tlc_minimum_value,
            tlc_fee_proportional_millionths,
        );
        let message = unsigned_channel_update.message_to_sign();
        let signature = self.node1_sk.sign(message);
        unsigned_channel_update.signature = Some(signature);
        unsigned_channel_update
    }

    pub fn create_channel_update_of_node2(
        &self,
        channel_flags: ChannelUpdateChannelFlags,
        tlc_expiry_delta: u64,
        tlc_minimum_value: u128,
        tlc_fee_proportional_millionths: u128,
    ) -> ChannelUpdate {
        let mut unsigned_channel_update = ChannelUpdate::new_unsigned(
            self.channel_announcement.channel_outpoint.clone(),
            now_timestamp_as_millis_u64(),
            ChannelUpdateMessageFlags::UPDATE_OF_NODE2,
            channel_flags,
            tlc_expiry_delta,
            tlc_minimum_value,
            tlc_fee_proportional_millionths,
        );
        let message = unsigned_channel_update.message_to_sign();
        let signature = self.node2_sk.sign(message);
        unsigned_channel_update.signature = Some(signature);
        unsigned_channel_update
    }
}

pub fn create_invalid_ecdsa_signature() -> EcdsaSignature {
    let sk = Privkey::from([42u8; 32]);
    sk.sign([0u8; 32])
}


================================================
File: src/watchtower/actor.rs
================================================
use anyhow::anyhow;
use ckb_hash::new_blake2b;
use ckb_jsonrpc_types::{Either, Status};
use ckb_sdk::{
    rpc::ckb_indexer::{CellType, Order, ScriptType, SearchKey, SearchMode, Tx},
    traits::{CellCollector, CellQueryOptions, DefaultCellCollector, ValueRangeOption},
    transaction::builder::FeeCalculator,
    util::blake160,
    CkbRpcClient, RpcError,
};
use ckb_types::{
    self,
    core::{Capacity, EpochNumberWithFraction, HeaderView, TransactionView},
    packed::{Bytes, CellInput, CellOutput, OutPoint, Script, Transaction, WitnessArgs},
    prelude::*,
};
use molecule::prelude::Entity;
use ractor::{Actor, ActorProcessingErr, ActorRef};
use secp256k1::{Message, PublicKey, Secp256k1, SecretKey};
use tracing::{error, info, trace, warn};

use crate::{
    ckb::{
        contracts::{get_cell_deps, get_script_by_contract, Contract},
        CkbConfig,
    },
    fiber::channel::{create_witness_for_commitment_cell, RevocationData, SettlementData},
    NetworkServiceEvent,
};

use super::WatchtowerStore;

pub const DEFAULT_WATCHTOWER_CHECK_INTERVAL_SECONDS: u64 = 60;

pub struct WatchtowerActor<S> {
    store: S,
}

impl<S: WatchtowerStore> WatchtowerActor<S> {
    pub fn new(store: S) -> Self {
        Self { store }
    }
}

pub enum WatchtowerMessage {
    NetworkServiceEvent(NetworkServiceEvent),
    PeriodicCheck,
}

pub struct WatchtowerState {
    config: CkbConfig,
    secret_key: SecretKey,
}

#[ractor::async_trait]
impl<S> Actor for WatchtowerActor<S>
where
    S: WatchtowerStore + Send + Sync + 'static,
{
    type Msg = WatchtowerMessage;
    type State = WatchtowerState;
    type Arguments = CkbConfig;

    async fn pre_start(
        &self,
        _myself: ActorRef<Self::Msg>,
        config: Self::Arguments,
    ) -> Result<Self::State, ActorProcessingErr> {
        let secret_key = config.read_secret_key()?;
        Ok(Self::State { config, secret_key })
    }

    async fn handle(
        &self,
        _myself: ActorRef<Self::Msg>,
        message: Self::Msg,
        state: &mut Self::State,
    ) -> Result<(), ActorProcessingErr> {
        match message {
            WatchtowerMessage::NetworkServiceEvent(event) => {
                trace!("Received NetworkServiceEvent: {:?}", event);
                match event {
                    NetworkServiceEvent::RemoteTxComplete(
                        _peer_id,
                        channel_id,
                        funding_tx_lock,
                        settlement_data,
                    ) => {
                        self.store.insert_watch_channel(
                            channel_id,
                            funding_tx_lock,
                            settlement_data,
                        );
                    }
                    NetworkServiceEvent::ChannelClosed(_peer_id, channel_id, _close_tx_hash) => {
                        self.store.remove_watch_channel(channel_id);
                    }
                    NetworkServiceEvent::RevokeAndAckReceived(
                        _peer_id,
                        channel_id,
                        revocation_data,
                        settlement_data,
                    ) => {
                        self.store
                            .update_revocation(channel_id, revocation_data, settlement_data);
                    }
                    NetworkServiceEvent::RemoteCommitmentSigned(
                        _peer_id,
                        channel_id,
                        _commitment_tx,
                        settlement_data,
                    ) => {
                        self.store
                            .update_local_settlement(channel_id, settlement_data);
                    }
                    _ => {
                        // ignore
                    }
                }
            }
            WatchtowerMessage::PeriodicCheck => self.periodic_check(state),
        }
        Ok(())
    }
}

impl<S> WatchtowerActor<S>
where
    S: WatchtowerStore,
{
    fn periodic_check(&self, state: &WatchtowerState) {
        for channel_data in self.store.get_watch_channels() {
            let secret_key = state.secret_key;
            let rpc_url = state.config.rpc_url.clone();
            tokio::task::block_in_place(move || {
                let ckb_client = CkbRpcClient::new(&rpc_url);
                let mut cell_collector = DefaultCellCollector::new(&rpc_url);
                let search_key = SearchKey {
                    script: channel_data.funding_tx_lock.clone().into(),
                    script_type: ScriptType::Lock,
                    script_search_mode: Some(SearchMode::Exact),
                    with_data: None,
                    filter: None,
                    group_by_transaction: None,
                };
                // we need two parties' signatures to unlock the funding tx, so we can check the last one transaction only to see if it's an old version commitment tx
                match ckb_client.get_transactions(search_key, Order::Desc, 1u32.into(), None) {
                    Ok(txs) => {
                        if let Some(Tx::Ungrouped(tx)) = txs.objects.first() {
                            if matches!(tx.io_type, CellType::Input) {
                                match ckb_client.get_transaction(tx.tx_hash.clone()) {
                                    Ok(Some(tx_with_status)) => {
                                        if tx_with_status.tx_status.status != Status::Committed {
                                            error!("Cannot find the commitment tx: {:?}, status is {:?}, maybe ckb indexer bug?", tx_with_status.tx_status.status, tx.tx_hash);
                                        } else if let Some(tx) = tx_with_status.transaction {
                                            match tx.inner {
                                                Either::Left(tx) => {
                                                    let tx: Transaction = tx.inner.into();
                                                    if tx.raw().outputs().len() == 1 {
                                                        let output = tx
                                                            .raw()
                                                            .outputs()
                                                            .get(0)
                                                            .expect("get output 0 of tx");
                                                        let commitment_lock = output.lock();
                                                        let lock_args =
                                                            commitment_lock.args().raw_data();
                                                        let pub_key_hash: [u8; 20] = lock_args
                                                            [0..20]
                                                            .try_into()
                                                            .expect("checked length");
                                                        let commitment_number = u64::from_be_bytes(
                                                            lock_args[28..36]
                                                                .try_into()
                                                                .expect("u64 from slice"),
                                                        );

                                                        if blake160(
                                                            &channel_data
                                                                .remote_settlement_data
                                                                .x_only_aggregated_pubkey,
                                                        )
                                                        .0 == pub_key_hash
                                                        {
                                                            match channel_data
                                                                .revocation_data
                                                                .clone()
                                                            {
                                                                Some(revocation_data)
                                                                    if revocation_data
                                                                        .commitment_number
                                                                        >= commitment_number =>
                                                                {
                                                                    let commitment_tx_out_point =
                                                                        OutPoint::new(
                                                                            tx.calc_tx_hash(),
                                                                            0,
                                                                        );
                                                                    match ckb_client.get_live_cell(
                                                                        commitment_tx_out_point
                                                                            .clone()
                                                                            .into(),
                                                                        false,
                                                                    ) {
                                                                        Ok(cell_with_status) => {
                                                                            if cell_with_status
                                                                                .status
                                                                                == "live"
                                                                            {
                                                                                warn!("Found an old version commitment tx submitted by remote: {:#x}", tx.calc_tx_hash());
                                                                                match build_revocation_tx(
                                                                                    commitment_tx_out_point,
                                                                                    revocation_data,
                                                                                    secret_key,
                                                                                    &mut cell_collector,
                                                                                ) {
                                                                                    Ok(tx) => {
                                                                                        match ckb_client
                                                                                            .send_transaction(
                                                                                                tx.data()
                                                                                                    .into(),
                                                                                                None,
                                                                                            ) {
                                                                                            Ok(tx_hash) => {
                                                                                                info!("Revocation tx: {:?} sent, tx_hash: {:?}", tx, tx_hash);
                                                                                            }
                                                                                            Err(err) => {
                                                                                                error!("Failed to send revocation tx: {:?}, error: {:?}", tx, err);
                                                                                            }
                                                                                        }
                                                                                    }
                                                                                    Err(err) => {
                                                                                        error!("Failed to build revocation tx: {:?}", err);
                                                                                    }
                                                                                }
                                                                            }
                                                                        }
                                                                        Err(err) => {
                                                                            error!("Failed to get live cell: {:?}", err);
                                                                        }
                                                                    }
                                                                }
                                                                _ => {
                                                                    try_settle_commitment_tx(
                                                                        commitment_lock,
                                                                        ckb_client,
                                                                        channel_data
                                                                            .remote_settlement_data
                                                                            .clone(),
                                                                        secret_key,
                                                                        &mut cell_collector,
                                                                    );
                                                                }
                                                            }
                                                        } else {
                                                            try_settle_commitment_tx(
                                                                commitment_lock,
                                                                ckb_client,
                                                                channel_data
                                                                    .local_settlement_data
                                                                    .clone()
                                                                    .expect(
                                                                        "remote settlement data",
                                                                    ),
                                                                secret_key,
                                                                &mut cell_collector,
                                                            );
                                                        }
                                                    } else {
                                                        // there may be a race condition that PeriodicCheck is triggered before the remove_channel fn is called
                                                        // it's a close channel tx, ignore
                                                    }
                                                }
                                                Either::Right(_tx) => {
                                                    // unreachable, ignore
                                                }
                                            }
                                        } else {
                                            error!("Cannot find the commitment tx: {:?}, transcation is none, maybe ckb indexer bug?", tx.tx_hash);
                                        }
                                    }
                                    Ok(None) => {
                                        error!("Cannot find the commitment tx: {:?}, maybe ckb indexer bug?", tx.tx_hash);
                                    }
                                    Err(err) => {
                                        error!("Failed to get funding tx: {:?}", err);
                                    }
                                }
                            }
                        }
                    }
                    Err(err) => {
                        error!("Failed to get transactions: {:?}", err);
                    }
                }
            });
        }
    }
}

fn build_revocation_tx(
    commitment_tx_out_point: OutPoint,
    revocation_data: RevocationData,
    secret_key: SecretKey,
    cell_collector: &mut DefaultCellCollector,
) -> Result<TransactionView, Box<dyn std::error::Error>> {
    let empty_witness_args = [16, 0, 0, 0, 16, 0, 0, 0, 16, 0, 0, 0, 16, 0, 0, 0];
    let witness = [
        empty_witness_args.to_vec(),
        vec![0xFF],
        revocation_data.commitment_number.to_be_bytes().to_vec(),
        revocation_data.x_only_aggregated_pubkey.to_vec(),
        revocation_data.aggregated_signature.serialize().to_vec(),
    ]
    .concat();

    let pubkey = PublicKey::from_secret_key(&Secp256k1::new(), &secret_key);
    let args = blake160(pubkey.serialize().as_ref());
    let fee_provider_lock_script = get_script_by_contract(Contract::Secp256k1Lock, args.as_bytes());

    let change_output = CellOutput::new_builder()
        .lock(fee_provider_lock_script.clone())
        .build();
    let change_output_occupied_capacity = change_output
        .occupied_capacity(Capacity::shannons(0))
        .expect("capacity does not overflow")
        .as_u64();
    let placeholder_witness = WitnessArgs::new_builder()
        .lock(Some(ckb_types::bytes::Bytes::from(vec![0u8; 65])).pack())
        .build();

    let mut tx_builder = Transaction::default()
        .as_advanced_builder()
        .cell_deps(get_cell_deps(
            vec![Contract::CommitmentLock, Contract::Secp256k1Lock],
            &revocation_data.output.type_().to_opt(),
        ))
        .input(
            CellInput::new_builder()
                .previous_output(commitment_tx_out_point)
                .build(),
        )
        .output(revocation_data.output.clone())
        .output_data(revocation_data.output_data)
        .witness(witness.pack())
        .output(change_output.clone())
        .output_data(Bytes::default())
        .witness(placeholder_witness.as_bytes().pack());

    // TODO: move it to config or use https://github.com/nervosnetwork/ckb/pull/4477
    let fee_calculator = FeeCalculator::new(1000);

    let mut query = CellQueryOptions::new_lock(fee_provider_lock_script);
    query.script_search_mode = Some(SearchMode::Exact);
    query.secondary_script_len_range = Some(ValueRangeOption::new_exact(0));
    query.data_len_range = Some(ValueRangeOption::new_exact(0));
    let (cells, _total_capacity) = cell_collector.collect_live_cells(&query, true)?;

    let mut inputs_capacity = 0u64;
    for cell in cells {
        let input_capacity: u64 = cell.output.capacity().unpack();
        inputs_capacity += input_capacity;
        tx_builder = tx_builder.input(
            CellInput::new_builder()
                .previous_output(cell.out_point)
                .build(),
        );
        let fee =
            fee_calculator.fee(tx_builder.clone().build().data().serialized_size_in_block() as u64);
        if inputs_capacity >= change_output_occupied_capacity + fee {
            let new_change_output = change_output
                .as_builder()
                .capacity((inputs_capacity - fee).pack())
                .build();
            let tx = tx_builder
                .set_outputs(vec![revocation_data.output, new_change_output])
                .build();

            let tx = sign_tx(tx, secret_key)?;
            return Ok(tx);
        }
    }

    Err(Box::new(RpcError::Other(anyhow!("Not enough capacity"))))
}

fn try_settle_commitment_tx(
    commitment_lock: Script,
    ckb_client: CkbRpcClient,
    settlement_data: SettlementData,
    secret_key: SecretKey,
    cell_collector: &mut DefaultCellCollector,
) {
    let current_epoch = match ckb_client.get_tip_header() {
        Ok(tip_header) => {
            let tip_header: HeaderView = tip_header.into();
            tip_header.epoch()
        }
        Err(err) => {
            error!("Failed to get tip header: {:?}", err);
            return;
        }
    };

    let lock_args = commitment_lock.args().raw_data();
    let script = commitment_lock
        .as_builder()
        .args(lock_args[0..36].to_vec().pack())
        .build();
    let search_key = SearchKey {
        script: script.into(),
        script_type: ScriptType::Lock,
        script_search_mode: Some(SearchMode::Prefix),
        with_data: None,
        filter: None,
        group_by_transaction: None,
    };
    // the live cells number should be 1 or 0 for normal case, however, an attacker may create a lot of cells to implement a tx pinning attack.
    match ckb_client.get_cells(search_key, Order::Desc, 100u32.into(), None) {
        Ok(cells) => {
            for cell in cells.objects {
                let cell_output: CellOutput = cell.output.into();
                let commitment_tx_out_point =
                    OutPoint::new(cell.out_point.tx_hash.pack(), cell.out_point.index.value());
                let lock_script_args = cell_output.lock().args().raw_data();
                let since = u64::from_le_bytes(
                    lock_script_args[20..28].try_into().expect("u64 from slice"),
                );
                let header: HeaderView = match ckb_client.get_header_by_number(cell.block_number) {
                    Ok(Some(header)) => header.into(),
                    Ok(None) => {
                        error!("Cannot find header: {}", cell.block_number);
                        continue;
                    }
                    Err(err) => {
                        error!("Failed to get header: {:?}", err);
                        continue;
                    }
                };
                let since_epoch = EpochNumberWithFraction::from_full_value(since);
                if header.epoch().to_rational() + since_epoch.to_rational()
                    > current_epoch.to_rational()
                {
                    continue;
                }
                info!(
                    "Found a force closed commitment tx: {:#x}",
                    cell.out_point.tx_hash
                );
                match build_settlement_tx(
                    commitment_tx_out_point,
                    since,
                    settlement_data.clone(),
                    secret_key,
                    cell_collector,
                ) {
                    Ok(tx) => match ckb_client.send_transaction(tx.data().into(), None) {
                        Ok(tx_hash) => {
                            info!("Settlement tx: {:?} sent, tx_hash: {:#x}", tx, tx_hash);
                        }
                        Err(err) => {
                            error!("Failed to send settlement tx: {:?}, error: {:?}", tx, err);
                        }
                    },
                    Err(err) => {
                        error!("Failed to build settlement tx: {:?}", err);
                    }
                }
            }
        }
        Err(err) => {
            error!("Failed to get cells: {:?}", err);
        }
    }
}

fn build_settlement_tx(
    commitment_tx_out_point: OutPoint,
    since: u64,
    settlement_data: SettlementData,
    secret_key: SecretKey,
    cell_collector: &mut DefaultCellCollector,
) -> Result<TransactionView, Box<dyn std::error::Error>> {
    // TODO use 0x00 ~ 0xFD to get back the funds
    let pubkey = PublicKey::from_secret_key(&Secp256k1::new(), &secret_key);
    let args = blake160(pubkey.serialize().as_ref());
    let fee_provider_lock_script = get_script_by_contract(Contract::Secp256k1Lock, args.as_bytes());

    let change_output = CellOutput::new_builder()
        .lock(fee_provider_lock_script.clone())
        .build();
    let change_output_occupied_capacity = change_output
        .occupied_capacity(Capacity::shannons(0))
        .expect("capacity does not overflow")
        .as_u64();
    let placeholder_witness = WitnessArgs::new_builder()
        .lock(Some(ckb_types::bytes::Bytes::from(vec![0u8; 65])).pack())
        .build();

    let SettlementData {
        x_only_aggregated_pubkey,
        aggregated_signature,
        to_local_output,
        to_local_output_data,
        to_remote_output,
        to_remote_output_data,
    } = settlement_data;

    let mut tx_builder = Transaction::default()
        .as_advanced_builder()
        .cell_deps(get_cell_deps(
            vec![Contract::CommitmentLock, Contract::Secp256k1Lock],
            &to_local_output.type_().to_opt(),
        ))
        .input(
            CellInput::new_builder()
                .previous_output(commitment_tx_out_point)
                .since(since.pack())
                .build(),
        )
        .output(to_local_output.clone())
        .output_data(to_local_output_data)
        .output(to_remote_output.clone())
        .output_data(to_remote_output_data)
        .output(change_output.clone())
        .output_data(Bytes::default())
        .witness(
            create_witness_for_commitment_cell(x_only_aggregated_pubkey, aggregated_signature)
                .pack(),
        )
        .witness(placeholder_witness.as_bytes().pack());

    // TODO: move it to config or use https://github.com/nervosnetwork/ckb/pull/4477
    let fee_calculator = FeeCalculator::new(1000);

    let mut query = CellQueryOptions::new_lock(fee_provider_lock_script);
    query.script_search_mode = Some(SearchMode::Exact);
    query.secondary_script_len_range = Some(ValueRangeOption::new_exact(0));
    query.data_len_range = Some(ValueRangeOption::new_exact(0));
    let (cells, _total_capacity) = cell_collector.collect_live_cells(&query, true)?;

    let mut inputs_capacity = 0u64;
    for cell in cells {
        let input_capacity: u64 = cell.output.capacity().unpack();
        inputs_capacity += input_capacity;
        tx_builder = tx_builder.input(
            CellInput::new_builder()
                .previous_output(cell.out_point)
                .build(),
        );
        let fee =
            fee_calculator.fee(tx_builder.clone().build().data().serialized_size_in_block() as u64);
        if inputs_capacity >= change_output_occupied_capacity + fee {
            let new_change_output = change_output
                .as_builder()
                .capacity((inputs_capacity - fee).pack())
                .build();
            let outputs = vec![to_local_output, to_remote_output, new_change_output];
            let tx = tx_builder.set_outputs(outputs).build();
            let tx = sign_tx(tx, secret_key)?;
            return Ok(tx);
        }
    }

    Err(Box::new(RpcError::Other(anyhow!("Not enough capacity"))))
}

fn sign_tx(
    tx: TransactionView,
    secret_key: SecretKey,
) -> Result<TransactionView, Box<dyn std::error::Error>> {
    let tx = tx.data();
    let witness = tx.witnesses().get(1).expect("get witness at index 1");
    let mut blake2b = new_blake2b();
    blake2b.update(tx.calc_tx_hash().as_slice());
    blake2b.update(&(witness.item_count() as u64).to_le_bytes());
    blake2b.update(&witness.raw_data());
    let mut message = vec![0u8; 32];
    blake2b.finalize(&mut message);
    let secp256k1_message = Message::from_digest_slice(&message)?;
    let secp256k1 = Secp256k1::new();
    let signature = secp256k1.sign_ecdsa_recoverable(&secp256k1_message, &secret_key);
    let (recov_id, data) = signature.serialize_compact();
    let mut signature_bytes = [0u8; 65];
    signature_bytes[0..64].copy_from_slice(&data[0..64]);
    signature_bytes[64] = recov_id.to_i32() as u8;

    let witness = WitnessArgs::new_builder()
        .lock(Some(ckb_types::bytes::Bytes::from(signature_bytes.to_vec())).pack())
        .build();
    let witnesses = vec![
        tx.witnesses().get(0).expect("get witness at index 0"),
        witness.as_bytes().pack(),
    ];

    Ok(tx.as_advanced_builder().set_witnesses(witnesses).build())
}


================================================
File: src/watchtower/mod.rs
================================================
mod actor;
mod store;

pub use actor::{WatchtowerActor, WatchtowerMessage, DEFAULT_WATCHTOWER_CHECK_INTERVAL_SECONDS};
pub use store::{ChannelData, WatchtowerStore};


================================================
File: src/watchtower/store.rs
================================================
use ckb_types::packed::Script;
use serde::{Deserialize, Serialize};
use serde_with::serde_as;

use crate::fiber::{
    channel::{RevocationData, SettlementData},
    serde_utils::EntityHex,
    types::Hash256,
};

pub trait WatchtowerStore {
    /// Get the channels that are currently being watched by the watchtower
    fn get_watch_channels(&self) -> Vec<ChannelData>;
    /// Insert a channel's funding tx lock script into the store, it will be used to monitor the channel,
    /// please note that the lock script should be globally unique, so that the watchtower can identify the channel.
    fn insert_watch_channel(
        &self,
        channel_id: Hash256,
        funding_tx_lock: Script,
        remote_settlement_data: SettlementData,
    );
    /// Remove a channel from the store, the watchtower will stop monitoring the channel
    fn remove_watch_channel(&self, channel_id: Hash256);
    /// Update the revocation data of a channel, the watchtower will use this data to revoke an old version commitment transaction and settle the remote commitment transaction of a force closed channel
    fn update_revocation(
        &self,
        channel_id: Hash256,
        revocation_data: RevocationData,
        remote_settlement_data: SettlementData,
    );
    /// Update the settlement data of a channel, the watchtower will use this data to settle the local commitment transaction of a force closed channel
    fn update_local_settlement(&self, channel_id: Hash256, local_settlement_data: SettlementData);
}

/// The data of a channel that the watchtower is monitoring
#[serde_as]
#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]
pub struct ChannelData {
    pub channel_id: Hash256,
    #[serde_as(as = "EntityHex")]
    pub funding_tx_lock: Script,
    pub remote_settlement_data: SettlementData,
    pub local_settlement_data: Option<SettlementData>,
    pub revocation_data: Option<RevocationData>,
}


================================================
File: tests/bruno/bruno.json
================================================
{
  "version": "1",
  "name": "fnn",
  "type": "collection"
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/README.md
================================================


```markdown
node1 ---> node2 ---> node3

seq node  rpc
1   node1 connect_peer(node2)
2   node2 connect_peer(node3)
3   node1 open_channel(node2, 200 CKB) auto accept? channel1
4   node2 open_channel(node3, 100 CKB) auto accept? channel2
5   node3 generate 0.1 CKB invoice, which includes payment_hash
6   node1 add_tlc(channel1, tlc_id, 0.1 CKB payment_hash, expiry)
7   node2 add_tlc(channel2, tlc_id, 0.1 CKB payment_hash, expiry)
8   node3 remove_tlc(channel2, RemoveTlcFulfill(payment_preimage))
9   node2 remove_tlc(channel1, RemoveTlcFulfill(payment_preimage))
repeat 5 ~ 9 with different amount
10  node3 close_channel(channel2)
11  node2 close_channel(channel1)
```

verify node1, node2, node3 balance by checking on-chain final close tx


================================================
File: tests/bruno/e2e/3-nodes-transfer/01-node1-connect-node2.bru
================================================
meta {
  name: connect peer
  type: http
  seq: 1
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "connect_peer",
    "params": [
      {"address": "{{NODE1_ADDR}}"}
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Dialing a peer is async in tentacle. Sleep for some time to make sure
  // we're connected to the peer.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/02-node2-connect-node3.bru
================================================
meta {
  name: connect peer
  type: http
  seq: 2
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "connect_peer",
    "params": [
      {"address": "{{NODE2_ADDR}}"}
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Dialing a peer is async in tentacle. Sleep for some time to make sure
  // we're connected to the peer.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/03-node1-node2-open-channel.bru
================================================
meta {
  name: Node1 open a channel to Node2
  type: http
  seq: 3
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}",
        "funding_amount": "0x377aab54d000"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 2000));
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/04-node2-get-auto-accepted-channel.bru
================================================
meta {
  name: get auto accepted channel id from Node2
  type: http
  seq: 4
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE1_PEERID}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  console.log(res.body.result);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 2000));
  bru.setVar("N1N2_CHANNEL_ID", res.body.result.channels[0].channel_id);
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/06-ckb-generate-blocks.bru
================================================
meta {
  name: generate a few epochs for channel 1
  type: http
  seq: 6
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x2"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/07-node2-node3-open-channel.bru
================================================
meta {
  name: Node2 open a channel to Node3
  type: http
  seq: 7
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE3_PEERID}}",
        "funding_amount": "0x377aab54d000"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 2000));
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/08-node3-get-auto-accepted-channel.bru
================================================
meta {
  name: get auto accepted channel id from Node3
  type: http
  seq: 8
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  console.log(res.body.result);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 2000));
  bru.setVar("N2N3_CHANNEL_ID", res.body.result.channels[0].channel_id);
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/10-ckb-generate-blocks.bru
================================================
meta {
  name: generate a few epochs for channel 2
  type: http
  seq: 10
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x2"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/10-node2-list-channels.bru
================================================
meta {
  name: get channels from node2
  type: http
  seq: 10
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE3_PEERID}}"
      }
    ]
  }
}

script:pre-request {
  await new Promise(r => setTimeout(r, 1000));
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 1000));
  console.log("list channels: ", res.body.result.channels[0]);
  if (res.body.result.channels[0].remote_balance != "0x0" || res.body.result.channels[0].local_balance != "0x377939c85200") {
    throw new Error("Assertion failed: channel amount is not right");
  }
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/11-node3-gen-invoice.bru
================================================
meta {
  name: generate a invoice
  type: http
  seq: 11
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "new_invoice",
    "params": [
      {
        "amount": "0x613ae6500",
        "currency": "Fibd",
        "description": "test invoice generated by node3",
        "expiry": "0xe10",
        "final_expiry_delta": "0xDFFA0",
        "payment_preimage": "{{payment_preimage}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:pre-request {
  // generate random preimage
  function generateRandomPreimage() {
    let hash = '0x';
    for (let i = 0; i < 64; i++) {
        hash += Math.floor(Math.random() * 16).toString(16);
    }
    return hash;
  }
  const payment_preimage = generateRandomPreimage();
  bru.setVar("payment_preimage", payment_preimage);
  let hash_algorithm = bru.getEnvVar("HASH_ALGORITHM");
  if (hash_algorithm !== null) {
    let body = req.getBody();
    body.params[0].hash_algorithm = hash_algorithm;
    req.setBody(body);
  }
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("generated result: ", res.body.result);
  bru.setVar("payment_hash", res.body.result.invoice.data.payment_hash);
  bru.setVar("payment_amount", res.body.result.invoice.amount);
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/12-node1-add-tlc.bru
================================================
meta {
  name: Node1 add tlc
  type: http
  seq: 12
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "add_tlc",
    "params": [
      {
        "channel_id": "{{N1N2_CHANNEL_ID}}",
        "amount": "{{payment_amount}}",
        "payment_hash": "{{payment_hash}}",
        "expiry": "{{expiry}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.tlc_id: isDefined
}

script:pre-request {
  let expiry = "0x" + (Date.now() + 1000 * 60 * 60 * 24).toString(16);
  bru.setVar("expiry", expiry);

  let hash_algorithm = bru.getEnvVar("HASH_ALGORITHM");
  if (hash_algorithm !== null) {
    let body = req.getBody();
    body.params[0].hash_algorithm = hash_algorithm;
    req.setBody(body);
  }
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  bru.setVar("N1N2_TLC_ID1", res.body.result.tlc_id);
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/13-node2-add-tlc.bru
================================================
meta {
  name: Node2 add tlc
  type: http
  seq: 13
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "add_tlc",
    "params": [
      {
        "channel_id": "{{N2N3_CHANNEL_ID}}",
        "amount": "{{payment_amount}}",
        "payment_hash": "{{payment_hash}}",
        "expiry": "{{expiry}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.tlc_id: isDefined
}

script:pre-request {
  let expiry = "0x" + (Date.now() + 1000 * 60 * 60 * 24).toString(16);
  bru.setVar("expiry", expiry);

  let hash_algorithm = bru.getEnvVar("HASH_ALGORITHM");
  if (hash_algorithm !== null) {
    let body = req.getBody();
    body.params[0].hash_algorithm = hash_algorithm;
    req.setBody(body);
  }
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 1000));
  bru.setVar("N2N3_TLC_ID1", res.body.result.tlc_id);
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/14-node3-get-invoice.bru
================================================
meta {
  name: get invoice
  type: http
  seq: 14
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "get_invoice",
    "params": [
      {
        "payment_hash": "{{payment_hash}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("generated result: ", res.body);
  if (res.body.result.status != "Paid") {
    throw new Error("Assertion failed: status expected to be Paid");
  }
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/14-node3-remove-tlc.bru
================================================
meta {
  name: remove tlc from NODE3, Node3 auto remove tlc with preimage
  type: http
  seq: 14
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "remove_tlc",
    "params": [
      {
        "channel_id": "{{N2N3_CHANNEL_ID}}",
        "tlc_id": "{{N2N3_TLC_ID1}}",
        "reason": {
          "payment_preimage": "{{payment_preimage}}"
        }
      }
    ]
  }
}

assert {
  res.body.error: isDefined
  res.body.result: isUndefined
}

script:pre-request {
  // waiting auto remove tlc is finished
  await new Promise(r => setTimeout(r, 2000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("remove tlc result: ", res.body);
  if (!(res.body.error.message.includes("Trying to remove non-existing tlc with id"))) {
    throw new Error("Assertion failed: error message is not right");
  }

}


================================================
File: tests/bruno/e2e/3-nodes-transfer/15-node2-remove-tlc.bru
================================================
meta {
  name: remove tlc from NODE2
  type: http
  seq: 15
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "remove_tlc",
    "params": [
      {
        "channel_id": "{{N1N2_CHANNEL_ID}}",
        "tlc_id": "{{N1N2_TLC_ID1}}",
        "reason": {
          "payment_preimage": "{{payment_preimage}}"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/16-node3-gen-invoice.bru
================================================
meta {
  name: generate a invoice
  type: http
  seq: 16
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "new_invoice",
    "params": [
      {
        "amount": "0x867ba4900",
        "currency": "Fibd",
        "description": "test invoice generated by node3",
        "expiry": "0xe10",
        "final_expiry_delta": "0xDFFA0",
        "payment_preimage": "{{payment_preimage}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:pre-request {
  // generate random preimage
  function generateRandomPreimage() {
    let hash = '0x';
    for (let i = 0; i < 64; i++) {
        hash += Math.floor(Math.random() * 16).toString(16);
    }
    return hash;
  }
  const payment_preimage = generateRandomPreimage();
  bru.setVar("payment_preimage", payment_preimage);
  let hash_algorithm = bru.getEnvVar("HASH_ALGORITHM");
  if (hash_algorithm !== null) {
    let body = req.getBody();
    body.params[0].hash_algorithm = hash_algorithm;
    req.setBody(body);
  }
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("generated result: ", res.body.result);
  bru.setVar("payment_hash", res.body.result.invoice.data.payment_hash);
  bru.setVar("payment_amount", res.body.result.invoice.amount);
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/17-node1-add-tlc.bru
================================================
meta {
  name: Node1 add tlc
  type: http
  seq: 17
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "add_tlc",
    "params": [
      {
        "channel_id": "{{N1N2_CHANNEL_ID}}",
        "amount": "{{payment_amount}}",
        "payment_hash": "{{payment_hash}}",
        "expiry": "{{expiry}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.tlc_id: isDefined
}

script:pre-request {
  let expiry = "0x" + (Date.now() + 1000 * 60 * 60 * 24).toString(16);
  bru.setVar("expiry", expiry);

  let hash_algorithm = bru.getEnvVar("HASH_ALGORITHM");
  if (hash_algorithm !== null) {
    let body = req.getBody();
    body.params[0].hash_algorithm = hash_algorithm;
    req.setBody(body);
  }
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  bru.setVar("N1N2_TLC_ID2", res.body.result.tlc_id);
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/18-node2-add-tlc.bru
================================================
meta {
  name: Node2 add tlc
  type: http
  seq: 18
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "add_tlc",
    "params": [
      {
        "channel_id": "{{N2N3_CHANNEL_ID}}",
        "amount": "{{payment_amount}}",
        "payment_hash": "{{payment_hash}}",
        "expiry": "{{expiry}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.tlc_id: isDefined
}

script:pre-request {
  let expiry = "0x" + (Date.now() + 1000 * 60 * 60 * 24).toString(16);
  bru.setVar("expiry", expiry);

  let hash_algorithm = bru.getEnvVar("HASH_ALGORITHM");
  if (hash_algorithm !== null) {
    let body = req.getBody();
    body.params[0].hash_algorithm = hash_algorithm;
    req.setBody(body);
  }
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  bru.setVar("N2N3_TLC_ID2", res.body.result.tlc_id);
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/19-node3-remove-tlc.bru
================================================
meta {
  name: Node2 remove tlc
  type: http
  seq: 19
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "remove_tlc",
    "params": [
      {
        "channel_id": "{{N2N3_CHANNEL_ID}}",
        "tlc_id": "{{N2N3_TLC_ID2}}",
        "reason": {
          "payment_preimage": "{{payment_preimage}}"
        }
      }
    ]
  }
}

assert {
  res.body.error: isDefined
  res.body.result: isUndefined
}

script:pre-request {
  // waiting auto remove tlc is finished
  await new Promise(r => setTimeout(r, 2000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
    if (!(res.body.error.message.includes("Trying to remove non-existing tlc with id"))) {
    throw new Error("Assertion failed: error message is not right");
  }
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/20-node2-remove-tlc.bru
================================================
meta {
  name: Node1 remove tlc
  type: http
  seq: 19
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "remove_tlc",
    "params": [
      {
        "channel_id": "{{N1N2_CHANNEL_ID}}",
        "tlc_id": "{{N1N2_TLC_ID2}}",
        "reason": {
          "payment_preimage": "{{payment_preimage}}"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/20-node3-list-channels.bru
================================================
meta {
  name: get channels from node3
  type: http
  seq: 20
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}"
      }
    ]
  }
}

script:pre-request {
  await new Promise(r => setTimeout(r, 3000));
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 1000));
  console.log("step 20 list channels: ", res.body.result.channels[0]);
  // node1 original balance is: 60993800000000 (0x377939c85200)
  // step 13: 26100000000
  // step 18: 36100000000
  // sum is: 62200000000 (0xe7b68ae00)
  if (res.body.result.channels[0].local_balance != "0xe7b68ae00" || res.body.result.channels[0].remote_balance != "0x376abe5fa400") {
    throw new Error("Assertion failed: channel amount is not right");
  }
  if (res.body.result.channels[0].state.state_name != "CHANNEL_READY") {
    throw new Error("Assertion failed: channel status is not right");
  }
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/21-node1-send-shutdown-channel-1.bru
================================================
meta {
  name: Node1 send shutdown channel1
  type: http
  seq: 21
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "shutdown_channel",
    "params": [
      {
        "channel_id": "{{N1N2_CHANNEL_ID}}",
        "close_script": {
          "code_hash": "0x2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a",
          "hash_type": "data",
          "args": "0x0101010101010101010101010101010101010101"
        },
        "fee_rate": "0x3FC"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
}


================================================
File: tests/bruno/e2e/3-nodes-transfer/23-node2-send-shutdown-channel-2.bru
================================================
meta {
  name: Node2 send shutdown
  type: http
  seq: 23
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "shutdown_channel",
    "params": [
      {
        "channel_id": "{{N2N3_CHANNEL_ID}}",
        "close_script": {
          "code_hash": "0x2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a",
          "hash_type": "data",
          "args": "0x0101010101010101010101010101010101010101"
        },
        "fee_rate": "0x3FC"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
}


================================================
File: tests/bruno/e2e/cross-chain-hub/README.md
================================================
# Cross-Chain Hub

## Roles

- Bitcoin user: lnd node lnd-bob
- CKB user: FNN 1
- Cross-Chain Hub service provider: lnd node lnd-ingrid and FNN 3

## Run Locally

1. Install [bitcoind](https://bitcoin.org/en/download), [lnd](https://github.com/lightningnetwork/lnd), and [jq](https://jqlang.github.io/jq/download/). Ensure that the executables are in your PATH.
2. Start Bitcoin and LND nodes using `tests/deploy/lnd-init/setup-lnd.sh`.
3. Start CKB and FNN using `tests/nodes/start.sh`.
4. Go to `tests/bruno` and run the command `npm exec -- @usebruno/cli run e2e/cross-chain-hub -r --env test`.


================================================
File: tests/bruno/e2e/cross-chain-hub/01-add-btc-invoice.bru
================================================
meta {
  name: 01-add-btc-invoice
  type: http
  seq: 1
}

post {
  url: {{LND_BOB_RPC_URL}}/v1/invoices
  body: json
  auth: none
}

body:json {
  {"value":20000}
}

assert {
  res.status: eq 200
}

script:post-response {
  bru.setVar("BTC_PAY_REQ", res.body.payment_request);
  const payment_hash = Buffer.from(res.body.r_hash, 'base64').toString('hex');
  console.log(payment_hash);
  bru.setVar("PAYMENT_HASH", `0x${payment_hash}`);
}

docs {
  BTC user generates an invoice via lnd.
}


================================================
File: tests/bruno/e2e/cross-chain-hub/02-create-send-btc-order.bru
================================================
meta {
  name: 02-create-send-btc-order
  type: http
  seq: 2
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_btc",
    "params": [
      {
        "btc_pay_req": "{{BTC_PAY_REQ}}",
        "currency": "Fibt"
      }
    ]
  }
}

assert {
  res.status: eq 200
  res.body.error: isUndefined
}

script:post-response {
  if (res.body.result) {
    bru.setVar("CKB_PAY_REQ", res.body.result.ckb_pay_req);
    console.log(res.body.result.payment_hash);
  }
}

docs {
  CKB user sends the received BTC invoice to the cross-chain hub to exchange a CKB invoice.
}


================================================
File: tests/bruno/e2e/cross-chain-hub/03-node1-connect-node3.bru
================================================
meta {
  name: 03-node1-connect-node3
  type: http
  seq: 3
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}
body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "connect_peer",
    "params": [
      {"address": "{{NODE3_ADDR}}"}
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Dialing a peer is async in tentacle. Sleep for some time to make sure
  // we're connected to the peer.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/cross-chain-hub/04-node1-open-channel-to-node3.bru
================================================
meta {
  name: 04-node1-open-channel-to-node3
  type: http
  seq: 4
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE3_PEERID}}",
        "funding_amount": "0xc350",
        "funding_udt_type_script": {
          "code_hash": "{{UDT_CODE_HASH}}",
          "hash_type": "data1",
          "args": "0x32e555f3ff8e135cece1351a6a2971518392c1e30375c1e006ad0ce8eac07947"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 1000));
  console.log("N1N3 response: ", res.body);
  console.log("N1N3 response: ", res.body.result.temporary_channel_id);
  bru.setVar("N1N3_TEMP_CHANNEL_ID", res.body.result.temporary_channel_id);
}


================================================
File: tests/bruno/e2e/cross-chain-hub/05-node3-accept-channel.bru
================================================
meta {
  name: 05-node3-accept-channel
  type: http
  seq: 5
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE1_PEERID}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 2000));
  console.log("accept channel result: ", res.body);
  bru.setVar("N1N3_CHANNEL_ID", res.body.result.channels[0].channel_id);
}


================================================
File: tests/bruno/e2e/cross-chain-hub/06-ckb-generate-blocks.bru
================================================
meta {
  name: 06-ckb-generate-blocks
  type: http
  seq: 6
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x2"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/cross-chain-hub/07-node1-add-tlc.bru
================================================
meta {
  name: 07-node1-add-tlc
  type: http
  seq: 7
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "add_tlc",
    "params": [
      {
        "channel_id": "{{N1N3_CHANNEL_ID}}",
        "amount": "0x4e20",
        "payment_hash": "{{PAYMENT_HASH}}",
        "expiry": "{{expiry}}",
        "hash_algorithm": "sha256"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.tlc_id: isDefined
}

script:pre-request {
  let expiry = "0x" + (Date.now() + 1000 * 60 * 60 * 24).toString(16);
  bru.setVar("expiry", expiry);
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("response from node1 AddTlc:", res.body);
  bru.setVar("N1N3_TLC_ID1", res.body.result.tlc_id);
}


================================================
File: tests/bruno/e2e/cross-chain-hub/08-check-btc-received.bru
================================================
meta {
  name: 08-check-btc-received
  type: http
  seq: 8
}

get {
  url: {{LND_BOB_RPC_URL}}/v1/balance/channels
  body: none
  auth: none
}

vars:post-response {
  max_iterations: 10
}

assert {
  res.status: eq 200
}

script:pre-request {
  if(bru.getVar("iteration") === undefined){
    bru.setVar("iteration", 0);
  }
}

script:post-response {
  const i = bru.getVar("iteration");
  const n = bru.getVar("max_iterations");
  if (i < n) {
    console.log(`Try ${i+1}/${n}`);
  }

  if (parseInt(res.body.local_balance.sat, 10) > 0) {
    console.log("Bob has received the payment");
    bru.setVar("iteration", 0);
  } else if (i+1 < n) {
    await new Promise(r => setTimeout(r, 100));
    bru.setVar("iteration", i + 1);
    bru.setNextRequest("08-check-btc-received");
  } else {
    bru.setVar("iteration", 0);
    throw new Error("Bob has not received the payment");
  }
}


================================================
File: tests/bruno/e2e/cross-chain-hub/09-create-receive-btc-order.bru
================================================
meta {
  name: 09-create-receive-btc-order
  type: http
  seq: 9
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "receive_btc",
    "params": [
      {
        "payment_hash": "{{PAYMENT_HASH}}",
        "channel_id": "{{N1N3_CHANNEL_ID}}",
        "amount_sats": "0x1",
        "final_tlc_expiry": "0x3c"
      }
    ]
  }
}

assert {
  res.status: eq 200
  res.body.error: isUndefined
}

script:pre-request {
  const uuid = require('uuid');
  const CryptoJS = require("crypto-js");

  const preimage = CryptoJS.SHA256(uuid.v4());
  const hash = CryptoJS.SHA256(preimage);
  console.log(preimage.toString(CryptoJS.enc.Hex));
  console.log(hash.toString(CryptoJS.enc.Hex));

  bru.setVar("PAYMENT_HASH", `0x${hash.toString(CryptoJS.enc.Hex)}`);
  bru.setVar("PAYMENT_PREIMAGE", `0x${preimage.toString(CryptoJS.enc.Hex)}`);
}

script:post-response {
  if (res.body.result) {
    bru.setVar("BTC_PAY_REQ", res.body.result.btc_pay_req);
    console.log(res.body.result.payment_hash);
  }
}

docs {
  CKB user requests a BTC invoice to receive BTC from Bitcoin user.
}


================================================
File: tests/bruno/e2e/cross-chain-hub/10-pay-btc-invoice.bru
================================================
meta {
  name: 10-pay-btc-invoice
  type: http
  seq: 10
}

post {
  url: {{LND_BOB_RPC_URL}}/v2/router/send
  body: json
  auth: none
}

body:json {
  {
    "payment_request": "{{BTC_PAY_REQ}}",
    "timeout_seconds": 1
  }
}

assert {
  res.status: eq 409
}

script:pre-request {
  const axios = require('axios');

  const url = bru.getEnvVar("LND_BOB_RPC_URL") + "/v2/router/send";
  const body = {
    payment_request: bru.getVar("BTC_PAY_REQ"),
    timeout_seconds: 1
  };
  console.log(url);
  console.log(body);

  const resp = await axios({
    method: 'POST',
    url: url,
    data: body,
    responseType: 'stream'
  });
  resp.data.destroy();
}

docs {
  Send payment via lnd RPC https://lightning.engineering/api-docs/api/lnd/router/send-payment-v2.

  This is a server-streaming RPC which will block Bruno. The workaround is sending the request in the pre-script so the Bruno request will return 409 because the payment is already sent.
}


================================================
File: tests/bruno/e2e/cross-chain-hub/11-get-receive-btc-order-tlc-id.bru
================================================
meta {
  name: 11-get-receive-btc-order-tlc-id
  type: http
  seq: 11
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "get_receive_btc_order",
    "params": [
      {
        "payment_hash": "{{PAYMENT_HASH}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.status: eq 200
}

script:pre-request {
  if(bru.getVar("iteration") === undefined){
    bru.setVar("iteration", 0);
  }
}

script:post-response {
  const i = bru.getVar("iteration");
  const n = bru.getVar("max_iterations");
  if (i < n) {
    console.log(`Try ${i+1}/${n}`);
  }

  if (res.body.result.tlc_id !== null) {
    bru.setVar("N3N1_TLC_ID1", res.body.result.tlc_id);
    console.log(`Node 3 has sent a pending tlc: ${res.body.result.tlc_id}`);
    bru.setVar("iteration", 0);
    // wait for confirmation
    await new Promise(r => setTimeout(r, 500));
  } else if (i+1 < n) {
    await new Promise(r => setTimeout(r, 10));
    bru.setVar("iteration", i + 1);
    bru.setNextRequest("11-get-receive-btc-order-tlc-id");
  } else {
    bru.setVar("iteration", 0);
    throw new Error("Node 3 has not sent a pending tlc");
  }
}


================================================
File: tests/bruno/e2e/cross-chain-hub/12-remove-tlc-for-receive-btc-order.bru
================================================
meta {
  name: 12-remove-tlc-for-receive-btc-order
  type: http
  seq: 12
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "remove_tlc",
    "params": [
      {
        "channel_id": "{{N1N3_CHANNEL_ID}}",
        "tlc_id": "{{N3N1_TLC_ID1}}",
        "reason": {
          "payment_preimage": "{{PAYMENT_PREIMAGE}}"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}


================================================
File: tests/bruno/e2e/cross-chain-hub/13-node1-send-shutdown-channel.bru
================================================
meta {
  name: 13-node1-send-shutdown-channel
  type: http
  seq: 13
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "shutdown_channel",
    "params": [
      {
        "channel_id": "{{N1N3_CHANNEL_ID}}",
        "close_script": {
          "code_hash": "0x2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a",
          "hash_type": "data",
          "args": "0x0101010101010101010101010101010101010101"
        },
        "fee_rate": "0x3FC"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
}


================================================
File: tests/bruno/e2e/cross-chain-hub/14-node3-send-shutdown-channel.bru
================================================
meta {
  name: 14-node3-send-shutdown-channel
  type: http
  seq: 14
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "shutdown_channel",
    "params": [
      {
        "channel_id": "{{N1N3_CHANNEL_ID}}",
        "close_script": {
          "code_hash": "0x2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a",
          "hash_type": "data",
          "args": "0x0303030303030303030303030303030303030303"
        },
        "fee_rate": "0x3FC"
      }
    ]
  }
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
}


================================================
File: tests/bruno/e2e/cross-chain-hub/15-node3-list-channel.bru
================================================
meta {
  name: 15-node3-list-channel
  type: http
  seq: 15
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE1_PEERID}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
  res.body.result.channels.map(channel => channel.channel_id): notContains {{N1N3_CHANNEL_ID}}
}

================================================
File: tests/bruno/e2e/invoice-ops/1-gen-invoice.bru
================================================
meta {
  name: generate a invoice
  type: http
  seq: 1
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

script:pre-request {
  // generate random preimage
  function generateRandomPreimage() {
    let hash = '0x';
    for (let i = 0; i < 64; i++) {
        hash += Math.floor(Math.random() * 16).toString(16);
    }
    return hash;
  }
  const payment_preimage = generateRandomPreimage();
  bru.setVar("payment_preimage", payment_preimage);
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "new_invoice",
    "params": [
      {
        "amount": "0x64",
        "currency": "Fibd",
        "description": "test invoice",
        "expiry": "0xe10",
        "final_expiry_delta": "0xDFFA0",
        "payment_preimage": "{{payment_preimage}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("generated result: ", res.body.result);
  bru.setVar("INVOICE_ADDR", res.body.result.invoice_address);
  bru.setVar("INVOICE_PAYMENT_HASH", res.body.result.invoice.data.payment_hash);
}


================================================
File: tests/bruno/e2e/invoice-ops/2-gen-invoice-duplicate.bru
================================================
meta {
  name: generate duplicate invoice
  type: http
  seq: 2
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

docs {
  description: "use the same payment_preimage to generate a new invoice, expect an error"
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "new_invoice",
    "params": [
      {
        "amount": "0x64",
        "currency": "Fibd",
        "description": "test invoice",
        "expiry": "0xe10",
        "final_expiry_delta": "0xDFFA0",
        "payment_preimage": "{{payment_preimage}}"
      }
    ]
  }
}

assert {
  res.body.error: isDefined
  res.body.result: isUndefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("generated result: ", res.body.result);
}


================================================
File: tests/bruno/e2e/invoice-ops/3-invoice-decode.bru
================================================
meta {
  name: invoice decode test
  type: http
  seq: 3
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "parse_invoice",
    "params": [
      {
        "invoice": "{{INVOICE_ADDR}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("generated result: ", res.body.result);
}


================================================
File: tests/bruno/e2e/invoice-ops/4-get-invoice.bru
================================================
meta {
  name: get invoice
  type: http
  seq: 4
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "get_invoice",
    "params": [
      {
        "payment_hash": "{{INVOICE_PAYMENT_HASH}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("generated result: ", res.body);
}


================================================
File: tests/bruno/e2e/invoice-ops/5-cancel-invoice.bru
================================================
meta {
  name: cancel invoice
  type: http
  seq: 5
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "cancel_invoice",
    "params": [
      {
        "payment_hash": "{{INVOICE_PAYMENT_HASH}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("generated result: ", res.body);
  if (res.body.result.status != "Cancelled") {
    throw new Error("Assertion failed: status expected to be Cancelled");
  }
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/README.md
================================================
# E2E test for a happy path fiber network channel open and closure

Below is a complete happy path process to open, transact over and close a fiber channel.
We intend to create a [bruno](https://www.usebruno.com/) collection to execute all these operations.
The whole process is something like:

1. Connect to peer from NODE3 to NODE1
2. Send `open_channel` from NODE3 to NODE1 (thus NODE3 is the opener and NODE1 the acceptor)
3. NODE1 automatically accepts channel and replies `accept_channel` message
4. NODE1 sends a `tx_update` to NODE3 add input1 with 100000000000 ckb to inputs, and outputs 50000000000 to the funding transaction.
5. NODE3 adds input2 with 200000000000 ckb to tx1 and sends a `tx_update` to NODE1, and fund the channel with 100000000000 ckb (so now we have 150000000000 ckb in the funding output).
6. NODE1 remove input1 from tx2 and add input3 to tx2 with the balance of funding transaction output unchanged.
7. NODE3 sends a `tx_complete` to NODE1 to express his intention of complete the funding process
8. NODE1 sends a `tx_complete` to NODE3 to express his intention of complete the funding process
9. Both NODE1 and NODE3 send a `commitment_signed` to sign a spending transaction of the yet to exist funding transaction
10. The node with less funds in the funding transaction sends a `tx_signatures` to its counterparty
11. The counterparty replies a `tx_signatures`
12. The opener NODE3 sends a `channel_ready` to indicate the channel is ready for him
13. The acceptor waits a few blocks after the funding transaction is broadcasted and replies a `channel_ready`
14. NODE3 sends an `add_tlc` to pay NODE1 1000000000 (payment1).
15. NODE1 sends an `add_tlc` to pay NODE3 to pay 2000000000 (payment2), and then NODE3 sends 3000000000 to NODE1 (payment3).
16. NODE1 sends an `add_tlc` to pay NODE3 to pay 2000000000 (payment4), and then NODE3 sends 3000000000 to NODE1 (payment5).
17. NODE1 sends NODE3 a `remove_tlc` to complete a payment3.
18. NODE3 sends NODE1 a `remove_tlc` to fail payment2. By this time, NODE1 has 110000000000 ckb ready to use, and NODE3 has 43000000000 ckb ready to use.
19. NODE1 initiates a `shutdown` to close the channel
20. NODE3 replies a `shutdown` to acknowledge the closure of this channel
21. There are still payment1, payment4 and payment5 waiting for resolution. We remove them payment1 and payment5 by failing them from NODE1, and complete payment4 from NODE3. NODE1 has 101000000000 ckb ready to use, and NODE3 has 49000000000 ckb ready to use.
22. NODE3 and NODE1 automatically send a `closing_signed` to their counterparty on all tlc finished.

Note that the channel is opened with a delay of 3.5 epochs (14 hours), 3.5 epochs is [presented](https://github.com/nervosnetwork/rfcs/blob/master/rfcs/0017-tx-valid-since/e-i-l-encoding.png) as 3(E) and 1(I)/2(L): (L << 40) | (I << 24) | E = 0x20001000003,

## Starting nodes

```
./tests/nodes/start.sh
```

## Running tests

Currently only a few tests are implemented in [the current directory](./) as not all these functionalities are implemented.

```
cd tests/bruno
npm exec -- @usebruno/cli run e2e/open-use-close-a-channel -r --env test
```


================================================
File: tests/bruno/e2e/open-use-close-a-channel/01-connect-peer.bru
================================================
meta {
  name: connect peer
  type: http
  seq: 1
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "connect_peer",
    "params": [
      {"address": "{{NODE1_ADDR}}"}
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Dialing a peer is async in tentacle. Sleep for some time to make sure
  // we're connected to the peer.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/02-open-channel.bru
================================================
meta {
  name: Node3 open a channel to Node1
  type: http
  seq: 2
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE1_PEERID}}",
        "funding_amount": "0xba43b7400",
        "commitment_delay_epoch": "0x20001000003"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 2000));
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/03-get-auto-accepted-channel.bru
================================================
meta {
  name: get auto accepted channel id from Node1
  type: http
  seq: 3
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE3_PEERID}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
  res.body.result.channels[0].channel_outpoint: isDefined
}

script:post-response {
  console.log(res.body.result);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 2000));
  bru.setVar("CHANNEL_ID", res.body.result.channels[0].channel_id);
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/06-generate-a-few-blocks.bru
================================================
meta {
  name: generate a few epochs
  type: http
  seq: 6
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x2"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/07-add-tlc-from-NODE3.bru
================================================
meta {
  name: add tlc from NODE3
  type: http
  seq: 7
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "add_tlc",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "amount": "0x5f5e100",
        "payment_hash": "0x266cec97cbede2cfbce73666f08deed9560bdf7841a7a5a51b3a3f09da249e21",
        "expiry": "{{expiry}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.tlc_id: isDefined
}

script:pre-request {
  let expiry = "0x" + (Date.now() + 1000 * 60 * 60 * 24).toString(16);
  bru.setVar("expiry", expiry);
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  bru.setVar("TLC_ID1", res.body.result.tlc_id);
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/08-add-tlc-from-NODE1-err.bru
================================================
meta {
  name: add tlc from NODE1
  type: http
  seq: 8
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "add_tlc",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "amount": "0xbebc200",
        "payment_hash": "0xcb7bce98a778f130d34da522623d7e56705bddfe0dc4781bd2331211134a19a8",
        "expiry": "{{expiry}}"
      }
    ]
  }
}

assert {
  res.body.error: isDefined
  res.body.result: isUndefined
}

script:pre-request {
  await new Promise(r => setTimeout(r, 2000));
  let expiry = "0x" + (Date.now() + 1000 * 60 * 60 * 24).toString(16);
  bru.setVar("expiry", expiry);
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  if (res.body.error.message != "TemporaryChannelFailure") {
    throw new Error("Assertion failed: error message is not right");
  }

  // Node 1 only holds 62 CKB as reserved amount, there is no extra amount for TLC, so the request will fail.
  // Set the TLC ID into a wrong one, than step 14 will fail as expected.
  bru.setVar("TLC_ID2", "0x3200");
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/09-add-tlc-from-NODE3.bru
================================================
meta {
  name: add tlc from NODE3
  type: http
  seq: 9
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "add_tlc",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "amount": "0x11e1a300",
        "payment_hash": "0x29449e2cc6f56a691253fe88e3a378171c81573b09247010b4f1cb8c806e1e09",
        "expiry": "{{expiry}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.tlc_id: isDefined
}

script:pre-request {
  await new Promise(r => setTimeout(r, 2000));
  let expiry = "0x" + (Date.now() + 1000 * 60 * 60 * 24).toString(16);
  bru.setVar("expiry", expiry);
}

script:post-response {
  console.log("step 9 response: ", res.body);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  bru.setVar("TLC_ID3", res.body.result.tlc_id);
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/10-add-tlc-from-NODE1-amount-err.bru
================================================
meta {
  name: add tlc from NODE1
  type: http
  seq: 10
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "add_tlc",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "amount": "0x0",
        "payment_hash": "0xcb7bce98a778f130d34da522623d7e56705bddfe0dc4781bd2331211134a19a5",
        "expiry": "{{expiry}}"
      }
    ]
  }
}

assert {
  res.body.error: isDefined
  res.body.result: isUndefined
}

script:pre-request {
  await new Promise(r => setTimeout(r, 2000));
  let expiry = "0x" + (Date.now() + 1000 * 60 * 60 * 24).toString(16);
  bru.setVar("expiry", expiry);
}

script:post-response {
  console.log("step 10 response: ", res.body);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));

  if (res.body.error.message != "AmountBelowMinimum") {
    throw new Error("Assertion failed: error message is not right");
  }
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/10-add-tlc-from-NODE1-balance-err.bru
================================================
meta {
  name: add tlc from NODE1
  type: http
  seq: 10
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "add_tlc",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "amount": "0xbebc200",
        "payment_hash": "0xcb7bce98a778f130d34da522623d7e56705bddfe0dc4781bd2331211134a19a6",
        "expiry": "{{expiry}}"
      }
    ]
  }
}

assert {
  res.body.error: isDefined
  res.body.result: isUndefined
}

script:pre-request {
  let expiry = "0x" + (Date.now() + 1000 * 60 * 60 * 24).toString(16);
  bru.setVar("expiry", expiry);
}

script:post-response {
  console.log("step 10 response: ", res.body);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));

  if (res.body.error.message != "TemporaryChannelFailure") {
    throw new Error("Assertion failed: error message is not right");
  }
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/11-add-tlc-from-NODE3.bru
================================================
meta {
  name: add tlc from NODE3
  type: http
  seq: 11
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "add_tlc",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "amount": "0x11e1a300",
        "payment_hash": "0x29449e2cc6f56a691253fe88e3a378171c81573b09247010b4f1cb8c806e1e38",
        "expiry": "{{expiry}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.tlc_id: isDefined
}

script:pre-request {
  await new Promise(r => setTimeout(r, 1000));
  let expiry = "0x" + (Date.now() + 1000 * 60 * 60 * 24).toString(16);
  bru.setVar("expiry", expiry);
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  bru.setVar("TLC_ID5", res.body.result.tlc_id);
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/12-add-tlc-from-NODE3.bru
================================================
meta {
  name: add tlc from NODE3
  type: http
  seq: 12
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "add_tlc",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "amount": "0x11e1a300",
        "payment_hash": "0x29449e2cc6f56a691253fe88e3a378171c81573b09247010b4f1cb8c806e1e12",
        "expiry": "{{expiry}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.tlc_id: isDefined
}

script:pre-request {
  await new Promise(r => setTimeout(r, 2000));
  let expiry = "0x" + (Date.now() + 1000 * 60 * 60 * 24).toString(16);
  bru.setVar("expiry", expiry);
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  bru.setVar("TLC_ID6", res.body.result.tlc_id);
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/13-remove-tlc-from-NODE1.bru
================================================
meta {
  name: remove tlc from NODE1
  type: http
  seq: 13
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "remove_tlc",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "tlc_id": "{{TLC_ID1}}",
        "reason": {
          "payment_preimage": "0x0000000000000000000000000000000000000000000000000000000000000000"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:pre-request {
  await new Promise(r => setTimeout(r, 2000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/14-remove-tlc-from-NODE3.bru
================================================
meta {
  name: remove tlc from NODE3
  type: http
  seq: 14
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "remove_tlc",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "tlc_id": "{{TLC_ID2}}",
        "reason": {
          "error_code": "TemporaryNodeFailure"
        }
      }
    ]
  }
}

assert {
  res.body.error: isDefined
  res.body.result: isUndefined
}

script:pre-request {
  await new Promise(r => setTimeout(r, 2000));
}

script:post-response {
  console.log("step 14: ", res.body);
  // tlc_id2 is not added successfully, so it should not be removed successfully.
   if (!(res.body.error.message.includes("Trying to remove non-existing tlc with id"))) {
    throw new Error("Assertion failed: error message is not right");
  }

  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));

}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/15-shutdown-from-NODE1.bru
================================================
meta {
  name: send shutdown from NODE1
  type: http
  seq: 15
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "shutdown_channel",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "close_script": {
          "code_hash": "0x2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a",
          "hash_type": "data",
          "args": "0x0101010101010101010101010101010101010101"
        },
        "fee_rate": "0x3FC"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:pre-request {
  await new Promise(r => setTimeout(r, 2000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/16-remove-tlc-from-NODE1.bru
================================================
meta {
  name: remove tlc from NODE1
  type: http
  seq: 16
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "remove_tlc",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "tlc_id": "{{TLC_ID3}}",
        "reason": {
          "error_code": "TemporaryNodeFailure"
        }
      }
    ]
  }
}

script:pre-request {
  await new Promise(r => setTimeout(r, 2000));
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/17-remove-tlc-from-NODE3.bru
================================================
meta {
  name: remove tlc from NODE3
  type: http
  seq: 17
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "remove_tlc",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "tlc_id": "{{TLC_ID3}}",
        "reason": {
          "error_code": "TemporaryNodeFailure"
        }
      }
    ]
  }
}

script:pre-request {
  await new Promise(r => setTimeout(r, 2000));
}

assert {
  res.body.error: isDefined
  res.body.result: isUndefined
}

script:post-response {
    console.log("step 18: ", res.body);
  // This request is remove a TLC which already removed in previous step.
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/18-remove-tlc-from-NODE1.bru
================================================
meta {
  name: remove tlc from NODE1
  type: http
  seq: 18
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "remove_tlc",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "tlc_id": "{{TLC_ID5}}",
        "reason": {
          "payment_preimage": "0x0000000000000000000000000000000000000000000000000000000000000002"
        }
      }
    ]
  }
}

script:pre-request {
  await new Promise(r => setTimeout(r, 2000));
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/19-remove-tlc-from-NODE1.bru
================================================
meta {
  name: remove tlc from NODE1
  type: http
  seq: 19
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "remove_tlc",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "tlc_id": "{{TLC_ID6}}",
        "reason": {
          "error_code": "TemporaryNodeFailure"
        }
      }
    ]
  }
}

script:pre-request {
  await new Promise(r => setTimeout(r, 2000));
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
}


================================================
File: tests/bruno/e2e/open-use-close-a-channel/20-list-channel-from-NODE1.bru
================================================
meta {
  name: get channels from node1
  type: http
  seq: 20
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE1_PEERID}}"
      }
    ]
  }
}

script:pre-request {
  await new Promise(r => setTimeout(r, 2000));
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 1000));
  console.log("step 20 list channels: ", res.body.result.channels);
  // all channels should be closed
  if (res.body.result.channels.length != 0) {
    throw new Error("channels length is not right");
  }
}


================================================
File: tests/bruno/e2e/reestablish/01-connect-peer.bru
================================================
meta {
  name: connect peer
  type: http
  seq: 1
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "connect_peer",
    "params": [
      {"address": "{{NODE1_ADDR}}"}
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Dialing a peer is async in tentacle. Sleep for some time to make sure
  // we're connected to the peer.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/reestablish/02-open-channel.bru
================================================
meta {
  name: Node3 open a channel to Node1
  type: http
  seq: 2
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE1_PEERID}}",
        "funding_amount": "0xba43b7400"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 2000));
}


================================================
File: tests/bruno/e2e/reestablish/03-get-auto-accepted-channel.bru
================================================
meta {
  name: get auto accepted channel id from Node1
  type: http
  seq: 3
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE3_PEERID}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  console.log(res.body.result);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 2000));
  bru.setVar("CHANNEL_ID", res.body.result.channels[0].channel_id);
}


================================================
File: tests/bruno/e2e/reestablish/06-generate-a-few-blocks.bru
================================================
meta {
  name: generate a few epochs
  type: http
  seq: 6
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x2"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/reestablish/07-add-tlc-from-NODE3.bru
================================================
meta {
  name: add tlc from NODE3
  type: http
  seq: 7
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "add_tlc",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "amount": "0x5f5e100",
        "payment_hash": "0x266cec97cbede2cfbce73666f08deed9560bdf7841a7a5a51b3a3f09da249e21",
        "expiry": "{{expiry}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.tlc_id: isDefined
}

script:pre-request {
  let expiry = "0x" + (Date.now() + 1000 * 60 * 60 * 24).toString(16);
  bru.setVar("expiry", expiry);
}

script:post-response {
  bru.setVar("TLC_ID1", res.body.result.tlc_id);
}


================================================
File: tests/bruno/e2e/reestablish/08-disconnect-NODE1.bru
================================================
meta {
  name: disconnect NODE3 from NODE1
  type: http
  seq: 8
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "disconnect_peer",
    "params": [
      {"peer_id": "{{NODE3_PEERID}}"}
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/reestablish/09-reconnect-peer-NODE1.bru
================================================
meta {
  name: reconnect peer NODE3
  type: http
  seq: 9
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "connect_peer",
    "params": [
      {"address": "{{NODE3_ADDR}}"}
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Dialing a peer is async in tentacle. Sleep for some time to make sure
  // we're connected to the peer.
  await new Promise(r => setTimeout(r, 3000));
}


================================================
File: tests/bruno/e2e/reestablish/10-remove-tlc-from-NODE1.bru
================================================
meta {
  name: remove tlc from NODE1
  type: http
  seq: 10
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "remove_tlc",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "tlc_id": "{{TLC_ID1}}",
        "reason": {
          "error_code": "TemporaryNodeFailure"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // assert we can remove it without error, if we can't remove it means the reestablish failed
  // for example, if the tlc is not synced yet, it's status will not be in `Committed`, so we can't remove it

  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("remove tlc response: ", res.body);
}


================================================
File: tests/bruno/e2e/reestablish/11-shutdown-from-NODE1.bru
================================================
meta {
  name: send shutdown from NODE1
  type: http
  seq: 11
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "shutdown_channel",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "close_script": {
          "code_hash": "0x2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a",
          "hash_type": "data",
          "args": "0x0101010101010101010101010101010101010101"
        },
        "fee_rate": "0x3FC"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
}


================================================
File: tests/bruno/e2e/router-pay/01-node1-connect-node2.bru
================================================
meta {
  name: connect peer
  type: http
  seq: 1
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "connect_peer",
    "params": [
      { "address": "{{NODE1_ADDR}}" }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Dialing a peer is async in tentacle. Sleep for some time to make sure
  // we're connected to the peer.
  console.log("connect result: ", res.body.result);
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/router-pay/02-node2-connect-node3.bru
================================================
meta {
  name: connect peer
  type: http
  seq: 2
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "connect_peer",
    "params": [
      {"address": "{{NODE2_ADDR}}"}
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Dialing a peer is async in tentacle. Sleep for some time to make sure
  // we're connected to the peer.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/router-pay/03-node1-node2-open-channel.bru
================================================
meta {
  name: Node1 open a channel to Node2
  type: http
  seq: 3
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}",
        "funding_amount": "0x377aab54d000",
        "tlc_fee_proportional_millionths": "0x4B0"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 2000));
}


================================================
File: tests/bruno/e2e/router-pay/04-node2-get-auto-accepted-channel.bru
================================================
meta {
  name: get auto accepted channel id from Node2
  type: http
  seq: 4
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE1_PEERID}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  console.log(res.body.result);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 2000));
  bru.setVar("N1N2_CHANNEL_ID", res.body.result.channels[0].channel_id);
}


================================================
File: tests/bruno/e2e/router-pay/06-ckb-generate-blocks.bru
================================================
meta {
  name: generate a few epochs for channel 1
  type: http
  seq: 6
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x2"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/router-pay/07-node2-node3-open-channel.bru
================================================
meta {
  name: Node2 open a channel to Node3
  type: http
  seq: 7
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE3_PEERID}}",
        "funding_amount": "0x377aab54d000",
        "tlc_fee_proportional_millionths": "0x578"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 2000));
}


================================================
File: tests/bruno/e2e/router-pay/08-node3-get-auto-accepted-channel.bru
================================================
meta {
  name: get auto accepted channel id from Node3
  type: http
  seq: 8
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  console.log(res.body.result);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 2000));
  bru.setVar("N2N3_CHANNEL_ID", res.body.result.channels[0].channel_id);
}


================================================
File: tests/bruno/e2e/router-pay/10-ckb-generate-blocks.bru
================================================
meta {
  name: generate a few epochs for channel 2
  type: http
  seq: 10
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x2"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/router-pay/11-node2-list-channels.bru
================================================
meta {
  name: get channels from node2
  type: http
  seq: 11
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE3_PEERID}}"
      }
    ]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
  console.log("step 11 list channels: ", res.body.result.channels);
}


================================================
File: tests/bruno/e2e/router-pay/11-node2-list-graph-channels.bru
================================================
meta {
  name: get channels from node2
  type: http
  seq: 11
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "graph_channels",
    "params": [
      { }
    ]
  }
}


assert {
  res.status: eq 200
}

script:pre-request {
  await new Promise(r => setTimeout(r, 2000));
}

script:post-response {
  console.log("step 11 list graph channels: ", res.body.result.channels);
  if (res.body.result.channels.length != 2) {
    throw new Error("graph channels length is not right");
  }
}


================================================
File: tests/bruno/e2e/router-pay/11-node3-gen-invoice.bru
================================================
meta {
  name: generate a invoice
  type: http
  seq: 11
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "new_invoice",
    "params": [
      {
        "amount": "0x613ae6500",
        "currency": "Fibd",
        "description": "test invoice generated by node3",
        "expiry": "0xe10",
        "final_expiry_delta": "0xDFFA0",
        "payment_preimage": "{{payment_preimage}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:pre-request {
  // generate random preimage
  function generateRandomPreimage() {
    let hash = '0x';
    for (let i = 0; i < 64; i++) {
        hash += Math.floor(Math.random() * 16).toString(16);
    }
    return hash;
  }
  const payment_preimage = generateRandomPreimage();
  bru.setVar("payment_preimage", payment_preimage);
  let hash_algorithm = bru.getEnvVar("HASH_ALGORITHM");
  if (hash_algorithm !== null) {
    let body = req.getBody();
    body.params[0].hash_algorithm = hash_algorithm;
    req.setBody(body);
  }
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("generated result: ", res.body.result);
  bru.setVar("payment_hash", res.body.result.invoice.data.payment_hash);
  bru.setVar("payment_amount", res.body.result.invoice.amount);
}


================================================
File: tests/bruno/e2e/router-pay/12-node1-send-payment.bru
================================================
meta {
  name: Node1 send payment with router
  type: http
  seq: 12
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_payment",
    "params": [
      {
        "target_pubkey": "03032b99943822e721a651c5a5b9621043017daa9dc3ec81d83215fd2e25121187",
        "amount": "0x190",
        "payment_hash": "{{payment_hash}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("12 step result: ", res.body);
}


================================================
File: tests/bruno/e2e/router-pay/12-node1-to-get-payment-status.bru
================================================
meta {
  name: Node1 send get_payment for query status
  type: http
  seq: 12
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "get_payment",
    "params": [
      {
        "payment_hash": "{{payment_hash}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}

script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 2000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 500));
  console.log("get result: ", res.body.result);
  if (res.body.result.status != "Success") {
    throw new Error("Assertion failed: payment session status expected to be Success");
  }

}

================================================
File: tests/bruno/e2e/router-pay/13-node-send-duplicate-payment-err.bru
================================================
meta {
  name: Node1 send payment with router, since we have created a payment session for this payment, it will return error
  type: http
  seq: 13
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_payment",
    "params": [
      {
        "target_pubkey": "03032b99943822e721a651c5a5b9621043017daa9dc3ec81d83215fd2e25121187",
        "amount": "0x190",
        "payment_hash": "{{payment_hash}}"
      }
    ]
  }
}

assert {
  res.body.error: isDefined
}

script:pre-request {
  await new Promise(r => setTimeout(r, 1000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("get result: ", res.body)
}


================================================
File: tests/bruno/e2e/router-pay/13-node2-list-channels.bru
================================================
meta {
  name: get channels from node2
  type: http
  seq: 13
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE3_PEERID}}"
      }
    ]
  }
}

script:pre-request {
  await new Promise(r => setTimeout(r, 3000));
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 1000));
  console.log("step 13 list channels: ", res.body.result.channels[0]);
  if (res.body.result.channels[0].remote_balance != "0x190" || res.body.result.channels[0].local_balance != "0x377939c85070") {
    throw new Error("Assertion failed: channel amount is not right");
  }
}


================================================
File: tests/bruno/e2e/router-pay/14-node3-gen-invoice-later.bru
================================================
meta {
  name: generate a invoice
  type: http
  seq: 14
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "new_invoice",
    "params": [
      {
        "amount": "0x613",
        "currency": "Fibd",
        "description": "test invoice generated by node3",
        "expiry": "0xe10",
        "final_expiry_delta": "0xDFFA0",
        "payment_preimage": "{{payment_preimage}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:pre-request {
  // generate random preimage
  function generateRandomPreimage() {
    let hash = '0x';
    for (let i = 0; i < 64; i++) {
        hash += Math.floor(Math.random() * 16).toString(16);
    }
    return hash;
  }
  const payment_preimage = generateRandomPreimage();
  bru.setVar("payment_preimage", payment_preimage);
  let hash_algorithm = bru.getEnvVar("HASH_ALGORITHM");
  if (hash_algorithm !== null) {
    let body = req.getBody();
    body.params[0].hash_algorithm = hash_algorithm;
    req.setBody(body);
  }
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("generated result: ", res.body.result);
  bru.setVar("encoded_invoice", res.body.result.invoice_address);
}


================================================
File: tests/bruno/e2e/router-pay/15-node1-send-payment-with-invoice.bru
================================================
meta {
  name: Node1 send payment with router only with invoice
  type: http
  seq: 15
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_payment",
    "params": [
      {
        "invoice": "{{encoded_invoice}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}


script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}


script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("send payment result: ", res.body);

}


================================================
File: tests/bruno/e2e/router-pay/16-node1-get-nodes.bru
================================================
meta {
  name: Node1 send get_nodes rpc request
  type: http
  seq: 16
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "graph_nodes",
    "params": [{}]
  }
}

assert {
  res.body.error: isUndefined
}

script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("get result: ", res.body.result);
  if (res.body.result.nodes.length != 4) {
    throw new Error("Assertion failed: nodes number is not right");
  }
}


================================================
File: tests/bruno/e2e/router-pay/16-node1-send-payment-keysend.bru
================================================
meta {
  name: Node1 send payment with router in keysend mode
  type: http
  seq: 16
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_payment",
    "params": [
      {
        "target_pubkey": "03032b99943822e721a651c5a5b9621043017daa9dc3ec81d83215fd2e25121187",
        "amount": "0x1F4",
        "keysend": true
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}

script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("send payment result: ", res.body);
}


================================================
File: tests/bruno/e2e/router-pay/17-node1-get-payment-status.bru
================================================
meta {
  name: Node1 send get_payment for query status
  type: http
  seq: 17
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "get_payment",
    "params": [
      {
        "payment_hash": "{{payment_hash}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}

script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("get result: ", res.body.result);
  if (res.body.result.status != "Success") {
    throw new Error("Assertion failed: payment session status expected to be Success");
  }

}


================================================
File: tests/bruno/e2e/router-pay/18-node1-get-channels.bru
================================================
meta {
  name: Node1 send get_channels rpc request
  type: http
  seq: 18
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "graph_channels",
    "params": [
      {
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}

script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("get result: ", res.body.result);
  if (res.body.result.channels.length != 2) {
    throw new Error("Assertion failed: channels number is not right");
  }
}


================================================
File: tests/bruno/e2e/router-pay/19-node1-get-nodes-page.bru
================================================
meta {
  name: Node1 send get_nodes rpc request
  type: http
  seq: 19
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "graph_nodes",
    "params": [{
        "limit": "0x2"
    }]
  }
}

assert {
  res.body.error: isUndefined
}

script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("get result: ", res.body.result);
  if (res.body.result.nodes.length != 2) {
    throw new Error("Assertion failed: nodes number is not right");
  }
  bru.setVar("last_cursor", res.body.result.last_cursor);
}


================================================
File: tests/bruno/e2e/router-pay/20-node1-get-nodes-page-2.bru
================================================

meta {
  name: Node1 send get_nodes rpc request
  type: http
  seq: 20
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "graph_nodes",
    "params": [{
        "limit": "0x2",
        "after": "{{last_cursor}}"
    }]
  }
}

assert {
  res.body.error: isUndefined
}

script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("get result: ", res.body.result);
  if (res.body.result.nodes.length != 2) {
    throw new Error("Assertion failed: nodes number is not right");
  }
  bru.setVar("last_cursor_2", res.body.result.last_cursor);
}


================================================
File: tests/bruno/e2e/router-pay/21-node1-get-nodes-page-3.bru
================================================

meta {
  name: Node1 send get_nodes rpc request
  type: http
  seq: 21
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "graph_nodes",
    "params": [{
        "limit": "0x2",
        "after": "{{last_cursor_2}}"
    }]
  }
}

assert {
  res.body.error: isUndefined
}

script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("get result: ", res.body.result);
  if (res.body.result.nodes.length != 0) {
    throw new Error("Assertion failed: nodes number is not right");
  }
}


================================================
File: tests/bruno/e2e/router-pay/21-node2-list-channels.bru
================================================
meta {
  name: get channels from node2
  type: http
  seq: 21
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE3_PEERID}}"
      }
    ]
  }
}

script:pre-request {
  await new Promise(r => setTimeout(r, 3000));
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 1000));
  console.log("step 21 list channels: ", res.body.result.channels[0]);
  // step 12: 400
  // step 14: 1555
  // step 15: 500
  // sum is: 2455  (0x997)
  if (res.body.result.channels[0].remote_balance != "0x997" || res.body.result.channels[0].local_balance != "0x377939c84869") {
    throw new Error("Assertion failed: channel amount is not right");
  }
}


================================================
File: tests/bruno/e2e/router-pay/22-node3-gen-expiring-invoice.bru
================================================
meta {
  name: generate a invoice which will expiring in short time
  type: http
  seq: 22
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "new_invoice",
    "params": [
      {
        "amount": "0x613",
        "currency": "Fibd",
        "description": "test invoice generated by node3",
        "expiry": "0x2",
        "final_expiry_delta": "0xDFFA0",
        "payment_preimage": "{{payment_preimage}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:pre-request {
  // generate random preimage
  function generateRandomPreimage() {
    let hash = '0x';
    for (let i = 0; i < 64; i++) {
        hash += Math.floor(Math.random() * 16).toString(16);
    }
    return hash;
  }
  const payment_preimage = generateRandomPreimage();
  bru.setVar("payment_preimage", payment_preimage);
  let hash_algorithm = bru.getEnvVar("HASH_ALGORITHM");
  if (hash_algorithm !== null) {
    let body = req.getBody();
    body.params[0].hash_algorithm = hash_algorithm;
    req.setBody(body);
  }
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 3000));
  console.log("generated result: ", res.body.result);
  bru.setVar("encoded_invoice", res.body.result.invoice_address);
}


================================================
File: tests/bruno/e2e/router-pay/23-node1-send-payment-will-fail.bru
================================================
meta {
  name: Node1 send payment with router
  type: http
  seq: 23
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_payment",
    "params": [
      {
        "invoice": "{{encoded_invoice}}"
      }
    ]
  }
}

assert {
  res.body.error: isDefined
}


script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}


script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  if (!(res.body.error.message.includes("invoice is expired"))) {
    throw new Error("Assertion failed: error message is not right");
  }
}


================================================
File: tests/bruno/e2e/router-pay/24-node1-gen-invoice-for-self.bru
================================================
meta {
  name: generate a invoice
  type: http
  seq: 24
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "new_invoice",
    "params": [
      {
        "amount": "0x613ae650",
        "currency": "Fibd",
        "description": "test invoice generated by node1",
        "expiry": "0xe10",
        "final_expiry_delta": "0xDFFA0",
        "payment_preimage": "{{payment_preimage}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:pre-request {
  // generate random preimage
  function generateRandomPreimage() {
    let hash = '0x';
    for (let i = 0; i < 64; i++) {
        hash += Math.floor(Math.random() * 16).toString(16);
    }
    return hash;
  }
  const payment_preimage = generateRandomPreimage();
  bru.setVar("payment_preimage", payment_preimage);
  let hash_algorithm = bru.getEnvVar("HASH_ALGORITHM");
  if (hash_algorithm !== null) {
    let body = req.getBody();
    body.params[0].hash_algorithm = hash_algorithm;
    req.setBody(body);
  }
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  bru.setVar("payment_hash_self", res.body.result.invoice.data.payment_hash);
  console.log("generated result: ", res.body.result);
  bru.setVar("encoded_invoice_self", res.body.result.invoice_address);
}


================================================
File: tests/bruno/e2e/router-pay/25-node1-pay-self-with-node2-err.bru
================================================

meta {
  name: Node1 send payment with router
  type: http
  seq: 25
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_payment",
    "params": [
      {
        "invoice": "{{encoded_invoice_self}}",
        "allow_self_payment": true
      }
    ]
  }
}

assert {
  res.body.error: isDefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("25 step result: ", res.body);
  // for pay self router A -> B -> A, can not use the same channel from A -> B and B -> A
  if (!(res.body.error.message.includes("Failed to build route"))) {
    throw new Error("Assertion failed: error message is not right");
  }
}


================================================
File: tests/bruno/e2e/router-pay/26-node2-node1-open-channel.bru
================================================
meta {
  name: Node2 open a channel to Node1
  type: http
  seq: 26
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE1_PEERID}}",
        "funding_amount": "0x277aab54d000",
        "tlc_fee_proportional_millionths": "0x4B0"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:pre-request {
  await new Promise(r => setTimeout(r, 1000));
}

script:post-response {
  await new Promise(r => setTimeout(r, 1000));
  console.log("26 step result: ", res.body);
}


================================================
File: tests/bruno/e2e/router-pay/27-ckb-generate-blocks.bru
================================================
meta {
  name: generate a few epochs for channel 1
  type: http
  seq: 27
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x2"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/router-pay/28-node1-list-graph-channels.bru
================================================
meta {
  name: get channels from node1
  type: http
  seq: 28
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "graph_channels",
    "params": [
      { }
    ]
  }
}

assert {
  res.status: eq 200
}

script:pre-request {
  await new Promise(r => setTimeout(r, 2000));
}

script:post-response {
  console.log("list channels: ", res.body.result.channels);
  if (res.body.result.channels.length != 3) {
    throw new Error("graph channels length is not right");
  }
}


================================================
File: tests/bruno/e2e/router-pay/29-node1-pay-self-with-node2-succ.bru
================================================

meta {
  name: Node1 send payment with router
  type: http
  seq: 29
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_payment",
    "params": [
      {
        "invoice": "{{encoded_invoice_self}}",
        "allow_self_payment": true
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("29 step result: ", res.body);
  // for pay self router A -> B -> A, note A -> B and B -> A will use different channel
}


================================================
File: tests/bruno/e2e/router-pay/30-node2-list-graph-chanels.bru
================================================
meta {
  name: get channels from node2
  type: http
  seq: 30
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "graph_channels",
    "params": [
      { }
    ]
  }
}


assert {
  res.status: eq 200
}

script:pre-request {
  await new Promise(r => setTimeout(r, 2000));
}

script:post-response {
  console.log("list channels: ", res.body.result.channels);
  if (res.body.result.channels.length != 3) {
    throw new Error("graph channels length is not right");
  }
}


================================================
File: tests/bruno/e2e/router-pay/31-node1-get-payment-status.bru
================================================
meta {
  name: Node1 send get_payment for query status
  type: http
  seq: 31
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "get_payment",
    "params": [
      {
        "payment_hash": "{{payment_hash_self}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}

script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 500));
  console.log("get result: ", res.body.result);
  if (res.body.result.status != "Success") {
    throw new Error("Assertion failed: payment session status expected to be Success");
  }

}

================================================
File: tests/bruno/e2e/router-pay/32-node2-list-channels.bru
================================================
meta {
  name: get channels from node2
  type: http
  seq: 32
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE1_PEERID}}"
      }
    ]
  }
}


assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 1000));
  console.log("step 32 list graph channels: ", res.body.result.channels);
  bru.setVar("CHANNEL_ID_TO_UPDATE", res.body.result.channels[0].channel_id);
}


================================================
File: tests/bruno/e2e/router-pay/33-node2-update-channel.bru
================================================
meta {
  name: get channels from node2
  type: http
  seq: 32
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "update_channel",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID_TO_UPDATE}}",
        "tlc_fee_proportional_millionths": "0x2710"
      }
    ]
  }
}

script:pre-request {
  await new Promise(r => setTimeout(r, 3000));
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 2000));
  console.log("step 33 list channels: ", res.body.result);
}


================================================
File: tests/bruno/e2e/router-pay/34-node1-send-payment.bru
================================================
meta {
  name: Node1 send payment with router
  type: http
  seq: 34
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_payment",
    "params": [
      {
        "target_pubkey": "03032b99943822e721a651c5a5b9621043017daa9dc3ec81d83215fd2e25121187",
        "amount": "0x190",
        "keysend": true
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 2000));
  bru.setVar("payment_hash", res.body.result.payment_hash);
  console.log("33 step result: ", res.body);
}


================================================
File: tests/bruno/e2e/router-pay/35-node1-get-payment-status.bru
================================================
meta {
  name: Node1 send get_payment for query status
  type: http
  seq: 35
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "get_payment",
    "params": [
      {
        "payment_hash": "{{payment_hash}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}

script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 2000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 500));
  console.log("get result: ", res.body.result);
  if (res.body.result.status != "Success") {
    throw new Error("Assertion failed: payment session status expected to be Success");
  }

}

================================================
File: tests/bruno/e2e/shutdown-force/01-connect-peer.bru
================================================
meta {
  name: connect peer
  type: http
  seq: 1
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "connect_peer",
    "params": [
      {"address": "{{NODE1_ADDR}}"}
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Dialing a peer is async in tentacle. Sleep for some time to make sure
  // we're connected to the peer.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/shutdown-force/02-open-channel.bru
================================================
meta {
  name: Node3 open a channel to Node1
  type: http
  seq: 2
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE1_PEERID}}",
        "funding_amount": "0xba43b7400"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 2000));
}


================================================
File: tests/bruno/e2e/shutdown-force/03-get-auto-accepted-channel.bru
================================================
meta {
  name: get auto accepted channel id from Node1
  type: http
  seq: 3
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE3_PEERID}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  console.log(res.body.result);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 2000));
  bru.setVar("CHANNEL_ID", res.body.result.channels[0].channel_id);
}


================================================
File: tests/bruno/e2e/shutdown-force/04-generate-a-few-blocks.bru
================================================
meta {
  name: generate a few blocks
  type: http
  seq: 4
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": {{iteration}},
    "jsonrpc": "2.0",
    "method": "generate_block",
    "params": []
  }
}

vars:post-response {
  max_iterations: 10
}

assert {
  res.status: eq 200
}

script:pre-request {
  // Script taken from https://github.com/usebruno/bruno/discussions/385#discussioncomment-8015350
  // This does not seem to work.
  if(bru.getVar("iteration") === undefined){
    console.log("Started generating blocks...");
    bru.setVar("iteration", 0);
  }
}

script:post-response {
  if(bru.getVar("iteration") < bru.getVar("max_iterations") -1){
    bru.setVar("iteration", bru.getVar("iteration") + 1);
    // This is the name of this bruno file, set this to continue generating blocks.
    bru.setNextRequest("generate a few blocks");
  } else {
    console.log("Stopping generating blocks");
    bru.setVar("iteration", undefined);
    // Don't know why it takes so long for funding transaction to be confirmed.
    await new Promise(r => setTimeout(r, 5000));
  }
  await new Promise(r => setTimeout(r, 10));
  console.log("Generated the " + bru.getVar("iteration") + "th block");
}


================================================
File: tests/bruno/e2e/shutdown-force/05-shutdown-force-NODE1.bru
================================================
meta {
  name: send shutdown from NODE1
  type: http
  seq: 5
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "shutdown_channel",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "close_script": {
          "code_hash": "0x2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a",
          "hash_type": "data",
          "args": "0x0101010101010101010101010101010101010101"
        },
        "fee_rate": "0x3FC",
        "force": true
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  console.log("res.body: ", res.body);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
}


================================================
File: tests/bruno/e2e/shutdown-force/06-generate-a-few-blocks.bru
================================================
meta {
  name: generate a few blocks after shutdown
  type: http
  seq: 6
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": {{iteration}},
    "jsonrpc": "2.0",
    "method": "generate_block",
    "params": []
  }
}

vars:post-response {
  max_iterations: 10
}

assert {
  res.status: eq 200
}

script:pre-request {
  // Script taken from https://github.com/usebruno/bruno/discussions/385#discussioncomment-8015350
  // This does not seem to work.
  if(bru.getVar("iteration") === undefined){
    console.log("Started generating blocks...");
    bru.setVar("iteration", 0);
  }
}

script:post-response {
  if(bru.getVar("iteration") < bru.getVar("max_iterations") -1){
    bru.setVar("iteration", bru.getVar("iteration") + 1);
    // This is the name of this bruno file, set this to continue generating blocks.
    bru.setNextRequest("generate a few blocks after shutdown", bru.getVar("iteration"));
  } else {
    console.log("Stopping generating blocks");
    // Don't know why it takes so long for funding transaction to be confirmed.
    await new Promise(r => setTimeout(r, 5000));
  }
  await new Promise(r => setTimeout(r, 10));
  console.log("Generated the " + bru.getVar("iteration") + "th block");
}


================================================
File: tests/bruno/e2e/shutdown-force/07-list-channel.bru
================================================
meta {
  name: List all channels after shutdown force
  type: http
  seq: 7
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE3_PEERID}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  console.log(res.body.result);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 2000));
  bru.setVar("CHANNEL_ID", res.body.result.channels.length);
  if (res.body.result.channels.length != 0) {
    console.log("channel first: ", res.body.result.channels[0]);
    throw new Error("Assertion failed: expect thel channel is closed");
  }
}


================================================
File: tests/bruno/e2e/udt/01-node1-connect-node2.bru
================================================
meta {
  name: connect peer
  type: http
  seq: 1
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}
body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "connect_peer",
    "params": [
      {"address": "{{NODE1_ADDR}}"}
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Dialing a peer is async in tentacle. Sleep for some time to make sure
  // we're connected to the peer.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/udt/02-node1-node2-open-channel-amount-err.bru
================================================
meta {
  name: Node1 open a channel to Node2, run a specific UDT type we don't have enough cells, (args is not right)
  type: http
  seq: 2
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}


body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}",
          "funding_amount": "0x4b0",
          "funding_udt_type_script": {
            "code_hash": "{{UDT_CODE_HASH}}",
            "hash_type": "data1",
            "args": "0x32e555f3ff8e135cece1351a6a2971518392c1e30375c1e006ad0ce8eac0794a"
          }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 1000));
  console.log("N1N2 response: ", res.body);
  console.log("N1N2 response: ", res.body.result.temporary_channel_id);
  bru.setVar("N1N2_TEMP_CHANNEL_ID", res.body.result.temporary_channel_id);
}


================================================
File: tests/bruno/e2e/udt/03-node2-list-channel-empty.bru
================================================
meta {
  name: get channel list from node2
  type: http
  seq: 3
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE1_PEERID}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 2000));
  console.log("accept channel result: ", res.body);
  if (res.body.result.channels.length != 0) {
    throw new Error("Assertion failed: expect there is no channel");
  }
}


================================================
File: tests/bruno/e2e/udt/04-node1-node2-open-channel.bru
================================================
meta {
  name: Node1 open a channel to Node2, make funding_amount is larger to check overflow issue
  type: http
  seq: 4
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}


body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}",
          "funding_amount": "0xfffffffffffffffffffffffffffff",
          "funding_udt_type_script": {
            "code_hash": "{{UDT_CODE_HASH}}",
            "hash_type": "data1",
            "args": "0x32e555f3ff8e135cece1351a6a2971518392c1e30375c1e006ad0ce8eac07947"
          }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 1000));
  console.log("N1N2 response: ", res.body);
  console.log("N1N2 response: ", res.body.result.temporary_channel_id);
  bru.setVar("N1N2_TEMP_CHANNEL_ID", res.body.result.temporary_channel_id);
}


================================================
File: tests/bruno/e2e/udt/05-node2-list-channel.bru
================================================
meta {
  name: get channel list from node2
  type: http
  seq: 5
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE1_PEERID}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 2000));
  console.log("accept channel result: ", res.body);
  bru.setVar("N1N2_CHANNEL_ID", res.body.result.channels[0].channel_id);
}


================================================
File: tests/bruno/e2e/udt/06-ckb-generate-blocks.bru
================================================
meta {
  name: generate a few epochs
  type: http
  seq: 6
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x2"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/udt/07-node2-gen-invoice.bru
================================================
meta {
  name: generate a invoice
  type: http
  seq: 7
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

script:pre-request {
  // generate random preimage
  function generateRandomPreimage() {
    let hash = '0x';
    for (let i = 0; i < 64; i++) {
        hash += Math.floor(Math.random() * 16).toString(16);
    }
    return hash;
  }
  const payment_preimage = generateRandomPreimage();
  bru.setVar("payment_preimage", payment_preimage);
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "new_invoice",
    "params": [
      {
        "amount": "0xc8",
        "currency": "Fibd",
        "description": "test invoice generated by node2",
        "expiry": "0xe10",
        "final_expiry_delta": "0xDFFA0",
        "payment_preimage": "{{payment_preimage}}",
        "udt_type_script": {
            "code_hash": "{{UDT_CODE_HASH}}",
            "hash_type": "data1",
            "args": "0x32e555f3ff8e135cece1351a6a2971518392c1e30375c1e006ad0ce8eac07947"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("generated result: ", res.body.result);
  // assert `UdtScript` is present in the response data
  let udt_script_attr = res.body.result.invoice.data.attrs.find((attr) => attr.UdtScript);
  if (udt_script_attr.UdtScript === undefined) {
    throw new Error("UdtScript is not present in the response data");
  }
  bru.setVar("payment_hash", res.body.result.invoice.data.payment_hash);
  bru.setVar("payment_amount", res.body.result.invoice.amount);
}


================================================
File: tests/bruno/e2e/udt/08-node1-add-tlc.bru
================================================
meta {
  name: Node1 add tlc
  type: http
  seq: 8
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "add_tlc",
    "params": [
      {
        "channel_id": "{{N1N2_CHANNEL_ID}}",
        "amount": "{{payment_amount}}",
        "payment_hash": "{{payment_hash}}",
        "expiry": "{{expiry}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.tlc_id: isDefined
}

script:pre-request {
  let expiry = "0x" + (Date.now() + 1000 * 60 * 60 * 24).toString(16);
  bru.setVar("expiry", expiry);
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("response from node1 AddTlc:", res.body);
  bru.setVar("N1N2_TLC_ID1", res.body.result.tlc_id);

}


================================================
File: tests/bruno/e2e/udt/09-node2-remove-tlc.bru
================================================
meta {
  name: remove tlc from NODE2
  type: http
  seq: 9
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "remove_tlc",
    "params": [
      {
        "channel_id": "{{N1N2_CHANNEL_ID}}",
        "tlc_id": "{{N1N2_TLC_ID1}}",
        "reason": {
          "payment_preimage": "{{payment_preimage}}"
        }
      }
    ]
  }
}

assert {
  res.body.error: isDefined
  res.body.result: isUndefined
}

script:pre-request {
  // waiting auto remove tlc is finished
  await new Promise(r => setTimeout(r, 2000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  if (!(res.body.error.message.includes("Trying to remove non-existing tlc with id"))) {
    throw new Error("Assertion failed: error message is not right");
  }
}


================================================
File: tests/bruno/e2e/udt/10-node1-node2-open-channel-invalid.bru
================================================
meta {
  name: Node1 open a invalid channel to Node3
  type: http
  seq: 10
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}


body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}",
          "funding_amount": "0x4b0",
          "funding_udt_type_script": {
            "code_hash": "0xe1e354d6d643ad42724d40967e334984534e0367405c5ae42a9d7d63d77df410",
            "hash_type": "data1",
            "args": "0x32e555f3ff8e135cece1351a6a2971518392c1e30375c1e006ad0ce8eac07947"
          }
      }
    ]
  }
}

assert {
  res.body.error: isDefined
  res.body.result: isUndefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  // will get error message since channel is closed in previous step
  await new Promise(r => setTimeout(r, 100));
  if (!(res.body.error.message === "Invalid parameter: Invalid UDT type script")) {
    throw new Error("Assertion failed: error message is not right");
  }
}

================================================
File: tests/bruno/e2e/udt/11-node1-node2-open-channel-no-auto-accept.bru
================================================
meta {
  name: Node1 open a channel to Node2, that should not be auto accepted
  type: http
  seq: 11
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}


body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}",
          "funding_amount": "0x200",
          "funding_udt_type_script": {
            "code_hash": "{{UDT_CODE_HASH}}",
            "hash_type": "data1",
            "args": "0x32e555f3ff8e135cece1351a6a2971518392c1e30375c1e006ad0ce8eac07947"
          }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 1000));
  console.log("N1N2 response: ", res.body);
  console.log("N1N2 response: ", res.body.result.temporary_channel_id);
  bru.setVar("N1N2_TEMP_CHANNEL_ID", res.body.result.temporary_channel_id);
}


================================================
File: tests/bruno/e2e/udt/12-node2-accept-channel.bru
================================================
meta {
  name: node2 accept udt channel
  type: http
  seq: 12
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "accept_channel",
    "params": [
      {
        "temporary_channel_id": "{{N1N2_TEMP_CHANNEL_ID}}",
        "funding_amount": "0x0"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 1000));
  console.log("accept channel result: ", res.body);
}


================================================
File: tests/bruno/e2e/udt/13-ckb-generate-blocks.bru
================================================
meta {
  name: generate a few epochs
  type: http
  seq: 13
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x2"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/udt/14-node2-list-channel-expect-two-channel.bru
================================================
meta {
  name: get channel list from node2
  type: http
  seq: 14
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE1_PEERID}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 2000));
  console.log("accept channel result: ", res.body.result.channels);
    if (res.body.result.channels.length != 2) {
    throw new Error("Assertion failed: expect there are 2 channels");
  }
}


================================================
File: tests/bruno/e2e/udt/15-node1-send-shutdown-channel.bru
================================================
meta {
  name: Node1 send shutdown channel1
  type: http
  seq: 15
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "shutdown_channel",
    "params": [
      {
        "channel_id": "{{N1N2_CHANNEL_ID}}",
        "close_script": {
          "code_hash": "0x2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a",
          "hash_type": "data",
          "args": "0x0101010101010101010101010101010101010101"
        },
        "fee_rate": "0x3FC"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/udt-router-pay/01-node1-connect-node2.bru
================================================
meta {
  name: connect peer
  type: http
  seq: 1
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "connect_peer",
    "params": [
      { "address": "{{NODE1_ADDR}}" }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Dialing a peer is async in tentacle. Sleep for some time to make sure
  // we're connected to the peer.
  console.log("connect result: ", res.body.result);
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/udt-router-pay/02-node2-connect-node3.bru
================================================
meta {
  name: connect peer
  type: http
  seq: 2
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "connect_peer",
    "params": [
      {"address": "{{NODE2_ADDR}}"}
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Dialing a peer is async in tentacle. Sleep for some time to make sure
  // we're connected to the peer.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/udt-router-pay/03-node1-node2-open-channel.bru
================================================
meta {
  name: Node1 open a channel to Node2
  type: http
  seq: 3
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}",
        "funding_amount": "0x3B9ACA00",
        "tlc_fee_proportional_millionths": "0x4B0",
        "funding_udt_type_script": {
            "code_hash": "{{UDT_CODE_HASH}}",
            "hash_type": "data1",
            "args": "0x32e555f3ff8e135cece1351a6a2971518392c1e30375c1e006ad0ce8eac07947"
          }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 2000));
}


================================================
File: tests/bruno/e2e/udt-router-pay/04-node2-get-auto-accepted-channel.bru
================================================
meta {
  name: get auto accepted channel id from Node2
  type: http
  seq: 4
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE1_PEERID}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  console.log(res.body.result);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 2000));
  bru.setVar("N1N2_CHANNEL_ID", res.body.result.channels[0].channel_id);
}


================================================
File: tests/bruno/e2e/udt-router-pay/06-ckb-generate-blocks.bru
================================================
meta {
  name: generate a few epochs for channel 1
  type: http
  seq: 6
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x2"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/udt-router-pay/07-node2-node3-open-channel.bru
================================================
meta {
  name: Node2 open a channel to Node3
  type: http
  seq: 7
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE3_PEERID}}",
        "funding_amount": "0x3B9ACA00",
        "funding_udt_type_script": {
            "code_hash": "{{UDT_CODE_HASH}}",
            "hash_type": "data1",
            "args": "0x32e555f3ff8e135cece1351a6a2971518392c1e30375c1e006ad0ce8eac07947"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 2000));
}


================================================
File: tests/bruno/e2e/udt-router-pay/08-node3-get-auto-accepted-channel.bru
================================================
meta {
  name: get auto accepted channel id from Node3
  type: http
  seq: 8
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  console.log(res.body.result);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 2000));
  bru.setVar("N2N3_CHANNEL_ID", res.body.result.channels[0].channel_id);
}


================================================
File: tests/bruno/e2e/udt-router-pay/10-ckb-generate-blocks.bru
================================================
meta {
  name: generate a few epochs for channel 2
  type: http
  seq: 10
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x2"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/udt-router-pay/11-node2-list-channels.bru
================================================
meta {
  name: get channels from node2
  type: http
  seq: 11
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE3_PEERID}}"
      }
    ]
  }
}

script:pre-request {
  await new Promise(r => setTimeout(r, 1000));
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 1000));
  console.log("list channels: ", res.body.result.channels[0]);
  if (res.body.result.channels[0].remote_balance != "0x0" || res.body.result.channels[0].local_balance != "0x3b9aca00") {
    throw new Error("Assertion failed: channel amount is not right");
  }
}


================================================
File: tests/bruno/e2e/udt-router-pay/11-node3-gen-invoice.bru
================================================
meta {
  name: generate a invoice
  type: http
  seq: 11
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "new_invoice",
    "params": [
      {
        "amount": "0x5F5E100",
        "currency": "Fibd",
        "description": "test invoice generated by node3",
        "expiry": "0xe10",
        "final_expiry_delta": "0xDFFA0",
        "payment_preimage": "{{payment_preimage}}",
        "udt_type_script": {
            "code_hash": "{{UDT_CODE_HASH}}",
            "hash_type": "data1",
            "args": "0x32e555f3ff8e135cece1351a6a2971518392c1e30375c1e006ad0ce8eac07947"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:pre-request {
  // generate random preimage
  function generateRandomPreimage() {
    let hash = '0x';
    for (let i = 0; i < 64; i++) {
        hash += Math.floor(Math.random() * 16).toString(16);
    }
    return hash;
  }
  const payment_preimage = generateRandomPreimage();
  bru.setVar("payment_preimage", payment_preimage);
  let hash_algorithm = bru.getEnvVar("HASH_ALGORITHM");
  if (hash_algorithm !== null) {
    let body = req.getBody();
    body.params[0].hash_algorithm = hash_algorithm;
    req.setBody(body);
  }
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("generated result: ", res.body.result);
  bru.setVar("payment_hash", res.body.result.invoice.data.payment_hash);
  bru.setVar("payment_amount", res.body.result.invoice.amount);
}


================================================
File: tests/bruno/e2e/udt-router-pay/12-node1-send-payment.bru
================================================
meta {
  name: Node1 send payment with router
  type: http
  seq: 12
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_payment",
    "params": [
      {
        "target_pubkey": "03032b99943822e721a651c5a5b9621043017daa9dc3ec81d83215fd2e25121187",
        "amount": "0x5F5E100",
        "payment_hash": "{{payment_hash}}",
        "udt_type_script": {
            "code_hash": "{{UDT_CODE_HASH}}",
            "hash_type": "data1",
            "args": "0x32e555f3ff8e135cece1351a6a2971518392c1e30375c1e006ad0ce8eac07947"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("send payment result: ", res.body);
}


================================================
File: tests/bruno/e2e/udt-router-pay/13-node3-gen-invoice-later.bru
================================================
meta {
  name: generate a invoice
  type: http
  seq: 13
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "new_invoice",
    "params": [
      {
        "amount": "0x20",
        "currency": "Fibd",
        "description": "test invoice generated by node3",
        "expiry": "0xe10",
        "final_expiry_delta": "0xDFFA0",
        "payment_preimage": "{{payment_preimage}}",
        "udt_type_script": {
            "code_hash": "{{UDT_CODE_HASH}}",
            "hash_type": "data1",
            "args": "0x32e555f3ff8e135cece1351a6a2971518392c1e30375c1e006ad0ce8eac07947"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:pre-request {
  // generate random preimage
  function generateRandomPreimage() {
    let hash = '0x';
    for (let i = 0; i < 64; i++) {
        hash += Math.floor(Math.random() * 16).toString(16);
    }
    return hash;
  }
  const payment_preimage = generateRandomPreimage();
  bru.setVar("payment_preimage", payment_preimage);
  let hash_algorithm = bru.getEnvVar("HASH_ALGORITHM");
  if (hash_algorithm !== null) {
    let body = req.getBody();
    body.params[0].hash_algorithm = hash_algorithm;
    req.setBody(body);
  }
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("generated result: ", res.body.result);
  bru.setVar("encoded_invoice", res.body.result.invoice_address);
}


================================================
File: tests/bruno/e2e/udt-router-pay/14-node1-send-payment-with-invoice.bru
================================================
meta {
  name: Node1 send payment with router only with invoice
  type: http
  seq: 14
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_payment",
    "params": [
      {
        "invoice": "{{encoded_invoice}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}


script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}


script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("send payment result: ", res.body);

}


================================================
File: tests/bruno/e2e/udt-router-pay/15-node1-send-payment-keysend.bru
================================================
meta {
  name: Node1 send payment with router in keysend mode
  type: http
  seq: 15
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_payment",
    "params": [
      {
        "target_pubkey": "03032b99943822e721a651c5a5b9621043017daa9dc3ec81d83215fd2e25121187",
        "amount": "0x30",
        "keysend": true,
        "udt_type_script": {
            "code_hash": "{{UDT_CODE_HASH}}",
            "hash_type": "data1",
            "args": "0x32e555f3ff8e135cece1351a6a2971518392c1e30375c1e006ad0ce8eac07947"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}

script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("send payment result: ", res.body);
}


================================================
File: tests/bruno/e2e/udt-router-pay/16-node1-send-payment-keysend-large-amount.bru
================================================
meta {
  name: Node1 send payment with router in keysend mode
  type: http
  seq: 16
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_payment",
    "params": [
      {
        "target_pubkey": "03032b99943822e721a651c5a5b9621043017daa9dc3ec81d83215fd2e25121187",
        "amount": "0x3B9ACA02",
        "keysend": true,
        "udt_type_script": {
            "code_hash": "{{UDT_CODE_HASH}}",
            "hash_type": "data1",
            "args": "0x32e555f3ff8e135cece1351a6a2971518392c1e30375c1e006ad0ce8eac07947"
        }
      }
    ]
  }
}

assert {
  res.body.error: isDefined
}

script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 100));
  console.log("send payment result: ", res.body);
}


================================================
File: tests/bruno/e2e/udt-router-pay/17-node2-list-channels.bru
================================================
meta {
  name: get channels from node2
  type: http
  seq: 17
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE3_PEERID}}"
      }
    ]
  }
}

script:pre-request {
  await new Promise(r => setTimeout(r, 3000));
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 1000));
  console.log("step 17 list channels: ", res.body.result.channels[0]);
  // step 12: 100000000
  // step 14: 32
  // step 15: 48
  // sum is: 100000080 (0x5f5e150)
  if (res.body.result.channels[0].remote_balance != "0x5f5e150" || res.body.result.channels[0].local_balance != "0x35a4e8b0") {
    throw new Error("Assertion failed: channel amount is not right");
  }
}


================================================
File: tests/bruno/e2e/watchtower/force-close/01-connect-peer.bru
================================================
meta {
  name: connect peer
  type: http
  seq: 1
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "connect_peer",
    "params": [
      {"address": "{{NODE1_ADDR}}"}
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Dialing a peer is async in tentacle. Sleep for some time to make sure
  // we're connected to the peer.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close/02-open-channel.bru
================================================
meta {
  name: Node1 open a channel to Node2 with amount 99 ckb
  type: http
  seq: 2
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}",
        "funding_amount": "0x24e160300",
        "shutdown_script": {
          "code_hash": "0x2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a",
          "hash_type": "data",
          "args": "0x42"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 2000));
    bru.setVar("N1N2_TEMP_CHANNEL_ID", res.body.result.temporary_channel_id);
}


================================================
File: tests/bruno/e2e/watchtower/force-close/03-accept-channel.bru
================================================
meta {
  name: node2 accept channel
  type: http
  seq: 3
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "accept_channel",
    "params": [
      {
        "temporary_channel_id": "{{N1N2_TEMP_CHANNEL_ID}}",
        "funding_amount": "0x1004ccb00",
        "shutdown_script": {
          "code_hash": "0x2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b",
          "hash_type": "data",
          "args": "0x42"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 1000));
  console.log("accept channel result: ", res.body);
  bru.setVar("CHANNEL_ID", res.body.result.channel_id);
}


================================================
File: tests/bruno/e2e/watchtower/force-close/04-generate-a-few-blocks.bru
================================================
meta {
  name: generate a few blocks
  type: http
  seq: 4
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x1"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close/05-node2-gen-invoice.bru
================================================
meta {
  name: generate a invoice
  type: http
  seq: 5
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "new_invoice",
    "params": [
      {
        "amount": "0x2dc6c0",
        "currency": "Fibd",
        "description": "test invoice generated by node2",
        "expiry": "0xe10",
        "final_expiry_delta": "0xDFFA0",
        "payment_preimage": "{{payment_preimage}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:pre-request {
  // generate random preimage
  function generateRandomPreimage() {
    let hash = '0x';
    for (let i = 0; i < 64; i++) {
        hash += Math.floor(Math.random() * 16).toString(16);
    }
    return hash;
  }
  const payment_preimage = generateRandomPreimage();
  bru.setVar("payment_preimage", payment_preimage);
  let hash_algorithm = bru.getEnvVar("HASH_ALGORITHM");
  if (hash_algorithm !== null) {
    let body = req.getBody();
    body.params[0].hash_algorithm = hash_algorithm;
    req.setBody(body);
  }
}

script:post-response {
  console.log("generated result: ", res.body.result);
  bru.setVar("encoded_invoice", res.body.result.invoice_address);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close/06-node1-send-payment-with-invoice.bru
================================================
meta {
  name: Node1 send payment with invoice
  type: http
  seq: 6
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_payment",
    "params": [
      {
        "invoice": "{{encoded_invoice}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}


script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}


script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close/07-force-close.bru
================================================
meta {
  name: Node1 force close channel
  type: http
  seq: 7
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "shutdown_channel",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "close_script": {
          "code_hash": "0x2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a",
          "hash_type": "data",
          "args": "0x0101010101010101010101010101010101010101"
        },
        "fee_rate": "0x3FC",
        "force": true
      }
    ]
  }
}

script:post-response {
  console.log(res.body);
}


================================================
File: tests/bruno/e2e/watchtower/force-close/08-get-force-closed-commitment-tx-hash.bru
================================================
meta {
  name: get force closed commitment tx hash
  type: http
  seq: 8
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}",
        "include_closed": true
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  console.log(res.body.result);
  bru.setVar("TX_HASH", res.body.result.channels[0].latest_commitment_transaction_hash);
}


================================================
File: tests/bruno/e2e/watchtower/force-close/09-generate-a-few-blocks-for-commitment-tx.bru
================================================
meta {
  name: generate a few blocks for commitment tx
  type: http
  seq: 9
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x1"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  // Wait for the commitment tx to be included in a block
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close/10-generate-a-few-blocks-for-settlement-tx-generated.bru
================================================
meta {
  name: generate a few blocks for watchtower to generate settlement tx, default delay epoch is 6 epochs
  type: http
  seq: 10
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x7"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  // Wait for the commitment tx to be revoked by the watchtower
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close/11-generate-a-few-blocks-for-settlement-tx-committed.bru
================================================
meta {
  name: generate a few blocks for settlement tx to be committed
  type: http
  seq: 11
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x1"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close/12-check-commitment-tx.bru
================================================
meta {
  name: check submitted commitment tx should be settled
  type: http
  seq: 12
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "get_live_cell",
    "params": [
      {
        "index": "0x0",
        "tx_hash": "{{TX_HASH}}"
      },
      false
    ]
  }
}

assert {
  res.body.result.status: eq "unknown"
}

script:post-response {
  console.log("generated result: ", res.body);
}


================================================
File: tests/bruno/e2e/watchtower/force-close/13-check-balance-node1.bru
================================================
meta {
  name: check balance, 0x24e160300 - 0x2dc6c0 - 0x1c7 (fee) == 0x24de83a79
  type: http
  seq: 13
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "get_cells_capacity",
    "params": [
      {
        "script": {
          "code_hash": "0x2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a",
          "hash_type": "data",
          "args": "0x42"
        },
        "script_type": "lock"
      }
    ]
  }
}

assert {
  res.body.result.capacity: eq "0x24de83a79"
}

script:post-response {
  console.log("result: ", res.body);
}


================================================
File: tests/bruno/e2e/watchtower/force-close/14-check-balance-node2.bru
================================================
meta {
  name: check balance, 0x1004ccb00 + 0x2dc6c0 - 0x1c7 (fee) == 0x1007a8ff9
  type: http
  seq: 14
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "get_cells_capacity",
    "params": [
      {
        "script": {
          "code_hash": "0x2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b2b",
          "hash_type": "data",
          "args": "0x42"
        },
        "script_type": "lock"
      }
    ]
  }
}

assert {
  res.body.result.capacity: eq "0x1007a8ff9"
}

script:post-response {
  console.log("result: ", res.body);
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-multiple-payments/01-connect-peer.bru
================================================
meta {
  name: connect peer
  type: http
  seq: 1
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "connect_peer",
    "params": [
      {"address": "{{NODE1_ADDR}}"}
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Dialing a peer is async in tentacle. Sleep for some time to make sure
  // we're connected to the peer.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-multiple-payments/02-open-channel.bru
================================================
meta {
  name: Node1 open a channel to Node2 with amount 99 ckb
  type: http
  seq: 2
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}",
        "funding_amount": "0x24e160300",
        "shutdown_script": {
          "code_hash": "0x2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c",
          "hash_type": "data",
          "args": "0x42"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 2000));
    bru.setVar("N1N2_TEMP_CHANNEL_ID", res.body.result.temporary_channel_id);
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-multiple-payments/03-accept-channel.bru
================================================
meta {
  name: node2 accept channel
  type: http
  seq: 3
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "accept_channel",
    "params": [
      {
        "temporary_channel_id": "{{N1N2_TEMP_CHANNEL_ID}}",
        "funding_amount": "0x1004ccb00",
        "shutdown_script": {
          "code_hash": "0x2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d",
          "hash_type": "data",
          "args": "0x42"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 1000));
  console.log("accept channel result: ", res.body);
  bru.setVar("CHANNEL_ID", res.body.result.channel_id);
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-multiple-payments/04-generate-a-few-blocks.bru
================================================
meta {
  name: generate a few blocks
  type: http
  seq: 4
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x1"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-multiple-payments/05-node2-gen-invoice.bru
================================================
meta {
  name: generate a invoice
  type: http
  seq: 5
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "new_invoice",
    "params": [
      {
        "amount": "0x2dc6c0",
        "currency": "Fibd",
        "description": "test invoice generated by node2",
        "expiry": "0xe10",
        "final_expiry_delta": "0xDFFA0",
        "payment_preimage": "{{payment_preimage}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:pre-request {
  // generate random preimage
  function generateRandomPreimage() {
    let hash = '0x';
    for (let i = 0; i < 64; i++) {
        hash += Math.floor(Math.random() * 16).toString(16);
    }
    return hash;
  }
  const payment_preimage = generateRandomPreimage();
  bru.setVar("payment_preimage", payment_preimage);
  let hash_algorithm = bru.getEnvVar("HASH_ALGORITHM");
  if (hash_algorithm !== null) {
    let body = req.getBody();
    body.params[0].hash_algorithm = hash_algorithm;
    req.setBody(body);
  }
}

script:post-response {
  console.log("generated result: ", res.body.result);
  bru.setVar("encoded_invoice", res.body.result.invoice_address);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-multiple-payments/06-node1-send-payment-with-invoice.bru
================================================
meta {
  name: Node1 send payment with invoice
  type: http
  seq: 6
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_payment",
    "params": [
      {
        "invoice": "{{encoded_invoice}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}


script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}


script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-multiple-payments/07-node1-gen-invoice.bru
================================================
meta {
  name: generate a invoice
  type: http
  seq: 7
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "new_invoice",
    "params": [
      {
        "amount": "0x16e360",
        "currency": "Fibd",
        "description": "test invoice generated by node1",
        "expiry": "0xe10",
        "final_expiry_delta": "0xDFFA0",
        "payment_preimage": "{{payment_preimage}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:pre-request {
  // generate random preimage
  function generateRandomPreimage() {
    let hash = '0x';
    for (let i = 0; i < 64; i++) {
        hash += Math.floor(Math.random() * 16).toString(16);
    }
    return hash;
  }
  const payment_preimage = generateRandomPreimage();
  bru.setVar("payment_preimage", payment_preimage);
  let hash_algorithm = bru.getEnvVar("HASH_ALGORITHM");
  if (hash_algorithm !== null) {
    let body = req.getBody();
    body.params[0].hash_algorithm = hash_algorithm;
    req.setBody(body);
  }
}

script:post-response {
  console.log("generated result: ", res.body.result);
  bru.setVar("encoded_invoice", res.body.result.invoice_address);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-multiple-payments/08-node2-send-payment-with-invoice.bru
================================================
meta {
  name: Node2 send payment with invoice
  type: http
  seq: 8
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_payment",
    "params": [
      {
        "invoice": "{{encoded_invoice}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}


script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}


script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-multiple-payments/09-force-close.bru
================================================
meta {
  name: Node1 force close channel
  type: http
  seq: 9
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "shutdown_channel",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "close_script": {
          "code_hash": "0x2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a",
          "hash_type": "data",
          "args": "0x0101010101010101010101010101010101010101"
        },
        "fee_rate": "0x3FC",
        "force": true
      }
    ]
  }
}

script:post-response {
  console.log(res.body);
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-multiple-payments/10-generate-a-few-blocks-for-commitment-tx.bru
================================================
meta {
  name: generate a few blocks for commitment tx
  type: http
  seq: 10
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x1"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  // Wait for the commitment tx to be included in a block
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-multiple-payments/11-generate-a-few-blocks-for-settlement-tx-generated.bru
================================================
meta {
  name: generate a few blocks for watchtower to generate settlement tx, default delay epoch is 6 epochs
  type: http
  seq: 11
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x7"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  // Wait for the commitment tx to be revoked by the watchtower
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-multiple-payments/12-generate-a-few-blocks-for-settlement-tx-committed.bru
================================================
meta {
  name: generate a few blocks for settlement tx to be committed
  type: http
  seq: 12
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x1"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-multiple-payments/13-get-force-closed-commitment-tx-hash.bru
================================================
meta {
  name: get force closed commitment tx hash
  type: http
  seq: 13
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}",
        "include_closed": true
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  console.log(res.body.result);
  bru.setVar("TX_HASH", res.body.result.channels[0].latest_commitment_transaction_hash);
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-multiple-payments/14-check-commitment-tx.bru
================================================
meta {
  name: check submitted commitment tx should be settled
  type: http
  seq: 14
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "get_live_cell",
    "params": [
      {
        "index": "0x0",
        "tx_hash": "{{TX_HASH}}"
      },
      false
    ]
  }
}

assert {
  res.body.result.status: eq "unknown"
}

script:post-response {
  console.log("generated result: ", res.body);
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-multiple-payments/15-check-balance-node1.bru
================================================
meta {
  name: check balance, 0x24e160300 - 0x2dc6c0 + 0x16e360 - 0x1c7 (fee) == 0x24dff1dd9
  type: http
  seq: 15
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "get_cells_capacity",
    "params": [
      {
        "script": {
          "code_hash": "0x2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c",
          "hash_type": "data",
          "args": "0x42"
        },
        "script_type": "lock"
      }
    ]
  }
}

assert {
  res.body.result.capacity: eq "0x24dff1dd9"
}

script:post-response {
  console.log("result: ", res.body);
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-multiple-payments/16-check-balance-node2.bru
================================================
meta {
  name: check balance, 0x1004ccb00 + 0x2dc6c0 - 0x16e360 - 0x1c7 (fee) == 0x10063ac99
  type: http
  seq: 16
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "get_cells_capacity",
    "params": [
      {
        "script": {
          "code_hash": "0x2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d2d",
          "hash_type": "data",
          "args": "0x42"
        },
        "script_type": "lock"
      }
    ]
  }
}

assert {
  res.body.result.capacity: eq "0x10063ac99"
}

script:post-response {
  console.log("result: ", res.body);
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-open-channel/01-connect-peer.bru
================================================
meta {
  name: connect peer
  type: http
  seq: 1
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "connect_peer",
    "params": [
      {"address": "{{NODE1_ADDR}}"}
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Dialing a peer is async in tentacle. Sleep for some time to make sure
  // we're connected to the peer.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-open-channel/02-open-channel.bru
================================================
meta {
  name: Node1 open a channel to Node2 with amount 99 ckb
  type: http
  seq: 2
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}",
        "funding_amount": "0x24e160300",
        "shutdown_script": {
          "code_hash": "0x2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e",
          "hash_type": "data",
          "args": "0x42"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 2000));
    bru.setVar("N1N2_TEMP_CHANNEL_ID", res.body.result.temporary_channel_id);
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-open-channel/03-accept-channel.bru
================================================
meta {
  name: node2 accept channel
  type: http
  seq: 3
}

post {
  url: {{NODE2_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "accept_channel",
    "params": [
      {
        "temporary_channel_id": "{{N1N2_TEMP_CHANNEL_ID}}",
        "funding_amount": "0x1004ccb00",
        "shutdown_script": {
          "code_hash": "0x2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f",
          "hash_type": "data",
          "args": "0x42"
        }
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}

script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 1000));
  console.log("accept channel result: ", res.body);
  bru.setVar("CHANNEL_ID", res.body.result.channel_id);
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-open-channel/04-generate-a-few-blocks.bru
================================================
meta {
  name: generate a few blocks
  type: http
  seq: 4
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x1"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-open-channel/05-force-close.bru
================================================
meta {
  name: Node1 force close channel
  type: http
  seq: 5
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "shutdown_channel",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "close_script": {
          "code_hash": "0x2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a2a",
          "hash_type": "data",
          "args": "0x0101010101010101010101010101010101010101"
        },
        "fee_rate": "0x3FC",
        "force": true
      }
    ]
  }
}

script:post-response {
  console.log(res.body);
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-open-channel/06-get-force-closed-commitment-tx-hash.bru
================================================
meta {
  name: get force closed commitment tx hash
  type: http
  seq: 6
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE2_PEERID}}",
        "include_closed": true
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  console.log(res.body.result);
  bru.setVar("TX_HASH", res.body.result.channels[0].latest_commitment_transaction_hash);
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-open-channel/07-generate-a-few-blocks-for-commitment-tx.bru
================================================
meta {
  name: generate a few blocks for commitment tx
  type: http
  seq: 7
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x1"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  // Wait for the commitment tx to be included in a block
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-open-channel/08-generate-a-few-blocks-for-settlement-tx-generated.bru
================================================
meta {
  name: generate a few blocks for watchtower to generate settlement tx, default delay epoch is 6 epochs
  type: http
  seq: 8
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x7"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  // Wait for the commitment tx to be revoked by the watchtower
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-open-channel/09-generate-a-few-blocks-for-settlement-tx-committed.bru
================================================
meta {
  name: generate a few blocks for settlement tx to be committed
  type: http
  seq: 9
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x1"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-open-channel/10-check-commitment-tx.bru
================================================
meta {
  name: check submitted commitment tx should be settled
  type: http
  seq: 10
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "get_live_cell",
    "params": [
      {
        "index": "0x0",
        "tx_hash": "{{TX_HASH}}"
      },
      false
    ]
  }
}

assert {
  res.body.result.status: eq "unknown"
}

script:post-response {
  console.log("generated result: ", res.body);
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-open-channel/11-check-balance-node1.bru
================================================
meta {
  name: check balance, 0x24e160300 - 0x1c7 (fee) == 0x24e160139
  type: http
  seq: 11
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "get_cells_capacity",
    "params": [
      {
        "script": {
          "code_hash": "0x2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e2e",
          "hash_type": "data",
          "args": "0x42"
        },
        "script_type": "lock"
      }
    ]
  }
}

assert {
  res.body.result.capacity: eq "0x24e160139"
}

script:post-response {
  console.log("result: ", res.body);
}


================================================
File: tests/bruno/e2e/watchtower/force-close-after-open-channel/12-check-balance-node2.bru
================================================
meta {
  name: check balance, 0x1004ccb00 - 0x1c7 (fee) == 0x1004cc939
  type: http
  seq: 12
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "get_cells_capacity",
    "params": [
      {
        "script": {
          "code_hash": "0x2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f2f",
          "hash_type": "data",
          "args": "0x42"
        },
        "script_type": "lock"
      }
    ]
  }
}

assert {
  res.body.result.capacity: eq "0x1004cc939"
}

script:post-response {
  console.log("result: ", res.body);
}


================================================
File: tests/bruno/e2e/watchtower/revocation/01-connect-peer.bru
================================================
meta {
  name: connect peer
  type: http
  seq: 1
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "connect_peer",
    "params": [
      {"address": "{{NODE1_ADDR}}"}
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isNull
}

script:post-response {
  // Dialing a peer is async in tentacle. Sleep for some time to make sure
  // we're connected to the peer.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/watchtower/revocation/02-open-channel.bru
================================================
meta {
  name: Node1 open a channel to Node3
  type: http
  seq: 2
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "open_channel",
    "params": [
      {
        "peer_id": "{{NODE3_PEERID}}",
        "funding_amount": "0xba43b7400"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.temporary_channel_id: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 2000));
}


================================================
File: tests/bruno/e2e/watchtower/revocation/03-get-auto-accepted-channel.bru
================================================
meta {
  name: get auto accepted channel id from Node1
  type: http
  seq: 3
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "list_channels",
    "params": [
      {
        "peer_id": "{{NODE3_PEERID}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result.channels: isDefined
}

script:post-response {
  await new Promise(r => setTimeout(r, 2000));
  console.log(res.body.result);
  bru.setVar("CHANNEL_ID", res.body.result.channels[0].channel_id);
}


================================================
File: tests/bruno/e2e/watchtower/revocation/04-generate-a-few-blocks.bru
================================================
meta {
  name: generate a few blocks
  type: http
  seq: 4
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x1"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/watchtower/revocation/05-node3-gen-invoice.bru
================================================
meta {
  name: generate a invoice
  type: http
  seq: 5
}

post {
  url: {{NODE3_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "new_invoice",
    "params": [
      {
        "amount": "0x1",
        "currency": "Fibd",
        "description": "test invoice generated by node3",
        "expiry": "0xe10",
        "final_expiry_delta": "0xDFFA0",
        "payment_preimage": "{{payment_preimage}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
  res.body.result: isDefined
}

script:pre-request {
  // generate random preimage
  function generateRandomPreimage() {
    let hash = '0x';
    for (let i = 0; i < 64; i++) {
        hash += Math.floor(Math.random() * 16).toString(16);
    }
    return hash;
  }
  const payment_preimage = generateRandomPreimage();
  bru.setVar("payment_preimage", payment_preimage);
  let hash_algorithm = bru.getEnvVar("HASH_ALGORITHM");
  if (hash_algorithm !== null) {
    let body = req.getBody();
    body.params[0].hash_algorithm = hash_algorithm;
    req.setBody(body);
  }
}

script:post-response {
  console.log("generated result: ", res.body.result);
  bru.setVar("encoded_invoice", res.body.result.invoice_address);
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/watchtower/revocation/06-node1-send-payment-with-invoice.bru
================================================
meta {
  name: Node1 send payment with invoice
  type: http
  seq: 6
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "send_payment",
    "params": [
      {
        "invoice": "{{encoded_invoice}}"
      }
    ]
  }
}

assert {
  res.body.error: isUndefined
}


script:pre-request {
  // sleep for a while
  await new Promise(r => setTimeout(r, 1000));
}


script:post-response {
  // Sleep for sometime to make sure current operation finishes before next request starts.
  await new Promise(r => setTimeout(r, 1000));
}


================================================
File: tests/bruno/e2e/watchtower/revocation/07-submit-old-version-commitment-tx.bru
================================================
meta {
  name: Node1 submit an old version commitment tx
  type: http
  seq: 7
}

post {
  url: {{NODE1_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": "42",
    "jsonrpc": "2.0",
    "method": "submit_commitment_transaction",
    "params": [
      {
        "channel_id": "{{CHANNEL_ID}}",
        "commitment_number": "0x0"
      }
    ]
  }
}

script:post-response {
  console.log(res.body);
  bru.setVar("TX_HASH", res.body.result.tx_hash);
}


================================================
File: tests/bruno/e2e/watchtower/revocation/08-generate-a-few-blocks-for-commitment-tx.bru
================================================
meta {
  name: generate a few blocks for commitment tx
  type: http
  seq: 8
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x1"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  // Wait for the commitment tx to be included in a block
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/watchtower/revocation/09-generate-a-few-blocks-for-revocation-tx.bru
================================================
meta {
  name: generate a few blocks for revocation tx
  type: http
  seq: 9
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "generate_epochs",
    "params": ["0x1"]
  }
}

assert {
  res.status: eq 200
}

script:post-response {
  // Wait for the commitment tx to be revoked by the watchtower
  await new Promise(r => setTimeout(r, 5000));
}


================================================
File: tests/bruno/e2e/watchtower/revocation/10-check-commitment-tx.bru
================================================
meta {
  name: check submitted commitment tx should be revoked
  type: http
  seq: 10
}

post {
  url: {{CKB_RPC_URL}}
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "id": 42,
    "jsonrpc": "2.0",
    "method": "get_live_cell",
    "params": [
      {
        "index": "0x0",
        "tx_hash": "{{TX_HASH}}"
      },
      false
    ]
  }
}

assert {
  res.body.result.status: eq "unknown"
}

script:post-response {
  console.log("generated result: ", res.body);
}


================================================
File: tests/bruno/environments/test.bru
================================================
vars {
  CKB_RPC_URL: http://127.0.0.1:8114
  NODE1_RPC_URL: http://127.0.0.1:21714
  NODE2_RPC_URL: http://127.0.0.1:21715
  NODE3_RPC_URL: http://127.0.0.1:21716
  NODE1_ADDR: /ip4/127.0.0.1/tcp/8344/p2p/QmbvRjJHAQDmj3cgnUBGQ5zVnGxUKwb2qJygwNs2wk41h8
  NODE2_ADDR: /ip4/127.0.0.1/tcp/8345/p2p/QmSRcPqUn4aQrKHXyCDjGn2qBVf43tWBDS2Wj9QDUZXtZp
  NODE3_ADDR: /ip4/127.0.0.1/tcp/8346/p2p/QmaFDJb9CkMrXy7nhTWBY5y9mvuykre3EzzRsCJUAVXprZ
  NODE1_PEERID: QmbvRjJHAQDmj3cgnUBGQ5zVnGxUKwb2qJygwNs2wk41h8
  NODE2_PEERID: QmSRcPqUn4aQrKHXyCDjGn2qBVf43tWBDS2Wj9QDUZXtZp
  NODE3_PEERID: QmaFDJb9CkMrXy7nhTWBY5y9mvuykre3EzzRsCJUAVXprZ
  UDT_CODE_HASH: 0xe1e354d6d643ad42724d40967e334984534e0367405c5ae42a9d7d63d77df419
  LND_BOB_RPC_URL: http://127.0.0.1:8180
  LND_INGRID_RPC_URL: http://127.0.0.1:8080
}


================================================
File: tests/bruno/environments/xudt-test.bru
================================================
vars {
  CKB_RPC_URL: http://127.0.0.1:8114
  NODE1_RPC_URL: http://127.0.0.1:21714
  NODE2_RPC_URL: http://127.0.0.1:21715
  NODE3_RPC_URL: http://127.0.0.1:21716
  NODE1_ADDR: /ip4/127.0.0.1/tcp/8344/p2p/QmbvRjJHAQDmj3cgnUBGQ5zVnGxUKwb2qJygwNs2wk41h8
  NODE2_ADDR: /ip4/127.0.0.1/tcp/8345/p2p/QmSRcPqUn4aQrKHXyCDjGn2qBVf43tWBDS2Wj9QDUZXtZp
  NODE3_ADDR: /ip4/127.0.0.1/tcp/8346/p2p/QmaFDJb9CkMrXy7nhTWBY5y9mvuykre3EzzRsCJUAVXprZ
  NODE1_PEERID: QmbvRjJHAQDmj3cgnUBGQ5zVnGxUKwb2qJygwNs2wk41h8
  NODE2_PEERID: QmSRcPqUn4aQrKHXyCDjGn2qBVf43tWBDS2Wj9QDUZXtZp
  NODE3_PEERID: QmaFDJb9CkMrXy7nhTWBY5y9mvuykre3EzzRsCJUAVXprZ
  UDT_CODE_HASH: 0x50bd8d6680b8b9cf98b73f3c08faf8b2a21914311954118ad6609be6e78a1b95
  LND_BOB_RPC_URL: http://127.0.0.1:8180
  LND_INGRID_RPC_URL: http://127.0.0.1:8080
}


================================================
File: tests/bruno/unit/connect-non-existent-peer.bru
================================================
meta {
  name: connect non-existent peer
  type: http
}

post {
  url: {{NODE3_RPC_URL}}/ckb
  body: json
  auth: none
}

headers {
  Content-Type: application/json
  Accept: application/json
}

body:json {
  {
    "request": {
      "ConnectPeer": "/ip4/127.127.127.127/tcp/8344/p2p/QmbvRjJHAQDmj3cgnUBGQ5zVnGxUKbb2qJygwNs2wk41h8"
    }
  }
  
}


tests {
  test("should return non 200 status", function() {
    // This actually fails because tentacle does not immediately return dialing error.
    // expect(res.status).to.equal(200);
  });
}


================================================
File: tests/bruno/unit/start.sh
================================================
#!/usr/bin/env bash

export RUST_BACKTRACE=full RUST_LOG=debug

script_dir="$(cd -- "$(dirname -- "${BASH_SOURCE[0]}")/.." &>/dev/null && pwd)"
nodes_dir="$(dirname "$script_dir")/nodes"

"${nodes_dir}/start.sh" 3


================================================
File: tests/deploy/deploy.sh
================================================
#!/usr/bin/env bash

set -xeuo pipefail

script_dir="$(cd -- "$(dirname -- "${BASH_SOURCE[0]}")" &>/dev/null && pwd)"
data_dir="$script_dir/node-data"
udt_init_dir="$script_dir/udt-init"
nodes_dir="$script_dir/../nodes"
cd "$script_dir" || exit 1

miner_key_file="$data_dir/specs/miner.key"

if ! [ -f "$miner_key_file" ]; then
    echo "$miner_key_file not found, use the default test account" >&2
    mkdir -p "$(dirname "$miner_key_file")"
    echo "d00c06bfd800d27397002dca6fb0993d5ba6399b4238b2f29ee9deb97593d2bc" >"$miner_key_file"
fi

ckb-cli() {
    # Don't pollute the home directory.
    env HOME="$data_dir" ckb-cli "$@"
}

if ! (echo | ckb-cli account import --local-only --privkey-path "$miner_key_file"); then
    :
fi

run_udt_init() {
    export NODES_DIR="$nodes_dir"
    (
        cd "$udt_init_dir" || exit 1
        cargo run -- "$@"
    )
}

run_udt_init


================================================
File: tests/deploy/generate-blocks.sh
================================================
#!/usr/bin/env bash

CKB_RPC_URL="${CKB_RPC_URL:-http://127.0.0.1:8114}"

function generate_one() {
    curl --request POST \
        -H "Content-Type: application/json" \
        --url "$CKB_RPC_URL" \
        --data '{
      "id": 42,
      "jsonrpc": "2.0",
      "method": "generate_block",
      "params": []
    }'
    echo
}

function generate_n() {
    if [ $# -eq 0 ]; then
        generate_one
    else
        for i in $(seq "$@"); do
            generate_one
        done
    fi
}

case "${1:-}" in
--url)
    CKB_RPC_URL="$2"
    shift
    shift
    generate_n "$@"
    ;;
--url=*)
    CKB_RPC_URL="${1#*=}"
    shift
    generate_n "$@"
    ;;
--help)
    echo 'usage: generate-blocks.sh [--help|--url CKB_RPC_URL] [count]'
    ;;
*)
    generate_n "$@"
    ;;
esac


================================================
File: tests/deploy/init-dev-chain.sh
================================================
#!/usr/bin/env bash

set -euo pipefail
export SHELLOPTS

check_deps() {
    for command in "$@"; do
        if ! command -v "$command" >/dev/null; then
            echo "$* are required to run this script"
            exit 1
        fi
    done
}

check_deps ckb ckb-cli perl

script_dir="$(cd -- "$(dirname -- "${BASH_SOURCE[0]}")" &>/dev/null && pwd)"
data_dir="$script_dir/node-data"
nodes_dir="$script_dir/../nodes"

# If -f is used, we will remove old state data. Otherwise we will skip the initialization.
while getopts "f" opt; do
    case $opt in
    f)
        rm -rf "$data_dir"
        ;;
    \?)
        echo "Invalid option: $OPTARG" 1>&2
        ;;
    esac
done

# Initialize the data directory if it does not exist.
if ! [[ -d "$data_dir" ]]; then
    ckb init -C "$data_dir" -c dev --force --ba-arg 0xc8328aabcd9b9e8e64fbc566c4385c3bdeb219d7
    cp "$nodes_dir/deployer/dev.toml" "$data_dir/specs/dev.toml"
    sed -i.bak 's|\.\./\.\./deploy/contracts|\.\./\.\./\.\./deploy/contracts|g' "$data_dir/specs/dev.toml"

    # Enable the IntegrationTest module (required to generate blocks).
    if ! grep -E '^modules.*IntegrationTest' "$data_dir/ckb.toml"; then
        # -i.bak is required to sed work on both Linux and macOS.
        sed -i.bak 's/\("Debug"\)/\1, "IntegrationTest"/' "$data_dir/ckb.toml"
    fi

    ckb run -C "$data_dir" --indexer &

    # Make some accounts with default balances, and deploy the contracts to the network.
    # Don't continue until the default account has some money.
    # Transfer some money from the default account (node 3) to node 1 for later use.
    echo "begin to setup wallet states for nodes"
    for i in {1..20}; do
        if ! nc -z 127.0.0.1 8114; then
            echo "waiting CKB ready $i ..."
            sleep 2
        else
            echo "CKB is ready now ..."
            break
        fi
    done

    # Transfer some money to the node 1.
    # The address of node 1 can be seen with the following command:
    # echo | HOME=/tmp ckb-cli account import --local-only --privkey-path "$$nodes_dir/1/ckb/key"
    ckb-cli wallet transfer --to-address $(cat "$nodes_dir/1/ckb/wallet") --capacity 5000000000 --fee-rate 2000 --privkey-path "$nodes_dir/deployer/ckb/key"

    sleep 1
    "$script_dir/generate-blocks.sh" 4
    sleep 1

    # Transfer some money to the node 2.
    ckb-cli wallet transfer --to-address $(cat "$nodes_dir/2/ckb/wallet") --capacity 5000000000 --fee-rate 2000 --privkey-path "$nodes_dir/deployer/ckb/key"
    sleep 1
    "$script_dir/generate-blocks.sh" 4
    sleep 1

    # Transfer some money to the node 3.
    ckb-cli wallet transfer --to-address $(cat "$nodes_dir/3/ckb/wallet") --capacity 5000000000 --fee-rate 2000 --privkey-path "$nodes_dir/deployer/ckb/key"
    sleep 1
    # Generate a few blocks so that above transaction is confirmed.
    echo "begin to generate blocks for wallet updating..."
    "$script_dir/generate-blocks.sh" 4

    # Also deploy the contracts.
    echo "deploy.sh..."
    "$script_dir/deploy.sh"

    pkill -P $$
fi


================================================
File: tests/deploy/.gitignore
================================================
# ckb dev chain data used for tests
/node-data/
/.env
/.env.local
/migrations/*
!/migrations/templates/

================================================
File: tests/deploy/contracts/README.md
================================================
The binaries within this directory are used to verify if the transaction built from our code base can pass ckb-vm verification.

The source code of these binaries are from the following repo [fiber-scripts](https://github.com/nervosnetwork/fiber-scripts) with commit 701d8c8a08790dd61c64f695aaa5fbed22e4b8ad.

We copied the following binaries from https://github.com/nervosnetwork/fiber-scripts/tree/main/deps

- auth
- simple_udt

The following binaries are built from https://github.com/nervosnetwork/ckb-production-scripts with commit 410b16c499a8888781d9ab03160eeef93182d8e6.

- xudt_rce

and built the following binaries

- funding-lock
- commitment-lock


================================================
File: tests/deploy/lnd-init/README.md
================================================
# lnd init

Setup 1 bitcoind and 2 lnd nodes.

Install [bitcoind](https://bitcoin.org/en/download), [lnd](https://github.com/lightningnetwork/lnd), and [jq](https://jqlang.github.io/jq/download/). Ensure that the executables are in your PATH.

The nodes will have their own data directories:

- `bitcoind`: bitcoind node.
- `lnd-bob`: lnd node for the BTC user.
- `lnd-ingrid`: lnd node for the cross-chain hub operator.


================================================
File: tests/deploy/lnd-init/setup-lnd.sh
================================================
#!/usr/bin/env bash

set -e

script_dir="$(cd -- "$(dirname -- "${BASH_SOURCE[0]}")" &>/dev/null && pwd)"
bob_port=11009
ingrid_port=10009

echo "=> bootstrap"
echo "script_dir=$script_dir"

kill-via-pid-file () {
  local pid="$(cat "$1" 2>/dev/null || true)"
  if [ -n "$pid" ]; then
    kill "$pid" || true
    sleep 3
    if kill -0 "$pid" 2>/dev/null; then
      echo "Failed to kill $pid, force killing it."
      kill -9 "$pid"
    fi
    rm -f "$1"
  fi
}

cleanup() {
  echo "=> cleanup"
  kill-via-pid-file "$script_dir/bitcoind/bitcoind.pid"
  kill-via-pid-file "$script_dir/lnd-bob/lnd.pid"
  kill-via-pid-file "$script_dir/lnd-ingrid/lnd.pid"
  rm -rf "$script_dir/bitcoind/regtest"

  local lnd_dir

  for lnd_dir in lnd-bob lnd-ingrid; do
    rm -rf "$script_dir/$lnd_dir/data"
    rm -rf "$script_dir/$lnd_dir/letsencrypt"
    rm -rf "$script_dir/$lnd_dir/logs"
  done
}

setup-bitcoind() {
  echo "=> setting up bitcoind"
  local bitcoind_dir="$script_dir/bitcoind"
  local bitcoind_conf="$bitcoind_dir/bitcoin.conf"
  local bitcoind_pid="$bitcoind_dir/bitcoind.pid"

  bitcoind -conf="$bitcoind_conf" -datadir="$bitcoind_dir" -daemonwait -pid="$bitcoind_pid"
  bitcoin-cli -conf="$bitcoind_conf" -datadir="$bitcoind_dir" -rpcwait createwallet dev >/dev/null
  echo "bitcoind wallet created"
  bitcoin-cli -conf="$bitcoind_conf" -generate 101 >/dev/null
  echo "bitcoind blocks generated"
}

setup-lnd() {
  local lnd_name="$1"
  local lnd_port="$2"
  local lnd_dir="$script_dir/$lnd_name"
  echo "=> setting up lnd $lnd_name"
  nohup lnd --lnddir="$lnd_dir" &>/dev/null &
  echo "$!" > "$lnd_dir/lnd.pid"
  local retries=30
  echo "waiting for ready"
  while [[ $retries -gt 0 ]] && ! lncli -n regtest --lnddir="$lnd_dir" --no-macaroons --rpcserver "localhost:$lnd_port" getinfo &>/dev/null; do
    sleep 1
    retries=$((retries - 1))
  done
  echo "remaining retries=$retries"
}

setup-channels() {
  echo "=> open channel from ingrid to bob"
  local bob_dir="$script_dir/lnd-bob"
  local ingrid_dir="$script_dir/lnd-ingrid"
  local ingrid_p2tr_address="$(lncli -n regtest --lnddir="$ingrid_dir" --no-macaroons --rpcserver "localhost:$ingrid_port" newaddress p2tr | jq -r .address)"
  local bob_node_key="$(lncli -n regtest --lnddir="$bob_dir" --no-macaroons --rpcserver "localhost:$bob_port" getinfo | jq -r .identity_pubkey)"
  echo "ingrid_p2tr_address=$ingrid_p2tr_address"
  echo "bob_node_key=$bob_node_key"

  echo "deposit btc"
  local bitcoind_dir="$script_dir/bitcoind"
  local bitcoind_conf="$bitcoind_dir/bitcoin.conf"
  bitcoin-cli -conf="$bitcoind_conf" -rpcwait -named sendtoaddress address="$ingrid_p2tr_address" amount=5 fee_rate=25
  bitcoin-cli -conf="$bitcoind_conf" -generate 1 >/dev/null

  echo "openchannel"
  local retries=5
  while [[ $retries -gt 0 ]] && ! lncli -n regtest --lnddir="$ingrid_dir" --no-macaroons --rpcserver "localhost:$ingrid_port" \
      openchannel \
      --node_key "$bob_node_key" \
      --connect localhost:9835 \
      --local_amt 1000000 \
      --sat_per_vbyte 1 \
      --min_confs 0; do
    sleep 3
    retries=$((retries - 1))
  done

  echo "generate blocks"
  bitcoin-cli -conf="$bitcoind_conf" -generate 3 >/dev/null
}

cleanup
setup-bitcoind
setup-lnd lnd-bob $bob_port
setup-lnd lnd-ingrid $ingrid_port
setup-channels


================================================
File: tests/deploy/lnd-init/.gitignore
================================================
/bitcoind/regtest
/lnd-bob/data
/lnd-bob/letsencrypt
/lnd-bob/logs
/lnd-bob/tls.cert
/lnd-bob/tls.key
/lnd-ingrid/data
/lnd-ingrid/letsencrypt
/lnd-ingrid/logs
/lnd-ingrid/tls.cert
/lnd-ingrid/tls.key
*.pid


================================================
File: tests/deploy/lnd-init/bitcoind/bitcoin.conf
================================================
server=1
regtest=1

[regtest]
rpcport=18443
rpcuser=btc
rpcpassword=btc
zmqpubrawblock=tcp://127.0.0.1:28332
zmqpubrawtx=tcp://127.0.0.1:28333


================================================
File: tests/deploy/lnd-init/lnd-bob/lnd.conf
================================================
[Application Options]
listen=0.0.0.0:9835
rpclisten=localhost:11009
restlisten=localhost:8180
no-macaroons=true
no-rest-tls=true
noseedbackup=true

[Bitcoin]
bitcoin.active=1
bitcoin.regtest=1
bitcoin.node=bitcoind

[Bitcoind]
bitcoind.rpchost=localhost:18443
bitcoind.rpcuser=btc
bitcoind.rpcpass=btc
bitcoind.zmqpubrawblock=tcp://127.0.0.1:28332
bitcoind.zmqpubrawtx=tcp://127.0.0.1:28333


================================================
File: tests/deploy/lnd-init/lnd-ingrid/lnd.conf
================================================
[Application Options]
listen=0.0.0.0:9735
rpclisten=localhost:10009
restlisten=localhost:8080
no-macaroons=true
no-rest-tls=true
noseedbackup=true

[Bitcoin]
bitcoin.active=1
bitcoin.regtest=1
bitcoin.node=bitcoind

[Bitcoind]
bitcoind.rpchost=localhost:18443
bitcoind.rpcuser=btc
bitcoind.rpcpass=btc
bitcoind.zmqpubrawblock=tcp://127.0.0.1:28332
bitcoind.zmqpubrawtx=tcp://127.0.0.1:28333


================================================
File: tests/deploy/migrations/templates/commitment-lock.toml
================================================
[[cells]]
name = "commitment-lock"
enable_type_id = true
location = { file = "contracts/commitment-lock" }

[[cells]]
name = "lock-dep-auth"
enable_type_id = false
location = { file = "contracts/auth" }
[[cells]]
name = "lock-dep-simple_udt"
enable_type_id = false
location = { file = "contracts/simple_udt" }

# Dep group cells
[[dep_groups]]
name = "commitment-lock-dev-group"
cells = ["commitment-lock", "lock-dep-auth", "lock-dep-simple_udt"]

# The lock script set to output cells
[lock]
code_hash = "0x9bd7e06f3ecf4be0f2fcd2188b23f1b9fcc88e5d4b65a8637b17723bbda3cce8"
args = "0xc8328aabcd9b9e8e64fbc566c4385c3bdeb219d7"
hash_type = "type"


================================================
File: tests/deploy/migrations/templates/funding-lock.toml
================================================
[[cells]]
name = "funding-lock"
enable_type_id = true
location = { file = "contracts/funding-lock" }

[[cells]]
name = "lock-dep-auth"
enable_type_id = false
location = { file = "contracts/auth" }
[[cells]]
name = "lock-dep-simple_udt"
enable_type_id = false
location = { file = "contracts/simple_udt" }

# Dep group cells
[[dep_groups]]
name = "funding-lock-dev-group"
cells = [
  "funding-lock",
  "lock-dep-auth",
  "lock-dep-simple_udt",
]

# The lock script set to output cells
[lock]
code_hash = "0x9bd7e06f3ecf4be0f2fcd2188b23f1b9fcc88e5d4b65a8637b17723bbda3cce8"
args = "0xc8328aabcd9b9e8e64fbc566c4385c3bdeb219d7"
hash_type = "type"

================================================
File: tests/deploy/migrations/templates/simple-udt.toml
================================================
[[cells]]
name = "simple_udt"
enable_type_id = true
location = { file = "contracts/simple_udt" }

# The lock script set to output cells
[lock]
code_hash = "0x9bd7e06f3ecf4be0f2fcd2188b23f1b9fcc88e5d4b65a8637b17723bbda3cce8"
args = "0xc8328aabcd9b9e8e64fbc566c4385c3bdeb219d7"
hash_type = "type"

================================================
File: tests/deploy/migrations/templates/xudt.toml
================================================
[[cells]]
name = "xudt"
enable_type_id = true
location = { file = "contracts/xudt_rce" }

# The lock script set to output cells
[lock]
code_hash = "0x9bd7e06f3ecf4be0f2fcd2188b23f1b9fcc88e5d4b65a8637b17723bbda3cce8"
args = "0xc8328aabcd9b9e8e64fbc566c4385c3bdeb219d7"
hash_type = "type"

================================================
File: tests/deploy/udt-init/README.md
================================================
# udt-dev-init


================================================
File: tests/deploy/udt-init/Cargo.lock
================================================
# This file is automatically @generated by Cargo.
# It is not intended for manual editing.
version = 3

[[package]]
name = "addr2line"
version = "0.22.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6e4503c46a5c0c7844e948c9a4d6acd9f50cccb4de1c48eb9e291ea17470c678"
dependencies = [
 "gimli",
]

[[package]]
name = "adler"
version = "1.0.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f26201604c87b1e01bd3d98f8d5d9a8fcbb815e8cedb41ffccbeb4bf593a35fe"

[[package]]
name = "ahash"
version = "0.7.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "891477e0c6a8957309ee5c45a6368af3ae14bb510732d2684ffa19af310920f9"
dependencies = [
 "getrandom 0.2.15",
 "once_cell",
 "version_check",
]

[[package]]
name = "anyhow"
version = "1.0.86"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b3d1d046238990b9cf5bcde22a3fb3584ee5cf65fb2765f454ed428c7a0063da"

[[package]]
name = "autocfg"
version = "1.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0c4b4d0bd25bd0b74681c0ad21497610ce1b7c91b1022cd21c80c6fbdd9476b0"

[[package]]
name = "backtrace"
version = "0.3.73"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5cc23269a4f8976d0a4d2e7109211a419fe30e8d88d677cd60b6bc79c5732e0a"
dependencies = [
 "addr2line",
 "cc",
 "cfg-if 1.0.0",
 "libc",
 "miniz_oxide",
 "object",
 "rustc-demangle",
]

[[package]]
name = "base64"
version = "0.21.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9d297deb1925b89f2ccc13d7635fa0714f12c87adce1c75356b39ca9b7178567"

[[package]]
name = "bech32"
version = "0.8.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cf9ff0bbfd639f15c74af777d81383cf53efb7c93613f6cab67c6c11e05bbf8b"

[[package]]
name = "bit-vec"
version = "0.6.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "349f9b6a179ed607305526ca489b34ad0a41aed5f7980fa90eb03160b69598fb"

[[package]]
name = "bitflags"
version = "1.3.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bef38d45163c2f1dde094a7dfd33ccf595c92905c8f8f4fdc18d06fb1037718a"

[[package]]
name = "bitflags"
version = "2.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cf4b9d6a944f767f8e5e0db018570623c85f3d925ac718db4e06d0187adb21c1"

[[package]]
name = "blake2b-ref"
version = "0.3.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "294d17c72e0ba59fad763caa112368d0672083779cdebbb97164f4bb4c1e339a"

[[package]]
name = "blake2b-rs"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a89a8565807f21b913288968e391819e7f9b2f0f46c7b89549c051cccf3a2771"
dependencies = [
 "cc",
 "cty",
]

[[package]]
name = "block-buffer"
version = "0.10.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3078c7629b62d3f0439517fa394996acacc5cbc91c5a20d8c658e77abd503a71"
dependencies = [
 "generic-array",
]

[[package]]
name = "bumpalo"
version = "3.16.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "79296716171880943b8470b5f8d03aa55eb2e645a4874bdbb28adb49162e012c"

[[package]]
name = "byteorder"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1fd0f2584146f6f2ef48085050886acf353beff7305ebd1ae69500e27c67f64b"

[[package]]
name = "bytes"
version = "1.6.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "514de17de45fdb8dc022b1a7975556c53c86f9f0aa5f534b98977b171857c2c9"
dependencies = [
 "serde",
]

[[package]]
name = "cacache"
version = "12.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "142316461ed3a3dfcba10417317472da5bfd0461e4d276bf7c07b330766d9490"
dependencies = [
 "digest",
 "either",
 "futures",
 "hex",
 "libc",
 "memmap2",
 "miette",
 "reflink-copy",
 "serde",
 "serde_derive",
 "serde_json",
 "sha1",
 "sha2",
 "ssri",
 "tempfile",
 "thiserror",
 "tokio",
 "tokio-stream",
 "walkdir",
]

[[package]]
name = "cc"
version = "1.0.99"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "96c51067fd44124faa7f870b4b1c969379ad32b2ba805aa959430ceaa384f695"

[[package]]
name = "cfg-if"
version = "0.1.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4785bdd1c96b2a846b2bd7cc02e86b6b3dbf14e7e53446c4f54c92a361040822"

[[package]]
name = "cfg-if"
version = "1.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "baf1de4339761588bc0619e3cbc0120ee582ebb74b53b4efbf79117bd2da40fd"

[[package]]
name = "ckb-chain-spec"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "38fa470ac81179a066b3dd3e0d56e8fb9988aaddf5c2ae921cbc2ee6c60bbc56"
dependencies = [
 "cacache",
 "ckb-constant",
 "ckb-crypto",
 "ckb-dao-utils",
 "ckb-error",
 "ckb-hash",
 "ckb-jsonrpc-types",
 "ckb-logger",
 "ckb-pow",
 "ckb-rational",
 "ckb-resource",
 "ckb-traits",
 "ckb-types",
 "serde",
 "toml",
]

[[package]]
name = "ckb-channel"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "081350579a7d6cee3c7d3b82b3667860517e785269f8cd72b27ae472775d9c04"
dependencies = [
 "crossbeam-channel",
]

[[package]]
name = "ckb-constant"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fce0d46bfe7d555b60e7e1b589643bcd2d6a40e4cc0a04c5e9412dbb30c1f206"

[[package]]
name = "ckb-crypto"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d2b268e177104ec7089656562adac06dd8209298873cb806fff76c1d3df16566"
dependencies = [
 "ckb-fixed-hash",
 "faster-hex",
 "lazy_static",
 "rand 0.8.5",
 "secp256k1",
 "thiserror",
]

[[package]]
name = "ckb-dao-utils"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1df36dfa384153423e777f3f40beeb5fbb42d5ba223d411d7850bf72e190428e"
dependencies = [
 "byteorder",
 "ckb-error",
 "ckb-types",
]

[[package]]
name = "ckb-error"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e6726194aed3b38485270e64d3823b3fb5e9d7ce6ea2ea117106f97619272de5"
dependencies = [
 "anyhow",
 "ckb-occupied-capacity",
 "derive_more",
 "thiserror",
]

[[package]]
name = "ckb-fixed-hash"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e497f03441f4622bc6d1d44db95ff47c37bec03ef2c8132ca19ac8005c70995f"
dependencies = [
 "ckb-fixed-hash-core",
 "ckb-fixed-hash-macros",
]

[[package]]
name = "ckb-fixed-hash-core"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bb5f80c82b9b0498272f085b86824cfe0b76a2c04ee653a91f9ff362fd9b6f6c"
dependencies = [
 "ckb_schemars",
 "faster-hex",
 "serde",
 "thiserror",
]

[[package]]
name = "ckb-fixed-hash-macros"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "00ede2291016d17450e9d117fac6fb515629779e31ea452d5146a117cd12bf0f"
dependencies = [
 "ckb-fixed-hash-core",
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "ckb-gen-types"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e0a7891f62f4ae4f018bfde91a46178c78491a1dfee740a20b994003a23f10af"
dependencies = [
 "cfg-if 1.0.0",
 "ckb-error",
 "ckb-fixed-hash",
 "ckb-hash",
 "ckb-occupied-capacity",
 "molecule",
 "numext-fixed-uint",
]

[[package]]
name = "ckb-hash"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d96b7aec74956ae5e79d0fc68e5903dc2b133c2c64644514485bbc9feb5367eb"
dependencies = [
 "blake2b-ref",
 "blake2b-rs",
]

[[package]]
name = "ckb-jsonrpc-types"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "44e622a66404770b52da9dfbc9b994f2b711ea2368ef23cc9b1c96ca38491ecf"
dependencies = [
 "ckb-types",
 "ckb_schemars",
 "faster-hex",
 "serde",
 "serde_json",
]

[[package]]
name = "ckb-logger"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c76af0252cd14e57fafac7c67282eedb9c7bbf40a529ed4eb1bb85067b767e7a"
dependencies = [
 "log",
]

[[package]]
name = "ckb-merkle-mountain-range"
version = "0.5.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "56ccb671c5921be8a84686e6212ca184cb1d7c51cadcdbfcbd1cc3f042f5dfb8"
dependencies = [
 "cfg-if 1.0.0",
]

[[package]]
name = "ckb-mock-tx-types"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fd785084e7c3903cb49f0d2abb12c56880827cae14723cd4fed1bf3fa26a74db"
dependencies = [
 "ckb-jsonrpc-types",
 "ckb-traits",
 "ckb-types",
 "serde",
]

[[package]]
name = "ckb-occupied-capacity"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5e01910f17fcdb1850df67a5b340bbb98d18948eacb476fc85d9a7699294d7ab"
dependencies = [
 "ckb-occupied-capacity-core",
 "ckb-occupied-capacity-macros",
]

[[package]]
name = "ckb-occupied-capacity-core"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "21ead5905cedba4acf082f88723c8f42a508bd28fd9c00e1dbf170049ef778b4"
dependencies = [
 "serde",
]

[[package]]
name = "ckb-occupied-capacity-macros"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "893198354933ba8fa0a1d99c013c819a295f6ae30b1af89fc14e0b62d7afa024"
dependencies = [
 "ckb-occupied-capacity-core",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "ckb-pow"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "069c3db99adb9d350d186de8e02a43e77dff7be2a8b9b7cf61ba80a280e2dd00"
dependencies = [
 "byteorder",
 "ckb-hash",
 "ckb-types",
 "eaglesong",
 "log",
 "serde",
]

[[package]]
name = "ckb-rational"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7be813511d1c17a6bab8a7dcfbee6e086aa2bae3bb77cfd4a570abfb67af2c16"
dependencies = [
 "numext-fixed-uint",
 "serde",
]

[[package]]
name = "ckb-resource"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d1e74f9bc4039a4cf6d579dc8b444b3d76780e51aab94daccdd5e6e58d01cc32"
dependencies = [
 "ckb-system-scripts",
 "ckb-types",
 "includedir",
 "includedir_codegen",
 "phf",
 "serde",
 "walkdir",
]

[[package]]
name = "ckb-script"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f6b92a1f4f059f4680b08817dfb739a40356dcf4798b3cb8ae1f1d67218eb0fb"
dependencies = [
 "byteorder",
 "ckb-chain-spec",
 "ckb-error",
 "ckb-hash",
 "ckb-logger",
 "ckb-traits",
 "ckb-types",
 "ckb-vm",
 "faster-hex",
 "serde",
 "tokio",
]

[[package]]
name = "ckb-sdk"
version = "3.4.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "75d816b57b37c49a99c715f07e120928d8139993523efec0b9e2faa94db7edce"
dependencies = [
 "anyhow",
 "bech32",
 "bitflags 1.3.2",
 "bytes",
 "ckb-chain-spec",
 "ckb-crypto",
 "ckb-dao-utils",
 "ckb-hash",
 "ckb-jsonrpc-types",
 "ckb-mock-tx-types",
 "ckb-resource",
 "ckb-script",
 "ckb-traits",
 "ckb-types",
 "dashmap",
 "derive-getters",
 "dyn-clone",
 "enum-repr-derive",
 "futures",
 "jsonrpc-core",
 "lazy_static",
 "log",
 "lru",
 "parking_lot",
 "reqwest",
 "secp256k1",
 "serde",
 "serde_derive",
 "serde_json",
 "sha3",
 "sparse-merkle-tree",
 "thiserror",
 "tokio",
 "tokio-util",
]

[[package]]
name = "ckb-system-scripts"
version = "0.5.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fa5c59063142de7a68cfad4449c6b3863563856219a2925dfb8c5f019ec2aa47"
dependencies = [
 "blake2b-rs",
 "faster-hex",
 "includedir",
 "includedir_codegen",
 "phf",
]

[[package]]
name = "ckb-traits"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b6500281355bbf7a235fb386b2883e8ffb8cb5bab8447bd86dd229148ec52704"
dependencies = [
 "ckb-types",
]

[[package]]
name = "ckb-types"
version = "0.118.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "88f4ef54b7665440d1984489c580e8d540888496d7b9ff8d57262ac583ff97a4"
dependencies = [
 "bit-vec",
 "bytes",
 "ckb-channel",
 "ckb-constant",
 "ckb-error",
 "ckb-fixed-hash",
 "ckb-gen-types",
 "ckb-hash",
 "ckb-merkle-mountain-range",
 "ckb-occupied-capacity",
 "ckb-rational",
 "derive_more",
 "golomb-coded-set",
 "merkle-cbt",
 "molecule",
 "numext-fixed-uint",
 "once_cell",
 "paste",
]

[[package]]
name = "ckb-vm"
version = "0.24.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ddff96029d3298cb630e95f29d4b9a93384e938a0b75758684aa8794b53bdd1a"
dependencies = [
 "byteorder",
 "bytes",
 "cc",
 "ckb-vm-definitions",
 "derive_more",
 "goblin 0.2.3",
 "goblin 0.4.0",
 "rand 0.7.3",
 "scroll",
 "serde",
]

[[package]]
name = "ckb-vm-definitions"
version = "0.24.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c280bf1d589d23ab0358f58601c2187fc6be86a131644583ef72ea96a0a13ddd"
dependencies = [
 "paste",
]

[[package]]
name = "ckb_schemars"
version = "0.8.19"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f21f99fca82a4eb8708e406e99246987b087ecc1e1babeece1a0b1d5238b1750"
dependencies = [
 "ckb_schemars_derive",
 "dyn-clone",
 "serde",
 "serde_json",
]

[[package]]
name = "ckb_schemars_derive"
version = "0.8.19"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "40c813b4fadbdd9f33b1cf02a1ddfa9537d955c8d2fbe150d1fc1684dbf78e73"
dependencies = [
 "proc-macro2",
 "quote",
 "serde_derive_internals",
 "syn 1.0.109",
]

[[package]]
name = "convert_case"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6245d59a3e82a7fc217c5828a6692dbc6dfb63a0c8c90495621f7b9d79704a0e"

[[package]]
name = "core-foundation"
version = "0.9.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "91e195e091a93c46f7102ec7818a2aa394e1e1771c3ab4825963fa03e45afb8f"
dependencies = [
 "core-foundation-sys",
 "libc",
]

[[package]]
name = "core-foundation-sys"
version = "0.8.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "06ea2b9bc92be3c2baa9334a323ebca2d6f074ff852cd1d7b11064035cd3868f"

[[package]]
name = "cpufeatures"
version = "0.2.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "53fe5e26ff1b7aef8bca9c6080520cfb8d9333c7568e1829cef191a9723e5504"
dependencies = [
 "libc",
]

[[package]]
name = "crc32fast"
version = "1.4.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a97769d94ddab943e4510d138150169a2758b5ef3eb191a9ee688de3e23ef7b3"
dependencies = [
 "cfg-if 1.0.0",
]

[[package]]
name = "crossbeam-channel"
version = "0.5.13"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "33480d6946193aa8033910124896ca395333cae7e2d1113d1fef6c3272217df2"
dependencies = [
 "crossbeam-utils",
]

[[package]]
name = "crossbeam-utils"
version = "0.8.20"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "22ec99545bb0ed0ea7bb9b8e1e9122ea386ff8a48c0922e43f36d45ab09e0e80"

[[package]]
name = "crypto-common"
version = "0.1.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1bfb12502f3fc46cca1bb51ac28df9d618d813cdc3d2f25b9fe775a34af26bb3"
dependencies = [
 "generic-array",
 "typenum",
]

[[package]]
name = "cty"
version = "0.2.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b365fabc795046672053e29c954733ec3b05e4be654ab130fe8f1f94d7051f35"

[[package]]
name = "dashmap"
version = "5.5.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "978747c1d849a7d2ee5e8adc0159961c48fb7e5db2f06af6723b80123bb53856"
dependencies = [
 "cfg-if 1.0.0",
 "hashbrown 0.14.5",
 "lock_api",
 "once_cell",
 "parking_lot_core",
]

[[package]]
name = "derive-getters"
version = "0.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0122f262bf9c9a367829da84f808d9fb128c10ef283bbe7b0922a77cf07b2747"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "derive_more"
version = "0.99.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4fb810d30a7c1953f91334de7244731fc3f3c10d7fe163338a35b9f640960321"
dependencies = [
 "convert_case",
 "proc-macro2",
 "quote",
 "rustc_version",
 "syn 1.0.109",
]

[[package]]
name = "digest"
version = "0.10.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9ed9a281f7bc9b7576e61468ba615a66a5c8cfdff42420a70aa82701a3b1e292"
dependencies = [
 "block-buffer",
 "crypto-common",
]

[[package]]
name = "displaydoc"
version = "0.2.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "97369cbbc041bc366949bc74d34658d6cda5621039731c6310521892a3a20ae0"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.66",
]

[[package]]
name = "dyn-clone"
version = "1.0.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0d6ef0072f8a535281e4876be788938b528e9a1d43900b82c2569af7da799125"

[[package]]
name = "eaglesong"
version = "0.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8d978bd5d343e8ab9b5c0fc8d93ff9c602fdc96616ffff9c05ac7a155419b824"

[[package]]
name = "either"
version = "1.12.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3dca9240753cf90908d7e4aac30f630662b02aebaa1b58a3cadabdb23385b58b"

[[package]]
name = "encoding_rs"
version = "0.8.34"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b45de904aa0b010bce2ab45264d0631681847fa7b6f2eaa7dab7619943bc4f59"
dependencies = [
 "cfg-if 1.0.0",
]

[[package]]
name = "enum-repr-derive"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c6f2936062c28214e84685742fa4affc52a39d036e8a3dcf98034810e449ec95"
dependencies = [
 "proc-macro-error",
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "equivalent"
version = "1.0.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5443807d6dff69373d433ab9ef5378ad8df50ca6298caf15de6e52e24aaf54d5"

[[package]]
name = "errno"
version = "0.3.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "534c5cf6194dfab3db3242765c03bbe257cf92f22b38f6bc0c58d59108a820ba"
dependencies = [
 "libc",
 "windows-sys 0.52.0",
]

[[package]]
name = "faster-hex"
version = "0.6.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "51e2ce894d53b295cf97b05685aa077950ff3e8541af83217fc720a6437169f8"

[[package]]
name = "fastrand"
version = "2.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9fc0510504f03c51ada170672ac806f1f105a88aa97a5281117e1ddc3368e51a"

[[package]]
name = "flate2"
version = "1.0.30"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5f54427cfd1c7829e2a139fcefea601bf088ebca651d2bf53ebc600eac295dae"
dependencies = [
 "crc32fast",
 "miniz_oxide",
]

[[package]]
name = "fnv"
version = "1.0.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3f9eec918d3f24069decb9af1554cad7c880e2da24a9afd88aca000531ab82c1"

[[package]]
name = "foreign-types"
version = "0.3.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f6f339eb8adc052cd2ca78910fda869aefa38d22d5cb648e6485e4d3fc06f3b1"
dependencies = [
 "foreign-types-shared",
]

[[package]]
name = "foreign-types-shared"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "00b0228411908ca8685dba7fc2cdd70ec9990a6e753e89b6ac91a84c40fbaf4b"

[[package]]
name = "form_urlencoded"
version = "1.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e13624c2627564efccf4934284bdd98cbaa14e79b0b5a141218e507b3a823456"
dependencies = [
 "percent-encoding",
]

[[package]]
name = "futures"
version = "0.3.30"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "645c6916888f6cb6350d2550b80fb63e734897a8498abe35cfb732b6487804b0"
dependencies = [
 "futures-channel",
 "futures-core",
 "futures-executor",
 "futures-io",
 "futures-sink",
 "futures-task",
 "futures-util",
]

[[package]]
name = "futures-channel"
version = "0.3.30"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "eac8f7d7865dcb88bd4373ab671c8cf4508703796caa2b1985a9ca867b3fcb78"
dependencies = [
 "futures-core",
 "futures-sink",
]

[[package]]
name = "futures-core"
version = "0.3.30"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "dfc6580bb841c5a68e9ef15c77ccc837b40a7504914d52e47b8b0e9bbda25a1d"

[[package]]
name = "futures-executor"
version = "0.3.30"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a576fc72ae164fca6b9db127eaa9a9dda0d61316034f33a0a0d4eda41f02b01d"
dependencies = [
 "futures-core",
 "futures-task",
 "futures-util",
]

[[package]]
name = "futures-io"
version = "0.3.30"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a44623e20b9681a318efdd71c299b6b222ed6f231972bfe2f224ebad6311f0c1"

[[package]]
name = "futures-macro"
version = "0.3.30"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "87750cf4b7a4c0625b1529e4c543c2182106e4dedc60a2a6455e00d212c489ac"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.66",
]

[[package]]
name = "futures-sink"
version = "0.3.30"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9fb8e00e87438d937621c1c6269e53f536c14d3fbd6a042bb24879e57d474fb5"

[[package]]
name = "futures-task"
version = "0.3.30"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "38d84fa142264698cdce1a9f9172cf383a0c82de1bddcf3092901442c4097004"

[[package]]
name = "futures-util"
version = "0.3.30"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3d6401deb83407ab3da39eba7e33987a73c3df0c82b4bb5813ee871c19c41d48"
dependencies = [
 "futures-channel",
 "futures-core",
 "futures-io",
 "futures-macro",
 "futures-sink",
 "futures-task",
 "memchr",
 "pin-project-lite",
 "pin-utils",
 "slab",
]

[[package]]
name = "generic-array"
version = "0.14.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "85649ca51fd72272d7821adaf274ad91c288277713d9c18820d8499a7ff69e9a"
dependencies = [
 "typenum",
 "version_check",
]

[[package]]
name = "getrandom"
version = "0.1.16"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8fc3cb4d91f53b50155bdcfd23f6a4c39ae1969c2ae85982b135750cccaf5fce"
dependencies = [
 "cfg-if 1.0.0",
 "libc",
 "wasi 0.9.0+wasi-snapshot-preview1",
]

[[package]]
name = "getrandom"
version = "0.2.15"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c4567c8db10ae91089c99af84c68c38da3ec2f087c3f82960bcdbf3656b6f4d7"
dependencies = [
 "cfg-if 1.0.0",
 "libc",
 "wasi 0.11.0+wasi-snapshot-preview1",
]

[[package]]
name = "gimli"
version = "0.29.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "40ecd4077b5ae9fd2e9e169b102c6c330d0605168eb0e8bf79952b256dbefffd"

[[package]]
name = "goblin"
version = "0.2.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d20fd25aa456527ce4f544271ae4fea65d2eda4a6561ea56f39fb3ee4f7e3884"
dependencies = [
 "log",
 "plain",
 "scroll",
]

[[package]]
name = "goblin"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "532a09cd3df2c6bbfc795fb0434bff8f22255d1d07328180e918a2e6ce122d4d"
dependencies = [
 "log",
 "plain",
 "scroll",
]

[[package]]
name = "golomb-coded-set"
version = "0.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "812f314a99fb5b7f0f9d0a8388539578f83f3aca6a65f588b8dbeefb731e2f98"
dependencies = [
 "siphasher",
]

[[package]]
name = "h2"
version = "0.3.26"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "81fe527a889e1532da5c525686d96d4c2e74cdd345badf8dfef9f6b39dd5f5e8"
dependencies = [
 "bytes",
 "fnv",
 "futures-core",
 "futures-sink",
 "futures-util",
 "http",
 "indexmap",
 "slab",
 "tokio",
 "tokio-util",
 "tracing",
]

[[package]]
name = "hashbrown"
version = "0.12.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8a9ee70c43aaf417c914396645a0fa852624801b24ebb7ae78fe8272889ac888"
dependencies = [
 "ahash",
]

[[package]]
name = "hashbrown"
version = "0.14.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e5274423e17b7c9fc20b6e7e208532f9b19825d82dfd615708b70edd83df41f1"

[[package]]
name = "heapsize"
version = "0.4.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1679e6ea370dee694f91f1dc469bf94cf8f52051d147aec3e1f9497c6fc22461"
dependencies = [
 "winapi",
]

[[package]]
name = "hermit-abi"
version = "0.3.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d231dfb89cfffdbc30e7fc41579ed6066ad03abda9e567ccafae602b97ec5024"

[[package]]
name = "hex"
version = "0.4.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7f24254aa9a54b5c858eaee2f5bccdb46aaf0e486a595ed5fd8f86ba55232a70"

[[package]]
name = "http"
version = "0.2.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "601cbb57e577e2f5ef5be8e7b83f0f63994f25aa94d673e54a92d5c516d101f1"
dependencies = [
 "bytes",
 "fnv",
 "itoa",
]

[[package]]
name = "http-body"
version = "0.4.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7ceab25649e9960c0311ea418d17bee82c0dcec1bd053b5f9a66e265a693bed2"
dependencies = [
 "bytes",
 "http",
 "pin-project-lite",
]

[[package]]
name = "httparse"
version = "1.9.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0fcc0b4a115bf80b728eb8ea024ad5bd707b615bfed49e0665b6e0f86fd082d9"

[[package]]
name = "httpdate"
version = "1.0.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "df3b46402a9d5adb4c86a0cf463f42e19994e3ee891101b1841f30a545cb49a9"

[[package]]
name = "hyper"
version = "0.14.29"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f361cde2f109281a220d4307746cdfd5ee3f410da58a70377762396775634b33"
dependencies = [
 "bytes",
 "futures-channel",
 "futures-core",
 "futures-util",
 "h2",
 "http",
 "http-body",
 "httparse",
 "httpdate",
 "itoa",
 "pin-project-lite",
 "socket2",
 "tokio",
 "tower-service",
 "tracing",
 "want",
]

[[package]]
name = "hyper-tls"
version = "0.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d6183ddfa99b85da61a140bea0efc93fdf56ceaa041b37d553518030827f9905"
dependencies = [
 "bytes",
 "hyper",
 "native-tls",
 "tokio",
 "tokio-native-tls",
]

[[package]]
name = "icu_collections"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "db2fa452206ebee18c4b5c2274dbf1de17008e874b4dc4f0aea9d01ca79e4526"
dependencies = [
 "displaydoc",
 "yoke",
 "zerofrom",
 "zerovec",
]

[[package]]
name = "icu_locid"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "13acbb8371917fc971be86fc8057c41a64b521c184808a698c02acc242dbf637"
dependencies = [
 "displaydoc",
 "litemap",
 "tinystr",
 "writeable",
 "zerovec",
]

[[package]]
name = "icu_locid_transform"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "01d11ac35de8e40fdeda00d9e1e9d92525f3f9d887cdd7aa81d727596788b54e"
dependencies = [
 "displaydoc",
 "icu_locid",
 "icu_locid_transform_data",
 "icu_provider",
 "tinystr",
 "zerovec",
]

[[package]]
name = "icu_locid_transform_data"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fdc8ff3388f852bede6b579ad4e978ab004f139284d7b28715f773507b946f6e"

[[package]]
name = "icu_normalizer"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "19ce3e0da2ec68599d193c93d088142efd7f9c5d6fc9b803774855747dc6a84f"
dependencies = [
 "displaydoc",
 "icu_collections",
 "icu_normalizer_data",
 "icu_properties",
 "icu_provider",
 "smallvec",
 "utf16_iter",
 "utf8_iter",
 "write16",
 "zerovec",
]

[[package]]
name = "icu_normalizer_data"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f8cafbf7aa791e9b22bec55a167906f9e1215fd475cd22adfcf660e03e989516"

[[package]]
name = "icu_properties"
version = "1.5.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "93d6020766cfc6302c15dbbc9c8778c37e62c14427cb7f6e601d849e092aeef5"
dependencies = [
 "displaydoc",
 "icu_collections",
 "icu_locid_transform",
 "icu_properties_data",
 "icu_provider",
 "tinystr",
 "zerovec",
]

[[package]]
name = "icu_properties_data"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "67a8effbc3dd3e4ba1afa8ad918d5684b8868b3b26500753effea8d2eed19569"

[[package]]
name = "icu_provider"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6ed421c8a8ef78d3e2dbc98a973be2f3770cb42b606e3ab18d6237c4dfde68d9"
dependencies = [
 "displaydoc",
 "icu_locid",
 "icu_provider_macros",
 "stable_deref_trait",
 "tinystr",
 "writeable",
 "yoke",
 "zerofrom",
 "zerovec",
]

[[package]]
name = "icu_provider_macros"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1ec89e9337638ecdc08744df490b221a7399bf8d164eb52a665454e60e075ad6"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.66",
]

[[package]]
name = "idna"
version = "1.0.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "686f825264d630750a544639377bae737628043f20d38bbc029e8f29ea968a7e"
dependencies = [
 "idna_adapter",
 "smallvec",
 "utf8_iter",
]

[[package]]
name = "idna_adapter"
version = "1.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "daca1df1c957320b2cf139ac61e7bd64fed304c5040df000a745aa1de3b4ef71"
dependencies = [
 "icu_normalizer",
 "icu_properties",
]

[[package]]
name = "includedir"
version = "0.6.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "afd126bd778c00c43a9dc76d1609a0894bf4222088088b2217ccc0ce9e816db7"
dependencies = [
 "flate2",
 "phf",
]

[[package]]
name = "includedir_codegen"
version = "0.6.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0ac1500c9780957c9808c4ec3b94002f35aab01483833f5a8bce7dfb243e3148"
dependencies = [
 "flate2",
 "phf_codegen",
 "walkdir",
]

[[package]]
name = "indexmap"
version = "2.2.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "168fb715dda47215e360912c096649d23d58bf392ac62f73919e831745e40f26"
dependencies = [
 "equivalent",
 "hashbrown 0.14.5",
]

[[package]]
name = "ipnet"
version = "2.9.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8f518f335dce6725a761382244631d86cf0ccb2863413590b31338feb467f9c3"

[[package]]
name = "itoa"
version = "1.0.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "49f1f14873335454500d59611f1cf4a4b0f786f9ac11f4312a78e4cf2566695b"

[[package]]
name = "js-sys"
version = "0.3.69"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "29c15563dc2726973df627357ce0c9ddddbea194836909d655df6a75d2cf296d"
dependencies = [
 "wasm-bindgen",
]

[[package]]
name = "jsonrpc-core"
version = "18.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "14f7f76aef2d054868398427f6c54943cf3d1caa9a7ec7d0c38d69df97a965eb"
dependencies = [
 "futures",
 "futures-executor",
 "futures-util",
 "log",
 "serde",
 "serde_derive",
 "serde_json",
]

[[package]]
name = "keccak"
version = "0.1.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ecc2af9a1119c51f12a14607e783cb977bde58bc069ff0c3da1095e635d70654"
dependencies = [
 "cpufeatures",
]

[[package]]
name = "lazy_static"
version = "1.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e2abad23fbc42b3700f2f279844dc832adb2b2eb069b2df918f455c4e18cc646"

[[package]]
name = "libc"
version = "0.2.155"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "97b3888a4aecf77e811145cadf6eef5901f4782c53886191b2f693f24761847c"

[[package]]
name = "linux-raw-sys"
version = "0.4.14"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "78b3ae25bc7c8c38cec158d1f2757ee79e9b3740fbc7ccf0e59e4b08d793fa89"

[[package]]
name = "litemap"
version = "0.7.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4ee93343901ab17bd981295f2cf0026d4ad018c7c31ba84549a4ddbb47a45104"

[[package]]
name = "lock_api"
version = "0.4.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "07af8b9cdd281b7915f413fa73f29ebd5d55d0d3f0155584dade1ff18cea1b17"
dependencies = [
 "autocfg",
 "scopeguard",
]

[[package]]
name = "log"
version = "0.4.21"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "90ed8c1e510134f979dbc4f070f87d4313098b704861a105fe34231c70a3901c"

[[package]]
name = "lru"
version = "0.7.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e999beba7b6e8345721bd280141ed958096a2e4abdf74f67ff4ce49b4b54e47a"
dependencies = [
 "hashbrown 0.12.3",
]

[[package]]
name = "memchr"
version = "2.7.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "78ca9ab1a0babb1e7d5695e3530886289c18cf2f87ec19a575a0abdce112e3a3"

[[package]]
name = "memmap2"
version = "0.5.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "83faa42c0a078c393f6b29d5db232d8be22776a891f8f56e5284faee4a20b327"
dependencies = [
 "libc",
]

[[package]]
name = "merkle-cbt"
version = "0.3.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "171d2f700835121c3b04ccf0880882987a050fd5c7ae88148abf537d33dd3a56"
dependencies = [
 "cfg-if 1.0.0",
]

[[package]]
name = "miette"
version = "5.10.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "59bb584eaeeab6bd0226ccf3509a69d7936d148cf3d036ad350abe35e8c6856e"
dependencies = [
 "miette-derive",
 "once_cell",
 "thiserror",
 "unicode-width",
]

[[package]]
name = "miette-derive"
version = "5.10.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "49e7bc1560b95a3c4a25d03de42fe76ca718ab92d1a22a55b9b4cf67b3ae635c"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.66",
]

[[package]]
name = "mime"
version = "0.3.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6877bb514081ee2a7ff5ef9de3281f14a4dd4bceac4c09388074a6b5df8a139a"

[[package]]
name = "miniz_oxide"
version = "0.7.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b8a240ddb74feaf34a79a7add65a741f3167852fba007066dcac1ca548d89c08"
dependencies = [
 "adler",
]

[[package]]
name = "mio"
version = "0.8.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a4a650543ca06a924e8b371db273b2756685faae30f8487da1b56505a8f78b0c"
dependencies = [
 "libc",
 "wasi 0.11.0+wasi-snapshot-preview1",
 "windows-sys 0.48.0",
]

[[package]]
name = "molecule"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6efe1c7efcd0bdf4ca590e104bcb13087d9968956ae4ae98e92fb8c1da0f3730"
dependencies = [
 "bytes",
 "cfg-if 1.0.0",
 "faster-hex",
]

[[package]]
name = "native-tls"
version = "0.2.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a8614eb2c83d59d1c8cc974dd3f920198647674a0a035e1af1fa58707e317466"
dependencies = [
 "libc",
 "log",
 "openssl",
 "openssl-probe",
 "openssl-sys",
 "schannel",
 "security-framework",
 "security-framework-sys",
 "tempfile",
]

[[package]]
name = "num_cpus"
version = "1.16.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4161fcb6d602d4d2081af7c3a45852d875a03dd337a6bfdd6e06407b61342a43"
dependencies = [
 "hermit-abi",
 "libc",
]

[[package]]
name = "numext-constructor"
version = "0.1.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "621fe0f044729f810c6815cdd77e8f5e0cd803ce4f6a38380ebfc1322af98661"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "numext-fixed-uint"
version = "0.1.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6c68c76f96d589d1009a666c5072f37f3114d682696505f2cf445f27766c7d70"
dependencies = [
 "numext-fixed-uint-core",
 "numext-fixed-uint-hack",
]

[[package]]
name = "numext-fixed-uint-core"
version = "0.1.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6aab1d6457b97b49482f22a92f0f58a2f39bdd7f3b2f977eae67e8bc206aa980"
dependencies = [
 "heapsize",
 "numext-constructor",
 "rand 0.7.3",
 "serde",
 "thiserror",
]

[[package]]
name = "numext-fixed-uint-hack"
version = "0.1.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0200f8d55c36ec1b6a8cf810115be85d4814f045e0097dfd50033ba25adb4c9e"
dependencies = [
 "numext-fixed-uint-core",
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "object"
version = "0.36.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "576dfe1fc8f9df304abb159d767a29d0476f7750fbf8aa7ad07816004a207434"
dependencies = [
 "memchr",
]

[[package]]
name = "once_cell"
version = "1.19.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3fdb12b2476b595f9358c5161aa467c2438859caa136dec86c26fdd2efe17b92"

[[package]]
name = "openssl"
version = "0.10.70"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "61cfb4e166a8bb8c9b55c500bc2308550148ece889be90f609377e58140f42c6"
dependencies = [
 "bitflags 2.5.0",
 "cfg-if 1.0.0",
 "foreign-types",
 "libc",
 "once_cell",
 "openssl-macros",
 "openssl-sys",
]

[[package]]
name = "openssl-macros"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a948666b637a0f465e8564c73e89d4dde00d72d4d473cc972f390fc3dcee7d9c"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.66",
]

[[package]]
name = "openssl-probe"
version = "0.1.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ff011a302c396a5197692431fc1948019154afc178baf7d8e37367442a4601cf"

[[package]]
name = "openssl-sys"
version = "0.9.105"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8b22d5b84be05a8d6947c7cb71f7c849aa0f112acd4bf51c2a7c1c988ac0a9dc"
dependencies = [
 "cc",
 "libc",
 "pkg-config",
 "vcpkg",
]

[[package]]
name = "parking_lot"
version = "0.12.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f1bf18183cf54e8d6059647fc3063646a1801cf30896933ec2311622cc4b9a27"
dependencies = [
 "lock_api",
 "parking_lot_core",
]

[[package]]
name = "parking_lot_core"
version = "0.9.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1e401f977ab385c9e4e3ab30627d6f26d00e2c73eef317493c4ec6d468726cf8"
dependencies = [
 "cfg-if 1.0.0",
 "libc",
 "redox_syscall",
 "smallvec",
 "windows-targets 0.52.5",
]

[[package]]
name = "paste"
version = "1.0.15"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "57c0d7b74b563b49d38dae00a0c37d4d6de9b432382b2892f0574ddcae73fd0a"

[[package]]
name = "percent-encoding"
version = "2.3.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e3148f5046208a5d56bcfc03053e3ca6334e51da8dfb19b6cdc8b306fae3283e"

[[package]]
name = "phf"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3dfb61232e34fcb633f43d12c58f83c1df82962dcdfa565a4e866ffc17dafe12"
dependencies = [
 "phf_shared",
]

[[package]]
name = "phf_codegen"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cbffee61585b0411840d3ece935cce9cb6321f01c45477d30066498cd5e1a815"
dependencies = [
 "phf_generator",
 "phf_shared",
]

[[package]]
name = "phf_generator"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "17367f0cc86f2d25802b2c26ee58a7b23faeccf78a396094c13dced0d0182526"
dependencies = [
 "phf_shared",
 "rand 0.7.3",
]

[[package]]
name = "phf_shared"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c00cf8b9eafe68dde5e9eaa2cef8ee84a9336a47d566ec55ca16589633b65af7"
dependencies = [
 "siphasher",
]

[[package]]
name = "pin-project-lite"
version = "0.2.14"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bda66fc9667c18cb2758a2ac84d1167245054bcf85d5d1aaa6923f45801bdd02"

[[package]]
name = "pin-utils"
version = "0.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8b870d8c151b6f2fb93e84a13146138f05d02ed11c7e7c54f8826aaaf7c9f184"

[[package]]
name = "pkg-config"
version = "0.3.30"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d231b230927b5e4ad203db57bbcbee2802f6bce620b1e4a9024a07d94e2907ec"

[[package]]
name = "plain"
version = "0.2.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b4596b6d070b27117e987119b4dac604f3c58cfb0b191112e24771b2faeac1a6"

[[package]]
name = "ppv-lite86"
version = "0.2.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5b40af805b3121feab8a3c29f04d8ad262fa8e0561883e7653e024ae4479e6de"

[[package]]
name = "proc-macro-error"
version = "1.0.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "da25490ff9892aab3fcf7c36f08cfb902dd3e71ca0f9f9517bea02a73a5ce38c"
dependencies = [
 "proc-macro-error-attr",
 "proc-macro2",
 "quote",
 "syn 1.0.109",
 "version_check",
]

[[package]]
name = "proc-macro-error-attr"
version = "1.0.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a1be40180e52ecc98ad80b184934baf3d0d29f979574e439af5a55274b35f869"
dependencies = [
 "proc-macro2",
 "quote",
 "version_check",
]

[[package]]
name = "proc-macro2"
version = "1.0.85"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "22244ce15aa966053a896d1accb3a6e68469b97c7f33f284b99f0d576879fc23"
dependencies = [
 "unicode-ident",
]

[[package]]
name = "quote"
version = "1.0.36"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0fa76aaf39101c457836aec0ce2316dbdc3ab723cdda1c6bd4e6ad4208acaca7"
dependencies = [
 "proc-macro2",
]

[[package]]
name = "rand"
version = "0.7.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6a6b1679d49b24bbfe0c803429aa1874472f50d9b363131f0e89fc356b544d03"
dependencies = [
 "getrandom 0.1.16",
 "libc",
 "rand_chacha 0.2.2",
 "rand_core 0.5.1",
 "rand_hc",
 "rand_pcg",
]

[[package]]
name = "rand"
version = "0.8.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "34af8d1a0e25924bc5b7c43c079c942339d8f0a8b57c39049bef581b46327404"
dependencies = [
 "libc",
 "rand_chacha 0.3.1",
 "rand_core 0.6.4",
]

[[package]]
name = "rand_chacha"
version = "0.2.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f4c8ed856279c9737206bf725bf36935d8666ead7aa69b52be55af369d193402"
dependencies = [
 "ppv-lite86",
 "rand_core 0.5.1",
]

[[package]]
name = "rand_chacha"
version = "0.3.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e6c10a63a0fa32252be49d21e7709d4d4baf8d231c2dbce1eaa8141b9b127d88"
dependencies = [
 "ppv-lite86",
 "rand_core 0.6.4",
]

[[package]]
name = "rand_core"
version = "0.5.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "90bde5296fc891b0cef12a6d03ddccc162ce7b2aff54160af9338f8d40df6d19"
dependencies = [
 "getrandom 0.1.16",
]

[[package]]
name = "rand_core"
version = "0.6.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ec0be4795e2f6a28069bec0b5ff3e2ac9bafc99e6a9a7dc3547996c5c816922c"
dependencies = [
 "getrandom 0.2.15",
]

[[package]]
name = "rand_hc"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ca3129af7b92a17112d59ad498c6f81eaf463253766b90396d39ea7a39d6613c"
dependencies = [
 "rand_core 0.5.1",
]

[[package]]
name = "rand_pcg"
version = "0.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "16abd0c1b639e9eb4d7c50c0b8100b0d0f849be2349829c740fe8e6eb4816429"
dependencies = [
 "rand_core 0.5.1",
]

[[package]]
name = "redox_syscall"
version = "0.5.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c82cf8cff14456045f55ec4241383baeff27af886adb72ffb2162f99911de0fd"
dependencies = [
 "bitflags 2.5.0",
]

[[package]]
name = "reflink-copy"
version = "0.1.18"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6d731e7e3ebfcf422d96b8473e507d5b64790900dd5464772d38d1da9da24d3a"
dependencies = [
 "cfg-if 1.0.0",
 "rustix",
 "windows",
]

[[package]]
name = "reqwest"
version = "0.11.27"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "dd67538700a17451e7cba03ac727fb961abb7607553461627b97de0b89cf4a62"
dependencies = [
 "base64",
 "bytes",
 "encoding_rs",
 "futures-core",
 "futures-util",
 "h2",
 "http",
 "http-body",
 "hyper",
 "hyper-tls",
 "ipnet",
 "js-sys",
 "log",
 "mime",
 "native-tls",
 "once_cell",
 "percent-encoding",
 "pin-project-lite",
 "rustls-pemfile",
 "serde",
 "serde_json",
 "serde_urlencoded",
 "sync_wrapper",
 "system-configuration",
 "tokio",
 "tokio-native-tls",
 "tower-service",
 "url",
 "wasm-bindgen",
 "wasm-bindgen-futures",
 "web-sys",
 "winreg",
]

[[package]]
name = "rustc-demangle"
version = "0.1.24"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "719b953e2095829ee67db738b3bfa9fa368c94900df327b3f07fe6e794d2fe1f"

[[package]]
name = "rustc_version"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bfa0f585226d2e68097d4f95d113b15b83a82e819ab25717ec0590d9584ef366"
dependencies = [
 "semver",
]

[[package]]
name = "rustix"
version = "0.38.34"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "70dc5ec042f7a43c4a73241207cecc9873a06d45debb38b329f8541d85c2730f"
dependencies = [
 "bitflags 2.5.0",
 "errno",
 "libc",
 "linux-raw-sys",
 "windows-sys 0.52.0",
]

[[package]]
name = "rustls-pemfile"
version = "1.0.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1c74cae0a4cf6ccbbf5f359f08efdf8ee7e1dc532573bf0db71968cb56b1448c"
dependencies = [
 "base64",
]

[[package]]
name = "ryu"
version = "1.0.18"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f3cb5ba0dc43242ce17de99c180e96db90b235b8a9fdc9543c96d2209116bd9f"

[[package]]
name = "same-file"
version = "1.0.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "93fc1dc3aaa9bfed95e02e6eadabb4baf7e3078b0bd1b4d7b6b0b68378900502"
dependencies = [
 "winapi-util",
]

[[package]]
name = "schannel"
version = "0.1.23"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fbc91545643bcf3a0bbb6569265615222618bdf33ce4ffbbd13c4bbd4c093534"
dependencies = [
 "windows-sys 0.52.0",
]

[[package]]
name = "scopeguard"
version = "1.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "94143f37725109f92c262ed2cf5e59bce7498c01bcc1502d7b9afe439a4e9f49"

[[package]]
name = "scroll"
version = "0.10.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fda28d4b4830b807a8b43f7b0e6b5df875311b3e7621d84577188c175b6ec1ec"
dependencies = [
 "scroll_derive",
]

[[package]]
name = "scroll_derive"
version = "0.10.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "aaaae8f38bb311444cfb7f1979af0bc9240d95795f75f9ceddf6a59b79ceffa0"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "secp256k1"
version = "0.29.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9465315bc9d4566e1724f0fffcbcc446268cb522e60f9a27bcded6b19c108113"
dependencies = [
 "secp256k1-sys",
]

[[package]]
name = "secp256k1-sys"
version = "0.10.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d4387882333d3aa8cb20530a17c69a3752e97837832f34f6dccc760e715001d9"
dependencies = [
 "cc",
]

[[package]]
name = "security-framework"
version = "2.11.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c627723fd09706bacdb5cf41499e95098555af3c3c29d014dc3c458ef6be11c0"
dependencies = [
 "bitflags 2.5.0",
 "core-foundation",
 "core-foundation-sys",
 "libc",
 "security-framework-sys",
]

[[package]]
name = "security-framework-sys"
version = "2.11.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "317936bbbd05227752583946b9e66d7ce3b489f84e11a94a510b4437fef407d7"
dependencies = [
 "core-foundation-sys",
 "libc",
]

[[package]]
name = "semver"
version = "1.0.23"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "61697e0a1c7e512e84a621326239844a24d8207b4669b41bc18b32ea5cbf988b"

[[package]]
name = "serde"
version = "1.0.203"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7253ab4de971e72fb7be983802300c30b5a7f0c2e56fab8abfc6a214307c0094"
dependencies = [
 "serde_derive",
]

[[package]]
name = "serde_derive"
version = "1.0.203"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "500cbc0ebeb6f46627f50f3f5811ccf6bf00643be300b4c3eabc0ef55dc5b5ba"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.66",
]

[[package]]
name = "serde_derive_internals"
version = "0.26.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "85bf8229e7920a9f636479437026331ce11aa132b4dde37d121944a44d6e5f3c"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "serde_json"
version = "1.0.117"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "455182ea6142b14f93f4bc5320a2b31c1f266b66a4a5c858b013302a5d8cbfc3"
dependencies = [
 "itoa",
 "ryu",
 "serde",
]

[[package]]
name = "serde_urlencoded"
version = "0.7.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d3491c14715ca2294c4d6a88f15e84739788c1d030eed8c110436aafdaa2f3fd"
dependencies = [
 "form_urlencoded",
 "itoa",
 "ryu",
 "serde",
]

[[package]]
name = "serde_yaml"
version = "0.9.34+deprecated"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6a8b1a1a2ebf674015cc02edccce75287f1a0130d394307b36743c2f5d504b47"
dependencies = [
 "indexmap",
 "itoa",
 "ryu",
 "serde",
 "unsafe-libyaml",
]

[[package]]
name = "sha-1"
version = "0.10.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f5058ada175748e33390e40e872bd0fe59a19f265d0158daa551c5a88a76009c"
dependencies = [
 "cfg-if 1.0.0",
 "cpufeatures",
 "digest",
]

[[package]]
name = "sha1"
version = "0.10.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e3bf829a2d51ab4a5ddf1352d8470c140cadc8301b2ae1789db023f01cedd6ba"
dependencies = [
 "cfg-if 1.0.0",
 "cpufeatures",
 "digest",
]

[[package]]
name = "sha2"
version = "0.10.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "793db75ad2bcafc3ffa7c68b215fee268f537982cd901d132f89c6343f3a3dc8"
dependencies = [
 "cfg-if 1.0.0",
 "cpufeatures",
 "digest",
]

[[package]]
name = "sha3"
version = "0.10.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "75872d278a8f37ef87fa0ddbda7802605cb18344497949862c0d4dcb291eba60"
dependencies = [
 "digest",
 "keccak",
]

[[package]]
name = "siphasher"
version = "0.3.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "38b58827f4464d87d377d175e90bf58eb00fd8716ff0a62f80356b5e61555d0d"

[[package]]
name = "slab"
version = "0.4.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8f92a496fb766b417c996b9c5e57daf2f7ad3b0bebe1ccfca4856390e3d3bb67"
dependencies = [
 "autocfg",
]

[[package]]
name = "smallvec"
version = "1.13.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3c5e1a9a646d36c3599cd173a41282daf47c44583ad367b8e6837255952e5c67"

[[package]]
name = "socket2"
version = "0.5.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ce305eb0b4296696835b71df73eb912e0f1ffd2556a501fcede6e0c50349191c"
dependencies = [
 "libc",
 "windows-sys 0.52.0",
]

[[package]]
name = "sparse-merkle-tree"
version = "0.6.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8851f6c92491ebe5528eabc1244292175a739eb0162974f9f9670a7dc748748b"
dependencies = [
 "blake2b-rs",
 "cc",
 "cfg-if 0.1.10",
]

[[package]]
name = "ssri"
version = "9.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "da7a2b3c2bc9693bcb40870c4e9b5bf0d79f9cb46273321bf855ec513e919082"
dependencies = [
 "base64",
 "digest",
 "hex",
 "miette",
 "serde",
 "sha-1",
 "sha2",
 "thiserror",
 "xxhash-rust",
]

[[package]]
name = "stable_deref_trait"
version = "1.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a8f112729512f8e442d81f95a8a7ddf2b7c6b8a1a6f509a95864142b30cab2d3"

[[package]]
name = "syn"
version = "1.0.109"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "72b64191b275b66ffe2469e8af2c1cfe3bafa67b529ead792a6d0160888b4237"
dependencies = [
 "proc-macro2",
 "quote",
 "unicode-ident",
]

[[package]]
name = "syn"
version = "2.0.66"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c42f3f41a2de00b01c0aaad383c5a45241efc8b2d1eda5661812fda5f3cdcff5"
dependencies = [
 "proc-macro2",
 "quote",
 "unicode-ident",
]

[[package]]
name = "sync_wrapper"
version = "0.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2047c6ded9c721764247e62cd3b03c09ffc529b2ba5b10ec482ae507a4a70160"

[[package]]
name = "synstructure"
version = "0.13.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c8af7666ab7b6390ab78131fb5b0fce11d6b7a6951602017c35fa82800708971"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.66",
]

[[package]]
name = "system-configuration"
version = "0.5.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ba3a3adc5c275d719af8cb4272ea1c4a6d668a777f37e115f6d11ddbc1c8e0e7"
dependencies = [
 "bitflags 1.3.2",
 "core-foundation",
 "system-configuration-sys",
]

[[package]]
name = "system-configuration-sys"
version = "0.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a75fb188eb626b924683e3b95e3a48e63551fcfb51949de2f06a9d91dbee93c9"
dependencies = [
 "core-foundation-sys",
 "libc",
]

[[package]]
name = "tempfile"
version = "3.10.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "85b77fafb263dd9d05cbeac119526425676db3784113aa9295c88498cbf8bff1"
dependencies = [
 "cfg-if 1.0.0",
 "fastrand",
 "rustix",
 "windows-sys 0.52.0",
]

[[package]]
name = "thiserror"
version = "1.0.61"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c546c80d6be4bc6a00c0f01730c08df82eaa7a7a61f11d656526506112cc1709"
dependencies = [
 "thiserror-impl",
]

[[package]]
name = "thiserror-impl"
version = "1.0.61"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "46c3384250002a6d5af4d114f2845d37b57521033f30d5c3f46c4d70e1197533"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.66",
]

[[package]]
name = "tinystr"
version = "0.7.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9117f5d4db391c1cf6927e7bea3db74b9a1c1add8f7eda9ffd5364f40f57b82f"
dependencies = [
 "displaydoc",
 "zerovec",
]

[[package]]
name = "tokio"
version = "1.38.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ba4f4a02a7a80d6f274636f0aa95c7e383b912d41fe721a31f29e29698585a4a"
dependencies = [
 "backtrace",
 "bytes",
 "libc",
 "mio",
 "num_cpus",
 "pin-project-lite",
 "socket2",
 "tokio-macros",
 "windows-sys 0.48.0",
]

[[package]]
name = "tokio-macros"
version = "2.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5f5ae998a069d4b5aba8ee9dad856af7d520c3699e6159b185c2acd48155d39a"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.66",
]

[[package]]
name = "tokio-native-tls"
version = "0.3.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bbae76ab933c85776efabc971569dd6119c580d8f5d448769dec1764bf796ef2"
dependencies = [
 "native-tls",
 "tokio",
]

[[package]]
name = "tokio-stream"
version = "0.1.15"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "267ac89e0bec6e691e5813911606935d77c476ff49024f98abcea3e7b15e37af"
dependencies = [
 "futures-core",
 "pin-project-lite",
 "tokio",
]

[[package]]
name = "tokio-util"
version = "0.7.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9cf6b47b3771c49ac75ad09a6162f53ad4b8088b76ac60e8ec1455b31a189fe1"
dependencies = [
 "bytes",
 "futures-core",
 "futures-sink",
 "pin-project-lite",
 "tokio",
]

[[package]]
name = "toml"
version = "0.5.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f4f7f0dd8d50a853a531c426359045b1998f04219d88799810762cd4ad314234"
dependencies = [
 "serde",
]

[[package]]
name = "tower-service"
version = "0.3.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b6bc1c9ce2b5135ac7f93c72918fc37feb872bdc6a5533a8b85eb4b86bfdae52"

[[package]]
name = "tracing"
version = "0.1.40"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c3523ab5a71916ccf420eebdf5521fcef02141234bbc0b8a49f2fdc4544364ef"
dependencies = [
 "pin-project-lite",
 "tracing-core",
]

[[package]]
name = "tracing-core"
version = "0.1.32"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c06d3da6113f116aaee68e4d601191614c9053067f9ab7f6edbcb161237daa54"
dependencies = [
 "once_cell",
]

[[package]]
name = "try-lock"
version = "0.2.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e421abadd41a4225275504ea4d6566923418b7f05506fbc9c0fe86ba7396114b"

[[package]]
name = "typenum"
version = "1.17.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "42ff0bf0c66b8238c6f3b578df37d0b7848e55df8577b3f74f92a69acceeb825"

[[package]]
name = "udt-init"
version = "0.1.0"
dependencies = [
 "ckb-chain-spec",
 "ckb-gen-types",
 "ckb-jsonrpc-types",
 "ckb-resource",
 "ckb-sdk",
 "ckb-types",
 "hex",
 "rand 0.8.5",
 "serde",
 "serde_derive",
 "serde_json",
 "serde_yaml",
 "thiserror",
]

[[package]]
name = "unicode-ident"
version = "1.0.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3354b9ac3fae1ff6755cb6db53683adb661634f67557942dea4facebec0fee4b"

[[package]]
name = "unicode-width"
version = "0.1.13"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0336d538f7abc86d282a4189614dfaa90810dfc2c6f6427eaf88e16311dd225d"

[[package]]
name = "unsafe-libyaml"
version = "0.2.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "673aac59facbab8a9007c7f6108d11f63b603f7cabff99fabf650fea5c32b861"

[[package]]
name = "url"
version = "2.5.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "32f8b686cadd1473f4bd0117a5d28d36b1ade384ea9b5069a1c40aefed7fda60"
dependencies = [
 "form_urlencoded",
 "idna",
 "percent-encoding",
]

[[package]]
name = "utf16_iter"
version = "1.0.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c8232dd3cdaed5356e0f716d285e4b40b932ac434100fe9b7e0e8e935b9e6246"

[[package]]
name = "utf8_iter"
version = "1.0.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b6c140620e7ffbb22c2dee59cafe6084a59b5ffc27a8859a5f0d494b5d52b6be"

[[package]]
name = "vcpkg"
version = "0.2.15"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "accd4ea62f7bb7a82fe23066fb0957d48ef677f6eeb8215f372f52e48bb32426"

[[package]]
name = "version_check"
version = "0.9.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "49874b5167b65d7193b8aba1567f5c7d93d001cafc34600cee003eda787e483f"

[[package]]
name = "walkdir"
version = "2.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "29790946404f91d9c5d06f9874efddea1dc06c5efe94541a7d6863108e3a5e4b"
dependencies = [
 "same-file",
 "winapi-util",
]

[[package]]
name = "want"
version = "0.3.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bfa7760aed19e106de2c7c0b581b509f2f25d3dacaf737cb82ac61bc6d760b0e"
dependencies = [
 "try-lock",
]

[[package]]
name = "wasi"
version = "0.9.0+wasi-snapshot-preview1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cccddf32554fecc6acb585f82a32a72e28b48f8c4c1883ddfeeeaa96f7d8e519"

[[package]]
name = "wasi"
version = "0.11.0+wasi-snapshot-preview1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9c8d87e72b64a3b4db28d11ce29237c246188f4f51057d65a7eab63b7987e423"

[[package]]
name = "wasm-bindgen"
version = "0.2.92"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4be2531df63900aeb2bca0daaaddec08491ee64ceecbee5076636a3b026795a8"
dependencies = [
 "cfg-if 1.0.0",
 "wasm-bindgen-macro",
]

[[package]]
name = "wasm-bindgen-backend"
version = "0.2.92"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "614d787b966d3989fa7bb98a654e369c762374fd3213d212cfc0251257e747da"
dependencies = [
 "bumpalo",
 "log",
 "once_cell",
 "proc-macro2",
 "quote",
 "syn 2.0.66",
 "wasm-bindgen-shared",
]

[[package]]
name = "wasm-bindgen-futures"
version = "0.4.42"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "76bc14366121efc8dbb487ab05bcc9d346b3b5ec0eaa76e46594cabbe51762c0"
dependencies = [
 "cfg-if 1.0.0",
 "js-sys",
 "wasm-bindgen",
 "web-sys",
]

[[package]]
name = "wasm-bindgen-macro"
version = "0.2.92"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a1f8823de937b71b9460c0c34e25f3da88250760bec0ebac694b49997550d726"
dependencies = [
 "quote",
 "wasm-bindgen-macro-support",
]

[[package]]
name = "wasm-bindgen-macro-support"
version = "0.2.92"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e94f17b526d0a461a191c78ea52bbce64071ed5c04c9ffe424dcb38f74171bb7"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.66",
 "wasm-bindgen-backend",
 "wasm-bindgen-shared",
]

[[package]]
name = "wasm-bindgen-shared"
version = "0.2.92"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "af190c94f2773fdb3729c55b007a722abb5384da03bc0986df4c289bf5567e96"

[[package]]
name = "web-sys"
version = "0.3.69"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "77afa9a11836342370f4817622a2f0f418b134426d91a82dfb48f532d2ec13ef"
dependencies = [
 "js-sys",
 "wasm-bindgen",
]

[[package]]
name = "winapi"
version = "0.3.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5c839a674fcd7a98952e593242ea400abe93992746761e38641405d28b00f419"
dependencies = [
 "winapi-i686-pc-windows-gnu",
 "winapi-x86_64-pc-windows-gnu",
]

[[package]]
name = "winapi-i686-pc-windows-gnu"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ac3b87c63620426dd9b991e5ce0329eff545bccbbb34f3be09ff6fb6ab51b7b6"

[[package]]
name = "winapi-util"
version = "0.1.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4d4cc384e1e73b93bafa6fb4f1df8c41695c8a91cf9c4c64358067d15a7b6c6b"
dependencies = [
 "windows-sys 0.52.0",
]

[[package]]
name = "winapi-x86_64-pc-windows-gnu"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "712e227841d057c1ee1cd2fb22fa7e5a5461ae8e48fa2ca79ec42cfc1931183f"

[[package]]
name = "windows"
version = "0.57.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "12342cb4d8e3b046f3d80effd474a7a02447231330ef77d71daa6fbc40681143"
dependencies = [
 "windows-core",
 "windows-targets 0.52.5",
]

[[package]]
name = "windows-core"
version = "0.57.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d2ed2439a290666cd67ecce2b0ffaad89c2a56b976b736e6ece670297897832d"
dependencies = [
 "windows-implement",
 "windows-interface",
 "windows-result",
 "windows-targets 0.52.5",
]

[[package]]
name = "windows-implement"
version = "0.57.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9107ddc059d5b6fbfbffdfa7a7fe3e22a226def0b2608f72e9d552763d3e1ad7"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.66",
]

[[package]]
name = "windows-interface"
version = "0.57.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "29bee4b38ea3cde66011baa44dba677c432a78593e202392d1e9070cf2a7fca7"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.66",
]

[[package]]
name = "windows-result"
version = "0.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5e383302e8ec8515204254685643de10811af0ed97ea37210dc26fb0032647f8"
dependencies = [
 "windows-targets 0.52.5",
]

[[package]]
name = "windows-sys"
version = "0.48.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "677d2418bec65e3338edb076e806bc1ec15693c5d0104683f2efe857f61056a9"
dependencies = [
 "windows-targets 0.48.5",
]

[[package]]
name = "windows-sys"
version = "0.52.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "282be5f36a8ce781fad8c8ae18fa3f9beff57ec1b52cb3de0789201425d9a33d"
dependencies = [
 "windows-targets 0.52.5",
]

[[package]]
name = "windows-targets"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9a2fa6e2155d7247be68c096456083145c183cbbbc2764150dda45a87197940c"
dependencies = [
 "windows_aarch64_gnullvm 0.48.5",
 "windows_aarch64_msvc 0.48.5",
 "windows_i686_gnu 0.48.5",
 "windows_i686_msvc 0.48.5",
 "windows_x86_64_gnu 0.48.5",
 "windows_x86_64_gnullvm 0.48.5",
 "windows_x86_64_msvc 0.48.5",
]

[[package]]
name = "windows-targets"
version = "0.52.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6f0713a46559409d202e70e28227288446bf7841d3211583a4b53e3f6d96e7eb"
dependencies = [
 "windows_aarch64_gnullvm 0.52.5",
 "windows_aarch64_msvc 0.52.5",
 "windows_i686_gnu 0.52.5",
 "windows_i686_gnullvm",
 "windows_i686_msvc 0.52.5",
 "windows_x86_64_gnu 0.52.5",
 "windows_x86_64_gnullvm 0.52.5",
 "windows_x86_64_msvc 0.52.5",
]

[[package]]
name = "windows_aarch64_gnullvm"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2b38e32f0abccf9987a4e3079dfb67dcd799fb61361e53e2882c3cbaf0d905d8"

[[package]]
name = "windows_aarch64_gnullvm"
version = "0.52.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7088eed71e8b8dda258ecc8bac5fb1153c5cffaf2578fc8ff5d61e23578d3263"

[[package]]
name = "windows_aarch64_msvc"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "dc35310971f3b2dbbf3f0690a219f40e2d9afcf64f9ab7cc1be722937c26b4bc"

[[package]]
name = "windows_aarch64_msvc"
version = "0.52.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9985fd1504e250c615ca5f281c3f7a6da76213ebd5ccc9561496568a2752afb6"

[[package]]
name = "windows_i686_gnu"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a75915e7def60c94dcef72200b9a8e58e5091744960da64ec734a6c6e9b3743e"

[[package]]
name = "windows_i686_gnu"
version = "0.52.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "88ba073cf16d5372720ec942a8ccbf61626074c6d4dd2e745299726ce8b89670"

[[package]]
name = "windows_i686_gnullvm"
version = "0.52.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "87f4261229030a858f36b459e748ae97545d6f1ec60e5e0d6a3d32e0dc232ee9"

[[package]]
name = "windows_i686_msvc"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8f55c233f70c4b27f66c523580f78f1004e8b5a8b659e05a4eb49d4166cca406"

[[package]]
name = "windows_i686_msvc"
version = "0.52.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "db3c2bf3d13d5b658be73463284eaf12830ac9a26a90c717b7f771dfe97487bf"

[[package]]
name = "windows_x86_64_gnu"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "53d40abd2583d23e4718fddf1ebec84dbff8381c07cae67ff7768bbf19c6718e"

[[package]]
name = "windows_x86_64_gnu"
version = "0.52.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4e4246f76bdeff09eb48875a0fd3e2af6aada79d409d33011886d3e1581517d9"

[[package]]
name = "windows_x86_64_gnullvm"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0b7b52767868a23d5bab768e390dc5f5c55825b6d30b86c844ff2dc7414044cc"

[[package]]
name = "windows_x86_64_gnullvm"
version = "0.52.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "852298e482cd67c356ddd9570386e2862b5673c85bd5f88df9ab6802b334c596"

[[package]]
name = "windows_x86_64_msvc"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ed94fce61571a4006852b7389a063ab983c02eb1bb37b47f8272ce92d06d9538"

[[package]]
name = "windows_x86_64_msvc"
version = "0.52.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bec47e5bfd1bff0eeaf6d8b485cc1074891a197ab4225d504cb7a1ab88b02bf0"

[[package]]
name = "winreg"
version = "0.50.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "524e57b2c537c0f9b1e69f1965311ec12182b4122e45035b1508cd24d2adadb1"
dependencies = [
 "cfg-if 1.0.0",
 "windows-sys 0.48.0",
]

[[package]]
name = "write16"
version = "1.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d1890f4022759daae28ed4fe62859b1236caebfc61ede2f63ed4e695f3f6d936"

[[package]]
name = "writeable"
version = "0.5.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1e9df38ee2d2c3c5948ea468a8406ff0db0b29ae1ffde1bcf20ef305bcc95c51"

[[package]]
name = "xxhash-rust"
version = "0.8.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "927da81e25be1e1a2901d59b81b37dd2efd1fc9c9345a55007f09bf5a2d3ee03"

[[package]]
name = "yoke"
version = "0.7.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "120e6aef9aa629e3d4f52dc8cc43a015c7724194c97dfaf45180d2daf2b77f40"
dependencies = [
 "serde",
 "stable_deref_trait",
 "yoke-derive",
 "zerofrom",
]

[[package]]
name = "yoke-derive"
version = "0.7.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2380878cad4ac9aac1e2435f3eb4020e8374b5f13c296cb75b4620ff8e229154"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.66",
 "synstructure",
]

[[package]]
name = "zerofrom"
version = "0.1.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cff3ee08c995dee1859d998dea82f7374f2826091dd9cd47def953cae446cd2e"
dependencies = [
 "zerofrom-derive",
]

[[package]]
name = "zerofrom-derive"
version = "0.1.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "595eed982f7d355beb85837f651fa22e90b3c044842dc7f2c2842c086f295808"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.66",
 "synstructure",
]

[[package]]
name = "zerovec"
version = "0.10.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "aa2b893d79df23bfb12d5461018d408ea19dfafe76c2c7ef6d4eba614f8ff079"
dependencies = [
 "yoke",
 "zerofrom",
 "zerovec-derive",
]

[[package]]
name = "zerovec-derive"
version = "0.10.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6eafa6dfb17584ea3e2bd6e76e0cc15ad7af12b09abdd1ca55961bed9b1063c6"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.66",
]


================================================
File: tests/deploy/udt-init/Cargo.toml
================================================
[package]
name = "udt-init"
version = "0.1.0"
edition = "2021"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]
ckb-sdk = { version = "3.4" }
ckb-types = "0.118"
ckb-jsonrpc-types = "0.118"
serde = { version = "1.0", features = ["derive"] }
serde_derive = "1.0"
serde_json = "1.0"
thiserror = "1.0.30"
hex = "0.4.3"
serde_yaml = "0.9.34"
rand = "0.8.5"
ckb-chain-spec = "0.118.0"
ckb-resource = "0.118.0"
ckb-gen-types = "0.118.0"


================================================
File: tests/deploy/udt-init/.gitignore
================================================
target

================================================
File: tests/deploy/udt-init/src/main.rs
================================================
use ckb_chain_spec::ChainSpec;
use ckb_resource::Resource;
use ckb_sdk::{
    transaction::{
        builder::{sudt::SudtTransactionBuilder, CkbTransactionBuilder},
        handler::{sighash::Secp256k1Blake160SighashAllScriptHandler, sudt::SudtHandler},
        input::InputIterator,
        signer::{SignContexts, TransactionSigner},
        TransactionBuilderConfiguration,
    },
    Address, CkbRpcClient, NetworkInfo, ScriptId,
};
use ckb_types::{
    core::BlockView,
    packed::CellOutput,
    prelude::{Entity, Unpack},
};
use ckb_types::{
    core::{DepType, ScriptHashType},
    packed::{OutPoint, Script},
    prelude::Pack,
    H256,
};
use ckb_types::{packed::CellDep, prelude::Builder};
use rand::Rng;
use serde::{Deserialize, Serialize};
use std::{collections::HashSet, path::Path};
use std::{fs, net::TcpListener};

use std::{error::Error as StdErr, str::FromStr};

const UDT_KINDS: [&str; 2] = ["SIMPLE_UDT", "XUDT"];

fn get_udt_info(udt_kind: &str) -> (H256, H256, usize) {
    let genesis_block = build_gensis_block();
    let genesis_tx = genesis_block
        .transaction(0)
        .expect("genesis block transaction #0 should exist");

    let index = if udt_kind == "SIMPLE_UDT" { 8 } else { 9 };
    let output_data = genesis_tx.outputs_data().get(index).unwrap().raw_data();
    (
        CellOutput::calc_data_hash(&output_data).unpack(),
        genesis_tx.hash().unpack(),
        index,
    )
}

fn gen_dev_udt_handler(udt_kind: &str) -> SudtHandler {
    let (data_hash, genesis_tx, index) = get_udt_info(udt_kind);
    let script_id = ScriptId::new_data1(data_hash);

    let udt_cell_dep = CellDep::new_builder()
        .out_point(
            OutPoint::new_builder()
                .tx_hash(genesis_tx.pack())
                .index(index.pack())
                .build(),
        )
        .dep_type(DepType::Code.into())
        .build();

    ckb_sdk::transaction::handler::sudt::SudtHandler::new_with_customize(
        vec![udt_cell_dep],
        script_id,
    )
}

fn gen_dev_sighash_handler() -> Secp256k1Blake160SighashAllScriptHandler {
    let genesis_block = build_gensis_block();
    let secp256k1_dep_group_tx_hash = genesis_block
        .transaction(1)
        .expect("genesis block transaction #1 should exist")
        .hash();
    let secp256k1_dep_group_out_point = OutPoint::new_builder()
        .tx_hash(secp256k1_dep_group_tx_hash)
        .index(0u32.pack())
        .build();
    let cell_dep = CellDep::new_builder()
        .out_point(secp256k1_dep_group_out_point)
        .dep_type(DepType::DepGroup.into())
        .build();

    Secp256k1Blake160SighashAllScriptHandler::new_with_customize(vec![cell_dep])
}

fn generate_configuration(
    udt_kind: &str,
) -> Result<(NetworkInfo, TransactionBuilderConfiguration), Box<dyn StdErr>> {
    let network_info = NetworkInfo::devnet();
    let mut configuration =
        TransactionBuilderConfiguration::new_devnet().expect("new devnet configuration");

    configuration.register_script_handler(Box::new(gen_dev_sighash_handler()));
    configuration.register_script_handler(Box::new(gen_dev_udt_handler(udt_kind)));
    return Ok((network_info, configuration));
}

fn init_or_send_udt(
    udt_kind: &str,
    issuer_address: &str,
    sender_info: &(String, H256),
    receiver_address: Option<&str>,
    sudt_amount: u128,
    apply: bool,
) -> Result<(), Box<dyn StdErr>> {
    let (network_info, configuration) = generate_configuration(udt_kind)?;

    let issuer = Address::from_str(issuer_address)?;
    let sender = Address::from_str(&sender_info.0)?;
    let receiver = if let Some(addr) = receiver_address {
        Address::from_str(addr)?
    } else {
        sender.clone()
    };

    let iterator = InputIterator::new_with_address(&[sender], &network_info);
    let owner_mode = receiver_address.is_none();
    let mut builder = SudtTransactionBuilder::new(configuration, iterator, &issuer, owner_mode)?;
    builder.set_sudt_type_script(generate_udt_type_script(udt_kind, issuer_address));
    builder.add_output(&receiver, sudt_amount);

    let mut tx_with_groups = builder.build(&Default::default())?;

    let private_keys = vec![sender_info.1.clone()];

    TransactionSigner::new(&network_info).sign_transaction(
        &mut tx_with_groups,
        &SignContexts::new_sighash_h256(private_keys)?,
    )?;

    let json_tx = ckb_jsonrpc_types::TransactionView::from(tx_with_groups.get_tx_view().clone());
    if apply {
        let tx_hash = CkbRpcClient::new(network_info.url.as_str())
            .send_transaction(json_tx.inner, None)
            .expect("send transaction");
        println!(">>> tx {} sent! <<<", tx_hash);
    } else {
        let result = CkbRpcClient::new(network_info.url.as_str())
            .test_tx_pool_accept(json_tx.inner, None)
            .expect("accept transaction");
        println!(">>> check tx result: {:?}  <<<", result);
    }

    Ok(())
}

fn generate_blocks(num: u64) -> Result<(), Box<dyn StdErr>> {
    let network_info = NetworkInfo::devnet();
    let rpc_client = CkbRpcClient::new(network_info.url.as_str());
    for _i in 0..num {
        rpc_client.generate_block()?;
        // sleep 200ms
        std::thread::sleep(std::time::Duration::from_millis(200));
    }
    Ok(())
}

fn generate_udt_type_script(udt_kind: &str, address: &str) -> ckb_types::packed::Script {
    let address = Address::from_str(address).expect("parse address");
    let sudt_owner_lock_script: Script = (&address).into();
    let (code_hash, _, _) = get_udt_info(udt_kind);
    Script::new_builder()
        .code_hash(code_hash.pack())
        .hash_type(ScriptHashType::Data1.into())
        .args(sudt_owner_lock_script.calc_script_hash().as_bytes().pack())
        .build()
}

fn get_nodes_info(node: &str) -> (String, H256) {
    let nodes_dir = std::env::var("NODES_DIR").expect("env var");
    let node_dir = format!("{}/{}", nodes_dir, node);
    let wallet = std::fs::read_to_string(format!("{}/ckb/wallet", node_dir)).expect("read failed");
    let key = std::fs::read_to_string(format!("{}/ckb/key", node_dir)).expect("read failed");
    (wallet, H256::from_str(key.trim()).expect("parse hex"))
}

#[derive(Serialize, Deserialize, Clone, Debug)]
struct UdtScript {
    code_hash: H256,
    hash_type: String,
    /// args may be used in pattern matching
    args: String,
}

#[derive(Serialize, Deserialize, Clone, Debug)]
struct UdtCellDep {
    dep_type: String,
    tx_hash: H256,
    index: u32,
}

#[derive(Serialize, Deserialize, Clone, Debug)]
struct UdtInfo {
    name: String,
    script: UdtScript,
    auto_accept_amount: Option<u128>,
    cell_deps: Vec<UdtCellDep>,
}

#[derive(Serialize, Deserialize, Clone, Debug)]
struct UdtInfos {
    infos: Vec<UdtInfo>,
}

fn is_port_available(port: u16) -> bool {
    match TcpListener::bind(("127.0.0.1", port)) {
        Ok(listener) => {
            drop(listener); // Close the listener
            true
        }
        Err(_) => false,
    }
}

fn generate_ports(num_ports: usize) -> Vec<u16> {
    let mut ports = HashSet::new();
    let mut rng = rand::thread_rng();

    while ports.len() < num_ports {
        // avoid https://en.wikipedia.org/wiki/Ephemeral_port
        let port: u16 = rng.gen_range(1024..32768);
        if is_port_available(port) {
            ports.insert(port);
        }
    }

    ports.into_iter().collect()
}

fn genrate_nodes_config() {
    let node_dir_env = std::env::var("NODES_DIR").expect("env var");
    let nodes_dir = Path::new(&node_dir_env);
    let yaml_file_path = nodes_dir.join("deployer/config.yml");
    let content = std::fs::read_to_string(yaml_file_path).expect("read failed");
    let data: serde_yaml::Value = serde_yaml::from_str(&content).expect("Unable to parse YAML");
    let mut udt_infos = vec![];
    for udt in UDT_KINDS {
        let (code_hash, genesis_tx, index) = get_udt_info(udt);
        let udt_info = UdtInfo {
            name: udt.to_string(),
            auto_accept_amount: Some(1000),
            script: UdtScript {
                code_hash: code_hash,
                hash_type: "Data1".to_string(),
                args: "0x.*".to_string(),
            },
            cell_deps: vec![UdtCellDep {
                dep_type: "code".to_string(),
                tx_hash: genesis_tx,
                index: index as u32,
            }],
        };
        udt_infos.push(udt_info);
    }
    let header = format!(
        "{}\n{}\n\n",
        "# this is generated from nodes/deployer/config.yml, any changes will not be checked in",
        "# you can edit nodes/deployer/config.yml and run `REMOVE_OLD_STATE=y ./tests/nodes/start.sh` to regenerate"
    );
    let config_dirs = vec!["bootnode", "1", "2", "3"];
    let mut ports_map = vec![];
    let on_github_action = std::env::var("ON_GITHUB_ACTION").is_ok();
    let gen_ports = generate_ports(6);
    let mut ports_iter = gen_ports.iter();
    let dev_config = nodes_dir.join("deployer/dev.toml");
    for (i, config_dir) in config_dirs.iter().enumerate() {
        let use_gen_port = on_github_action && i != 0;
        let default_fiber_port = (8343 + i) as u16;
        let default_rpc_port = (21713 + i) as u16;
        let (fiber_port, rpc_port) = if use_gen_port {
            (*ports_iter.next().unwrap(), *ports_iter.next().unwrap())
        } else {
            (default_fiber_port, default_rpc_port)
        };
        ports_map.push((default_fiber_port, fiber_port));
        ports_map.push((default_rpc_port, rpc_port));
        let mut data = data.clone();
        data["fiber"]["listening_addr"] =
            serde_yaml::Value::String(format!("/ip4/0.0.0.0/tcp/{}", fiber_port));
        data["fiber"]["announced_addrs"] =
            serde_yaml::Value::Sequence(vec![serde_yaml::Value::String(format!(
                "/ip4/127.0.0.1/tcp/{}",
                fiber_port
            ))]);
        data["fiber"]["announced_node_name"] = serde_yaml::Value::String(format!("fiber-{}", i));
        data["rpc"]["listening_addr"] =
            serde_yaml::Value::String(format!("127.0.0.1:{}", rpc_port));
        data["ckb"]["udt_whitelist"] = serde_yaml::to_value(&udt_infos).unwrap();

        // Node 3 acts as a CCH node.
        if i == 3 {
            data["services"]
                .as_sequence_mut()
                .unwrap()
                .push(serde_yaml::Value::String("cch".to_string()));
        }

        let new_yaml = header.to_string() + &serde_yaml::to_string(&data).unwrap();
        let config_path = nodes_dir.join(config_dir).join("config.yml");
        std::fs::write(config_path, new_yaml).expect("write failed");
        let node_dev_config = nodes_dir.join(config_dir).join("dev.toml");
        fs::copy(dev_config.clone(), node_dev_config).expect("copy dev.toml failed");
    }

    if on_github_action {
        let bruno_dir = nodes_dir.join("../bruno/environments/");
        for config in std::fs::read_dir(bruno_dir).expect("read dir") {
            let config = config.expect("read config");
            for (default_port, port) in ports_map.iter() {
                let content = std::fs::read_to_string(config.path()).expect("read config");
                let new_content = content.replace(&default_port.to_string(), &port.to_string());
                std::fs::write(config.path(), new_content).expect("write config");
            }
        }
    }

    // write the real ports into a file so that later script can use it to double check the ports
    let content = ports_map
        .iter()
        .skip(2) // bootnode node was not always started
        .map(|(_, port)| port.to_string())
        .collect::<Vec<_>>()
        .join("\n")
        + "\n";

    let port_file_path = nodes_dir.join(".ports");
    std::fs::write(port_file_path, content).expect("write ports list");
}

fn init_udt_accounts() -> Result<(), Box<dyn StdErr>> {
    let udt_owner = get_nodes_info("deployer");
    for udt in UDT_KINDS {
        init_or_send_udt(
            udt,
            &udt_owner.0,
            &udt_owner,
            None,
            0xfffffffffffffffffffffffffffffff,
            true,
        )
        .expect("init udt");
        generate_blocks(8).expect("ok");
        std::thread::sleep(std::time::Duration::from_millis(1000));
        for i in 0..3 {
            let wallet = get_nodes_info(&(i + 1).to_string());
            init_or_send_udt(
                udt,
                &udt_owner.0,
                &udt_owner,
                Some(&wallet.0),
                0xffffffffffffffffffffffffffffff,
                true,
            )?;
            generate_blocks(8).expect("ok");
        }

        let script = generate_udt_type_script(udt, &udt_owner.0);
        println!("initialized udt_type_script: {} ...", script);
    }
    Ok(())
}

fn build_gensis_block() -> BlockView {
    let node_dir_env = std::env::var("NODES_DIR").expect("env var");
    let nodes_dir = Path::new(&node_dir_env);
    let dev_toml = nodes_dir.join("deployer/dev.toml");
    let chain_spec =
        ChainSpec::load_from(&Resource::file_system(dev_toml)).expect("load chain spec");
    let genesis_block = chain_spec.build_genesis().expect("build genesis block");
    genesis_block
}

fn main() -> Result<(), Box<dyn StdErr>> {
    genrate_nodes_config();
    init_udt_accounts()?;
    Ok(())
}


================================================
File: tests/nodes/start.sh
================================================
#!/usr/bin/env bash
set -euo pipefail
export SHELLOPTS
export RUST_BACKTRACE=full RUST_LOG=info,fnn=debug,fnn::cch::actor::tracker=off,fnn::fiber::gossip=off,fnn::fiber::graph=off

should_remove_old_state="${REMOVE_OLD_STATE:-}"
should_clean_fiber_state="${REMOVE_OLD_FIBER:-}"
should_start_bootnode="${START_BOOTNODE:-}"
script_dir="$(cd -- "$(dirname -- "${BASH_SOURCE[0]}")" &>/dev/null && pwd)"
nodes_dir="$(dirname "$script_dir")/nodes"
deploy_dir="$(dirname "$script_dir")/deploy"
bruno_dir="$(dirname "$script_dir")/bruno/environments"

# The following environment variables are used in the contract tests.
# We may load all contracts within the following folder to the test environment.
export TESTING_CONTRACTS_DIR="$deploy_dir/contracts"

# Initialize the dev-chain if it does not exist.
# This script is nilpotent, so it is safe to run multiple times.
"$deploy_dir/init-dev-chain.sh"

if [ -n "$should_clean_fiber_state" ]; then
    echo "starting to clean fiber store ...."
    rm -rf "$nodes_dir"/*/fiber/store
elif [ -n "$should_remove_old_state" ]; then
    echo "starting to reset ...."
    rm -rf "$nodes_dir"/*/fiber/store
    "$deploy_dir/init-dev-chain.sh" -f
fi

echo "Initializing finished, begin to start services ...."
sleep 1

ckb run -C "$deploy_dir/node-data" --indexer &
cargo build

# Start the dev node in the background.
cd "$nodes_dir" || exit 1

start() {
    ../../target/debug/fnn "$@"
}

if [ "$#" -ne 1 ]; then
    if [[ -n "$should_start_bootnode" ]]; then
        LOG_PREFIX=$'[boot node]' start -d bootnode &
        # sleep some time to ensure bootnode started
        # while other nodes try to connect to it.
        sleep 5
        # export the environment variable so that other nodes can connect to the bootnode.
        export FIBER_BOOTNODE_ADDRS=/ip4/127.0.0.1/tcp/8343/p2p/Qmbyc4rhwEwxxSQXd5B4Ej4XkKZL6XLipa3iJrnPL9cjGR
    fi
    LOG_PREFIX=$'[node 1]' start -d 1 &
    LOG_PREFIX=$'[node 2]' start -d 2 &
    LOG_PREFIX=$'[node 3]' start -d 3 &
else
    for id in "$@"; do
        LOG_PREFIX="[$id]"$'' start -d "$id" &
    done
fi

# we will exit when any of the background processes exits.
# we don't use `wait -n` because of compatibility issues between bash and zsh
initial_jobs=$(jobs -p | wc -l)
while true; do
    current_jobs=$(jobs -p | wc -l)
    if [ "$current_jobs" -lt "$initial_jobs" ]; then
        echo "A background job has exited, exiting ..."
        exit 1
    fi
    sleep 1
done


================================================
File: tests/nodes/1/ckb/key
================================================
cccd5f7e693b60447623fb71a5983f15a426938c33699b1a81d1239cfa656cd1

================================================
File: tests/nodes/1/ckb/wallet
================================================
ckt1qzda0cr08m85hc8jlnfp3zer7xulejywt49kt2rr0vthywaa50xwsqgx5lf4pczpamsfam48evs0c8nvwqqa59qapt46f

================================================
File: tests/nodes/2/ckb/key
================================================
85af6ff21ea891dbb384b771e02317427e7b66e84b4516c03d74ca4fd5ad0500

================================================
File: tests/nodes/2/ckb/wallet
================================================
ckt1qzda0cr08m85hc8jlnfp3zer7xulejywt49kt2rr0vthywaa50xwsqt4vqqyehpxn47deg5l6eeqtkfrt5kfkfchkwv62

================================================
File: tests/nodes/3/ckb/key
================================================
d00c06bfd800d27397002dca6fb0993d5ba6399b4238b2f29ee9deb975ffffff



================================================
File: tests/nodes/3/ckb/wallet
================================================
ckt1qzda0cr08m85hc8jlnfp3zer7xulejywt49kt2rr0vthywaa50xwsqtrnd9f2lh5vlwlj23dedf7jje65cdj8qs7q4awr

================================================
File: tests/nodes/bootnode/ckb/key
================================================
d00c06bfd800d27397002dca6fb0993d5ba6399b4238b2f29ee9deb97593d2bc

================================================
File: tests/nodes/bootnode/ckb/wallet
================================================
ckt1qzda0cr08m85hc8jlnfp3zer7xulejywt49kt2rr0vthywaa50xwsqwgx292hnvmn68xf779vmzrshpmm6epn4c0cgwga

================================================
File: tests/nodes/deployer/config.yml
================================================
## NOTE: we don't use this config.yml to start nodes.
## Instead the initialize program `udt-init` will use it as a config template to generate `config.yml` for nodes

fiber:
  chain: dev.toml
  auto_announce_node: true
  announce_private_addr: true
  watchtower_check_interval_seconds: 1
  gossip_store_maintenance_interval_ms: 1000
  gossip_network_maintenance_interval_ms: 1000

rpc:
  listening_addr: 127.0.0.1:41716
  enabled_modules:
    - cch
    - channel
    - payment
    - graph
    - info
    - invoice
    - peer
    - dev

cch:
  ignore_startup_failure: true
  wrapped_btc_type_script_args: "0x32e555f3ff8e135cece1351a6a2971518392c1e30375c1e006ad0ce8eac07947"
  lnd_cert_path: ../../../deploy/lnd-init/lnd-ingrid/tls.cert

ckb:
  # udt whitelist, will be generated by udt-init
  udt_whitelist:
    - name: simple_udt
      script:
        code_hash: 0xe1e354d6d643ad42724d40967e334984534e0367405c5ae42a9d7d63d77df419
        hash_type: Data1
        args: 0x.*
      cell_deps:
        - tx_hash: 0xdce1d5c46170c5624076c06884bb169b712e6fcde38d3a78999f1be2d75adcde
          index: 0
          dep_type: code

services:
  - fiber
  - rpc
  - ckb


================================================
File: tests/nodes/deployer/dev.toml
================================================
name = "ckb_dev"

[genesis]
version = 0
parent_hash = "0x0000000000000000000000000000000000000000000000000000000000000000"
timestamp = 0
compact_target = 0x20010000
uncles_hash = "0x0000000000000000000000000000000000000000000000000000000000000000"
nonce = "0x0"

[genesis.genesis_cell]
message = "ckb_dev"

[genesis.genesis_cell.lock]
code_hash = "0x0000000000000000000000000000000000000000000000000000000000000000"
args = "0x"
hash_type = "data"

# An array list paths to system cell files, which is absolute or relative to
# the directory containing this config file.
[[genesis.system_cells]]
file = { bundled = "specs/cells/secp256k1_blake160_sighash_all" }
create_type_id = true
capacity = 100_000_0000_0000
[[genesis.system_cells]]
file = { bundled = "specs/cells/dao" }
create_type_id = true
capacity = 16_000_0000_0000
[[genesis.system_cells]]
file = { bundled = "specs/cells/secp256k1_data" }
create_type_id = false
capacity = 1_048_617_0000_0000
[[genesis.system_cells]]
file = { bundled = "specs/cells/secp256k1_blake160_multisig_all" }
create_type_id = true
capacity = 100_000_0000_0000
[[genesis.system_cells]]
file = { file = "../../deploy/contracts/auth" }
create_type_id = false
capacity = 200_000_0000_0000
[[genesis.system_cells]]
file = { file = "../../deploy/contracts/funding-lock" }
create_type_id = false
capacity = 200_000_0000_0000
[[genesis.system_cells]]
file = { file = "../../deploy/contracts/commitment-lock" }
create_type_id = false
capacity = 200_000_0000_0000
[[genesis.system_cells]]
file = { file = "../../deploy/contracts/simple_udt" }
create_type_id = false
capacity = 200_000_0000_0000
[[genesis.system_cells]]
file = { file = "../../deploy/contracts/xudt_rce" }
create_type_id = false
capacity = 200_000_0000_0000

[genesis.system_cells_lock]
code_hash = "0x0000000000000000000000000000000000000000000000000000000000000000"
args = "0x"
hash_type = "data"

# Dep group cells
[[genesis.dep_groups]]
name = "secp256k1_blake160_sighash_all"
files = [
  { bundled = "specs/cells/secp256k1_data" },
  { bundled = "specs/cells/secp256k1_blake160_sighash_all" },
]
[[genesis.dep_groups]]
name = "secp256k1_blake160_multisig_all"
files = [
  { bundled = "specs/cells/secp256k1_data" },
  { bundled = "specs/cells/secp256k1_blake160_multisig_all" },
]

# For first 11 block
[genesis.bootstrap_lock]
code_hash = "0x0000000000000000000000000000000000000000000000000000000000000000"
args = "0x"
hash_type = "type"

# Burn
[[genesis.issued_cells]]
capacity = 8_400_000_000_00000000
lock.code_hash = "0x0000000000000000000000000000000000000000000000000000000000000000"
lock.args = "0x62e907b15cbf27d5425399ebf6f0fb50ebb88f18"
lock.hash_type = "data"

# issue for random generated private key: d00c06bfd800d27397002dca6fb0993d5ba6399b4238b2f29ee9deb97593d2bc
[[genesis.issued_cells]]
capacity = 20_000_000_000_00000000
lock.code_hash = "0x9bd7e06f3ecf4be0f2fcd2188b23f1b9fcc88e5d4b65a8637b17723bbda3cce8"
lock.args = "0xc8328aabcd9b9e8e64fbc566c4385c3bdeb219d7"
lock.hash_type = "type"

# issue for random generated private key: 63d86723e08f0f813a36ce6aa123bb2289d90680ae1e99d4de8cdb334553f24d
[[genesis.issued_cells]]
capacity = 5_198_735_037_00000000
lock.code_hash = "0x9bd7e06f3ecf4be0f2fcd2188b23f1b9fcc88e5d4b65a8637b17723bbda3cce8"
lock.args = "0x470dcdc5e44064909650113a274b3b36aecb6dc7"
lock.hash_type = "type"

[params]
initial_primary_epoch_reward = 1_917_808_21917808
secondary_epoch_reward = 613_698_63013698
max_block_cycles = 10_000_000_000
cellbase_maturity = 0
primary_epoch_reward_halving_interval = 8760
epoch_duration_target = 80
genesis_epoch_length = 10
# For development and testing purposes only.
# Keep difficulty be permanent if the pow is Dummy. (default: false)
permanent_difficulty_in_dummy = true
starting_block_limiting_dao_withdrawing_lock = 0

[params.hardfork]
ckb2023 = 0


[pow]
func = "Dummy"


================================================
File: tests/nodes/deployer/ckb/key
================================================
d00c06bfd800d27397002dca6fb0993d5ba6399b4238b2f29ee9deb97593d2bc

================================================
File: tests/nodes/deployer/ckb/wallet
================================================
ckt1qzda0cr08m85hc8jlnfp3zer7xulejywt49kt2rr0vthywaa50xwsqwgx292hnvmn68xf779vmzrshpmm6epn4c0cgwga

================================================
File: tests/nodes/deployer/fiber/sk
================================================
965b639c03022dee2e51c9655e9ba972a631be522bec5f573d72f8ff59328fba


================================================
File: .github/codecov.yaml
================================================
coverage:
  status:
    project:
      default:
        # This target could be increased, but don't decrease it.
        target: 25%
        threshold: 0%
        paths:
        - "src"
    patch:
      default:
        # The majority of new code should be tested.
        target: 60%
        threshold: 0%
        paths:
        - "src"


================================================
File: .github/workflows/ci.yml
================================================
on: [push, pull_request]

name: Continuous integration

jobs:
  check:
    name: Check
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: dsherret/rust-toolchain-file@v1
      - uses: Swatinem/rust-cache@v2
      - run: |
          cargo check
          make check-dirty-rpc-doc

  cargo-shear:
    name: Cargo Shear
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: dsherret/rust-toolchain-file@v1
      - uses: cargo-bins/cargo-binstall@main
      - run: |
          cargo binstall --no-confirm cargo-shear --force --locked
          cargo shear

  test:
    name: Test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: dsherret/rust-toolchain-file@v1
      - uses: Swatinem/rust-cache@v2
      - uses: taiki-e/install-action@v2
        with:
          tool: nextest
      - run: |
          TEST_TEMP_RETAIN=1 RUST_BACKTRACE=full RUST_LOG=trace cargo nextest run --no-fail-fast

  fmt:
    name: Rustfmt
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: dsherret/rust-toolchain-file@v1
      - uses: Swatinem/rust-cache@v2
      - run: cargo fmt --all -- --check

  clippy:
    name: Clippy
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: dsherret/rust-toolchain-file@v1
      - uses: Swatinem/rust-cache@v2
      - run: |
          make clippy

  coverage:
    name: Code Coverage
    needs: [ test ]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: dsherret/rust-toolchain-file@v1
      - uses: Swatinem/rust-cache@v2
      - name: Install Grcov
        run: make coverage-install-tools
      - name: Generate Code Coverage Report of Unit Tests
        run: |
          make coverage-run-unittests
          make coverage-collect-data
      - name: Upload Code Coverage Report of Unit Tests
        uses: codecov/codecov-action@v3
        with:
          files: coverage-report.info
          env_vars: OS,RUST_TOOLCHAIN
          fail_ci_if_error: false
          flags: unittests
          verbose: false
          token: ${{ secrets.CODECOV_TOKEN }}

  build:
    name: Build
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        profile: [dev, release]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'
    steps:
      - uses: actions/checkout@v2
      - uses: dsherret/rust-toolchain-file@v1
      - uses: Swatinem/rust-cache@v2
      - name: Install Dependencies (Windows)
        if: contains(matrix.os, 'windows')
        run: |
          vcpkg integrate install
          vcpkg install openssl:x64-windows-static-md
      - run: cargo build --verbose --profile ${{ matrix.profile }}


================================================
File: .github/workflows/e2e.yml
================================================
on: [push, pull_request]

name: E2E tests

jobs:
  e2e-testing:
    strategy:
      fail-fast: false
      matrix:
        workflow:
          - 3-nodes-transfer
          - invoice-ops
          - open-use-close-a-channel
          - udt
          - reestablish
          - cross-chain-hub
          - router-pay
          - udt-router-pay
          - watchtower
        release:
          - "0.116.1"
        test_env:
          - "test"
        extra_bru_args:
          - ""
        include:
          # add an extra workflow to run udt using the env file xudt-test
          - workflow: "udt"
            test_env: "xudt-test"
            release: "0.116.1"
          # add an extra workflow to run 3-nodes-transfer with sha256 hash algorithm
          - workflow: "3-nodes-transfer"
            test_env: "test"
            release: "0.116.1"
            extra_bru_args: "--env-var HASH_ALGORITHM=sha256"
    name: e2e test for ${{ matrix.workflow }} --env ${{ matrix.test_env }} ${{ matrix.extra_bru_args }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: Swatinem/rust-cache@v2
      - uses: dsherret/rust-toolchain-file@v1
      - name: Install dependencies
        run: |
          version=${{ matrix.release }}
          wget "https://github.com/nervosnetwork/ckb/releases/download/v${version}/ckb_v${version}_x86_64-unknown-linux-gnu-portable.tar.gz"
          tar -xvaf "ckb_v${version}_x86_64-unknown-linux-gnu-portable.tar.gz"
          sudo mv "ckb_v${version}_x86_64-unknown-linux-gnu-portable"/* /usr/local/bin/
          if [ ${{ matrix.workflow }} = "cross-chain-hub" ]; then
            wget "https://bitcoin.org/bin/bitcoin-core-27.0/bitcoin-27.0-x86_64-linux-gnu.tar.gz"
            tar -xvaf "bitcoin-27.0-x86_64-linux-gnu.tar.gz"
            echo "$(pwd)/bitcoin-27.0/bin" >> $GITHUB_PATH
            wget "https://github.com/lightningnetwork/lnd/releases/download/v0.18.0-beta/lnd-linux-amd64-v0.18.0-beta.tar.gz"
            tar -xvaf "lnd-linux-amd64-v0.18.0-beta.tar.gz"
            echo "$(pwd)/lnd-linux-amd64-v0.18.0-beta" >> $GITHUB_PATH
          fi

      - name: Run e2e workflow
        run: |
          set -euo pipefail

          if [ ${{ matrix.workflow }} = "cross-chain-hub" ]; then
            ./tests/deploy/lnd-init/setup-lnd.sh
          fi

          # Prebuild the program so that we can run the following script faster
          cargo build
          cd tests/deploy/udt-init && cargo build && cd -
          if [ ${{ matrix.workflow }} = "router-pay" ]; then
            export START_BOOTNODE=y
          fi
          export ON_GITHUB_ACTION=y
          ./tests/nodes/start.sh &

          # Wait for the nodes to start, the initialization takes some time
          # check all the ports are open

          # when .ports file is not generated, we will retry 20 times to check if all ports are open
          port_file=./tests/nodes/.ports
          retry_count=0
          while [ $retry_count -lt 100 ]; do
            if [ -f $port_file ]; then
              break
            else
                retry_count=$((retry_count + 1))
                echo "File $port_file not found. Retrying in 2 seconds..."
                sleep 2
            fi
          done

          ports=()
          while IFS= read -r line; do
            ports+=("$line")
          done < ./tests/nodes/.ports

          echo "Checking if all ports are open ... ${ports[@]}"

          try_number=60
          count=0
          while [ $count -lt $try_number ]; do
            all_open=true
            for port in "${ports[@]}"; do
              if ! nc -z 127.0.0.1 $port; then
                echo "Port $port is not open yet ..."
                all_open=false
                break
              fi
            done
            if $all_open; then
              echo "All ports are open now ..."
              break
            else
              count=$((count + 1))
              if [ $count -eq $try_number ]; then
                echo "Reached maximum number of tries ($try_number), exiting with status 1"
                exit 1
              fi
              echo "Not all ports are open, waiting 3 seconds before retrying"
              sleep 3
            fi
          done


          (cd ./tests/bruno; npm exec -- @usebruno/cli@1.20.0 run e2e/${{ matrix.workflow }} -r --env ${{ matrix.test_env }} ${{ matrix.extra_bru_args }} ) &

          # -n means we will exit when any of the background processes exits.
          # https://www.gnu.org/software/bash/manual/bash.html#index-wait
          wait -n


================================================
File: .github/workflows/release.yml
================================================
name: Release
on:
  push:
    branches: [ 'playground/release' ]
    tags: [ '*' ]
env:
  CARGO_TERM_COLOR: always
  RUST_TOOLCHAIN: 1.81.0
permissions:
  contents: write
jobs:
  release:
    name: Build & Release
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ ubuntu-20.04, ubuntu-22.04, macos-13, windows-2019 ]
        include:
          - os: ubuntu-20.04
            bin_suffix:
            pkg_suffix: x86_64-linux-portable
          - os: ubuntu-22.04
            bin_suffix:
            pkg_suffix: x86_64-linux
          - os: macos-13
            bin_suffix:
            pkg_suffix: x86_64-darwin-portable
          - os: windows-2019
            bin_suffix: .exe
            pkg_suffix: x86_64-windows
    steps:
    - name: Checkout the Repository
      uses: actions/checkout@v4
    - name: Install Rust Toolchain
      run: |
        rustup toolchain install ${{ env.RUST_TOOLCHAIN }} --profile minimal
        rustup override set ${{ env.RUST_TOOLCHAIN }}
    - if: matrix.os == 'windows-2019'
      name: Windows Dependencies
      run: |
        iwr -useb get.scoop.sh -outfile 'install-scoop.ps1'
        .\install-scoop.ps1 -RunAsAdmin
        echo "LIBCLANG_PATH=$($HOME)/scoop/apps/llvm/current/bin" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
        echo "$env:USERPROFILE\scoop\shims" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append
        scoop install llvm yasm
        vcpkg integrate install
        vcpkg install openssl:x64-windows-static-md
    - if: matrix.os == 'ubuntu-20.04'
      name: Build linux portable
      run: |
        export PWD_DIR=$(pwd)
        curl -LO https://www.openssl.org/source/openssl-1.1.1s.tar.gz
        tar -xzf openssl-1.1.1s.tar.gz
        cd openssl-1.1.1s
        ./Configure linux-x86_64 shared
        make
        cd ..
        export OPENSSL_LIB_DIR=${PWD_DIR}/openssl-1.1.1s
        export OPENSSL_INCLUDE_DIR=${PWD_DIR}/openssl-1.1.1s/include
        export OPENSSL_STATIC=1
        cargo build --release --features portable
        cd migrate
        cargo build --release --features portable
        cd ..
    - if: matrix.os == 'ubuntu-22.04'
      name: Build linux
      run: cargo build --release && cd migrate && cargo build --release && cd ..
    - if: matrix.os == 'macos-13'
      name: Build macos portable
      run: |
        export OPENSSL_LIB_DIR=/usr/local/opt/openssl@1.1/lib
        export OPENSSL_INCLUDE_DIR=/usr/local/opt/openssl@1.1/include
        export OPENSSL_STATIC=1
        cargo build --release --features portable && cd migrate && cargo build --release --features portable && cd ..
    - if: matrix.os == 'windows-2019'
      name: Build windows
      run: cargo build --release && cd migrate && cargo build --release && cd ..
    - name: Get the Version
      id: get_version
      shell: bash
      run: echo "VERSION=$(echo $GITHUB_REF | cut -d / -f 3)" >> $GITHUB_OUTPUT
    - id: get_package
      name: Package
      shell: bash
      run: |
        pkgname="fnn_${{ steps.get_version.outputs.VERSION }}-${{ matrix.pkg_suffix }}.tar.gz"
        cp "target/release/fnn${{ matrix.bin_suffix }}" "fnn${{ matrix.bin_suffix }}"
        cp "migrate/target/release/fnn-migrate${{ matrix.bin_suffix }}" "fnn-migrate${{ matrix.bin_suffix }}"
        tar czvf "${pkgname}" "fnn${{ matrix.bin_suffix }}" "fnn-migrate${{ matrix.bin_suffix }}" "config"
        echo "PKGNAME=${pkgname}" >> $GITHUB_OUTPUT
    - name: Upload Release Asset
      uses: softprops/action-gh-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        draft: true
        files: |
          ${{ steps.get_package.outputs.PKGNAME }}


