Directory structure:
└── utxostack-mutiny-node/
    ├── README.md
    ├── Cargo.toml
    ├── LICENSE
    ├── flake.lock
    ├── flake.nix
    ├── justfile
    ├── rust-toolchain.toml
    ├── .envrc
    ├── docs/
    │   └── Testing.md
    ├── mutiny-core/
    │   ├── README.md
    │   ├── Cargo.toml
    │   ├── LICENSE
    │   ├── webdriver.json
    │   └── src/
    │       ├── authclient.rs
    │       ├── authmanager.rs
    │       ├── blindauth.rs
    │       ├── chain.rs
    │       ├── encrypt.rs
    │       ├── error.rs
    │       ├── event.rs
    │       ├── fees.rs
    │       ├── gossip.rs
    │       ├── key.rs
    │       ├── keymanager.rs
    │       ├── labels.rs
    │       ├── ldkstorage.rs
    │       ├── lib.rs
    │       ├── logging.rs
    │       ├── messagehandler.rs
    │       ├── node.rs
    │       ├── nodemanager.rs
    │       ├── onchain.rs
    │       ├── peermanager.rs
    │       ├── scorer.rs
    │       ├── storage.rs
    │       ├── subscription.rs
    │       ├── test_utils.rs
    │       ├── utils.rs
    │       ├── vss.rs
    │       ├── lsp/
    │       │   ├── lsps.rs
    │       │   ├── mod.rs
    │       │   └── voltage.rs
    │       └── networking/
    │           ├── mod.rs
    │           ├── proxy.rs
    │           ├── socket.rs
    │           ├── websocket.rs
    │           └── ws_socket.rs
    ├── mutiny-wasm/
    │   ├── README.md
    │   ├── Cargo.toml
    │   ├── LICENSE
    │   ├── webdriver.json
    │   └── src/
    │       ├── error.rs
    │       ├── indexed_db.rs
    │       ├── lib.rs
    │       ├── models.rs
    │       └── utils.rs
    ├── .cargo/
    │   └── config.toml
    └── .github/
        └── workflows/
            ├── release.yml
            └── test.yml

================================================
File: README.md
================================================
# mutiny-node

[![MIT licensed](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/utxostack/mutiny-node/blob/master/LICENSE)
[![npm version](https://badge.fury.io/js/@nervina-labs%2Fmutiny-wasm.svg)](https://badge.fury.io/js/@nervina-labs%2Fmutiny-wasm)

The mutiny node that powers the mutiny web frontend.

## Importing

The web front end imports the NPM package that this project
creates [here](https://www.npmjs.com/package/@nervina-labs/mutiny-wasm).

## Development

### Nixos

A `flake.nix` file has been added for easier nix development and testing. Pretty much all cargo / wasm commands work,
though right now optimized for `aarch64-unknown-linux-gnu` and `wasm32-unknown-unknown` compilation in the nix shell.

To start:

```
nix develop
```

Then the following `just` examples that work:

```
just clippy-nix
just test-nix
just pack
just release
```

### Building on the mac

See the discussion here:
https://github.com/rust-bitcoin/rust-secp256k1/issues/283

You may have to either prefix some environment variables or set them in your env or shell file:

```
AR=/opt/homebrew/opt/llvm/bin/llvm-ar CC=/opt/homebrew/opt/llvm/bin/clang
```

### Dependencies

- [rust](https://www.rust-lang.org/) (specifically, nightly: `rustup toolchain install nightly-2024-09-19`
  and `rustup target add wasm32-unknown-unknown --toolchain nightly`)

- [node](https://nodejs.org/en/)

- [wasm-pack](https://rustwasm.github.io/wasm-pack/installer/#)

```
cargo install wasm-pack
```

- [just](https://github.com/casey/just)

- [chromedriver](https://chromedriver.chromium.org/)

```
brew install chromedriver
```

### Build

Get all the dependencies above first.

Build the rust wasm stuff:

```
just pack
```

### Testing

To run the local tests you can simply use

```
just test
```

## Acknowledgments

This project was initially forked from [mutiny-node](https://github.com/MutinyWallet/mutiny-node). We are grateful for the solid work done by the original contributors.



================================================
File: Cargo.toml
================================================
[workspace]
resolver = "2"

members = [
    "mutiny-core",
    "mutiny-wasm",
]


# Tell `rustc` to optimize for small code size.
[profile.release.package.mutiny-core]
opt-level = "z"

[profile.release.package.mutiny-wasm]
opt-level = "z"

[patch.crates-io]
lightning-background-processor = { git = "https://github.com/utxostack/rust-lightning.git", branch = "fix-channel-manager-wasm32" }
lightning = { git = "https://github.com/utxostack/rust-lightning.git", branch = "fix-channel-manager-wasm32" }
lightning-types = { git = "https://github.com/utxostack/rust-lightning.git", branch = "fix-channel-manager-wasm32" }
lightning-invoice = { git = "https://github.com/utxostack/rust-lightning.git", branch = "fix-channel-manager-wasm32" }
lightning-rapid-gossip-sync = { git = "https://github.com/utxostack/rust-lightning.git", branch = "fix-channel-manager-wasm32" }
lightning-transaction-sync = { git = "https://github.com/utxostack/rust-lightning.git", branch = "fix-channel-manager-wasm32" }


================================================
File: LICENSE
================================================
MIT License

Copyright (c) 2022-2024 Mutiny Wallet Inc.

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


================================================
File: flake.lock
================================================
{
  "nodes": {
    "flake-utils": {
      "inputs": {
        "systems": "systems"
      },
      "locked": {
        "lastModified": 1726560853,
        "narHash": "sha256-X6rJYSESBVr3hBoH0WbKE5KvhPU5bloyZ2L4K60/fPQ=",
        "owner": "numtide",
        "repo": "flake-utils",
        "rev": "c1dfcf08411b08f6b8615f7d8971a2bfa81d5e8a",
        "type": "github"
      },
      "original": {
        "owner": "numtide",
        "repo": "flake-utils",
        "type": "github"
      }
    },
    "nixpkgs": {
      "locked": {
        "lastModified": 1728492678,
        "narHash": "sha256-9UTxR8eukdg+XZeHgxW5hQA9fIKHsKCdOIUycTryeVw=",
        "owner": "NixOS",
        "repo": "nixpkgs",
        "rev": "5633bcff0c6162b9e4b5f1264264611e950c8ec7",
        "type": "github"
      },
      "original": {
        "id": "nixpkgs",
        "ref": "nixos-unstable",
        "type": "indirect"
      }
    },
    "root": {
      "inputs": {
        "flake-utils": "flake-utils",
        "nixpkgs": "nixpkgs",
        "rust-overlay": "rust-overlay"
      }
    },
    "rust-overlay": {
      "inputs": {
        "nixpkgs": [
          "nixpkgs"
        ]
      },
      "locked": {
        "lastModified": 1728873041,
        "narHash": "sha256-e4jz7yFADiZjMhv+iQwYtAN8AOUlOpbNQYnbwUFLjeM=",
        "owner": "oxalica",
        "repo": "rust-overlay",
        "rev": "bdbe1611c2029de90bca372ce0b1e3b4fa65f55a",
        "type": "github"
      },
      "original": {
        "owner": "oxalica",
        "repo": "rust-overlay",
        "type": "github"
      }
    },
    "systems": {
      "locked": {
        "lastModified": 1681028828,
        "narHash": "sha256-Vy1rq5AaRuLzOxct8nz4T6wlgyUR7zLU309k9mBC768=",
        "owner": "nix-systems",
        "repo": "default",
        "rev": "da67096a3b9bf56a91d16901293e51ba5b49a27e",
        "type": "github"
      },
      "original": {
        "owner": "nix-systems",
        "repo": "default",
        "type": "github"
      }
    }
  },
  "root": "root",
  "version": 7
}


================================================
File: flake.nix
================================================
{
  description = "Minimal rust wasm32-unknown-unknown example";

  inputs = {
    flake-utils.url = "github:numtide/flake-utils";
    rust-overlay = {
      url = "github:oxalica/rust-overlay";
      inputs.nixpkgs.follows = "nixpkgs";
    };
    nixpkgs.url = "nixpkgs/nixos-unstable";
  };

  outputs = { self, nixpkgs, flake-utils, rust-overlay }:
    flake-utils.lib.eachDefaultSystem (system:
      let
        overlays = [ rust-overlay.overlays.default ];
        pkgs = import nixpkgs { inherit system overlays; };
        rust = pkgs.rust-bin.fromRustupToolchainFile ./rust-toolchain.toml;
        inputs = [
          rust
          pkgs.rust-analyzer
          pkgs.openssl
          pkgs.zlib
          pkgs.gcc
          pkgs.pkg-config
          pkgs.just
          pkgs.wasm-pack
          pkgs.wasm-bindgen-cli
          pkgs.binaryen
          pkgs.clang
          pkgs.corepack_20
          pkgs.nodejs_20
        ] ++ pkgs.lib.optionals (!pkgs.stdenv.isDarwin) [
          # Add firefox deps only on non-darwin.
          # darwin is listed in badPlatforms in pkgs.firefox's meta.
          pkgs.firefox
          pkgs.geckodriver
        ];
      in
      {
        defaultPackage = pkgs.rustPlatform.buildRustPackage {
          src = ./.;

          cargoLock = {
            lockFile = ./Cargo.lock;
          };

          nativeBuildInputs = inputs;
        };


        devShell = pkgs.mkShell {
          packages = inputs;
          shellHook = ''
            export LIBCLANG_PATH=${pkgs.libclang.lib}/lib/
            export LD_LIBRARY_PATH=${pkgs.openssl}/lib:$LD_LIBRARY_PATH
            export CC_wasm32_unknown_unknown=${pkgs.llvmPackages_14.clang-unwrapped}/bin/clang-14
            export CFLAGS_wasm32_unknown_unknown="-I ${pkgs.llvmPackages_14.libclang.lib}/lib/clang/14.0.6/include/"
          '';
        };
      }
    );
}


================================================
File: justfile
================================================
pack:
    wasm-pack build ./mutiny-wasm --weak-refs --target web --scope nervina-labs

link:
    wasm-pack build ./mutiny-wasm --dev --weak-refs --target web --scope nervina-labs && cd mutiny-wasm/pkg && pnpm link --global

login:
    wasm-pack login --scope=@nervina-labs

dev: 
    wasm-pack build ./mutiny-wasm --dev --weak-refs --target web --scope nervina-labs

release:
    wasm-pack build ./mutiny-wasm --release --weak-refs --target web --scope nervina-labs

publish:
    wasm-pack publish --access public -t web

[macos]
test:
    cargo test -p mutiny-core --target=aarch64-apple-darwin --locked
    WASM_BINDGEN_TEST_TIMEOUT=120 wasm-pack test --headless --chrome ./mutiny-core
    WASM_BINDGEN_TEST_TIMEOUT=120 wasm-pack test --headless --chrome ./mutiny-wasm

[linux]
test:
    cargo test -p mutiny-core --target=x86_64-unknown-linux-gnu
    WASM_BINDGEN_TEST_TIMEOUT=120 wasm-pack test --headless --firefox ./mutiny-core
    WASM_BINDGEN_TEST_TIMEOUT=120 wasm-pack test --headless --firefox ./mutiny-wasm

test-nix:
    cargo test -p mutiny-core --target=aarch64-unknown-linux-gnu
    WASM_BINDGEN_TEST_TIMEOUT=120 wasm-pack test --headless --firefox ./mutiny-core
    WASM_BINDGEN_TEST_TIMEOUT=120 wasm-pack test --headless --firefox ./mutiny-wasm

[macos]
clippy:
    cargo clippy --all-features --tests --package mutiny-core --target=wasm32-unknown-unknown -- -D warnings
    cargo clippy --all-features --tests --package mutiny-core --target=aarch64-apple-darwin -- -D warnings
    cargo clippy --all-features --tests --package mutiny-wasm -- -D warnings

[linux]
clippy:
    cargo clippy --all-features --tests --package mutiny-core --target=wasm32-unknown-unknown -- -D warnings
    cargo clippy --all-features --tests --package mutiny-core --target=x86_64-unknown-linux-gnu -- -D warnings
    cargo clippy --all-features --tests --package mutiny-wasm -- -D warnings

clippy-nix:
    cargo clippy --all-features --tests --package mutiny-core --target=wasm32-unknown-unknown -- -D warnings
    cargo clippy --all-features --tests --package mutiny-core --target=aarch64-unknown-linux-gnu -- -D warnings
    cargo clippy --all-features --tests --package mutiny-wasm -- -D warnings


================================================
File: rust-toolchain.toml
================================================
[toolchain]
channel = "nightly-2024-09-19"
components = ["rustfmt", "clippy"]
targets = [ "wasm32-unknown-unknown" ]
profile = "default"


================================================
File: .envrc
================================================
use flake


================================================
File: docs/Testing.md
================================================
# Testing

Things to test before cutting a release:

- [ ] `just test`/CI passes
- [ ] Enable diagnostics
- [ ] Join a fedimint
- [ ] Leave a fedimint and rejoin
- [ ] Receive on lightning
  - [ ] One with fedimint
  - [ ] One that creates a channel
  - [ ] One that uses an existing channel
- [ ] Send on lightning
  - [ ] Small amount (1 sat)
  - [ ] Medium amount (1,000 sat)
  - [ ] Large amount (100,000 sat)
- [ ] Receive on chain
- [ ] Send on chain
- [ ] Swap to lightning
- [ ] Swap fedimint to lightning
- [ ] Nostr Wallet Connect
  - [ ] Auto approval
  - [ ] Manual approval
  - [ ] Editing a budget
- [ ] Syncing Nostr Contacts
- [ ] Adding a contact
- [ ] Restore from seed
- [ ] Adding an encryption password
  - [ ] Make sure we can decrypt wallet
- [ ] Changing an encryption password
- [ ] Restoring with an encryption password
- [ ] Export logs
  - [ ] Try with and without encryption password
- [ ] Mutual Close Channel
  - [ ] Known Issue: balance will be double counted until 6 confirmations
- [ ] Force Close Channel
- [ ] Get Mutiny+
- [ ] Test lightning address payments
- [ ] Change to Zeus LSP (https://mutinynet-flow.lnolymp.us)
  - [ ] Doesn't allow if you have channels
  - [ ] re-test all channel things again

Testing Utils:

- [Faucet](https://faucet.mutinynet.com/)
- You can also DM the faucet, just search `Mutinynet`
  - DM it an invoice or on-chain address and it'll send to them
  - DM it `zap me` for it to zap you, you need a lightning address for this
  - DM it `spam me` for it to zap you 25 times, you need a lightning address for this


================================================
File: mutiny-core/README.md
================================================
# mutiny-core

The core SDK for the mutiny node.

```bash
cargo add mutiny-core
```

### Usage

```rust
use bitcoin::Network;
use mutiny_core::nodemanager::NodeManager;

async fn main() {
    let nm = NodeManager::new(
        "password".to_string(),
        None,
        None,
        Some(Network::Testnet),
        None,
        None,
        None,
    ).await.unwrap();

    let address = nm.get_new_address().await.unwrap();
    println!("Address: {}", address);

    let tx_details_opt = nm.check_address(address).await.unwrap();
}

```

================================================
File: mutiny-core/Cargo.toml
================================================
cargo-features = ["per-package-target"]

[package]
name = "mutiny-core"
version = "1.7.13"
edition = "2021"
authors = [
  "Tony Giorgio <tony@mutinywallet.com>",
  "benthecarman <ben@mutinywallet.com>",
]
description = "The core SDK for the mutiny node"
license = "MIT"
documentation = "https://docs.rs/mutiny-core"
homepage = "https://mutinywallet.com"
repository = "https://github.com/mutinywallet/mutiny-node"

[dependencies]
cfg-if = "1.0.0"
bip39 = { version = "2.0.0" }
bitcoin = { version = "0.32.2", default-features = false, features = [
  "std",
  "serde",
  "secp-recovery",
  "rand",
] }
bdk_esplora = { version = "=0.18.0", default-features = false, features = [
  "std",
  "async-https",
] }
bdk_chain = { version = "=0.19.0", features = ["std"] }
bdk_wallet = { version = "=1.0.0-beta.4", features = ["std"] }
bdk-macros = "0.6.0"
getrandom = { version = "0.2" }
itertools = "0.11.0"
serde = { version = "^1.0", features = ["derive"] }
serde_json = { version = "^1.0" }
uuid = { version = "1.1.2", features = ["v4"] }
esplora-client = { version = "0.9", default-features = false, features = [
  "async",
] }
lightning = { version = "0.0.124", default-features = false, features = [
  "max_level_trace",
  "grind_signatures",
  "std",
] }
lightning-invoice = { version = "0.32.0", features = ["serde"] }
lightning-rapid-gossip-sync = { version = "0.0.124" }
lightning-background-processor = { version = "0.0.124", features = ["futures"] }
lightning-transaction-sync = { version = "0.0.124", default-features = false, features = [
  "esplora-async-https",
] }
lightning-liquidity = "0.1.0-alpha.5"
chrono = "0.4.22"
futures-util = { version = "0.3", default-features = false }
reqwest = { version = "0.11", default-features = false, features = [
  "multipart",
  "json",
] }
async-trait = "0.1.68"
url = { version = "2.3.1", features = ["serde"] }
cbc = { version = "0.1", features = ["alloc"] }
aes = { version = "0.8" }
jwt-compact = { version = "0.8.0-beta.1", features = ["es256k"] }
argon2 = { version = "0.5.0", features = ["password-hash", "alloc"] }
bincode = "1.3.3"
hex-conservative = "0.1.1"
async-lock = "3.2.0"

base64 = "0.13.0"
pbkdf2 = "0.11"
aes-gcm = "0.10.1"

log = "0.4.18"
futures = "0.3.25"
thiserror = "1.0"
anyhow = "1.0"

[dev-dependencies]
wasm-bindgen-test = "0.3.33"
mockall = "0.11.2"
web-sys = { version = "0.3.65", features = ["console"] }
js-sys = "0.3.65"

[features]
default = []
ignored_tests = []

[target.'cfg(target_arch = "wasm32")'.dependencies]
wasm-bindgen-futures = { version = "0.4.38" }
gloo-net = { version = "0.4.0" }
web-time = "1.1"
gloo-timers = { version = "0.3.0", features = ["futures"] }
getrandom = { version = "0.2", features = ["js"] }
web-sys = { version = "0.3.65", features = ["console"] }
js-sys = "0.3.65"

[target.'cfg(not(target_arch = "wasm32"))'.dependencies]
tokio = { version = "1", features = ["rt", "macros"] }
tokio-tungstenite = { version = "0.19.0", features = ["native-tls"] }
lightning-net-tokio = "0.0.124"

[target.'cfg(not(target_arch = "wasm32"))'.dev-dependencies]
tokio = { version = "1", features = ["full"] }
env_logger = "0.10"
warp = "0.3.7"

[package.metadata.wasm-pack.profile.release]
wasm-opt = true


================================================
File: mutiny-core/LICENSE
================================================
MIT License

Copyright (c) 2022-2023 Mutiny Wallet Inc.

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


================================================
File: mutiny-core/webdriver.json
================================================
{
  "goog:chromeOptions": {
    "args": [
      "--use-fake-device-for-media-stream",
      "--use-fake-ui-for-media-stream"
    ]
  },
  "moz:firefoxOptions": {
    "prefs": {
      "media.navigator.streams.fake": true,
      "media.navigator.permission.disabled": true,
      "media.webaudio.enabled": false,
      "datareporting.healthreport.uploadEnabled": false
    },
    "args": []
  }
}


================================================
File: mutiny-core/src/authclient.rs
================================================
use crate::{authmanager::AuthManager, error::MutinyError, logging::MutinyLogger, utils};
use async_lock::RwLock;
use bitcoin::hashes::{hex::prelude::*, sha256, Hash};
use bitcoin::key::rand::Rng;
use bitcoin::secp256k1::rand::thread_rng;
use jwt_compact::UntrustedToken;
use lightning::{log_debug, log_error, log_info};
use lightning::{log_trace, util::logger::*};
use reqwest::Client;
use reqwest::{Method, StatusCode, Url};
use serde_json::Value;

use std::sync::Arc;

pub struct MutinyAuthClient {
    pub auth: AuthManager,
    url: String,
    http_client: Client,
    jwt: RwLock<Option<String>>,
    logger: Arc<MutinyLogger>,
}

impl MutinyAuthClient {
    pub fn new(auth: AuthManager, logger: Arc<MutinyLogger>, url: String) -> Self {
        let http_client = Client::new();
        Self {
            auth,
            url,
            http_client,
            jwt: RwLock::new(None),
            logger,
        }
    }

    pub async fn authenticate(&self) -> Result<(), MutinyError> {
        self.retrieve_new_jwt().await?;
        Ok(())
    }

    pub async fn is_authenticated(&self) -> Option<String> {
        let lock = self.jwt.read().await;
        if let Some(jwt) = lock.as_ref() {
            return Some(jwt.to_string()); // TODO parse and make sure still valid
        }
        None
    }

    pub async fn request(
        &self,
        method: Method,
        url: Url,
        body: Option<Value>,
    ) -> Result<reqwest::Response, MutinyError> {
        let res = self
            .authenticated_request(method.clone(), url.clone(), body.clone())
            .await?;
        match res.status() {
            // If we get a 401, refresh the JWT and try again
            StatusCode::UNAUTHORIZED => {
                self.retrieve_new_jwt().await?;
                self.authenticated_request(method, url, body).await
            }
            StatusCode::OK | StatusCode::ACCEPTED | StatusCode::CREATED => Ok(res),
            code => {
                log_error!(self.logger, "Received unexpected status code: {code}");
                Err(MutinyError::ConnectionFailed)
            }
        }
    }

    async fn authenticated_request(
        &self,
        method: Method,
        url: Url,
        body: Option<Value>,
    ) -> Result<reqwest::Response, MutinyError> {
        log_trace!(self.logger, "Doing an authenticated request {url:?}");

        let mut request = self.http_client.request(method, url);

        let mut jwt = self.is_authenticated().await;
        if jwt.is_none() {
            jwt = Some(self.retrieve_new_jwt().await?);
        }
        request = request.bearer_auth(jwt.expect("either had one or retrieved new"));

        if let Some(json) = body {
            request = request.json(&json);
        }

        utils::fetch_with_timeout(
            &self.http_client,
            request.build().expect("should build req"),
        )
        .await
    }

    // TODO: Multiple concurrent `retrieve_new_jwt` calls could trigger multiple token refreshes.
    // In a future PR, maybe we can add JWT parsing and validation before initiating a new token request.
    async fn retrieve_new_jwt(&self) -> Result<String, MutinyError> {
        let mut lock = self.jwt.write().await;
        log_debug!(self.logger, "Retrieving new JWT token");

        let jwt_url = self.url.clone();

        // message: timestamp + '-' + random data
        let timestamp = utils::now().as_secs() - 1;
        let random_data: u64 = thread_rng().gen_range(u32::MAX as u64..u64::MAX);
        let challenge = format!("{}-{}", timestamp, random_data);

        let hashed_msg = sha256::Hash::hash(challenge.as_bytes());
        let (sig, pubkey) = self.auth.sign(hashed_msg.as_ref())?;

        let sig_hex = format!("{:x}", sig.serialize_der().as_hex());
        let pubkey_hex = format!("{:x}", pubkey.serialize().as_hex());

        let response = self
            .http_client
            .post(&jwt_url)
            .json(&serde_json::json!({
                "public_key": pubkey_hex,
                "signature": sig_hex,
                "challenge": challenge,
            }))
            .send()
            .await
            .map_err(|e| {
                log_error!(self.logger, "JWT auth request failed: {e}");
                MutinyError::JwtAuthFailure
            })?;

        if response.status().is_success() {
            let response_text = response
                .text()
                .await
                .map_err(|_| MutinyError::JwtAuthFailure)?;

            let jwt: String = serde_json::from_str::<Value>(&response_text)
                .map_err(|_| MutinyError::JwtAuthFailure)?
                .get("token")
                .and_then(|token| token.as_str().map(String::from))
                .ok_or(MutinyError::JwtAuthFailure)?;

            // basic validation to make sure it is a valid string
            let _ = UntrustedToken::new(&jwt).map_err(|e| {
                log_error!(self.logger, "Could not validate JWT {jwt}: {e}");
                MutinyError::JwtAuthFailure
            })?;

            log_info!(self.logger, "Retrieved new JWT token");
            *lock = Some(jwt.clone());
            Ok(jwt)
        } else {
            // Attempt to parse error message from response body
            let status = response.status();
            let response_text = response.text().await.unwrap_or_default();
            let error_message = serde_json::from_str::<serde_json::Value>(&response_text)
                .ok()
                .and_then(|json| {
                    json.get("message")
                        .and_then(|m| m.as_str().map(|s| s.to_string()))
                })
                .unwrap_or_else(|| "Unknown error".to_string());
            log_error!(
                self.logger,
                "Error trying to retrieve JWT: {} - {}",
                status,
                error_message
            );
            Err(MutinyError::JwtAuthFailure)
        }
    }
}

#[cfg(test)]
#[cfg(not(target_arch = "wasm32"))]
mod tests {
    use super::MutinyAuthClient;
    use crate::authmanager::AuthManager;
    use crate::logging::MutinyLogger;
    use crate::test_utils::*;
    use crate::utils;

    use bip39::Mnemonic;
    use bitcoin::bip32::Xpriv;
    use bitcoin::hashes::{hex::prelude::*, sha256, Hash};
    use bitcoin::key::rand::Rng;
    use bitcoin::secp256k1::{self, rand::thread_rng, Message, PublicKey, Secp256k1};
    use bitcoin::Network;
    use env_logger::Builder;
    use log::LevelFilter;
    use secp256k1::ecdsa::Signature;
    use secp256k1::rand::rngs::OsRng;
    use serde_json::json;
    use warp::Filter;

    use std::str::FromStr;
    use std::sync::Arc;
    use std::sync::Once;
    use std::time::{SystemTime, UNIX_EPOCH};

    static INIT: Once = Once::new();

    fn initialize_logger() {
        INIT.call_once(|| {
            Builder::new()
                .filter(None, LevelFilter::Debug)
                .is_test(true)
                .init();
        });
    }

    #[tokio::test]
    async fn test_authentication() {
        initialize_logger();

        let jwt_route = warp::post()
            .and(warp::path("auth"))
            .and(warp::header::exact_ignore_case(
                "content-type",
                "application/json",
            ))
            .map(|| {
                let token_response = json!({
                    "token": "eyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWUsImlhdCI6MTUxNjIzOTAyMn0.tyh-VfuzIxCyGYDlkBA7DfyjrqmSHu6pQ2hoZuFqUSLPNY2N0mpHb3nk5K17HWP_3cYHBw7AhHale5wky6-sVA"
                });
                warp::reply::with_status(
                    warp::reply::json(&token_response),
                    warp::http::StatusCode::OK,
                )
            });

        let (addr, server) =
            warp::serve(jwt_route).bind_with_graceful_shutdown(([127, 0, 0, 1], 3030), async {
                // Use ctrl_c to ensure the server does not shut down before receiving an interrupt signal,
                // preventing the server from closing prematurely before test requests are completed
                tokio::signal::ctrl_c()
                    .await
                    .expect("failed to listen for shutdown signal");
            });

        tokio::spawn(server);

        let auth_manager = create_manager();
        let logger = Arc::new(MutinyLogger::default());
        let client = MutinyAuthClient::new(auth_manager, logger, format!("http://{}/auth", addr));

        client.authenticate().await.expect("Authentication failed");
        assert!(client.is_authenticated().await.is_some());
    }

    #[tokio::test]
    async fn test_authentication_error_case() {
        initialize_logger();

        let jwt_route = warp::post()
            .and(warp::path("auth"))
            .and(warp::header::exact_ignore_case(
                "content-type",
                "application/json",
            ))
            .map(|| {
                warp::reply::with_status(
                    warp::reply::json(&json!({
                        "message": "signature verification failed"
                    })),
                    warp::http::StatusCode::UNAUTHORIZED,
                )
            });

        let (addr, server) =
            warp::serve(jwt_route).bind_with_graceful_shutdown(([127, 0, 0, 1], 3031), async {
                tokio::signal::ctrl_c()
                    .await
                    .expect("failed to listen for shutdown signal");
            });

        tokio::spawn(server);

        let auth_manager = create_manager();
        let logger = Arc::new(MutinyLogger::default());
        let client = MutinyAuthClient::new(auth_manager, logger, format!("http://{}/auth", addr));

        let result = client.authenticate().await;
        assert!(result.is_err(), "Expected authentication to fail");
    }

    #[tokio::test]
    async fn test_verify_jwt_signature_success() {
        let secp = Secp256k1::new();
        let (secret_key, pubkey) = secp.generate_keypair(&mut OsRng);

        // message: timestamp + '-' + random data
        let timestamp = utils::now().as_secs() - 1;
        let timestamp_2 = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .expect("Time went backwards")
            .as_secs()
            - 1;
        assert_eq!(timestamp, timestamp_2);

        let random_data: u64 = thread_rng().gen_range(u32::MAX as u64..u64::MAX);
        let challenge = format!("{}-{}", timestamp, random_data);

        let hashed_msg = sha256::Hash::hash(challenge.as_bytes());
        let msg =
            Message::from_digest_slice(hashed_msg.as_ref()).expect("32 bytes, guaranteed by type");
        let sig = secp.sign_ecdsa(&msg, &secret_key);

        // hex
        let pubkey_hex = format!("{:x}", pubkey.serialize().as_hex());
        let sig_hex = format!("{:x}", sig.serialize_der().as_hex());

        // verify
        let signature_bytes = Vec::from_hex(&sig_hex).unwrap();
        let public_key_bytes = Vec::from_hex(&pubkey_hex).unwrap();

        let secp = Secp256k1::verification_only();
        let pubkey = PublicKey::from_slice(&public_key_bytes).unwrap();
        let signature = Signature::from_der(&signature_bytes).unwrap();

        // Hash the message before verifying (because the signature was created using the hashed message)
        let hashed_message = sha256::Hash::hash(challenge.as_bytes());
        let msg = Message::from_digest_slice(hashed_message.as_ref()).unwrap();

        let ret = secp.verify_ecdsa(&msg, &signature, &pubkey);

        assert!(ret.is_ok());
    }

    #[tokio::test]
    async fn test_lightning_pubkey() {
        let mnemonic_str =
            "drift main obtain birth salon coyote cream build pottery attack attend glue";
        let mnemonic = Mnemonic::from_str(mnemonic_str).unwrap();

        let seed = mnemonic.to_seed("");
        let xprivkey = Xpriv::new_master(Network::Testnet, &seed).unwrap();
        let auth = AuthManager::new(xprivkey).unwrap();
        let pubkey_hex = format!("{:x}", auth.pubkey().serialize().as_hex());
        assert_eq!(
            pubkey_hex,
            "037ff12d3f50e36df10d8a5d5bfcf678e6fa891ae87dc526026922f7b47ae8e2a7"
        );
    }

    #[tokio::test]
    async fn test_auth_manager_sign() {
        let mnemonic_str =
            "earn stem rate film cat mesh hold violin elite usage maze crane robot fan market sing pepper web collect spice decorate turn creek owner";
        let mnemonic = Mnemonic::from_str(mnemonic_str).unwrap();

        let seed = mnemonic.to_seed("");
        let xprivkey = Xpriv::new_master(Network::Testnet, &seed).unwrap();
        let auth = AuthManager::new(xprivkey).unwrap();
        let pubkey_hex = format!("{:x}", auth.pubkey().serialize().as_hex());
        assert_eq!(
            pubkey_hex,
            "037474ffe18d09f9a65030f8c01899eec41e1d4ee3dead23556c1a0f7863931e29"
        );
        println!("pubkey_hex: {}", pubkey_hex);

        let timestamp = utils::now().as_secs() - 1;
        let random_data: u64 = thread_rng().gen_range(u32::MAX as u64..u64::MAX);
        let challenge = format!("{}-{}", timestamp, random_data);

        let hashed_msg = sha256::Hash::hash(challenge.as_bytes());
        let (sig, pubkey) = auth.sign(hashed_msg.as_ref()).unwrap();
        assert_eq!(format!("{:x}", pubkey.serialize().as_hex()), pubkey_hex);

        let sig_hex = format!("{:x}", sig.serialize_der().as_hex());
        println!("sig_hex: {}", sig_hex);
        println!("pubkey_hex2: {}", pubkey_hex);

        // verify
        let signature_bytes = Vec::from_hex(&sig_hex).unwrap();
        let public_key_bytes = Vec::from_hex(&pubkey_hex).unwrap();

        let secp = Secp256k1::verification_only();
        let pubkey = PublicKey::from_slice(&public_key_bytes).unwrap();
        let signature = Signature::from_der(&signature_bytes).unwrap();

        // Hash the message before verifying (because the signature was created using the hashed message)
        let hashed_message = sha256::Hash::hash(challenge.as_bytes());
        let msg = Message::from_digest_slice(hashed_message.as_ref()).unwrap();

        let ret = secp.verify_ecdsa(&msg, &signature, &pubkey);

        assert!(ret.is_ok());
    }
}


================================================
File: mutiny-core/src/authmanager.rs
================================================
use crate::error::MutinyError;
use bitcoin::bip32::{DerivationPath, Xpriv};
use bitcoin::secp256k1::{ecdsa, All, Message, PublicKey, Secp256k1, SecretKey};

use std::str::FromStr;

#[derive(Clone)]
pub struct AuthManager {
    hashing_key: SecretKey,
    context: Secp256k1<All>,
}

impl AuthManager {
    pub fn new(xprivkey: Xpriv) -> Result<Self, MutinyError> {
        let context = Secp256k1::new();

        let master_path = DerivationPath::from_str("m/0'/0'")?;
        let master_x_key = xprivkey.derive_priv(&context, &master_path)?;

        let seed = master_x_key.private_key.secret_bytes();
        let master_key = Xpriv::new_master(xprivkey.network, &seed)?;

        let lightning_key_path = DerivationPath::from_str("m/0'")?;
        let lightning_key = master_key.derive_priv(&context, &lightning_key_path)?;
        let hashing_key = lightning_key.private_key;

        Ok(Self {
            hashing_key,
            context,
        })
    }

    pub fn sign(
        &self,
        message_hash: &[u8; 32],
    ) -> Result<(ecdsa::Signature, PublicKey), MutinyError> {
        let pubkey = self.hashing_key.public_key(&self.context);
        let msg = Message::from_digest_slice(message_hash).expect("32 bytes, guaranteed by type");
        let sig = self.context.sign_ecdsa(&msg, &self.hashing_key);
        Ok((sig, pubkey))
    }

    pub fn pubkey(&self) -> PublicKey {
        self.hashing_key.public_key(&self.context)
    }
}

#[cfg(test)]
#[cfg(not(target_arch = "wasm32"))]
mod test {
    use crate::test_utils::*;

    use super::*;

    #[tokio::test]
    async fn test_create_signature() {
        let test_name = "test_create_signature";
        log!("{}", test_name);

        let auth = create_manager();

        let k1 = [0; 32];

        let (sig, pk) = auth.sign(&k1).unwrap();

        auth.context
            .verify_ecdsa(&Message::from_digest_slice(&k1).unwrap(), &sig, &pk)
            .unwrap();
    }
}


================================================
File: mutiny-core/src/blindauth.rs
================================================
use crate::{
    auth::MutinyAuthClient,
    error::MutinyError,
    key::{create_root_child_key, ChildKey},
    onchain::coin_type_from_network,
};
use crate::{logging::MutinyLogger, storage::MutinyStorage};
use async_lock::RwLock;
use bitcoin::{
    bip32::{ChildNumber, DerivationPath, Xpriv},
    secp256k1::Secp256k1,
    Network,
};
use fedimint_client::derivable_secret::{ChildId, DerivableSecret};
use lightning::log_error;
use lightning::util::logger::Logger;
use reqwest::Method;
use serde::{Deserialize, Serialize};
use std::{collections::HashMap, sync::Arc};
use tbs::{blind_message, BlindedMessage, BlindedSignature, BlindingKey};
use url::Url;

const BLINDAUTH_CLIENT_NONCE: &[u8] = b"BlindAuth Client Salt";

/// The type of blinded message this is for
const SERVICE_REGISTRATION_CHILD_ID: ChildId = ChildId(0);

/// Child ID used to derive the spend key from a service plan's DerivableSecret
const SPEND_KEY_CHILD_ID: ChildId = ChildId(0);

/// Child ID used to derive the blinding key from a service plan's DerivableSecret
const BLINDING_KEY_CHILD_ID: ChildId = ChildId(1);

#[derive(Debug, Serialize, Deserialize, Clone, Default, PartialEq, Eq)]
pub struct TokenStorage {
    // (service_id, plan_id): number of times used
    pub map: HashMap<ServicePlanIndex, u32>,
    pub tokens: Vec<SignedToken>,
    pub version: u32,
}

impl TokenStorage {
    fn increment(&mut self, service_id: u32, plan_id: u32, token: SignedToken) {
        let value = self
            .map
            .entry(ServicePlanIndex {
                service_id,
                plan_id,
            })
            .or_insert(0);
        *value += 1;
        self.tokens.push(token);
        self.version += 1;
    }

    fn get_value(&self, service_id: u32, plan_id: u32) -> u32 {
        self.map
            .get(&ServicePlanIndex {
                service_id,
                plan_id,
            })
            .unwrap_or(&0)
            .to_owned()
    }
}

#[derive(Debug, Clone, Default, Eq, PartialEq, Hash)]
pub struct ServicePlanIndex {
    pub service_id: u32,
    pub plan_id: u32,
}

impl Serialize for ServicePlanIndex {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        let string = format!("{}-{}", self.service_id, self.plan_id);
        serializer.serialize_str(&string)
    }
}

impl<'a> Deserialize<'a> for ServicePlanIndex {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: serde::Deserializer<'a>,
    {
        let uri = String::deserialize(deserializer)?;

        let parts: Vec<&str> = uri.split('-').collect();
        if parts.len() != 2 {
            return Err(serde::de::Error::custom("Invalid ServicePlanIndex"));
        }

        let service_id = parts[0].parse::<u32>().map_err(serde::de::Error::custom)?;
        let plan_id = parts[1].parse::<u32>().map_err(serde::de::Error::custom)?;
        Ok(ServicePlanIndex {
            service_id,
            plan_id,
        })
    }
}

#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Eq)]
pub struct UnsignedToken {
    pub counter: u32,
    pub service_id: u32,
    pub plan_id: u32,
    pub blinded_message: BlindedMessage,
}

#[derive(Debug, Serialize, Deserialize, Clone, PartialEq, Eq)]
pub struct SignedToken {
    pub counter: u32,
    pub service_id: u32,
    pub plan_id: u32,
    pub blinded_message: BlindedMessage,
    pub blind_sig: BlindedSignature,
    pub spent: bool,
}

#[derive(Serialize, Deserialize)]
pub struct CheckServiceTokenResponse {
    pub tokens: Vec<ServicePlans>,
}

#[derive(Serialize, Deserialize)]
pub struct ServicePlans {
    pub service: Service,
    pub plan: Plan,
}

#[derive(Serialize, Deserialize)]
pub struct Service {
    pub id: u32,
    pub name: String,
}

#[derive(Serialize, Deserialize)]
pub struct Plan {
    pub id: u32,
    pub service_id: u32,
    pub name: String,
    pub allocation_count: u32,
    pub allocation_type: String,
    pub subscription_plan_reference: Option<i32>,
}

#[derive(Serialize, Deserialize)]
pub struct RedeemServiceTokenRequest {
    pub service_id: u32,
    pub plan_id: u32,
    pub blinded_message: BlindedMessage,
}

#[derive(Serialize, Deserialize)]
pub struct RedeemServiceTokenResponse {
    pub service_id: u32,
    pub plan_id: u32,
    pub blind_sig: BlindedSignature,
}

pub struct BlindAuthClient<S: MutinyStorage> {
    secret: DerivableSecret,
    auth_client: Arc<MutinyAuthClient>,
    base_url: String,
    storage: S,
    token_storage: Arc<RwLock<TokenStorage>>,
    pub logger: Arc<MutinyLogger>,
}

impl<S: MutinyStorage> BlindAuthClient<S> {
    pub fn new(
        xprivkey: Xpriv,
        auth_client: Arc<MutinyAuthClient>,
        network: Network,
        base_url: String,
        storage: &S,
        logger: Arc<MutinyLogger>,
    ) -> Result<Self, MutinyError> {
        let token_storage = storage.get_token_storage()?;
        let secret = create_blind_auth_secret(xprivkey, network)?;

        Ok(Self {
            secret,
            auth_client,
            base_url,
            storage: storage.clone(),
            token_storage: Arc::new(RwLock::new(token_storage)),
            logger,
        })
    }

    pub async fn redeem_available_tokens(&self) -> Result<(), MutinyError> {
        // check to see what is available to the user
        let available_tokens = self.check_available_tokens().await?;

        // fetch available one by one
        for service in available_tokens.tokens {
            match self.retrieve_blinded_signature(service).await {
                Ok(_) => (),
                Err(e) => {
                    log_error!(self.logger, "could not redeem token: {e}");
                }
            };
        }

        Ok(())
    }

    async fn check_available_tokens(&self) -> Result<CheckServiceTokenResponse, MutinyError> {
        get_available_tokens(&self.auth_client, &self.base_url).await
    }

    async fn retrieve_blinded_signature(
        &self,
        service: ServicePlans,
    ) -> Result<SignedToken, MutinyError> {
        let service_id = service.service.id;
        let plan_id = service.plan.id;
        let mut token_storage_guard = self.token_storage.write().await;
        let next_counter = token_storage_guard.get_value(service_id, plan_id) + 1;

        // create the deterministic info to derive the token from
        let token_to_blind =
            derive_blind_token(&self.secret, service_id, plan_id, next_counter).await?;
        let token_req = RedeemServiceTokenRequest {
            service_id,
            plan_id,
            blinded_message: token_to_blind.blinded_message,
        };

        // request a blinded signature
        let token_resp =
            retrieve_blinded_signature(&self.auth_client, &self.base_url, token_req).await?;
        let signed_token = SignedToken {
            counter: token_to_blind.counter,
            service_id,
            plan_id,
            blinded_message: token_to_blind.blinded_message,
            blind_sig: token_resp.blind_sig,
            spent: false,
        };

        // store the complete blinded token info
        token_storage_guard.increment(service_id, plan_id, signed_token.clone());

        // FIXME what if storage fails remotely? Revert somehow?
        // It will at least be there locally
        // Maybe have an "issued" tokens call so we can see if we're caught up with the server?
        self.storage
            .insert_token_storage(token_storage_guard.clone())
            .await
            .map_err(|e| {
                log_error!(self.logger, "could not save token storage: {e:?}");
                e
            })?;

        Ok(signed_token)
    }

    pub async fn available_tokens(&self) -> Vec<SignedToken> {
        self.token_storage
            .read()
            .await
            .tokens
            .clone()
            .into_iter()
            .filter(|t| !t.spent)
            .collect::<Vec<SignedToken>>()
    }

    pub async fn used_token(&self, token: &SignedToken) -> Result<(), MutinyError> {
        // once a token has sufficiently been used, mark it as spent and save it back
        let mut token_storage_guard = self.token_storage.write().await;

        // find the token in the vector of tokens
        if let Some(index) = token_storage_guard.tokens.iter_mut().position(|t| {
            t.service_id == token.service_id
                && t.plan_id == token.plan_id
                && t.counter == token.counter
        }) {
            // mark the found token as spent
            token_storage_guard.tokens[index].spent = true;
            token_storage_guard.version += 1;

            // save the updated token storage back to the database or other persistent storage
            self.storage
                .insert_token_storage(token_storage_guard.clone())
                .await?;
        } else {
            return Err(MutinyError::NotFound);
        }

        Ok(())
    }

    pub fn get_unblinded_info_from_token(
        &self,
        token: &SignedToken,
    ) -> (fedimint_mint_client::Nonce, BlindingKey) {
        generate_nonce(&self.secret, token.service_id, token.plan_id, token.counter)
    }
}

async fn get_available_tokens(
    auth_client: &MutinyAuthClient,
    base_url: &str,
) -> Result<CheckServiceTokenResponse, MutinyError> {
    let url = Url::parse(&format!("{}/v1/check-tokens", base_url))
        .map_err(|_| MutinyError::ConnectionFailed)?;
    let res = auth_client
        .request(Method::GET, url, None)
        .await?
        .json::<CheckServiceTokenResponse>()
        .await
        .map_err(|_| MutinyError::ConnectionFailed)?;

    Ok(res)
}

async fn retrieve_blinded_signature(
    auth_client: &MutinyAuthClient,
    base_url: &str,
    req: RedeemServiceTokenRequest,
) -> Result<RedeemServiceTokenResponse, MutinyError> {
    let url = Url::parse(&format!("{}/v1/redeem-tokens", base_url))
        .map_err(|_| MutinyError::ConnectionFailed)?;
    let body = serde_json::to_value(req)?;
    let res = auth_client
        .request(Method::POST, url, Some(body))
        .await?
        .json::<RedeemServiceTokenResponse>()
        .await
        .map_err(|_| MutinyError::ConnectionFailed)?;

    Ok(res)
}

async fn derive_blind_token(
    secret: &DerivableSecret,
    service_id: u32,
    plan_id: u32,
    counter: u32,
) -> Result<UnsignedToken, MutinyError> {
    let (nonce, blinding_key) = generate_nonce(secret, service_id, plan_id, counter);
    let blinded_message = blind_message(nonce.to_message(), blinding_key);

    let unsigned_token = UnsignedToken {
        counter,
        service_id,
        plan_id,
        blinded_message,
    };

    Ok(unsigned_token)
}

fn generate_nonce(
    secret: &DerivableSecret,
    service_id: u32,
    plan_id: u32,
    counter: u32,
) -> (fedimint_mint_client::Nonce, BlindingKey) {
    let child_secret = secret
        .child_key(SERVICE_REGISTRATION_CHILD_ID)
        .child_key(ChildId(service_id.into()))
        .child_key(ChildId(plan_id.into()))
        .child_key(ChildId(counter.into()));

    let spend_key = child_secret
        .child_key(SPEND_KEY_CHILD_ID)
        .to_secp_key(fedimint_ln_common::bitcoin::secp256k1::SECP256K1);

    let nonce = fedimint_mint_client::Nonce(spend_key.public_key());

    let blinding_key = BlindingKey(
        child_secret
            .child_key(BLINDING_KEY_CHILD_ID)
            .to_bls12_381_key(),
    );
    (nonce, blinding_key)
}

// Creates the root derivation secret for the blind auth client:
// `m/2'/N'` where `N` is the network type.
//
// Each specific service+plan will have a derivation from there.
fn create_blind_auth_secret(
    xprivkey: Xpriv,
    network: Network,
) -> Result<DerivableSecret, MutinyError> {
    let context = Secp256k1::new();

    let shared_key = create_root_child_key(&context, xprivkey, ChildKey::BlindAuth)?;
    let xpriv = shared_key.derive_priv(
        &context,
        &DerivationPath::from(vec![ChildNumber::from_hardened_idx(
            coin_type_from_network(network),
        )?]),
    )?;

    Ok(DerivableSecret::new_root(
        &xpriv.private_key.secret_bytes(),
        BLINDAUTH_CLIENT_NONCE,
    ))
}

#[cfg(test)]
#[cfg(not(target_arch = "wasm32"))]
mod test {
    use crate::auth::MutinyAuthClient;
    use crate::blindauth::{BlindAuthClient, ServicePlanIndex, SignedToken, TokenStorage};
    use crate::generate_seed;
    use crate::logging::MutinyLogger;
    use crate::storage::MemoryStorage;
    use crate::test_utils::create_manager;
    use bitcoin::bip32::Xpriv;
    use bitcoin::Network;
    use nostr::prelude::hex;
    use std::sync::Arc;
    use tbs::{
        unblind_signature, AggregatePublicKey, BlindedMessage, BlindedSignature, PubKeyPoint,
    };

    const FREE_PK: &str = "a5596b43416c17dcd331a64d4a5f60ab3a470fc03f83a3d834910903ee78f5ade33da927b86481d6edd3de08e89455d6115f5c5e642f4a47d24c85a458369e736cfc410b984cf7e4bf97853a40632f26ca9ad65008bfbe27f40ab8aa7bdffe9f";

    fn create_client() -> BlindAuthClient<MemoryStorage> {
        let storage = MemoryStorage::default();
        let logger = Arc::new(MutinyLogger::default());
        let mnemonic = generate_seed(12).unwrap();
        let xpriv = Xpriv::new_master(Network::Regtest, &mnemonic.to_seed("")).unwrap();

        // Set up test auth client
        let auth_manager = create_manager();
        let lnurl_client = Arc::new(
            lnurl::Builder::default()
                .build_async()
                .expect("failed to make lnurl client"),
        );
        let auth_client = MutinyAuthClient::new(
            auth_manager,
            lnurl_client,
            logger.clone(),
            "https://auth-staging.mutinywallet.com".to_string(),
        );

        BlindAuthClient::new(
            xpriv,
            Arc::new(auth_client),
            Network::Regtest,
            "https://blind-auth-staging.mutinywallet.com".to_string(),
            &storage,
            logger,
        )
        .unwrap()
    }

    #[test]
    fn test_token_storage_serialization() {
        let mut map = std::collections::HashMap::new();
        map.insert(
            ServicePlanIndex {
                service_id: 1,
                plan_id: 1,
            },
            1,
        );

        let token = SignedToken {
            counter: 1,
            service_id: 1,
            plan_id: 1,
            blinded_message: BlindedMessage(Default::default()),
            blind_sig: BlindedSignature(Default::default()),
            spent: false,
        };

        let storage = TokenStorage {
            map,
            tokens: vec![token],
            version: 0,
        };

        let serialized = serde_json::to_string(&storage).unwrap();
        let deserialized: TokenStorage = serde_json::from_str(&serialized).unwrap();

        assert_eq!(storage, deserialized);

        // test backwards compatibility
        let string = "{\"map\":{\"1-1\":1},\"tokens\":[{\"counter\":1,\"service_id\":1,\"plan_id\":1,\"blinded_message\":\"c00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\",\"blind_sig\":\"c00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\",\"spent\":false}],\"version\":0}";
        let deserialized: TokenStorage = serde_json::from_str(string).unwrap();
        assert_eq!(storage, deserialized);
    }

    #[tokio::test]
    async fn test_blind_auth_client() {
        let client = create_client();
        assert!(client.available_tokens().await.is_empty());

        client.redeem_available_tokens().await.unwrap();

        let tokens = client.available_tokens().await;
        assert!(!tokens.is_empty());

        let token = tokens.first().unwrap();

        // do the unblinding
        let (nonce, blinding_key) = client.get_unblinded_info_from_token(token);
        let unblinded_sig = unblind_signature(blinding_key, token.blind_sig);

        // check that the signature is valid
        let free_pk: AggregatePublicKey = AggregatePublicKey(
            PubKeyPoint::from_compressed(
                hex::decode(FREE_PK).expect("Invalid key hex")[..]
                    .try_into()
                    .expect("Invalid key byte key"),
            )
            .expect("Invalid FREE_PK"),
        );
        assert!(tbs::verify(nonce.to_message(), unblinded_sig, free_pk));
    }
}


================================================
File: mutiny-core/src/chain.rs
================================================
use std::sync::Arc;

use bitcoin::{Script, Transaction, Txid};
use lightning::chain::chaininterface::BroadcasterInterface;
use lightning::chain::{Filter, WatchedOutput};
use lightning::log_warn;
use lightning::util::logger::Logger;
use lightning_transaction_sync::EsploraSyncClient;

use crate::logging::MutinyLogger;
use crate::onchain::OnChainWallet;
use crate::storage::MutinyStorage;
use crate::utils;

pub struct MutinyChain<S: MutinyStorage> {
    pub tx_sync: Arc<EsploraSyncClient<Arc<MutinyLogger>>>,
    pub wallet: Arc<OnChainWallet<S>>,
    logger: Arc<MutinyLogger>,
}

impl<S: MutinyStorage> MutinyChain<S> {
    pub(crate) fn new(
        tx_sync: Arc<EsploraSyncClient<Arc<MutinyLogger>>>,
        wallet: Arc<OnChainWallet<S>>,
        logger: Arc<MutinyLogger>,
    ) -> Self {
        Self {
            tx_sync,
            wallet,
            logger,
        }
    }
}

impl<S: MutinyStorage> Filter for MutinyChain<S> {
    fn register_tx(&self, txid: &Txid, script_pubkey: &Script) {
        self.tx_sync.register_tx(txid, script_pubkey);
    }

    fn register_output(&self, output: WatchedOutput) {
        self.tx_sync.register_output(output);
    }
}

impl<S: MutinyStorage> BroadcasterInterface for MutinyChain<S> {
    fn broadcast_transactions(&self, txs: &[&Transaction]) {
        let txs_clone = txs
            .iter()
            .map(|tx| (*tx).clone())
            .collect::<Vec<Transaction>>();
        let wallet = self.wallet.clone();
        let logger = self.logger.clone();
        utils::spawn(async move {
            for tx in txs_clone {
                if let Err(e) = wallet.broadcast_transaction(tx).await {
                    log_warn!(logger, "Error broadcasting transaction: {e}")
                }
            }
        });
    }
}


================================================
File: mutiny-core/src/encrypt.rs
================================================
use crate::error::MutinyError;
use aes::cipher::block_padding::Pkcs7;
use aes::cipher::{BlockDecryptMut, BlockEncryptMut, KeyIvInit};
use aes::Aes256;
use aes_gcm::Aes256Gcm;
use aes_gcm::{
    aead::{generic_array::GenericArray, Aead},
    KeyInit,
};
use argon2::Argon2;
use base64;
use bitcoin::secp256k1;
use bitcoin::secp256k1::SecretKey;
use cbc::{Decryptor, Encryptor};
use getrandom::getrandom;
use std::sync::Arc;

type Aes256CbcEnc = Encryptor<Aes256>;
type Aes256CbcDec = Decryptor<Aes256>;

#[derive(Clone)]
pub struct Cipher {
    key: Arc<Aes256Gcm>,
    salt: [u8; 16],
}

pub fn encryption_key_from_pass(password: &str) -> Result<Cipher, MutinyError> {
    let mut salt = [0u8; 16];
    getrandom(&mut salt).unwrap();

    let key = get_encryption_key(password, &salt)?;

    // convert key to proper format for aes_gcm
    let key = GenericArray::clone_from_slice(&key);
    Ok(Cipher {
        key: Arc::new(Aes256Gcm::new(&key)),
        salt,
    })
}

pub fn encrypt(content: &str, c: Cipher) -> Result<String, MutinyError> {
    // convert key and nonce to proper format for aes_gcm
    let mut nonce = [0u8; 12];
    getrandom(&mut nonce).unwrap();

    // convert nonce to proper format for aes_gcm
    let nonce = GenericArray::from_slice(&nonce);

    let encrypted_data = c.key.encrypt(nonce, content.as_bytes().to_vec().as_ref())?;

    let mut result: Vec<u8> = Vec::new();
    result.extend(&c.salt);
    result.extend(nonce);
    result.extend(encrypted_data);

    Ok(base64::encode(&result))
}

pub fn decrypt_with_password(encrypted: &str, password: &str) -> Result<String, MutinyError> {
    let encrypted = base64::decode(encrypted)?;
    if encrypted.len() < 12 + 16 {
        return Err(MutinyError::IncorrectPassword);
    }

    let (rest, encrypted_bytes) = encrypted.split_at(16 + 12);
    let (salt, nonce_bytes) = rest.split_at(16);

    let key = get_encryption_key(password, salt)?;

    // convert key and nonce to proper format for aes_gcm
    let key = GenericArray::clone_from_slice(&key);
    let nonce = GenericArray::from_slice(nonce_bytes);

    let cipher = Aes256Gcm::new(&key);

    let decrypted_data = cipher
        .decrypt(nonce, encrypted_bytes)
        .map_err(|_| MutinyError::IncorrectPassword)?;

    let decrypted_string =
        String::from_utf8(decrypted_data).map_err(|_| MutinyError::IncorrectPassword)?;

    Ok(decrypted_string)
}

pub fn get_encryption_key(password: &str, salt: &[u8]) -> Result<[u8; 32], MutinyError> {
    let mut key = [0u8; 32];
    argon2()
        .hash_password_into(password.as_bytes(), salt, &mut key)
        .map_err(|_| MutinyError::IncorrectPassword)?;
    Ok(key)
}

fn argon2() -> Argon2<'static> {
    let mut binding = argon2::ParamsBuilder::new();
    let params = binding.m_cost(7 * 1024).t_cost(1).p_cost(1);
    Argon2::from(params.build().expect("valid params"))
}

pub fn encrypt_with_key(encryption_key: &SecretKey, bytes: &[u8]) -> Vec<u8> {
    let iv: [u8; 16] = secp256k1::rand::random();

    let cipher = Aes256CbcEnc::new(&encryption_key.secret_bytes().into(), &iv.into());
    let mut encrypted: Vec<u8> = cipher.encrypt_padded_vec_mut::<Pkcs7>(bytes);
    encrypted.extend(iv);

    encrypted
}

pub fn decrypt_with_key(
    encryption_key: &SecretKey,
    bytes: Vec<u8>,
) -> Result<Vec<u8>, MutinyError> {
    if bytes.len() < 16 {
        return Err(MutinyError::IncorrectPassword);
    }
    // split last 16 bytes off as iv
    let iv = &bytes[bytes.len() - 16..];
    let bytes = &bytes[..bytes.len() - 16];

    let cipher = Aes256CbcDec::new(&encryption_key.secret_bytes().into(), iv.into());
    let decrypted: Vec<u8> = cipher.decrypt_padded_vec_mut::<Pkcs7>(bytes)?;

    Ok(decrypted)
}

#[cfg(test)]
mod tests {
    use crate::encrypt::{
        decrypt_with_key, decrypt_with_password, encrypt, encrypt_with_key,
        encryption_key_from_pass,
    };
    use bitcoin::secp256k1::SecretKey;

    #[test]
    fn test_encryption() {
        let password = "password";
        let content = "hello world";
        let cipher = encryption_key_from_pass(password).unwrap();

        let encrypted = encrypt(content, cipher).unwrap();
        println!("{encrypted}");

        let decrypted = decrypt_with_password(&encrypted, password).unwrap();
        println!("{decrypted}");
        assert_eq!(content, decrypted);
    }

    #[test]
    fn test_encryption_with_key() {
        let key = SecretKey::from_slice(&[1u8; 32]).unwrap();
        let content = [6u8; 32].to_vec();

        let encrypted = encrypt_with_key(&key, &content);

        let decrypted = decrypt_with_key(&key, encrypted).unwrap();
        assert_eq!(content, decrypted);
    }
}


================================================
File: mutiny-core/src/error.rs
================================================
use aes::cipher::block_padding::UnpadError;
use bdk_wallet::error::BuildFeeBumpError;
use bdk_wallet::signer::SignerError;
use bdk_wallet::tx_builder::AddUtxoError;
use bitcoin::psbt::ExtractTxError;
use hex_conservative::HexToArrayError;
use lightning::ln::channelmanager::RetryableSendFailure;
use lightning::ln::peer_handler::PeerHandleError;
use lightning_invoice::ParseOrSemanticError;
use lightning_rapid_gossip_sync::GraphSyncError;
use lightning_transaction_sync::TxSyncError;
use log::error;
use std::string::FromUtf8Error;
use thiserror::Error;

#[derive(Error, Debug)]
#[allow(dead_code)]
// copied from LDK lite
/// An error that possibly needs to be handled by the user.
pub enum MutinyError {
    /// Returned when trying to start Mutiny while it is already running.
    #[error("Mutiny is already running.")]
    AlreadyRunning,
    /// Returned when trying to stop Mutiny while it is not running.
    #[error("Mutiny is not running.")]
    NotRunning,
    /// Returned when Mutiny tries to startup with a different network than the one it was
    /// previously running on.
    #[error("Incorrect expected network.")]
    NetworkMismatch,
    /// Returned on any resource that is not found.
    #[error("Resource Not found.")]
    NotFound,
    /// The funding transaction could not be created.
    #[error("Funding transaction could not be created.")]
    FundingTxCreationFailed,
    /// A network connection has been closed.
    #[error("Network connection closed.")]
    ConnectionFailed,
    /// The invoice or address is on a different network
    #[error("The invoice or address is on a different network.")]
    IncorrectNetwork,
    /// Payment of the given invoice has already been initiated.
    #[error("An invoice must not get payed twice.")]
    NonUniquePaymentHash,
    /// Payment Timed out
    #[error("Payment timed out.")]
    PaymentTimeout,
    /// The given invoice is invalid.
    #[error("The given invoice is invalid.")]
    InvoiceInvalid,
    /// The given invoice is expired.
    #[error("The given invoice is expired.")]
    InvoiceExpired,
    /// Invoice creation failed.
    #[error("Failed to create invoice.")]
    InvoiceCreationFailed,
    /// We have enough balance to pay an invoice, but
    /// the this would take from our reserve amount which is not allowed.
    #[error("Channel reserve amount is too high.")]
    ReserveAmountError,
    /// We do not have enough balance to pay the given amount.
    #[error("We do not have enough balance to pay the given amount.")]
    InsufficientBalance,
    /// Could not make a request to the LSP.
    #[error("Failed to make a request to the LSP.")]
    LspGenericError,
    /// LSP indicated it could not fund the channel requested.
    #[error("Failed to request channel from LSP due to funding error.")]
    LspFundingError,
    /// LSP indicated the amount is too high to fund.
    #[error("Failed to request channel from LSP due to amount being too high.")]
    LspAmountTooHighError,
    /// LSP indicated it was not connected to the client node.
    #[error("Failed to have a connection to the LSP node.")]
    LspConnectionError,
    /// LSP required an invoice and none was provided.
    #[error("Failed to provide an invoice to the LSP.")]
    LspInvoiceRequired,
    /// Subscription Client Not Configured
    #[error("Subscription Client Not Configured")]
    SubscriptionClientNotConfigured,
    /// Invalid Arguments were given
    #[error("Invalid Arguments were given")]
    InvalidArgumentsError,
    /// No route for the given target could be found.
    #[error("Failed to find route.")]
    RoutingFailed,
    /// A given peer info could not be parsed.
    #[error("Failed to parse the given peer information.")]
    PeerInfoParseFailed,
    /// A channel could not be opened.
    #[error("Failed to create channel.")]
    ChannelCreationFailed,
    /// A channel could not be opened.
    #[error("Failed to create channel. {0}")]
    ChannelCreationFailedWithReason(String),
    /// A channel could not be closed.
    #[error("Failed to close channel.")]
    ChannelClosingFailed,
    /// Persistence failed.
    #[error("Failed to persist data.")]
    PersistenceFailed {
        #[from]
        source: MutinyStorageError,
    },
    #[error("Failed to read data from storage.")]
    ReadError { source: MutinyStorageError },
    #[error("Failed to decode lightning data.")]
    LnDecodeError,
    /// A failure to generate a mnemonic seed.
    #[error("Failed to generate seed")]
    SeedGenerationFailed,
    /// User provided invalid mnemonic.
    #[error("Invalid mnemonic")]
    InvalidMnemonic,
    /// Invalid BTC transaction or hex string.
    #[error("Invalid BTC transaction")]
    InvalidTransaction,
    /// A wallet operation failed.
    #[error("Failed to conduct wallet operation.")]
    WalletOperationFailed,
    /// A signing operation failed.
    #[error("Failed to sign given transaction.")]
    WalletSigningFailed,
    /// A chain access operation failed.
    #[error("Failed to conduct chain access operation.")]
    ChainAccessFailed,
    /// A failure to sync the on-chain wallet
    #[error("Failed to to sync on-chain wallet.")]
    WalletSyncError,
    /// An error with rapid gossip sync
    #[error("Failed to execute a rapid gossip sync function")]
    RapidGossipSyncError,
    /// A error with DLCs
    #[error("Failed to execute a dlc function")]
    DLCManagerError,
    /// Node pubkey given is invalid
    #[error("The given node pubkey is invalid.")]
    PubkeyInvalid,
    /// Error converting JS f64 value to Amount
    #[error("Satoshi amount is invalid")]
    BadAmountError,
    /// Error getting the bitcoin price
    #[error("Failed to get the bitcoin price.")]
    BitcoinPriceError,
    /// Error getting nostr data
    #[error("Failed to get nostr data.")]
    NostrError,
    /// Error with Nip07 Extension
    #[error("Error with NIP-07 extension")]
    Nip07Extension,
    /// Incorrect password entered.
    #[error("Incorrect password entered.")]
    IncorrectPassword,
    /// Cannot change password to the same password
    #[error("Cannot change password to the same password.")]
    SamePassword,
    /// Error calling Cashu Mint
    #[error("Error calling Cashu Mint.")]
    CashuMintError,
    /// Mint URL in token was empty
    #[error("Mint URL in token is empty.")]
    EmptyMintURLError,
    /// Token already spent.
    #[error("Token has been already spent.")]
    TokenAlreadySpent,
    #[error("Message Packet size exceeded")]
    PacketSizeExceeded,
    #[error("Invalid fee rate")]
    InvalidFeerate,
    #[error("Invalid psbt")]
    InvalidPsbt,
    #[error("Invalid hex")]
    InvalidHex,
    /// Failed to authenticate using JWT
    #[error("Failed to authenticate using JWT.")]
    JwtAuthFailure,
    #[error("Failed to parse VSS value from getObject response.")]
    FailedParsingVssValue,
    #[error(transparent)]
    Other(anyhow::Error),
}

#[derive(Error, Debug)]
pub enum MutinyStorageError {
    #[error("Failed to serialize or deserialize")]
    SerdeError {
        #[from]
        source: serde_json::Error,
    },
    #[error("Failed to get lock on memory storage")]
    LockError,
    #[error("Failed to use indexeddb storage")]
    IndexedDBError,
    #[error(transparent)]
    Other(#[from] anyhow::Error),
}

impl PartialEq for MutinyStorageError {
    fn eq(&self, other: &Self) -> bool {
        match (self, other) {
            (Self::SerdeError { .. }, Self::SerdeError { .. }) => true,
            (Self::LockError, Self::LockError) => true,
            (Self::IndexedDBError, Self::IndexedDBError) => true,
            (Self::Other(e), Self::Other(e2)) => e.to_string() == e2.to_string(),
            _ => false,
        }
    }
}

impl PartialEq for MutinyError {
    fn eq(&self, other: &Self) -> bool {
        match (self, other) {
            (Self::AlreadyRunning, Self::AlreadyRunning) => true,
            (Self::NotRunning, Self::NotRunning) => true,
            (Self::NetworkMismatch, Self::NetworkMismatch) => true,
            (Self::NotFound, Self::NotFound) => true,
            (Self::FundingTxCreationFailed, Self::FundingTxCreationFailed) => true,
            (Self::ConnectionFailed, Self::ConnectionFailed) => true,
            (Self::IncorrectNetwork, Self::IncorrectNetwork) => true,
            (Self::NonUniquePaymentHash, Self::NonUniquePaymentHash) => true,
            (Self::PaymentTimeout, Self::PaymentTimeout) => true,
            (Self::InvoiceInvalid, Self::InvoiceInvalid) => true,
            (Self::InvoiceExpired, Self::InvoiceExpired) => true,
            (Self::InvoiceCreationFailed, Self::InvoiceCreationFailed) => true,
            (Self::ReserveAmountError, Self::ReserveAmountError) => true,
            (Self::InsufficientBalance, Self::InsufficientBalance) => true,
            (Self::LspGenericError, Self::LspGenericError) => true,
            (Self::LspFundingError, Self::LspFundingError) => true,
            (Self::LspAmountTooHighError, Self::LspAmountTooHighError) => true,
            (Self::LspConnectionError, Self::LspConnectionError) => true,
            (Self::SubscriptionClientNotConfigured, Self::SubscriptionClientNotConfigured) => true,
            (Self::InvalidArgumentsError, Self::InvalidArgumentsError) => true,
            (Self::RoutingFailed, Self::RoutingFailed) => true,
            (Self::PeerInfoParseFailed, Self::PeerInfoParseFailed) => true,
            (Self::ChannelCreationFailed, Self::ChannelCreationFailed) => true,
            (
                Self::ChannelCreationFailedWithReason(x),
                Self::ChannelCreationFailedWithReason(y),
            ) => x == y,
            (Self::ChannelClosingFailed, Self::ChannelClosingFailed) => true,
            (Self::PersistenceFailed { source }, Self::PersistenceFailed { source: source2 }) => {
                source == source2
            }
            (Self::ReadError { source }, Self::ReadError { source: source2 }) => source == source2,
            (Self::LnDecodeError, Self::LnDecodeError) => true,
            (Self::SeedGenerationFailed, Self::SeedGenerationFailed) => true,
            (Self::InvalidMnemonic, Self::InvalidMnemonic) => true,
            (Self::WalletOperationFailed, Self::WalletOperationFailed) => true,
            (Self::WalletSigningFailed, Self::WalletSigningFailed) => true,
            (Self::ChainAccessFailed, Self::ChainAccessFailed) => true,
            (Self::WalletSyncError, Self::WalletSyncError) => true,
            (Self::RapidGossipSyncError, Self::RapidGossipSyncError) => true,
            (Self::PubkeyInvalid, Self::PubkeyInvalid) => true,
            (Self::BadAmountError, Self::BadAmountError) => true,
            (Self::BitcoinPriceError, Self::BitcoinPriceError) => true,
            (Self::DLCManagerError, Self::DLCManagerError) => true,
            (Self::NostrError, Self::NostrError) => true,
            (Self::IncorrectPassword, Self::IncorrectPassword) => true,
            (Self::SamePassword, Self::SamePassword) => true,
            (Self::CashuMintError, Self::CashuMintError) => true,
            (Self::EmptyMintURLError, Self::EmptyMintURLError) => true,
            (Self::TokenAlreadySpent, Self::TokenAlreadySpent) => true,
            (Self::Other(e), Self::Other(e2)) => e.to_string() == e2.to_string(),
            _ => false,
        }
    }
}

impl MutinyError {
    pub fn read_err(e: MutinyStorageError) -> Self {
        MutinyError::ReadError { source: e }
    }

    pub fn write_err(e: MutinyStorageError) -> Self {
        MutinyError::PersistenceFailed { source: e }
    }
}

impl From<ExtractTxError> for MutinyError {
    fn from(_e: ExtractTxError) -> Self {
        Self::InvalidPsbt
    }
}

impl From<UnpadError> for MutinyError {
    fn from(_e: UnpadError) -> Self {
        Self::IncorrectPassword
    }
}

impl From<base64::DecodeError> for MutinyError {
    fn from(_e: base64::DecodeError) -> Self {
        Self::IncorrectPassword
    }
}

impl From<FromUtf8Error> for MutinyError {
    fn from(_e: FromUtf8Error) -> Self {
        Self::IncorrectPassword
    }
}

impl From<aes_gcm::Error> for MutinyError {
    fn from(_: aes_gcm::Error) -> Self {
        Self::IncorrectPassword
    }
}

impl From<aes_gcm::aes::cipher::InvalidLength> for MutinyError {
    fn from(_: aes_gcm::aes::cipher::InvalidLength) -> Self {
        Self::IncorrectPassword
    }
}

impl From<bdk_chain::local_chain::AlterCheckPointError> for MutinyError {
    fn from(_e: bdk_chain::local_chain::AlterCheckPointError) -> Self {
        Self::WalletOperationFailed
    }
}

impl From<bdk_wallet::descriptor::error::Error> for MutinyError {
    fn from(_: bdk_wallet::descriptor::error::Error) -> Self {
        Self::WalletOperationFailed
    }
}

// impl From<bdk_wallet::NewError<MutinyError>> for MutinyError {
//     fn from(e: bdk_wallet::NewError<MutinyError>) -> Self {
//         match e {
//             bdk_wallet::NewError::Write(e) => e,
//             bdk_wallet::NewError::Descriptor(e) => e.into(),
//             bdk_wallet::NewError::NonEmptyDatabase => Self::WalletOperationFailed,
//         }
//     }
// }

impl From<bdk_wallet::LoadError> for MutinyError {
    fn from(e: bdk_wallet::LoadError) -> Self {
        match e {
            bdk_wallet::LoadError::Descriptor(e) => e.into(),
            bdk_wallet::LoadError::MissingGenesis => Self::WalletOperationFailed,
            bdk_wallet::LoadError::MissingNetwork => Self::WalletOperationFailed,
            bdk_wallet::LoadError::MissingDescriptor(_keychain_kind) => Self::WalletOperationFailed,
            bdk_wallet::LoadError::Mismatch(_load_mismatch) => Self::WalletSyncError,
        }
    }
}

impl From<AddUtxoError> for MutinyError {
    fn from(_: AddUtxoError) -> Self {
        Self::WalletOperationFailed
    }
}

impl From<bip39::Error> for MutinyError {
    fn from(_e: bip39::Error) -> Self {
        Self::InvalidMnemonic
    }
}

impl From<bitcoin::bip32::Error> for MutinyError {
    fn from(_e: bitcoin::bip32::Error) -> Self {
        Self::InvalidMnemonic
    }
}

impl From<bitcoin::address::ParseError> for MutinyError {
    fn from(_e: bitcoin::address::ParseError) -> Self {
        Self::PubkeyInvalid
    }
}

impl From<bitcoin::hex::HexToBytesError> for MutinyError {
    fn from(_e: bitcoin::hex::HexToBytesError) -> Self {
        Self::InvalidHex
    }
}

impl From<bitcoin::hex::HexToArrayError> for MutinyError {
    fn from(_e: bitcoin::hex::HexToArrayError) -> Self {
        Self::InvalidHex
    }
}

impl From<TxSyncError> for MutinyError {
    fn from(_e: TxSyncError) -> Self {
        MutinyError::ChainAccessFailed
    }
}

impl From<lightning::ln::msgs::DecodeError> for MutinyError {
    fn from(_e: lightning::ln::msgs::DecodeError) -> Self {
        MutinyError::LnDecodeError
    }
}

impl From<lightning::ln::script::InvalidShutdownScript> for MutinyError {
    fn from(_e: lightning::ln::script::InvalidShutdownScript) -> Self {
        MutinyError::InvalidArgumentsError
    }
}

impl From<ParseOrSemanticError> for MutinyError {
    fn from(_e: ParseOrSemanticError) -> Self {
        Self::InvoiceInvalid
    }
}

impl From<PeerHandleError> for MutinyError {
    fn from(_e: PeerHandleError) -> Self {
        // TODO handle the case where `no_connection_possible`
        Self::ConnectionFailed
    }
}

impl From<RetryableSendFailure> for MutinyError {
    fn from(s: RetryableSendFailure) -> Self {
        match s {
            RetryableSendFailure::PaymentExpired => Self::InvoiceExpired,
            RetryableSendFailure::RouteNotFound => Self::RoutingFailed,
            RetryableSendFailure::DuplicatePayment => Self::NonUniquePaymentHash,
            RetryableSendFailure::OnionPacketSizeExceeded => Self::PacketSizeExceeded,
        }
    }
}

impl From<GraphSyncError> for MutinyError {
    fn from(_e: GraphSyncError) -> Self {
        MutinyError::RapidGossipSyncError
    }
}

impl From<std::io::Error> for MutinyError {
    fn from(e: std::io::Error) -> Self {
        MutinyError::PersistenceFailed {
            source: MutinyStorageError::Other(e.into()),
        }
    }
}

impl From<serde_json::Error> for MutinyError {
    fn from(_: serde_json::Error) -> Self {
        Self::ReadError {
            source: MutinyStorageError::Other(anyhow::anyhow!("Failed to deserialize")),
        }
    }
}

impl<G> From<std::sync::PoisonError<G>> for MutinyStorageError {
    fn from(_e: std::sync::PoisonError<G>) -> Self {
        MutinyStorageError::LockError
    }
}

impl<G> From<std::sync::TryLockError<G>> for MutinyError {
    fn from(_e: std::sync::TryLockError<G>) -> Self {
        MutinyStorageError::LockError.into()
    }
}

impl<G> From<std::sync::TryLockError<G>> for MutinyStorageError {
    fn from(_e: std::sync::TryLockError<G>) -> Self {
        MutinyStorageError::LockError
    }
}

// impl From<bitcoin::hashes::hex::Error> for MutinyError {
//     fn from(_e: bitcoin::hashes::hex::Error) -> Self {
//         MutinyError::ReadError {
//             source: MutinyStorageError::Other(anyhow::anyhow!("Failed to decode hex")),
//         }
//     }
// }

impl From<HexToArrayError> for MutinyError {
    fn from(value: HexToArrayError) -> Self {
        MutinyError::ReadError {
            source: MutinyStorageError::Other(anyhow::anyhow!(value)),
        }
    }
}

// impl From<bitcoin::address::Error> for MutinyError {
//     fn from(e: bitcoin::address::Error) -> Self {
//         match e {
//             bitcoin::address::Error::NetworkValidation { .. } => MutinyError::IncorrectNetwork,
//             bitcoin::address::Error::UnrecognizedScript => MutinyError::InvalidArgumentsError,
//             bitcoin::address::Error::UnknownAddressType(_) => MutinyError::InvalidArgumentsError,
//             _ => MutinyError::ReadError {
//                 source: MutinyStorageError::Other(anyhow::anyhow!("Failed to decode address")),
//             },
//         }
//     }
// }

impl From<esplora_client::Error> for MutinyError {
    fn from(_e: esplora_client::Error) -> Self {
        // This is most likely a chain access failure
        Self::ChainAccessFailed
    }
}

impl From<Box<esplora_client::Error>> for MutinyError {
    fn from(_e: Box<esplora_client::Error>) -> Self {
        // This is most likely a chain access failure
        Self::ChainAccessFailed
    }
}

// impl From<bdk_wallet::InsertTxError> for MutinyError {
//     fn from(_e: bdk_wallet::InsertTxError) -> Self {
//         Self::WalletSyncError
//     }
// }

impl From<bdk_wallet::error::CreateTxError> for MutinyError {
    fn from(_e: bdk_wallet::error::CreateTxError) -> Self {
        Self::WalletOperationFailed
    }
}

impl From<BuildFeeBumpError> for MutinyError {
    fn from(e: BuildFeeBumpError) -> Self {
        match e {
            BuildFeeBumpError::UnknownUtxo(_) => Self::NotFound,
            BuildFeeBumpError::TransactionNotFound(_) => Self::NotFound,
            BuildFeeBumpError::TransactionConfirmed(_) => Self::NotFound,
            BuildFeeBumpError::IrreplaceableTransaction(_) => Self::InvalidArgumentsError,
            BuildFeeBumpError::FeeRateUnavailable => Self::WalletOperationFailed,
        }
    }
}

impl From<SignerError> for MutinyError {
    fn from(_: SignerError) -> Self {
        Self::WalletOperationFailed
    }
}

impl From<anyhow::Error> for MutinyError {
    fn from(e: anyhow::Error) -> Self {
        error!("Got unhandled error: {e}");
        // handle fedimint anyhow errors
        match e.to_string().as_str() {
            "Insufficient balance" => Self::InsufficientBalance,
            "MissingInvoiceAmount" => Self::BadAmountError,
            _str => Self::Other(e),
        }
    }
}


================================================
File: mutiny-core/src/event.rs
================================================
use crate::ldkstorage::{MutinyNodePersister, PhantomChannelManager};
use crate::logging::MutinyLogger;
use crate::lsp::{AnyLsp, Lsp};
use crate::messagehandler::{BumpChannelClosureTransaction, CommonLnEvent, CommonLnEventCallback};
use crate::node::BumpTxEventHandler;
use crate::nodemanager::ChannelClosure;
use crate::onchain::OnChainWallet;
use crate::storage::MutinyStorage;
use crate::utils::{self, sleep};
use crate::{fees::MutinyFeeEstimator, storage::read_payment_info, PrivacyLevel};
use crate::{keymanager::PhantomKeysManager, storage::persist_payment_info};
use anyhow::anyhow;
use bitcoin::absolute::LockTime;
use bitcoin::secp256k1::PublicKey;
use bitcoin::secp256k1::Secp256k1;
use core::fmt;
use lightning::events::{BumpTransactionEvent, ClosureReason, Event, PaymentPurpose, ReplayEvent};
use lightning::sign::SpendableOutputDescriptor;
use lightning::{
    log_debug, log_error, log_info, log_warn, util::errors::APIError, util::logger::Logger,
};
use lightning_invoice::Bolt11Invoice;
use serde::{Deserialize, Serialize};
use std::str::FromStr;
use std::sync::Arc;

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq, Eq, Hash)]
pub struct PaymentInfo {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub preimage: Option<[u8; 32]>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub secret: Option<[u8; 32]>,
    pub status: HTLCStatus,
    #[serde(skip_serializing_if = "MillisatAmount::is_none")]
    #[serde(default)]
    pub amt_msat: MillisatAmount,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub fee_paid_msat: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub bolt11: Option<Bolt11Invoice>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub payee_pubkey: Option<PublicKey>,
    #[serde(default)]
    pub privacy_level: PrivacyLevel,
    pub last_update: u64,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq, Eq, PartialOrd, Ord, Hash, Default)]
pub struct MillisatAmount(pub Option<u64>);

impl MillisatAmount {
    pub fn is_none(&self) -> bool {
        self.0.is_none()
    }
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub enum HTLCStatus {
    /// Our invoice has not been paid yet
    Pending,
    /// We are currently trying to pay an invoice
    InFlight,
    /// An invoice has been paid
    Succeeded,
    /// We failed to pay an invoice
    Failed,
}

impl fmt::Display for HTLCStatus {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            HTLCStatus::Pending => write!(f, "Pending"),
            HTLCStatus::InFlight => write!(f, "InFlight"),
            HTLCStatus::Succeeded => write!(f, "Succeeded"),
            HTLCStatus::Failed => write!(f, "Failed"),
        }
    }
}

impl FromStr for HTLCStatus {
    type Err = String;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s {
            "Pending" => Ok(HTLCStatus::Pending),
            "InFlight" => Ok(HTLCStatus::InFlight),
            "Succeeded" => Ok(HTLCStatus::Succeeded),
            "Failed" => Ok(HTLCStatus::Failed),
            _ => Err(format!("'{}' is not a valid HTLCStatus", s)),
        }
    }
}

#[derive(Clone)]
pub struct EventHandler<S: MutinyStorage> {
    channel_manager: Arc<PhantomChannelManager<S>>,
    fee_estimator: Arc<MutinyFeeEstimator<S>>,
    wallet: Arc<OnChainWallet<S>>,
    keys_manager: Arc<PhantomKeysManager<S>>,
    persister: Arc<MutinyNodePersister<S>>,
    bump_tx_event_handler: Arc<BumpTxEventHandler<S>>,
    lsp_client: Option<AnyLsp<S>>,
    logger: Arc<MutinyLogger>,
    do_not_bump_channel_closed_tx: bool,
    sweep_target_address: Option<bitcoin::Address>,
    ln_event_callback: Option<CommonLnEventCallback>,
}

impl<S: MutinyStorage> EventHandler<S> {
    #[allow(clippy::too_many_arguments)]
    pub(crate) fn new(
        channel_manager: Arc<PhantomChannelManager<S>>,
        fee_estimator: Arc<MutinyFeeEstimator<S>>,
        wallet: Arc<OnChainWallet<S>>,
        keys_manager: Arc<PhantomKeysManager<S>>,
        persister: Arc<MutinyNodePersister<S>>,
        bump_tx_event_handler: Arc<BumpTxEventHandler<S>>,
        lsp_client: Option<AnyLsp<S>>,
        logger: Arc<MutinyLogger>,
        do_not_bump_channel_closed_tx: bool,
        sweep_target_address: Option<bitcoin::Address>,
        ln_event_callback: Option<CommonLnEventCallback>,
    ) -> Self {
        Self {
            channel_manager,
            fee_estimator,
            wallet,
            keys_manager,
            lsp_client,
            persister,
            bump_tx_event_handler,
            logger,
            do_not_bump_channel_closed_tx,
            sweep_target_address,
            ln_event_callback,
        }
    }

    pub async fn handle_event(&self, event: Event) -> Result<(), ReplayEvent> {
        match event {
            Event::FundingGenerationReady {
                temporary_channel_id,
                counterparty_node_id,
                channel_value_satoshis,
                output_script,
                user_channel_id,
            } => {
                log_debug!(self.logger, "EVENT: FundingGenerationReady processing");

                // Get the open parameters for this channel
                let params_opt = match self.persister.get_channel_open_params(user_channel_id) {
                    Ok(params) => params,
                    Err(e) => {
                        log_error!(self.logger, "ERROR: Could not get channel open params: {e}");
                        return Ok(());
                    }
                };

                let psbt_result = match &params_opt {
                    None => {
                        log_warn!(
                            self.logger,
                            "WARNING: Could not find channel open params for channel {user_channel_id}"
                        );
                        self.wallet.create_signed_psbt_to_spk(
                            output_script,
                            channel_value_satoshis,
                            None,
                        )
                    }
                    Some(params) => {
                        log_debug!(self.logger, "Opening channel with params: {params:?}");
                        if let Some(utxos) = &params.utxos {
                            self.wallet.create_sweep_psbt_to_output(
                                utxos,
                                output_script,
                                channel_value_satoshis,
                                params.absolute_fee.expect("Absolute fee should be set"),
                            )
                        } else {
                            self.wallet.create_signed_psbt_to_spk(
                                output_script,
                                channel_value_satoshis,
                                Some(params.sats_per_vbyte),
                            )
                        }
                    }
                };

                let label = format!("LN Channel: {}", counterparty_node_id);
                let labels = params_opt
                    .as_ref()
                    .and_then(|p| p.labels.clone())
                    .unwrap_or_else(|| vec![label]);

                let psbt = match psbt_result {
                    Ok(psbt) => {
                        if let Err(e) = self.wallet.label_psbt(&psbt, labels) {
                            log_warn!(
                                self.logger,
                                "ERROR: Could not label PSBT, but continuing: {e}"
                            );
                        };
                        psbt
                    }
                    Err(e) => {
                        let error_msg = format!("ERROR: Could not create a signed transaction to open channel with: {e}");
                        if let Err(e) = self.channel_manager.force_close_without_broadcasting_txn(
                            &temporary_channel_id,
                            &counterparty_node_id,
                            error_msg,
                        ) {
                            log_error!(
                                self.logger,
                                "ERROR: Could not force close failed channel: {e:?}"
                            );
                        }
                        return Ok(());
                    }
                };

                let tx = match psbt.extract_tx() {
                    Ok(tx) => tx,
                    Err(err) => {
                        log_error!(self.logger, "ERROR: extract tx from pstb: {err:?}");
                        return Ok(());
                    }
                };

                if let Err(e) = self.channel_manager.funding_transaction_generated(
                    temporary_channel_id,
                    counterparty_node_id,
                    tx.clone(),
                ) {
                    log_error!(
                        self.logger,
                        "ERROR: Could not send funding transaction to channel manager: {e:?}"
                    );
                    return Ok(());
                }

                if let Some(mut params) = params_opt {
                    params.opening_tx = Some(tx);

                    let _ = self
                        .persister
                        .persist_channel_open_params(user_channel_id, params);
                }

                log_info!(self.logger, "EVENT: FundingGenerationReady success");
            }
            Event::PaymentClaimable {
                receiver_node_id,
                payment_hash,
                purpose,
                amount_msat,
                counterparty_skimmed_fee_msat,
                ..
            } => {
                log_debug!(self.logger, "EVENT: PaymentReceived received payment from payment hash {} of {amount_msat} millisatoshis to {receiver_node_id:?}", payment_hash);

                if let Some(payment_info) =
                    read_payment_info(&self.persister.storage, &payment_hash.0, true, &self.logger)
                {
                    if matches!(
                        payment_info.status,
                        HTLCStatus::Succeeded | HTLCStatus::Failed
                    ) {
                        self.channel_manager.fail_htlc_backwards(&payment_hash);
                        return Ok(());
                    }
                }

                let expected_skimmed_fee_msat = self
                    .lsp_client
                    .as_ref()
                    .map(|lsp_client| {
                        lsp_client.get_expected_skimmed_fee_msat(payment_hash, amount_msat)
                    })
                    .unwrap_or(0);

                if counterparty_skimmed_fee_msat > expected_skimmed_fee_msat {
                    log_error!(self.logger, "ERROR: Payment with hash {} skimmed a fee of {} millisatoshis when we expected a fee of {} millisatoshis", payment_hash, counterparty_skimmed_fee_msat, expected_skimmed_fee_msat);
                    self.channel_manager.fail_htlc_backwards(&payment_hash);
                    return Ok(());
                }

                if let Some(payment_preimage) = match purpose {
                    PaymentPurpose::Bolt11InvoicePayment {
                        payment_preimage, ..
                    } => payment_preimage,
                    PaymentPurpose::SpontaneousPayment(preimage) => Some(preimage),
                    PaymentPurpose::Bolt12OfferPayment { .. }
                    | PaymentPurpose::Bolt12RefundPayment { .. } => {
                        log_error!(self.logger, "Not support Bolt12");
                        self.channel_manager.fail_htlc_backwards(&payment_hash);
                        return Ok(());
                    }
                } {
                    self.channel_manager.claim_funds(payment_preimage);
                } else {
                    self.channel_manager.fail_htlc_backwards(&payment_hash);
                    log_error!(self.logger, "ERROR: No payment preimage found");
                };
            }
            Event::PaymentClaimed {
                receiver_node_id,
                payment_hash,
                purpose,
                amount_msat,
                htlcs,
                sender_intended_total_msat,
                onion_fields: _,
            } => {
                log_debug!(self.logger, "EVENT: PaymentClaimed claimed payment from payment hash {} of {} millisatoshis ({sender_intended_total_msat:?} intended)  from {} htlcs", payment_hash, amount_msat, htlcs.len());

                let (payment_preimage, payment_secret) = match purpose {
                    PaymentPurpose::Bolt11InvoicePayment {
                        payment_preimage,
                        payment_secret,
                        ..
                    } => (payment_preimage, Some(payment_secret)),
                    PaymentPurpose::SpontaneousPayment(preimage) => (Some(preimage), None),
                    PaymentPurpose::Bolt12OfferPayment { .. }
                    | PaymentPurpose::Bolt12RefundPayment { .. } => {
                        log_error!(self.logger, "Not support Bolt12");
                        return Ok(());
                    }
                };
                match read_payment_info(
                    &self.persister.storage,
                    &payment_hash.0,
                    true,
                    &self.logger,
                ) {
                    Some(mut saved_payment_info) => {
                        let payment_preimage = payment_preimage.map(|p| p.0);
                        let payment_secret = payment_secret.map(|p| p.0);
                        saved_payment_info.status = HTLCStatus::Succeeded;
                        saved_payment_info.preimage = payment_preimage;
                        saved_payment_info.secret = payment_secret;
                        saved_payment_info.amt_msat = MillisatAmount(Some(amount_msat));
                        saved_payment_info.last_update = crate::utils::now().as_secs();
                        match persist_payment_info(
                            &self.persister.storage,
                            &payment_hash.0,
                            &saved_payment_info,
                            true,
                        ) {
                            Ok(_) => (),
                            Err(e) => log_error!(
                                self.logger,
                                "ERROR: could not persist payment info: {e}"
                            ),
                        }
                    }
                    None => {
                        let payment_preimage = payment_preimage.map(|p| p.0);
                        let payment_secret = payment_secret.map(|p| p.0);
                        let last_update = crate::utils::now().as_secs();

                        let payment_info = PaymentInfo {
                            preimage: payment_preimage,
                            secret: payment_secret,
                            status: HTLCStatus::Succeeded,
                            amt_msat: MillisatAmount(Some(amount_msat)),
                            fee_paid_msat: None,
                            payee_pubkey: receiver_node_id,
                            bolt11: None,
                            last_update,
                            privacy_level: PrivacyLevel::NotAvailable,
                        };
                        match persist_payment_info(
                            &self.persister.storage,
                            &payment_hash.0,
                            &payment_info,
                            true,
                        ) {
                            Ok(_) => (),
                            Err(e) => log_error!(
                                self.logger,
                                "ERROR: could not persist payment info: {e}"
                            ),
                        }
                    }
                }

                if let Some(cb) = self.ln_event_callback.as_ref() {
                    let event = CommonLnEvent::PaymentClaimed {
                        receiver_node_id: receiver_node_id.map(|node_id| format!("{node_id}")),
                        amount_msat,
                        payment_hash: format!("{payment_hash:x}"),
                    };
                    cb.trigger(event);
                }
            }
            Event::PaymentSent {
                payment_preimage,
                payment_hash,
                fee_paid_msat,
                ..
            } => {
                log_debug!(self.logger, "EVENT: PaymentSent: {}", payment_hash);

                match read_payment_info(
                    &self.persister.storage,
                    &payment_hash.0,
                    false,
                    &self.logger,
                ) {
                    Some(mut saved_payment_info) => {
                        saved_payment_info.status = HTLCStatus::Succeeded;
                        saved_payment_info.preimage = Some(payment_preimage.0);
                        saved_payment_info.fee_paid_msat = fee_paid_msat;
                        saved_payment_info.last_update = crate::utils::now().as_secs();
                        match persist_payment_info(
                            &self.persister.storage,
                            &payment_hash.0,
                            &saved_payment_info,
                            false,
                        ) {
                            Ok(_) => (),
                            Err(e) => log_error!(
                                self.logger,
                                "ERROR: could not persist payment info: {e}"
                            ),
                        }
                    }
                    None => {
                        // we succeeded in a payment that we didn't have saved? ...
                        log_warn!(
                            self.logger,
                            "WARN: payment succeeded but we did not have it stored"
                        );
                    }
                }
                if let Some(cb) = self.ln_event_callback.as_ref() {
                    let event = CommonLnEvent::PaymentSent {
                        payment_hash: format!("{payment_hash:x}"),
                    };
                    cb.trigger(event);
                }
            }
            Event::OpenChannelRequest {
                temporary_channel_id,
                counterparty_node_id,
                channel_type,
                ..
            } => {
                let lsp_pubkey = match self.lsp_client {
                    Some(ref lsp) => Some(lsp.get_lsp_pubkey().await),
                    None => None,
                };
                log_debug!(
                    self.logger,
                    "EVENT: OpenChannelRequest counterparty: {counterparty_node_id} and LSP pubkey: {lsp_pubkey:?}"
                );

                let mut internal_channel_id_bytes = [0u8; 16];
                if getrandom::getrandom(&mut internal_channel_id_bytes).is_err() {
                    log_debug!(
                        self.logger,
                        "EVENT: OpenChannelRequest failed random number generation"
                    );
                };
                let internal_channel_id = u128::from_be_bytes(internal_channel_id_bytes);

                let log_result = |result: Result<(), APIError>| match result {
                    Ok(_) => log_debug!(self.logger, "EVENT: OpenChannelRequest accepted"),
                    Err(e) => log_debug!(self.logger, "EVENT: OpenChannelRequest error: {e:?}"),
                };

                let is_zero_conf_channel = channel_type.requires_zero_conf();
                log_debug!(
                    self.logger,
                    "EVENT: OpenChannelRequest zero-conf channel: {is_zero_conf_channel}"
                );

                if lsp_pubkey.as_ref() != Some(&counterparty_node_id) {
                    log_error!(
                        self.logger,
                        "EVENT: OpenChannelRequest error: The counterparty node id doesn't match the LSP pubkey"
                    );
                } else if is_zero_conf_channel {
                    // if the event request channel type is 0-conf, accept 0 conf channel
                    let result = self
                        .channel_manager
                        .accept_inbound_channel_from_trusted_peer_0conf(
                            &temporary_channel_id,
                            &counterparty_node_id,
                            internal_channel_id,
                        );
                    log_result(result);
                    log_debug!(
                        self.logger,
                        "Accept zero confirmation channel when matched LSP Pubkey"
                    );
                } else {
                    // if the event request channel type is not 0-conf, open normal channel
                    let result = self.channel_manager.accept_inbound_channel(
                        &temporary_channel_id,
                        &counterparty_node_id,
                        internal_channel_id,
                    );
                    log_result(result);
                }
            }
            Event::PaymentPathSuccessful { .. } => {
                log_debug!(self.logger, "EVENT: PaymentPathSuccessful, ignored");
            }
            Event::PaymentPathFailed { .. } => {
                log_debug!(self.logger, "EVENT: PaymentPathFailed, ignored");
            }
            Event::ProbeSuccessful { .. } => {
                log_debug!(self.logger, "EVENT: ProbeSuccessful, ignored");
            }
            Event::ProbeFailed { .. } => {
                log_debug!(self.logger, "EVENT: ProbeFailed, ignored");
            }
            Event::PaymentFailed {
                payment_hash,
                reason,
                ..
            } => {
                if let Some(payment_hash) = payment_hash {
                    log_error!(
                        self.logger,
                        "EVENT: PaymentFailed: {} for reason {reason:?}",
                        payment_hash
                    );

                    match read_payment_info(
                        &self.persister.storage,
                        &payment_hash.0,
                        false,
                        &self.logger,
                    ) {
                        Some(mut saved_payment_info) => {
                            saved_payment_info.status = HTLCStatus::Failed;
                            saved_payment_info.last_update = crate::utils::now().as_secs();
                            match persist_payment_info(
                                &self.persister.storage,
                                &payment_hash.0,
                                &saved_payment_info,
                                false,
                            ) {
                                Ok(_) => (),
                                Err(e) => log_error!(
                                    self.logger,
                                    "ERROR: could not persist payment info: {e}"
                                ),
                            }
                        }
                        None => {
                            // we failed in a payment that we didn't have saved? ...
                            log_warn!(
                                self.logger,
                                "WARN: payment failed but we did not have it stored"
                            );
                        }
                    }
                    if let Some(cb) = self.ln_event_callback.as_ref() {
                        let event = CommonLnEvent::PaymentFailed {
                            payment_hash: format!("{payment_hash:x}"),
                            reason: reason.map(|r| format!("{r:?}")),
                        };
                        cb.trigger(event);
                    }
                }
            }
            Event::PaymentForwarded { .. } => {
                log_info!(self.logger, "EVENT: PaymentForwarded somehow...");
            }
            Event::HTLCHandlingFailed { .. } => {
                log_debug!(self.logger, "EVENT: HTLCHandlingFailed, ignored");
            }
            Event::PendingHTLCsForwardable { time_forwardable } => {
                log_debug!(
                    self.logger,
                    "EVENT: PendingHTLCsForwardable: {time_forwardable:?}, processing..."
                );

                let forwarding_channel_manager = self.channel_manager.clone();
                let min = time_forwardable.as_millis() as i32;
                sleep(min).await;
                forwarding_channel_manager.process_pending_htlc_forwards();
            }
            Event::SpendableOutputs { outputs, .. } => {
                if let Err(e) = self.handle_spendable_outputs(&outputs).await {
                    log_error!(self.logger, "Failed to handle spendable outputs: {e}");
                    // if we have an error we should persist the outputs so we can try again later
                    if let Err(e) = self.persister.persist_failed_spendable_outputs(outputs) {
                        log_error!(
                            self.logger,
                            "Failed to persist failed spendable outputs: {e}"
                        );
                    }
                }
            }
            Event::ChannelClosed {
                channel_id,
                reason,
                user_channel_id,
                counterparty_node_id: node_id,
                channel_capacity_sats,
                channel_funding_txo,
                ..
            } => {
                // if we still have channel open params, then it was just a failed channel open
                // we should not persist this as a closed channel and pass back the failure reason
                if let Ok(Some(mut params)) =
                    self.persister.get_channel_open_params(user_channel_id)
                {
                    // Remove the LDK fluff from the error message
                    let reason_str = reason.to_string().replace(
                        "Channel closed because counterparty force-closed with message: ",
                        "",
                    );

                    params.failure_reason = Some(reason_str);
                    let _ = self
                        .persister
                        .persist_channel_open_params(user_channel_id, params);
                    return Ok(());
                };

                log_debug!(
                    self.logger,
                    "EVENT: Channel {} of size {} closed due to: {:?}",
                    channel_id,
                    channel_capacity_sats
                        .map(|s| s.to_string())
                        .unwrap_or_else(|| "unknown".to_string()),
                    reason
                );

                // We guess this is a force close if the reason isn't belongs to a cooperative reason
                let maybe_force_closed = !matches!(
                    reason,
                    ClosureReason::LegacyCooperativeClosure
                        | ClosureReason::LocallyInitiatedCooperativeClosure
                        | ClosureReason::CounterpartyCoopClosedUnfundedChannel
                        | ClosureReason::CounterpartyInitiatedCooperativeClosure
                );

                let event = CommonLnEvent::ChannelClosed {
                    channel_id: format!("{channel_id}"),
                    reason: format!("{reason}"),
                    channel_funding_txo: channel_funding_txo.map(|txo| format!("{txo}")),
                    counterparty_node_id: node_id.map(|node_id| format!("{node_id:x}")),
                    maybe_force_closed,
                };

                let closure = ChannelClosure::new(
                    user_channel_id,
                    channel_id,
                    channel_funding_txo,
                    node_id,
                    reason,
                );
                if let Err(e) = self
                    .persister
                    .persist_channel_closure(user_channel_id, closure)
                {
                    log_error!(self.logger, "Failed to persist channel closure: {e}");
                }

                if let Some(cb) = self.ln_event_callback.as_ref() {
                    cb.trigger(event);
                }
            }
            Event::DiscardFunding { .. } => {
                // A "real" node should probably "lock" the UTXOs spent in funding transactions until
                // the funding transaction either confirms, or this event is generated.
                log_debug!(self.logger, "EVENT: DiscardFunding, ignored");
            }
            Event::ChannelReady {
                channel_id,
                user_channel_id,
                counterparty_node_id,
                channel_type,
            } => {
                log_debug!(
                    self.logger,
                    "EVENT: ChannelReady channel_id: {}, user_channel_id: {}, counterparty_node_id: {}, channel_type: {}",
                    channel_id,
                    user_channel_id,
                    counterparty_node_id,
                    channel_type);
            }
            Event::ChannelPending {
                channel_id,
                user_channel_id,
                counterparty_node_id,
                funding_txo,
                ..
            } => {
                log_debug!(
                    self.logger,
                    "EVENT: ChannelPending channel_id: {}, user_channel_id: {}, counterparty_node_id: {}",
                    channel_id,
                    user_channel_id,
                    counterparty_node_id);

                if let Err(e) = self.persister.delete_channel_open_params(user_channel_id) {
                    log_warn!(
                        self.logger,
                        "ERROR: Could not delete channel open params, but continuing: {e}"
                    );
                }

                let all_channels = self.channel_manager.list_channels();
                let found_channel = all_channels.iter().find(|chan| {
                    chan.funding_txo.map(|a| a.into_bitcoin_outpoint()) == Some(funding_txo)
                });
                if let Some(channel) = found_channel {
                    let closure = ChannelClosure::new_placeholder(
                        user_channel_id,
                        channel_id,
                        funding_txo,
                        counterparty_node_id,
                        channel.force_close_spend_delay,
                    );
                    if let Err(e) = self
                        .persister
                        .persist_channel_closure(user_channel_id, closure)
                    {
                        log_error!(self.logger, "Failed to persist channel closure: {e}");
                    }
                } else {
                    log_warn!(
                        self.logger,
                        "WARNING: Could not find channel with funding txo {funding_txo:?} when calling list_channels in ChannelPending event"
                    );
                }
            }
            Event::HTLCIntercepted { .. } => {}
            Event::BumpTransaction(event) => match &event {
                BumpTransactionEvent::ChannelClose {
                    channel_id,
                    commitment_tx,
                    ..
                } => {
                    let txid = format!("{:x}", commitment_tx.compute_txid());
                    let hex_tx = bitcoin::consensus::encode::serialize_hex(commitment_tx);
                    let timestamp = utils::now().as_secs();
                    log_debug!(
                        self.logger,
                        "EVENT: BumpTransaction channel_id {} tx_id {} timestamp {}\nhex_tx {}",
                        channel_id,
                        txid,
                        timestamp,
                        hex_tx
                    );

                    // Leverages the `BumpTransactionEvent::ChannelClose` mechanism to automatically retry
                    // rebroadcasting the commitment transaction if the initial broadcast fails.
                    // This operation has almost no side effects, as broadcasting the same transaction multiple times
                    // does not alter its state or the blockchain, and nodes will simply ignore duplicate broadcasts.
                    log_debug!(
                        self.logger,
                        "Trying rebroadcast for commitment tx transaction: {event:?}"
                    );
                    if let Err(e) = self
                        .wallet
                        .broadcast_transaction(commitment_tx.clone())
                        .await
                    {
                        log_error!(self.logger, "Failed to rebroadcast commitment tx: {e}");
                    }

                    if self.do_not_bump_channel_closed_tx {
                        log_debug!(self.logger, "Skip channel close transaction");
                    } else {
                        log_debug!(self.logger, "Bump channel close transaction");
                        self.bump_tx_event_handler.handle_event(&event);
                    }
                    if let Some(cb) = self.ln_event_callback.as_ref() {
                        let closure_bumping_event = BumpChannelClosureTransaction {
                            channel_id: format!("{channel_id}"),
                            txid,
                            hex_tx,
                            timestamp,
                        };

                        if let Err(e) = self
                            .persister
                            .persist_channel_closure_bumping_event(&closure_bumping_event)
                        {
                            log_error!(
                                self.logger,
                                "Failed to persist channel closure bumping event: {e}"
                            );
                        }
                        cb.trigger(CommonLnEvent::BumpChannelCloseTransaction {
                            channel_id: closure_bumping_event.channel_id,
                            txid: closure_bumping_event.txid,
                            hex_tx: closure_bumping_event.hex_tx,
                            timestamp,
                        });
                    }
                }
                _ => {
                    log_debug!(self.logger, "EVENT: BumpTransaction: {event:?}");
                    self.bump_tx_event_handler.handle_event(&event);
                }
            },
            Event::ConnectionNeeded { node_id, addresses } => {
                // we don't support bolt 12 yet, and we won't have the connection info anyways
                log_debug!(
                    self.logger,
                    "EVENT: ConnectionNeeded: {node_id} @ {addresses:?}"
                );
            }
            Event::FundingTxBroadcastSafe {
                channel_id,
                counterparty_node_id,
                ..
            } => {
                log_debug!(
                    self.logger,
                    "EVENT: FundingTxBroadcastSafe: {counterparty_node_id:?}/{channel_id}"
                );
            }
            Event::InvoiceReceived { payment_id, .. } => {
                log_debug!(self.logger, "EVENT: InvoiceReceived: {payment_id}");
            }
            Event::OnionMessageIntercepted { peer_node_id, .. } => {
                log_debug!(
                    self.logger,
                    "EVENT: OnionMessageIntercepted: {peer_node_id}"
                );
            }
            Event::OnionMessagePeerConnected { peer_node_id } => {
                log_debug!(
                    self.logger,
                    "EVENT: OnionMessagePeerConnected: {peer_node_id}"
                );
            }
        }
        Ok(())
    }

    // Separate function to handle spendable outputs
    // This is so we can return a result and handle errors
    // without having to use a lot of nested if statements
    pub(crate) async fn handle_spendable_outputs(
        &self,
        outputs: &[SpendableOutputDescriptor],
    ) -> anyhow::Result<()> {
        // Filter out static outputs, we don't want to spend them
        // because they have gone to our BDK wallet.
        // This would only be a waste in fees.
        let output_descriptors = outputs
            .iter()
            .filter(|d| match d {
                SpendableOutputDescriptor::StaticOutput { .. } => false,
                SpendableOutputDescriptor::DelayedPaymentOutput(_) => true,
                SpendableOutputDescriptor::StaticPaymentOutput(_) => true,
            })
            .collect::<Vec<_>>();

        // If there are no spendable outputs, we don't need to do anything
        if output_descriptors.is_empty() {
            return Ok(());
        }

        log_debug!(
            self.logger,
            "EVENT: processing SpendableOutputs {}",
            output_descriptors.len()
        );

        let tx_feerate = self.fee_estimator.get_normal_fee_rate();

        // We set nLockTime to the current height to discourage fee sniping.
        // Occasionally randomly pick a nLockTime even further back, so
        // that transactions that are delayed after signing for whatever reason,
        // e.g. high-latency mix networks and some CoinJoin implementations, have
        // better privacy.
        // Logic copied from core: https://github.com/bitcoin/bitcoin/blob/1d4846a8443be901b8a5deb0e357481af22838d0/src/wallet/spend.cpp#L936
        let mut height = self.channel_manager.current_best_block().height;

        let mut rand = [0u8; 4];
        getrandom::getrandom(&mut rand).unwrap();
        // 10% of the time
        if (u32::from_be_bytes(rand) % 10) == 0 {
            // subtract random number between 0 and 100
            getrandom::getrandom(&mut rand).unwrap();
            height -= u32::from_be_bytes(rand) % 100;
        }

        let locktime = LockTime::from_height(height).ok();

        let spending_tx = self
            .keys_manager
            .spend_spendable_outputs(
                &output_descriptors,
                Vec::new(),
                tx_feerate,
                locktime,
                &Secp256k1::new(),
                self.sweep_target_address.clone(),
            )
            .map_err(|_| anyhow!("Failed to spend spendable outputs"))?;

        self.wallet.broadcast_transaction(spending_tx).await?;

        Ok(())
    }
}

#[cfg(test)]
mod test {
    use crate::event::{HTLCStatus, MillisatAmount, PaymentInfo};
    use crate::{utils, PrivacyLevel};
    use bitcoin::secp256k1::PublicKey;
    use lightning_invoice::Bolt11Invoice;
    use std::str::FromStr;

    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};
    wasm_bindgen_test_configure!(run_in_browser);

    #[test]
    fn test_payment_info_serialization_symmetry() {
        let preimage = [1; 32];
        let pubkey = PublicKey::from_str(
            "02465ed5be53d04fde66c9418ff14a5f2267723810176c9212b722e542dc1afb1b",
        )
        .unwrap();

        let payment_info = PaymentInfo {
            preimage: Some(preimage),
            status: HTLCStatus::Succeeded,
            privacy_level: PrivacyLevel::Anonymous,
            amt_msat: MillisatAmount(Some(420)),
            fee_paid_msat: None,
            bolt11: None,
            payee_pubkey: Some(pubkey),
            secret: None,
            last_update: utils::now().as_secs(),
        };

        let serialized = serde_json::to_string(&payment_info).unwrap();
        let deserialized: PaymentInfo = serde_json::from_str(&serialized).unwrap();
        assert_eq!(payment_info, deserialized);

        let serialized = serde_json::to_value(&payment_info).unwrap();
        let deserialized: PaymentInfo = serde_json::from_value(serialized).unwrap();
        assert_eq!(payment_info, deserialized);
    }

    #[test]
    fn test_payment_info_without_amount() {
        let pubkey = PublicKey::from_str(
            "02465ed5be53d04fde66c9418ff14a5f2267723810176c9212b722e542dc1afb1b",
        )
        .unwrap();

        let payment_info = PaymentInfo {
            preimage: None,
            status: HTLCStatus::Succeeded,
            privacy_level: PrivacyLevel::Anonymous,
            amt_msat: MillisatAmount(None),
            fee_paid_msat: None,
            bolt11: Some(Bolt11Invoice::from_str("lntb1pnmghqhdqqnp4qty5slw3t6d6gt43tndkq6p6ut9ewrqrfq2nj67wnmk6dqzefweqcpp5fk6cxcwnjdrzw5zm9mzjuhfrwnee3feewmtycj5nk7klngava7gqsp5qajl23w8dluhxn90duny44ar0syrxqa4w3ap8635aat78lvdvfds9qyysgqcqzptxqyz5vqrzjqg7s0fwc76ky6umpgeuh7p7qm4l4jljw0uxa3uu5vrupjzjlpeny0apyqqqqqqqqsgqqqqlgqqqqlgqqjqr5p4cd64qa80ksthgdff908gxmjwvrwwmhnxnxlsrc0c2weuzcw3kthknu6cgalqdk0cnqsugvmcz9dvgr5l9rtphgm37ycg362s9sspwvxmj0").unwrap()),
            payee_pubkey: Some(pubkey),
            secret: None,
            last_update: utils::now().as_secs(),
        };

        let serialized = serde_json::to_string(&payment_info).unwrap();
        let deserialized: PaymentInfo = serde_json::from_str(&serialized).unwrap();
        assert_eq!(payment_info, deserialized);

        let serialized = serde_json::to_value(&payment_info).unwrap();
        let deserialized: PaymentInfo = serde_json::from_value(serialized).unwrap();
        assert_eq!(payment_info, deserialized);
    }
}


================================================
File: mutiny-core/src/fees.rs
================================================
use crate::logging::MutinyLogger;
use crate::storage::MutinyStorage;
use crate::{error::MutinyError, utils};
use bitcoin::{FeeRate, Weight};
use esplora_client::AsyncClient;
use futures::lock::Mutex;
use lightning::chain::chaininterface::{
    ConfirmationTarget, FeeEstimator, FEERATE_FLOOR_SATS_PER_KW,
};
use lightning::log_trace;
use lightning::util::logger::Logger;
use serde::Deserialize;
use std::collections::HashMap;
use std::sync::Arc;

// Constants for overhead, input, and output sizes
pub(crate) const TX_OVERHEAD: usize = 10;
pub(crate) const TAPROOT_INPUT_NON_WITNESS_SIZE: usize = 41;
pub(crate) const TAPROOT_INPUT_WITNESS_SIZE: usize = 67;
pub(crate) const P2WSH_OUTPUT_SIZE: usize = 43;
#[allow(dead_code)]
pub(crate) const TAPROOT_OUTPUT_SIZE: usize = 43;

#[derive(Clone)]
pub struct MutinyFeeEstimator<S: MutinyStorage> {
    storage: S,
    esplora: Arc<AsyncClient>,
    logger: Arc<MutinyLogger>,
    last_fee_update_time_secs: Arc<Mutex<Option<u64>>>,
}

impl<S: MutinyStorage> MutinyFeeEstimator<S> {
    pub fn new(
        storage: S,
        esplora: Arc<AsyncClient>,
        logger: Arc<MutinyLogger>,
    ) -> MutinyFeeEstimator<S> {
        MutinyFeeEstimator {
            storage,
            esplora,
            logger,
            last_fee_update_time_secs: Arc::new(Mutex::new(None)),
        }
    }

    /// Calculate the estimated fee in satoshis for a transaction.
    /// It is assumed that the inputs will be Taproot key spends.
    pub fn calculate_expected_fee(
        &self,
        num_utxos: usize,
        output_size: usize,
        change_size: Option<usize>,
        sats_per_kw: Option<u32>,
    ) -> u64 {
        // if no fee rate is provided, use the normal confirmation target
        let sats_per_kw = sats_per_kw.unwrap_or_else(|| self.get_normal_fee_rate());
        let expected_weight = {
            // Calculate the non-witness and witness data sizes
            let non_witness_size = TX_OVERHEAD
                + (num_utxos * TAPROOT_INPUT_NON_WITNESS_SIZE)
                + output_size
                + change_size.unwrap_or(0);
            let witness_size = num_utxos * TAPROOT_INPUT_WITNESS_SIZE;

            // Calculate the transaction weight
            (non_witness_size * 4) + witness_size
        };

        FeeRate::from_sat_per_kwu(sats_per_kw.into())
            .fee_wu(Weight::from_wu(expected_weight as u64))
            .unwrap()
            .to_sat()
    }

    async fn get_last_sync_time(&self) -> Option<u64> {
        let lock = self.last_fee_update_time_secs.lock().await;
        *lock
    }
}

#[derive(Deserialize, Debug)]
#[serde(rename_all = "camelCase")]
struct MempoolFees {
    fastest_fee: f64,
    half_hour_fee: f64,
    hour_fee: f64,
    economy_fee: f64,
    minimum_fee: f64,
}

impl<S: MutinyStorage> MutinyFeeEstimator<S> {
    async fn get_mempool_recommended_fees(&self) -> anyhow::Result<HashMap<String, f64>> {
        let client = self.esplora.client();
        let request = client
            .get(format!("{}/v1/fees/recommended", self.esplora.url()))
            .build()?;

        let fees_response = utils::fetch_with_timeout(client, request)
            .await?
            .error_for_status()?;
        let fees = fees_response.json::<MempoolFees>().await?;

        // convert to hashmap of num blocks -> fee rate
        let mut fee_estimates = HashMap::new();
        fee_estimates.insert("1".to_string(), fees.fastest_fee);
        fee_estimates.insert("3".to_string(), fees.half_hour_fee);
        fee_estimates.insert("6".to_string(), fees.hour_fee);
        fee_estimates.insert("12".to_string(), fees.economy_fee);
        fee_estimates.insert("1008".to_string(), fees.minimum_fee);

        Ok(fee_estimates)
    }

    pub async fn update_fee_estimates_if_necessary(&self) -> Result<(), MutinyError> {
        let last_sync = self.get_last_sync_time().await;
        if last_sync.is_none() || utils::now().as_secs() > last_sync.unwrap() + 60 * 10 {
            self.update_fee_estimates().await?;
        }
        Ok(())
    }

    async fn update_fee_estimates(&self) -> Result<(), MutinyError> {
        // first try mempool.space's API
        let mempool_fees = self.get_mempool_recommended_fees().await;

        // if that fails, fall back to esplora's API
        let fee_estimates = match mempool_fees {
            Ok(mempool_fees) => {
                log_trace!(self.logger, "Retrieved fees from mempool");
                mempool_fees
            }
            Err(e) => {
                log_trace!(
                    self.logger,
                    "Failed to retrieve fees from mempool, falling back to esplora: {e}"
                );
                self.esplora
                    .get_fee_estimates()
                    .await
                    .map_err(|e| {
                        log_trace!(self.logger, "Failed to get esplora fee: {e}");
                        e
                    })?
                    .into_iter()
                    .map(|(k, v)| (k.to_string(), v))
                    .collect()
            }
        };

        self.storage.insert_fee_estimates(fee_estimates)?;
        let mut update_time_lock = self.last_fee_update_time_secs.lock().await;
        *update_time_lock = Some(utils::now().as_secs());

        Ok(())
    }

    pub fn get_low_fee_rate(&self) -> u32 {
        // MinAllowedNonAnchorChannelRemoteFee is a fee rate we expect to get slowly
        self.get_est_sat_per_1000_weight(ConfirmationTarget::MinAllowedNonAnchorChannelRemoteFee)
    }

    pub fn get_normal_fee_rate(&self) -> u32 {
        // NonAnchorChannelFee is a fee rate we expect to be confirmed in 6 blocks
        self.get_est_sat_per_1000_weight(ConfirmationTarget::NonAnchorChannelFee)
    }

    pub fn get_high_fee_rate(&self) -> u32 {
        // OnChainSweep is the highest fee rate we have, so use that
        self.get_est_sat_per_1000_weight(ConfirmationTarget::UrgentOnChainSweep)
    }
}

impl<S: MutinyStorage> FeeEstimator for MutinyFeeEstimator<S> {
    fn get_est_sat_per_1000_weight(&self, confirmation_target: ConfirmationTarget) -> u32 {
        let num_blocks = num_blocks_from_conf_target(confirmation_target);
        let fallback_fee = fallback_fee_from_conf_target(confirmation_target);

        let fee = match self.storage.get_fee_estimates() {
            Err(_) | Ok(None) => fallback_fee,
            Ok(Some(estimates)) => {
                let found = estimates.get(&num_blocks.to_string());
                match found {
                    Some(num) => {
                        log_trace!(self.logger, "Got fee rate from saved cache!");
                        let sats_vbyte = num.to_owned();
                        // convert to sats per kw
                        let fee_rate = sats_vbyte * 250.0;

                        // return the fee rate, but make sure it's not lower than the floor
                        (fee_rate as u32).max(FEERATE_FLOOR_SATS_PER_KW)
                    }
                    None => fallback_fee,
                }
            }
        };

        // any post processing we do after we get the fee rate from the cache
        match confirmation_target {
            ConfirmationTarget::MinAllowedNonAnchorChannelRemoteFee => fee - 250, // helps with rounding errors
            ConfirmationTarget::MinAllowedAnchorChannelRemoteFee => 250, // just pin to 1 sat/vbyte to prevent force closes
            _ => fee,
        }
    }
}

fn num_blocks_from_conf_target(confirmation_target: ConfirmationTarget) -> usize {
    match confirmation_target {
        ConfirmationTarget::AnchorChannelFee => 1008,
        ConfirmationTarget::MinAllowedAnchorChannelRemoteFee => 1008,
        ConfirmationTarget::MinAllowedNonAnchorChannelRemoteFee => 1008,
        ConfirmationTarget::ChannelCloseMinimum => 1008,
        ConfirmationTarget::NonAnchorChannelFee => 6,
        ConfirmationTarget::UrgentOnChainSweep => 1,
        ConfirmationTarget::MaximumFeeEstimate => 1,
        ConfirmationTarget::OutputSpendingFee => 6,
    }
}

fn fallback_fee_from_conf_target(confirmation_target: ConfirmationTarget) -> u32 {
    match confirmation_target {
        ConfirmationTarget::MinAllowedAnchorChannelRemoteFee => 250,
        ConfirmationTarget::MinAllowedNonAnchorChannelRemoteFee => 3 * 250,
        ConfirmationTarget::ChannelCloseMinimum => 10 * 250,
        ConfirmationTarget::AnchorChannelFee => 10 * 250,
        ConfirmationTarget::NonAnchorChannelFee => 20 * 250,
        ConfirmationTarget::UrgentOnChainSweep => 50 * 250,
        ConfirmationTarget::MaximumFeeEstimate => 50 * 250,
        ConfirmationTarget::OutputSpendingFee => 20 * 250,
    }
}

#[cfg(test)]
mod test {
    use super::*;
    #[cfg(not(target_arch = "wasm32"))]
    use crate::storage::{MemoryStorage, MutinyStorage};
    #[cfg(not(target_arch = "wasm32"))]
    use crate::test_utils::*;
    #[cfg(not(target_arch = "wasm32"))]
    use esplora_client::Builder;
    #[cfg(not(target_arch = "wasm32"))]
    use std::collections::HashMap;

    #[cfg(not(target_arch = "wasm32"))]
    async fn create_fee_estimator() -> MutinyFeeEstimator<MemoryStorage> {
        let storage = MemoryStorage::default();
        let esplora = Arc::new(
            Builder::new("https://mutinynet.com/api")
                .build_async()
                .unwrap(),
        );
        let logger = Arc::new(MutinyLogger::default());

        MutinyFeeEstimator::new(storage, esplora, logger)
    }

    #[test]
    fn test_num_blocks_from_conf_target() {
        assert_eq!(
            num_blocks_from_conf_target(ConfirmationTarget::ChannelCloseMinimum),
            1008
        );
        assert_eq!(
            num_blocks_from_conf_target(ConfirmationTarget::NonAnchorChannelFee),
            6
        );
        assert_eq!(
            num_blocks_from_conf_target(ConfirmationTarget::UrgentOnChainSweep),
            1
        );
    }

    #[test]
    fn test_fallback_fee_from_conf_target() {
        assert_eq!(
            fallback_fee_from_conf_target(ConfirmationTarget::ChannelCloseMinimum),
            2_500
        );
        assert_eq!(
            fallback_fee_from_conf_target(ConfirmationTarget::NonAnchorChannelFee),
            5_000
        );
        assert_eq!(
            fallback_fee_from_conf_target(ConfirmationTarget::UrgentOnChainSweep),
            12_500
        );
    }

    #[cfg(not(target_arch = "wasm32"))]
    #[tokio::test]
    async fn test_get_est_sat_per_1000_weight() {
        let test_name = "test_get_est_sat_per_1000_weight";
        log!("{}", test_name);

        let fee_estimator = create_fee_estimator().await;
        // set up the cache
        let mut fee_estimates = HashMap::new();
        fee_estimates.insert("6".to_string(), 10_f64);
        fee_estimator
            .storage
            .insert_fee_estimates(fee_estimates)
            .unwrap();

        // test that we get the fee rate from the cache
        assert_eq!(
            fee_estimator.get_est_sat_per_1000_weight(ConfirmationTarget::NonAnchorChannelFee),
            2500
        );

        // test that we get the fallback fee rate
        assert_eq!(
            fee_estimator.get_est_sat_per_1000_weight(ConfirmationTarget::ChannelCloseMinimum),
            2_500
        );
        assert_eq!(
            fee_estimator.get_est_sat_per_1000_weight(ConfirmationTarget::UrgentOnChainSweep),
            12_500
        );

        // test post-processing
        assert_eq!(
            fee_estimator
                .get_est_sat_per_1000_weight(ConfirmationTarget::MinAllowedAnchorChannelRemoteFee),
            250
        );
        assert!(
            fee_estimator.get_est_sat_per_1000_weight(ConfirmationTarget::AnchorChannelFee) >= 250
        );
    }

    #[cfg(not(target_arch = "wasm32"))]
    #[tokio::test]
    async fn test_estimate_expected_fee() {
        let test_name = "test_estimate_expected_fee";
        log!("{}", test_name);

        let fee_estimator = create_fee_estimator().await;

        assert_eq!(
            fee_estimator.calculate_expected_fee(
                1,
                TAPROOT_OUTPUT_SIZE,
                Some(TAPROOT_OUTPUT_SIZE),
                Some(1_000)
            ),
            615
        );

        // set up the cache
        let mut fee_estimates = HashMap::new();
        fee_estimates.insert("3".to_string(), 20_f64);
        fee_estimates.insert("6".to_string(), 8_f64);
        fee_estimates.insert("1008".to_string(), 1_f64);
        fee_estimator
            .storage
            .insert_fee_estimates(fee_estimates)
            .unwrap();

        assert_eq!(
            fee_estimator.calculate_expected_fee(1, P2WSH_OUTPUT_SIZE, None, None),
            886
        );

        assert_eq!(
            fee_estimator.calculate_expected_fee(1, P2WSH_OUTPUT_SIZE, None, Some(4000)),
            1772
        );

        assert_eq!(
            fee_estimator.calculate_expected_fee(3, P2WSH_OUTPUT_SIZE, None, None),
            1810
        );

        assert_eq!(
            fee_estimator.calculate_expected_fee(
                3,
                P2WSH_OUTPUT_SIZE,
                Some(TAPROOT_OUTPUT_SIZE),
                None
            ),
            2154
        );
    }
}


================================================
File: mutiny-core/src/gossip.rs
================================================
use crate::{
    node::decay_params,
    scorer::{HubPreferentialScorer, ProbScorer},
};
use bitcoin::hashes::hex::FromHex;
use bitcoin::Network;
use hex_conservative::DisplayHex;
use lightning::ln::msgs::NodeAnnouncement;
use lightning::routing::gossip::NodeId;
use lightning::util::logger::Logger;
use lightning::util::ser::ReadableArgs;
use lightning::{log_debug, log_error, log_info, log_trace, log_warn};
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::str::FromStr;
use std::sync::Arc;
#[cfg(not(target_arch = "wasm32"))]
use std::time::Instant;
#[cfg(target_arch = "wasm32")]
use web_time::Instant;

use crate::error::MutinyError;
use crate::logging::MutinyLogger;
use crate::node::{NetworkGraph, RapidGossipSync};
use crate::storage::MutinyStorage;
use crate::utils;

pub(crate) const LN_PEER_METADATA_KEY_PREFIX: &str = "ln_peer/";
pub const GOSSIP_SYNC_TIME_KEY: &str = "last_sync_timestamp";
pub const NETWORK_GRAPH_KEY: &str = "network_graph";
pub const PROB_SCORER_KEY: &str = "prob_scorer";

struct Gossip {
    pub last_sync_timestamp: u32,
    pub network_graph: Arc<NetworkGraph>,
    pub scorer: Option<HubPreferentialScorer>,
}

impl Gossip {
    pub fn new(network: Network, logger: Arc<MutinyLogger>) -> Self {
        Self {
            last_sync_timestamp: 0,
            network_graph: Arc::new(NetworkGraph::new(network, logger)),
            scorer: None,
        }
    }
}

#[allow(dead_code)]
async fn get_scorer(
    storage: &impl MutinyStorage,
    network_graph: Arc<NetworkGraph>,
    logger: Arc<MutinyLogger>,
) -> Result<Option<HubPreferentialScorer>, MutinyError> {
    if let Some(prob_scorer_str) = storage.get_data::<String>(PROB_SCORER_KEY)? {
        let prob_scorer_bytes: Vec<u8> = Vec::from_hex(&prob_scorer_str)?;
        let mut readable_bytes = lightning::io::Cursor::new(prob_scorer_bytes);
        let params = decay_params();
        let args = (params, Arc::clone(&network_graph), Arc::clone(&logger));
        let scorer = ProbScorer::read(&mut readable_bytes, args)?;
        Ok(Some(HubPreferentialScorer::new(scorer)))
    } else {
        Ok(None)
    }
}

#[allow(dead_code)]
async fn get_gossip_data(
    storage: &impl MutinyStorage,
    logger: Arc<MutinyLogger>,
) -> Result<Option<Gossip>, MutinyError> {
    // Get the `last_sync_timestamp`
    let last_sync_timestamp: u32 = match storage.get_data(GOSSIP_SYNC_TIME_KEY)? {
        Some(last_sync_timestamp) => last_sync_timestamp,
        None => return Ok(None),
    };

    // Get the `network_graph`
    let network_graph: Arc<NetworkGraph> = match storage.get_data::<String>(NETWORK_GRAPH_KEY)? {
        Some(network_graph_str) => {
            let network_graph_bytes: Vec<u8> = Vec::from_hex(&network_graph_str)?;
            let mut readable_bytes = lightning::io::Cursor::new(network_graph_bytes);
            Arc::new(NetworkGraph::read(&mut readable_bytes, logger.clone())?)
        }
        None => return Ok(None),
    };

    log_debug!(logger, "Got network graph, getting scorer...");

    let scorer = get_scorer(storage, network_graph.clone(), logger.clone()).await?;

    if scorer.is_none() {
        log_warn!(logger, "Could not read probabilistic scorer from database");
    }

    let gossip = Gossip {
        last_sync_timestamp,
        network_graph,
        scorer,
    };

    Ok(Some(gossip))
}

/// Scorer is the scorer that gets pulled remotely
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Scorer {
    pub value: String,
}

// async fn get_remote_scorer_bytes(
//     auth_client: &MutinyAuthClient,
//     base_url: &str,
// ) -> Result<Vec<u8>, MutinyError> {
//     let url = Url::parse(&format!("{}/v1/scorer", base_url))
//         .map_err(|_| MutinyError::ConnectionFailed)?;

//     let response = auth_client
//         .request(Method::GET, url, None)
//         .await
//         .map_err(|_| MutinyError::ConnectionFailed)?;

//     let scorer: Scorer = response
//         .json()
//         .await
//         .map_err(|_| MutinyError::ConnectionFailed)?;

//     let decoded = base64::decode(scorer.value).map_err(|_| MutinyError::ConnectionFailed)?;
//     Ok(decoded)
// }

// /// Gets the remote scorer from the server, parses it and returns it as a [`HubPreferentialScorer`]
// pub async fn get_remote_scorer(
//     auth_client: &MutinyAuthClient,
//     base_url: &str,
//     network_graph: Arc<NetworkGraph>,
//     logger: Arc<MutinyLogger>,
// ) -> Result<HubPreferentialScorer, MutinyError> {
//     let start = Instant::now();
//     let scorer_bytes = get_remote_scorer_bytes(auth_client, base_url).await?;
//     let mut readable_bytes = lightning::io::Cursor::new(scorer_bytes);
//     let params = decay_params();
//     let args = (params, network_graph, logger.clone());
//     let scorer = ProbScorer::read(&mut readable_bytes, args)?;

//     log_trace!(
//         logger,
//         "Retrieved remote scorer in {}ms",
//         start.elapsed().as_millis()
//     );

//     Ok(HubPreferentialScorer::new(scorer))
// }

fn write_gossip_data(
    storage: &impl MutinyStorage,
    last_sync_timestamp: u32,
    _network_graph: &NetworkGraph,
) -> Result<(), MutinyError> {
    // Save the last sync timestamp
    storage.write_data(GOSSIP_SYNC_TIME_KEY.to_string(), last_sync_timestamp, None)?;

    // Save the network graph
    // skip for now, we don't read it currently
    // storage.set_data(NETWORK_GRAPH_KEY, network_graph.encode().to_hex(), None)?;

    Ok(())
}

pub async fn get_gossip_sync(
    storage: &impl MutinyStorage,
    network: Network,
    logger: Arc<MutinyLogger>,
) -> Result<(RapidGossipSync, HubPreferentialScorer), MutinyError> {
    // Always get default gossip until fixed:
    // https://github.com/lightningdevkit/rapid-gossip-sync-server/issues/45
    let mut gossip_data = Gossip::new(network, logger.clone());

    log_debug!(
        &logger,
        "Previous gossip sync timestamp: {}",
        gossip_data.last_sync_timestamp
    );

    let start = Instant::now();

    // get network graph
    let gossip_sync = RapidGossipSync::new(gossip_data.network_graph.clone(), logger.clone());

    let scorer_hex: Option<String> = storage.get_data(PROB_SCORER_KEY)?;

    if let Some(hex) = scorer_hex {
        let scorer_bytes: Vec<u8> = Vec::from_hex(&hex)?;
        let mut readable_bytes = lightning::io::Cursor::new(scorer_bytes);
        let params = decay_params();
        let args = (
            params,
            Arc::clone(&gossip_data.network_graph),
            Arc::clone(&logger),
        );
        if let Ok(scorer) = ProbScorer::read(&mut readable_bytes, args) {
            log_debug!(logger, "retrieved local scorer");
            let scorer = HubPreferentialScorer::new(scorer);
            gossip_data.scorer = Some(scorer);
        } else {
            log_error!(logger, "failed to parse local scorer");
        }
    }

    let prob_scorer = match gossip_data.scorer {
        Some(scorer) => scorer,
        None => {
            let params = decay_params();
            let scorer = ProbScorer::new(params, gossip_data.network_graph.clone(), logger.clone());
            HubPreferentialScorer::new(scorer)
        }
    };

    log_trace!(
        &logger,
        "Gossip sync/Scorer initialized in {}ms",
        start.elapsed().as_millis()
    );
    Ok((gossip_sync, prob_scorer))
}

pub(crate) async fn fetch_updated_gossip(
    rgs_url: String,
    now: u64,
    last_sync_timestamp: u32,
    gossip_sync: &RapidGossipSync,
    storage: &impl MutinyStorage,
    logger: &MutinyLogger,
) -> Result<(), MutinyError> {
    let http_client = Client::builder()
        .build()
        .map_err(|_| MutinyError::RapidGossipSyncError)?;

    let request = http_client
        .get(&rgs_url)
        .build()
        .map_err(|_| MutinyError::RapidGossipSyncError)?;

    let rgs_response = utils::fetch_with_timeout(&http_client, request).await?;
    let rgs_data = rgs_response
        .bytes()
        .await
        .map_err(|_| MutinyError::RapidGossipSyncError)?
        .to_vec();

    let new_last_sync_timestamp_result =
        gossip_sync.update_network_graph_no_std(&rgs_data, Some(now))?;

    log_info!(
        logger,
        "RGS sync result: {}",
        new_last_sync_timestamp_result
    );

    // save the network graph if has been updated
    if new_last_sync_timestamp_result != last_sync_timestamp {
        write_gossip_data(
            storage,
            new_last_sync_timestamp_result,
            gossip_sync.network_graph(),
        )?;
    }

    Ok(())
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Default)]
pub struct LnPeerMetadata {
    /// The node's network address to connect to
    pub connection_string: Option<String>,
    /// The node's alias given from the node announcement
    pub alias: Option<String>,
    /// The node's color given from the node announcement
    pub color: Option<String>,
    /// The label set by the user for this node
    pub label: Option<String>,
    /// The timestamp of when this information was last updated
    pub timestamp: Option<u32>,
    /// Our nodes' uuids that are connected to this node
    #[serde(default)]
    pub nodes: Vec<String>,
}

impl LnPeerMetadata {
    pub(crate) fn with_connection_string(self, connection_string: String) -> Self {
        Self {
            connection_string: Some(connection_string),
            ..self
        }
    }

    pub(crate) fn with_node(&self, node: String) -> Self {
        let mut nodes = self.nodes.clone();

        if !nodes.contains(&node) {
            nodes.push(node);
            nodes.sort();
        }

        Self {
            nodes,
            ..self.clone()
        }
    }

    pub(crate) fn with_label(&self, label: Option<String>) -> Self {
        Self {
            label,
            ..self.clone()
        }
    }

    pub(crate) fn merge_opt(&self, other: Option<&LnPeerMetadata>) -> LnPeerMetadata {
        match other {
            Some(other) => self.merge(other),
            None => self.clone(),
        }
    }

    pub(crate) fn merge(&self, other: &LnPeerMetadata) -> LnPeerMetadata {
        let (primary, secondary) = if self.timestamp > other.timestamp {
            (self.clone(), other.clone())
        } else {
            (other.clone(), self.clone())
        };

        // combine nodes from both
        let mut nodes: Vec<String> = primary.nodes.into_iter().chain(secondary.nodes).collect();

        // remove duplicates
        nodes.sort();
        nodes.dedup();

        Self {
            connection_string: primary.connection_string.or(secondary.connection_string),
            alias: primary.alias.or(secondary.alias),
            color: primary.color.or(secondary.color),
            label: primary.label.or(secondary.label),
            timestamp: primary.timestamp.or(secondary.timestamp),
            nodes,
        }
    }
}

impl From<NodeAnnouncement> for LnPeerMetadata {
    fn from(value: NodeAnnouncement) -> Self {
        Self {
            connection_string: None, // todo get from addresses
            alias: Some(value.contents.alias.to_string()),
            color: Some(value.contents.rgb.to_lower_hex_string()),
            label: None,
            timestamp: Some(value.contents.timestamp),
            nodes: vec![],
        }
    }
}

pub(crate) fn read_peer_info(
    storage: &impl MutinyStorage,
    node_id: &NodeId,
) -> Result<Option<LnPeerMetadata>, MutinyError> {
    let key = format!("{LN_PEER_METADATA_KEY_PREFIX}{node_id}");
    storage.get_data(key)
}

pub(crate) fn get_all_peers(
    storage: &impl MutinyStorage,
) -> Result<HashMap<NodeId, LnPeerMetadata>, MutinyError> {
    let mut peers = HashMap::new();

    let all: HashMap<String, LnPeerMetadata> = storage.scan(LN_PEER_METADATA_KEY_PREFIX, None)?;
    for (key, value) in all {
        // remove the prefix from the key
        let key = key.replace(LN_PEER_METADATA_KEY_PREFIX, "");
        if let Ok(node_id) = NodeId::from_str(&key) {
            peers.insert(node_id, value);
        }
    }
    Ok(peers)
}

pub(crate) fn save_peer_connection_info(
    storage: &impl MutinyStorage,
    our_node_id: &str,
    node_id: &NodeId,
    connection_string: &str,
    label: Option<String>,
) -> Result<(), MutinyError> {
    let key = format!("{LN_PEER_METADATA_KEY_PREFIX}{node_id}");

    let current: Option<LnPeerMetadata> = storage.get_data(&key)?;

    // If there is already some metadata, we add the connection string to it
    // Otherwise we create a new metadata with the connection string
    let new_info = match current {
        Some(current) => current
            .with_connection_string(connection_string.to_string())
            .with_node(our_node_id.to_string()),
        None => LnPeerMetadata {
            connection_string: Some(connection_string.to_string()),
            label,
            timestamp: Some(utils::now().as_secs() as u32),
            nodes: vec![our_node_id.to_string()],
            ..Default::default()
        },
    };

    storage.write_data(key, new_info, None)?;
    Ok(())
}

pub(crate) fn set_peer_label(
    storage: &impl MutinyStorage,
    node_id: &NodeId,
    label: Option<String>,
) -> Result<(), MutinyError> {
    // We filter out empty labels
    let label = label.filter(|l| !l.is_empty());
    let key = format!("{LN_PEER_METADATA_KEY_PREFIX}{node_id}");

    let current: Option<LnPeerMetadata> = storage.get_data(&key)?;

    // If there is already some metadata, we add the label to it
    // Otherwise we create a new metadata with the label
    let new_info = match current {
        Some(current) => current.with_label(label),
        None => LnPeerMetadata {
            label,
            timestamp: Some(utils::now().as_secs() as u32),
            ..Default::default()
        },
    };

    storage.write_data(key, new_info, None)?;
    Ok(())
}

pub(crate) fn delete_peer_info(
    storage: &impl MutinyStorage,
    uuid: &str,
    node_id: &NodeId,
) -> Result<(), MutinyError> {
    let key = format!("{LN_PEER_METADATA_KEY_PREFIX}{node_id}");

    let current: Option<LnPeerMetadata> = storage.get_data(&key)?;

    if let Some(mut current) = current {
        current.nodes.retain(|n| n != uuid);
        if current.nodes.is_empty() {
            storage.delete(&[key])?;
        } else {
            storage.write_data(key, current, None)?;
        }
    }

    Ok(())
}

pub(crate) fn save_ln_peer_info(
    storage: &impl MutinyStorage,
    node_id: &NodeId,
    info: &LnPeerMetadata,
) -> Result<(), MutinyError> {
    let key = format!("{LN_PEER_METADATA_KEY_PREFIX}{node_id}");

    let current: Option<LnPeerMetadata> = storage.get_data(&key)?;

    let new_info = info.merge_opt(current.as_ref());

    // if the new info is different than the current info, we should to save it
    if !current.is_some_and(|c| c == new_info) {
        storage.write_data(key, new_info, None)?;
    }

    Ok(())
}

pub(crate) fn get_rgs_url(
    network: Network,
    user_provided_url: Option<&str>,
    last_sync_time: Option<u32>,
) -> Option<String> {
    let last_sync_time = last_sync_time.unwrap_or(0);
    if let Some(url) = user_provided_url.filter(|url| !url.is_empty()) {
        let url = url.strip_suffix('/').unwrap_or(url);
        Some(format!("{url}/{last_sync_time}"))
    } else {
        match network {
            Network::Bitcoin => Some(format!(
                "https://rapidsync.lightningdevkit.org/snapshot/{last_sync_time}"
            )),
            Network::Testnet => Some(format!(
                "https://rapidsync.lightningdevkit.org/testnet/snapshot/{last_sync_time}"
            )),
            Network::Signet => Some(format!(
                "https://rgs.mutinynet.com/snapshot/{last_sync_time}"
            )),
            Network::Regtest => None,
            net => unreachable!("Unknown network {net}!"),
        }
    }
}

#[cfg(test)]
mod test {
    use crate::storage::MemoryStorage;
    use bitcoin::secp256k1::{Secp256k1, SecretKey};
    use uuid::Uuid;
    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};

    use super::*;

    wasm_bindgen_test_configure!(run_in_browser);

    fn dummy_node_id() -> NodeId {
        let secp = Secp256k1::new();
        let mut entropy = [0u8; 32];
        getrandom::getrandom(&mut entropy).unwrap();
        let secret_key = SecretKey::from_slice(&entropy).unwrap();
        let pubkey = secret_key.public_key(&secp);
        NodeId::from_pubkey(&pubkey)
    }

    fn dummy_peer_info() -> (NodeId, LnPeerMetadata) {
        let node_id = dummy_node_id();
        let uuid = Uuid::new_v4().to_string();
        let data = LnPeerMetadata {
            connection_string: Some("example.com:9735".to_string()),
            alias: Some("test alias".to_string()),
            color: Some("123456".to_string()),
            label: Some("test label".to_string()),
            timestamp: Some(utils::now().as_secs() as u32),
            nodes: vec![uuid],
        };

        (node_id, data)
    }

    #[test]
    fn test_merge_peer_info() {
        let no_timestamp = LnPeerMetadata {
            alias: Some("none".to_string()),
            timestamp: None,
            ..Default::default()
        };
        let max_timestamp = LnPeerMetadata {
            alias: Some("max".to_string()),
            timestamp: Some(u32::MAX),
            ..Default::default()
        };
        let min_timestamp = LnPeerMetadata {
            alias: Some("min".to_string()),
            timestamp: Some(u32::MIN),
            ..Default::default()
        };

        assert_eq!(no_timestamp.merge(&max_timestamp), max_timestamp);
        assert_eq!(no_timestamp.merge(&min_timestamp), min_timestamp);
        assert_eq!(max_timestamp.merge(&min_timestamp), max_timestamp);
    }

    #[test]
    // hack to disable this test
    #[cfg(feature = "ignored_tests")]
    async fn test_gossip() {
        crate::test_utils::log!("test RGS sync");
        let storage = MemoryStorage::default();

        let logger = Arc::new(MutinyLogger::default());
        let _gossip_sync = get_gossip_sync(&storage, Network::Regtest, logger.clone())
            .await
            .unwrap();

        let data = get_gossip_data(&storage, logger).await.unwrap();

        assert!(data.is_some());
        assert!(data.unwrap().last_sync_timestamp > 0);
    }

    #[test]
    fn test_peer_info() {
        let storage = MemoryStorage::default();
        let (node_id, data) = dummy_peer_info();

        save_ln_peer_info(&storage, &node_id, &data).unwrap();

        let read = read_peer_info(&storage, &node_id).unwrap();
        let all = get_all_peers(&storage).unwrap();

        assert!(read.is_some());
        assert_eq!(read.unwrap(), data);
        assert_eq!(all.len(), 1);
        assert_eq!(*all.get(&node_id).unwrap(), data);

        delete_peer_info(&storage, data.nodes.first().unwrap(), &node_id).unwrap();

        let read = read_peer_info(&storage, &node_id).unwrap();

        assert!(read.is_none());
    }

    #[test]
    fn test_delete_label() {
        let storage = MemoryStorage::default();

        let (node_id, data) = dummy_peer_info();

        save_ln_peer_info(&storage, &node_id, &data).unwrap();

        // remove the label
        set_peer_label(&storage, &node_id, None).unwrap();

        let read = read_peer_info(&storage, &node_id).unwrap();

        let expected = LnPeerMetadata {
            label: None,
            ..data
        };

        assert!(read.is_some());
        assert_eq!(read.unwrap(), expected);
    }
}


================================================
File: mutiny-core/src/key.rs
================================================
use bitcoin::{
    bip32::{ChildNumber, DerivationPath, Xpriv},
    secp256k1::Secp256k1,
};

use crate::error::MutinyError;

pub(crate) enum ChildKey {
    Node,
    // Federation,
    // BlindAuth,
}

impl ChildKey {
    pub(crate) fn to_child_number(&self) -> u32 {
        match self {
            ChildKey::Node => 0,
            // ChildKey::Federation => 1,
            // ChildKey::BlindAuth => 2,
        }
    }
}

pub(crate) fn create_root_child_key(
    context: &Secp256k1<bitcoin::secp256k1::All>,
    xprivkey: Xpriv,
    child_key: ChildKey,
) -> Result<Xpriv, MutinyError> {
    let child_number = ChildNumber::from_hardened_idx(child_key.to_child_number())?;

    Ok(xprivkey.derive_priv(context, &DerivationPath::from(vec![child_number]))?)
}

#[cfg(test)]
fn run_key_generation_tests() {
    use bip39::Mnemonic;
    use bitcoin::Network;
    use std::str::FromStr;

    let context = Secp256k1::new();
    let mnemonic = Mnemonic::from_str("abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon about").expect("could not generate");
    let xpriv = Xpriv::new_master(Network::Testnet, &mnemonic.to_seed("")).unwrap();

    let first_root_key = create_root_child_key(&context, xpriv, ChildKey::Node);
    let copy_root_key = create_root_child_key(&context, xpriv, ChildKey::Node);
    assert_eq!(first_root_key, copy_root_key);
}

#[cfg(test)]
#[cfg(not(target_arch = "wasm32"))]
mod tests {
    use crate::key::run_key_generation_tests;

    #[test]
    fn key_generation_tests() {
        run_key_generation_tests();
    }
}

#[cfg(test)]
#[cfg(target_arch = "wasm32")]
mod wasm_tests {
    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};

    use crate::key::run_key_generation_tests;

    wasm_bindgen_test_configure!(run_in_browser);

    #[test]
    fn key_generation_tests() {
        run_key_generation_tests();
    }
}


================================================
File: mutiny-core/src/keymanager.rs
================================================
use crate::logging::MutinyLogger;
use crate::onchain::OnChainWallet;
use crate::storage::MutinyStorage;
use crate::{error::MutinyError, key::create_root_child_key};
use crate::{key::ChildKey, labels::LabelStorage};
use bdk_wallet::KeychainKind;
use bip39::Mnemonic;
use bitcoin::absolute::LockTime;
use bitcoin::bip32::{ChildNumber, DerivationPath, Xpriv};
use bitcoin::hashes::{sha256, Hash, HashEngine, Hmac, HmacEngine};
use bitcoin::secp256k1::ecdh::SharedSecret;
use bitcoin::secp256k1::ecdsa::RecoverableSignature;
use bitcoin::secp256k1::ecdsa::Signature;
use bitcoin::secp256k1::{PublicKey, Scalar, Secp256k1, SecretKey, Signing};
use bitcoin::{Address, ScriptBuf, Transaction, TxOut};
use lightning::ln::msgs::{DecodeError, UnsignedGossipMessage};
use lightning::ln::script::ShutdownScript;
use lightning::offers::invoice::UnsignedBolt12Invoice;
use lightning::offers::invoice_request::UnsignedInvoiceRequest;
use lightning::sign::{
    EntropySource, InMemorySigner, KeyMaterial, NodeSigner, OutputSpender,
    PhantomKeysManager as LdkPhantomKeysManager, Recipient, SignerProvider,
    SpendableOutputDescriptor,
};
use lightning::util::logger::Logger;
use lightning::{log_error, log_warn};
use lightning_invoice::RawBolt11Invoice;
use std::sync::Arc;
use uuid::Uuid;

pub struct PhantomKeysManager<S: MutinyStorage> {
    inner: LdkPhantomKeysManager,
    wallet: Arc<OnChainWallet<S>>,
    logger: Arc<MutinyLogger>,
}

impl<S: MutinyStorage> PhantomKeysManager<S> {
    pub fn new(
        wallet: Arc<OnChainWallet<S>>,
        seed: &[u8; 32],
        starting_time_secs: u64,
        starting_time_nanos: u32,
        cross_node_seed: &[u8; 32],
        logger: Arc<MutinyLogger>,
    ) -> Self {
        let inner = LdkPhantomKeysManager::new(
            seed,
            starting_time_secs,
            starting_time_nanos,
            cross_node_seed,
        );
        Self {
            inner,
            wallet,
            logger,
        }
    }

    pub(crate) fn get_node_secret_key(&self) -> SecretKey {
        self.inner.get_node_secret_key()
    }

    /// See [`KeysManager::spend_spendable_outputs`] for documentation on this method.
    pub fn spend_spendable_outputs<C: Signing>(
        &self,
        descriptors: &[&SpendableOutputDescriptor],
        outputs: Vec<TxOut>,
        feerate_sat_per_1000_weight: u32,
        locktime: Option<LockTime>,
        secp_ctx: &Secp256k1<C>,
        sweep_target_address: Option<Address>,
    ) -> Result<Transaction, ()> {
        let address = if let Some(address) = sweep_target_address {
            address
        } else {
            let mut wallet = self.wallet.wallet.try_write().map_err(|_| ())?;
            // These often fail because we continually retry these. Use LastUnused so we don't generate a ton of new
            // addresses for no reason.
            wallet.next_unused_address(KeychainKind::Internal).address
        };

        let result = self.inner.spend_spendable_outputs(
            descriptors,
            outputs,
            address.script_pubkey(),
            feerate_sat_per_1000_weight,
            locktime,
            secp_ctx,
        );

        match result {
            Ok(tx) => {
                // Add a label to the address so that we can track that this was a force close
                if let Err(e) = self
                    .wallet
                    .storage
                    .set_address_labels(address, vec!["Swept Force Close".to_string()])
                {
                    log_warn!(
                        self.logger,
                        "Failed to set address label for spendable outputs: {e}"
                    )
                }
                Ok(tx)
            }
            Err(e) => Err(e),
        }
    }
}

impl<S: MutinyStorage> EntropySource for PhantomKeysManager<S> {
    fn get_secure_random_bytes(&self) -> [u8; 32] {
        self.inner.get_secure_random_bytes()
    }
}

impl<S: MutinyStorage> NodeSigner for PhantomKeysManager<S> {
    fn get_inbound_payment_key_material(&self) -> KeyMaterial {
        self.inner.get_inbound_payment_key_material()
    }

    fn get_node_id(&self, recipient: Recipient) -> Result<PublicKey, ()> {
        self.inner.get_node_id(recipient)
    }

    fn ecdh(
        &self,
        recipient: Recipient,
        other_key: &PublicKey,
        tweak: Option<&Scalar>,
    ) -> Result<SharedSecret, ()> {
        self.inner.ecdh(recipient, other_key, tweak)
    }

    fn sign_invoice(
        &self,
        invoice: &RawBolt11Invoice,
        recipient: Recipient,
    ) -> Result<RecoverableSignature, ()> {
        self.inner.sign_invoice(invoice, recipient)
    }

    fn sign_bolt12_invoice_request(
        &self,
        invoice_request: &UnsignedInvoiceRequest,
    ) -> Result<bitcoin::secp256k1::schnorr::Signature, ()> {
        self.inner.sign_bolt12_invoice_request(invoice_request)
    }

    fn sign_bolt12_invoice(
        &self,
        invoice: &UnsignedBolt12Invoice,
    ) -> Result<bitcoin::secp256k1::schnorr::Signature, ()> {
        self.inner.sign_bolt12_invoice(invoice)
    }

    fn sign_gossip_message(&self, msg: UnsignedGossipMessage) -> Result<Signature, ()> {
        self.inner.sign_gossip_message(msg)
    }
}

impl<S: MutinyStorage> SignerProvider for PhantomKeysManager<S> {
    type EcdsaSigner = InMemorySigner;

    fn generate_channel_keys_id(
        &self,
        inbound: bool,
        channel_value_satoshis: u64,
        user_channel_id: u128,
    ) -> [u8; 32] {
        self.inner
            .generate_channel_keys_id(inbound, channel_value_satoshis, user_channel_id)
    }

    fn derive_channel_signer(
        &self,
        channel_value_satoshis: u64,
        channel_keys_id: [u8; 32],
    ) -> Self::EcdsaSigner {
        self.inner
            .derive_channel_signer(channel_value_satoshis, channel_keys_id)
    }

    fn read_chan_signer(&self, reader: &[u8]) -> Result<Self::EcdsaSigner, DecodeError> {
        self.inner.read_chan_signer(reader)
    }

    fn get_destination_script(&self, _channel_keys_id: [u8; 32]) -> Result<ScriptBuf, ()> {
        let mut wallet = self.wallet.wallet.try_write().map_err(|_| ())?;
        let script = wallet
            .reveal_next_address(KeychainKind::External)
            .address
            .script_pubkey();
        if let Some(changeset) = wallet.take_staged() {
            if let Err(err) = self.wallet.storage.write_changes(&changeset) {
                log_error!(
                    self.logger,
                    "Signer failed to reveal destination script: {err:?}"
                );
                return Err(());
            }
        }
        Ok(script)
    }

    fn get_shutdown_scriptpubkey(&self) -> Result<ShutdownScript, ()> {
        let mut wallet = self.wallet.wallet.try_write().map_err(|_| ())?;
        let script = wallet
            .reveal_next_address(KeychainKind::External)
            .address
            .script_pubkey();
        if let Some(changeset) = wallet.take_staged() {
            if let Err(err) = self.wallet.storage.write_changes(&changeset) {
                log_error!(
                    self.logger,
                    "Signer failed to reveal shutdown script: {err:?}"
                );
                return Err(());
            }
        }
        ShutdownScript::try_from(script).map_err(|_| ())
    }
}

pub fn generate_seed(num_words: u8) -> Result<Mnemonic, MutinyError> {
    // the bip39 library supports 12. 15, 18, 21, and 24 word mnemonics
    // we only support 12 & 24 for backwards compatibility with other wallets
    let entropy_size = match num_words {
        12 => 16,
        24 => 32,
        _ => return Err(MutinyError::SeedGenerationFailed),
    };

    let mut entropy = vec![0u8; entropy_size];
    getrandom::getrandom(&mut entropy).map_err(|_| MutinyError::SeedGenerationFailed)?;
    let mnemonic =
        Mnemonic::from_entropy(&entropy).map_err(|_| MutinyError::SeedGenerationFailed)?;
    Ok(mnemonic)
}

// A node private key will be derived from `m/0'/X'`, where its node pubkey will
// be derived from the LDK default being `m/0'/X'/0'`. The PhantomKeysManager shared
// key secret will be derived from `m/0'`.
pub(crate) fn create_keys_manager<S: MutinyStorage>(
    wallet: Arc<OnChainWallet<S>>,
    xprivkey: Xpriv,
    child_index: u32,
    logger: Arc<MutinyLogger>,
) -> Result<PhantomKeysManager<S>, MutinyError> {
    let context = Secp256k1::new();

    let shared_key = create_root_child_key(&context, xprivkey, ChildKey::Node)?;

    let xpriv = shared_key.derive_priv(
        &context,
        &DerivationPath::from(vec![ChildNumber::from_hardened_idx(child_index)?]),
    )?;

    let now = crate::utils::now();

    Ok(PhantomKeysManager::new(
        wallet,
        &xpriv.private_key.secret_bytes(),
        now.as_secs(),
        now.as_nanos() as u32,
        &shared_key.private_key.secret_bytes(),
        logger,
    ))
}

pub(crate) fn pubkey_from_keys_manager<S: MutinyStorage>(
    keys_manager: &PhantomKeysManager<S>,
) -> PublicKey {
    keys_manager
        .get_node_id(Recipient::Node)
        .expect("cannot parse node id")
}

pub(crate) fn deterministic_uuid_from_keys_manager<S: MutinyStorage>(
    keys_manager: &PhantomKeysManager<S>,
) -> Uuid {
    let secret_bytes = keys_manager.get_node_secret_key().secret_bytes();
    // hash secret bytes just in case
    let hashed_secret_bytes = sha256::Hash::hash(&secret_bytes);
    let node_id = pubkey_from_keys_manager(keys_manager);

    // create a Hmac that commits to a secret plus their node id and a salt,
    // this way it can't be calculated off of only public info.
    let mut engine = HmacEngine::new(&hashed_secret_bytes.to_byte_array());
    engine.input(&node_id.serialize());
    engine.input(b"Mutiny Node UUID");
    let hmac = Hmac::<sha256::Hash>::from_engine(engine);

    // take first 16 bytes to create the UUID
    let bytes = hmac.as_byte_array();
    Uuid::from_slice(&bytes[..16]).expect("exactly 16 bytes")
}

#[cfg(test)]
mod tests {
    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};

    wasm_bindgen_test_configure!(run_in_browser);

    use crate::{
        encrypt::encryption_key_from_pass, keymanager::pubkey_from_keys_manager, test_utils::*,
    };

    use super::{create_keys_manager, deterministic_uuid_from_keys_manager};
    use crate::fees::MutinyFeeEstimator;
    use crate::logging::MutinyLogger;
    use crate::onchain::OnChainWallet;
    use crate::storage::MemoryStorage;
    use bip39::Mnemonic;
    use bitcoin::bip32::Xpriv;
    use bitcoin::Network;
    use esplora_client::Builder;
    use std::str::FromStr;
    use std::sync::atomic::AtomicBool;
    use std::sync::Arc;

    #[test]
    async fn derive_pubkey_child_from_seed() {
        let test_name = "derive_pubkey_child_from_seed";
        log!("{}", test_name);

        let mnemonic = Mnemonic::from_str("abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon about").expect("could not generate");
        let esplora = Arc::new(
            Builder::new("https://blockstream.info/testnet/api/")
                .build_async()
                .unwrap(),
        );
        let network = Network::Testnet;
        let pass = uuid::Uuid::new_v4().to_string();
        let cipher = encryption_key_from_pass(&pass).unwrap();
        let db = MemoryStorage::new(Some(pass), Some(cipher), None);
        let logger = Arc::new(MutinyLogger::default());
        let fees = Arc::new(MutinyFeeEstimator::new(
            db.clone(),
            esplora.clone(),
            logger.clone(),
        ));
        let stop = Arc::new(AtomicBool::new(false));
        let xpriv = Xpriv::new_master(network, &mnemonic.to_seed("")).unwrap();

        let wallet = Arc::new(
            OnChainWallet::new(
                xpriv,
                db,
                network,
                esplora,
                fees,
                stop,
                logger.clone(),
                None,
            )
            .unwrap(),
        );

        let km = create_keys_manager(wallet.clone(), xpriv, 1, logger.clone()).unwrap();
        let pubkey = pubkey_from_keys_manager(&km);
        assert_eq!(
            "02cae09cf2c8842ace44068a5bf3117a494ebbf69a99e79712483c36f97cdb7b54",
            pubkey.to_string()
        );

        let km = create_keys_manager(wallet.clone(), xpriv, 2, logger.clone()).unwrap();
        let second_pubkey = pubkey_from_keys_manager(&km);
        assert_eq!(
            "03fcc9eaaf0b84946ea7935e3bc4f2b498893c2f53e5d2994d6877d149601ce553",
            second_pubkey.to_string()
        );

        let km = create_keys_manager(wallet, xpriv, 2, logger).unwrap();
        let second_pubkey_again = pubkey_from_keys_manager(&km);

        assert_eq!(second_pubkey, second_pubkey_again);
    }

    #[test]
    async fn derive_uuid_from_key_manager() {
        let test_name = "derive_uuid_from_key_manager";
        log!("{}", test_name);

        let mnemonic = Mnemonic::from_str("abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon about").expect("could not generate");
        let esplora = Arc::new(
            Builder::new("https://blockstream.info/testnet/api/")
                .build_async()
                .unwrap(),
        );
        let network = Network::Testnet;
        let pass = uuid::Uuid::new_v4().to_string();
        let cipher = encryption_key_from_pass(&pass).unwrap();
        let db = MemoryStorage::new(Some(pass), Some(cipher), None);
        let logger = Arc::new(MutinyLogger::default());
        let fees = Arc::new(MutinyFeeEstimator::new(
            db.clone(),
            esplora.clone(),
            logger.clone(),
        ));
        let stop = Arc::new(AtomicBool::new(false));
        let xpriv = Xpriv::new_master(network, &mnemonic.to_seed("")).unwrap();

        let wallet = Arc::new(
            OnChainWallet::new(
                xpriv,
                db,
                network,
                esplora,
                fees,
                stop,
                logger.clone(),
                None,
            )
            .unwrap(),
        );

        let km = create_keys_manager(wallet.clone(), xpriv, 1, logger.clone()).unwrap();
        let uuid = deterministic_uuid_from_keys_manager(&km);
        assert_eq!("1f586dda-909b-e737-e49b-f1dfbcfd21c0", uuid.to_string());

        let km = create_keys_manager(wallet.clone(), xpriv, 2, logger.clone()).unwrap();
        let second_uuid = deterministic_uuid_from_keys_manager(&km);
        assert_eq!(
            "acb9c94d-780a-5ef5-f576-069a7bb4c5ae",
            second_uuid.to_string()
        );

        let km = create_keys_manager(wallet, xpriv, 2, logger).unwrap();
        let second_uuid_again = deterministic_uuid_from_keys_manager(&km);

        assert_eq!(second_uuid, second_uuid_again);
    }
}


================================================
File: mutiny-core/src/labels.rs
================================================
use crate::error::MutinyError;
use crate::nodemanager::NodeManager;
use crate::storage::MutinyStorage;
use bitcoin::Address;
use lightning_invoice::Bolt11Invoice;
use serde::{Deserialize, Serialize};
use serde_json::Value;
use std::collections::{HashMap, HashSet};

use uuid::Uuid;

const ADDRESS_LABELS_MAP_KEY: &str = "address_labels";
const INVOICE_LABELS_MAP_KEY: &str = "invoice_labels";
const LABEL_PREFIX: &str = "label/";
const CONTACT_PREFIX: &str = "contact/";

#[derive(Debug, Clone, Serialize, Deserialize, Eq, PartialEq, Default)]
pub struct LabelItem {
    /// List of addresses that have this label
    pub addresses: HashSet<String>,
    /// List of invoices that have this label
    pub invoices: HashSet<Bolt11Invoice>,
    /// Epoch time in seconds when this label was last used
    pub last_used_time: u64,
}

#[derive(Debug, Clone, Default, Serialize, Deserialize, Eq, Ord, PartialEq, PartialOrd, Hash)]
pub struct Contact {
    pub name: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub image_url: Option<String>,
    pub last_used: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize, Eq, PartialEq)]
pub enum TagItem {
    Label((String, LabelItem)),
    Contact((String, Contact)),
}

pub(crate) fn get_label_item_key(label: impl AsRef<str>) -> String {
    format!("{}{}", LABEL_PREFIX, label.as_ref())
}

pub(crate) fn get_contact_key(label: impl AsRef<str>) -> String {
    format!("{}{}", CONTACT_PREFIX, label.as_ref())
}

pub trait LabelStorage {
    /// Get a map of addresses to labels. This can be used to get all the labels for an address
    fn get_address_labels(&self) -> Result<HashMap<String, Vec<String>>, MutinyError>;
    /// Get a map of invoices to labels. This can be used to get all the labels for an invoice
    fn get_invoice_labels(&self) -> Result<HashMap<Bolt11Invoice, Vec<String>>, MutinyError>;
    /// Get all the existing labels
    fn get_labels(&self) -> Result<HashMap<String, LabelItem>, MutinyError>;
    /// Get information about a label
    fn get_label(&self, label: impl AsRef<str>) -> Result<Option<LabelItem>, MutinyError>;
    /// Set the labels for an address, replacing any existing labels
    /// If you do not want to replace any existing labels, use `get_address_labels` to get the existing labels,
    /// add the new labels, and then use `set_address_labels` to set the new labels
    fn set_address_labels(&self, address: Address, labels: Vec<String>) -> Result<(), MutinyError>;
    /// Set the labels for an invoice, replacing any existing labels
    /// If you do not want to replace any existing labels, use `get_invoice_labels` to get the existing labels,
    /// add the new labels, and then use `set_invoice_labels` to set the new labels
    fn set_invoice_labels(
        &self,
        invoice: Bolt11Invoice,
        labels: Vec<String>,
    ) -> Result<(), MutinyError>;
    /// Get all the existing contacts
    fn get_contacts(&self) -> Result<HashMap<String, Contact>, MutinyError>;
    /// Get a contact by label, the label should be a uuid
    fn get_contact(&self, label: impl AsRef<str>) -> Result<Option<Contact>, MutinyError>;
    /// Create a new contact from an existing label and returns the new identifying label
    fn create_contact_from_label(
        &self,
        label: impl AsRef<str>,
        contact: Contact,
    ) -> Result<String, MutinyError>;
    /// Create a new contact and return the identifying label
    fn create_new_contact(&self, contact: Contact) -> Result<String, MutinyError>;
    /// Deletes a contact and all labels associated with it
    fn delete_contact(&self, id: impl AsRef<str>) -> Result<(), MutinyError>;
    /// Edits an existing contact and replaces the existing contact
    fn edit_contact(&self, id: impl AsRef<str>, contact: Contact) -> Result<(), MutinyError>;
    /// Gets all the existing tags (labels and contacts)
    fn get_tag_items(&self) -> Result<Vec<TagItem>, MutinyError>;
}

impl<S: MutinyStorage> LabelStorage for S {
    fn get_address_labels(&self) -> Result<HashMap<String, Vec<String>>, MutinyError> {
        let res: Option<HashMap<String, Vec<String>>> = self.get_data(ADDRESS_LABELS_MAP_KEY)?;
        Ok(res.unwrap_or_default()) // if no labels exist, return an empty map
    }

    fn get_invoice_labels(&self) -> Result<HashMap<Bolt11Invoice, Vec<String>>, MutinyError> {
        let res: Option<HashMap<Bolt11Invoice, Vec<String>>> =
            self.get_data(INVOICE_LABELS_MAP_KEY)?;
        Ok(res.unwrap_or_default()) // if no labels exist, return an empty map
    }

    fn get_labels(&self) -> Result<HashMap<String, LabelItem>, MutinyError> {
        let all = self.scan(LABEL_PREFIX, None)?;
        // remove the prefix from the keys
        let mut labels = HashMap::new();
        for (key, label_item) in all {
            let label = key.replace(LABEL_PREFIX, "");
            labels.insert(label, label_item);
        }

        Ok(labels)
    }

    fn get_label(&self, label: impl AsRef<str>) -> Result<Option<LabelItem>, MutinyError> {
        let key = get_label_item_key(label);
        self.get_data(key)
    }

    fn set_address_labels(&self, address: Address, labels: Vec<String>) -> Result<(), MutinyError> {
        // update the labels map
        let mut address_labels = self.get_address_labels()?;
        address_labels.insert(address.to_string(), labels.clone());
        self.write_data(ADDRESS_LABELS_MAP_KEY.to_string(), address_labels, None)?;

        // update the label items
        let now = crate::utils::now().as_secs();
        for label in labels {
            let key = get_label_item_key(&label);
            match self.get_label(&label)? {
                Some(mut label_item) => {
                    // Add the address to the label item
                    // and sort so we can dedup the addresses
                    label_item.addresses.insert(address.to_string());

                    // Update the last used timestamp
                    label_item.last_used_time = now;

                    // if it is a contact, update last used
                    if let Some(contact) = self.get_contact(&label)? {
                        let mut contact = contact;
                        contact.last_used = now;
                        self.edit_contact(&label, contact)?;
                    }

                    self.write_data(key, label_item, None)?;
                }
                None => {
                    let mut addresses = HashSet::with_capacity(1);
                    addresses.insert(address.to_string());
                    // Create a new label item
                    let label_item = LabelItem {
                        addresses,
                        invoices: HashSet::new(),
                        last_used_time: now,
                    };
                    self.write_data(key, label_item, None)?;
                }
            }
        }

        Ok(())
    }

    fn set_invoice_labels(
        &self,
        invoice: Bolt11Invoice,
        labels: Vec<String>,
    ) -> Result<(), MutinyError> {
        // update the labels map
        let mut invoice_labels = self.get_invoice_labels()?;
        invoice_labels.insert(invoice.clone(), labels.clone());
        self.write_data(INVOICE_LABELS_MAP_KEY.to_string(), invoice_labels, None)?;

        // update the label items
        let now = crate::utils::now().as_secs();
        for label in labels {
            let key = get_label_item_key(&label);
            match self.get_label(&label)? {
                Some(mut label_item) => {
                    // Add the invoice to the label item
                    // and sort so we can dedup the invoices
                    label_item.invoices.insert(invoice.clone());

                    // Update the last used timestamp
                    label_item.last_used_time = now;

                    // if it is a contact, update last used
                    if let Some(contact) = self.get_contact(&label)? {
                        let mut contact = contact;
                        contact.last_used = now;
                        self.edit_contact(&label, contact)?;
                    }

                    self.write_data(key, label_item, None)?;
                }
                None => {
                    // Create a new label item
                    let invoices = HashSet::from_iter(vec![invoice.clone()]);
                    let label_item = LabelItem {
                        addresses: HashSet::new(),
                        invoices,
                        last_used_time: now,
                    };
                    self.write_data(key, label_item, None)?;
                }
            }
        }

        Ok(())
    }

    fn get_contacts(&self) -> Result<HashMap<String, Contact>, MutinyError> {
        let all = self.scan::<Contact>(CONTACT_PREFIX, None)?;
        // remove the prefix from the keys
        let mut contacts = HashMap::with_capacity(all.len());
        for (key, contact) in all {
            let label = key.replace(CONTACT_PREFIX, "");
            contacts.insert(label, contact);
        }

        Ok(contacts)
    }

    fn get_contact(&self, label: impl AsRef<str>) -> Result<Option<Contact>, MutinyError> {
        self.get_data(get_contact_key(label))
    }

    fn create_contact_from_label(
        &self,
        label: impl AsRef<str>,
        contact: Contact,
    ) -> Result<String, MutinyError> {
        match self.get_label(&label)? {
            None => Err(MutinyError::NotFound),
            Some(current) => {
                // convert label into a uuid for uniqueness
                let id = Uuid::new_v4().to_string();
                // create label item
                self.write_data(get_label_item_key(&id), current, None)?;

                // replace label in address_labels with new uuid
                let addr_labels = self.get_address_labels()?;
                let mut updated = HashMap::new();
                let label_str = label.as_ref().to_string();
                for (addr, labels) in addr_labels {
                    if labels.contains(&label_str) {
                        let new_labels: Vec<String> = labels
                            .into_iter()
                            // replace the label with the new id, otherwise keep old one
                            .map(|l| if l == label_str { id.clone() } else { l })
                            .collect();

                        updated.insert(addr, new_labels);
                    }
                }
                self.write_data(ADDRESS_LABELS_MAP_KEY.to_string(), updated, None)?;

                // replace label in invoice_labels with new uuid
                let invoice_labels = self.get_invoice_labels()?;
                let mut updated = HashMap::new();
                let label_str = label.as_ref().to_string();
                for (inv, labels) in invoice_labels {
                    if labels.contains(&label_str) {
                        let new_labels: Vec<String> = labels
                            .into_iter()
                            // replace the label with the new id, otherwise keep old one
                            .map(|l| if l == label_str { id.clone() } else { l })
                            .collect();

                        updated.insert(inv, new_labels);
                    }
                }
                self.write_data(INVOICE_LABELS_MAP_KEY.to_string(), updated, None)?;

                // create the contact
                let key = get_contact_key(&id);
                self.write_data(key, contact, None)?;

                // delete old label item
                self.delete(&[get_label_item_key(&label)])?;
                Ok(id)
            }
        }
    }

    /// Create a new contact and return the identifying label
    fn create_new_contact(&self, contact: Contact) -> Result<String, MutinyError> {
        // generate a uuid, this will be the "label" that we use to store the contact
        let id = Uuid::new_v4().to_string();
        let key = get_contact_key(&id);
        self.write_data(key, contact, None)?;

        let key = get_label_item_key(&id);
        let label_item = LabelItem {
            last_used_time: crate::utils::now().as_secs(),
            ..Default::default()
        };
        self.write_data(key, label_item, None)?;
        Ok(id)
    }

    fn delete_contact(&self, id: impl AsRef<str>) -> Result<(), MutinyError> {
        // first remove from all labels
        let mut inv_labels = self.get_invoice_labels()?;
        for value in inv_labels.values_mut() {
            value.retain(|s| *s != id.as_ref());
        }
        let mut addr_labels = self.get_address_labels()?;
        for value in addr_labels.values_mut() {
            value.retain(|s| *s != id.as_ref());
        }
        let to_set: Vec<(String, Value)> = vec![
            (
                ADDRESS_LABELS_MAP_KEY.to_string(),
                serde_json::to_value(addr_labels)?,
            ),
            (
                INVOICE_LABELS_MAP_KEY.to_string(),
                serde_json::to_value(inv_labels)?,
            ),
        ];
        self.write_raw(to_set)?;

        // then delete actual label
        let contact_key = get_contact_key(&id);
        let label_item_key = get_label_item_key(&id);
        self.delete(&[contact_key, label_item_key])?;
        Ok(())
    }

    fn edit_contact(&self, id: impl AsRef<str>, contact: Contact) -> Result<(), MutinyError> {
        self.write_data(get_contact_key(&id), contact, None)
    }

    fn get_tag_items(&self) -> Result<Vec<TagItem>, MutinyError> {
        let mut tag_items = vec![];

        // Get all the contacts
        let contacts = self.get_contacts()?;
        // Get all the labels
        let mut labels = self.get_labels()?;

        // filter out labels that have a contact
        labels.retain(|label, _| !contacts.contains_key(label));

        // Convert the labels into tag items
        tag_items.extend(
            labels
                .into_iter()
                .map(|(label, label_item)| TagItem::Label((label, label_item))),
        );

        // Convert the contacts into tag items
        tag_items.extend(
            contacts
                .into_iter()
                .map(|(id, c)| TagItem::Contact((id, c))),
        );

        Ok(tag_items)
    }
}

impl<S: MutinyStorage> LabelStorage for NodeManager<S> {
    fn get_address_labels(&self) -> Result<HashMap<String, Vec<String>>, MutinyError> {
        self.storage.get_address_labels()
    }

    fn get_invoice_labels(&self) -> Result<HashMap<Bolt11Invoice, Vec<String>>, MutinyError> {
        self.storage.get_invoice_labels()
    }

    fn get_labels(&self) -> Result<HashMap<String, LabelItem>, MutinyError> {
        self.storage.get_labels()
    }

    fn get_label(&self, label: impl AsRef<str>) -> Result<Option<LabelItem>, MutinyError> {
        self.storage.get_label(label)
    }

    fn set_address_labels(&self, address: Address, labels: Vec<String>) -> Result<(), MutinyError> {
        self.storage.set_address_labels(address, labels)
    }

    fn set_invoice_labels(
        &self,
        invoice: Bolt11Invoice,
        labels: Vec<String>,
    ) -> Result<(), MutinyError> {
        self.storage.set_invoice_labels(invoice, labels)
    }

    fn get_contacts(&self) -> Result<HashMap<String, Contact>, MutinyError> {
        self.storage.get_contacts()
    }

    fn get_contact(&self, label: impl AsRef<str>) -> Result<Option<Contact>, MutinyError> {
        self.storage.get_contact(label)
    }

    fn create_contact_from_label(
        &self,
        label: impl AsRef<str>,
        contact: Contact,
    ) -> Result<String, MutinyError> {
        self.storage.create_contact_from_label(label, contact)
    }

    fn create_new_contact(&self, contact: Contact) -> Result<String, MutinyError> {
        self.storage.create_new_contact(contact)
    }

    fn delete_contact(&self, id: impl AsRef<str>) -> Result<(), MutinyError> {
        self.storage.delete_contact(id)
    }

    fn edit_contact(&self, id: impl AsRef<str>, contact: Contact) -> Result<(), MutinyError> {
        self.storage.edit_contact(id, contact)
    }

    fn get_tag_items(&self) -> Result<Vec<TagItem>, MutinyError> {
        self.storage.get_tag_items()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::test_utils::*;
    use bitcoin::Address;
    use itertools::Itertools;
    use lightning_invoice::Bolt11Invoice;
    use std::collections::HashMap;
    use std::str::FromStr;

    use crate::storage::MemoryStorage;
    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};
    wasm_bindgen_test_configure!(run_in_browser);

    const ADDRESS: &str = "1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa";
    const INVOICE: &str = "lnbc923720n1pj9nr6zpp5xmvlq2u5253htn52mflh2e6gn7pk5ht0d4qyhc62fadytccxw7hqhp5l4s6qwh57a7cwr7zrcz706qx0qy4eykcpr8m8dwz08hqf362egfscqzzsxqzfvsp5pr7yjvcn4ggrf6fq090zey0yvf8nqvdh2kq7fue0s0gnm69evy6s9qyyssqjyq0fwjr22eeg08xvmz88307yqu8tqqdjpycmermks822fpqyxgshj8hvnl9mkh6srclnxx0uf4ugfq43d66ak3rrz4dqcqd23vxwpsqf7dmhm";

    fn create_test_address_labels_map() -> HashMap<String, Vec<String>> {
        let mut labels = HashMap::new();
        labels.insert(
            "1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa".to_string(),
            vec!["test1".to_string()],
        );
        labels.insert(
            "1BitcoinEaterAddressDontSendf59kuE".to_string(),
            vec!["test2".to_string()],
        );
        labels.insert(
            "12cbQLTFMXRnSzktFkuoG3eHoMeFtpTu3S".to_string(),
            vec!["test3".to_string()],
        );
        labels
    }

    fn create_test_invoice_labels_map() -> HashMap<Bolt11Invoice, Vec<String>> {
        let mut labels = HashMap::new();
        labels.insert(
            Bolt11Invoice::from_str("lnbc923720n1pj9nrefpp5pczykgk37af5388n8dzynljpkzs7sje4melqgazlwv9y3apay8jqhp5rd8saxz3juve3eejq7z5fjttxmpaq88d7l92xv34n4h3mq6kwq2qcqzzsxqzfvsp5z0jwpehkuz9f2kv96h62p8x30nku76aj8yddpcust7g8ad0tr52q9qyyssqfy622q25helv8cj8hyxqltws4rdwz0xx2hw0uh575mn7a76cp3q4jcptmtjkjs4a34dqqxn8uy70d0qlxqleezv4zp84uk30pp5q3nqq4c9gkz").unwrap(),
            vec!["test1".to_string()],
        );
        labels.insert(
            Bolt11Invoice::from_str("lnbc923720n1pj9nre4pp58zjsgd3xkyj33wv6rfmsshg9hqdpqrh8dyaulzwg62x6h3qs39tqhp5vqcr4c3tnxyxr08rk28n8mkphe6c5gfusmyncpmdh604trq3cafqcqzzsxqzfvsp5un4ey9rh0pl23648xtng2k6gtw7w2p6ldaexl6ylwcuhnsnxnsfs9qyyssqxnhr6jvdqfwr97qk7dtsnqaps78r7fjlpyz5z57r2k70az5tvvss4tpucycqpph8gx0vxxr7xse442zf8wxlskln8n77qkd4kad4t5qp92lvrm").unwrap(),
            vec!["test2".to_string()],
        );
        labels.insert(
            Bolt11Invoice::from_str("lnbc923720n1pj9nr6zpp5xmvlq2u5253htn52mflh2e6gn7pk5ht0d4qyhc62fadytccxw7hqhp5l4s6qwh57a7cwr7zrcz706qx0qy4eykcpr8m8dwz08hqf362egfscqzzsxqzfvsp5pr7yjvcn4ggrf6fq090zey0yvf8nqvdh2kq7fue0s0gnm69evy6s9qyyssqjyq0fwjr22eeg08xvmz88307yqu8tqqdjpycmermks822fpqyxgshj8hvnl9mkh6srclnxx0uf4ugfq43d66ak3rrz4dqcqd23vxwpsqf7dmhm").unwrap(),
            vec!["test3".to_string()],
        );
        labels
    }

    fn create_test_labels() -> HashMap<String, LabelItem> {
        let mut labels = HashMap::new();
        labels.insert(
            "test1".to_string(),
            LabelItem {
                addresses: HashSet::from_iter(vec![
                    "1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa".to_string()
                ]),
                ..Default::default()
            },
        );
        labels.insert(
            "test2".to_string(),
            LabelItem {
                addresses: HashSet::from_iter(vec!["1BitcoinEaterAddressDontSendf59kuE".to_string()]),
                invoices: HashSet::from_iter(vec![Bolt11Invoice::from_str("lnbc923720n1pj9nr6zpp5xmvlq2u5253htn52mflh2e6gn7pk5ht0d4qyhc62fadytccxw7hqhp5l4s6qwh57a7cwr7zrcz706qx0qy4eykcpr8m8dwz08hqf362egfscqzzsxqzfvsp5pr7yjvcn4ggrf6fq090zey0yvf8nqvdh2kq7fue0s0gnm69evy6s9qyyssqjyq0fwjr22eeg08xvmz88307yqu8tqqdjpycmermks822fpqyxgshj8hvnl9mkh6srclnxx0uf4ugfq43d66ak3rrz4dqcqd23vxwpsqf7dmhm").unwrap()]),
                ..Default::default()
            },
        );
        labels.insert(
            "test3".to_string(),
            LabelItem {
                addresses: HashSet::from_iter(vec![
                    "12cbQLTFMXRnSzktFkuoG3eHoMeFtpTu3S".to_string()
                ]),
                ..Default::default()
            },
        );
        labels
    }

    fn create_test_contacts() -> HashMap<String, Contact> {
        let mut labels = HashMap::new();

        labels.insert(
            Uuid::new_v4().to_string(),
            Contact {
                name: "Satoshi Nakamoto".to_string(),
                image_url: None,
                last_used: 0,
            },
        );
        labels.insert(
            Uuid::new_v4().to_string(),
            Contact {
                name: "Hal Finney".to_string(),
                image_url: None,
                last_used: 0,
            },
        );
        labels.insert(
            Uuid::new_v4().to_string(),
            Contact {
                name: "Nick Szabo".to_string(),
                image_url: None,
                last_used: 0,
            },
        );

        labels
    }

    #[test]
    fn test_get_address_labels() {
        let test_name = "test_get_address_labels";
        log!("{}", test_name);

        let storage = MemoryStorage::default();
        let labels_map = create_test_address_labels_map();
        storage
            .write_data(ADDRESS_LABELS_MAP_KEY.to_string(), labels_map.clone(), None)
            .unwrap();

        let result = storage.get_address_labels();
        assert_eq!(result.unwrap(), labels_map);
    }

    #[test]
    fn test_get_invoice_labels() {
        let test_name = "test_get_invoice_labels";
        log!("{}", test_name);

        let storage = MemoryStorage::default();
        let labels_map = create_test_invoice_labels_map();
        storage
            .write_data(INVOICE_LABELS_MAP_KEY.to_string(), labels_map.clone(), None)
            .unwrap();

        let result = storage.get_invoice_labels();
        assert_eq!(result.unwrap(), labels_map);
    }

    #[test]
    fn test_get_labels() {
        let test_name = "test_get_labels";
        log!("{}", test_name);

        let storage = MemoryStorage::default();

        let labels = create_test_labels();
        for (label, label_item) in labels.clone() {
            storage
                .write_data(get_label_item_key(label), label_item, None)
                .unwrap();
        }

        let result = storage.get_labels().unwrap();

        // convert to vectors and sort for comparison
        let mut result: Vec<(String, LabelItem)> = result.into_iter().collect();
        result.sort_by(|a, b| a.0.cmp(&b.0));
        let mut labels: Vec<(String, LabelItem)> = labels.into_iter().collect();
        labels.sort_by(|a, b| a.0.cmp(&b.0));

        assert_eq!(result, labels);
    }

    #[test]
    async fn test_get_label() {
        let test_name = "test_get_label";
        log!("{}", test_name);

        let storage = MemoryStorage::default();

        let labels = create_test_labels();
        for (label, label_item) in labels.clone() {
            storage
                .write_data(get_label_item_key(label), label_item, None)
                .unwrap();
        }

        let label = "test_label".to_string();
        let result = storage.get_label(&label);
        assert_eq!(result.unwrap(), labels.get(&label).cloned());
    }

    #[test]
    async fn test_set_address_labels() {
        let test_name = "test_set_address_labels";
        log!("{}", test_name);

        let storage = MemoryStorage::default();

        let address = Address::from_str(ADDRESS).unwrap().assume_checked();
        let labels = vec!["label1".to_string(), "label2".to_string()];

        let result = storage.set_address_labels(address.clone(), labels.clone());
        assert!(result.is_ok());

        let address_labels = storage.get_address_labels().unwrap();
        assert_eq!(address_labels.get(&address.to_string()), Some(&labels));
    }

    #[test]
    async fn test_set_invoice_labels() {
        let test_name = "test_set_invoice_labels";
        log!("{}", test_name);

        let storage = MemoryStorage::default();

        let invoice = Bolt11Invoice::from_str(INVOICE).unwrap();
        let labels = vec!["label1".to_string(), "label2".to_string()];

        let result = storage.set_invoice_labels(invoice.clone(), labels.clone());
        assert!(result.is_ok());

        let invoice_labels = storage.get_invoice_labels().unwrap();
        assert_eq!(invoice_labels.get(&invoice), Some(&labels));
    }

    #[test]
    fn test_get_contacts() {
        let test_name = "test_get_contacts";
        log!("{}", test_name);

        let storage = MemoryStorage::default();

        let contacts = create_test_contacts();
        for (id, contact) in contacts.clone() {
            storage
                .write_data(get_contact_key(id), contact, None)
                .unwrap();
        }

        let result = storage.get_contacts().unwrap();

        // convert to vectors and sort for comparison
        let mut result: Vec<(String, Contact)> = result.into_iter().collect();
        result.sort_by(|a, b| a.0.cmp(&b.0));
        let mut contacts: Vec<(String, Contact)> = contacts.into_iter().collect();
        contacts.sort_by(|a, b| a.0.cmp(&b.0));

        assert_eq!(result, contacts);
    }

    #[test]
    async fn test_get_contact() {
        let test_name = "test_get_contact";
        log!("{}", test_name);

        let storage = MemoryStorage::default();

        let contact = Contact {
            name: "Satoshi Nakamoto".to_string(),
            image_url: None,
            last_used: 0,
        };
        let id = storage.create_new_contact(contact.clone()).unwrap();

        let result = storage.get_contact(id).unwrap();
        assert_eq!(result.unwrap(), contact);
    }

    #[test]
    fn test_edit_contact() {
        let test_name = "test_edit_contact";
        log!("{}", test_name);

        let storage = MemoryStorage::default();

        let contact = Contact {
            name: "Satoshi Nakamoto".to_string(),
            image_url: None,
            last_used: 0,
        };
        let id = storage.create_new_contact(contact).unwrap();

        let mut contact = storage.get_contact(&id).unwrap().unwrap();
        contact.name = "Satoshi Nakamoto 2".to_string();
        storage.edit_contact(&id, contact.clone()).unwrap();

        let result = storage.get_contact(&id).unwrap();
        assert_eq!(result.unwrap(), contact);
    }

    #[test]
    fn test_delete_contact() {
        let test_name = "test_delete_contact";
        log!("{}", test_name);

        let storage = MemoryStorage::default();

        let contact = Contact {
            name: "Satoshi Nakamoto".to_string(),
            image_url: None,
            last_used: 0,
        };
        let id = storage.create_new_contact(contact).unwrap();
        let contact = storage.get_contact(&id).unwrap();
        assert!(contact.is_some());

        // set labels for invoice and address
        let invoice = Bolt11Invoice::from_str(INVOICE).unwrap();
        storage
            .set_invoice_labels(invoice.clone(), vec![id.clone()])
            .unwrap();
        let address = Address::from_str(ADDRESS).unwrap().assume_checked();
        storage
            .set_address_labels(address, vec![id.clone()])
            .unwrap();

        // delete contact
        storage.delete_contact(&id).unwrap();

        // make sure it is deleted
        let result = storage.get_contact(&id).unwrap();
        assert!(result.is_none());
        let contacts = storage.get_contacts().unwrap();
        assert!(!contacts.contains_key(&id));

        // check invoice labels are empty
        let inv_labels = storage.get_invoice_labels().unwrap();
        let labels = inv_labels.get(&invoice).cloned().unwrap_or_default();
        assert!(labels.is_empty());

        // check address labels are empty
        let addr_labels = storage.get_address_labels().unwrap();
        let labels = addr_labels.get(ADDRESS).cloned().unwrap_or_default();
        assert!(labels.is_empty());
    }

    #[test]
    async fn test_create_contact_from_label() {
        let test_name = "test_create_contact_from_label";
        log!("{}", test_name);

        let storage = MemoryStorage::default();

        let address = Address::from_str(ADDRESS).unwrap().assume_checked();
        let invoice = Bolt11Invoice::from_str(INVOICE).unwrap();
        let label = "test_label".to_string();
        let other_label = "other_label".to_string();
        let contact = create_test_contacts().iter().next().unwrap().1.to_owned();

        storage
            .set_address_labels(address.clone(), vec![label.clone(), other_label.clone()])
            .unwrap();

        storage
            .set_invoice_labels(invoice.clone(), vec![label.clone(), other_label.clone()])
            .unwrap();

        let new_label = storage
            .create_contact_from_label(&label, contact.clone())
            .unwrap();

        let stored_contact = storage.get_contact(&new_label).unwrap();
        assert_eq!(stored_contact, Some(contact));

        let label_item = storage.get_label(&new_label).unwrap();
        assert!(label_item.is_some());
        assert_eq!(
            label_item
                .clone()
                .unwrap()
                .invoices
                .into_iter()
                .collect_vec(),
            vec![invoice]
        );
        assert_eq!(
            label_item.unwrap().addresses.into_iter().collect_vec(),
            vec![address.to_string()]
        );

        // check we properly converted the old label to a new label
        // check we also kept the other label
        let address_labels = storage.get_address_labels().unwrap();
        for (_, labels) in address_labels {
            assert!(!labels.contains(&label));
            assert!(labels.contains(&new_label));
            assert!(labels.contains(&other_label));
        }
        let invoice_labels = storage.get_invoice_labels().unwrap();
        for (_, labels) in invoice_labels {
            assert!(!labels.contains(&label));
            assert!(labels.contains(&new_label));
            assert!(labels.contains(&other_label));
        }

        // verify we deleted the old label
        let label_item = storage.get_label(&label).unwrap();
        assert!(label_item.is_none());
    }

    #[test]
    async fn test_create_new_contact() {
        let test_name = "test_create_new_contact";
        log!("{}", test_name);

        let storage = MemoryStorage::default();

        let contact = create_test_contacts().iter().next().unwrap().1.to_owned();

        let result = storage.create_new_contact(contact.clone());
        assert!(result.is_ok());

        let id = result.unwrap();
        let stored_contact = storage.get_contact(id).unwrap();
        assert_eq!(stored_contact, Some(contact));
    }

    #[test]
    fn test_get_tag_items() {
        let test_name = "test_get_tag_items";
        log!("{}", test_name);

        let mut expected_tag_items = Vec::new();
        let storage = MemoryStorage::default();

        let contacts = create_test_contacts().into_values();
        for contact in contacts {
            let id = storage.create_new_contact(contact.clone()).unwrap();
            expected_tag_items.push(TagItem::Contact((id, contact)));
        }

        let labels = create_test_labels();
        for (label, label_item) in labels {
            storage
                .write_data(get_label_item_key(label.clone()), label_item.clone(), None)
                .unwrap();
            expected_tag_items.push(TagItem::Label((label, label_item)));
        }

        let result = storage.get_tag_items().unwrap();

        // check they have same items
        if result.len() != expected_tag_items.len() {
            panic!("Incorrect tag items length")
        }

        for item in expected_tag_items {
            if !result.contains(&item) {
                panic!("Tag item missing! {item:?}")
            }
        }
    }

    #[test]
    async fn test_labeling_contact_with_address() {
        let test_name = "test_labeling_contact_with_address";
        log!("{test_name}");

        let storage = MemoryStorage::default();

        let contacts = create_test_contacts();
        let contact = contacts.iter().next().unwrap().1.to_owned();
        assert_eq!(contact.last_used, 0);
        let id = storage.create_new_contact(contact.clone()).unwrap();

        let address = Address::from_str(ADDRESS).unwrap().assume_checked();

        storage
            .set_address_labels(address, vec![id.clone()])
            .unwrap();

        // check that the contact was updated
        let contact = storage.get_contact(&id).unwrap().unwrap();
        assert_ne!(contact.last_used, 0)
    }

    #[test]
    async fn test_labeling_contact_with_invoice() {
        let test_name = "test_labeling_contact_with_invoice";
        log!("{test_name}");

        let storage = MemoryStorage::default();

        let contacts = create_test_contacts();
        let contact = contacts.iter().next().unwrap().1.to_owned();
        assert_eq!(contact.last_used, 0);
        let id = storage.create_new_contact(contact.clone()).unwrap();

        let invoice = Bolt11Invoice::from_str(INVOICE).unwrap();

        storage
            .set_invoice_labels(invoice, vec![id.clone()])
            .unwrap();

        // check that the contact was updated
        let contact = storage.get_contact(&id).unwrap().unwrap();
        assert_ne!(contact.last_used, 0)
    }
}


================================================
File: mutiny-core/src/ldkstorage.rs
================================================
use crate::error::{MutinyError, MutinyStorageError};
use crate::fees::MutinyFeeEstimator;
use crate::gossip::PROB_SCORER_KEY;
use crate::keymanager::PhantomKeysManager;
use crate::logging::MutinyLogger;
use crate::messagehandler::BumpChannelClosureTransaction;
use crate::node::Router;
use crate::node::{default_user_config, ChainMonitor};
use crate::nodemanager::ChannelClosure;
use crate::storage::{IndexItem, MutinyStorage, VersionedValue};
use crate::utils;
use crate::utils::{sleep, spawn};
use crate::{chain::MutinyChain, scorer::HubPreferentialScorer};
use anyhow::anyhow;
use bitcoin::hashes::hex::FromHex;
use bitcoin::Network;
use bitcoin::{BlockHash, Transaction};
use esplora_client::AsyncClient;
use futures::{try_join, TryFutureExt};
use futures_util::lock::Mutex;
use hex_conservative::DisplayHex;
use lightning::chain::transaction::OutPoint;
use lightning::chain::{BestBlock, ChannelMonitorUpdateStatus};
use lightning::io::Cursor;
use lightning::ln::channelmanager::{
    self, ChainParameters, ChannelManager as LdkChannelManager, ChannelManagerReadArgs,
};
use lightning::sign::{InMemorySigner, SpendableOutputDescriptor};
use lightning::util::logger::Logger;
use lightning::util::persist::Persister;
use lightning::util::ser::{Readable, ReadableArgs, Writeable};
use lightning::{chain::chainmonitor::Persist, log_trace};
use lightning::{
    chain::channelmonitor::{ChannelMonitor, ChannelMonitorUpdate},
    log_warn,
};
use lightning::{log_debug, log_error};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::io;
use std::sync::atomic::{AtomicU32, Ordering};
use std::sync::Arc;

pub const CHANNEL_MANAGER_KEY: &str = "manager";
pub const MONITORS_PREFIX_KEY: &str = "monitors/";
const CHANNEL_OPENING_PARAMS_PREFIX: &str = "chan_open_params/";
pub const CHANNEL_CLOSURE_PREFIX: &str = "channel_closure/";
pub const CHANNEL_CLOSURE_BUMP_PREFIX: &str = "channel_closure_bump/";
const FAILED_SPENDABLE_OUTPUT_DESCRIPTOR_KEY: &str = "failed_spendable_outputs";

pub(crate) type PhantomChannelManager<S: MutinyStorage> = LdkChannelManager<
    Arc<ChainMonitor<S>>,
    Arc<MutinyChain<S>>,
    Arc<PhantomKeysManager<S>>,
    Arc<PhantomKeysManager<S>>,
    Arc<PhantomKeysManager<S>>,
    Arc<MutinyFeeEstimator<S>>,
    Arc<Router<S>>,
    Arc<MutinyLogger>,
>;

#[derive(Clone)]
pub struct MutinyNodePersister<S: MutinyStorage> {
    node_id: String,
    pub(crate) storage: S,
    manager_version: Arc<AtomicU32>,
    pub(crate) chain_monitor: Arc<Mutex<Option<Arc<ChainMonitor<S>>>>>,
    logger: Arc<MutinyLogger>,
}

pub(crate) struct ReadChannelManager<S: MutinyStorage> {
    pub channel_manager: PhantomChannelManager<S>,
    pub is_restarting: bool,
    pub channel_monitors: Vec<(BlockHash, ChannelMonitor<InMemorySigner>)>,
}

impl<S: MutinyStorage> MutinyNodePersister<S> {
    pub fn new(node_id: String, storage: S, logger: Arc<MutinyLogger>) -> Self {
        MutinyNodePersister {
            node_id,
            storage,
            manager_version: Arc::new(AtomicU32::new(0)),
            chain_monitor: Arc::new(Mutex::new(None)),
            logger,
        }
    }

    #[cfg(test)]
    pub(crate) fn manager_version(&self) -> u32 {
        self.manager_version.load(Ordering::Relaxed)
    }

    fn get_key(&self, key: &str) -> String {
        format!("{}_{}", key, self.node_id)
    }

    pub(crate) fn get_monitor_key(&self, funding_txo: &OutPoint) -> String {
        let key = format!(
            "{MONITORS_PREFIX_KEY}{}_{}",
            funding_txo.txid, funding_txo.index
        );
        self.get_key(&key)
    }

    fn init_persist_monitor<W: Writeable>(
        &self,
        key: String,
        object: &W,
        version: u32,
        update_id: MonitorUpdateIdentifier,
    ) -> ChannelMonitorUpdateStatus {
        let storage = self.storage.clone();
        let chain_monitor = self.chain_monitor.clone();
        let logger = self.logger.clone();
        let object = object.encode();

        spawn(async move {
            // Sleep before persisting to give chance for the manager to be persisted
            sleep(50).await;
            match persist_monitor(storage, key, object, Some(version), logger.clone()) {
                Ok(()) => {
                    log_debug!(logger, "Persisted channel monitor: {update_id:?}");

                    // unwrap is safe, we set it up immediately
                    let chain_monitor = chain_monitor.lock().await;
                    let chain_monitor = chain_monitor.as_ref().unwrap();

                    // these errors are not fatal, so we don't return them just log
                    if let Err(e) = chain_monitor
                        .channel_monitor_updated(update_id.funding_txo, update_id.update_id)
                    {
                        log_error!(
                            logger,
                            "Error notifying chain monitor of channel monitor update: {e:?}"
                        );
                    }
                }
                Err(e) => {
                    log_error!(logger, "Error persisting channel monitor: {e}");
                }
            }
        });

        ChannelMonitorUpdateStatus::InProgress
    }

    // name this param _key so it is not confused with the key
    // that has the concatenated node_id
    fn read_value(&self, _key: &str) -> Result<Vec<u8>, MutinyError> {
        let key = self.get_key(_key);
        match self.storage.get_data(&key) {
            Ok(Some(value)) => Ok(value),
            Ok(None) => Err(MutinyError::read_err(MutinyStorageError::Other(anyhow!(
                "No value found for key: {key}"
            )))),
            Err(e) => Err(e),
        }
    }

    pub fn read_channel_monitors(
        &self,
        keys_manager: Arc<PhantomKeysManager<S>>,
    ) -> Result<Vec<(BlockHash, ChannelMonitor<InMemorySigner>)>, io::Error> {
        // Get all the channel monitor buffers that exist for this node
        let suffix = self.node_id.as_str();
        let channel_monitor_list: HashMap<String, Vec<u8>> = self
            .storage
            .scan(MONITORS_PREFIX_KEY, Some(suffix))
            .map_err(|_| io::ErrorKind::Other)?;

        let res =
            channel_monitor_list
                .into_iter()
                .try_fold(Vec::new(), |mut accum, (_, data)| {
                    let mut buffer = Cursor::new(data);
                    match <(BlockHash, ChannelMonitor<InMemorySigner>)>::read(
                        &mut buffer,
                        (keys_manager.as_ref(), keys_manager.as_ref()),
                    ) {
                        Ok((blockhash, channel_monitor)) => {
                            // if there are no claimable balances, we don't need to watch the channel
                            if !channel_monitor.get_claimable_balances().is_empty() {
                                accum.push((blockhash, channel_monitor));
                            } else {
                                log_debug!(
                                    self.logger,
                                    "Channel monitor {} has no claimable balances, not watching",
                                    channel_monitor.get_funding_txo().0
                                );
                            }
                            Ok(accum)
                        }
                        Err(e) => Err(io::Error::new(
                            io::ErrorKind::InvalidData,
                            format!("Failed to deserialize ChannelMonitor: {e}"),
                        )),
                    }
                })?;

        Ok(res)
    }

    #[allow(clippy::too_many_arguments)]
    pub(crate) async fn read_channel_manager(
        &self,
        network: Network,
        accept_underpaying_htlcs: bool,
        chain_monitor: Arc<ChainMonitor<S>>,
        mutiny_chain: Arc<MutinyChain<S>>,
        fee_estimator: Arc<MutinyFeeEstimator<S>>,
        mutiny_logger: Arc<MutinyLogger>,
        keys_manager: Arc<PhantomKeysManager<S>>,
        router: Arc<Router<S>>,
        channel_monitors: Vec<(BlockHash, ChannelMonitor<InMemorySigner>)>,
        esplora: &AsyncClient,
    ) -> Result<ReadChannelManager<S>, MutinyError> {
        log_debug!(mutiny_logger, "Reading channel manager from storage");
        let key = self.get_key(CHANNEL_MANAGER_KEY);
        match self.storage.get_data::<VersionedValue>(&key) {
            Ok(Some(versioned_value)) => {
                log_trace!(
                    mutiny_logger,
                    "Got versioned value: {}",
                    versioned_value.version
                );
                // new encoding is in hex
                let hex: String = serde_json::from_value(versioned_value.value.clone())?;
                let bytes = FromHex::from_hex(&hex)?;
                let res = Self::parse_channel_manager(
                    bytes,
                    accept_underpaying_htlcs,
                    chain_monitor,
                    mutiny_chain,
                    fee_estimator,
                    mutiny_logger.clone(),
                    keys_manager,
                    router,
                    channel_monitors,
                )?;

                log_trace!(mutiny_logger, "parsed channel manager, swapping it");

                self.manager_version
                    .swap(versioned_value.version, Ordering::SeqCst);

                Ok(res)
            }
            Ok(None) => {
                // no key manager stored, start a new one
                log_debug!(mutiny_logger, "Creating a new channel manager");

                Self::create_new_channel_manager(
                    network,
                    accept_underpaying_htlcs,
                    chain_monitor,
                    mutiny_chain,
                    fee_estimator,
                    mutiny_logger,
                    keys_manager,
                    router,
                    channel_monitors,
                    esplora,
                )
                .await
            }
            Err(_) => {
                // old encoding with no version number and as an array of numbers
                log_warn!(
                    mutiny_logger,
                    "A very old encoding of channel manager with no version number, parsing it"
                );

                let bytes = self.read_value(CHANNEL_MANAGER_KEY)?;
                Self::parse_channel_manager(
                    bytes,
                    accept_underpaying_htlcs,
                    chain_monitor,
                    mutiny_chain,
                    fee_estimator,
                    mutiny_logger,
                    keys_manager,
                    router,
                    channel_monitors,
                )
            }
        }
    }

    #[allow(clippy::too_many_arguments)]
    fn parse_channel_manager(
        bytes: Vec<u8>,
        accept_underpaying_htlcs: bool,
        chain_monitor: Arc<ChainMonitor<S>>,
        mutiny_chain: Arc<MutinyChain<S>>,
        fee_estimator: Arc<MutinyFeeEstimator<S>>,
        mutiny_logger: Arc<MutinyLogger>,
        keys_manager: Arc<PhantomKeysManager<S>>,
        router: Arc<Router<S>>,
        mut channel_monitors: Vec<(BlockHash, ChannelMonitor<InMemorySigner>)>,
    ) -> Result<ReadChannelManager<S>, MutinyError> {
        log_debug!(mutiny_logger, "Parsing channel manager");

        let mut channel_monitor_mut_references = Vec::new();
        for (_, channel_monitor) in channel_monitors.iter_mut() {
            channel_monitor_mut_references.push(channel_monitor);
        }
        let read_args = ChannelManagerReadArgs::new(
            keys_manager.clone(),
            keys_manager.clone(),
            keys_manager,
            fee_estimator,
            chain_monitor,
            mutiny_chain,
            router,
            mutiny_logger.clone(),
            default_user_config(accept_underpaying_htlcs),
            channel_monitor_mut_references,
        );

        log_trace!(mutiny_logger, "Read channel manager arguments");
        let mut readable_kv_value = Cursor::new(bytes);
        let Ok((_, channel_manager)) =
            <(BlockHash, PhantomChannelManager<S>)>::read(&mut readable_kv_value, read_args)
        else {
            log_error!(mutiny_logger, "Could not read channel manager");
            return Err(MutinyError::ReadError {
                source: MutinyStorageError::Other(anyhow!("could not read manager")),
            });
        };

        log_debug!(mutiny_logger, "Read channel manager okay");
        Ok(ReadChannelManager {
            channel_manager,
            is_restarting: true,
            channel_monitors,
        })
    }

    #[allow(clippy::too_many_arguments)]
    pub(crate) async fn create_new_channel_manager(
        network: Network,
        accept_underpaying_htlcs: bool,
        chain_monitor: Arc<ChainMonitor<S>>,
        mutiny_chain: Arc<MutinyChain<S>>,
        fee_estimator: Arc<MutinyFeeEstimator<S>>,
        mutiny_logger: Arc<MutinyLogger>,
        keys_manager: Arc<PhantomKeysManager<S>>,
        router: Arc<Router<S>>,
        channel_monitors: Vec<(BlockHash, ChannelMonitor<InMemorySigner>)>,
        esplora: &AsyncClient,
    ) -> Result<ReadChannelManager<S>, MutinyError> {
        // if regtest, we don't need to get the tip hash and can
        // just use genesis, this also lets us use regtest in tests
        let best_block = if network == Network::Regtest {
            BestBlock::from_network(network)
        } else {
            let height_future = esplora
                .get_height()
                .map_err(|_| MutinyError::ChainAccessFailed);
            let hash_future = esplora
                .get_tip_hash()
                .map_err(|_| MutinyError::ChainAccessFailed);
            let (height, hash) = try_join!(height_future, hash_future)?;
            BestBlock::new(hash, height)
        };
        let chain_params = ChainParameters {
            network,
            best_block,
        };

        let fresh_channel_manager: PhantomChannelManager<S> = channelmanager::ChannelManager::new(
            fee_estimator,
            chain_monitor,
            mutiny_chain,
            router,
            mutiny_logger,
            keys_manager.clone(),
            keys_manager.clone(),
            keys_manager,
            default_user_config(accept_underpaying_htlcs),
            chain_params,
            utils::now().as_secs() as u32,
        );

        Ok(ReadChannelManager {
            channel_manager: fresh_channel_manager,
            is_restarting: false,
            channel_monitors,
        })
    }

    pub(crate) fn persist_channel_closure(
        &self,
        user_channel_id: u128,
        closure: ChannelClosure,
    ) -> Result<(), MutinyError> {
        let key = self.get_key(&format!(
            "{CHANNEL_CLOSURE_PREFIX}{}",
            user_channel_id.to_be_bytes().to_lower_hex_string()
        ));

        let force_close_spend_delay = self
            .storage
            .get_channel_closure(&key)?
            .and_then(|c| c.force_close_spend_delay);
        let mut closure = closure;
        closure.set_force_close_spend_delay(force_close_spend_delay);

        self.storage
            .write_data(key.clone(), &closure, Some(closure.timestamp as u32))?;

        let index = self.storage.activity_index();
        let mut index = index.try_write()?;
        index.retain(|i| i.key != key); // remove old version
        index.insert(IndexItem {
            timestamp: Some(closure.timestamp),
            key,
        });

        Ok(())
    }

    pub(crate) fn get_channel_closure(
        &self,
        user_channel_id: u128,
    ) -> Result<Option<ChannelClosure>, MutinyError> {
        let key = self.get_key(&format!(
            "{CHANNEL_CLOSURE_PREFIX}{}",
            user_channel_id.to_be_bytes().to_lower_hex_string()
        ));
        self.storage.get_channel_closure(&key)
    }

    pub(crate) fn list_channel_closures(&self) -> Result<Vec<ChannelClosure>, MutinyError> {
        let suffix = format!("_{}", self.node_id);
        let map: HashMap<String, ChannelClosure> =
            self.storage.scan(CHANNEL_CLOSURE_PREFIX, Some(&suffix))?;

        map.into_iter()
            .map(|(key, mut closure)| closure.set_user_channel_id_from_key(&key).map(|_| closure))
            .collect::<Result<Vec<_>, _>>()
    }

    pub(crate) fn persist_channel_closure_bumping_event(
        &self,
        closure: &BumpChannelClosureTransaction,
    ) -> Result<(), MutinyError> {
        let key = self.get_key(&format!(
            "{CHANNEL_CLOSURE_BUMP_PREFIX}{}",
            closure.channel_id
        ));
        self.storage
            .write_data(key.clone(), closure, Some(closure.timestamp as u32))?;

        let index = self.storage.activity_index();
        let mut index = index.try_write()?;
        index.retain(|i| i.key != key); // remove old version
        index.insert(IndexItem {
            timestamp: Some(closure.timestamp),
            key,
        });

        Ok(())
    }

    /// Persists the failed spendable outputs to storage.
    /// Previously failed spendable outputs are not overwritten.
    ///
    /// This is used to retry spending them later.
    pub fn persist_failed_spendable_outputs(
        &self,
        failed: Vec<SpendableOutputDescriptor>,
    ) -> anyhow::Result<()> {
        let key = self.get_key(FAILED_SPENDABLE_OUTPUT_DESCRIPTOR_KEY);

        // get the currently stored descriptors encoded as hex
        // if there are none, use an empty vector
        let mut descriptors: Vec<String> = self.storage.get_data(&key)?.unwrap_or_default();

        // convert the failed descriptors to hex
        let failed_hex: Vec<String> = failed
            .into_iter()
            .map(|desc| desc.encode().to_lower_hex_string())
            .collect();

        // add the new descriptors
        descriptors.extend(failed_hex);

        self.storage.write_data(key, descriptors, None)?;

        Ok(())
    }

    /// Persists the failed spendable outputs to storage.
    /// Previously failed spendable outputs are overwritten.
    ///
    /// This is used to retry spending them later.
    pub fn set_failed_spendable_outputs(
        &self,
        descriptors: Vec<SpendableOutputDescriptor>,
    ) -> anyhow::Result<()> {
        let key = self.get_key(FAILED_SPENDABLE_OUTPUT_DESCRIPTOR_KEY);

        // convert the failed descriptors to hex
        let descriptors_hex: Vec<String> = descriptors
            .into_iter()
            .map(|desc| desc.encode().to_lower_hex_string())
            .collect();

        self.storage.write_data(key, descriptors_hex, None)?;

        Ok(())
    }

    /// Retrieves the failed spendable outputs from storage
    pub fn get_failed_spendable_outputs(&self) -> anyhow::Result<Vec<SpendableOutputDescriptor>> {
        let key = self.get_key(FAILED_SPENDABLE_OUTPUT_DESCRIPTOR_KEY);

        // get the currently stored descriptors encoded as hex
        // if there are none, use an empty vector
        let strings: Vec<String> = self.storage.get_data(key)?.unwrap_or_default();

        // convert the hex strings to descriptors
        let mut descriptors = vec![];
        for desc in strings {
            let bytes =
                Vec::from_hex(&desc).map_err(|_| anyhow!("failed to decode descriptor {desc}"))?;
            let descriptor = SpendableOutputDescriptor::read(&mut Cursor::new(bytes))
                .map_err(|_| anyhow!("failed to read descriptor from storage: {desc}"))?;
            descriptors.push(descriptor);
        }

        Ok(descriptors)
    }

    /// Clears the failed spendable outputs from storage
    /// This is used when the failed spendable outputs have been successfully spent
    pub fn clear_failed_spendable_outputs(&self) -> anyhow::Result<()> {
        let key = self.get_key(FAILED_SPENDABLE_OUTPUT_DESCRIPTOR_KEY);
        self.storage.delete(&[key])?;

        Ok(())
    }

    pub(crate) fn persist_channel_open_params(
        &self,
        id: u128,
        params: ChannelOpenParams,
    ) -> Result<(), MutinyError> {
        let key = self.get_key(&channel_open_params_key(id));
        self.storage.write_data(key, params, None)
    }

    pub(crate) fn get_channel_open_params(
        &self,
        id: u128,
    ) -> Result<Option<ChannelOpenParams>, MutinyError> {
        let key = self.get_key(&channel_open_params_key(id));
        self.storage.get_data(key)
    }

    pub(crate) fn delete_channel_open_params(&self, id: u128) -> Result<(), MutinyError> {
        let key = self.get_key(&channel_open_params_key(id));
        self.storage.delete(&[key])
    }
}

fn channel_open_params_key(id: u128) -> String {
    format!("{CHANNEL_OPENING_PARAMS_PREFIX}{id}")
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub(crate) struct ChannelOpenParams {
    pub(crate) sats_per_vbyte: u64,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub(crate) absolute_fee: Option<u64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub(crate) utxos: Option<Vec<bitcoin::OutPoint>>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub(crate) labels: Option<Vec<String>>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub(crate) opening_tx: Option<Transaction>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub(crate) failure_reason: Option<String>,
}

impl ChannelOpenParams {
    pub fn new(sats_per_vbyte: u64) -> Self {
        Self {
            sats_per_vbyte,
            absolute_fee: None,
            utxos: None,
            labels: None,
            opening_tx: None,
            failure_reason: None,
        }
    }

    pub fn new_sweep(
        sats_per_vbyte: u64,
        absolute_fee: u64,
        utxos: Vec<bitcoin::OutPoint>,
    ) -> Self {
        Self {
            sats_per_vbyte,
            absolute_fee: Some(absolute_fee),
            utxos: Some(utxos),
            labels: None,
            opening_tx: None,
            failure_reason: None,
        }
    }
}

impl<'a, S: MutinyStorage>
    Persister<
        'a,
        Arc<PhantomChannelManager<S>>,
        Arc<MutinyLogger>,
        Arc<utils::Mutex<HubPreferentialScorer>>,
    > for MutinyNodePersister<S>
{
    fn persist_manager(
        &self,
        channel_manager: &Arc<PhantomChannelManager<S>>,
    ) -> Result<(), lightning::io::Error> {
        let old = self.manager_version.fetch_add(1, Ordering::SeqCst);
        let version = old + 1;
        let key = self.get_key(CHANNEL_MANAGER_KEY);

        let value = VersionedValue {
            version,
            value: serde_json::to_value(channel_manager.encode().to_lower_hex_string()).unwrap(),
        };

        self.storage
            .write_data(key, value, Some(version))
            .map_err(|_| lightning::io::ErrorKind::Other.into())
    }

    fn persist_graph(
        &self,
        _network_graph: &lightning::routing::gossip::NetworkGraph<Arc<MutinyLogger>>,
    ) -> Result<(), lightning::io::Error> {
        Ok(())
    }

    fn persist_scorer(
        &self,
        scorer: &Arc<utils::Mutex<HubPreferentialScorer>>,
    ) -> Result<(), lightning::io::Error> {
        let scorer_str = scorer.encode().to_lower_hex_string();
        self.storage
            .write_data(PROB_SCORER_KEY.to_string(), scorer_str, None)
            .map_err(|_| lightning::io::ErrorKind::Other.into())
    }
}

impl<S: MutinyStorage> Persist<InMemorySigner> for MutinyNodePersister<S> {
    fn persist_new_channel(
        &self,
        funding_txo: OutPoint,
        monitor: &ChannelMonitor<InMemorySigner>,
    ) -> ChannelMonitorUpdateStatus {
        let key = self.get_monitor_key(&funding_txo);

        let update_id = monitor.get_latest_update_id();
        debug_assert!(update_id == utils::get_monitor_version(&monitor.encode()));

        // safely convert u64 to u32
        let version = if update_id >= u32::MAX as u64 {
            u32::MAX
        } else {
            update_id as u32
        };

        let update_id = MonitorUpdateIdentifier {
            funding_txo,
            update_id,
        };

        log_debug!(
            self.logger,
            "persist_new_channel: (channel_id, latest_update_id, version, is_fully_resolved, claimable_balances, current_best_block): {:?}",
            (
                monitor.channel_id().to_string(),
                monitor.get_latest_update_id(),
                version,
                monitor.is_fully_resolved(self.logger.as_ref()),
                monitor.get_claimable_balances(),
                monitor.current_best_block(),
            )
        );

        self.init_persist_monitor(key, monitor, version, update_id)
    }

    fn update_persisted_channel(
        &self,
        funding_txo: OutPoint,
        _update: Option<&ChannelMonitorUpdate>,
        monitor: &ChannelMonitor<InMemorySigner>,
    ) -> ChannelMonitorUpdateStatus {
        let key = self.get_monitor_key(&funding_txo);
        let update_id = monitor.get_latest_update_id();
        debug_assert!(update_id == utils::get_monitor_version(&monitor.encode()));

        // safely convert u64 to u32
        let version = if update_id >= u32::MAX as u64 {
            u32::MAX
        } else {
            update_id as u32
        };

        let update_id = MonitorUpdateIdentifier {
            funding_txo,
            update_id,
        };

        log_debug!(
            self.logger,
            "update_persisted_channel: (channel_id, latest_update_id, version, is_fully_resolved, claimable_balances, current_best_block): {:?}",
            (
                monitor.channel_id(),
                monitor.get_latest_update_id(),
                version,
                monitor.is_fully_resolved(self.logger.as_ref()),
                monitor.get_claimable_balances(),
                monitor.current_best_block()
            )
        );

        self.init_persist_monitor(key, monitor, version, update_id)
    }

    fn archive_persisted_channel(&self, _channel_funding_outpoint: OutPoint) {
        // TODO
    }
}

#[derive(Debug, Clone)]
pub struct MonitorUpdateIdentifier {
    pub funding_txo: OutPoint,
    pub update_id: u64,
}

pub(crate) fn persist_monitor(
    storage: impl MutinyStorage,
    key: String,
    object: Vec<u8>,
    version: Option<u32>,
    logger: Arc<MutinyLogger>,
) -> Result<(), lightning::io::Error> {
    let res = storage.write_data(key.clone(), object, version);

    res.map_err(|e| {
        match e {
            MutinyError::PersistenceFailed { source } => {
                log_error!(logger, "Persistence failed on {key}: {source}");
            }
            _ => {
                log_error!(logger, "Error storing {key}: {e}");
            }
        };
        lightning::io::ErrorKind::Other.into()
    })
}

#[cfg(test)]
mod test {
    use crate::{
        event::PaymentInfo,
        node::NetworkGraph,
        storage::{list_payment_info, MemoryStorage},
        PrivacyLevel,
    };
    use crate::{
        event::{HTLCStatus, MillisatAmount},
        scorer::HubPreferentialScorer,
    };
    use crate::{keymanager::create_keys_manager, scorer::ProbScorer};
    use crate::{node::scoring_params, storage::persist_payment_info};
    use crate::{onchain::OnChainWallet, storage::read_payment_info};
    use bip39::Mnemonic;
    use bitcoin::hashes::Hash;
    use bitcoin::secp256k1::PublicKey;
    use bitcoin::Txid;
    use bitcoin::{bip32::Xpriv, TxOut};
    use esplora_client::Builder;
    use lightning::routing::scoring::ProbabilisticScoringDecayParameters;

    use lightning::{ln::PaymentHash, routing::router::DefaultRouter};
    use lightning_transaction_sync::EsploraSyncClient;
    use std::str::FromStr;
    use std::sync::atomic::AtomicBool;
    use uuid::Uuid;
    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};

    use super::*;

    use crate::test_utils::*;

    wasm_bindgen_test_configure!(run_in_browser);

    fn get_test_persister() -> MutinyNodePersister<MemoryStorage> {
        let id = Uuid::new_v4().to_string();
        let storage = MemoryStorage::default();
        MutinyNodePersister::new(id, storage, Arc::new(MutinyLogger::default()))
    }

    #[test]
    fn test_get_monitor_key() {
        let test_name = "test_get_monitor_key";
        log!("{}", test_name);

        let persister = get_test_persister();
        let outpoint = OutPoint {
            txid: Txid::from_str(
                "465ed5be53d04fde66c9418ff14a5f2267723810176c9212b722e542dc1afb1b",
            )
            .unwrap(),
            index: 0,
        };
        let key = persister.get_monitor_key(&outpoint);

        assert_eq!(
            key,
            format!(
                "monitors/465ed5be53d04fde66c9418ff14a5f2267723810176c9212b722e542dc1afb1b_0_{}",
                persister.node_id
            )
        );
    }

    #[test]
    fn test_persist_payment_info() {
        let test_name = "test_persist_payment_info";
        log!("{}", test_name);

        let persister = get_test_persister();
        let preimage = [1; 32];
        let payment_hash = PaymentHash([0; 32]);
        let pubkey = PublicKey::from_str(
            "02465ed5be53d04fde66c9418ff14a5f2267723810176c9212b722e542dc1afb1b",
        )
        .unwrap();

        let payment_info = PaymentInfo {
            preimage: Some(preimage),
            status: HTLCStatus::Succeeded,
            privacy_level: PrivacyLevel::NotAvailable,
            amt_msat: MillisatAmount(Some(420)),
            fee_paid_msat: None,
            bolt11: None,
            payee_pubkey: Some(pubkey),
            secret: None,
            last_update: utils::now().as_secs(),
        };
        let result = persist_payment_info(&persister.storage, &payment_hash.0, &payment_info, true);
        assert!(result.is_ok());

        let result = read_payment_info(
            &persister.storage,
            &payment_hash.0,
            true,
            &MutinyLogger::default(),
        );

        assert!(result.is_some());
        assert_eq!(result.clone().unwrap().preimage, Some(preimage));
        assert_eq!(result.unwrap().status, HTLCStatus::Succeeded);

        let list = list_payment_info(&persister.storage, true).unwrap();
        assert_eq!(list.len(), 1);
        assert_eq!(list[0].0, payment_hash);
        assert_eq!(list[0].1.preimage, Some(preimage));

        let result = read_payment_info(
            &persister.storage,
            &payment_hash.0,
            true,
            &MutinyLogger::default(),
        );

        assert!(result.is_some());
        assert_eq!(result.clone().unwrap().preimage, Some(preimage));
        assert_eq!(result.unwrap().status, HTLCStatus::Succeeded);

        let list = list_payment_info(&persister.storage, true).unwrap();
        assert_eq!(list.len(), 1);
        assert_eq!(list[0].0, payment_hash);
        assert_eq!(list[0].1.preimage, Some(preimage));
    }

    #[test]
    fn test_persist_channel_closure() {
        let test_name = "test_persist_channel_closure";
        log!("{}", test_name);

        let persister = get_test_persister();

        let user_channel_id: u128 = 123456789;
        let closure = ChannelClosure {
            user_channel_id: Some(user_channel_id.to_be_bytes()),
            channel_id: Some([1; 32]),
            node_id: None,
            reason: "This is a test.".to_string(),
            timestamp: utils::now().as_secs(),
            channel_funding_txo: None,
            force_close_spend_delay: None,
        };
        let result = persister.persist_channel_closure(user_channel_id, closure.clone());
        assert!(result.is_ok());

        let result = persister.list_channel_closures().unwrap();
        assert_eq!(result, vec![closure.clone()]);

        let result = persister.get_channel_closure(user_channel_id).unwrap();
        assert_eq!(result, Some(closure));
    }

    #[test]
    fn test_persist_spendable_output_descriptor() {
        let test_name = "test_persist_spendable_output_descriptor";
        log!("{}", test_name);

        let persister = get_test_persister();

        let static_output_0 = SpendableOutputDescriptor::StaticOutput {
            outpoint: OutPoint {
                txid: Txid::all_zeros(),
                index: 0,
            },
            output: TxOut::NULL,
            channel_keys_id: None,
        };
        let result = persister.persist_failed_spendable_outputs(vec![static_output_0.clone()]);
        assert!(result.is_ok());

        let result = persister.get_failed_spendable_outputs().unwrap();
        assert_eq!(result, vec![static_output_0.clone()]);

        let static_output_1 = SpendableOutputDescriptor::StaticOutput {
            outpoint: OutPoint {
                txid: Txid::all_zeros(),
                index: 1,
            },
            output: TxOut::NULL,
            channel_keys_id: None,
        };
        let result = persister.persist_failed_spendable_outputs(vec![static_output_1.clone()]);
        assert!(result.is_ok());

        let result = persister.get_failed_spendable_outputs().unwrap();
        assert_eq!(result, vec![static_output_0, static_output_1]);

        let result = persister.clear_failed_spendable_outputs();
        assert!(result.is_ok());

        let result = persister.get_failed_spendable_outputs().unwrap();
        assert!(result.is_empty());
    }

    #[test]
    async fn test_upgrade_channel_manager() {
        let test_name = "test_channel_manager";
        log!("{}", test_name);

        let mnemonic = Mnemonic::from_str(
            "shallow car virus tree add switch spring bulb midnight license modify junior",
        )
        .unwrap();

        let network = Network::Signet;

        let persister = Arc::new(get_test_persister());
        // encode old version into persister
        persister
            .storage
            .write_data(
                persister.get_key(CHANNEL_MANAGER_KEY),
                MANAGER_BYTES.to_vec(),
                None,
            )
            .unwrap();

        // need to init a bunch of stuff to read a channel manager

        let logger = Arc::new(MutinyLogger::default());

        let stop = Arc::new(AtomicBool::new(false));
        let xpriv = Xpriv::new_master(network, &mnemonic.to_seed("")).unwrap();

        let esplora_server_url = "https://mutinynet.com/api/".to_string();
        let esplora = Arc::new(Builder::new(&esplora_server_url).build_async().unwrap());
        let fees = Arc::new(MutinyFeeEstimator::new(
            persister.storage.clone(),
            esplora.clone(),
            logger.clone(),
        ));
        let tx_sync = Arc::new(EsploraSyncClient::new(esplora_server_url, logger.clone()));

        let wallet = Arc::new(
            OnChainWallet::new(
                xpriv,
                persister.storage.clone(),
                network,
                esplora.clone(),
                fees.clone(),
                stop,
                logger.clone(),
                None,
            )
            .unwrap(),
        );

        let km = Arc::new(create_keys_manager(wallet.clone(), xpriv, 0, logger.clone()).unwrap());

        let chain = Arc::new(MutinyChain::new(tx_sync, wallet, logger.clone()));

        let network_graph = Arc::new(NetworkGraph::new(network, logger.clone()));
        let scorer = ProbScorer::new(
            ProbabilisticScoringDecayParameters::default(),
            network_graph.clone(),
            logger.clone(),
        );
        let scorer = HubPreferentialScorer::new(scorer);

        // init chain monitor
        let chain_monitor: Arc<ChainMonitor<MemoryStorage>> = Arc::new(ChainMonitor::new(
            Some(chain.tx_sync.clone()),
            chain.clone(),
            logger.clone(),
            fees.clone(),
            persister.clone(),
        ));

        let router: Arc<Router<_>> = Arc::new(DefaultRouter::new(
            network_graph,
            logger.clone(),
            km.clone(),
            Arc::new(utils::Mutex::new(scorer)),
            scoring_params(),
        ));

        // make sure it correctly reads
        let read = persister
            .read_channel_manager(
                network,
                false,
                chain_monitor.clone(),
                chain.clone(),
                fees.clone(),
                logger.clone(),
                km.clone(),
                router.clone(),
                vec![],
                &esplora,
            )
            .await
            .unwrap();
        // starts at version 0
        assert_eq!(persister.manager_version(), 0);
        assert!(read.is_restarting);

        // persist, should be new version
        persister
            .persist_manager(&Arc::new(read.channel_manager))
            .unwrap();
        assert_eq!(persister.manager_version(), 1);

        // make sure we can read with new encoding
        let read = persister
            .read_channel_manager(
                network,
                false,
                chain_monitor,
                chain.clone(),
                fees.clone(),
                logger.clone(),
                km,
                router,
                vec![],
                &esplora,
            )
            .await
            .unwrap();

        // should be same version
        assert_eq!(persister.manager_version(), 1);
        assert!(read.is_restarting);
    }
}


================================================
File: mutiny-core/src/lib.rs
================================================
#![crate_name = "mutiny_core"]
// wasm is considered "extra_unused_type_parameters"
#![allow(
    async_fn_in_trait,
    incomplete_features,
    clippy::extra_unused_type_parameters,
    clippy::arc_with_non_send_sync,
    type_alias_bounds
)]
extern crate core;

pub mod authclient;
pub mod authmanager;
mod chain;
pub mod encrypt;
pub mod error;
pub mod event;
mod fees;
mod gossip;
mod key;
mod keymanager;
pub mod labels;
mod ldkstorage;
pub mod logging;
pub mod lsp;
pub mod messagehandler;
mod networking;
mod node;
pub mod nodemanager;
mod onchain;
mod peermanager;
pub mod scorer;
pub mod storage;
mod subscription;
pub mod utils;
pub mod vss;

#[cfg(test)]
mod test_utils;

use crate::authmanager::AuthManager;
use crate::error::MutinyError;
pub use crate::gossip::{GOSSIP_SYNC_TIME_KEY, NETWORK_GRAPH_KEY, PROB_SCORER_KEY};
pub use crate::keymanager::generate_seed;
pub use crate::ldkstorage::{
    CHANNEL_CLOSURE_BUMP_PREFIX, CHANNEL_CLOSURE_PREFIX, CHANNEL_MANAGER_KEY, MONITORS_PREFIX_KEY,
};
use crate::nodemanager::NodeManager;
use crate::nodemanager::{ChannelClosure, MutinyBip21RawMaterials};
use crate::storage::get_invoice_by_hash;
use crate::utils::sleep;
use crate::utils::spawn;
use crate::{authclient::MutinyAuthClient, logging::MutinyLogger};
use crate::{
    event::{HTLCStatus, MillisatAmount, PaymentInfo},
    onchain::FULL_SYNC_STOP_GAP,
};
use crate::{labels::LabelStorage, nodemanager::NodeBalance};
use crate::{logging::LOGGING_KEY, nodemanager::NodeManagerBuilder};
use crate::{
    onchain::get_esplora_url,
    storage::{
        get_payment_hash_from_key, get_transaction_details, list_payment_info, IndexItem,
        MutinyStorage, DEVICE_ID_KEY, EXPECTED_NETWORK_KEY, NEED_FULL_SYNC_KEY, ONCHAIN_PREFIX,
        PAYMENT_INBOUND_PREFIX_KEY, PAYMENT_OUTBOUND_PREFIX_KEY, TRANSACTION_DETAILS_PREFIX_KEY,
    },
};
use anyhow::Context;
use bdk_chain::ConfirmationTime;
use bip39::Mnemonic;
pub use bitcoin;
use bitcoin::consensus::encode::serialize_hex;
use bitcoin::secp256k1::PublicKey;
use bitcoin::{bip32::Xpriv, Transaction};
use bitcoin::{hashes::sha256, Network, Txid};
use bitcoin::{hashes::Hash, Address};

use futures_util::lock::Mutex;
use hex_conservative::{DisplayHex, FromHex};
use itertools::Itertools;
pub use lightning;
use lightning::chain::BestBlock;
use lightning::ln::PaymentHash;
use lightning::util::logger::Logger;
use lightning::{log_debug, log_error, log_info, log_trace, log_warn};
pub use lightning_invoice;
use lightning_invoice::{Bolt11Invoice, Bolt11InvoiceDescription};

use messagehandler::CommonLnEventCallback;
use serde::{Deserialize, Serialize};
use utils::{spawn_with_handle, StopHandle};

use std::collections::HashMap;
use std::collections::HashSet;
use std::str::FromStr;
use std::sync::Arc;
use std::time::Duration;
#[cfg(not(target_arch = "wasm32"))]
use std::time::Instant;

#[cfg(target_arch = "wasm32")]
use web_time::Instant;

#[cfg(test)]
use mockall::{automock, predicate::*};

pub const DEVICE_LOCK_INTERVAL_SECS: u64 = 5;
const BITCOIN_PRICE_CACHE_SEC: u64 = 300;
const DEFAULT_PAYMENT_TIMEOUT: u64 = 30;
const DUST_LIMIT: u64 = 546;

#[cfg_attr(test, automock)]
pub trait InvoiceHandler {
    fn logger(&self) -> &MutinyLogger;
    fn skip_hodl_invoices(&self) -> bool;
    fn get_network(&self) -> Network;
    async fn get_best_block(&self) -> Result<BestBlock, MutinyError>;
    async fn lookup_payment(&self, payment_hash: &[u8; 32]) -> Option<MutinyInvoice>;
    async fn pay_invoice(
        &self,
        invoice: &Bolt11Invoice,
        amt_sats: Option<u64>,
        labels: Vec<String>,
    ) -> Result<MutinyInvoice, MutinyError>;
    async fn create_invoice(
        &self,
        amount: Option<u64>,
        labels: Vec<String>,
        expiry_delta_secs: Option<u32>,
    ) -> Result<MutinyInvoice, MutinyError>;
}

pub struct LnUrlParams {
    pub max: u64,
    pub min: u64,
    pub tag: String,
}

#[derive(Copy, Clone)]
pub struct MutinyBalance {
    pub confirmed: u64,
    pub unconfirmed: u64,
    pub lightning: u64,
    pub closing: u64,
}

impl MutinyBalance {
    fn new(ln_balance: NodeBalance) -> Self {
        Self {
            confirmed: ln_balance.confirmed,
            unconfirmed: ln_balance.unconfirmed,
            lightning: ln_balance.lightning,
            closing: ln_balance.closing,
        }
    }
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, Eq)]
pub enum ActivityItem {
    OnChain(TransactionDetails),
    Lightning(Box<MutinyInvoice>),
    ChannelClosed(ChannelClosure),
}

/// A wallet transaction
#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, Eq)]
pub struct TransactionDetails {
    /// Optional transaction
    pub transaction: Option<Transaction>,
    /// Transaction id
    pub txid: Option<Txid>,
    /// Internal id before a transaction id is created
    pub internal_id: Txid,
    /// Received value (sats)
    /// Sum of owned outputs of this transaction.
    pub received: u64,
    /// Sent value (sats)
    /// Sum of owned inputs of this transaction.
    pub sent: u64,
    /// Fee value in sats if it was available.
    pub fee: Option<u64>,
    /// If the transaction is confirmed, contains height and Unix timestamp of the block containing the
    /// transaction, unconfirmed transaction contains `None`.
    pub confirmation_time: ConfirmationTime,
    /// Labels associated with this transaction
    pub labels: Vec<String>,
}

impl PartialOrd for TransactionDetails {
    fn partial_cmp(&self, other: &Self) -> Option<core::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for TransactionDetails {
    fn cmp(&self, other: &Self) -> core::cmp::Ordering {
        match (self.confirmation_time, other.confirmation_time) {
            (ConfirmationTime::Confirmed { .. }, ConfirmationTime::Confirmed { .. }) => self
                .confirmation_time
                .cmp(&self.confirmation_time)
                .then_with(|| self.txid.cmp(&other.txid)),
            (ConfirmationTime::Confirmed { .. }, ConfirmationTime::Unconfirmed { .. }) => {
                core::cmp::Ordering::Less
            }
            (ConfirmationTime::Unconfirmed { .. }, ConfirmationTime::Confirmed { .. }) => {
                core::cmp::Ordering::Greater
            }
            (
                ConfirmationTime::Unconfirmed { last_seen: a },
                ConfirmationTime::Unconfirmed { last_seen: b },
            ) => a.cmp(&b).then_with(|| self.txid.cmp(&other.txid)),
        }
    }
}

impl ActivityItem {
    pub fn last_updated(&self) -> Option<u64> {
        match self {
            ActivityItem::OnChain(t) => match t.confirmation_time {
                ConfirmationTime::Confirmed { time, .. } => Some(time),
                ConfirmationTime::Unconfirmed { .. } => None,
            },
            ActivityItem::Lightning(i) => match i.status {
                HTLCStatus::Succeeded => Some(i.last_updated),
                HTLCStatus::Failed => Some(i.last_updated),
                HTLCStatus::Pending | HTLCStatus::InFlight => None,
            },
            ActivityItem::ChannelClosed(c) => Some(c.timestamp),
        }
    }

    pub fn labels(&self) -> Vec<String> {
        match self {
            ActivityItem::OnChain(t) => t.labels.clone(),
            ActivityItem::Lightning(i) => i.labels.clone(),
            ActivityItem::ChannelClosed(_) => vec![],
        }
    }

    pub fn is_channel_open(&self) -> bool {
        match self {
            ActivityItem::OnChain(onchain) => {
                onchain.labels.iter().any(|l| l.contains("LN Channel:"))
            }
            ActivityItem::Lightning(_) => false,
            ActivityItem::ChannelClosed(_) => false,
        }
    }
}

impl PartialOrd for ActivityItem {
    fn partial_cmp(&self, other: &Self) -> Option<core::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for ActivityItem {
    fn cmp(&self, other: &Self) -> core::cmp::Ordering {
        // We want None to be greater than Some because those are pending transactions
        // so those should be at the top of the list
        let sort = match (self.last_updated(), other.last_updated()) {
            (Some(self_time), Some(other_time)) => self_time.cmp(&other_time),
            (Some(_), None) => core::cmp::Ordering::Less,
            (None, Some(_)) => core::cmp::Ordering::Greater,
            (None, None) => {
                // if both are none, do lightning first
                match (self, other) {
                    (ActivityItem::Lightning(_), ActivityItem::OnChain(_)) => {
                        core::cmp::Ordering::Greater
                    }
                    (ActivityItem::OnChain(_), ActivityItem::Lightning(_)) => {
                        core::cmp::Ordering::Less
                    }
                    (ActivityItem::Lightning(l1), ActivityItem::Lightning(l2)) => {
                        // compare lightning by expire time
                        l1.expire.cmp(&l2.expire)
                    }
                    (ActivityItem::OnChain(o1), ActivityItem::OnChain(o2)) => {
                        // compare onchain by confirmation time (which will be last seen for unconfirmed)
                        o1.confirmation_time.cmp(&o2.confirmation_time)
                    }
                    _ => core::cmp::Ordering::Equal,
                }
            }
        };

        // if the sort is equal, sort by serialization so we have a stable sort
        sort.then_with(|| {
            serde_json::to_string(self)
                .unwrap()
                .cmp(&serde_json::to_string(other).unwrap())
        })
    }
}

/// Privacy Level for a payment
#[derive(Debug, Clone, Copy, Serialize, Deserialize, Eq, PartialEq, Default, Hash)]
pub enum PrivacyLevel {
    /// A public payment that is visible to everyone.
    Public,
    /// A private payment that is only visible to the sender and receiver.
    Private,
    /// A payment where the receiver does not know the sender.
    Anonymous,
    /// No information is shared about the payment.
    #[default]
    NotAvailable,
}

impl core::fmt::Display for PrivacyLevel {
    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
        match self {
            PrivacyLevel::Public => write!(f, "Public"),
            PrivacyLevel::Private => write!(f, "Private"),
            PrivacyLevel::Anonymous => write!(f, "Anonymous"),
            PrivacyLevel::NotAvailable => write!(f, "Not Available"),
        }
    }
}

impl FromStr for PrivacyLevel {
    type Err = MutinyError;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s {
            "Public" => Ok(PrivacyLevel::Public),
            "Private" => Ok(PrivacyLevel::Private),
            "Anonymous" => Ok(PrivacyLevel::Anonymous),
            "Not Available" => Ok(PrivacyLevel::NotAvailable),
            _ => Err(MutinyError::InvalidArgumentsError),
        }
    }
}

#[derive(Debug, Serialize, Deserialize, Clone, Eq, PartialEq)]
pub struct MutinyInvoice {
    pub bolt11: Option<Bolt11Invoice>,
    pub description: Option<String>,
    pub payment_hash: sha256::Hash,
    pub preimage: Option<String>,
    pub payee_pubkey: Option<PublicKey>,
    pub amount_sats: Option<u64>,
    pub expire: u64,
    pub status: HTLCStatus,
    #[serde(default)]
    pub privacy_level: PrivacyLevel,
    pub fees_paid: Option<u64>,
    pub fee_paid_msat: Option<u64>,
    pub inbound: bool,
    pub labels: Vec<String>,
    pub last_updated: u64,
}

#[cfg(test)]
impl Default for MutinyInvoice {
    fn default() -> Self {
        MutinyInvoice {
            bolt11: None,
            description: None,
            payment_hash: sha256::Hash::all_zeros(),
            preimage: None,
            payee_pubkey: None,
            amount_sats: None,
            expire: 0,
            status: HTLCStatus::Pending,
            privacy_level: PrivacyLevel::NotAvailable,
            fees_paid: None,
            fee_paid_msat: None,
            inbound: false,
            labels: vec![],
            last_updated: 0,
        }
    }
}

impl MutinyInvoice {
    pub fn paid(&self) -> bool {
        self.status == HTLCStatus::Succeeded
    }
}

impl From<Bolt11Invoice> for MutinyInvoice {
    fn from(value: Bolt11Invoice) -> Self {
        let description = match value.description() {
            Bolt11InvoiceDescription::Direct(a) => {
                let desc = a.clone().into_inner();
                if desc.0.is_empty() {
                    None
                } else {
                    Some(desc.0)
                }
            }
            Bolt11InvoiceDescription::Hash(_) => None,
        };

        let timestamp = value.duration_since_epoch().as_secs();
        let expiry = timestamp + value.expiry_time().as_secs();

        let payment_hash = value.payment_hash().to_owned();
        let payee_pubkey = value.payee_pub_key().map(|p| p.to_owned());
        let amount_sats = value.amount_milli_satoshis().map(|m| m / 1000);

        MutinyInvoice {
            bolt11: Some(value),
            description,
            payment_hash,
            preimage: None,
            payee_pubkey,
            amount_sats,
            expire: expiry,
            status: HTLCStatus::Pending,
            privacy_level: PrivacyLevel::NotAvailable,
            fees_paid: None,
            fee_paid_msat: None,
            inbound: true,
            labels: vec![],
            last_updated: timestamp,
        }
    }
}

impl From<MutinyInvoice> for PaymentInfo {
    fn from(invoice: MutinyInvoice) -> Self {
        let preimage: Option<[u8; 32]> = invoice
            .preimage
            .map(|s| FromHex::from_hex(&s).expect("preimage should decode"));
        let secret = None;
        let status = invoice.status;
        let amt_msat = invoice
            .amount_sats
            .map(|s| MillisatAmount(Some(s)))
            .unwrap_or(MillisatAmount(None));
        let fee_paid_msat = invoice.fee_paid_msat;
        let bolt11 = invoice.bolt11;
        let payee_pubkey = invoice.payee_pubkey;
        let last_update = invoice.last_updated;

        PaymentInfo {
            preimage,
            secret,
            status,
            amt_msat,
            fee_paid_msat,
            bolt11,
            payee_pubkey,
            privacy_level: invoice.privacy_level,
            last_update,
        }
    }
}

impl MutinyInvoice {
    pub(crate) fn from(
        i: PaymentInfo,
        payment_hash: PaymentHash,
        inbound: bool,
        labels: Vec<String>,
    ) -> Result<Self, MutinyError> {
        match i.bolt11 {
            Some(invoice) => {
                // Construct an invoice from a bolt11, easy
                let amount_sats = if let Some(inv_amt) = invoice.amount_milli_satoshis() {
                    if inv_amt == 0 {
                        i.amt_msat.0.map(|a| a / 1_000)
                    } else {
                        Some(inv_amt / 1_000)
                    }
                } else {
                    i.amt_msat.0.map(|a| a / 1_000)
                };
                Ok(MutinyInvoice {
                    inbound,
                    last_updated: i.last_update,
                    status: i.status,
                    labels,
                    amount_sats,
                    payee_pubkey: i.payee_pubkey,
                    preimage: i.preimage.map(|p| p.to_lower_hex_string()),
                    fees_paid: i.fee_paid_msat.map(|f| f / 1_000),
                    fee_paid_msat: i.fee_paid_msat,
                    privacy_level: i.privacy_level,
                    ..invoice.into()
                })
            }
            None => {
                let amount_sats: Option<u64> = i.amt_msat.0.map(|s| s / 1_000);
                let fees_paid = i.fee_paid_msat.map(|f| f / 1_000);
                let preimage = i.preimage.map(|p| p.to_lower_hex_string());
                let payment_hash = sha256::Hash::from_byte_array(payment_hash.0);
                let invoice = MutinyInvoice {
                    bolt11: None,
                    description: None,
                    payment_hash,
                    preimage,
                    payee_pubkey: i.payee_pubkey,
                    amount_sats,
                    expire: i.last_update,
                    status: i.status,
                    privacy_level: i.privacy_level,
                    fees_paid,
                    fee_paid_msat: i.fee_paid_msat,
                    inbound,
                    labels,
                    last_updated: i.last_update,
                };
                Ok(invoice)
            }
        }
    }
}

/// FedimintSweepResult is the result of how much was swept and the fees paid.
#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct FedimintSweepResult {
    /// The final amount that was swept.
    /// This should be the amount specified if it was not max.
    pub amount: u64,

    /// The total fees paid for the sweep.
    pub fees: Option<u64>,
}

pub struct MutinyWalletConfigBuilder {
    // xprivkey: Xpriv,
    #[cfg(target_arch = "wasm32")]
    websocket_proxy_addr: Option<String>,
    network: Option<Network>,
    user_esplora_url: Option<String>,
    user_rgs_url: Option<String>,
    lsp_url: Option<String>,
    lsp_connection_string: Option<String>,
    lsp_token: Option<String>,
    auth_client: Option<Arc<MutinyAuthClient>>,
    subscription_url: Option<String>,
    blind_auth_url: Option<String>,
    hermes_url: Option<String>,
    do_not_connect_peers: bool,
    do_not_bump_channel_close_tx: bool,
    sweep_target_address: Option<Address>,
    skip_device_lock: bool,
    pub safe_mode: bool,
    skip_hodl_invoices: bool,
}

impl MutinyWalletConfigBuilder {
    pub fn new(_xprivkey: Xpriv) -> MutinyWalletConfigBuilder {
        MutinyWalletConfigBuilder {
            // xprivkey,
            #[cfg(target_arch = "wasm32")]
            websocket_proxy_addr: None,
            network: None,
            user_esplora_url: None,
            user_rgs_url: None,
            lsp_url: None,
            lsp_connection_string: None,
            lsp_token: None,
            auth_client: None,
            subscription_url: None,
            blind_auth_url: None,
            hermes_url: None,
            do_not_connect_peers: false,
            do_not_bump_channel_close_tx: false,
            sweep_target_address: None,
            skip_device_lock: false,
            safe_mode: false,
            skip_hodl_invoices: true,
        }
    }

    /// Required
    pub fn with_network(mut self, network: Network) -> MutinyWalletConfigBuilder {
        self.network = Some(network);
        self
    }

    #[cfg(target_arch = "wasm32")]
    pub fn with_websocket_proxy_addr(&mut self, websocket_proxy_addr: String) {
        self.websocket_proxy_addr = Some(websocket_proxy_addr);
    }

    pub fn with_user_esplora_url(&mut self, user_esplora_url: String) {
        self.user_esplora_url = Some(user_esplora_url);
    }

    pub fn with_user_rgs_url(&mut self, user_rgs_url: String) {
        self.user_rgs_url = Some(user_rgs_url);
    }

    pub fn with_lsp_url(&mut self, lsp_url: String) {
        self.lsp_url = Some(lsp_url);
    }

    pub fn with_lsp_connection_string(&mut self, lsp_connection_string: String) {
        self.lsp_connection_string = Some(lsp_connection_string);
    }

    pub fn with_lsp_token(&mut self, lsp_token: String) {
        self.lsp_token = Some(lsp_token);
    }

    pub fn with_auth_client(&mut self, auth_client: Arc<MutinyAuthClient>) {
        self.auth_client = Some(auth_client);
    }

    pub fn with_subscription_url(&mut self, subscription_url: String) {
        self.subscription_url = Some(subscription_url);
    }

    pub fn with_blind_auth_url(&mut self, blind_auth_url: String) {
        self.blind_auth_url = Some(blind_auth_url);
    }

    pub fn with_hermes_url(&mut self, hermes_url: String) {
        self.hermes_url = Some(hermes_url);
    }

    pub fn do_not_connect_peers(&mut self) {
        self.do_not_connect_peers = true;
    }

    pub fn do_not_bump_channel_close_tx(&mut self) {
        self.do_not_bump_channel_close_tx = true;
    }

    pub fn with_sweep_target_address(&mut self, sweep_target_address: Address) {
        self.sweep_target_address = Some(sweep_target_address);
    }

    pub fn with_skip_device_lock(&mut self) {
        self.skip_device_lock = true;
    }

    pub fn with_safe_mode(&mut self) {
        self.safe_mode = true;
        self.skip_device_lock = true;
    }

    pub fn do_not_skip_hodl_invoices(&mut self) {
        self.skip_hodl_invoices = false;
    }

    pub fn build(self) -> MutinyWalletConfig {
        let network = self.network.expect("network is required");

        MutinyWalletConfig {
            // xprivkey: self.xprivkey,
            #[cfg(target_arch = "wasm32")]
            websocket_proxy_addr: self.websocket_proxy_addr,
            network,
            user_esplora_url: self.user_esplora_url,
            user_rgs_url: self.user_rgs_url,
            lsp_url: self.lsp_url,
            lsp_connection_string: self.lsp_connection_string,
            lsp_token: self.lsp_token,
            auth_client: self.auth_client,
            subscription_url: self.subscription_url,
            blind_auth_url: self.blind_auth_url,
            hermes_url: self.hermes_url,
            do_not_connect_peers: self.do_not_connect_peers,
            do_not_bump_channel_close_tx: self.do_not_bump_channel_close_tx,
            sweep_target_address: self.sweep_target_address,
            skip_device_lock: self.skip_device_lock,
            safe_mode: self.safe_mode,
            skip_hodl_invoices: self.skip_hodl_invoices,
        }
    }
}

#[derive(Clone)]
pub struct MutinyWalletConfig {
    // xprivkey: Xpriv,
    #[cfg(target_arch = "wasm32")]
    websocket_proxy_addr: Option<String>,
    network: Network,
    user_esplora_url: Option<String>,
    user_rgs_url: Option<String>,
    lsp_url: Option<String>,
    lsp_connection_string: Option<String>,
    lsp_token: Option<String>,
    auth_client: Option<Arc<MutinyAuthClient>>,
    subscription_url: Option<String>,
    blind_auth_url: Option<String>,
    hermes_url: Option<String>,
    do_not_connect_peers: bool,
    do_not_bump_channel_close_tx: bool,
    sweep_target_address: Option<Address>,
    skip_device_lock: bool,
    pub safe_mode: bool,
    skip_hodl_invoices: bool,
}

pub struct MutinyWalletBuilder<S: MutinyStorage> {
    xprivkey: Xpriv,
    storage: S,
    config: Option<MutinyWalletConfig>,
    session_id: Option<String>,
    network: Option<Network>,
    auth_client: Option<Arc<MutinyAuthClient>>,
    blind_auth_url: Option<String>,
    hermes_url: Option<String>,
    ln_event_callback: Option<CommonLnEventCallback>,
    subscription_url: Option<String>,
    do_not_connect_peers: bool,
    do_not_bump_channel_close_tx: bool,
    sweep_target_address: Option<Address>,
    skip_hodl_invoices: bool,
    skip_device_lock: bool,
    safe_mode: bool,
    logs: Vec<String>,
}

impl<S: MutinyStorage> MutinyWalletBuilder<S> {
    pub fn new(xprivkey: Xpriv, storage: S) -> MutinyWalletBuilder<S> {
        MutinyWalletBuilder::<S> {
            xprivkey,
            storage,
            config: None,
            session_id: None,
            network: None,
            auth_client: None,
            subscription_url: None,
            blind_auth_url: None,
            hermes_url: None,
            ln_event_callback: None,
            do_not_connect_peers: false,
            do_not_bump_channel_close_tx: false,
            sweep_target_address: None,
            skip_device_lock: false,
            safe_mode: false,
            skip_hodl_invoices: true,
            logs: Default::default(),
        }
    }

    pub fn with_config(mut self, config: MutinyWalletConfig) -> MutinyWalletBuilder<S> {
        self.network = Some(config.network);
        self.do_not_connect_peers = config.do_not_connect_peers;
        self.do_not_bump_channel_close_tx = config.do_not_bump_channel_close_tx;
        self.sweep_target_address = config.sweep_target_address.clone();
        self.skip_hodl_invoices = config.skip_hodl_invoices;
        self.skip_device_lock = config.skip_device_lock;
        self.safe_mode = config.safe_mode;
        self.auth_client = config.auth_client.clone();
        self.subscription_url = config.subscription_url.clone();
        self.blind_auth_url = config.blind_auth_url.clone();
        self.hermes_url = config.hermes_url.clone();
        self.config = Some(config);
        self
    }

    pub fn with_session_id(&mut self, session_id: String) {
        self.session_id = Some(session_id);
    }

    pub fn with_logs(&mut self, logs: Vec<String>) {
        self.logs = logs;
    }

    pub fn with_network(&mut self, network: Network) {
        self.network = Some(network);
    }

    pub fn with_auth_client(&mut self, auth_client: Arc<MutinyAuthClient>) {
        self.auth_client = Some(auth_client);
    }

    pub fn with_subscription_url(&mut self, subscription_url: String) {
        self.subscription_url = Some(subscription_url);
    }

    pub fn with_blind_auth_url(&mut self, blind_auth_url: String) {
        self.blind_auth_url = Some(blind_auth_url);
    }

    pub fn with_hermes_url(&mut self, hermes_url: String) {
        self.hermes_url = Some(hermes_url);
    }

    pub fn with_ln_event_callback(&mut self, cb: CommonLnEventCallback) {
        self.ln_event_callback = Some(cb);
    }

    pub fn do_not_connect_peers(&mut self) {
        self.do_not_connect_peers = true;
    }

    pub fn do_not_bump_channel_close_tx(&mut self) {
        self.do_not_bump_channel_close_tx = true;
    }

    pub fn with_sweep_target_address(&mut self, sweep_target_address: Address) {
        self.sweep_target_address = Some(sweep_target_address);
    }

    pub fn do_not_skip_hodl_invoices(&mut self) {
        self.skip_hodl_invoices = false;
    }

    pub fn with_skip_device_lock(&mut self) {
        self.skip_device_lock = true;
    }

    pub fn with_safe_mode(&mut self) {
        self.safe_mode = true;
        self.skip_device_lock = true;
    }

    pub async fn build(self) -> Result<MutinyWallet<S>, MutinyError> {
        let network = self
            .network
            .map_or_else(|| Err(MutinyError::InvalidArgumentsError), Ok)?;
        let config = self.config.unwrap_or(
            MutinyWalletConfigBuilder::new(self.xprivkey)
                .with_network(network)
                .build(),
        );

        let expected_network = self.storage.get::<Network>(EXPECTED_NETWORK_KEY)?;
        match expected_network {
            Some(n) => {
                if n != network {
                    return Err(MutinyError::NetworkMismatch);
                }
            }
            None => {
                self.storage
                    .write_data(EXPECTED_NETWORK_KEY.to_string(), self.network, None)?
            }
        }

        let logger = Arc::new(MutinyLogger::with_writer(
            self.storage.clone(),
            self.session_id,
            self.logs,
        ));

        // Need to prevent other devices from running at the same time
        log_debug!(logger, "checking device lock");
        if !config.skip_device_lock {
            let start = Instant::now();
            if let Some(lock) = self.storage.get_device_lock()? {
                log_info!(logger, "Current device lock: {lock:?}");
            }
            self.storage.set_device_lock(&logger)?;
            log_debug!(
                logger,
                "Device lock set: took {}ms",
                start.elapsed().as_millis()
            );
            if let Some(lock) = self.storage.get_device_lock()? {
                log_info!(logger, "New device lock: {lock:?}");
            }

            // Wait device lock syncing
            let device_id = self.storage.get_device_id()?;
            let max_retries = 10;
            let mut retries = 0;
            while retries <= max_retries {
                log_info!(logger, "Waiting device lock syncing... {retries}");

                match self.storage.fetch_device_lock().await {
                    Ok(lock_option) => {
                        if let Some(lock) = lock_option {
                            if lock.is_last_locker(&device_id) {
                                break;
                            }
                        }
                    }
                    Err(MutinyError::FailedParsingVssValue) => {
                        log_info!(logger, "Failed to parse VSS value, retrying... {retries}");
                    }
                    Err(e) => {
                        log_error!(logger, "Error fetching device lock: {:?}", e);
                        return Err(e);
                    }
                }

                retries += 1;

                if retries > max_retries {
                    log_error!(
                        logger,
                        "Can't sync device lock to VSS after {max_retries} attempts"
                    );
                    return Err(MutinyError::AlreadyRunning);
                }
                sleep(300).await;
            }
        }
        log_debug!(logger, "finished checking device lock");

        // spawn thread to claim device lock
        log_trace!(logger, "spawning claim device lock");
        let storage_clone = self.storage.clone();
        let logger_clone = logger.clone();
        let device_lock_stop_handle = spawn_with_handle(|stop_signal| async move {
            loop {
                if stop_signal.stopping() {
                    log_debug!(logger_clone, "stopping claim device lock");
                    if let Err(e) = storage_clone.release_device_lock(&logger_clone) {
                        log_error!(logger_clone, "Error releasing device lock: {e}");
                    }
                    break;
                }
                if let Err(e) = storage_clone.set_device_lock(&logger_clone) {
                    log_error!(logger_clone, "Error setting device lock: {e}");
                }

                let mut remained_sleep_ms = (DEVICE_LOCK_INTERVAL_SECS * 1000) as i32;
                while !stop_signal.stopping() && remained_sleep_ms > 0 {
                    let sleep_ms = 300;
                    sleep(sleep_ms).await;
                    remained_sleep_ms -= sleep_ms;
                }
            }
        });
        log_trace!(logger, "finished spawning claim device lock");

        log_trace!(logger, "setting up esplora");
        let esplora_server_url = get_esplora_url(network, config.user_esplora_url.clone());
        let esplora = esplora_client::Builder::new(&esplora_server_url).build_async()?;
        let esplora = Arc::new(esplora);
        log_trace!(logger, "finished setting up esplora");

        log_trace!(logger, "setting up node manager");
        let start = Instant::now();
        let mut nm_builder = NodeManagerBuilder::new(self.xprivkey, self.storage.clone())
            .with_config(config.clone());
        nm_builder.with_logger(logger.clone());
        nm_builder.with_esplora(esplora.clone());
        if let Some(cb) = self.ln_event_callback.clone() {
            nm_builder.with_ln_event_callback(cb);
        }
        let node_manager = Arc::new(
            nm_builder
                .build()
                .await
                .with_context(|| "build node manager")?,
        );

        log_trace!(
            logger,
            "NodeManager started, took: {}ms",
            start.elapsed().as_millis()
        );

        // start syncing node manager
        log_trace!(logger, "starting node manager sync");
        NodeManager::start_sync(node_manager.clone());
        log_trace!(logger, "finished node manager sync");

        if !self.skip_hodl_invoices {
            log_warn!(
                logger,
                "Starting with HODL invoices enabled. This is not recommended!"
            );
        }

        let start = Instant::now();

        // auth manager, take from auth_client if it already exists
        log_trace!(logger, "creating auth manager");
        let auth = if let Some(auth_client) = self.auth_client.clone() {
            auth_client.auth.clone()
        } else {
            AuthManager::new(self.xprivkey)?
        };
        log_trace!(logger, "finished creating auth manager");

        // populate the activity index
        log_trace!(logger, "populating activity index");
        let mut activity_index = node_manager
            .wallet
            .list_transactions(false)?
            .into_iter()
            .map(|t| IndexItem {
                timestamp: match t.confirmation_time {
                    ConfirmationTime::Confirmed { time, .. } => Some(time),
                    ConfirmationTime::Unconfirmed { .. } => None,
                },
                key: format!("{ONCHAIN_PREFIX}{}", t.internal_id),
            })
            .collect::<Vec<_>>();

        // add any transaction details stored from fedimint
        let transaction_details = self
            .storage
            .scan::<TransactionDetails>(TRANSACTION_DETAILS_PREFIX_KEY, None)?
            .into_iter()
            .map(|(k, v)| {
                let timestamp = match v.confirmation_time {
                    ConfirmationTime::Confirmed { height: _, time } => Some(time), // confirmed timestamp
                    ConfirmationTime::Unconfirmed { .. } => None, // unconfirmed timestamp
                };
                IndexItem { timestamp, key: k }
            })
            .collect::<Vec<_>>();
        activity_index.extend(transaction_details);

        // add the channel closures to the activity index
        let closures = self
            .storage
            .scan::<ChannelClosure>(CHANNEL_CLOSURE_PREFIX, None)?
            .into_iter()
            .map(|(k, v)| IndexItem {
                timestamp: Some(v.timestamp),
                key: k,
            })
            .collect::<Vec<_>>();
        activity_index.extend(closures);

        // add inbound invoices to the activity index
        let inbound = self
            .storage
            .scan::<PaymentInfo>(PAYMENT_INBOUND_PREFIX_KEY, None)?
            .into_iter()
            .filter(|(_, p)| matches!(p.status, HTLCStatus::Succeeded | HTLCStatus::InFlight))
            .map(|(k, v)| IndexItem {
                timestamp: Some(v.last_update),
                key: k,
            })
            .collect::<Vec<_>>();

        let outbound = self
            .storage
            .scan::<PaymentInfo>(PAYMENT_OUTBOUND_PREFIX_KEY, None)?
            .into_iter()
            .filter(|(_, p)| matches!(p.status, HTLCStatus::Succeeded | HTLCStatus::InFlight))
            .map(|(k, v)| IndexItem {
                timestamp: Some(v.last_update),
                key: k,
            })
            .collect::<Vec<_>>();

        activity_index.extend(inbound);
        activity_index.extend(outbound);

        // add the activity index to the storage
        {
            let index = self.storage.activity_index();
            let mut read = index.try_write()?;
            read.extend(activity_index);
        }
        log_trace!(logger, "finished populating activity index");

        log_trace!(logger, "creating price cache");
        let price_cache = self
            .storage
            .get_bitcoin_price_cache()?
            .into_iter()
            .map(|(k, v)| (k, (v, Duration::from_secs(0))))
            .collect();
        log_trace!(logger, "finished creating price cache");

        log_trace!(logger, "creating mutiny wallet");
        let mw = MutinyWallet {
            xprivkey: self.xprivkey,
            config,
            storage: self.storage,
            node_manager: Some(node_manager),
            auth,
            logger: logger.clone(),
            network,
            skip_hodl_invoices: self.skip_hodl_invoices,
            safe_mode: self.safe_mode,
            bitcoin_price_cache: Arc::new(Mutex::new(price_cache)),
            device_lock_stop_handle,
        };
        log_trace!(logger, "finished creating mutiny wallet");
        // if we are in safe mode, don't create any nodes or
        // start any nostr services
        if self.safe_mode {
            return Ok(mw);
        }

        // if we don't have any nodes, create one
        log_trace!(logger, "listing nodes");
        let nm = mw
            .node_manager
            .as_ref()
            .ok_or(MutinyError::NotRunning)?
            .clone();
        if mw
            .node_manager
            .as_ref()
            .unwrap()
            .list_nodes()
            .await?
            .is_empty()
        {
            log_trace!(logger, "going to create first node");
            // spawn in background, this can take a while and we don't want to block
            utils::spawn(async move {
                if let Err(e) = nm.new_node().await {
                    log_error!(nm.logger, "Failed to create first node: {e}");
                }
            })
        };
        log_trace!(logger, "finished listing nodes");

        log_info!(
            mw.logger,
            "Final setup took {}ms",
            start.elapsed().as_millis()
        );

        Ok(mw)
    }
}

/// MutinyWallet is the main entry point for the library.
/// It contains the NodeManager, which is the main interface to manage the
/// bitcoin and the lightning functionality.
#[derive(Clone)]
pub struct MutinyWallet<S: MutinyStorage> {
    xprivkey: Xpriv,
    config: MutinyWalletConfig,
    pub(crate) storage: S,
    pub node_manager: Option<Arc<NodeManager<S>>>,
    pub auth: AuthManager,
    pub logger: Arc<MutinyLogger>,
    network: Network,
    skip_hodl_invoices: bool,
    safe_mode: bool,
    bitcoin_price_cache: Arc<Mutex<HashMap<String, (f32, Duration)>>>,
    device_lock_stop_handle: StopHandle,
}

impl<S: MutinyStorage> MutinyWallet<S> {
    /// Starts up all the nodes again.
    /// Not needed after [NodeManager]'s `new()` function.
    pub async fn start(&mut self) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling start");
        if self.node_manager.is_some() {
            return Err(MutinyError::AlreadyRunning);
        }

        self.storage.start().await?;

        let mut nm_builder = NodeManagerBuilder::new(self.xprivkey, self.storage.clone())
            .with_config(self.config.clone());
        nm_builder.with_logger(self.logger.clone());

        // when we restart, gen a new session id
        let node_manager = Arc::new(nm_builder.build().await?);
        self.node_manager.replace(node_manager.clone());
        NodeManager::start_sync(node_manager.clone());

        log_trace!(self.logger, "finished calling start");
        Ok(())
    }

    /// Pays a lightning invoice from a federation (preferred) or node.
    /// An amount should only be provided if the invoice does not have an amount.
    /// Amountless invoices cannot be paid by a federation.
    /// The amount should be in satoshis.
    pub async fn pay_invoice(
        &self,
        inv: &Bolt11Invoice,
        amt_sats: Option<u64>,
        labels: Vec<String>,
    ) -> Result<MutinyInvoice, MutinyError> {
        log_trace!(self.logger, "calling pay_invoice");

        let node_manager = self.node_manager.as_ref().ok_or(MutinyError::NotRunning)?;

        if inv.network() != self.network {
            return Err(MutinyError::IncorrectNetwork);
        }

        // check invoice is expired
        if inv.would_expire(utils::now()) {
            return Err(MutinyError::InvoiceExpired);
        }

        // set labels now, need to set it before in case the payment times out
        self.storage
            .set_invoice_labels(inv.clone(), labels.clone())?;

        // If any balance at all, then fallback to node manager for payment.
        // Take the error from the node manager as the priority.
        let res = if node_manager
            .nodes
            .read()
            .await
            .iter()
            .flat_map(|(_, n)| {
                n.chain_monitor
                    .get_claimable_balances(&[])
                    .into_iter()
                    .map(|b| b.claimable_amount_satoshis())
            })
            .sum::<u64>()
            > 0
        {
            let res = node_manager
                .pay_invoice(None, inv, amt_sats, labels)
                .await?;

            Ok(res)
        } else {
            Err(MutinyError::InsufficientBalance)
        };
        log_trace!(self.logger, "finished calling pay_invoice");

        res
    }

    /// Estimates the lightning fee for a transaction. Amount is either from the invoice
    /// if one is available or a passed in amount (priority). It will try to predict either
    /// sending the payment through a federation or through lightning, depending on balances.
    /// The amount and fee is in satoshis.
    /// Returns None if it has no good way to calculate fee.
    pub async fn estimate_ln_fee(
        &self,
        inv: Option<&Bolt11Invoice>,
        amt_sats: Option<u64>,
    ) -> Result<Option<u64>, MutinyError> {
        log_trace!(self.logger, "calling estimate_ln_fee");

        let amt = amt_sats
            .or(inv
                .and_then(|i| i.amount_milli_satoshis())
                .map(|a| a / 1_000))
            .ok_or(MutinyError::BadAmountError)?;

        // check balances first
        let total_balances = self.get_balance().await?;

        if total_balances.lightning > amt {
            // TODO try something to try to get lightning fee
            return Ok(None);
        }

        Err(MutinyError::InsufficientBalance)
    }

    /// Creates a BIP 21 invoice. This creates a new address and a lightning invoice.
    /// The lightning invoice may return errors related to the LSP. Check the error and
    /// fallback to `get_new_address` and warn the user that Lightning is not available.
    ///
    /// Errors that might be returned include:
    ///
    /// - [`MutinyError::LspGenericError`]: This is returned for various reasons, including if a
    ///   request to the LSP server fails for any reason, or if the server returns
    ///   a status other than 500 that can't be parsed into a `ProposalResponse`.
    ///
    /// - [`MutinyError::LspFundingError`]: Returned if the LSP server returns an error with
    ///   a status of 500, indicating an "Internal Server Error", and a message
    ///   stating "Cannot fund new channel at this time". This means that the LSP cannot support
    ///   a new channel at this time.
    ///
    /// - [`MutinyError::LspAmountTooHighError`]: Returned if the LSP server returns an error with
    ///   a status of 500, indicating an "Internal Server Error", and a message stating "Invoice
    ///   amount is too high". This means that the LSP cannot support the amount that the user
    ///   requested. The user should request a smaller amount from the LSP.
    ///
    /// - [`MutinyError::LspConnectionError`]: Returned if the LSP server returns an error with
    ///   a status of 500, indicating an "Internal Server Error", and a message that starts with
    ///   "Failed to connect to peer". This means that the LSP is not connected to our node.
    ///
    /// If the server returns a status of 500 with a different error message,
    /// a [`MutinyError::LspGenericError`] is returned.
    pub async fn create_bip21(
        &self,
        amount: Option<u64>,
        labels: Vec<String>,
    ) -> Result<MutinyBip21RawMaterials, MutinyError> {
        log_trace!(self.logger, "calling create_bip21");

        let invoice = if self.safe_mode || amount.is_none() {
            None
        } else {
            Some(
                self.create_lightning_invoice(amount, labels.clone(), None)
                    .await?
                    .bolt11
                    .ok_or(MutinyError::InvoiceCreationFailed)?,
            )
        };

        let Ok(address) = self.create_address(labels.clone()).await else {
            return Err(MutinyError::WalletOperationFailed);
        };
        log_trace!(self.logger, "finished calling create_bip21");

        Ok(MutinyBip21RawMaterials {
            address,
            invoice,
            btc_amount: amount.map(|amount| bitcoin::Amount::from_sat(amount).to_btc().to_string()),
            labels,
        })
    }

    pub async fn send_to_address(
        &self,
        send_to: Address,
        amount: u64,
        labels: Vec<String>,
        fee_rate: Option<u64>,
    ) -> Result<Txid, MutinyError> {
        log_trace!(self.logger, "calling send_to_address");

        let node_manager = self.node_manager.as_ref().ok_or(MutinyError::NotRunning)?;

        // If any balance at all, then fallback to node manager for payment.
        // Take the error from the node manager as the priority.
        let b = node_manager.get_balance().await?;
        let res = if b.confirmed + b.unconfirmed > 0 {
            let res = node_manager
                .send_to_address(send_to, amount, labels, fee_rate)
                .await?;
            Ok(res)
        } else {
            Err(MutinyError::InsufficientBalance)
        };
        log_trace!(self.logger, "finished calling send_to_address");

        res
    }

    /// Estimates the onchain fee for a transaction sending to the given address.
    /// The amount is in satoshis and the fee rate is in sat/vbyte.
    pub async fn estimate_tx_fee(
        &self,
        destination_address: Address,
        amount: u64,
        fee_rate: Option<u64>,
    ) -> Result<u64, MutinyError> {
        log_trace!(self.logger, "calling estimate_tx_fee");

        let node_manager = self.node_manager.as_ref().ok_or(MutinyError::NotRunning)?;

        if amount < DUST_LIMIT {
            return Err(MutinyError::WalletOperationFailed);
        }

        let b = node_manager.get_balance().await?;
        let res = if b.confirmed + b.unconfirmed > 0 {
            let res = node_manager.estimate_tx_fee(destination_address, amount, fee_rate)?;

            Ok(res)
        } else {
            Err(MutinyError::InsufficientBalance)
        };
        log_trace!(self.logger, "finished calling estimate_tx_fee");

        res
    }

    /// Sweeps all the funds from the wallet to the given address.
    /// The fee rate is in sat/vbyte.
    ///
    /// If a fee rate is not provided, one will be used from the fee estimator.
    pub async fn sweep_wallet(
        &self,
        send_to: Address,
        labels: Vec<String>,
        fee_rate: Option<u64>,
        allow_dust: Option<bool>,
    ) -> Result<Txid, MutinyError> {
        log_trace!(self.logger, "calling sweep_wallet");

        let node_manager = self.node_manager.as_ref().ok_or(MutinyError::NotRunning)?;

        let b = node_manager.get_balance().await?;
        let res = if b.confirmed + b.unconfirmed > 0 {
            let res = node_manager
                .sweep_wallet(send_to.clone(), labels, fee_rate, allow_dust)
                .await?;

            Ok(res)
        } else {
            log_error!(self.logger, "node manager doesn't have a balance");
            Err(MutinyError::InsufficientBalance)
        };
        log_trace!(self.logger, "finished calling sweep_wallet");

        res
    }

    pub fn construct_sweep_tx(
        &self,
        send_to: Address,
        fee_rate: Option<u64>,
        allow_dust: Option<bool>,
    ) -> Result<String, MutinyError> {
        let node_manager = self.node_manager.as_ref().ok_or(MutinyError::NotRunning)?;
        let tx = node_manager.construct_sweep_tx(send_to, fee_rate, allow_dust)?;
        Ok(serialize_hex(&tx))
    }

    pub async fn insert_unconfirmed_tx(
        &self,
        tx_hex: String,
        last_seen: u64,
    ) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling insert_unconfirmed_tx");

        let node_manager = self.node_manager.as_ref().ok_or(MutinyError::NotRunning)?;
        let tx_bytes = Vec::from_hex(&tx_hex).map_err(|_| MutinyError::InvalidTransaction)?;
        let tx = bitcoin::consensus::deserialize::<bitcoin::Transaction>(&tx_bytes)
            .map_err(|_| MutinyError::InvalidTransaction)?;

        node_manager.insert_unconfirmed_tx(tx, last_seen).await?;

        log_trace!(self.logger, "finished calling insert_unconfirmed_tx");

        Ok(())
    }

    pub async fn create_address(
        &self,
        labels: Vec<String>,
    ) -> Result<bitcoin::Address, MutinyError> {
        log_trace!(self.logger, "calling create_address");

        let node_manager = self.node_manager.as_ref().ok_or(MutinyError::NotRunning)?;

        // Fallback to node_manager address creation
        let Ok(addr) = node_manager.get_new_address(labels.clone()) else {
            return Err(MutinyError::WalletOperationFailed);
        };

        log_trace!(self.logger, "finished calling create_address");
        Ok(addr)
    }

    async fn create_lightning_invoice(
        &self,
        amount: Option<u64>,
        labels: Vec<String>,
        expiry_delta_secs: Option<u32>,
    ) -> Result<MutinyInvoice, MutinyError> {
        log_trace!(self.logger, "calling create_lightning_invoice");

        let node_manager = self.node_manager.as_ref().ok_or(MutinyError::NotRunning)?;

        let (inv, _fee) = node_manager
            .create_invoice(amount, labels, expiry_delta_secs)
            .await?;

        log_trace!(self.logger, "finished calling create_lightning_invoice");
        Ok(inv)
    }

    /// Gets the current balance of the wallet.
    /// This includes both on-chain, lightning funds, and federations.
    ///
    /// This will not include any funds in an unconfirmed lightning channel.
    pub async fn get_balance(&self) -> Result<MutinyBalance, MutinyError> {
        log_trace!(self.logger, "calling get_balance");

        let node_manager = self.node_manager.as_ref().ok_or(MutinyError::NotRunning)?;

        let ln_balance = node_manager.get_balance().await?;

        Ok(MutinyBalance::new(ln_balance))
    }

    fn get_invoice_internal(
        &self,
        key: &str,
        inbound: bool,
        labels_map: &HashMap<Bolt11Invoice, Vec<String>>,
    ) -> Result<Option<MutinyInvoice>, MutinyError> {
        if let Some(info) = self.storage.get_data::<PaymentInfo>(key)? {
            let labels = match info.bolt11.clone() {
                None => vec![],
                Some(i) => labels_map.get(&i).cloned().unwrap_or_default(),
            };
            let prefix = match inbound {
                true => PAYMENT_INBOUND_PREFIX_KEY,
                false => PAYMENT_OUTBOUND_PREFIX_KEY,
            };
            let payment_hash_str = get_payment_hash_from_key(key, prefix);
            let hash: [u8; 32] = FromHex::from_hex(payment_hash_str)?;

            return MutinyInvoice::from(info, PaymentHash(hash), inbound, labels).map(Some);
        };

        Ok(None)
    }

    /// Get the sorted activity list for lightning payments, channels, and txs.
    pub fn get_activity(
        &self,
        limit: Option<usize>,
        offset: Option<usize>,
    ) -> Result<Vec<ActivityItem>, MutinyError> {
        log_trace!(self.logger, "calling get_activity");

        let index = {
            let index = self.storage.activity_index();
            let vec = index.try_read()?.clone().into_iter().collect_vec();

            let (start, end) = match (offset, limit) {
                (None, None) => (0, vec.len()),
                (Some(offset), Some(limit)) => {
                    let end = offset.saturating_add(limit).min(vec.len());
                    (offset, end)
                }
                (Some(offset), None) => (offset, vec.len()),
                (None, Some(limit)) => (0, limit),
            };

            // handle out of bounds
            let start = start.min(vec.len());
            let end = end.min(vec.len());

            // handle start > end
            if start > end {
                return Ok(vec![]);
            }

            vec[start..end].to_vec()
        };

        let labels_map = self.storage.get_invoice_labels()?;

        let mut activities = Vec::with_capacity(index.len());
        for item in index {
            if item.key.starts_with(PAYMENT_INBOUND_PREFIX_KEY) {
                if let Some(mutiny_invoice) =
                    self.get_invoice_internal(&item.key, true, &labels_map)?
                {
                    activities.push(ActivityItem::Lightning(Box::new(mutiny_invoice)));
                }
            } else if item.key.starts_with(PAYMENT_OUTBOUND_PREFIX_KEY) {
                if let Some(mutiny_invoice) =
                    self.get_invoice_internal(&item.key, false, &labels_map)?
                {
                    activities.push(ActivityItem::Lightning(Box::new(mutiny_invoice)));
                }
            } else if item.key.starts_with(CHANNEL_CLOSURE_PREFIX) {
                if let Some(mut closure) = self.storage.get_data::<ChannelClosure>(&item.key)? {
                    if closure.user_channel_id.is_none() {
                        // convert keys to u128
                        let user_channel_id_str = item
                            .key
                            .trim_start_matches(CHANNEL_CLOSURE_PREFIX)
                            .splitn(2, '_') // Channel closures have `_{node_id}` at the end
                            .collect::<Vec<&str>>()[0];
                        let user_channel_id: [u8; 16] = FromHex::from_hex(user_channel_id_str)?;
                        closure.user_channel_id = Some(user_channel_id);
                    }
                    activities.push(ActivityItem::ChannelClosed(closure));
                }
            } else if item.key.starts_with(ONCHAIN_PREFIX) {
                // convert keys to txid
                let txid_str = item.key.trim_start_matches(ONCHAIN_PREFIX);
                let txid: Txid = Txid::from_str(txid_str)?;
                let Some(node_manager) = self.node_manager.as_ref() else {
                    continue;
                };
                if let Some(tx_details) = node_manager.get_transaction(txid)? {
                    // make sure it is a relevant transaction
                    if tx_details.sent != 0 || tx_details.received != 0 {
                        activities.push(ActivityItem::OnChain(tx_details));
                    }
                }
            } else if item.key.starts_with(TRANSACTION_DETAILS_PREFIX_KEY) {
                // convert keys to internal transaction id
                let internal_id_str = item.key.trim_start_matches(TRANSACTION_DETAILS_PREFIX_KEY);
                let internal_id: Txid = Txid::from_str(internal_id_str)?;
                if let Some(tx_details) =
                    get_transaction_details(&self.storage, internal_id, &self.logger)
                {
                    // make sure it is a relevant transaction
                    if tx_details.sent != 0 || tx_details.received != 0 {
                        activities.push(ActivityItem::OnChain(tx_details));
                    }
                }
            }
        }
        log_trace!(self.logger, "finished calling get_activity");

        Ok(activities)
    }

    pub fn get_transaction(&self, txid: Txid) -> Result<Option<TransactionDetails>, MutinyError> {
        log_trace!(self.logger, "calling get_transaction");

        // check our local cache/state first
        if let Some(t) = get_transaction_details(&self.storage, txid, &self.logger) {
            log_trace!(self.logger, "finished calling get_transaction");
            return Ok(Some(t));
        }

        if let Some(node_manager) = self.node_manager.as_ref() {
            log_trace!(self.logger, "finished calling get_transaction");
            // fall back to node manager
            return node_manager.get_transaction(txid);
        }

        log_trace!(self.logger, "finished calling get_transaction");
        Ok(None)
    }

    /// Returns all the lightning activity for a given label
    pub async fn get_label_activity(
        &self,
        label: &String,
    ) -> Result<Vec<ActivityItem>, MutinyError> {
        log_trace!(self.logger, "calling get_label_activity");

        let node_manager = self.node_manager.as_ref().ok_or(MutinyError::NotRunning)?;

        let Some(label_item) = node_manager.get_label(label)? else {
            return Ok(Vec::new());
        };

        // get all the payment hashes for this label
        let payment_hashes: HashSet<sha256::Hash> = label_item
            .invoices
            .into_iter()
            .map(|i| *i.payment_hash())
            .collect();

        let index = self.storage.activity_index();
        let index = index.try_read()?.clone().into_iter().collect_vec();

        let labels_map = self.storage.get_invoice_labels()?;

        let mut activities = Vec::with_capacity(index.len());
        for item in index {
            if item.key.starts_with(PAYMENT_INBOUND_PREFIX_KEY) {
                let payment_hash_str =
                    get_payment_hash_from_key(&item.key, PAYMENT_INBOUND_PREFIX_KEY);
                let hash = sha256::Hash::from_str(payment_hash_str)?;

                if payment_hashes.contains(&hash) {
                    if let Some(mutiny_invoice) =
                        self.get_invoice_internal(&item.key, true, &labels_map)?
                    {
                        activities.push(ActivityItem::Lightning(Box::new(mutiny_invoice)));
                    }
                }
            } else if item.key.starts_with(PAYMENT_OUTBOUND_PREFIX_KEY) {
                let payment_hash_str =
                    get_payment_hash_from_key(&item.key, PAYMENT_OUTBOUND_PREFIX_KEY);
                let hash = sha256::Hash::from_str(payment_hash_str)?;

                if payment_hashes.contains(&hash) {
                    if let Some(mutiny_invoice) =
                        self.get_invoice_internal(&item.key, false, &labels_map)?
                    {
                        activities.push(ActivityItem::Lightning(Box::new(mutiny_invoice)));
                    }
                }
            }
        }
        log_trace!(self.logger, "finished calling get_label_activity");

        Ok(activities)
    }

    pub fn list_invoices(&self) -> Result<Vec<MutinyInvoice>, MutinyError> {
        log_trace!(self.logger, "calling list_invoices");

        let mut inbound_invoices = self.list_payment_info_from_persisters(true)?;
        let mut outbound_invoices = self.list_payment_info_from_persisters(false)?;
        inbound_invoices.append(&mut outbound_invoices);
        log_trace!(self.logger, "finished calling list_invoices");

        Ok(inbound_invoices)
    }

    fn list_payment_info_from_persisters(
        &self,
        inbound: bool,
    ) -> Result<Vec<MutinyInvoice>, MutinyError> {
        let now = utils::now();
        let labels_map = self.storage.get_invoice_labels()?;

        Ok(list_payment_info(&self.storage, inbound)?
            .into_iter()
            .filter_map(|(h, i)| {
                let labels = match i.bolt11.clone() {
                    None => vec![],
                    Some(i) => labels_map.get(&i).cloned().unwrap_or_default(),
                };
                let mutiny_invoice = MutinyInvoice::from(i.clone(), h, inbound, labels).ok();

                // filter out expired invoices
                mutiny_invoice.filter(|invoice| {
                    !invoice.bolt11.as_ref().is_some_and(|b| b.would_expire(now))
                        || matches!(invoice.status, HTLCStatus::Succeeded | HTLCStatus::InFlight)
                })
            })
            .collect())
    }

    /// Gets an invoice.
    /// This includes sent and received invoices.
    pub async fn get_invoice(&self, invoice: &Bolt11Invoice) -> Result<MutinyInvoice, MutinyError> {
        log_trace!(self.logger, "calling get_invoice");

        let res = self.get_invoice_by_hash(invoice.payment_hash()).await;
        log_trace!(self.logger, "finished calling get_invoice");

        res
    }

    /// Looks up an invoice by hash.
    /// This includes sent and received invoices.
    pub async fn get_invoice_by_hash(
        &self,
        hash: &sha256::Hash,
    ) -> Result<MutinyInvoice, MutinyError> {
        log_trace!(self.logger, "calling get_invoice_by_hash");

        let res = get_invoice_by_hash(hash, &self.storage, &self.logger);
        log_trace!(self.logger, "finished calling get_invoice_by_hash");

        res
    }

    /// Stops all of the nodes and background processes.
    /// Returns after node has been stopped.
    pub async fn stop(&mut self) -> Result<(), MutinyError> {
        log_debug!(self.logger, "calling stop");

        let node_manager = self.node_manager.take().ok_or(MutinyError::NotRunning)?;

        node_manager.stop().await?;

        // store wallet
        {
            log_debug!(self.logger, "save wallet state");
            let mut wallet = node_manager
                .wallet
                .wallet
                .try_write()
                .map_err(|_| MutinyError::WalletOperationFailed)?;
            if let Some(changeset) = wallet.take_staged() {
                node_manager.storage.write_changes(&changeset)?;
            }
        }

        log_debug!(self.logger, "release device lock");
        // stop device lock
        self.device_lock_stop_handle.stop().await;

        log_debug!(self.logger, "stop logger");
        // stop logger
        self.logger.stop().await;

        // stop the indexeddb object to close db connection
        if self.storage.connected().unwrap_or(false) {
            self.storage.stop().await;
        }

        log_debug!(self.logger, "finished calling stop");
        Ok(())
    }

    pub async fn change_password(
        &mut self,
        old: Option<String>,
        new: Option<String>,
    ) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling change_password");

        // check if old password is correct
        if old != self.storage.password().map(|s| s.to_owned()) {
            return Err(MutinyError::IncorrectPassword);
        }

        if old == new {
            return Err(MutinyError::SamePassword);
        }

        log_info!(self.logger, "Changing password");

        self.stop().await?;

        self.start().await?;

        self.storage.change_password_and_rewrite_storage(
            old.filter(|s| !s.is_empty()),
            new.filter(|s| !s.is_empty()),
        )?;

        // There's not a good way to check that all the indexeddb
        // data is saved in the background. This should get better
        // once we have async saving, but for now just make sure
        // the user has saved their seed already.
        sleep(5_000).await;

        log_trace!(self.logger, "finished calling change_password");
        Ok(())
    }

    /// Resets BDK's keychain tracker. This will require a re-sync of the blockchain.
    ///
    /// This can be useful if you get stuck in a bad state.
    pub async fn reset_onchain_tracker(&mut self) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling reset_onchain_tracker");

        let node_manager = self.node_manager.as_ref().ok_or(MutinyError::NotRunning)?;

        node_manager.reset_onchain_tracker().await?;
        // sleep for 250ms to give time for the storage to write
        utils::sleep(250).await;

        self.stop().await?;

        // sleep for 250ms to give time for the node manager to stop
        utils::sleep(250).await;

        self.start().await?;

        let node_manager = self.node_manager.as_ref().ok_or(MutinyError::NotRunning)?;
        node_manager.wallet.full_sync(FULL_SYNC_STOP_GAP).await?;

        log_trace!(self.logger, "finished calling reset_onchain_tracker");
        Ok(())
    }

    /// Deletes all the storage
    pub async fn delete_all(&self) -> Result<(), MutinyError> {
        log_debug!(self.logger, "calling delete_all");
        if self.node_manager.is_some() {
            return Err(MutinyError::AlreadyRunning);
        }

        self.storage.stop().await;

        self.storage.delete_all().await?;
        log_debug!(self.logger, "finished calling delete_all");

        Ok(())
    }

    /// Restores the mnemonic after deleting the previous state.
    ///
    /// Backup the state beforehand. Does not restore lightning data.
    /// Should refresh or restart afterwards. Wallet should be stopped.
    pub async fn restore_mnemonic(mut storage: S, m: Mnemonic) -> Result<(), MutinyError> {
        // Delete our storage but insert some device specific data
        let device_id = storage.get_device_id()?;
        let logs: Option<Vec<String>> = storage.get_data(LOGGING_KEY)?;
        storage.stop().await;
        S::clear(storage.database()?).await?;
        storage.start().await?;
        storage.insert_mnemonic(m)?;
        storage.write_data(NEED_FULL_SYNC_KEY.to_string(), true, None)?;
        storage.write_data(DEVICE_ID_KEY.to_string(), device_id, None)?;
        storage.write_data(LOGGING_KEY.to_string(), logs, None)?;

        Ok(())
    }

    /// Decodes a lightning invoice into useful information.
    /// Will return an error if the invoice is for a different network.
    pub fn decode_invoice(
        &self,
        invoice: Bolt11Invoice,
        network: Option<Network>,
    ) -> Result<MutinyInvoice, MutinyError> {
        log_trace!(self.logger, "calling decode_invoice");

        if invoice.network() != network.unwrap_or(self.network) {
            return Err(MutinyError::IncorrectNetwork);
        }

        let res = invoice.into();
        log_trace!(self.logger, "finished calling decode_invoice");

        Ok(res)
    }

    pub fn is_safe_mode(&self) -> bool {
        self.safe_mode
    }

    /// Gets the current bitcoin price in USD.
    pub async fn get_bitcoin_price(&self, fiat: Option<String>) -> Result<f32, MutinyError> {
        log_trace!(self.logger, "calling get_bitcoin_price");

        let now = crate::utils::now();
        let fiat = fiat.unwrap_or("usd".to_string());

        let cache_result = {
            let cache = self.bitcoin_price_cache.lock().await;
            cache.get(&fiat).cloned()
        };

        let res = match cache_result {
            Some((price, timestamp)) if timestamp == Duration::from_secs(0) => {
                // Cache is from previous run, return it but fetch a new price in the background
                let cache = self.bitcoin_price_cache.clone();
                let storage = self.storage.clone();
                let logger = self.logger.clone();
                spawn(async move {
                    if let Err(e) =
                        Self::fetch_and_cache_price(fiat, now, cache, storage, logger.clone()).await
                    {
                        log_warn!(logger, "failed to fetch bitcoin price: {e:?}");
                    }
                });
                Ok(price)
            }
            Some((price, timestamp))
                if timestamp + Duration::from_secs(BITCOIN_PRICE_CACHE_SEC) > now =>
            {
                // Cache is not expired
                Ok(price)
            }
            _ => {
                // Cache is either expired, empty, or doesn't have the desired fiat value
                Self::fetch_and_cache_price(
                    fiat,
                    now,
                    self.bitcoin_price_cache.clone(),
                    self.storage.clone(),
                    self.logger.clone(),
                )
                .await
            }
        };
        log_trace!(self.logger, "finished calling get_bitcoin_price");

        res
    }

    async fn fetch_and_cache_price(
        fiat: String,
        now: Duration,
        bitcoin_price_cache: Arc<Mutex<HashMap<String, (f32, Duration)>>>,
        storage: S,
        logger: Arc<MutinyLogger>,
    ) -> Result<f32, MutinyError> {
        match Self::fetch_bitcoin_price(&fiat).await {
            Ok(new_price) => {
                let mut cache = bitcoin_price_cache.lock().await;
                let cache_entry = (new_price, now);
                cache.insert(fiat.clone(), cache_entry);

                // save to storage in the background
                let cache_clone = cache.clone();
                spawn(async move {
                    let cache = cache_clone
                        .into_iter()
                        .map(|(k, (price, _))| (k, price))
                        .collect();

                    if let Err(e) = storage.insert_bitcoin_price_cache(cache) {
                        log_error!(logger, "failed to save bitcoin price cache: {e:?}");
                    }
                });

                Ok(new_price)
            }
            Err(e) => {
                // If fetching price fails, return the cached price (if any)
                let cache = bitcoin_price_cache.lock().await;
                if let Some((price, _)) = cache.get(&fiat) {
                    log_warn!(logger, "price api failed, returning cached price");
                    Ok(*price)
                } else {
                    // If there is no cached price, return the error
                    log_error!(logger, "no cached price and price api failed for {fiat}");
                    Err(e)
                }
            }
        }
    }

    async fn fetch_bitcoin_price(fiat: &str) -> Result<f32, MutinyError> {
        let api_url = format!("https://price.mutinywallet.com/price/{fiat}");

        let client = reqwest::Client::builder()
            .build()
            .map_err(|_| MutinyError::BitcoinPriceError)?;

        let request = client
            .get(api_url)
            .build()
            .map_err(|_| MutinyError::BitcoinPriceError)?;

        let resp: reqwest::Response = utils::fetch_with_timeout(&client, request).await?;

        let response: BitcoinPriceResponse = resp
            .error_for_status()
            .map_err(|_| MutinyError::BitcoinPriceError)?
            .json()
            .await
            .map_err(|_| MutinyError::BitcoinPriceError)?;

        Ok(response.price)
    }

    /// Returns the network of the wallet.
    pub fn get_network(&self) -> Network {
        self.network
    }
}

impl<S: MutinyStorage> InvoiceHandler for MutinyWallet<S> {
    fn logger(&self) -> &MutinyLogger {
        self.logger.as_ref()
    }

    fn skip_hodl_invoices(&self) -> bool {
        self.skip_hodl_invoices
    }

    fn get_network(&self) -> Network {
        self.network
    }

    async fn get_best_block(&self) -> Result<BestBlock, MutinyError> {
        let node = self
            .node_manager
            .as_ref()
            .ok_or(MutinyError::NotRunning)?
            .get_node_by_key_or_first(None)
            .await?;
        Ok(node.channel_manager.current_best_block())
    }

    async fn lookup_payment(&self, payment_hash: &[u8; 32]) -> Option<MutinyInvoice> {
        self.get_invoice_by_hash(&sha256::Hash::from_byte_array(*payment_hash))
            .await
            .ok()
    }

    async fn pay_invoice(
        &self,
        invoice: &Bolt11Invoice,
        amt_sats: Option<u64>,
        labels: Vec<String>,
    ) -> Result<MutinyInvoice, MutinyError> {
        self.pay_invoice(invoice, amt_sats, labels).await
    }

    async fn create_invoice(
        &self,
        amount: Option<u64>,
        labels: Vec<String>,
        expiry_delta_secs: Option<u32>,
    ) -> Result<MutinyInvoice, MutinyError> {
        self.create_lightning_invoice(amount, labels, expiry_delta_secs)
            .await
    }
}

#[derive(Deserialize, Clone, Copy, Debug)]
struct BitcoinPriceResponse {
    pub price: f32,
}

#[cfg(test)]
#[cfg(target_arch = "wasm32")]
mod tests {
    use crate::storage::{
        payment_key, persist_payment_info, IndexItem, MemoryStorage, MutinyStorage, ONCHAIN_PREFIX,
        PAYMENT_OUTBOUND_PREFIX_KEY,
    };
    use crate::{
        encrypt::encryption_key_from_pass, generate_seed, nodemanager::NodeManager, MutinyWallet,
        MutinyWalletBuilder, MutinyWalletConfigBuilder,
    };
    use crate::{
        event::{HTLCStatus, MillisatAmount, PaymentInfo},
        TransactionDetails,
    };
    use crate::{ldkstorage::CHANNEL_CLOSURE_PREFIX, storage::persist_transaction_details};
    use crate::{nodemanager::ChannelClosure, storage::TRANSACTION_DETAILS_PREFIX_KEY};
    use bdk_chain::{BlockId, ConfirmationTime};
    use bitcoin::bip32::Xpriv;
    use bitcoin::hashes::hex::FromHex;
    use bitcoin::hashes::Hash;
    use bitcoin::secp256k1::PublicKey;
    use bitcoin::transaction::Version;
    use bitcoin::{absolute::LockTime, Txid};
    use bitcoin::{Amount, BlockHash, Network, Transaction, TxOut};
    use hex_conservative::DisplayHex;
    use itertools::Itertools;
    use std::str::FromStr;

    use crate::test_utils::*;

    use crate::utils::{now, sleep};
    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};

    wasm_bindgen_test_configure!(run_in_browser);

    #[test]
    async fn create_mutiny_wallet() {
        let test_name = "create_mutiny_wallet";
        log!("{}", test_name);

        let mnemonic = generate_seed(12).unwrap();
        let network = Network::Regtest;
        let xpriv = Xpriv::new_master(network, &mnemonic.to_seed("")).unwrap();

        let pass = uuid::Uuid::new_v4().to_string();
        let cipher = encryption_key_from_pass(&pass).unwrap();
        let storage = MemoryStorage::new(Some(pass), Some(cipher), None);
        assert!(!NodeManager::has_node_manager(storage.clone()));
        let config = MutinyWalletConfigBuilder::new(xpriv)
            .with_network(network)
            .build();
        let mw = MutinyWalletBuilder::new(xpriv, storage.clone())
            .with_config(config)
            .build()
            .await
            .expect("mutiny wallet should initialize");
        mw.storage.insert_mnemonic(mnemonic).unwrap();
        assert!(NodeManager::has_node_manager(storage));
    }

    #[test]
    async fn restart_mutiny_wallet() {
        let test_name = "restart_mutiny_wallet";
        log!("{}", test_name);
        let network = Network::Regtest;
        let xpriv = Xpriv::new_master(network, &[0; 32]).unwrap();

        let pass = uuid::Uuid::new_v4().to_string();
        let cipher = encryption_key_from_pass(&pass).unwrap();
        let storage = MemoryStorage::new(Some(pass), Some(cipher), None);
        assert!(!NodeManager::has_node_manager(storage.clone()));
        let config = MutinyWalletConfigBuilder::new(xpriv)
            .with_network(network)
            .build();
        let mut mw = MutinyWalletBuilder::new(xpriv, storage.clone())
            .with_config(config)
            .build()
            .await
            .expect("mutiny wallet should initialize");

        let first_seed = mw.node_manager.as_ref().unwrap().xprivkey;

        assert!(mw.stop().await.is_ok());
        assert!(mw.start().await.is_ok());
        assert_eq!(first_seed, mw.node_manager.as_ref().unwrap().xprivkey);
    }

    #[test]
    async fn restart_mutiny_wallet_with_nodes() {
        let test_name = "restart_mutiny_wallet_with_nodes";
        log!("{}", test_name);

        let network = Network::Regtest;
        let xpriv = Xpriv::new_master(network, &[0; 32]).unwrap();

        let pass = uuid::Uuid::new_v4().to_string();
        let cipher = encryption_key_from_pass(&pass).unwrap();
        let storage = MemoryStorage::new(Some(pass), Some(cipher), None);

        assert!(!NodeManager::has_node_manager(storage.clone()));
        let config = MutinyWalletConfigBuilder::new(xpriv)
            .with_network(network)
            .build();
        let mut mw = MutinyWalletBuilder::new(xpriv, storage.clone())
            .with_config(config)
            .build()
            .await
            .expect("mutiny wallet should initialize");

        // let storage persist
        sleep(1000).await;

        assert_eq!(
            mw.node_manager
                .as_ref()
                .unwrap()
                .list_nodes()
                .await
                .unwrap()
                .len(),
            1
        );

        assert!(mw.node_manager.as_ref().unwrap().new_node().await.is_ok());
        // let storage persist
        sleep(1000).await;

        assert_eq!(
            mw.node_manager
                .as_ref()
                .unwrap()
                .list_nodes()
                .await
                .unwrap()
                .len(),
            2
        );

        assert!(mw.stop().await.is_ok());
        assert!(mw.start().await.is_ok());
        assert_eq!(
            mw.node_manager
                .as_ref()
                .unwrap()
                .list_nodes()
                .await
                .unwrap()
                .len(),
            2
        );
    }

    #[test]
    async fn restore_mutiny_mnemonic() {
        let test_name = "restore_mutiny_mnemonic";
        log!("{}", test_name);
        let mnemonic = generate_seed(12).unwrap();
        let network = Network::Regtest;
        let xpriv = Xpriv::new_master(network, &mnemonic.to_seed("")).unwrap();

        let pass = uuid::Uuid::new_v4().to_string();
        let cipher = encryption_key_from_pass(&pass).unwrap();
        let storage = MemoryStorage::new(Some(pass), Some(cipher), None);
        assert!(!NodeManager::has_node_manager(storage.clone()));
        let config = MutinyWalletConfigBuilder::new(xpriv)
            .with_network(network)
            .build();
        let mw = MutinyWalletBuilder::new(xpriv, storage.clone())
            .with_config(config)
            .build()
            .await
            .expect("mutiny wallet should initialize");
        let seed = mw.node_manager.as_ref().unwrap().xprivkey;
        assert!(!seed.private_key.secret_bytes().is_empty());

        // create a second mw and make sure it has a different seed
        let pass = uuid::Uuid::new_v4().to_string();
        let cipher = encryption_key_from_pass(&pass).unwrap();
        let storage2 = MemoryStorage::new(Some(pass), Some(cipher), None);
        assert!(!NodeManager::has_node_manager(storage2.clone()));
        let xpriv2 = Xpriv::new_master(network, &[0; 32]).unwrap();
        let config2 = MutinyWalletConfigBuilder::new(xpriv2)
            .with_network(network)
            .build();
        let mut mw2 = MutinyWalletBuilder::new(xpriv2, storage2.clone())
            .with_config(config2)
            .build()
            .await
            .expect("mutiny wallet should initialize");
        let seed2 = mw2.node_manager.as_ref().unwrap().xprivkey;
        assert_ne!(seed, seed2);

        // now restore the first seed into the 2nd mutiny node
        mw2.stop().await.expect("should stop");
        drop(mw2);

        let pass = uuid::Uuid::new_v4().to_string();
        let cipher = encryption_key_from_pass(&pass).unwrap();
        let storage3 = MemoryStorage::new(Some(pass), Some(cipher), None);

        MutinyWallet::restore_mnemonic(storage3.clone(), mnemonic.clone())
            .await
            .expect("mutiny wallet should restore");

        let new_mnemonic = storage3.get_mnemonic().unwrap().unwrap();
        let new_xpriv = Xpriv::new_master(network, &new_mnemonic.to_seed("")).unwrap();
        let config3 = MutinyWalletConfigBuilder::new(new_xpriv)
            .with_network(network)
            .build();
        let mw3 = MutinyWalletBuilder::new(new_xpriv, storage3.clone())
            .with_config(config3)
            .build()
            .await
            .expect("mutiny wallet should initialize");
        let restored_seed = mw3.node_manager.as_ref().unwrap().xprivkey;
        assert_eq!(seed, restored_seed);
    }

    #[test]
    async fn create_mutiny_wallet_safe_mode() {
        let test_name = "create_mutiny_wallet";
        log!("{}", test_name);

        let mnemonic = generate_seed(12).unwrap();
        let network = Network::Regtest;
        let xpriv = Xpriv::new_master(network, &mnemonic.to_seed("")).unwrap();

        let pass = uuid::Uuid::new_v4().to_string();
        let cipher = encryption_key_from_pass(&pass).unwrap();
        let storage = MemoryStorage::new(Some(pass), Some(cipher), None);
        assert!(!NodeManager::has_node_manager(storage.clone()));
        let mut config_builder = MutinyWalletConfigBuilder::new(xpriv).with_network(network);
        config_builder.with_safe_mode();
        let config = config_builder.build();
        let mw = MutinyWalletBuilder::new(xpriv, storage.clone())
            .with_config(config)
            .build()
            .await
            .expect("mutiny wallet should initialize");
        mw.storage.insert_mnemonic(mnemonic).unwrap();
        assert!(NodeManager::has_node_manager(storage));

        let bip21 = mw.create_bip21(None, vec![]).await.unwrap();
        assert!(bip21.invoice.is_none());

        let new_node = mw.node_manager.as_ref().unwrap().new_node().await;
        assert!(new_node.is_err());
    }

    #[test]
    async fn test_sort_index_item() {
        let test_name = "test_sort_index_item";
        log!("{}", test_name);

        let storage = MemoryStorage::new(None, None, None);
        let seed = generate_seed(12).expect("Failed to gen seed");
        let network = Network::Regtest;
        let xpriv = Xpriv::new_master(network, &seed.to_seed("")).unwrap();
        let c = MutinyWalletConfigBuilder::new(xpriv)
            .with_network(network)
            .build();
        let mw = MutinyWalletBuilder::new(xpriv, storage.clone())
            .with_config(c)
            .build()
            .await
            .expect("mutiny wallet should initialize");

        loop {
            if !mw
                .node_manager
                .as_ref()
                .unwrap()
                .list_nodes()
                .await
                .unwrap()
                .is_empty()
            {
                break;
            }
            sleep(100).await;
        }

        let node = mw
            .node_manager
            .as_ref()
            .unwrap()
            .get_node_by_key_or_first(None)
            .await
            .unwrap();

        let closure: ChannelClosure = ChannelClosure {
            user_channel_id: None,
            channel_id: None,
            node_id: None,
            reason: "".to_string(),
            timestamp: 1686258926,
            channel_funding_txo: None,
            force_close_spend_delay: None,
        };
        let closure_chan_id: u128 = 6969;
        node.persister
            .persist_channel_closure(closure_chan_id, closure.clone())
            .unwrap();

        let address = mw
            .node_manager
            .as_ref()
            .unwrap()
            .get_new_address(vec![])
            .unwrap();
        let output = TxOut {
            value: Amount::from_sat(10_000),
            script_pubkey: address.script_pubkey(),
        };
        let tx1 = Transaction {
            version: Version(1),
            lock_time: LockTime::ZERO,
            input: vec![],
            output: vec![output.clone()],
        };
        mw.node_manager
            .as_ref()
            .unwrap()
            .wallet
            .insert_tx(
                tx1.clone(),
                ConfirmationTime::Unconfirmed { last_seen: 0 },
                None,
            )
            .await
            .unwrap();

        let tx2 = Transaction {
            version: Version(2), // tx2 has different version than tx1 so they have different txids
            lock_time: LockTime::ZERO,
            input: vec![],
            output: vec![output],
        };
        mw.node_manager
            .as_ref()
            .unwrap()
            .wallet
            .insert_tx(
                tx2.clone(),
                ConfirmationTime::Confirmed {
                    height: 1,
                    time: 1234,
                },
                Some(BlockId {
                    height: 1,
                    hash: BlockHash::all_zeros(),
                }),
            )
            .await
            .unwrap();

        let pubkey = PublicKey::from_str(
            "02465ed5be53d04fde66c9418ff14a5f2267723810176c9212b722e542dc1afb1b",
        )
        .unwrap();

        let payment_hash1: [u8; 32] =
            FromHex::from_hex("55ecf9169a6fa07e8ba181fdddf5b0bcc7860176659fa22a7cca9da2a359a33b")
                .unwrap();
        let invoice1 = PaymentInfo {
            bolt11: None,
            preimage: None,
            payee_pubkey: Some(pubkey),
            status: HTLCStatus::Succeeded,
            amt_msat: MillisatAmount(Some(100 * 1_000)),
            last_update: 1681781585,
            secret: None,
            fee_paid_msat: None,
            privacy_level: Default::default(),
        };
        persist_payment_info(&storage, &payment_hash1, &invoice1, false).unwrap();

        let payment_hash2: [u8; 32] =
            FromHex::from_hex("661ab24752eb99fc9c90236ffe348b1f8b9da5b9c00601c711d53589d98e7919")
                .unwrap();
        let invoice2 = PaymentInfo {
            bolt11: None,
            preimage: None,
            secret: None,
            payee_pubkey: Some(pubkey),
            amt_msat: MillisatAmount(Some(100 * 1_000)),
            last_update: 1781781585,
            status: HTLCStatus::Succeeded,
            fee_paid_msat: None,
            privacy_level: Default::default(),
        };
        persist_payment_info(&storage, &payment_hash2, &invoice2, false).unwrap();

        let payment_hash3: [u8; 32] =
            FromHex::from_hex("ab98fb003849d440b49346c213bdae018468b9f2dbd731726f0aaf581fda4ad1")
                .unwrap();
        let invoice3 = PaymentInfo {
            bolt11: None,
            preimage: None,
            payee_pubkey: Some(pubkey),
            amt_msat: MillisatAmount(Some(101 * 1_000)),
            status: HTLCStatus::InFlight,
            last_update: 1581781585,
            secret: None,
            fee_paid_msat: None,
            privacy_level: Default::default(),
        };
        persist_payment_info(&storage, &payment_hash3, &invoice3, false).unwrap();

        let payment_hash4: [u8; 32] =
            FromHex::from_hex("3287bdd9c82dbb91acdffcb103b1235c74060c01b9d22b4a62184bff290e1e7e")
                .unwrap();
        let mut invoice4 = PaymentInfo {
            bolt11: None,
            preimage: None,
            payee_pubkey: Some(pubkey),
            amt_msat: MillisatAmount(Some(102 * 1_000)),
            status: HTLCStatus::InFlight,
            fee_paid_msat: None,
            last_update: 1581781585,
            secret: None,
            privacy_level: Default::default(),
        };
        persist_payment_info(&storage, &payment_hash4, &invoice4, false).unwrap();

        let transaction_details1 = TransactionDetails {
            transaction: None,
            txid: Some(Txid::all_zeros()),
            internal_id: Txid::all_zeros(),
            received: 0,
            sent: 10_000,
            fee: Some(100),
            confirmation_time: ConfirmationTime::Unconfirmed {
                last_seen: now().as_secs(),
            },
            labels: vec![],
        };
        persist_transaction_details(&storage, &transaction_details1).unwrap();

        let vec = {
            let index = storage.activity_index();
            let vec = index.read().unwrap().clone().into_iter().collect_vec();
            vec
        };

        let expected = vec![
            IndexItem {
                timestamp: None,
                key: format!("{ONCHAIN_PREFIX}{}", tx1.compute_txid()),
            },
            IndexItem {
                timestamp: None,
                key: format!(
                    "{PAYMENT_OUTBOUND_PREFIX_KEY}{}",
                    payment_hash4.to_lower_hex_string()
                ),
            },
            IndexItem {
                timestamp: None,
                key: format!(
                    "{PAYMENT_OUTBOUND_PREFIX_KEY}{}",
                    payment_hash3.to_lower_hex_string()
                ),
            },
            IndexItem {
                timestamp: None,
                key: format!(
                    "{TRANSACTION_DETAILS_PREFIX_KEY}{}",
                    transaction_details1.internal_id
                ),
            },
            IndexItem {
                timestamp: Some(invoice2.last_update),
                key: format!(
                    "{PAYMENT_OUTBOUND_PREFIX_KEY}{}",
                    payment_hash2.to_lower_hex_string()
                ),
            },
            IndexItem {
                timestamp: Some(closure.timestamp),
                key: format!(
                    "{CHANNEL_CLOSURE_PREFIX}{}_{}",
                    closure_chan_id.to_be_bytes().to_lower_hex_string(),
                    node.uuid
                ),
            },
            IndexItem {
                timestamp: Some(invoice1.last_update),
                key: format!(
                    "{PAYMENT_OUTBOUND_PREFIX_KEY}{}",
                    payment_hash1.to_lower_hex_string()
                ),
            },
            IndexItem {
                timestamp: Some(1234),
                key: format!("{ONCHAIN_PREFIX}{}", tx2.compute_txid()),
            },
        ];

        assert_eq!(vec.len(), expected.len()); // make sure im not dumb
        assert_eq!(vec, expected);

        let activity = mw.get_activity(None, None).unwrap();
        assert_eq!(activity.len(), expected.len());

        let with_limit = mw.get_activity(Some(3), None).unwrap();
        assert_eq!(with_limit.len(), 3);

        let with_offset = mw.get_activity(None, Some(3)).unwrap();
        assert_eq!(with_offset.len(), activity.len() - 3);

        let with_both = mw.get_activity(Some(3), Some(3)).unwrap();
        assert_eq!(with_limit.len(), 3);
        assert_ne!(with_both, with_limit);

        // check we handle out of bounds errors
        let with_limit_oob = mw.get_activity(Some(usize::MAX), None).unwrap();
        assert_eq!(with_limit_oob.len(), expected.len());
        let with_offset_oob = mw.get_activity(None, Some(usize::MAX)).unwrap();
        assert!(with_offset_oob.is_empty());
        let with_offset_oob = mw.get_activity(None, Some(expected.len())).unwrap();
        assert!(with_offset_oob.is_empty());
        let with_both_oob = mw.get_activity(Some(usize::MAX), Some(usize::MAX)).unwrap();
        assert!(with_both_oob.is_empty());

        // update an inflight payment and make sure it isn't duplicated
        invoice4.last_update = now().as_secs();
        invoice4.status = HTLCStatus::Succeeded;
        persist_payment_info(&storage, &payment_hash4, &invoice4, false).unwrap();

        let vec = {
            let index = storage.activity_index();
            let vec = index.read().unwrap().clone().into_iter().collect_vec();
            vec
        };

        let item = vec
            .iter()
            .find(|i| i.key == payment_key(false, &payment_hash4));
        assert!(item.is_some_and(|i| i.timestamp == Some(invoice4.last_update))); // make sure timestamp got updated
        assert_eq!(vec.len(), expected.len()); // make sure no duplicates
    }
}


================================================
File: mutiny-core/src/logging.rs
================================================
use std::sync::Arc;

use crate::utils::Mutex;
use crate::{error::MutinyError, utils, utils::sleep};
use crate::{storage::MutinyStorage, utils::StopHandle};
use chrono::Utc;
use hex_conservative::DisplayHex;
use lightning::util::logger::{Level, Logger, Record};
use log::*;

pub const LOGGING_KEY: &str = "logs";

const MAX_LOG_ITEMS: usize = 10_000;

#[derive(Clone)]
pub struct MutinyLogger {
    pub session_id: String,
    should_write: bool,
    should_persist: bool,
    memory_logs: Arc<Mutex<Vec<String>>>,
    stop_handle: Option<StopHandle>,
}

impl MutinyLogger {
    pub fn memory_only() -> Self {
        Self {
            should_persist: false,
            should_write: true,
            ..Default::default()
        }
    }

    pub fn with_writer<S: MutinyStorage>(
        logging_db: S,
        session_id: Option<String>,
        logs: Vec<String>,
    ) -> Self {
        let memory_logs = Arc::new(Mutex::new(logs));

        let stop_handle = utils::spawn_with_handle({
            let memory_logs = memory_logs.clone();
            |stop_signal| {
                async move {
                    loop {
                        // wait up to 5s, checking graceful shutdown check each 1s.
                        for _ in 0..5 {
                            if stop_signal.stopping() {
                                logging_db.stop().await;
                                return;
                            }
                            sleep(1_000).await;
                        }

                        // if there's any in memory logs, append them to the file system
                        let memory_logs_clone = {
                            if let Ok(mut memory_logs) = memory_logs.lock() {
                                let logs = memory_logs.clone();
                                memory_logs.clear();
                                Some(logs)
                            } else {
                                warn!("Failed to lock memory_logs, log entries may be lost.");
                                None
                            }
                        };

                        if let Some(logs) = memory_logs_clone {
                            if !logs.is_empty() {
                                // append them to storage
                                match write_logging_data(&logging_db, logs) {
                                    Ok(_) => {}
                                    Err(_) => {
                                        error!("could not write logging data to storage, trying again next time, log entries may be lost");
                                    }
                                }
                            }
                        }
                    }
                }
            }
        });

        MutinyLogger {
            session_id: session_id.unwrap_or_else(gen_session_id),
            should_write: true,
            should_persist: true,
            memory_logs,
            stop_handle: Some(stop_handle),
        }
    }

    pub fn get_memory_logs(&self) -> Result<Vec<String>, MutinyError> {
        let logs = self
            .memory_logs
            .lock()
            .map_err(|_err| MutinyError::Other(anyhow::anyhow!("can't get memory logs lock")))?
            .to_vec();
        Ok(logs)
    }

    pub(crate) fn get_logs<S: MutinyStorage>(
        &self,
        storage: &S,
    ) -> Result<Option<Vec<String>>, MutinyError> {
        if !self.should_write || !self.should_persist {
            return Ok(None);
        }
        get_logging_data(storage)
    }

    pub(crate) async fn stop(&self) {
        if let Some(stop_handle) = self.stop_handle.as_ref() {
            stop_handle.stop().await
        }
    }
}

impl Default for MutinyLogger {
    fn default() -> Self {
        Self {
            session_id: gen_session_id(),
            should_write: false,
            should_persist: false,
            memory_logs: Arc::new(Mutex::new(vec![])),
            stop_handle: None,
        }
    }
}

fn gen_session_id() -> String {
    let mut entropy = vec![0u8; 2];
    getrandom::getrandom(&mut entropy).unwrap();
    entropy.to_lower_hex_string()
}

impl Logger for MutinyLogger {
    fn log(&self, record: Record) {
        let raw_log = record.args.to_string();
        let log = format!(
            "{} {} {:<5} [{}:{}] {}\n",
            // Note that a "real" lightning node almost certainly does *not* want subsecond
            // precision for message-receipt information as it makes log entries a target for
            // deanonymization attacks. For testing, however, its quite useful.
            Utc::now().format("%Y-%m-%d %H:%M:%S%.3f"),
            // log the session id so we can tie logs to a particular session, useful for detecting
            // if we have multiple sessions running at once
            self.session_id,
            record.level,
            record.module_path,
            record.line,
            raw_log
        );

        if self.should_write && record.level >= Level::Trace {
            if let Ok(mut memory_logs) = self.memory_logs.lock() {
                memory_logs.push(log.clone());
            } else {
                warn!("Failed to lock memory_logs, log entry may be lost.");
            }
        }

        match record.level {
            Level::Gossip => (), // way too noisy
            Level::Trace => trace!("{}", log),
            Level::Debug => debug!("{}", log),
            Level::Info => info!("{}", log),
            Level::Warn => warn!("{}", log),
            Level::Error => error!("{}", log),
        }
    }
}

fn get_logging_data<S: MutinyStorage>(storage: &S) -> Result<Option<Vec<String>>, MutinyError> {
    storage.get_data(LOGGING_KEY)
}

fn write_logging_data<S: MutinyStorage>(
    storage: &S,
    mut recent_logs: Vec<String>,
) -> Result<(), MutinyError> {
    // get the existing data so we can append to it, trimming if needed
    // Note there is a potential race condition here if the logs are being written to
    // concurrently, but we don't care about that for now.
    let mut existing_logs: Vec<String> = get_logging_data(storage)?.unwrap_or_default();
    existing_logs.append(&mut recent_logs);
    if existing_logs.len() > MAX_LOG_ITEMS {
        let start_index = existing_logs.len() - MAX_LOG_ITEMS;
        existing_logs.drain(..start_index);
    }

    // Save the logs
    storage.write_data(LOGGING_KEY.to_string(), &existing_logs, None)?;

    Ok(())
}

#[cfg(test)]
use crate::test_utils::log;

#[cfg(test)]
#[derive(Clone)]
pub struct TestLogger {}

#[cfg(test)]
impl Logger for TestLogger {
    fn log(&self, record: Record) {
        let raw_log = record.args.to_string();
        let log = format!(
            "{} {:<5} [{}:{}] {}\n",
            // Note that a "real" lightning node almost certainly does *not* want subsecond
            // precision for message-receipt information as it makes log entries a target for
            // deanonymization attacks. For testing, however, its quite useful.
            Utc::now().format("%Y-%m-%d %H:%M:%S%.3f"),
            record.level,
            record.module_path,
            record.line,
            raw_log
        );

        log!("{}", log);
    }
}

#[cfg(test)]
mod tests {
    use lightning::{log_debug, util::logger::Logger};
    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};

    wasm_bindgen_test_configure!(run_in_browser);

    use crate::{test_utils::*, utils::sleep};

    use crate::logging::MutinyLogger;
    use crate::storage::MemoryStorage;

    #[test]
    async fn log_without_storage() {
        let test_name = "log_without_storage";
        log!("{}", test_name);

        let logger = MutinyLogger::default();
        assert_eq!(logger.get_logs(&()).unwrap(), None);

        log_debug!(logger, "testing");

        // saves every 5s, so do one second later
        sleep(6_000).await;

        assert_eq!(logger.get_logs(&()).unwrap(), None);
    }

    #[test]
    async fn log_with_storage() {
        let test_name = "log_with_storage";
        log!("{}", test_name);

        let storage = MemoryStorage::default();

        let logger = MutinyLogger::with_writer(storage.clone(), None, Default::default());

        let log_str = "testing logging with storage";
        log_debug!(logger, "{}", log_str);

        // saves every 5s, so do one second later
        sleep(6_000).await;

        assert!(logger
            .get_logs(&storage)
            .unwrap()
            .unwrap()
            .first()
            .unwrap()
            .contains(log_str));

        logger.stop().await;
    }
}


================================================
File: mutiny-core/src/messagehandler.rs
================================================
use std::sync::Arc;

use bitcoin::secp256k1::PublicKey;
use lightning::io::{Error, Read};
use lightning::ln::features::{InitFeatures, NodeFeatures};
use lightning::ln::msgs::{DecodeError, LightningError};
use lightning::ln::peer_handler::CustomMessageHandler;
use lightning::ln::wire::{CustomMessageReader, Type};
use lightning::util::ser::{Writeable, Writer};
use serde::{Deserialize, Serialize};

use crate::node::LiquidityManager;
use crate::storage::MutinyStorage;

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq, Eq, Hash)]
pub struct BumpChannelClosureTransaction {
    pub channel_id: String,
    pub txid: String,
    pub hex_tx: String,
    pub timestamp: u64,
}

#[derive(Serialize, Deserialize)]
#[serde(tag = "type")]
pub enum CommonLnEvent {
    // On Peer Connect
    OnConnect {
        their_node_id: String,
        inbound: bool,
        remote_network_address: Option<String>,
    },
    // On Peer Disconnect
    OnDisconnect {
        their_node_id: String,
    },
    BumpChannelCloseTransaction {
        channel_id: String,
        txid: String,
        hex_tx: String,
        timestamp: u64,
    },
    ChannelClosed {
        channel_id: String,
        reason: String,
        counterparty_node_id: Option<String>,
        channel_funding_txo: Option<String>,
        // This field may return true on a cooperate close event,
        // this must only be used to report debugging information.
        maybe_force_closed: bool,
    },
    // Sent payment
    PaymentSent {
        payment_hash: String,
    },
    // Sent payment failed
    PaymentFailed {
        payment_hash: String,
        reason: Option<String>,
    },
    // Received payment
    PaymentClaimed {
        /// The node that received the payment.
        receiver_node_id: Option<String>,
        /// The payment hash of the payment.
        payment_hash: String,
        amount_msat: u64,
    },
    // Wallet first synced
    WalletFirstSynced,
    // Transaction broadcasted
    TxBroadcasted {
        txid: String,
        hex_tx: String,
    },
}

#[derive(Clone)]
pub struct CommonLnEventCallback {
    pub callback: Arc<dyn Fn(CommonLnEvent) + Send + Sync>,
}

impl CommonLnEventCallback {
    pub fn trigger(&self, event: CommonLnEvent) {
        (self.callback)(event);
    }
}

pub struct MutinyMessageHandler<S: MutinyStorage> {
    pub liquidity: Option<Arc<LiquidityManager<S>>>,
    pub ln_event_callback: Option<CommonLnEventCallback>,
}

pub enum MutinyMessage<S: MutinyStorage> {
    Liquidity(<LiquidityManager<S> as CustomMessageReader>::CustomMessage),
}

impl<S: MutinyStorage> std::fmt::Debug for MutinyMessage<S> {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::Liquidity(arg0) => f.debug_tuple("Liquidity").field(arg0).finish(),
        }
    }
}

impl<S: MutinyStorage> CustomMessageHandler for MutinyMessageHandler<S> {
    fn handle_custom_message(
        &self,
        msg: Self::CustomMessage,
        sender_node_id: &PublicKey,
    ) -> Result<(), LightningError> {
        match msg {
            MutinyMessage::Liquidity(message) => {
                if let Some(liquidity) = &self.liquidity {
                    return CustomMessageHandler::handle_custom_message(
                        liquidity.as_ref(),
                        message,
                        sender_node_id,
                    );
                }
            }
        }

        Ok(())
    }

    fn get_and_clear_pending_msg(&self) -> Vec<(PublicKey, Self::CustomMessage)> {
        if let Some(liquidity) = &self.liquidity {
            liquidity
                .get_and_clear_pending_msg()
                .into_iter()
                .map(|(pubkey, message)| (pubkey, MutinyMessage::Liquidity(message)))
                .collect()
        } else {
            vec![]
        }
    }

    fn provided_node_features(&self) -> NodeFeatures {
        match &self.liquidity {
            Some(liquidity) => liquidity.provided_node_features(),
            None => NodeFeatures::empty(),
        }
    }

    fn provided_init_features(&self, their_node_id: &PublicKey) -> InitFeatures {
        match &self.liquidity {
            Some(liquidity) => liquidity.provided_init_features(their_node_id),
            None => InitFeatures::empty(),
        }
    }

    fn peer_connected(
        &self,
        their_node_id: &PublicKey,
        msg: &lightning::ln::msgs::Init,
        inbound: bool,
    ) -> Result<(), ()> {
        if let Some(cb) = self.ln_event_callback.clone() {
            let event = CommonLnEvent::OnConnect {
                their_node_id: their_node_id.to_string(),
                inbound,
                remote_network_address: msg
                    .remote_network_address
                    .as_ref()
                    .map(|addr| format!("{}", addr)),
            };
            cb.trigger(event);
        }
        Ok(())
    }

    fn peer_disconnected(&self, their_node_id: &PublicKey) {
        if let Some(cb) = self.ln_event_callback.clone() {
            let event = CommonLnEvent::OnDisconnect {
                their_node_id: their_node_id.to_string(),
            };
            cb.trigger(event);
        }
    }
}

impl<S: MutinyStorage> CustomMessageReader for MutinyMessageHandler<S> {
    type CustomMessage = MutinyMessage<S>;
    fn read<R: Read>(
        &self,
        message_type: u16,
        buffer: &mut R,
    ) -> Result<Option<Self::CustomMessage>, DecodeError> {
        if let Some(liquidity) = &self.liquidity {
            match <LiquidityManager<S> as CustomMessageReader>::read(
                liquidity,
                message_type,
                buffer,
            )? {
                None => Ok(None),
                Some(message) => Ok(Some(MutinyMessage::Liquidity(message))),
            }
        } else {
            Ok(None)
        }
    }
}

impl<S: MutinyStorage> Type for MutinyMessage<S> {
    fn type_id(&self) -> u16 {
        match self {
            MutinyMessage::Liquidity(message) => message.type_id(),
        }
    }
}

impl<S: MutinyStorage> Writeable for MutinyMessage<S> {
    fn write<W: Writer>(&self, writer: &mut W) -> Result<(), Error> {
        match self {
            MutinyMessage::Liquidity(message) => message.write(writer),
        }
    }
}


================================================
File: mutiny-core/src/node.rs
================================================
use crate::lsp::LspConfig;
use crate::messagehandler::CommonLnEventCallback;
use crate::nodemanager::ChannelClosure;
use crate::peermanager::{LspMessageRouter, PeerManager};
use crate::storage::MutinyStorage;
use crate::utils::get_monitor_version;
use crate::{
    chain::MutinyChain,
    error::{MutinyError, MutinyStorageError},
    event::{EventHandler, HTLCStatus, MillisatAmount, PaymentInfo},
    fees::MutinyFeeEstimator,
    gossip::{get_all_peers, read_peer_info, save_peer_connection_info},
    keymanager::{
        create_keys_manager, deterministic_uuid_from_keys_manager, pubkey_from_keys_manager,
    },
    ldkstorage::{MutinyNodePersister, PhantomChannelManager},
    logging::MutinyLogger,
    lsp::{AnyLsp, FeeRequest, Lsp},
    nodemanager::NodeIndex,
    onchain::OnChainWallet,
    peermanager::{GossipMessageHandler, PeerManagerImpl},
    utils::{self, sleep},
    MutinyInvoice, PrivacyLevel,
};
use crate::{fees::P2WSH_OUTPUT_SIZE, peermanager::connect_peer_if_necessary};
use crate::{keymanager::PhantomKeysManager, scorer::HubPreferentialScorer};
use crate::{labels::LabelStorage, DEFAULT_PAYMENT_TIMEOUT};
use crate::{
    ldkstorage::{persist_monitor, ChannelOpenParams},
    storage::persist_payment_info,
};
use crate::{messagehandler::MutinyMessageHandler, storage::read_payment_info};
use anyhow::{anyhow, Context};
use bitcoin::bip32::Xpriv;
use bitcoin::hashes::sha256::Hash as Sha256;
use bitcoin::Address;
use bitcoin::{hashes::Hash, secp256k1::PublicKey, FeeRate, Network, OutPoint};
use core::time::Duration;
use esplora_client::AsyncClient;
use futures_util::lock::Mutex;
use hex_conservative::DisplayHex;
use lightning::events::bump_transaction::{BumpTransactionEventHandler, Wallet};
use lightning::ln::channel_state::ChannelDetails;
use lightning::ln::invoice_utils::{
    create_invoice_from_channelmanager_and_duration_since_epoch, create_phantom_invoice,
};
use lightning::ln::PaymentSecret;
use lightning::onion_message::messenger::OnionMessenger as LdkOnionMessenger;
use lightning::routing::scoring::ProbabilisticScoringDecayParameters;
use lightning::sign::{InMemorySigner, NodeSigner, Recipient};
use lightning::util::config::MaxDustHTLCExposure;
use lightning::util::ser::Writeable;
use lightning::{
    chain::{chainmonitor, Filter, Watch},
    ln::{
        channelmanager::{PaymentId, PhantomRouteHints, Retry},
        peer_handler::{IgnoringMessageHandler, MessageHandler as LdkMessageHandler},
        PaymentHash, PaymentPreimage,
    },
    log_debug, log_error, log_info, log_trace, log_warn,
    routing::{
        gossip,
        gossip::NodeId,
        router::{DefaultRouter, PaymentParameters, RouteParameters},
    },
    util::{
        config::{ChannelHandshakeConfig, ChannelHandshakeLimits, UserConfig},
        logger::Logger,
    },
};
use lightning::{
    ln::channelmanager::{RecipientOnionFields, RetryableSendFailure},
    routing::scoring::ProbabilisticScoringFeeParameters,
    util::config::ChannelConfig,
};
use lightning_background_processor::process_events_async;
use lightning_invoice::Bolt11Invoice;
use lightning_liquidity::lsps2::client::LSPS2ClientConfig;
use lightning_liquidity::{LiquidityClientConfig, LiquidityManager as LDKLSPLiquidityManager};

#[cfg(test)]
use mockall::predicate::*;
use std::collections::HashMap;
#[cfg(not(target_arch = "wasm32"))]
use std::time::Instant;
use std::{
    str::FromStr,
    sync::{
        atomic::{AtomicBool, Ordering},
        Arc, RwLock,
    },
};
#[cfg(target_arch = "wasm32")]
use web_time::Instant;

const INITIAL_RECONNECTION_DELAY: u64 = 2;
const MAX_RECONNECTION_DELAY: u64 = 60;

pub(crate) type PendingConnections = Arc<Mutex<HashMap<NodeId, u32>>>;

pub(crate) type BumpTxEventHandler<S: MutinyStorage> = BumpTransactionEventHandler<
    Arc<MutinyChain<S>>,
    Arc<Wallet<Arc<OnChainWallet<S>>, Arc<MutinyLogger>>>,
    Arc<PhantomKeysManager<S>>,
    Arc<MutinyLogger>,
>;

pub(crate) type RapidGossipSync =
    lightning_rapid_gossip_sync::RapidGossipSync<Arc<NetworkGraph>, Arc<MutinyLogger>>;

pub(crate) type NetworkGraph = gossip::NetworkGraph<Arc<MutinyLogger>>;

pub(crate) type OnionMessenger<S: MutinyStorage> = LdkOnionMessenger<
    Arc<PhantomKeysManager<S>>,
    Arc<PhantomKeysManager<S>>,
    Arc<MutinyLogger>,
    Arc<PhantomChannelManager<S>>,
    Arc<LspMessageRouter>,
    Arc<PhantomChannelManager<S>>,
    IgnoringMessageHandler,
    IgnoringMessageHandler,
>;

pub type LiquidityManager<S> = LDKLSPLiquidityManager<
    Arc<PhantomKeysManager<S>>,
    Arc<PhantomChannelManager<S>>,
    Arc<dyn Filter + Send + Sync>,
>;

pub(crate) type MessageHandler<S: MutinyStorage> = LdkMessageHandler<
    Arc<PhantomChannelManager<S>>,
    Arc<GossipMessageHandler<S>>,
    Arc<OnionMessenger<S>>,
    Arc<MutinyMessageHandler<S>>,
>;

pub(crate) type ChainMonitor<S: MutinyStorage> = chainmonitor::ChainMonitor<
    InMemorySigner,
    Arc<dyn Filter + Send + Sync>,
    Arc<MutinyChain<S>>,
    Arc<MutinyFeeEstimator<S>>,
    Arc<MutinyLogger>,
    Arc<MutinyNodePersister<S>>,
>;

pub(crate) type Router<S: MutinyStorage> = DefaultRouter<
    Arc<NetworkGraph>,
    Arc<MutinyLogger>,
    Arc<PhantomKeysManager<S>>,
    Arc<utils::Mutex<HubPreferentialScorer>>,
    ProbabilisticScoringFeeParameters,
    HubPreferentialScorer,
>;

#[derive(Clone, Debug, Eq, PartialEq)]
pub enum ConnectionType {
    Tcp(String),
}

#[derive(Clone, Debug, Eq, PartialEq)]
pub struct PubkeyConnectionInfo {
    pub pubkey: PublicKey,
    pub connection_type: ConnectionType,
    pub original_connection_string: String,
}

impl PubkeyConnectionInfo {
    pub fn new(connection: &str) -> Result<Self, MutinyError> {
        if connection.is_empty() {
            return Err(MutinyError::PeerInfoParseFailed)
                .context("connect_peer requires peer connection info")?;
        };
        let connection = connection.to_lowercase();
        let (pubkey, peer_addr_str) = parse_peer_info(&connection)?;
        Ok(Self {
            pubkey,
            connection_type: ConnectionType::Tcp(peer_addr_str),
            original_connection_string: connection,
        })
    }

    #[cfg(not(target_arch = "wasm32"))]
    pub fn socket_address(&self) -> Result<std::net::SocketAddr, MutinyError> {
        match self.connection_type {
            ConnectionType::Tcp(ref tcp) => {
                std::net::SocketAddr::from_str(tcp).map_err(|_| MutinyError::InvalidArgumentsError)
            }
        }
    }
}

pub struct NodeBuilder<S: MutinyStorage> {
    // required
    xprivkey: Xpriv,
    storage: S,
    uuid: Option<String>,
    node_index: Option<NodeIndex>,
    gossip_sync: Option<Arc<RapidGossipSync>>,
    scorer: Option<Arc<utils::Mutex<HubPreferentialScorer>>>,
    chain: Option<Arc<MutinyChain<S>>>,
    fee_estimator: Option<Arc<MutinyFeeEstimator<S>>>,
    wallet: Option<Arc<OnChainWallet<S>>>,
    esplora: Option<Arc<AsyncClient>>,
    ln_event_callback: Option<CommonLnEventCallback>,
    #[cfg(target_arch = "wasm32")]
    websocket_proxy_addr: Option<String>,
    network: Option<Network>,
    has_done_initial_sync: Option<Arc<AtomicBool>>,

    // optional
    lsp_config: Option<LspConfig>,
    logger: Option<Arc<MutinyLogger>>,
    do_not_connect_peers: bool,
    do_not_bump_channel_close_tx: bool,
    sweep_target_address: Option<Address>,
}

impl<S: MutinyStorage> NodeBuilder<S> {
    pub fn new(xprivkey: Xpriv, storage: S) -> NodeBuilder<S> {
        NodeBuilder::<S> {
            xprivkey,
            storage,
            uuid: None,
            node_index: None,
            gossip_sync: None,
            scorer: None,
            chain: None,
            fee_estimator: None,
            wallet: None,
            esplora: None,
            has_done_initial_sync: None,
            ln_event_callback: None,
            #[cfg(target_arch = "wasm32")]
            websocket_proxy_addr: None,
            lsp_config: None,
            logger: None,
            network: None,
            do_not_connect_peers: false,
            do_not_bump_channel_close_tx: false,
            sweep_target_address: None,
        }
    }

    /// Required
    pub fn with_uuid(mut self, uuid: String) -> NodeBuilder<S> {
        self.uuid = Some(uuid);
        self
    }

    /// Required
    pub fn with_node_index(mut self, node_index: NodeIndex) -> NodeBuilder<S> {
        self.node_index = Some(node_index);
        self
    }

    /// Required
    pub fn with_gossip_sync(mut self, gossip_sync: Arc<RapidGossipSync>) -> NodeBuilder<S> {
        self.gossip_sync = Some(gossip_sync);
        self
    }

    /// Required
    pub fn with_scorer(
        mut self,
        scorer: Arc<utils::Mutex<HubPreferentialScorer>>,
    ) -> NodeBuilder<S> {
        self.scorer = Some(scorer);
        self
    }

    /// Required
    pub fn with_chain(mut self, chain: Arc<MutinyChain<S>>) -> NodeBuilder<S> {
        self.chain = Some(chain);
        self
    }

    /// Required
    pub fn with_fee_estimator(
        mut self,
        fee_estimator: Arc<MutinyFeeEstimator<S>>,
    ) -> NodeBuilder<S> {
        self.fee_estimator = Some(fee_estimator);
        self
    }

    /// Required
    pub fn with_wallet(mut self, wallet: Arc<OnChainWallet<S>>) -> NodeBuilder<S> {
        self.wallet = Some(wallet);
        self
    }

    /// Required
    pub fn with_esplora(mut self, esplora: Arc<AsyncClient>) -> NodeBuilder<S> {
        self.esplora = Some(esplora);
        self
    }

    pub fn with_network(mut self, network: Network) -> NodeBuilder<S> {
        self.network = Some(network);
        self
    }

    pub fn with_initial_sync(mut self, has_done_initial_sync: Arc<AtomicBool>) -> NodeBuilder<S> {
        self.has_done_initial_sync = Some(has_done_initial_sync);
        self
    }

    #[cfg(target_arch = "wasm32")]
    /// Required
    pub fn with_websocket_proxy_addr(&mut self, websocket_proxy_addr: String) {
        self.websocket_proxy_addr = Some(websocket_proxy_addr);
    }

    pub fn with_lsp_config(&mut self, lsp_config: LspConfig) {
        self.lsp_config = Some(lsp_config);
    }

    pub fn with_ln_event_callback(&mut self, callback: CommonLnEventCallback) {
        self.ln_event_callback = Some(callback);
    }

    pub fn with_logger(&mut self, logger: Arc<MutinyLogger>) {
        self.logger = Some(logger);
    }

    pub fn do_not_connect_peers(&mut self) {
        self.do_not_connect_peers = true;
    }

    pub fn do_not_bump_channel_close_tx(&mut self) {
        self.do_not_bump_channel_close_tx = true;
    }

    pub fn with_sweep_target_address(&mut self, sweep_target_address: Address) {
        self.sweep_target_address = Some(sweep_target_address);
    }

    pub fn log_params(&self, logger: &Arc<MutinyLogger>) {
        log_debug!(logger, "build parameters:");
        log_debug!(logger, "- uuid: {:?}", self.uuid);
        log_debug!(logger, "- node_index: {:?}", self.node_index);
        log_debug!(logger, "- gossip_sync: {:#?}", self.gossip_sync.is_some());
        log_debug!(logger, "- scorer: {:#?}", self.scorer.is_some());
        log_debug!(logger, "- chain: {:#?}", self.chain.is_some());
        log_debug!(
            logger,
            "- fee_estimator: {:#?}",
            self.fee_estimator.is_some()
        );
        log_debug!(logger, "- wallet: {:#?}", self.wallet.is_some());
        log_debug!(logger, "- esplora: {:?}", self.esplora);
        #[cfg(target_arch = "wasm32")]
        log_debug!(
            logger,
            "- websocket_proxy_addr: {:?}",
            self.websocket_proxy_addr
        );
        log_debug!(logger, "- network: {:?}", self.network);
        log_debug!(
            logger,
            "- has_done_initial_sync: {:?}",
            self.has_done_initial_sync
        );
        log_debug!(logger, "- lsp_config: {:?}", self.lsp_config);
        log_debug!(
            logger,
            "- do_not_connect_peers: {}",
            self.do_not_connect_peers
        );
    }

    pub async fn build(self) -> Result<Node<S>, MutinyError> {
        let node_start = Instant::now();

        // check for all required parameters
        let node_index = self.node_index.as_ref().map_or_else(
            || Err(MutinyError::InvalidArgumentsError),
            |v| Ok(v.clone()),
        )?;
        let gossip_sync = self.gossip_sync.as_ref().map_or_else(
            || Err(MutinyError::InvalidArgumentsError),
            |v| Ok(v.clone()),
        )?;
        let scorer = self.scorer.as_ref().map_or_else(
            || Err(MutinyError::InvalidArgumentsError),
            |v| Ok(v.clone()),
        )?;
        let chain = self.chain.as_ref().map_or_else(
            || Err(MutinyError::InvalidArgumentsError),
            |v| Ok(v.clone()),
        )?;
        let fee_estimator = self.fee_estimator.as_ref().map_or_else(
            || Err(MutinyError::InvalidArgumentsError),
            |v| Ok(v.clone()),
        )?;
        let wallet = self.wallet.as_ref().map_or_else(
            || Err(MutinyError::InvalidArgumentsError),
            |v| Ok(v.clone()),
        )?;
        let esplora = self.esplora.as_ref().map_or_else(
            || Err(MutinyError::InvalidArgumentsError),
            |v| Ok(v.clone()),
        )?;
        let network = self
            .network
            .map_or_else(|| Err(MutinyError::InvalidArgumentsError), Ok)?;
        #[cfg(target_arch = "wasm32")]
        let websocket_proxy_addr = self.websocket_proxy_addr.as_ref().map_or_else(
            || Err(MutinyError::InvalidArgumentsError),
            |v| Ok(v.clone()),
        )?;

        let logger = self
            .logger
            .clone()
            .unwrap_or(Arc::new(MutinyLogger::default()));

        self.log_params(&logger);

        log_info!(logger, "initializing a new node: {:?}", self.uuid);

        // a list of components that need to be stopped and whether or not they are stopped
        let stopped_components = Arc::new(RwLock::new(vec![]));

        let keys_manager = Arc::new(create_keys_manager(
            wallet.clone(),
            self.xprivkey,
            node_index.child_index,
            logger.clone(),
        )?);
        let pubkey = pubkey_from_keys_manager(&keys_manager);

        // if no UUID was given then this is new node, we deterministically generate
        // it from our key manager.
        let uuid = match self.uuid {
            Some(uuid) => uuid,
            None => deterministic_uuid_from_keys_manager(&keys_manager).to_string(),
        };

        // init the persister
        let persister = Arc::new(MutinyNodePersister::new(
            uuid.clone(),
            self.storage,
            logger.clone(),
        ));

        // init chain monitor
        let chain_monitor: Arc<ChainMonitor<S>> = Arc::new(ChainMonitor::new(
            Some(chain.tx_sync.clone()),
            chain.clone(),
            logger.clone(),
            fee_estimator.clone(),
            persister.clone(),
        ));

        // set chain monitor for persister for async storage
        persister
            .chain_monitor
            .lock()
            .await
            .replace(chain_monitor.clone());

        // read channelmonitor state from disk
        let channel_monitors = persister
            .read_channel_monitors(keys_manager.clone())
            .map_err(|e| MutinyError::ReadError {
                source: MutinyStorageError::Other(anyhow!("failed to read channel monitors: {e}")),
            })?;

        let network_graph = gossip_sync.network_graph().clone();

        let router: Arc<Router<_>> = Arc::new(DefaultRouter::new(
            network_graph,
            logger.clone(),
            keys_manager.clone(),
            scorer.clone(),
            scoring_params(),
        ));

        log_trace!(logger, "creating lsp config");
        let lsp_config: Option<LspConfig> = match node_index.lsp {
            None => {
                log_info!(logger, "no lsp saved, using configured one if present");
                self.lsp_config
            }
            Some(lsp) => {
                if self.lsp_config.as_ref().is_some_and(|l| l.matches(&lsp)) {
                    log_info!(logger, "lsp config matches saved lsp config");
                    // prefer node index lsp config over configured one
                    // as it may have extra info like the LSP connection info
                    Some(lsp)
                } else {
                    log_warn!(
                        logger,
                        "lsp config does not match saved lsp config, using saved one"
                    );
                    Some(lsp)
                }
            }
        };
        log_trace!(logger, "finished creating lsp config");

        // init channel manager
        log_trace!(logger, "initializing channel manager");
        let accept_underpaying_htlcs = lsp_config
            .as_ref()
            .is_some_and(|l| l.accept_underpaying_htlcs());
        let mut read_channel_manager = persister
            .read_channel_manager(
                network,
                accept_underpaying_htlcs,
                chain_monitor.clone(),
                chain.clone(),
                fee_estimator.clone(),
                logger.clone(),
                keys_manager.clone(),
                router.clone(),
                channel_monitors,
                &esplora,
            )
            .await?;
        log_trace!(logger, "finished initializing channel manager");

        let channel_manager: Arc<PhantomChannelManager<S>> =
            Arc::new(read_channel_manager.channel_manager);

        let stop = Arc::new(AtomicBool::new(false));

        log_trace!(logger, "creating lsp client");
        let (lsp_client, lsp_client_pubkey, liquidity) = match lsp_config {
            Some(LspConfig::VoltageFlow(config)) => {
                let lsp = AnyLsp::new_voltage_flow(config, logger.clone()).await?;
                let pubkey = lsp.get_lsp_pubkey().await;
                (Some(lsp), Some(pubkey), None)
            }
            Some(LspConfig::Lsps(lsps_config)) => {
                let liquidity_manager = Arc::new(LiquidityManager::new(
                    keys_manager.clone(),
                    channel_manager.clone(),
                    None,
                    None,
                    None,
                    Some(LiquidityClientConfig {
                        lsps2_client_config: Some(LSPS2ClientConfig::default()),
                    }),
                ));
                let lsp = AnyLsp::new_lsps(
                    lsps_config.connection_string.clone(),
                    lsps_config.token.clone(),
                    liquidity_manager.clone(),
                    channel_manager.clone(),
                    keys_manager.clone(),
                    network,
                    logger.clone(),
                    stop.clone(),
                )?;
                let pubkey = lsp.get_lsp_pubkey().await;
                (Some(lsp), Some(pubkey), Some(liquidity_manager))
            }
            None => (None, None, None),
        };
        log_trace!(logger, "finished creating lsp client");

        log_trace!(logger, "creating onion routers");
        let message_router = Arc::new(LspMessageRouter::new(lsp_client_pubkey));
        let onion_message_handler = Arc::new(OnionMessenger::new(
            keys_manager.clone(),
            keys_manager.clone(),
            logger.clone(),
            channel_manager.clone(),
            message_router.clone(),
            channel_manager.clone(),
            IgnoringMessageHandler {},
            IgnoringMessageHandler {},
        ));

        let route_handler = Arc::new(GossipMessageHandler {
            storage: persister.storage.clone(),
            network_graph: gossip_sync.network_graph().clone(),
            logger: logger.clone(),
        });
        log_trace!(logger, "finished creating onion routers");

        // init peer manager
        log_trace!(logger, "creating peer manager");
        let ln_msg_handler = MessageHandler {
            chan_handler: channel_manager.clone(),
            route_handler,
            onion_message_handler: onion_message_handler.clone(),
            custom_message_handler: Arc::new(MutinyMessageHandler {
                liquidity: liquidity.clone(),
                ln_event_callback: self.ln_event_callback.clone(),
            }),
        };
        log_trace!(logger, "finished creating peer manager");

        log_trace!(logger, "creating bump tx event handler");
        let bump_tx_event_handler = Arc::new(BumpTransactionEventHandler::new(
            Arc::clone(&chain),
            Arc::new(Wallet::new(Arc::clone(&wallet), Arc::clone(&logger))),
            Arc::clone(&keys_manager),
            Arc::clone(&logger),
        ));
        log_trace!(logger, "finished creating bump tx event handler");

        // init event handler
        log_trace!(logger, "creating event handler");

        if self.do_not_bump_channel_close_tx {
            log_info!(logger, "Disable bump for channel close transaction");
        }

        log_info!(
            logger,
            "Sweep target address: {:?}",
            self.sweep_target_address
        );

        let event_handler = EventHandler::new(
            channel_manager.clone(),
            fee_estimator.clone(),
            wallet.clone(),
            keys_manager.clone(),
            persister.clone(),
            bump_tx_event_handler,
            lsp_client.clone(),
            logger.clone(),
            self.do_not_bump_channel_close_tx,
            self.sweep_target_address,
            self.ln_event_callback.clone(),
        );
        log_trace!(logger, "finished creating event handler");

        log_trace!(logger, "creating peer manager");
        let peer_man = Arc::new(create_peer_manager(
            keys_manager.clone(),
            ln_msg_handler,
            logger.clone(),
        ));
        log_trace!(logger, "finished creating peer manager");

        if let Some(liquidity) = liquidity {
            log_trace!(logger, "setting liqudity callback");
            let process_msgs_pm = peer_man.clone();
            liquidity.set_process_msgs_callback(move || {
                process_msgs_pm.process_events();
            });
            log_trace!(logger, "finished setting liqudity callback");
        }

        // sync to chain tip
        log_trace!(logger, "syncing chain to tip");
        if read_channel_manager.is_restarting {
            let start = Instant::now();
            let mut chain_listener_channel_monitors =
                Vec::with_capacity(read_channel_manager.channel_monitors.len());
            for (blockhash, channel_monitor) in read_channel_manager.channel_monitors.drain(..) {
                // Get channel monitor ready to sync
                log_trace!(logger, "loading outputs to watch");
                channel_monitor.load_outputs_to_watch(&chain, &logger);

                let outpoint = channel_monitor.get_funding_txo().0;
                chain_listener_channel_monitors.push((
                    blockhash,
                    (
                        channel_monitor,
                        chain.clone(),
                        chain.clone(),
                        logger.clone(),
                    ),
                    outpoint,
                ));
            }

            // give channel monitors to chain monitor
            log_trace!(logger, "giving channel monitors to chain monitor");
            for item in chain_listener_channel_monitors.drain(..) {
                let channel_monitor = item.1 .0;
                let funding_outpoint = item.2;

                chain_monitor
                    .watch_channel(funding_outpoint, channel_monitor)
                    .map_err(|_| MutinyError::ChainAccessFailed)?;
            }

            log_trace!(
                logger,
                "Syncing monitors to chain tip took {}ms",
                start.elapsed().as_millis()
            );
        }
        log_trace!(logger, "finished syncing chain to tip");

        // Before we start the background processor, retry previously failed
        // spendable outputs. We should do this before we start the background
        // processor so we prevent any race conditions.
        // if we fail to read the spendable outputs, just log a warning and
        // continue
        log_trace!(logger, "retrying spendable outputs");
        let retry_spendable_outputs = persister
            .get_failed_spendable_outputs()
            .map_err(|e| MutinyError::ReadError {
                source: MutinyStorageError::Other(anyhow!(
                    "failed to read retry spendable outputs: {e}"
                )),
            })
            .unwrap_or_else(|e| {
                log_warn!(logger, "Failed to read retry spendable outputs: {e}");
                vec![]
            });

        if !retry_spendable_outputs.is_empty() {
            let event_handler = event_handler.clone();
            let persister = persister.clone();
            let logger = logger.clone();

            // We need to process our unhandled spendable outputs
            // can do this in the background, no need to block on it
            utils::spawn(async move {
                let start = Instant::now();
                log_info!(
                    logger,
                    "Retrying {} spendable outputs",
                    retry_spendable_outputs.len()
                );

                match event_handler
                    .handle_spendable_outputs(&retry_spendable_outputs)
                    .await
                {
                    Ok(_) => {
                        log_info!(logger, "Successfully retried spendable outputs");
                        if let Err(e) = persister.clear_failed_spendable_outputs() {
                            log_warn!(logger, "Failed to clear failed spendable outputs: {e}");
                        }
                    }
                    Err(_) => {
                        // retry them individually then only save failed ones
                        // if there was only one we don't need to retry
                        if retry_spendable_outputs.len() > 1 {
                            let mut failed = vec![];
                            for o in retry_spendable_outputs {
                                if event_handler
                                    .handle_spendable_outputs(&[o.clone()])
                                    .await
                                    .is_err()
                                {
                                    failed.push(o);
                                }
                            }
                            if let Err(e) = persister.set_failed_spendable_outputs(failed) {
                                log_warn!(logger, "Failed to set failed spendable outputs: {e}");
                            }
                        };
                    }
                }

                log_info!(
                    logger,
                    "Retrying spendable outputs took {}ms",
                    start.elapsed().as_millis()
                );
            });
        }
        log_trace!(logger, "finished retrying spendable outputs");

        // Check all existing channels against default configs.
        // If we have default config changes, those should apply
        // to all existing and new channels.
        log_trace!(logger, "checking default user config against channels");
        let default_config = default_user_config(accept_underpaying_htlcs).channel_config;
        for channel in channel_manager.list_channels() {
            // unwrap is safe after LDK.0.0.109
            if channel.config.unwrap() != default_config {
                match channel_manager.update_channel_config(
                    &channel.counterparty.node_id,
                    &[channel.channel_id],
                    &default_config,
                ) {
                    Ok(_) => {
                        log_debug!(
                            logger,
                            "changed default config for channel: {}",
                            channel.channel_id
                        )
                    }
                    Err(e) => {
                        log_error!(
                            logger,
                            "error changing default config for channel: {} - {e:?}",
                            channel.channel_id
                        )
                    }
                };
            }
        }
        log_trace!(
            logger,
            "finished checking default user config against channels"
        );

        log_trace!(logger, "spawning ldk background thread");
        let background_persister = persister.clone();
        let background_event_handler = event_handler.clone();
        let background_processor_logger = logger.clone();
        let background_processor_peer_manager = peer_man.clone();
        let background_processor_channel_manager = channel_manager.clone();
        let background_chain_monitor = chain_monitor.clone();
        let background_gossip_sync = gossip_sync.clone();
        let background_logger = logger.clone();
        let background_stop = stop.clone();
        stopped_components.try_write()?.push(false);
        let background_stopped_components = stopped_components.clone();
        utils::spawn(async move {
            loop {
                let gs = lightning_background_processor::GossipSync::rapid(
                    background_gossip_sync.clone(),
                );
                let ev = background_event_handler.clone();
                if let Err(e) = process_events_async(
                    background_persister.clone(),
                    |e| ev.handle_event(e),
                    background_chain_monitor.clone(),
                    background_processor_channel_manager.clone(),
                    Option::<Arc<OnionMessenger<S>>>::None,
                    gs,
                    background_processor_peer_manager.clone(),
                    background_processor_logger.clone(),
                    Some(scorer.clone()),
                    |d| {
                        let background_event_stop = background_stop.clone();
                        Box::pin(async move {
                            sleep(d.as_millis() as i32).await;
                            background_event_stop.load(Ordering::Relaxed)
                        })
                    },
                    true,
                    || Some(utils::now()),
                )
                .await
                {
                    log_error!(background_logger, "error running background processor: {e}",);
                }

                if background_stop.load(Ordering::Relaxed) {
                    log_debug!(
                        background_logger,
                        "stopping background component for node: {}",
                        pubkey,
                    );
                    stop_component(&background_stopped_components);
                    log_debug!(
                        background_logger,
                        "stopped background component for node: {}",
                        pubkey
                    );
                    break;
                }
            }
        });
        log_trace!(logger, "finished spawning ldk background thread");

        let pending_connections = Arc::new(Mutex::new(Default::default()));

        if !self.do_not_connect_peers {
            #[cfg(target_arch = "wasm32")]
            let reconnection_proxy_addr = websocket_proxy_addr.clone();

            log_trace!(logger, "spawning ldk reconnect thread");
            let reconnection_storage = persister.storage.clone();
            let reconnection_pubkey = pubkey;
            let reconnection_peer_man = peer_man.clone();
            let reconnection_fee = fee_estimator.clone();
            let reconnection_logger = logger.clone();
            let reconnection_uuid = uuid.clone();
            let reconnection_lsp_client = lsp_client.clone();
            let reconnection_stop = stop.clone();
            let reconnection_stopped_comp = stopped_components.clone();
            reconnection_stopped_comp.try_write()?.push(false);
            let pending_connections = pending_connections.clone();
            utils::spawn(async move {
                start_reconnection_handling(
                    &reconnection_storage,
                    reconnection_pubkey,
                    #[cfg(target_arch = "wasm32")]
                    reconnection_proxy_addr,
                    reconnection_peer_man,
                    pending_connections,
                    reconnection_fee,
                    &reconnection_logger,
                    reconnection_uuid,
                    reconnection_lsp_client.as_ref(),
                    reconnection_stop,
                    reconnection_stopped_comp,
                    network == Network::Regtest,
                )
                .await;
            });
            log_trace!(logger, "finished spawning ldk reconnect thread");
        }

        log_info!(
            logger,
            "Node started: {}",
            keys_manager.get_node_id(Recipient::Node).unwrap()
        );

        let sync_lock = Arc::new(Mutex::new(()));

        // Here we re-attempt to persist any monitors that failed to persist previously.
        log_trace!(logger, "reattempt monitor persistance thread");
        let retry_logger = logger.clone();
        let retry_persister = persister.clone();
        let retry_stop = stop.clone();
        let retry_chain_monitor = chain_monitor.clone();
        let retry_sync_lock = sync_lock.clone();
        utils::spawn(async move {
            // sleep 3 seconds before checking, we won't have any pending updates on startup
            sleep(3_000).await;

            loop {
                if retry_stop.load(Ordering::Relaxed) {
                    break;
                }

                let updates = {
                    let _lock = retry_sync_lock.lock().await;
                    retry_chain_monitor.list_pending_monitor_updates()
                };

                for (funding_txo, update_ids) in updates {
                    // if there are no updates, skip
                    if update_ids.is_empty() {
                        continue;
                    }

                    log_debug!(
                        retry_logger,
                        "Retrying to persist monitor for outpoint: {funding_txo:?}"
                    );

                    let data_opt = match retry_chain_monitor.get_monitor(funding_txo) {
                        Ok(monitor) => {
                            let key = retry_persister.get_monitor_key(&funding_txo);
                            let object = monitor.encode();
                            let update_id = monitor.get_latest_update_id();
                            debug_assert_eq!(update_id, get_monitor_version(&object));

                            // safely convert u64 to u32
                            let version = if update_id >= u32::MAX as u64 {
                                u32::MAX
                            } else {
                                update_id as u32
                            };

                            Some((key, object, version))
                        }
                        Err(_) => {
                            log_error!(
                                retry_logger,
                                "Failed to get monitor for outpoint: {funding_txo:?}"
                            );
                            None
                        }
                    };

                    if let Some((key, object, version)) = data_opt {
                        log_debug!(
                            retry_logger,
                            "Persisting monitor for output: {funding_txo:?}"
                        );
                        let res = persist_monitor(
                            retry_persister.storage.clone(),
                            key,
                            object,
                            Some(version),
                            retry_logger.clone(),
                        );

                        match res {
							Ok(_) => {
								for id in update_ids {
									if let Err(e) = retry_chain_monitor
										.channel_monitor_updated(funding_txo, id)
									{
										log_error!(retry_logger, "Error notifying chain monitor of channel monitor update: {e:?}");
									} else {
                                        log_debug!(
                                            retry_logger,
                                            "notified channel monitor updated: {funding_txo:?}"
                                        );
                                    }
								}
							}
							Err(e) => log_error!(
                                    retry_logger,
                                    "Failed to persist monitor for outpoint: {funding_txo:?}, error: {e:?}",
                                ),
						}
                    }
                }

                // sleep 3 seconds
                sleep(3_000).await;
            }
        });
        log_trace!(logger, "finished reattempt monitor persistance thread");

        log_trace!(
            logger,
            "Node started, took {}ms",
            node_start.elapsed().as_millis()
        );

        let has_done_initial_sync = self
            .has_done_initial_sync
            .unwrap_or(Arc::new(AtomicBool::new(false)));

        Ok(Node {
            uuid,
            stopped_components,
            child_index: node_index.child_index,
            pubkey,
            peer_manager: peer_man,
            pending_connections,
            keys_manager,
            channel_manager,
            chain_monitor,
            fee_estimator,
            network,
            persister,
            wallet,
            logger,
            lsp_client,
            sync_lock,
            stop,
            has_done_initial_sync,
            #[cfg(target_arch = "wasm32")]
            websocket_proxy_addr,
        })
    }
}

pub(crate) struct Node<S: MutinyStorage> {
    pub uuid: String,
    pub child_index: u32,
    stopped_components: Arc<RwLock<Vec<bool>>>,
    pub pubkey: PublicKey,
    pub peer_manager: Arc<PeerManagerImpl<S>>,
    pub pending_connections: PendingConnections,
    pub keys_manager: Arc<PhantomKeysManager<S>>,
    pub channel_manager: Arc<PhantomChannelManager<S>>,
    pub chain_monitor: Arc<ChainMonitor<S>>,
    pub fee_estimator: Arc<MutinyFeeEstimator<S>>,
    network: Network,
    pub persister: Arc<MutinyNodePersister<S>>,
    wallet: Arc<OnChainWallet<S>>,
    pub(crate) logger: Arc<MutinyLogger>,
    pub(crate) lsp_client: Option<AnyLsp<S>>,
    pub(crate) sync_lock: Arc<Mutex<()>>,
    stop: Arc<AtomicBool>,
    has_done_initial_sync: Arc<AtomicBool>,
    #[cfg(target_arch = "wasm32")]
    websocket_proxy_addr: String,
}

impl<S: MutinyStorage> Node<S> {
    pub async fn stop(&self) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling stop");

        self.stop.store(true, Ordering::Relaxed);

        self.stopped().await?;

        log_trace!(self.logger, "finished calling stop");

        Ok(())
    }

    /// stopped will await until the node is fully shut down
    pub async fn stopped(&self) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling stopped");

        loop {
            let all_stopped = {
                let stopped_components = self
                    .stopped_components
                    .try_read()
                    .map_err(|_| MutinyError::NotRunning)?;
                stopped_components.iter().all(|&x| x)
            };

            if all_stopped {
                break;
            }

            sleep(500).await;
        }

        log_trace!(self.logger, "finished calling stopped");
        Ok(())
    }

    pub async fn node_index(&self) -> NodeIndex {
        log_trace!(self.logger, "calling node_index");

        let lsp = match self.lsp_client.as_ref() {
            Some(lsp) => Some(lsp.get_config().await),
            None => None,
        };

        let n = NodeIndex {
            child_index: self.child_index,
            lsp,
            archived: Some(false),
        };

        log_trace!(self.logger, "finished calling node_index");

        n
    }

    pub async fn connect_peer(
        &self,
        peer_connection_info: PubkeyConnectionInfo,
        label: Option<String>,
    ) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling connect_peer");

        let connect_res = connect_peer_if_necessary(
            #[cfg(target_arch = "wasm32")]
            &self.websocket_proxy_addr,
            &peer_connection_info,
            &self.persister.storage,
            self.logger.clone(),
            self.peer_manager.clone(),
            self.pending_connections.clone(),
            self.fee_estimator.clone(),
            self.stop.clone(),
        )
        .await;
        let res = match connect_res {
            Ok(_) => {
                let node_id = NodeId::from_pubkey(&peer_connection_info.pubkey);

                // if we have the connection info saved in storage, update it if we need to
                // otherwise cache it in temp_peer_connection_map so we can later save it
                // if we open a channel in the future.
                if let Some(saved) = read_peer_info(&self.persister.storage, &node_id)?
                    .and_then(|p| p.connection_string)
                {
                    if saved != peer_connection_info.original_connection_string {
                        match save_peer_connection_info(
                            &self.persister.storage,
                            &self.uuid,
                            &node_id,
                            &peer_connection_info.original_connection_string,
                            label,
                        ) {
                            Ok(_) => (),
                            Err(_) => {
                                log_warn!(self.logger, "WARN: could not store peer connection info")
                            }
                        }
                    }
                } else {
                    // store this so we can reconnect later
                    if let Err(e) = save_peer_connection_info(
                        &self.persister.storage,
                        &self.uuid,
                        &node_id,
                        &peer_connection_info.original_connection_string,
                        label,
                    ) {
                        log_warn!(
                            self.logger,
                            "WARN: could not store peer connection info: {e}"
                        );
                    }
                }

                Ok(())
            }
            Err(e) => Err(e),
        };

        log_trace!(self.logger, "finished calling connect_peer");

        res
    }

    pub fn disconnect_peer(&self, peer_id: PublicKey) {
        log_trace!(self.logger, "calling disconnect_peer");
        self.peer_manager.disconnect_by_node_id(peer_id);
        log_trace!(self.logger, "finished calling disconnect_peer");
    }

    pub fn get_phantom_route_hint(&self) -> PhantomRouteHints {
        log_trace!(self.logger, "calling get_phantom_route_hint");
        let res = self.channel_manager.get_phantom_route_hints();
        log_trace!(self.logger, "calling get_phantom_route_hint");

        res
    }

    pub async fn get_lsp_fee(&self, amount_sat: u64) -> Result<u64, MutinyError> {
        log_trace!(self.logger, "calling get_lsp_fee");
        let res = match self.lsp_client.as_ref() {
            Some(lsp) => {
                let connect = lsp.get_lsp_connection_string().await;
                self.connect_peer(PubkeyConnectionInfo::new(&connect)?, None)
                    .await?;

                // Needs any amount over 0 if channel exists
                // Needs amount over minimum if no channel
                let inbound_capacity_msat: u64 = self
                    .channel_manager
                    .list_channels_with_counterparty(&lsp.get_lsp_pubkey().await)
                    .iter()
                    .map(|c| c.inbound_capacity_msat)
                    .sum();

                log_debug!(self.logger, "Current inbound liquidity {inbound_capacity_msat}msats, creating invoice for {}msats", amount_sat * 1000);

                let has_inbound_capacity = inbound_capacity_msat > amount_sat * 1_000;

                let min_amount_sat = if has_inbound_capacity {
                    1
                } else {
                    utils::min_lightning_amount(self.network, lsp.is_lsps())
                };

                if amount_sat < min_amount_sat {
                    return Err(MutinyError::BadAmountError);
                }

                // check the fee from the LSP
                let lsp_fee = lsp
                    .get_lsp_fee_msat(FeeRequest {
                        pubkey: self.pubkey.encode().to_lower_hex_string(),
                        amount_msat: amount_sat * 1000,
                    })
                    .await?;

                // Convert the fee from msat to sat for comparison and subtraction
                Ok(lsp_fee.fee_amount_msat / 1000)
            }
            None => Ok(0),
        };
        log_trace!(self.logger, "finished calling get_lsp_fee");

        res
    }

    fn get_outbound_capacity_msat(&self) -> u64 {
        let channels = self.channel_manager.list_channels();
        self.chain_monitor
            .get_claimable_balances(
                &channels
                    .iter()
                    // only consider channels that are confirmed
                    .filter(|c| !c.is_channel_ready)
                    .collect::<Vec<_>>(),
            )
            .into_iter()
            .map(|b| b.claimable_amount_satoshis())
            .sum::<u64>()
            * 1000
    }

    fn get_inbound_capacity_msat(&self) -> u64 {
        self.channel_manager
            .list_usable_channels()
            .iter()
            .map(|c| c.inbound_capacity_msat)
            .sum()
    }

    async fn try_connect_unusable_channel_peers(&self) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling try_connect_unusable_channel peers");

        let node_ids = self.peer_manager.get_peer_node_ids();
        for channel in self.channel_manager.list_channels() {
            if channel.is_usable || node_ids.contains(&channel.counterparty.node_id) {
                // skip connected peers
                continue;
            }

            let node_id = channel.counterparty.node_id.into();

            log_debug!(self.logger, "try connect peer {}", &node_id);

            let Some(peer_connection_string) = read_peer_info(&self.persister.storage, &node_id)?
                .and_then(|peer_info| peer_info.connection_string)
            else {
                log_debug!(
                        self.logger,
                        "failed to connect peer {} because we can't find peer connection string from storage",
                        &node_id
                    );
                continue;
            };

            log_debug!(
                self.logger,
                "find peer connection string {}",
                &peer_connection_string
            );

            let connect_info = match PubkeyConnectionInfo::new(&peer_connection_string) {
                Ok(info) => info,
                Err(err) => {
                    log_debug!(
                        self.logger,
                        "failed to parse peer connection string {}, error {:?}",
                        &peer_connection_string,
                        err
                    );
                    continue;
                }
            };

            if let Err(err) = self.connect_peer(connect_info, None).await {
                log_debug!(self.logger, "failed to connect, error {:?}", err);
            }
        }

        log_trace!(
            self.logger,
            "finished calling try_connect_unusable_channel peers"
        );
        Ok(())
    }

    pub async fn create_invoice(
        &self,
        amount_sat: Option<u64>,
        route_hints: Option<Vec<PhantomRouteHints>>,
        labels: Vec<String>,
        expiry_delta_secs: Option<u32>,
    ) -> Result<(Bolt11Invoice, u64), MutinyError> {
        log_trace!(self.logger, "calling create_invoice");

        let res = match self.lsp_client.as_ref() {
            Some(lsp) => {
                let connect = lsp.get_lsp_connection_string().await;
                self.connect_peer(PubkeyConnectionInfo::new(&connect)?, None)
                    .await?;
                if let Some(amount) = amount_sat {
                    if amount < 1 {
                        return Err(MutinyError::BadAmountError);
                    }
                    let inbound_capacity_msat: u64 = self.get_inbound_capacity_msat();
                    log_debug!(self.logger, "Current inbound liquidity {inbound_capacity_msat}msats, creating invoice for {}msats", amount * 1000);

                    if inbound_capacity_msat < amount * 1_000 {
                        log_debug!(
                            self.logger,
                            "Inbound capacity insufficient, try to resume disconnect channels..."
                        );
                        if let Err(err) = self.try_connect_unusable_channel_peers().await {
                            log_debug!(
                                self.logger,
                                "try connect unusable_channel_peers error {err:?}"
                            );
                        }

                        let inbound_capacity_msat: u64 = self.get_inbound_capacity_msat();
                        log_debug!(self.logger, "Current inbound liquidity {inbound_capacity_msat}msats, creating invoice for {}msats", amount * 1000);
                        if inbound_capacity_msat < amount * 1_000 {
                            return Err(MutinyError::InsufficientBalance);
                        }
                    }
                }
                Ok((
                    self.create_internal_invoice(
                        amount_sat,
                        None,
                        route_hints,
                        labels,
                        expiry_delta_secs,
                    )
                    .await?,
                    0,
                ))
            }
            None => Ok((
                self.create_internal_invoice(
                    amount_sat,
                    None,
                    route_hints,
                    labels,
                    expiry_delta_secs,
                )
                .await?,
                0,
            )),
        };

        log_trace!(self.logger, "finished calling create_invoice");

        res
    }

    async fn create_internal_invoice(
        &self,
        amount_sat: Option<u64>,
        fee_amount_msat: Option<u64>,
        route_hints: Option<Vec<PhantomRouteHints>>,
        labels: Vec<String>,
        expiry_delta_secs: Option<u32>,
    ) -> Result<Bolt11Invoice, MutinyError> {
        let amount_msat = amount_sat.map(|s| s * 1_000);
        // Use first element of labels as description
        let description = labels.first().unwrap_or(&"".to_string()).to_owned();

        // wait for first sync to complete
        for _ in 0..60 {
            // check if we've been stopped
            if self.stop.load(Ordering::Relaxed) {
                return Err(MutinyError::NotRunning);
            }

            if let Ok(true) = self.persister.storage.has_done_first_sync() {
                break;
            }

            sleep(1_000).await;
        }

        let invoice_res = match route_hints {
            None => {
                let now = crate::utils::now();
                create_invoice_from_channelmanager_and_duration_since_epoch(
                    &self.channel_manager.clone(),
                    self.keys_manager.clone(),
                    self.logger.clone(),
                    self.network.into(),
                    amount_msat,
                    description,
                    now,
                    expiry_delta_secs.unwrap_or(3600),
                    Some(40),
                )
            }
            Some(r) => create_phantom_invoice(
                amount_msat,
                None,
                description,
                expiry_delta_secs.unwrap_or(3600),
                r,
                self.keys_manager.clone(),
                self.keys_manager.clone(),
                self.logger.clone(),
                self.network.into(),
                Some(40),
                crate::utils::now(),
            ),
        };
        let invoice = invoice_res.map_err(|e| {
            log_error!(self.logger, "ERROR: could not generate invoice: {e}");
            MutinyError::InvoiceCreationFailed
        })?;

        self.save_invoice_payment_info(invoice.clone(), amount_msat, fee_amount_msat, labels)
            .await?;

        log_info!(self.logger, "SUCCESS: generated invoice: {invoice}");

        Ok(invoice)
    }

    async fn save_invoice_payment_info(
        &self,
        invoice: Bolt11Invoice,
        amount_msat: Option<u64>,
        fee_amount_msat: Option<u64>,
        labels: Vec<String>,
    ) -> Result<(), MutinyError> {
        let last_update = utils::now().as_secs();
        let payment_hash = PaymentHash(invoice.payment_hash().to_byte_array());
        let payment_info = PaymentInfo {
            preimage: None,
            secret: Some(invoice.payment_secret().0),
            status: HTLCStatus::Pending,
            amt_msat: MillisatAmount(amount_msat),
            fee_paid_msat: fee_amount_msat,
            bolt11: Some(invoice.clone()),
            payee_pubkey: None,
            privacy_level: PrivacyLevel::NotAvailable,
            last_update,
        };
        persist_payment_info(
            &self.persister.storage,
            &payment_hash.0,
            &payment_info,
            true,
        )
        .map_err(|e| {
            log_error!(self.logger, "ERROR: could not persist payment info: {e}");
            MutinyError::InvoiceCreationFailed
        })?;

        self.persister.storage.set_invoice_labels(invoice, labels)?;

        Ok(())
    }

    /// Gets all the closed channels for this node
    pub fn get_channel_closure(
        &self,
        user_channel_id: u128,
    ) -> Result<Option<ChannelClosure>, MutinyError> {
        log_trace!(self.logger, "calling get_channel_closure");
        let res = self.persister.get_channel_closure(user_channel_id);
        log_trace!(self.logger, "finished calling get_channel_closure");

        res
    }

    /// Gets all the closed channels for this node
    pub fn get_channel_closures(&self) -> Result<Vec<ChannelClosure>, MutinyError> {
        log_trace!(self.logger, "calling get_channel_closures");
        let res = self.persister.list_channel_closures();
        log_trace!(self.logger, "finished calling get_channel_closures");

        res
    }

    fn retry_strategy() -> Retry {
        Retry::Attempts(15)
    }

    /// init_invoice_payment sends off the payment but does not wait for results
    /// use pay_invoice_with_timeout to wait for results
    pub async fn init_invoice_payment(
        &self,
        invoice: &Bolt11Invoice,
        amt_sats: Option<u64>,
    ) -> Result<(PaymentId, PaymentHash), MutinyError> {
        log_trace!(self.logger, "calling init_invoice_payment");

        let payment_hash = invoice.payment_hash().to_byte_array();

        if read_payment_info(&self.persister.storage, &payment_hash, false, &self.logger)
            .is_some_and(|p| p.status != HTLCStatus::Failed)
        {
            return Err(MutinyError::NonUniquePaymentHash);
        }

        if read_payment_info(&self.persister.storage, &payment_hash, true, &self.logger)
            .is_some_and(|p| p.status != HTLCStatus::Failed)
        {
            return Err(MutinyError::NonUniquePaymentHash);
        }

        // get invoice amount or use amt_sats
        let send_msats = invoice
            .amount_milli_satoshis()
            .or(amt_sats.map(|x| x * 1_000))
            .ok_or(MutinyError::InvoiceInvalid)?;

        // check if we have enough balance to send
        if self.get_outbound_capacity_msat() < send_msats {
            log_debug!(
                self.logger,
                "Outbound capacity insufficient, try to resume disconnect channels..."
            );
            if let Err(err) = self.try_connect_unusable_channel_peers().await {
                log_debug!(
                    self.logger,
                    "try connect unusable_channel_peers error {err:?}"
                );
            }
            if self.get_outbound_capacity_msat() < send_msats {
                // Channels exist but not enough capacity
                return Err(MutinyError::InsufficientBalance);
            }
        }

        // make sure node at least has one connection before attempting payment
        // wait for connection before paying, or otherwise instant fail anyways
        // also check we've completed initial sync this run, otherwise we might create
        // htlcs that can cause a channel to be closed
        for _ in 0..DEFAULT_PAYMENT_TIMEOUT {
            // check if we've been stopped
            if self.stop.load(Ordering::Relaxed) {
                return Err(MutinyError::NotRunning);
            }
            let has_usable = !self.channel_manager.list_usable_channels().is_empty();
            let init = self.has_done_initial_sync.load(Ordering::Relaxed);
            if has_usable && init {
                break;
            }
            log_trace!(
                self.logger,
                "waiting for channel to be usable, has usable channels: {has_usable} finished init sync:{init}"
            );
            sleep(1_000).await;
        }

        let (pay_result, amt_msat) = if invoice.amount_milli_satoshis().is_none() {
            if amt_sats.is_none() {
                return Err(MutinyError::InvoiceInvalid);
            }
            let amount_msats = amt_sats.unwrap() * 1_000;
            (
                self.pay_invoice_internal(invoice, amount_msats),
                amount_msats,
            )
        } else {
            if amt_sats.is_some() {
                return Err(MutinyError::InvoiceInvalid);
            }
            let amount_msats = invoice.amount_milli_satoshis().unwrap();
            (
                self.pay_invoice_internal(invoice, amount_msats),
                amount_msats,
            )
        };

        let last_update = utils::now().as_secs();
        let mut payment_info = PaymentInfo {
            preimage: None,
            secret: None,
            status: HTLCStatus::InFlight,
            amt_msat: MillisatAmount(Some(amt_msat)),
            fee_paid_msat: None,
            bolt11: Some(invoice.clone()),
            payee_pubkey: None,
            privacy_level: PrivacyLevel::NotAvailable,
            last_update,
        };

        persist_payment_info(&self.persister.storage, &payment_hash, &payment_info, false)?;

        let res = match pay_result {
            Ok(id) => Ok((id, PaymentHash(payment_hash))),
            Err(error) => {
                log_error!(self.logger, "failed to make payment: {error:?}");
                // call list channels to see what our channels are
                let current_channels = self.channel_manager.list_channels();
                let claimable_balance = self
                    .chain_monitor
                    .get_claimable_balances(&[])
                    .into_iter()
                    .map(|b| b.claimable_amount_satoshis())
                    .sum::<u64>()
                    * 1000;
                log_debug!(
                    self.logger,
                    "current channel details: {:?}",
                    current_channels
                );

                payment_info.status = HTLCStatus::Failed;
                persist_payment_info(&self.persister.storage, &payment_hash, &payment_info, false)?;

                Err(map_sending_failure(
                    error,
                    amt_msat,
                    &current_channels,
                    claimable_balance,
                ))
            }
        };
        log_trace!(self.logger, "finished calling init_invoice_payment");

        res
    }

    // copied from LDK, modified to change a couple params
    fn pay_invoice_internal(
        &self,
        invoice: &Bolt11Invoice,
        amount_msats: u64,
    ) -> Result<PaymentId, RetryableSendFailure> {
        let payment_id = PaymentId(invoice.payment_hash().to_byte_array());
        let payment_hash = PaymentHash((*invoice.payment_hash()).to_byte_array());
        let mut recipient_onion = RecipientOnionFields::secret_only(*invoice.payment_secret());
        recipient_onion.payment_metadata = invoice.payment_metadata().cloned();
        let mut payment_params = PaymentParameters::from_node_id(
            invoice.recover_payee_pub_key(),
            invoice.min_final_cltv_expiry_delta() as u32,
        )
        .with_expiry_time(invoice.expires_at().unwrap().as_secs())
        .with_route_hints(invoice.route_hints())
        .unwrap();
        if let Some(features) = invoice.features() {
            payment_params = payment_params
                .with_bolt11_features(features.clone())
                .unwrap();
        }
        let route_params = RouteParameters {
            payment_params,
            final_value_msat: amount_msats,
            max_total_routing_fee_msat: None, // main change from LDK, we just want payment to succeed
        };

        self.channel_manager
            .as_ref()
            .send_payment(
                payment_hash,
                recipient_onion,
                payment_id,
                route_params,
                Self::retry_strategy(),
            )
            .map(|_| payment_id)
    }

    async fn await_payment(
        &self,
        payment_id: PaymentId,
        payment_hash: PaymentHash,
        timeout: u64,
        labels: Vec<String>,
    ) -> Result<MutinyInvoice, MutinyError> {
        let start = utils::now().as_secs();
        loop {
            let now = utils::now().as_secs();
            if now - start > timeout {
                // stop retrying after timeout, this should help prevent
                // payments completing unexpectedly after the timeout
                self.channel_manager.abandon_payment(payment_id);
                return Err(MutinyError::PaymentTimeout);
            }

            let payment_info = read_payment_info(
                &self.persister.storage,
                &payment_hash.0,
                false,
                &self.logger,
            );

            if let Some(info) = payment_info {
                match info.status {
                    HTLCStatus::Succeeded => {
                        let mutiny_invoice =
                            MutinyInvoice::from(info, payment_hash, false, labels)?;
                        return Ok(mutiny_invoice);
                    }
                    HTLCStatus::Failed => return Err(MutinyError::RoutingFailed),
                    _ => {}
                }
            }

            sleep(250).await;
        }
    }

    pub async fn pay_invoice_with_timeout(
        &self,
        invoice: &Bolt11Invoice,
        amt_sats: Option<u64>,
        timeout_secs: Option<u64>,
        labels: Vec<String>,
    ) -> Result<MutinyInvoice, MutinyError> {
        log_trace!(self.logger, "calling pay_invoice_with_timeout");

        // initiate payment
        let (payment_id, payment_hash) = self.init_invoice_payment(invoice, amt_sats).await?;
        let timeout: u64 = timeout_secs.unwrap_or(DEFAULT_PAYMENT_TIMEOUT);

        let res = self
            .await_payment(payment_id, payment_hash, timeout, labels)
            .await;
        log_trace!(self.logger, "finished calling pay_invoice_with_timeout");

        res
    }

    /// init_keysend_payment sends off the payment but does not wait for results
    /// use keysend_with_timeout to wait for results
    pub async fn init_keysend_payment(
        &self,
        to_node: PublicKey,
        amt_sats: u64,
        message: Option<String>,
        labels: Vec<String>,
        payment_id: PaymentId,
    ) -> Result<MutinyInvoice, MutinyError> {
        log_trace!(self.logger, "calling init_keysend_payment");

        let amt_msats = amt_sats * 1_000;

        // check if we have enough balance to send
        let channels = self.channel_manager.list_channels();
        if self
            .chain_monitor
            .get_claimable_balances(
                &channels
                    .iter()
                    // only consider channels that are confirmed
                    .filter(|c| !c.is_channel_ready)
                    .collect::<Vec<_>>(),
            )
            .into_iter()
            .map(|b| b.claimable_amount_satoshis())
            .sum::<u64>()
            * 1000
            < amt_msats
        {
            // Channels exist but not enough capacity
            return Err(MutinyError::InsufficientBalance);
        }

        // make sure node at least has one connection before attempting payment
        // wait for connection before paying, or otherwise instant fail anyways
        // also check we've completed initial sync this run, otherwise we might create
        // htlcs that can cause a channel to be closed
        for _ in 0..DEFAULT_PAYMENT_TIMEOUT {
            // check if we've been stopped
            if self.stop.load(Ordering::Relaxed) {
                return Err(MutinyError::NotRunning);
            }
            if !self.channel_manager.list_usable_channels().is_empty()
                && self.has_done_initial_sync.load(Ordering::SeqCst)
            {
                break;
            }
            sleep(1_000).await;
        }

        let mut entropy = [0u8; 32];
        getrandom::getrandom(&mut entropy).map_err(|_| MutinyError::SeedGenerationFailed)?;
        let payment_secret = PaymentSecret(entropy);

        let mut entropy = [0u8; 32];
        getrandom::getrandom(&mut entropy).map_err(|_| MutinyError::SeedGenerationFailed)?;
        let preimage = PaymentPreimage(entropy);

        let payment_params = PaymentParameters::for_keysend(to_node, 40, false);
        let route_params: RouteParameters = RouteParameters {
            final_value_msat: amt_msats,
            payment_params,
            max_total_routing_fee_msat: None,
        };

        let recipient_onion = if let Some(msg) = message {
            // keysend messages are encoded as TLV type 34349334
            RecipientOnionFields::secret_only(payment_secret)
                .with_custom_tlvs(vec![(34349334, msg.encode())])
                .map_err(|_| {
                    log_error!(self.logger, "could not encode keysend message");
                    MutinyError::InvoiceCreationFailed
                })?
        } else {
            RecipientOnionFields::spontaneous_empty()
        };

        let pay_result = self.channel_manager.send_spontaneous_payment_with_retry(
            Some(preimage),
            recipient_onion,
            payment_id,
            route_params,
            Self::retry_strategy(),
        );

        let payment_hash = PaymentHash(Sha256::hash(&preimage.0).to_byte_array());

        let last_update = utils::now().as_secs();
        let mut payment_info = PaymentInfo {
            preimage: Some(preimage.0),
            secret: None,
            status: HTLCStatus::InFlight,
            amt_msat: MillisatAmount(Some(amt_msats)),
            fee_paid_msat: None,
            bolt11: None,
            payee_pubkey: Some(to_node),
            privacy_level: PrivacyLevel::NotAvailable,
            last_update,
        };

        persist_payment_info(
            &self.persister.storage,
            &payment_hash.0,
            &payment_info,
            false,
        )?;

        let res = match pay_result {
            Ok(_) => {
                let mutiny_invoice =
                    MutinyInvoice::from(payment_info, payment_hash, false, labels)?;
                Ok(mutiny_invoice)
            }
            Err(error) => {
                payment_info.status = HTLCStatus::Failed;
                persist_payment_info(
                    &self.persister.storage,
                    &payment_hash.0,
                    &payment_info,
                    false,
                )?;
                let current_channels = self.channel_manager.list_channels();
                let claimable_balance = self
                    .chain_monitor
                    .get_claimable_balances(&[])
                    .into_iter()
                    .map(|b| b.claimable_amount_satoshis())
                    .sum::<u64>()
                    * 1000;
                Err(map_sending_failure(
                    error,
                    amt_msats,
                    &current_channels,
                    claimable_balance,
                ))
            }
        };
        log_trace!(self.logger, "finished calling init_keysend_payment");

        res
    }

    pub async fn keysend_with_timeout(
        &self,
        to_node: PublicKey,
        amt_sats: u64,
        message: Option<String>,
        labels: Vec<String>,
        timeout_secs: Option<u64>,
    ) -> Result<MutinyInvoice, MutinyError> {
        log_trace!(self.logger, "calling keysend_with_timeout");

        let mut entropy = [0u8; 32];
        getrandom::getrandom(&mut entropy).map_err(|_| MutinyError::SeedGenerationFailed)?;
        let payment_id = PaymentId(entropy);

        // initiate payment
        let pay = self
            .init_keysend_payment(to_node, amt_sats, message, labels.clone(), payment_id)
            .await?;

        let timeout: u64 = timeout_secs.unwrap_or(DEFAULT_PAYMENT_TIMEOUT);
        let payment_hash = PaymentHash(pay.payment_hash.to_byte_array());

        let res = self
            .await_payment(payment_id, payment_hash, timeout, labels)
            .await;
        log_trace!(self.logger, "finished calling keysend_with_timeout");

        res
    }

    async fn await_chan_funding_tx(
        &self,
        user_channel_id: u128,
        pubkey: &PublicKey,
        timeout: u64,
    ) -> Result<OutPoint, MutinyError> {
        let start = utils::now().as_secs();
        loop {
            if self.stop.load(Ordering::Relaxed) {
                return Err(MutinyError::NotRunning);
            }

            // We'll set failure reason if the peer rejects the channel
            if let Some(failure_reason) = self
                .persister
                .get_channel_open_params(user_channel_id)?
                .and_then(|p| p.failure_reason)
            {
                log_error!(self.logger, "Channel funding tx failed: {failure_reason}");
                // can now safely delete the channel open params
                let _ = self.persister.delete_channel_open_params(user_channel_id);
                return Err(MutinyError::ChannelCreationFailedWithReason(failure_reason));
            }

            let channels = self.channel_manager.list_channels_with_counterparty(pubkey);
            let channel = channels
                .iter()
                .find(|c| c.user_channel_id == user_channel_id);

            if let Some(outpoint) = channel.and_then(|c| c.funding_txo) {
                let outpoint = outpoint.into_bitcoin_outpoint();
                log_info!(self.logger, "Channel funding tx found: {}", outpoint);
                log_debug!(self.logger, "Waiting for Channel Pending event");
                loop {
                    // we delete the channel open params on channel pending event
                    // so if we can't find them, we know the channel is pending
                    // and we can safely return
                    if self
                        .persister
                        .get_channel_open_params(user_channel_id)
                        .map(|p| p.is_none())
                        .unwrap_or(false)
                    {
                        return Ok(outpoint);
                    }

                    let now = utils::now().as_secs();
                    if now - start > timeout {
                        return Err(MutinyError::ChannelCreationFailed);
                    }

                    if self.stop.load(Ordering::Relaxed) {
                        return Err(MutinyError::NotRunning);
                    }
                    sleep(250).await;
                }
            }

            let now = utils::now().as_secs();
            if now - start > timeout {
                return Err(MutinyError::ChannelCreationFailed);
            }

            sleep(250).await;
        }
    }

    pub async fn init_open_channel(
        &self,
        pubkey: PublicKey,
        amount_sat: u64,
        fee_rate: Option<u64>,
        user_channel_id: Option<u128>,
    ) -> Result<u128, MutinyError> {
        log_trace!(self.logger, "calling init_open_channel");

        let accept_underpaying_htlcs = self
            .lsp_client
            .as_ref()
            .is_some_and(|l| l.accept_underpaying_htlcs());
        let config = default_user_config(accept_underpaying_htlcs);

        let user_channel_id = user_channel_id.unwrap_or_else(|| {
            // generate random user channel id
            let mut user_channel_id_bytes = [0u8; 16];
            getrandom::getrandom(&mut user_channel_id_bytes).unwrap();
            u128::from_be_bytes(user_channel_id_bytes)
        });

        let sats_per_vbyte = if let Some(sats_vbyte) = fee_rate {
            sats_vbyte
        } else {
            let sats_per_kw = self.wallet.fees.get_normal_fee_rate();

            FeeRate::from_sat_per_kwu(sats_per_kw.into()).to_sat_per_vb_ceil()
        };

        // save params to db
        let params = ChannelOpenParams::new(sats_per_vbyte);
        self.persister
            .persist_channel_open_params(user_channel_id, params)?;

        let res = match self.channel_manager.create_channel(
            pubkey,
            amount_sat,
            0,
            user_channel_id,
            None,
            Some(config),
        ) {
            Ok(_) => {
                log_info!(
                    self.logger,
                    "SUCCESS: channel initiated with peer: {pubkey:?}"
                );
                Ok(user_channel_id)
            }
            Err(e) => {
                log_error!(
                    self.logger,
                    "ERROR: failed to open channel to pubkey {pubkey:?}: {e:?}"
                );
                Err(MutinyError::ChannelCreationFailed)
            }
        };

        log_trace!(self.logger, "finished calling init_open_channel");

        res
    }

    pub async fn open_channel_with_timeout(
        &self,
        pubkey: PublicKey,
        amount_sat: u64,
        fee_rate: Option<u64>,
        user_channel_id: Option<u128>,
        timeout: u64,
    ) -> Result<OutPoint, MutinyError> {
        log_trace!(self.logger, "calling open_channel_with_timeout");

        let init = self
            .init_open_channel(pubkey, amount_sat, fee_rate, user_channel_id)
            .await?;

        let res = self.await_chan_funding_tx(init, &pubkey, timeout).await;
        log_trace!(self.logger, "finished calling open_channel_with_timeout");

        res
    }

    pub async fn init_sweep_utxos_to_channel(
        &self,
        user_chan_id: Option<u128>,
        utxos: &[OutPoint],
        pubkey: PublicKey,
    ) -> Result<u128, MutinyError> {
        log_trace!(self.logger, "calling init_sweep_utxos_to_channel");

        // Calculate the total value of the selected utxos
        let utxo_value: u64 = {
            // find the wallet utxos
            let wallet = self.wallet.wallet.try_read()?;
            let all_utxos = wallet.list_unspent();

            // calculate total value of utxos
            let mut total = 0;
            for utxo in all_utxos {
                if utxos.contains(&utxo.outpoint) {
                    total += utxo.txout.value.to_sat();
                }
            }
            total
        };

        let sats_per_kw = self.wallet.fees.get_normal_fee_rate();

        // Calculate the expected transaction fee
        let expected_fee = self.wallet.fees.calculate_expected_fee(
            utxos.len(),
            P2WSH_OUTPUT_SIZE,
            None,
            Some(sats_per_kw),
        );

        // channel size is the total value of the utxos minus the fee
        let channel_value_satoshis = utxo_value - expected_fee;

        let accept_underpaying_htlcs = self
            .lsp_client
            .as_ref()
            .is_some_and(|l| l.accept_underpaying_htlcs());
        let config = default_user_config(accept_underpaying_htlcs);

        let user_channel_id = user_chan_id.unwrap_or_else(|| {
            // generate random user channel id
            let mut user_channel_id_bytes = [0u8; 16];
            getrandom::getrandom(&mut user_channel_id_bytes).unwrap();
            u128::from_be_bytes(user_channel_id_bytes)
        });

        let sats_per_vbyte = FeeRate::from_sat_per_kwu(sats_per_kw.into()).to_sat_per_vb_ceil();
        // save params to db
        let params = ChannelOpenParams::new_sweep(sats_per_vbyte, expected_fee, utxos.to_vec());
        self.persister
            .persist_channel_open_params(user_channel_id, params)?;

        let res = match self.channel_manager.create_channel(
            pubkey,
            channel_value_satoshis,
            0,
            user_channel_id,
            None,
            Some(config),
        ) {
            Ok(_) => {
                log_info!(
                    self.logger,
                    "SUCCESS: channel initiated with peer: {pubkey:?}"
                );
                Ok(user_channel_id)
            }
            Err(e) => {
                log_error!(
                    self.logger,
                    "ERROR: failed to open channel to pubkey {pubkey:?}: {e:?}"
                );
                // delete params from db because channel failed
                self.persister.delete_channel_open_params(user_channel_id)?;
                Err(MutinyError::ChannelCreationFailed)
            }
        };
        log_trace!(self.logger, "finished calling init_sweep_utxos_to_channel");

        res
    }

    pub async fn sweep_utxos_to_channel_with_timeout(
        &self,
        user_chan_id: Option<u128>,
        utxos: &[OutPoint],
        pubkey: PublicKey,
        timeout: u64,
    ) -> Result<OutPoint, MutinyError> {
        log_trace!(self.logger, "calling sweep_utxos_to_channel_with_timeout");

        let init = self
            .init_sweep_utxos_to_channel(user_chan_id, utxos, pubkey)
            .await?;

        let res = self.await_chan_funding_tx(init, &pubkey, timeout).await;
        log_trace!(
            self.logger,
            "finished calling sweep_utxos_to_channel_with_timeout"
        );

        res
    }
}

pub(crate) fn scoring_params() -> ProbabilisticScoringFeeParameters {
    ProbabilisticScoringFeeParameters {
        base_penalty_amount_multiplier_msat: 8192 * 100,
        base_penalty_msat: 100_000,
        liquidity_penalty_multiplier_msat: 30_000 * 15,
        liquidity_penalty_amount_multiplier_msat: 192 * 15,
        historical_liquidity_penalty_multiplier_msat: 10_000 * 15,
        historical_liquidity_penalty_amount_multiplier_msat: 64 * 15,
        ..Default::default()
    }
}

pub(crate) fn decay_params() -> ProbabilisticScoringDecayParameters {
    ProbabilisticScoringDecayParameters {
        liquidity_offset_half_life: core::time::Duration::from_secs(3 * 60 * 60),
        historical_no_updates_half_life: core::time::Duration::from_secs(60 * 60 * 24 * 3),
    }
}

fn map_sending_failure(
    error: RetryableSendFailure,
    amt_msat: u64,
    current_channels: &[ChannelDetails],
    claimable_balance: u64,
) -> MutinyError {
    // If the payment failed because of a route not found, check if the amount was
    // valid and return the correct error
    match error {
        RetryableSendFailure::RouteNotFound => {
            // If the amount was greater than our balance, return an InsufficientBalance error
            if amt_msat > claimable_balance {
                return MutinyError::InsufficientBalance;
            }

            // If the amount was within our balance but we couldn't pay because of
            // the channel reserve, return a ReserveAmountError
            let reserved_amt: u64 = current_channels
                .iter()
                .flat_map(|c| c.unspendable_punishment_reserve)
                .sum::<u64>()
                * 1_000; // multiply by 1k to convert to msat
            if claimable_balance - reserved_amt < amt_msat {
                return MutinyError::ReserveAmountError;
            }

            // if none of our channels could afford an HTLC, return a ReserveAmountError
            if current_channels
                .iter()
                .all(|c| c.next_outbound_htlc_limit_msat < amt_msat)
            {
                return MutinyError::ReserveAmountError;
            }

            MutinyError::RoutingFailed
        }
        RetryableSendFailure::PaymentExpired => MutinyError::InvoiceExpired,
        RetryableSendFailure::DuplicatePayment => MutinyError::NonUniquePaymentHash,
        RetryableSendFailure::OnionPacketSizeExceeded => MutinyError::PacketSizeExceeded,
    }
}

#[allow(clippy::too_many_arguments)]
async fn start_reconnection_handling<S: MutinyStorage>(
    storage: &S,
    node_pubkey: PublicKey,
    #[cfg(target_arch = "wasm32")] websocket_proxy_addr: String,
    peer_man: Arc<PeerManagerImpl<S>>,
    pending_connections: PendingConnections,
    fee_estimator: Arc<MutinyFeeEstimator<S>>,
    logger: &Arc<MutinyLogger>,
    uuid: String,
    lsp_client: Option<&AnyLsp<S>>,
    stop: Arc<AtomicBool>,
    stopped_components: Arc<RwLock<Vec<bool>>>,
    skip_fee_estimates: bool,
) {
    // wait for fee estimates sync to finish, it can cause issues if we try to connect before
    // we have fee estimates
    if !skip_fee_estimates {
        loop {
            if stop.load(Ordering::Relaxed) {
                return;
            }
            // make sure we have fee estimates and they are not empty
            if storage
                .get_fee_estimates()
                .map(|m| m.is_some_and(|m| !m.is_empty()))
                .unwrap_or(false)
            {
                break;
            }
            sleep(1_000).await;
        }
    }

    // Attempt initial connections first in the background
    #[cfg(target_arch = "wasm32")]
    let websocket_proxy_addr_copy_proxy = websocket_proxy_addr.clone();

    let proxy_logger = logger.clone();
    let peer_man_proxy = peer_man.clone();
    let proxy_fee_estimator = fee_estimator.clone();
    let lsp_client_copy = lsp_client.cloned();
    let storage_copy = storage.clone();
    let uuid_copy = uuid.clone();
    let stop_copy = stop.clone();
    utils::spawn(async move {
        // Now try to connect to the client's LSP
        // This is here in case the LSP client node info has not saved to storage yet
        let mut lsp_node_id = None;
        if let Some(lsp) = lsp_client_copy.as_ref() {
            let pubkey = lsp.get_lsp_pubkey().await;
            let connection_string = lsp.get_lsp_connection_string().await;
            let mut node_id = NodeId::from_pubkey(&pubkey);

            let connect_res = connect_peer_if_necessary(
                #[cfg(target_arch = "wasm32")]
                &websocket_proxy_addr_copy_proxy,
                &PubkeyConnectionInfo::new(connection_string.as_str()).unwrap(),
                &storage_copy,
                proxy_logger.clone(),
                peer_man_proxy.clone(),
                pending_connections.clone(),
                proxy_fee_estimator.clone(),
                stop_copy.clone(),
            )
            .await;
            match connect_res {
                Ok(_) => {
                    log_trace!(proxy_logger, "auto connected lsp: {node_id}");
                }
                Err(e) => {
                    log_trace!(proxy_logger, "could not connect to lsp {node_id}: {e}");
                    match lsp {
                        AnyLsp::VoltageFlow(lock) => {
                            let mut client = lock.write().await;
                            if let Err(e) = client.set_connection_info().await {
                                log_error!(
                                    proxy_logger,
                                    "could not set connection info from voltage lsp: {e}"
                                );
                            } else {
                                log_trace!(proxy_logger, "set connection info from voltage lsp");
                                // get new pubkey and connection string
                                let pubkey = lsp.get_lsp_pubkey().await;
                                node_id = NodeId::from_pubkey(&pubkey);
                                let connection_string = lsp.get_lsp_connection_string().await;

                                if let Err(e) = connect_peer_if_necessary(
                                    #[cfg(target_arch = "wasm32")]
                                    &websocket_proxy_addr_copy_proxy,
                                    &PubkeyConnectionInfo::new(connection_string.as_str()).unwrap(),
                                    &storage_copy,
                                    proxy_logger.clone(),
                                    peer_man_proxy.clone(),
                                    pending_connections.clone(),
                                    proxy_fee_estimator.clone(),
                                    stop_copy.clone(),
                                )
                                .await
                                {
                                    log_error!(
                                        proxy_logger,
                                        "could not connect to lsp after setting connection info: {e}"
                                    );
                                }
                            }
                        }
                        AnyLsp::Lsps(_) => {} // nothing to do here, just retry next loop
                    }
                }
            }

            lsp_node_id = Some(node_id);
            let connection_string = lsp.get_lsp_connection_string().await;
            if let Err(e) = save_peer_connection_info(
                &storage_copy,
                &uuid_copy,
                &node_id,
                &connection_string,
                None,
            ) {
                log_error!(proxy_logger, "could not save connection to lsp: {e}");
            }
        };

        // Now try to connect to other nodes the client might have, skipping the LSP if necessary
        let stored_peers = get_all_peers(&storage_copy).unwrap_or_default();
        let initial_peers: Vec<(NodeId, String)> = stored_peers
            .into_iter()
            .filter(|(_, d)| {
                d.connection_string.is_some() && d.nodes.binary_search(&uuid.to_string()).is_ok()
            })
            .map(|(n, d)| (n, d.connection_string.unwrap()))
            .filter(|(n, _)| lsp_node_id != Some(*n))
            .collect();
        for (pubkey, conn_str) in initial_peers.into_iter() {
            log_trace!(
                proxy_logger,
                "starting initial connection to peer: {pubkey}"
            );
            let peer_connection_info = match PubkeyConnectionInfo::new(&conn_str) {
                Ok(p) => p,
                Err(e) => {
                    log_error!(proxy_logger, "could not parse connection info: {e}");
                    continue;
                }
            };

            let connect_res = connect_peer_if_necessary(
                #[cfg(target_arch = "wasm32")]
                &websocket_proxy_addr,
                &peer_connection_info,
                &storage_copy,
                proxy_logger.clone(),
                peer_man_proxy.clone(),
                pending_connections.clone(),
                proxy_fee_estimator.clone(),
                stop.clone(),
            )
            .await;
            match connect_res {
                Ok(_) => {
                    log_trace!(proxy_logger, "initial connection to peer: {pubkey}");
                }
                Err(e) => {
                    log_warn!(
                        proxy_logger,
                        "could not start initial connection to peer: {e}"
                    );
                }
            }
        }

        // keep trying to connect each lightning peer if they get disconnected
        // hashMap to store backoff times for each pubkey
        let mut backoff_times = HashMap::new();

        // Only begin this process after 30s of running
        for _ in 0..30 {
            if stop.load(Ordering::Relaxed) {
                log_debug!(
                    proxy_logger,
                    "stopping connection component and disconnecting peers for node: {}",
                    node_pubkey,
                );
                peer_man_proxy.disconnect_all_peers();
                stop_component(&stopped_components);
                log_debug!(
                    proxy_logger,
                    "stopped connection component and disconnected peers for node: {}",
                    node_pubkey,
                );
                return;
            }
            sleep(1_000).await;
        }

        loop {
            for _ in 0..INITIAL_RECONNECTION_DELAY {
                if stop.load(Ordering::Relaxed) {
                    log_debug!(
                        proxy_logger,
                        "stopping connection component and disconnecting peers for node: {}",
                        node_pubkey,
                    );
                    peer_man_proxy.disconnect_all_peers();
                    stop_component(&stopped_components);
                    log_debug!(
                        proxy_logger,
                        "stopped connection component and disconnected peers for node: {}",
                        node_pubkey,
                    );
                    return;
                }
                sleep(1_000).await;
            }

            let peer_connections = get_all_peers(&storage_copy).unwrap_or_default();
            let current_connections = peer_man_proxy.get_peer_node_ids();

            let not_connected: Vec<(NodeId, String)> = peer_connections
                .into_iter()
                .filter(|(_, d)| {
                    d.connection_string.is_some()
                        && d.nodes.binary_search(&uuid.to_string()).is_ok()
                })
                .map(|(n, d)| (n, d.connection_string.unwrap()))
                .filter(|(n, _)| {
                    !current_connections
                        .iter()
                        .any(|c| &NodeId::from_pubkey(c) == n)
                })
                .collect();

            for (pubkey, conn_str) in not_connected.into_iter() {
                let now = crate::utils::now();

                // initialize backoff time and last attempt time if they do not exist
                let backoff_entry = backoff_times
                    .entry(pubkey)
                    .or_insert((INITIAL_RECONNECTION_DELAY, now));

                // skip this pubkey if not enough time has passed since the last attempt
                if now - backoff_entry.1 < Duration::from_secs(backoff_entry.0) {
                    continue;
                }

                // Update the last attempt time
                backoff_entry.1 = now;

                log_trace!(proxy_logger, "going to auto connect to peer: {pubkey}");
                let peer_connection_info = match PubkeyConnectionInfo::new(&conn_str) {
                    Ok(p) => p,
                    Err(e) => {
                        log_error!(proxy_logger, "could not parse connection info: {e}");
                        continue;
                    }
                };

                let connect_res = connect_peer_if_necessary(
                    #[cfg(target_arch = "wasm32")]
                    &websocket_proxy_addr,
                    &peer_connection_info,
                    &storage_copy,
                    proxy_logger.clone(),
                    peer_man_proxy.clone(),
                    pending_connections.clone(),
                    proxy_fee_estimator.clone(),
                    stop.clone(),
                )
                .await;
                match connect_res {
                    Ok(_) => {
                        log_trace!(proxy_logger, "auto connected peer: {pubkey}");
                        // reset backoff time to initial value if connection is successful
                        backoff_entry.0 = INITIAL_RECONNECTION_DELAY;
                    }
                    Err(e) => {
                        log_warn!(proxy_logger, "could not auto connect peer: {e}");
                        // double the backoff time if connection fails, but do not exceed max
                        backoff_entry.0 = (backoff_entry.0 * 2).min(MAX_RECONNECTION_DELAY);
                    }
                }
            }
        }
    });
}

fn stop_component(stopped_components: &Arc<RwLock<Vec<bool>>>) {
    let mut stopped = stopped_components
        .try_write()
        .expect("can write to stopped components");
    if let Some(first_false) = stopped.iter_mut().find(|x| !**x) {
        *first_false = true;
    }
}

pub(crate) fn create_peer_manager<S: MutinyStorage>(
    km: Arc<PhantomKeysManager<S>>,
    lightning_msg_handler: MessageHandler<S>,
    logger: Arc<MutinyLogger>,
) -> PeerManagerImpl<S> {
    let now = utils::now().as_secs();
    let mut ephemeral_bytes = [0u8; 32];
    getrandom::getrandom(&mut ephemeral_bytes).expect("Failed to generate entropy");

    PeerManagerImpl::new(
        lightning_msg_handler,
        now as u32,
        &ephemeral_bytes,
        logger,
        km,
    )
}

pub(crate) fn parse_peer_info(
    peer_pubkey_and_ip_addr: &str,
) -> Result<(PublicKey, String), MutinyError> {
    let (pubkey, peer_addr_str) = split_peer_connection_string(peer_pubkey_and_ip_addr)?;

    let peer_addr_str_with_port = if peer_addr_str.contains(':') {
        peer_addr_str
    } else {
        format!("{peer_addr_str}:9735")
    };

    Ok((pubkey, peer_addr_str_with_port))
}

pub(crate) fn split_peer_connection_string(
    peer_pubkey_and_ip_addr: &str,
) -> Result<(PublicKey, String), MutinyError> {
    let mut pubkey_and_addr = peer_pubkey_and_ip_addr.split('@');
    let pubkey = pubkey_and_addr
        .next()
        .ok_or_else(|| MutinyError::PeerInfoParseFailed)?;
    let peer_addr_str = pubkey_and_addr
        .next()
        .ok_or_else(|| MutinyError::PeerInfoParseFailed)?;
    let pubkey = PublicKey::from_str(pubkey).map_err(|_| MutinyError::PeerInfoParseFailed)?;
    Ok((pubkey, peer_addr_str.to_string()))
}

pub(crate) fn default_user_config(accept_underpaying_htlcs: bool) -> UserConfig {
    UserConfig {
        channel_handshake_limits: ChannelHandshakeLimits {
            // lnd's max to_self_delay is 2016, so we want to be compatible.
            their_to_self_delay: 2016,
            ..Default::default()
        },
        channel_handshake_config: ChannelHandshakeConfig {
            minimum_depth: 1,
            announce_for_forwarding: false,
            negotiate_scid_privacy: true,
            commit_upfront_shutdown_pubkey: false,
            negotiate_anchors_zero_fee_htlc_tx: true, // enable anchor channels
            max_inbound_htlc_value_in_flight_percent_of_channel: 100,
            our_to_self_delay: 6 * 24 * 2, // 2 days
            their_channel_reserve_proportional_millionths: 0,
            ..Default::default()
        },
        manually_accept_inbound_channels: true,
        channel_config: ChannelConfig {
            // Set to max supply of bitcoin.
            // Don't care about dust exposure, we just want to be able to make payments.
            max_dust_htlc_exposure: MaxDustHTLCExposure::FixedLimitMsat(
                21_000_000 * 100_000_000 * 1_000,
            ),
            accept_underpaying_htlcs,
            ..Default::default()
        },
        ..Default::default()
    }
}

#[cfg(test)]
#[cfg(not(target_arch = "wasm32"))]
mod tests {
    use super::*;
    use crate::get_invoice_by_hash;
    use crate::node::{map_sending_failure, parse_peer_info};
    use crate::storage::MemoryStorage;
    use crate::test_utils::*;
    use bitcoin::secp256k1::PublicKey;
    use lightning::ln::channel_state::ChannelCounterparty;
    use lightning::ln::features::InitFeatures;
    use lightning::ln::types::ChannelId;
    use lightning_invoice::Bolt11InvoiceDescription;
    use std::str::FromStr;

    #[test]
    fn test_parse_peer_info() {
        log!("test parse peer info");

        let pub_key = PublicKey::from_str(
            "0218845781f631c48f1c9709e23092067d06837f30aa0cd0544ac887fe91ddd166",
        )
        .unwrap();
        let addr = "127.0.0.1:4000";

        let (peer_pubkey, peer_addr) = parse_peer_info(&format!("{pub_key}@{addr}")).unwrap();

        assert_eq!(pub_key, peer_pubkey);
        assert_eq!(addr, peer_addr);
    }

    #[test]
    fn test_parse_peer_info_no_port() {
        log!("test parse peer info with no port");

        let pub_key = PublicKey::from_str(
            "0218845781f631c48f1c9709e23092067d06837f30aa0cd0544ac887fe91ddd166",
        )
        .unwrap();
        let addr = "127.0.0.1";
        let port = "9735";

        let (peer_pubkey, peer_addr) = parse_peer_info(&format!("{pub_key}@{addr}")).unwrap();

        assert_eq!(pub_key, peer_pubkey);
        assert_eq!(format!("{addr}:{port}"), peer_addr);
    }

    #[test]
    #[allow(deprecated)]
    fn test_map_sending_failure() {
        let amt_msat = 1_000_000;

        // test simple cases
        assert_eq!(
            map_sending_failure(
                RetryableSendFailure::PaymentExpired,
                amt_msat,
                &[],
                amt_msat
            ),
            MutinyError::InvoiceExpired
        );
        assert_eq!(
            map_sending_failure(
                RetryableSendFailure::DuplicatePayment,
                amt_msat,
                &[],
                amt_msat
            ),
            MutinyError::NonUniquePaymentHash
        );

        let mut channel_details = ChannelDetails {
            channel_id: ChannelId::new_zero(),
            counterparty: ChannelCounterparty {
                node_id: PublicKey::from_slice(&[2; 33]).unwrap(), // dummy value
                features: InitFeatures::empty(),
                unspendable_punishment_reserve: 0,
                forwarding_info: None,
                outbound_htlc_minimum_msat: None,
                outbound_htlc_maximum_msat: None,
            },
            funding_txo: None,
            channel_type: None,
            short_channel_id: None,
            outbound_scid_alias: None,
            inbound_scid_alias: None,
            channel_value_satoshis: 0,
            unspendable_punishment_reserve: None,
            user_channel_id: 0,
            feerate_sat_per_1000_weight: None,
            balance_msat: 0,
            outbound_capacity_msat: 0,
            next_outbound_htlc_limit_msat: 0,
            next_outbound_htlc_minimum_msat: 0,
            inbound_capacity_msat: 0,
            confirmations_required: None,
            confirmations: None,
            force_close_spend_delay: None,
            is_outbound: false,
            is_channel_ready: false,
            channel_shutdown_state: None,
            is_usable: false,
            is_announced: false,
            inbound_htlc_minimum_msat: None,
            inbound_htlc_maximum_msat: None,
            config: None,
            pending_inbound_htlcs: Default::default(),
            pending_outbound_htlcs: Default::default(),
        };

        assert_eq!(
            map_sending_failure(
                RetryableSendFailure::RouteNotFound,
                amt_msat,
                &[channel_details.clone()],
                0,
            ),
            MutinyError::InsufficientBalance
        );

        assert_eq!(
            map_sending_failure(
                RetryableSendFailure::RouteNotFound,
                amt_msat,
                &[channel_details.clone()],
                0,
            ),
            MutinyError::InsufficientBalance
        );

        // test punishment reserve
        channel_details.balance_msat = amt_msat + 10;
        channel_details.unspendable_punishment_reserve = Some(20);
        assert_eq!(
            map_sending_failure(
                RetryableSendFailure::RouteNotFound,
                amt_msat,
                &[channel_details.clone()],
                amt_msat + 10,
            ),
            MutinyError::ReserveAmountError
        );

        // set reserve back to 0 so we can test htlc reserve
        channel_details.unspendable_punishment_reserve = Some(0);
        assert_eq!(
            map_sending_failure(
                RetryableSendFailure::RouteNotFound,
                amt_msat,
                &[channel_details.clone()],
                amt_msat + 10,
            ),
            MutinyError::ReserveAmountError
        );

        // set htlc limit to be greater than amt_msat so we can pass the htlc limit check
        channel_details.next_outbound_htlc_limit_msat = amt_msat + 10;
        assert_eq!(
            map_sending_failure(
                RetryableSendFailure::RouteNotFound,
                amt_msat,
                &[channel_details.clone()],
                amt_msat + 10,
            ),
            MutinyError::RoutingFailed
        );
    }

    #[tokio::test]
    async fn test_create_node() {
        let storage = MemoryStorage::default();
        let node = create_node(storage).await;
        assert!(!node.pubkey.to_string().is_empty());
    }

    #[tokio::test]
    async fn test_create_invoice() {
        let storage = MemoryStorage::default();
        let node = create_node(storage.clone()).await;
        let logger = Arc::new(MutinyLogger::default());

        let now = crate::utils::now().as_secs();

        let amount_sats = Some(1_000);

        let (invoice, _) = node
            .create_invoice(amount_sats, None, vec![], None)
            .await
            .unwrap();

        assert_eq!(
            invoice.amount_milli_satoshis(),
            amount_sats.map(|amount| amount * 1000)
        );
        match invoice.description() {
            Bolt11InvoiceDescription::Direct(desc) => {
                assert_eq!(desc.to_string(), "");
            }
            _ => panic!("unexpected invoice description"),
        }

        let from_storage = get_invoice_by_hash(invoice.payment_hash(), &storage, &logger).unwrap();
        let by_hash = get_invoice_by_hash(invoice.payment_hash(), &storage, &logger).unwrap();

        assert_eq!(from_storage, by_hash);
        assert_eq!(from_storage.bolt11, Some(invoice.clone()));
        assert_eq!(from_storage.description, None);
        assert_eq!(from_storage.payment_hash, invoice.payment_hash().to_owned());
        assert_eq!(from_storage.preimage, None);
        assert_eq!(from_storage.payee_pubkey, None);
        assert_eq!(from_storage.amount_sats, amount_sats);
        assert_eq!(from_storage.status, HTLCStatus::Pending);
        assert_eq!(from_storage.fees_paid, None);
        assert!(from_storage.inbound);
        assert!(from_storage.last_updated >= now);
    }

    #[tokio::test]
    async fn test_fail_own_invoice() {
        let storage = MemoryStorage::default();
        let node = create_node(storage).await;

        let invoice = node
            .create_invoice(Some(10_000), None, vec![], None)
            .await
            .unwrap()
            .0;

        let result = node
            .pay_invoice_with_timeout(&invoice, None, None, vec![])
            .await;

        match result {
            Err(MutinyError::NonUniquePaymentHash) => {}
            Err(e) => panic!("unexpected error {e:?}"),
            Ok(_) => panic!("somehow paid own invoice"),
        }
    }

    #[tokio::test]
    async fn test_await_payment() {
        let storage = MemoryStorage::default();
        let node = create_node(storage).await;
        let payment_id = PaymentId([0; 32]);
        let payment_hash = PaymentHash([0; 32]);

        // check that we get PaymentTimeout if we don't have the payment info

        let result = node
            .await_payment(payment_id, payment_hash, 1, vec![])
            .await;

        assert_eq!(result.unwrap_err(), MutinyError::PaymentTimeout);

        let mut payment_info = PaymentInfo {
            preimage: None,
            secret: Some([0; 32]),
            status: HTLCStatus::InFlight,
            privacy_level: PrivacyLevel::NotAvailable,
            amt_msat: MillisatAmount(Some(1000)),
            fee_paid_msat: None,
            bolt11: None,
            payee_pubkey: None,
            last_update: crate::utils::now().as_secs(),
        };

        // check that it still fails if it is inflight

        persist_payment_info(
            &node.persister.storage,
            &payment_hash.0,
            &payment_info,
            false,
        )
        .unwrap();

        let result = node
            .await_payment(payment_id, payment_hash, 1, vec![])
            .await;

        assert_eq!(result.unwrap_err(), MutinyError::PaymentTimeout);

        // check that we get proper error if it fails

        payment_info.status = HTLCStatus::Failed;
        persist_payment_info(
            &node.persister.storage,
            &payment_hash.0,
            &payment_info,
            false,
        )
        .unwrap();

        let result = node
            .await_payment(payment_id, payment_hash, 1, vec![])
            .await;

        assert_eq!(result.unwrap_err(), MutinyError::RoutingFailed);

        // check that we get success

        payment_info.status = HTLCStatus::Succeeded;
        persist_payment_info(
            &node.persister.storage,
            &payment_hash.0,
            &payment_info,
            false,
        )
        .unwrap();

        let result = node
            .await_payment(payment_id, payment_hash, 1, vec![])
            .await;

        assert!(result.is_ok());
    }
}

#[cfg(test)]
#[cfg(target_arch = "wasm32")]
mod wasm_test {
    use crate::storage::MemoryStorage;
    use crate::test_utils::create_node;
    use crate::{error::MutinyError, storage::persist_payment_info};
    use crate::{
        event::{MillisatAmount, PaymentInfo},
        storage::get_invoice_by_hash,
    };
    use crate::{labels::LabelStorage, logging::MutinyLogger};
    use crate::{HTLCStatus, PrivacyLevel};
    use itertools::Itertools;
    use lightning::ln::channelmanager::PaymentId;
    use lightning::ln::PaymentHash;
    use lightning_invoice::Bolt11InvoiceDescription;
    use std::sync::Arc;
    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};

    wasm_bindgen_test_configure!(run_in_browser);

    #[test]
    async fn test_create_node() {
        let storage = MemoryStorage::default();
        let node = create_node(storage).await;
        assert!(!node.pubkey.to_string().is_empty());
    }

    #[test]
    async fn test_create_invoice() {
        let storage = MemoryStorage::default();
        let node = create_node(storage.clone()).await;
        let logger = Arc::new(MutinyLogger::default());

        let now = crate::utils::now().as_secs();

        let amount_sats = Some(1_000);
        let label = "test".to_string();
        let labels = vec![label.clone()];

        let (invoice, _) = node
            .create_invoice(amount_sats, None, labels.clone(), None)
            .await
            .unwrap();

        assert_eq!(
            invoice.amount_milli_satoshis(),
            amount_sats.map(|amount| amount * 1000)
        );
        match invoice.description() {
            Bolt11InvoiceDescription::Direct(desc) => {
                assert_eq!(desc.to_string(), "test");
            }
            _ => panic!("unexpected invoice description"),
        }

        let from_storage = get_invoice_by_hash(invoice.payment_hash(), &storage, &logger).unwrap();
        let by_hash = get_invoice_by_hash(invoice.payment_hash(), &storage, &logger).unwrap();

        assert_eq!(from_storage, by_hash);
        assert_eq!(from_storage.bolt11, Some(invoice.clone()));
        assert_eq!(from_storage.description, Some("test".to_string()));
        assert_eq!(from_storage.payment_hash, invoice.payment_hash().to_owned());
        assert_eq!(from_storage.preimage, None);
        assert_eq!(from_storage.payee_pubkey, None);
        assert_eq!(from_storage.amount_sats, amount_sats);
        assert_eq!(from_storage.status, HTLCStatus::Pending);
        assert_eq!(from_storage.fees_paid, None);
        assert_eq!(from_storage.labels, labels.clone());
        assert!(from_storage.inbound);
        assert!(from_storage.last_updated >= now);

        // check labels

        let invoice_labels = storage.get_invoice_labels().unwrap();
        assert_eq!(invoice_labels.len(), 1);
        assert_eq!(invoice_labels.get(&invoice).cloned(), Some(labels));

        let label_item = storage.get_label("test").unwrap().unwrap();

        assert!(label_item.last_used_time >= now);
        assert!(label_item.addresses.is_empty());
        assert_eq!(label_item.invoices.into_iter().collect_vec(), vec![invoice]);
    }

    #[test]
    async fn test_create_invoice_without_amount() {
        let storage = MemoryStorage::default();
        let node = create_node(storage.clone()).await;
        let logger = Arc::new(MutinyLogger::default());

        let now = crate::utils::now().as_secs();

        let amount_sats = None;
        let label = "test".to_string();
        let labels = vec![label.clone()];

        let (invoice, _) = node
            .create_invoice(amount_sats, None, labels.clone(), None)
            .await
            .unwrap();

        assert_eq!(invoice.amount_milli_satoshis(), amount_sats);
        match invoice.description() {
            Bolt11InvoiceDescription::Direct(desc) => {
                assert_eq!(desc.to_string(), "test");
            }
            _ => panic!("unexpected invoice description"),
        }

        let from_storage = get_invoice_by_hash(invoice.payment_hash(), &storage, &logger).unwrap();
        let by_hash = get_invoice_by_hash(invoice.payment_hash(), &storage, &logger).unwrap();

        assert_eq!(from_storage, by_hash);
        assert_eq!(from_storage.bolt11, Some(invoice.clone()));
        assert_eq!(from_storage.description, Some("test".to_string()));
        assert_eq!(from_storage.payment_hash, invoice.payment_hash().to_owned());
        assert_eq!(from_storage.preimage, None);
        assert_eq!(from_storage.payee_pubkey, None);
        assert_eq!(from_storage.amount_sats, amount_sats);
        assert_eq!(from_storage.status, HTLCStatus::Pending);
        assert_eq!(from_storage.fees_paid, None);
        assert_eq!(from_storage.labels, labels.clone());
        assert!(from_storage.inbound);
        assert!(from_storage.last_updated >= now);
    }

    #[test]
    async fn test_fail_own_invoice() {
        let storage = MemoryStorage::default();
        let node = create_node(storage).await;

        let invoice = node
            .create_invoice(Some(10_000), None, vec![], None)
            .await
            .unwrap()
            .0;

        let result = node
            .pay_invoice_with_timeout(&invoice, None, None, vec![])
            .await;

        match result {
            Err(MutinyError::NonUniquePaymentHash) => {}
            Err(e) => panic!("unexpected error {e:?}"),
            Ok(_) => panic!("somehow paid own invoice"),
        }
    }

    #[test]
    async fn test_await_payment() {
        let storage = MemoryStorage::default();
        let node = create_node(storage).await;
        let payment_id = PaymentId([0; 32]);
        let payment_hash = PaymentHash([0; 32]);

        // check that we get PaymentTimeout if we don't have the payment info

        let result = node
            .await_payment(payment_id, payment_hash, 1, vec![])
            .await;

        assert_eq!(result.unwrap_err(), MutinyError::PaymentTimeout);

        let mut payment_info = PaymentInfo {
            preimage: None,
            secret: Some([0; 32]),
            status: HTLCStatus::InFlight,
            privacy_level: PrivacyLevel::NotAvailable,
            amt_msat: MillisatAmount(Some(1000)),
            fee_paid_msat: None,
            bolt11: None,
            payee_pubkey: None,
            last_update: crate::utils::now().as_secs(),
        };

        // check that it still fails if it is inflight
        persist_payment_info(
            &node.persister.storage,
            &payment_hash.0,
            &payment_info,
            false,
        )
        .unwrap();

        let result = node
            .await_payment(payment_id, payment_hash, 1, vec![])
            .await;

        assert_eq!(result.unwrap_err(), MutinyError::PaymentTimeout);

        // check that we get proper error if it fails

        payment_info.status = HTLCStatus::Failed;
        persist_payment_info(
            &node.persister.storage,
            &payment_hash.0,
            &payment_info,
            false,
        )
        .unwrap();

        let result = node
            .await_payment(payment_id, payment_hash, 1, vec![])
            .await;

        assert_eq!(result.unwrap_err(), MutinyError::RoutingFailed);

        // check that we get success

        payment_info.status = HTLCStatus::Succeeded;
        persist_payment_info(
            &node.persister.storage,
            &payment_hash.0,
            &payment_info,
            false,
        )
        .unwrap();

        let result = node
            .await_payment(payment_id, payment_hash, 1, vec![])
            .await;

        assert!(result.is_ok());
    }
}


================================================
File: mutiny-core/src/nodemanager.rs
================================================
use crate::labels::LabelStorage;
use crate::ldkstorage::CHANNEL_CLOSURE_PREFIX;
use crate::logging::LOGGING_KEY;
use crate::lsp::voltage;
use crate::messagehandler::{CommonLnEvent, CommonLnEventCallback};
use crate::peermanager::PeerManager;
use crate::utils::sleep;
use crate::MutinyInvoice;
use crate::MutinyWalletConfig;
use crate::TransactionDetails;
use crate::{
    chain::MutinyChain,
    error::MutinyError,
    fees::MutinyFeeEstimator,
    gossip,
    gossip::{fetch_updated_gossip, get_rgs_url},
    logging::MutinyLogger,
    lsp::{deserialize_lsp_config, Lsp, LspConfig},
    node::{Node, PubkeyConnectionInfo, RapidGossipSync},
    onchain::get_esplora_url,
    onchain::OnChainWallet,
    utils,
};
use crate::{gossip::*, scorer::HubPreferentialScorer};
use crate::{
    node::NodeBuilder,
    storage::{MutinyStorage, DEVICE_ID_KEY, KEYCHAIN_STORE_KEY, NEED_FULL_SYNC_KEY},
};
use anyhow::anyhow;
use async_lock::RwLock;
use bdk_chain::{BlockId, ConfirmationTime};
use bdk_wallet::{KeychainKind, LocalOutput};
use bitcoin::address::NetworkUnchecked;
use bitcoin::bip32::Xpriv;
use bitcoin::blockdata::script;
use bitcoin::hashes::hex::FromHex;
use bitcoin::secp256k1::PublicKey;
use bitcoin::{Address, Network, OutPoint, Transaction, Txid};
use esplora_client::{AsyncClient, Builder};
use futures::future::join_all;
use hex_conservative::DisplayHex;
use lightning::chain::Confirm;
use lightning::events::ClosureReason;
use lightning::ln::channel_state::ChannelDetails;
use lightning::ln::channelmanager::PhantomRouteHints;
use lightning::ln::script::ShutdownScript;
use lightning::ln::types::ChannelId;
use lightning::routing::gossip::NodeId;
use lightning::sign::{NodeSigner, Recipient};
use lightning::util::logger::*;
use lightning::{log_debug, log_error, log_info, log_trace, log_warn};
use lightning_invoice::Bolt11Invoice;
use lightning_transaction_sync::EsploraSyncClient;
use reqwest::Client;
use serde::{Deserialize, Serialize};
use serde_json::Value;
use std::cmp::max;

use std::sync::atomic::{AtomicBool, Ordering};
#[cfg(not(target_arch = "wasm32"))]
use std::time::Instant;
use std::{collections::HashMap, ops::Deref, sync::Arc};
use url::Url;
#[cfg(target_arch = "wasm32")]
use web_time::Instant;

// This is the NodeStorage object saved to the DB
#[derive(Debug, Serialize, Deserialize, Clone, Default, PartialEq, Eq)]
pub struct NodeStorage {
    pub nodes: HashMap<String, NodeIndex>,
    #[serde(default)]
    pub version: u32,
}

// This is the NodeIndex reference that is saved to the DB
#[derive(Debug, Serialize, Deserialize, PartialEq, Eq, Clone, Default)]
pub struct NodeIndex {
    pub child_index: u32,
    #[serde(deserialize_with = "deserialize_lsp_config")]
    pub lsp: Option<LspConfig>,
    pub archived: Option<bool>,
}

impl NodeIndex {
    pub fn is_archived(&self) -> bool {
        self.archived.unwrap_or(false)
    }
}

// This is the NodeIdentity that refer to a specific node
// Used for public facing identification.
pub struct NodeIdentity {
    pub uuid: String,
    pub pubkey: PublicKey,
}

#[derive(Serialize, Clone, Eq, PartialEq)]
pub struct MutinyBip21RawMaterials {
    pub address: Address,
    pub invoice: Option<Bolt11Invoice>,
    pub btc_amount: Option<String>,
    pub labels: Vec<String>,
}

#[derive(Serialize, Deserialize, Clone, Eq, PartialEq)]
pub struct MutinyPeer {
    pub pubkey: PublicKey,
    pub connection_string: Option<String>,
    pub alias: Option<String>,
    pub color: Option<String>,
    pub label: Option<String>,
    pub is_connected: bool,
}

impl PartialOrd for MutinyPeer {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for MutinyPeer {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        self.is_connected
            .cmp(&other.is_connected)
            .then_with(|| self.alias.cmp(&other.alias))
            .then_with(|| self.pubkey.cmp(&other.pubkey))
            .then_with(|| self.connection_string.cmp(&other.connection_string))
    }
}

#[derive(Serialize, Deserialize, Clone, Eq, PartialEq)]
pub struct MutinyChannel {
    pub user_chan_id: String,
    pub balance: u64,
    pub size: u64,
    pub reserve: u64,
    pub inbound: u64,
    pub outpoint: Option<OutPoint>,
    pub peer: PublicKey,
    pub confirmations_required: Option<u32>,
    pub confirmations: u32,
    pub is_outbound: bool,
    pub is_usable: bool,
    pub is_anchor: bool,
    pub force_close_spend_delay: Option<u16>,
}

impl From<&ChannelDetails> for MutinyChannel {
    fn from(c: &ChannelDetails) -> Self {
        let size = c.channel_value_satoshis;
        let balance = c.next_outbound_htlc_limit_msat / 1_000;
        let inbound = c.inbound_capacity_msat / 1_000;

        // Don't calculate reserve, just make it what we didn't
        // account for in balance and inbound
        let reserve = size - (balance + inbound);

        let is_anchor = c
            .channel_type
            .as_ref()
            .map(|t| t.supports_anchors_zero_fee_htlc_tx())
            .unwrap_or(false);

        MutinyChannel {
            user_chan_id: c.user_channel_id.to_be_bytes().to_lower_hex_string(),
            balance,
            size,
            reserve,
            inbound,
            outpoint: c.funding_txo.map(|f| f.into_bitcoin_outpoint()),
            peer: c.counterparty.node_id,
            confirmations_required: c.confirmations_required,
            confirmations: c.confirmations.unwrap_or(0),
            is_outbound: c.is_outbound,
            is_usable: c.is_usable,
            is_anchor,
            force_close_spend_delay: c.force_close_spend_delay,
        }
    }
}

/// Information about a channel that was closed.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq, Eq, Hash)]
pub struct ChannelClosure {
    pub user_channel_id: Option<[u8; 16]>,
    pub channel_id: Option<[u8; 32]>,
    pub node_id: Option<PublicKey>,
    pub reason: String,
    pub timestamp: u64,
    #[serde(default)]
    pub channel_funding_txo: Option<OutPoint>,
    pub force_close_spend_delay: Option<u16>,
}

impl ChannelClosure {
    pub fn new(
        user_channel_id: u128,
        channel_id: ChannelId,
        channel_funding_txo: Option<lightning::chain::transaction::OutPoint>,
        node_id: Option<PublicKey>,
        reason: ClosureReason,
    ) -> Self {
        let channel_funding_txo =
            channel_funding_txo.map(|txo| OutPoint::new(txo.txid, txo.index.into()));
        Self {
            user_channel_id: Some(user_channel_id.to_be_bytes()),
            channel_id: Some(channel_id.0),
            channel_funding_txo,
            node_id,
            reason: reason.to_string(),
            timestamp: utils::now().as_secs(),
            force_close_spend_delay: None,
        }
    }

    pub fn new_placeholder(
        user_channel_id: u128,
        channel_id: ChannelId,
        channel_funding_txo: OutPoint,
        node_id: PublicKey,
        force_close_spend_delay: Option<u16>,
    ) -> Self {
        Self {
            user_channel_id: Some(user_channel_id.to_be_bytes()),
            channel_id: Some(channel_id.0),
            channel_funding_txo: Some(channel_funding_txo),
            node_id: Some(node_id),
            reason: "".to_string(),
            timestamp: 0, // Ensure that the real timestamp is used to update vss when the channel is shut down
            force_close_spend_delay,
        }
    }

    pub(crate) fn set_user_channel_id_from_key(&mut self, key: &str) -> Result<(), MutinyError> {
        if self.user_channel_id.is_some() {
            return Ok(());
        }

        // convert keys to u128
        let user_channel_id_str = key
            .trim_start_matches(CHANNEL_CLOSURE_PREFIX)
            .splitn(2, '_') // Channel closures have `_{node_id}` at the end
            .collect::<Vec<&str>>()[0];
        let user_channel_id: [u8; 16] = FromHex::from_hex(user_channel_id_str)?;
        self.user_channel_id = Some(user_channel_id);

        Ok(())
    }

    pub fn set_force_close_spend_delay(&mut self, delay: Option<u16>) {
        if self.force_close_spend_delay.is_some() {
            return;
        }

        self.force_close_spend_delay = delay;
    }
}

impl PartialOrd for ChannelClosure {
    fn partial_cmp(&self, other: &Self) -> Option<core::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for ChannelClosure {
    fn cmp(&self, other: &Self) -> core::cmp::Ordering {
        self.timestamp.cmp(&other.timestamp)
    }
}

pub struct NodeBalance {
    pub confirmed: u64,
    pub unconfirmed: u64,
    pub lightning: u64,
    pub closing: u64,
}

pub struct NodeManagerBuilder<S: MutinyStorage> {
    xprivkey: Xpriv,
    storage: S,
    esplora: Option<Arc<AsyncClient>>,
    config: Option<MutinyWalletConfig>,
    stop: Option<Arc<AtomicBool>>,
    logger: Option<Arc<MutinyLogger>>,
    ln_event_callback: Option<CommonLnEventCallback>,
}

impl<S: MutinyStorage> NodeManagerBuilder<S> {
    pub fn new(xprivkey: Xpriv, storage: S) -> NodeManagerBuilder<S> {
        NodeManagerBuilder::<S> {
            xprivkey,
            storage,
            esplora: None,
            config: None,
            stop: None,
            logger: None,
            ln_event_callback: None,
        }
    }

    pub fn with_config(mut self, config: MutinyWalletConfig) -> NodeManagerBuilder<S> {
        self.config = Some(config);
        self
    }

    pub fn with_stop(&mut self, stop: Arc<AtomicBool>) {
        self.stop = Some(stop);
    }

    pub fn with_esplora(&mut self, esplora: Arc<AsyncClient>) {
        self.esplora = Some(esplora);
    }

    pub fn with_ln_event_callback(&mut self, cb: CommonLnEventCallback) {
        self.ln_event_callback = Some(cb);
    }

    pub fn with_logger(&mut self, logger: Arc<MutinyLogger>) {
        self.logger = Some(logger);
    }

    /// Creates a new [NodeManager] with the given parameters.
    /// The mnemonic seed is read from storage, unless one is provided.
    /// If no mnemonic is provided, a new one is generated and stored.
    pub async fn build(self) -> Result<NodeManager<S>, MutinyError> {
        // config is required
        let c = self
            .config
            .map_or_else(|| Err(MutinyError::InvalidArgumentsError), Ok)?;
        let logger = self.logger.unwrap_or(Arc::new(MutinyLogger::default()));
        let stop = self.stop.unwrap_or(Arc::new(AtomicBool::new(false)));
        let esplora = if let Some(e) = self.esplora {
            e
        } else {
            let esplora_server_url = get_esplora_url(c.network, c.user_esplora_url);
            let esplora = Builder::new(&esplora_server_url).build_async()?;
            Arc::new(esplora)
        };

        #[cfg(target_arch = "wasm32")]
        let websocket_proxy_addr = c
            .websocket_proxy_addr
            .unwrap_or_else(|| String::from("wss://p.mutinywallet.com"));

        let start = Instant::now();
        log_info!(logger, "Building node manager components");

        log_trace!(logger, "creating tx sync client");
        let tx_sync = Arc::new(EsploraSyncClient::from_client(
            esplora.as_ref().clone(),
            logger.clone(),
        ));
        log_trace!(logger, "finished creating tx sync client");

        log_trace!(logger, "creating fee estimator");
        let fee_estimator = Arc::new(MutinyFeeEstimator::new(
            self.storage.clone(),
            esplora.clone(),
            logger.clone(),
        ));
        log_trace!(logger, "finished creating fee estimator");

        log_trace!(logger, "creating on chain wallet");
        let wallet = Arc::new(OnChainWallet::new(
            self.xprivkey,
            self.storage.clone(),
            c.network,
            esplora.clone(),
            fee_estimator.clone(),
            stop.clone(),
            logger.clone(),
            self.ln_event_callback.clone(),
        )?);
        log_trace!(logger, "finished creating on chain wallet");

        log_trace!(logger, "creating chain");
        let chain = Arc::new(MutinyChain::new(tx_sync, wallet.clone(), logger.clone()));
        log_trace!(logger, "finished creating chain");

        log_trace!(logger, "creating gossip sync");
        let (gossip_sync, scorer) =
            get_gossip_sync(&self.storage, c.network, logger.clone()).await?;
        log_trace!(logger, "finished creating gossip sync");

        log_trace!(logger, "creating scorer");
        let scorer = Arc::new(utils::Mutex::new(scorer));
        log_trace!(logger, "finished creating scorer");

        let gossip_sync = Arc::new(gossip_sync);

        log_trace!(logger, "creating lsp config");
        let lsp_config = if c.safe_mode {
            None
        } else {
            create_lsp_config(c.lsp_url, c.lsp_connection_string, c.lsp_token).unwrap_or_else(
                |_| {
                    log_warn!(
                        logger,
                        "Failed to create lsp config, falling back to no LSP configured"
                    );
                    None
                },
            )
        };
        log_trace!(logger, "finished creating lsp config");

        log_trace!(logger, "getting nodes from storage");
        let node_storage = self.storage.get_nodes()?;
        log_trace!(logger, "finished getting nodes from storage");

        log_trace!(
            logger,
            "Node manager Components built: took {}ms",
            start.elapsed().as_millis()
        );

        let has_done_initial_ldk_sync = Arc::new(AtomicBool::new(false));

        let nodes = if c.safe_mode {
            // If safe mode is enabled, we don't start any nodes
            log_warn!(logger, "Safe mode enabled, not starting any nodes");
            Arc::new(RwLock::new(HashMap::new()))
        } else {
            log_trace!(logger, "going through nodes");

            // Remove the archived nodes, we don't need to start them up.
            let unarchived_nodes = node_storage
                .clone()
                .nodes
                .into_iter()
                .filter(|(_, n)| !n.is_archived());

            let start = Instant::now();
            log_debug!(logger, "Building nodes");

            let mut nodes_map = HashMap::new();

            for node_item in unarchived_nodes {
                let mut node_builder = NodeBuilder::new(self.xprivkey, self.storage.clone())
                    .with_uuid(node_item.0)
                    .with_node_index(node_item.1)
                    .with_gossip_sync(gossip_sync.clone())
                    .with_scorer(scorer.clone())
                    .with_chain(chain.clone())
                    .with_fee_estimator(fee_estimator.clone())
                    .with_wallet(wallet.clone())
                    .with_esplora(esplora.clone())
                    .with_initial_sync(has_done_initial_ldk_sync.clone())
                    .with_network(c.network);
                node_builder.with_logger(logger.clone());

                #[cfg(target_arch = "wasm32")]
                node_builder.with_websocket_proxy_addr(websocket_proxy_addr.clone());

                if let Some(l) = lsp_config.clone() {
                    node_builder.with_lsp_config(l);
                }
                if let Some(cb) = self.ln_event_callback.clone() {
                    node_builder.with_ln_event_callback(cb);
                }
                if c.do_not_connect_peers {
                    node_builder.do_not_connect_peers();
                }

                if c.do_not_bump_channel_close_tx {
                    node_builder.do_not_bump_channel_close_tx();
                }

                if let Some(ref address) = c.sweep_target_address {
                    node_builder.with_sweep_target_address(address.clone());
                }

                let node = node_builder.build().await?;

                let id = node
                    .keys_manager
                    .get_node_id(Recipient::Node)
                    .expect("Failed to get node id");

                nodes_map.insert(id, Arc::new(node));
            }
            log_trace!(
                logger,
                "Nodes built: took {}ms",
                start.elapsed().as_millis()
            );

            // when we create the nodes we set the LSP if one is missing
            // we need to save it to local storage after startup in case
            // a LSP was set.
            let mut updated_nodes: HashMap<String, NodeIndex> =
                HashMap::with_capacity(nodes_map.len());
            for n in nodes_map.values() {
                updated_nodes.insert(n.uuid.clone(), n.node_index().await);
            }

            // insert updated nodes in background, isn't a huge deal if this fails,
            // it is only for updating the LSP config
            log_info!(logger, "inserting updated nodes");
            let version = node_storage.version + 1;
            let storage = self.storage.clone();
            let logger_clone = logger.clone();
            {
                let start = Instant::now();
                if let Err(e) = storage.insert_nodes(&NodeStorage {
                    nodes: updated_nodes,
                    version,
                }) {
                    log_error!(logger_clone, "Failed to insert updated nodes: {e}");
                } else {
                    log_info!(
                        logger_clone,
                        "inserted updated nodes, took {}ms",
                        start.elapsed().as_millis()
                    );
                }
            };

            Arc::new(RwLock::new(nodes_map))
        };

        let nm = NodeManager {
            stop,
            xprivkey: self.xprivkey,
            network: c.network,
            wallet,
            gossip_sync,
            scorer,
            chain,
            fee_estimator,
            storage: self.storage,
            node_storage: RwLock::new(node_storage),
            nodes,
            #[cfg(target_arch = "wasm32")]
            websocket_proxy_addr,
            user_rgs_url: c.user_rgs_url,
            esplora,
            ln_event_callback: self.ln_event_callback,
            lsp_config,
            logger,
            do_not_connect_peers: c.do_not_connect_peers,
            do_not_bump_channel_close_tx: c.do_not_bump_channel_close_tx,
            sweep_target_address: c.sweep_target_address,
            safe_mode: c.safe_mode,
            has_done_initial_ldk_sync,
        };

        Ok(nm)
    }
}

/// The [NodeManager] is the main entry point for interacting with the Mutiny Wallet.
/// It is responsible for managing the on-chain wallet and the lightning nodes.
///
/// It can be used to create a new wallet, or to load an existing wallet.
///
/// It can be configured to use all different custom backend services, or to use the default
/// services provided by Mutiny.
pub struct NodeManager<S: MutinyStorage> {
    pub(crate) stop: Arc<AtomicBool>,
    pub(crate) xprivkey: Xpriv,
    network: Network,
    #[cfg(target_arch = "wasm32")]
    websocket_proxy_addr: String,
    user_rgs_url: Option<String>,
    esplora: Arc<AsyncClient>,
    ln_event_callback: Option<CommonLnEventCallback>,
    pub(crate) wallet: Arc<OnChainWallet<S>>,
    gossip_sync: Arc<RapidGossipSync>,
    scorer: Arc<utils::Mutex<HubPreferentialScorer>>,
    chain: Arc<MutinyChain<S>>,
    fee_estimator: Arc<MutinyFeeEstimator<S>>,
    pub(crate) storage: S,
    pub(crate) node_storage: RwLock<NodeStorage>,
    pub(crate) nodes: Arc<RwLock<HashMap<PublicKey, Arc<Node<S>>>>>,
    pub(crate) lsp_config: Option<LspConfig>,
    pub(crate) logger: Arc<MutinyLogger>,
    do_not_connect_peers: bool,
    do_not_bump_channel_close_tx: bool,
    sweep_target_address: Option<Address>,
    pub safe_mode: bool,
    /// If we've completed an initial sync this instance
    pub(crate) has_done_initial_ldk_sync: Arc<AtomicBool>,
}

impl<S: MutinyStorage> NodeManager<S> {
    /// Returns if there is a saved wallet in storage.
    /// This is checked by seeing if a mnemonic seed exists in storage.
    pub fn has_node_manager(storage: S) -> bool {
        storage.get_mnemonic().is_ok_and(|x| x.is_some())
    }

    // New function to get a node by PublicKey or return the first node
    pub(crate) async fn get_node_by_key_or_first(
        &self,
        pk: Option<&PublicKey>,
    ) -> Result<Arc<Node<S>>, MutinyError> {
        log_trace!(self.logger, "calling get_node_by_key_or_first");

        let nodes = self.nodes.read().await;
        let node = match pk {
            Some(pubkey) => nodes.get(pubkey),
            None => nodes.iter().next().map(|(_, node)| node),
        };
        let res = node.cloned().ok_or(MutinyError::NotFound);
        log_trace!(self.logger, "finished calling get_node_by_key_or_first");

        res
    }

    /// Stops all of the nodes and background processes.
    /// Returns after node has been stopped.
    pub async fn stop(&self) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling stop");

        self.stop.swap(true, Ordering::Relaxed);
        let mut nodes = self.nodes.write().await;
        let node_futures = nodes.iter().map(|(_, n)| async {
            match n.stop().await {
                Ok(_) => {
                    log_debug!(self.logger, "stopped node: {}", n.pubkey)
                }
                Err(e) => {
                    log_error!(self.logger, "failed to stop node {}: {e}", n.pubkey)
                }
            }
        });
        log_debug!(self.logger, "stopping all nodes");
        join_all(node_futures).await;
        nodes.clear();
        log_debug!(self.logger, "finished calling stop");

        Ok(())
    }

    /// Creates a background process that will sync the wallet with the blockchain.
    /// This will also update the fee estimates every 10 minutes.
    pub fn start_sync(nm: Arc<NodeManager<S>>) {
        log_trace!(nm.logger, "calling start_sync");

        // sync every second on regtest, this makes testing easier
        let sync_interval_secs = match nm.network {
            Network::Bitcoin | Network::Testnet | Network::Signet => 60,
            Network::Regtest => 1,
            net => unreachable!("Unknown network: {net}"),
        };
        utils::spawn(async move {
            let mut synced = false;
            loop {
                // If we are stopped, don't sync
                if nm.stop.load(Ordering::Relaxed) {
                    return;
                }

                if !synced {
                    if let Err(e) = nm.sync_rgs().await {
                        log_error!(nm.logger, "Failed to sync RGS: {e}");
                    } else {
                        log_info!(nm.logger, "RGS Synced!");
                    }

                    if let Err(e) = nm.sync_scorer().await {
                        log_error!(nm.logger, "Failed to sync scorer: {e}");
                    } else {
                        log_info!(nm.logger, "Scorer Synced!");
                    }
                }

                // we don't need to re-sync fees every time
                // just do it every 10 minutes
                if let Err(e) = nm.fee_estimator.update_fee_estimates_if_necessary().await {
                    log_error!(nm.logger, "Failed to update fee estimates: {e}");
                } else {
                    log_info!(nm.logger, "Updated fee estimates!");
                }

                if let Err(e) = nm.sync().await {
                    log_error!(nm.logger, "Failed to sync: {e}");
                } else if !synced {
                    // if this is the first sync, set the done_first_sync flag
                    let _ = nm.storage.set_done_first_sync();
                    synced = true;

                    if let Some(cb) = nm.ln_event_callback.as_ref() {
                        let event = CommonLnEvent::WalletFirstSynced {};
                        cb.trigger(event);
                        log_debug!(nm.logger, "Triggered WalletFirstSynced event");
                    }
                }

                // wait for next sync round, checking graceful shutdown check each second.
                for _ in 0..sync_interval_secs {
                    if nm.stop.load(Ordering::Relaxed) {
                        return;
                    }
                    sleep(1_000).await;
                }
            }
        });
    }

    /// Broadcast a transaction to the network.
    /// The transaction is broadcast through the configured esplora server.
    pub async fn broadcast_transaction(&self, tx: Transaction) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling broadcast_transaction");
        let res = self.wallet.broadcast_transaction(tx).await;
        log_trace!(self.logger, "finished calling broadcast_transaction");

        res
    }

    /// Returns the network of the wallet.
    pub fn get_network(&self) -> Network {
        self.network
    }

    /// Gets a new bitcoin address from the wallet.
    /// Will generate the last unused address in our bdk wallet.
    pub fn get_new_address(&self, labels: Vec<String>) -> Result<Address, MutinyError> {
        log_trace!(self.logger, "calling get_new_address");

        if let Ok(mut wallet) = self.wallet.wallet.try_write() {
            let address = wallet.reveal_next_address(KeychainKind::External).address;
            self.set_address_labels(address.clone(), labels)?;
            log_trace!(self.logger, "finished calling get_new_address");

            if let Some(changeset) = wallet.take_staged() {
                self.storage.write_changes(&changeset)?;
            }

            return Ok(address);
        }

        log_error!(self.logger, "Could not get wallet lock to get new address");
        Err(MutinyError::WalletOperationFailed)
    }

    /// Gets the current balance of the on-chain wallet.
    pub fn get_wallet_balance(&self) -> Result<u64, MutinyError> {
        log_trace!(self.logger, "calling get_wallet_balance");

        if let Ok(wallet) = self.wallet.wallet.try_read() {
            log_trace!(self.logger, "finished calling get_wallet_balance");
            return Ok(wallet.balance().total().to_sat());
        }

        log_error!(
            self.logger,
            "Could not get wallet lock to get wallet balance"
        );
        Err(MutinyError::WalletOperationFailed)
    }

    /// Sends an on-chain transaction to the given address.
    /// The amount is in satoshis and the fee rate is in sat/vbyte.
    ///
    /// If a fee rate is not provided, one will be used from the fee estimator.
    pub async fn send_to_address(
        &self,
        send_to: Address,
        amount: u64,
        labels: Vec<String>,
        fee_rate: Option<u64>,
    ) -> Result<Txid, MutinyError> {
        log_trace!(self.logger, "calling send_to_address");
        let res = self.wallet.send(send_to, amount, labels, fee_rate).await;
        log_trace!(self.logger, "finished calling send_to_address");

        res
    }

    /// Sweeps all the funds from the wallet to the given address.
    /// The fee rate is in sat/vbyte.
    ///
    /// If a fee rate is not provided, one will be used from the fee estimator.
    pub async fn sweep_wallet(
        &self,
        send_to: Address,
        labels: Vec<String>,
        fee_rate: Option<u64>,
        allow_dust: Option<bool>,
    ) -> Result<Txid, MutinyError> {
        log_trace!(self.logger, "calling sweep_wallet");
        let res = self
            .wallet
            .sweep(send_to, labels, fee_rate, allow_dust)
            .await;
        log_trace!(self.logger, "calling sweep_wallet");

        res
    }

    pub fn construct_sweep_tx(
        &self,
        send_to: Address,
        fee_rate: Option<u64>,
        allow_dust: Option<bool>,
    ) -> Result<Transaction, MutinyError> {
        self.wallet
            .construct_sweep_tx(send_to.script_pubkey(), fee_rate, allow_dust)
    }

    /// Estimates the onchain fee for a transaction sending to the given address.
    /// The amount is in satoshis and the fee rate is in sat/vbyte.
    pub(crate) fn estimate_tx_fee(
        &self,
        destination_address: Address,
        amount: u64,
        fee_rate: Option<u64>,
    ) -> Result<u64, MutinyError> {
        log_trace!(self.logger, "calling estimate_tx_fee");
        let res =
            self.wallet
                .estimate_tx_fee(destination_address.script_pubkey(), amount, fee_rate);
        log_trace!(self.logger, "calling estimate_tx_fee");

        res
    }

    // /// Estimates the onchain fee for a transaction sweep our on-chain balance
    // /// to the given address.
    // ///
    // /// The fee rate is in sat/vbyte.
    // pub(crate) fn estimate_sweep_tx_fee(
    //     &self,
    //     destination_address: Address,
    //     fee_rate: Option<f32>,
    // ) -> Result<u64, MutinyError> {
    //     self.wallet
    //         .estimate_sweep_tx_fee(destination_address.script_pubkey(), fee_rate)
    // }

    /// Estimates the onchain fee for a opening a lightning channel.
    /// The amount is in satoshis and the fee rate is in sat/vbyte.
    pub fn estimate_channel_open_fee(
        &self,
        amount: u64,
        fee_rate: Option<u64>,
    ) -> Result<u64, MutinyError> {
        log_trace!(self.logger, "calling estimate_channel_open_fee");

        // Dummy p2wsh script for the channel output
        let script = script::Builder::new()
            .push_int(0)
            .push_slice([0; 32])
            .into_script();
        let res = self.wallet.estimate_tx_fee(script, amount, fee_rate);
        log_trace!(self.logger, "calling estimate_channel_open_fee");

        res
    }

    /// Estimates the onchain fee for sweeping our on-chain balance to open a lightning channel.
    /// The fee rate is in sat/vbyte.
    pub fn estimate_sweep_channel_open_fee(
        &self,
        fee_rate: Option<u64>,
        allow_dust: Option<bool>,
    ) -> Result<u64, MutinyError> {
        log_trace!(self.logger, "calling estimate_sweep_channel_open_fee");

        // Dummy p2wsh script for the channel output
        let script = script::Builder::new()
            .push_int(0)
            .push_slice([0; 32])
            .into_script();
        let res = self
            .wallet
            .estimate_sweep_tx_fee(script, fee_rate, allow_dust);
        log_trace!(self.logger, "calling estimate_sweep_channel_open_fee");

        res
    }

    /// Bumps the given transaction by replacing the given tx with a transaction at
    /// the new given fee rate in sats/vbyte
    pub async fn bump_fee(&self, txid: Txid, new_fee_rate: u64) -> Result<Txid, MutinyError> {
        log_trace!(self.logger, "calling bump_fee");

        // check that this is not a funding tx for any channels,
        // bumping those can cause loss of funds
        let channels = self.list_channels().await?;
        if channels
            .iter()
            .any(|c| c.outpoint.is_some_and(|t| t.txid == txid))
        {
            return Err(MutinyError::ChannelCreationFailed);
        }

        let res = self.wallet.bump_fee(txid, new_fee_rate).await;
        log_trace!(self.logger, "finished calling bump_fee");

        res
    }

    /// Checks if the given address has any transactions.
    /// If it does, it returns the details of the first transaction.
    ///
    /// This should be used to check if a payment has been made to an address.
    pub async fn check_address(
        &self,
        address: Address<NetworkUnchecked>,
    ) -> Result<Option<TransactionDetails>, MutinyError> {
        log_trace!(self.logger, "calling check_address");

        let address = address.require_network(self.network)?;
        let script = address.script_pubkey();
        let txs = self.esplora.scripthash_txs(&script, None).await?;

        let details_opt = txs.first().map(|tx| {
            let received: u64 = tx
                .vout
                .iter()
                .filter(|v| v.scriptpubkey == script)
                .map(|v| v.value)
                .sum();

            let confirmation_time = tx
                .confirmation_time()
                .map(|c| ConfirmationTime::Confirmed {
                    height: c.height,
                    time: c.timestamp,
                })
                .unwrap_or(ConfirmationTime::Unconfirmed {
                    last_seen: utils::now().as_secs(),
                });

            let address_labels = self.get_address_labels().unwrap_or_default();
            let labels = address_labels
                .get(&address.to_string())
                .cloned()
                .unwrap_or_default();

            let details = TransactionDetails {
                transaction: Some(tx.to_tx()),
                txid: Some(tx.txid),
                internal_id: tx.txid,
                received,
                sent: 0,
                fee: None,
                confirmation_time,
                labels,
            };

            let block_id = match tx.status.block_hash {
                Some(hash) => {
                    let height = tx
                        .status
                        .block_height
                        .expect("block height must be present");
                    Some(BlockId { hash, height })
                }
                None => None,
            };

            (details, block_id)
        });

        // if we found a tx we should try to import it into the wallet
        if let Some((details, block_id)) = details_opt.clone() {
            let wallet = self.wallet.clone();
            utils::spawn(async move {
                let tx = details.transaction.expect("tx must be present");
                wallet
                    .insert_tx(tx, details.confirmation_time, block_id)
                    .await
                    .expect("failed to insert tx");
            });
        }

        log_trace!(self.logger, "finished calling check_address");
        Ok(details_opt.map(|(d, _)| d))
    }

    pub(crate) async fn insert_unconfirmed_tx(
        &self,
        tx: Transaction,
        last_seen: u64,
    ) -> Result<(), MutinyError> {
        let confirmation_time = ConfirmationTime::Unconfirmed { last_seen };
        self.wallet.insert_tx(tx, confirmation_time, None).await
    }

    /// Adds labels to the TransactionDetails based on the address labels.
    /// This will panic if the TransactionDetails does not have a transaction.
    /// Make sure you flag `include_raw` when calling `list_transactions` to
    /// ensure that the transaction is included.
    fn add_onchain_labels(
        &self,
        address_labels: &HashMap<String, Vec<String>>,
        mut tx: TransactionDetails,
    ) -> TransactionDetails {
        // find the first output address that has a label
        tx.labels = tx
            .transaction
            .clone()
            .unwrap() // safe because we call with list_transactions(true)
            .output
            .iter()
            .find_map(|o| {
                if let Ok(addr) = Address::from_script(&o.script_pubkey, self.network) {
                    address_labels.get(&addr.to_string()).cloned()
                } else {
                    None
                }
            })
            .unwrap_or_default();

        tx
    }

    /// Lists all the on-chain transactions in the wallet.
    /// These are sorted by confirmation time.
    pub fn list_onchain(&self) -> Result<Vec<TransactionDetails>, MutinyError> {
        log_trace!(self.logger, "calling list_onchain");

        let mut txs = self.wallet.list_transactions(true)?;
        txs.sort();
        let address_labels = self.get_address_labels()?;
        let txs = txs
            .into_iter()
            .map(|tx| self.add_onchain_labels(&address_labels, tx))
            .collect();

        log_trace!(self.logger, "finished calling list_onchain");
        Ok(txs)
    }

    /// Gets the details of a specific on-chain transaction.
    pub fn get_transaction(&self, txid: Txid) -> Result<Option<TransactionDetails>, MutinyError> {
        log_trace!(self.logger, "calling get_transaction");

        let res = match self.wallet.get_transaction(txid)? {
            Some(tx) => {
                let address_labels = self.get_address_labels()?;
                let tx_details = self.add_onchain_labels(&address_labels, tx);
                Ok(Some(tx_details))
            }
            None => Ok(None),
        };
        log_trace!(self.logger, "finished calling get_transaction");

        res
    }

    /// Gets the current balance of the wallet.
    /// This includes both on-chain and lightning funds.
    ///
    /// This will not include any funds in an unconfirmed lightning channel.
    pub(crate) async fn get_balance(&self) -> Result<NodeBalance, MutinyError> {
        log_trace!(self.logger, "calling get_balance");

        let onchain = if let Ok(wallet) = self.wallet.wallet.try_read() {
            log_debug!(
                self.logger,
                "Calling get_balance, the tx_graph: ({:?})",
                wallet.tx_graph()
            );
            wallet.balance()
        } else {
            log_error!(self.logger, "Could not get wallet lock to get balance");
            return Err(MutinyError::WalletOperationFailed);
        };

        let nodes = self.nodes.read().await;
        let lightning_sats: u64 = nodes
            .iter()
            .flat_map(|(_, n)| n.chain_monitor.get_claimable_balances(&[]))
            .map(|b| b.claimable_amount_satoshis())
            .sum::<u64>();

        // get the amount closing
        let closing: u64 = nodes
            .iter()
            .flat_map(|(_, n)| {
                let channels = n.channel_manager.list_channels();
                let ignored_channels: Vec<&ChannelDetails> = channels.iter().collect();
                n.chain_monitor.get_claimable_balances(&ignored_channels)
            })
            .map(|b| b.claimable_amount_satoshis())
            .sum();

        log_trace!(self.logger, "finished calling get_balance");

        Ok(NodeBalance {
            confirmed: (onchain.confirmed + onchain.trusted_pending).to_sat(),
            unconfirmed: (onchain.untrusted_pending + onchain.immature).to_sat(),
            lightning: lightning_sats.saturating_sub(closing),
            closing,
        })
    }

    /// Lists all the UTXOs in the wallet.
    pub fn list_utxos(&self) -> Result<Vec<LocalOutput>, MutinyError> {
        log_trace!(self.logger, "calling list_utxos");
        let res = self.wallet.list_utxos();
        log_trace!(self.logger, "calling list_utxos");

        res
    }

    /// Syncs the lightning wallet with the blockchain.
    /// This will update the wallet with any lightning channels
    /// that have been opened or closed.
    ///
    /// This should be called before syncing the on-chain wallet
    /// to ensure that new on-chain transactions are picked up.
    async fn sync_ldk(&self) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling sync_ldk");

        // get nodes hashmap, immediately drop lock because sync can take a while
        let nodes = {
            let nodes = self.nodes.read().await;
            nodes.deref().clone()
        };

        // Lock all the nodes so we can sync them, make sure we keep the locks
        // in scope so they don't get dropped and unlocked.
        let futs = nodes
            .values()
            .map(|node| node.sync_lock.lock())
            .collect::<Vec<_>>();
        let _locks = join_all(futs).await;

        let confirmables: Vec<&(dyn Confirm + Send + Sync)> = nodes
            .iter()
            .flat_map(|(_, node)| {
                let vec: Vec<&(dyn Confirm + Send + Sync)> =
                    vec![node.channel_manager.deref(), node.chain_monitor.deref()];
                vec
            })
            .collect();

        self.chain
            .tx_sync
            .sync(confirmables)
            .await
            .map_err(|_e| MutinyError::ChainAccessFailed)?;

        log_trace!(self.logger, "finished calling sync_ldk");
        Ok(())
    }

    /// Syncs the rapid gossip sync data.
    /// Will be skipped if in safe mode.
    async fn sync_rgs(&self) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling sync_rgs");

        // Skip syncing RGS if we are in safe mode.
        if self.safe_mode {
            log_info!(self.logger, "Skipping rgs sync in safe mode");
        } else {
            let last_rgs_sync_timestamp = self
                .gossip_sync
                .network_graph()
                .get_last_rapid_gossip_sync_timestamp();

            if let Some(rgs_url) = get_rgs_url(
                self.network,
                self.user_rgs_url.as_deref(),
                last_rgs_sync_timestamp,
            ) {
                log_info!(self.logger, "RGS URL: {rgs_url}");

                let now = utils::now().as_secs();
                fetch_updated_gossip(
                    rgs_url,
                    now,
                    last_rgs_sync_timestamp.unwrap_or_default(),
                    &self.gossip_sync,
                    &self.storage,
                    &self.logger,
                )
                .await?;
            }
        }

        log_trace!(self.logger, "finished calling sync_rgs");
        Ok(())
    }

    /// Downloads the latest score data from the server and replaces the current scorer.
    /// Will be skipped if in safe mode.
    async fn sync_scorer(&self) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling sync_scorer");

        // Skip syncing scorer if we are in safe mode.
        if self.safe_mode {
            log_info!(self.logger, "Skipping scorer sync in safe mode");
            return Ok(());
        }

        // if let (Some(auth), Some(url)) = (self.auth_client.as_ref(), self.scorer_url.as_deref()) {
        //     let scorer = get_remote_scorer(
        //         auth,
        //         url,
        //         self.gossip_sync.network_graph().clone(),
        //         self.logger.clone(),
        //     )
        //     .await
        //     .map_err(|e| {
        //         log_error!(self.logger, "Failed to sync scorer: {e}");
        //         e
        //     })?;

        //     // Replace the current scorer with the new one
        //     let mut lock = self
        //         .scorer
        //         .try_lock()
        //         .map_err(|_| MutinyError::WalletSyncError)?;
        //     *lock = scorer;
        // }

        log_trace!(self.logger, "finished calling sync_scorer");
        Ok(())
    }

    /// Syncs the on-chain wallet and lightning wallet.
    /// This will update the on-chain wallet with any new
    /// transactions and update the lightning wallet with
    /// any channels that have been opened or closed.
    async fn sync(&self) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling sync");

        // If we are stopped, don't sync
        if self.stop.load(Ordering::Relaxed) {
            return Ok(());
        }

        // Sync ldk first because it may broadcast transactions
        // to addresses that are in our bdk wallet. This way
        // they are found on this iteration of syncing instead
        // of the next one.
        // Skip if we are in safe mode.
        if self.safe_mode {
            log_info!(self.logger, "Skipping ldk sync in safe mode");
        } else if let Err(e) = self.sync_ldk().await {
            log_error!(self.logger, "Failed to sync ldk: {e}");
            return Err(e);
        }

        // set has synced to true
        self.has_done_initial_ldk_sync.swap(true, Ordering::SeqCst);

        // sync bdk wallet
        let res = match self.wallet.sync().await {
            Ok(()) => Ok(log_info!(self.logger, "We are synced!")),
            Err(e) => {
                log_error!(self.logger, "Failed to sync on-chain wallet: {e}");
                Err(e)
            }
        };
        log_trace!(self.logger, "finished calling sync");

        res
    }

    /// Gets a fee estimate for a very low priority transaction.
    /// Value is in sat/vbyte.
    pub fn estimate_fee_low(&self) -> u32 {
        log_trace!(self.logger, "calling estimate_fee_low");
        let res = max(self.fee_estimator.get_low_fee_rate() / 250, 1);
        log_trace!(self.logger, "finished calling estimate_fee_low");

        res
    }

    /// Gets a fee estimate for an average priority transaction.
    /// Value is in sat/vbyte.
    pub fn estimate_fee_normal(&self) -> u32 {
        log_trace!(self.logger, "calling estimate_fee_normal");
        let res = max(self.fee_estimator.get_normal_fee_rate() / 250, 1);
        log_trace!(self.logger, "finished calling estimate_fee_normal");

        res
    }

    /// Gets a fee estimate for an high priority transaction.
    /// Value is in sat/vbyte.
    pub fn estimate_fee_high(&self) -> u32 {
        log_trace!(self.logger, "calling estimate_fee_high");
        let res = max(self.fee_estimator.get_high_fee_rate() / 250, 1);
        log_trace!(self.logger, "finished calling estimate_fee_high");

        res
    }

    /// Creates a new lightning node and adds it to the manager.
    pub async fn new_node(&self) -> Result<NodeIdentity, MutinyError> {
        log_trace!(self.logger, "calling new_node");
        if self.safe_mode {
            return Err(MutinyError::NotRunning);
        }

        let res = create_new_node_from_node_manager(self).await;
        log_trace!(self.logger, "finished calling new_node");

        res
    }

    /// Archives a node so it will not be started up next time the node manager is created.
    ///
    /// If the node has any active channels it will fail to archive
    #[allow(dead_code)]
    pub(crate) async fn archive_node(&self, pubkey: PublicKey) -> Result<(), MutinyError> {
        if let Some(node) = self.nodes.read().await.get(&pubkey) {
            // disallow archiving nodes with active channels or
            // claimable on-chain funds, so we don't lose funds
            if node.channel_manager.list_channels().is_empty()
                && node.chain_monitor.get_claimable_balances(&[]).is_empty()
            {
                self.archive_node_by_uuid(node.uuid.clone()).await
            } else {
                Err(anyhow!("Node has active channels, cannot archive").into())
            }
        } else {
            Err(anyhow!("Could not find node to archive").into())
        }
    }

    /// Archives a node so it will not be started up next time the node manager is created.
    ///
    /// If the node has any active channels it will fail to archive
    #[allow(dead_code)]
    pub(crate) async fn archive_node_by_uuid(&self, node_uuid: String) -> Result<(), MutinyError> {
        let mut node_storage = self.node_storage.write().await;

        match node_storage.nodes.get(&node_uuid).map(|n| n.to_owned()) {
            None => Err(anyhow!("Could not find node to archive").into()),
            Some(mut node) => {
                node.archived = Some(true);
                let prev = node_storage.nodes.insert(node_uuid, node);

                // Check that we did override the previous node index
                debug_assert!(prev.is_some());

                Ok(())
            }
        }
    }

    /// Lists the pubkeys of the lightning node in the manager.
    pub async fn list_nodes(&self) -> Result<Vec<PublicKey>, MutinyError> {
        log_trace!(self.logger, "calling list_nodes");

        let nodes = self.nodes.read().await;
        let peers = nodes.iter().map(|(_, n)| n.pubkey).collect();

        log_trace!(self.logger, "finished calling list_nodes");
        Ok(peers)
    }

    pub async fn get_configured_lsp(&self) -> Result<Option<LspConfig>, MutinyError> {
        let node = self.get_node_by_key_or_first(None).await?;
        Ok(node.node_index().await.lsp)
    }

    /// Changes all the node's LSPs to the given config. If any of the nodes have an active channel with the
    /// current LSP, it will fail to change the LSP.
    ///
    /// Requires a restart of the node manager to take effect.
    pub async fn change_lsp(&self, mut lsp_config: Option<LspConfig>) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling change_lsp");

        // if we are in safe mode we don't load the lightning state so we can't know if it is safe to change the LSP.
        if self.safe_mode {
            return Err(MutinyError::NotRunning);
        }

        // verify that the LSP config is valid
        match lsp_config.as_mut() {
            Some(LspConfig::VoltageFlow(config)) => {
                let http_client = Client::new();

                // try to connect to the LSP, update the config if successful
                let (pk, str) = voltage::LspClient::fetch_connection_info(
                    &http_client,
                    &config.url,
                    &self.logger,
                )
                .await?;
                config.pubkey = Some(pk);
                config.connection_string = Some(str);
            }
            Some(LspConfig::Lsps(config)) => {
                // make sure a valid connection string was provided
                PubkeyConnectionInfo::new(&config.connection_string)?;
            }
            None => {} // Nothing to verify
        }

        // edit node storage
        let mut node_storage = self.node_storage.write().await;
        node_storage.nodes.iter_mut().for_each(|(_, n)| {
            n.lsp = lsp_config.clone();
        });
        node_storage.version += 1; // update version for VSS

        // save updated lsp to storage
        self.storage.insert_nodes(&node_storage)?;
        log_trace!(self.logger, "finished calling change_lsp");

        Ok(())
    }

    /// Attempts to connect to a peer using either a specified node or the first available node.
    pub async fn connect_to_peer(
        &self,
        self_node_pubkey: Option<&PublicKey>,
        connection_string: &str,
        label: Option<String>,
    ) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling connect_to_peer");

        let node = self.get_node_by_key_or_first(self_node_pubkey).await?;
        let connect_info = PubkeyConnectionInfo::new(connection_string)?;
        let label_opt = label.filter(|s| !s.is_empty()); // filter out empty strings
        let res = node.connect_peer(connect_info, label_opt).await;

        log_trace!(self.logger, "finished calling connect_to_peer");
        match res {
            Ok(_) => {
                log_info!(self.logger, "Connected to peer: {connection_string}");
                Ok(())
            }
            Err(e) => {
                log_error!(
                    self.logger,
                    "Could not connect to peer: {connection_string} - {e}"
                );
                Err(e)
            }
        }
    }

    /// Disconnects from a peer using either a specified node or the first available node.
    pub async fn disconnect_peer(
        &self,
        self_node_pubkey: Option<&PublicKey>,
        peer: PublicKey,
    ) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling disconnect_peer");

        let node = self.get_node_by_key_or_first(self_node_pubkey).await?;
        node.disconnect_peer(peer);
        log_trace!(self.logger, "finished calling disconnect_peer");

        Ok(())
    }

    /// Deletes a peer from either a specified node or the first available node.
    /// This will prevent the node from attempting to reconnect to the peer.
    pub async fn delete_peer(
        &self,
        self_node_pubkey: Option<&PublicKey>,
        peer: &NodeId,
    ) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling delete_peer");

        let node = self.get_node_by_key_or_first(self_node_pubkey).await?;
        gossip::delete_peer_info(&self.storage, &node.uuid, peer)?;
        log_trace!(self.logger, "finished calling delete_peer");

        Ok(())
    }

    /// Sets the label of a peer from the selected node.
    pub fn label_peer(&self, node_id: &NodeId, label: Option<String>) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling label_peer");
        gossip::set_peer_label(&self.storage, node_id, label)?;
        log_trace!(self.logger, "finished calling label_peer");

        Ok(())
    }

    // all values in sats

    /// Creates a lightning invoice. The amount should be in satoshis.
    /// If no description is provided, the invoice will be created with no description.
    ///
    /// If the manager has more than one node it will create a phantom invoice.
    /// If there is only one node it will create an invoice just for that node.
    pub async fn create_invoice(
        &self,
        amount: Option<u64>,
        labels: Vec<String>,
        expiry_delta_secs: Option<u32>,
    ) -> Result<(MutinyInvoice, u64), MutinyError> {
        log_trace!(self.logger, "calling create_invoice");

        let nodes = self.nodes.read().await;
        let use_phantom = nodes.len() > 1 && self.lsp_config.is_none();
        if nodes.len() == 0 {
            return Err(MutinyError::InvoiceCreationFailed);
        }
        let route_hints: Option<Vec<PhantomRouteHints>> = if use_phantom {
            Some(
                nodes
                    .iter()
                    .map(|(_, n)| n.get_phantom_route_hint())
                    .collect(),
            )
        } else {
            None
        };

        // just create a normal invoice from the first node
        let first_node = if let Some(node) = nodes.values().next() {
            node
        } else {
            return Err(MutinyError::WalletOperationFailed);
        };
        let invoice = first_node
            .create_invoice(amount, route_hints, labels, expiry_delta_secs)
            .await?;
        log_trace!(self.logger, "finished calling create_invoice");

        Ok((invoice.0.into(), invoice.1))
    }

    /// Gets the LSP fee for receiving an invoice down the first node that exists.
    /// This could include the fee if a channel open is necessary. Otherwise the fee
    /// will be low or non-existant.
    pub async fn get_lsp_fee(&self, amount: u64) -> Result<u64, MutinyError> {
        log_trace!(self.logger, "calling get_lsp_fee");

        let node = self.get_node_by_key_or_first(None).await?;
        let res = node.get_lsp_fee(amount).await;

        log_trace!(self.logger, "finished calling get_lsp_fee");

        res
    }

    /// Pays a lightning invoice from either a specified node or the first available node.
    /// An amount should only be provided if the invoice does not have an amount.
    /// The amount should be in satoshis.
    pub(crate) async fn pay_invoice(
        &self,
        self_node_pubkey: Option<&PublicKey>,
        invoice: &Bolt11Invoice,
        amt_sats: Option<u64>,
        labels: Vec<String>,
    ) -> Result<MutinyInvoice, MutinyError> {
        log_trace!(self.logger, "calling pay_invoice");

        let node = self.get_node_by_key_or_first(self_node_pubkey).await?;
        let res = node
            .pay_invoice_with_timeout(invoice, amt_sats, None, labels)
            .await;
        log_trace!(self.logger, "finished calling pay_invoice");

        res
    }

    /// Sends a spontaneous payment to a node from either a specified node or the first available node.
    /// The amount should be in satoshis.
    pub async fn keysend(
        &self,
        self_node_pubkey: Option<&PublicKey>,
        to_node: PublicKey,
        amt_sats: u64,
        message: Option<String>,
        labels: Vec<String>,
    ) -> Result<MutinyInvoice, MutinyError> {
        log_trace!(self.logger, "calling keysend");

        let node = self.get_node_by_key_or_first(self_node_pubkey).await?;
        log_debug!(self.logger, "Keysending to {to_node}");
        let res = node
            .keysend_with_timeout(to_node, amt_sats, message, labels, None)
            .await;
        log_trace!(self.logger, "finished calling keysend");

        res
    }

    pub async fn get_channel_closure(
        &self,
        user_channel_id: u128,
    ) -> Result<ChannelClosure, MutinyError> {
        log_trace!(self.logger, "calling get_channel_closure");

        let nodes = self.nodes.read().await;
        for (_, node) in nodes.iter() {
            if let Ok(Some(closure)) = node.get_channel_closure(user_channel_id) {
                log_trace!(self.logger, "finished calling get_channel_closure");
                return Ok(closure);
            }
        }

        log_trace!(self.logger, "finished calling get_channel_closure");
        Err(MutinyError::NotFound)
    }

    pub async fn list_channel_closures(&self) -> Result<Vec<ChannelClosure>, MutinyError> {
        log_trace!(self.logger, "calling list_channel_closures");

        let mut channels: Vec<ChannelClosure> = vec![];
        let nodes = self.nodes.read().await;
        for (_, node) in nodes.iter() {
            if let Ok(mut invs) = node.get_channel_closures() {
                channels.append(&mut invs)
            }
        }

        log_trace!(self.logger, "finished calling list_channel_closures");
        Ok(channels)
    }

    /// Opens a channel from either a specified node or the first available node to the given pubkey.
    /// The amount is in satoshis.
    ///
    /// The node must be online and have a connection to the peer.
    /// The wallet must have enough funds to open the channel.
    pub async fn open_channel(
        &self,
        self_node_pubkey: Option<&PublicKey>,
        to_pubkey: Option<PublicKey>,
        amount: u64,
        fee_rate: Option<u64>,
        user_channel_id: Option<u128>,
    ) -> Result<MutinyChannel, MutinyError> {
        log_trace!(self.logger, "calling open_channel");

        let node = self.get_node_by_key_or_first(self_node_pubkey).await?;
        let to_pubkey = match to_pubkey {
            Some(pubkey) => pubkey,
            None => {
                node.lsp_client
                    .as_ref()
                    .ok_or(MutinyError::PubkeyInvalid)?
                    .get_lsp_pubkey()
                    .await
            }
        };

        let outpoint = node
            .open_channel_with_timeout(to_pubkey, amount, fee_rate, user_channel_id, 60)
            .await?;

        let all_channels = node.channel_manager.list_channels();
        let found_channel = all_channels
            .iter()
            .find(|chan| chan.funding_txo.map(|a| a.into_bitcoin_outpoint()) == Some(outpoint));

        log_trace!(self.logger, "finished calling open_channel");
        match found_channel {
            Some(channel) => Ok(channel.into()),
            None => Err(MutinyError::ChannelCreationFailed),
        }
    }

    /// Opens a channel from either a specified node or the first available node to the given pubkey.
    /// It will spend the given utxos in full to fund the channel.
    ///
    /// The node must be online and have a connection to the peer.
    /// The UTXOs must all exist in the wallet.
    pub async fn sweep_utxos_to_channel(
        &self,
        utxos: &[OutPoint],
        to_pubkey: Option<PublicKey>,
    ) -> Result<MutinyChannel, MutinyError> {
        log_trace!(self.logger, "calling sweep_utxos_to_channel");

        let node = self.get_node_by_key_or_first(None).await?;
        let to_pubkey = match to_pubkey {
            Some(pubkey) => pubkey,
            None => {
                node.lsp_client
                    .as_ref()
                    .ok_or(MutinyError::PubkeyInvalid)?
                    .get_lsp_pubkey()
                    .await
            }
        };

        let outpoint = node
            .sweep_utxos_to_channel_with_timeout(None, utxos, to_pubkey, 60)
            .await?;

        let all_channels = node.channel_manager.list_channels();
        let found_channel = all_channels
            .iter()
            .find(|chan| chan.funding_txo.map(|a| a.into_bitcoin_outpoint()) == Some(outpoint));

        log_trace!(self.logger, "finished calling sweep_utxos_to_channel");
        match found_channel {
            Some(channel) => Ok(channel.into()),
            None => Err(MutinyError::ChannelCreationFailed),
        }
    }

    /// Opens a channel from our selected node to the given pubkey.
    /// It will spend the all the on-chain utxo in full to fund the channel.
    ///
    /// The node must be online and have a connection to the peer.
    pub async fn sweep_all_to_channel(
        &self,
        to_pubkey: Option<PublicKey>,
    ) -> Result<MutinyChannel, MutinyError> {
        log_trace!(self.logger, "calling sweep_all_to_channel");

        let utxos = self
            .list_utxos()?
            .iter()
            .map(|u| u.outpoint)
            .collect::<Vec<_>>();

        let res = self.sweep_utxos_to_channel(&utxos, to_pubkey).await;
        log_trace!(self.logger, "finished calling sweep_all_to_channel");

        res
    }

    /// Closes a channel with the given outpoint.
    ///
    /// If force is true, the channel will be force closed.
    ///
    /// If abandon is true, the channel will be abandoned.
    /// This will force close without broadcasting the latest transaction.
    /// This should only be used if the channel will never actually be opened.
    ///
    /// If both force and abandon are true, an error will be returned.
    ///
    /// ldk uses background fee rate for closing channels which can be very slow
    pub async fn close_channel(
        &self,
        outpoint: &OutPoint,
        address: Option<Address>,
        force: bool,
        abandon: bool,
        target_feerate_sats_per_1000_weight: Option<u32>,
    ) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling close_channel");

        if force && abandon {
            return Err(MutinyError::ChannelClosingFailed);
        }

        let nodes = self.nodes.read().await;
        let channel_opt: Option<(Arc<Node<S>>, ChannelDetails)> =
            nodes.iter().find_map(|(_, n)| {
                n.channel_manager
                    .list_channels()
                    .iter()
                    .find(|c| c.funding_txo.map(|f| f.into_bitcoin_outpoint()) == Some(*outpoint))
                    .map(|c| (n.clone(), c.clone()))
            });

        let res = match channel_opt {
            Some((node, channel)) => {
                if force {
                    node.channel_manager
                        .force_close_broadcasting_latest_txn(
                            &channel.channel_id,
                            &channel.counterparty.node_id,
                            "user force close".to_string(),
                        )
                        .map_err(|e| {
                            log_error!(
                                self.logger,
                                "had an error force closing channel {} with node {} : {e:?}",
                                &channel.channel_id,
                                &channel.counterparty.node_id
                            );
                            MutinyError::ChannelClosingFailed
                        })?;
                } else if abandon {
                    node.channel_manager
                        .force_close_without_broadcasting_txn(
                            &channel.channel_id,
                            &channel.counterparty.node_id,
                            "Abandoned".to_string(),
                        )
                        .map_err(|e| {
                            log_error!(
                                self.logger,
                                "had an error abandoning closing channel {} with node {} : {e:?}",
                                &channel.channel_id,
                                &channel.counterparty.node_id
                            );
                            MutinyError::ChannelClosingFailed
                        })?;
                } else {
                    // convert address to ShutdownScript
                    let shutdown_script = if let Some(addr) = address {
                        Some(ShutdownScript::try_from(addr.script_pubkey())?)
                    } else {
                        None
                    };

                    // typical close tx weight
                    let close_tx_weight = 720;
                    let initiator_balance = if channel.is_outbound {
                        channel.outbound_capacity_msat / 1000
                    } else {
                        channel.inbound_capacity_msat / 1000
                    };
                    if let Some(feerate_pkw) = target_feerate_sats_per_1000_weight {
                        let estimate_fee: u64 = ((close_tx_weight * feerate_pkw) / 1000).into();
                        if estimate_fee > (initiator_balance * 8 / 10) {
                            log_warn!(
                                self.logger,
                                "close channel with feerate_pkw({feerate_pkw}) close_tx_weight({close_tx_weight}) estimate fee({estimate_fee}) is more than 80% initiator balance ({initiator_balance})",
                            );
                            return Err(MutinyError::InvalidFeerate);
                        }
                    }

                    node.channel_manager
                        .close_channel_with_feerate_and_script(
                            &channel.channel_id,
                            &channel.counterparty.node_id,
                            target_feerate_sats_per_1000_weight,
                            shutdown_script,
                        )
                        .map_err(|e| {
                            log_error!(
                                self.logger,
                                "had an error closing channel {} with node {} : {e:?}",
                                &channel.channel_id,
                                &channel.counterparty.node_id
                            );
                            MutinyError::ChannelClosingFailed
                        })?;
                }

                Ok(())
            }
            None => {
                log_error!(
                    self.logger,
                    "Channel not found with this transaction: {outpoint}",
                );
                Err(MutinyError::NotFound)
            }
        };
        log_trace!(self.logger, "finished calling close_channel");

        res
    }

    /// Lists all the channels for all the nodes in the node manager.
    pub async fn list_channels(&self) -> Result<Vec<MutinyChannel>, MutinyError> {
        log_trace!(self.logger, "calling list_channels");

        let nodes = self.nodes.read().await;
        let channels: Vec<ChannelDetails> = nodes
            .iter()
            .flat_map(|(_, n)| n.channel_manager.list_channels())
            .collect();

        let mutiny_channels: Vec<MutinyChannel> =
            channels.iter().map(MutinyChannel::from).collect();

        log_trace!(self.logger, "finished calling list_channels");
        Ok(mutiny_channels)
    }

    /// Lists all the peers for all the nodes in the node manager.
    pub async fn list_peers(&self) -> Result<Vec<MutinyPeer>, MutinyError> {
        log_trace!(self.logger, "calling list_peers");

        let peer_data = gossip::get_all_peers(&self.storage)?;

        // get peers saved in storage
        let mut storage_peers: Vec<MutinyPeer> = peer_data
            .iter()
            .map(|(node_id, metadata)| MutinyPeer {
                // node id should be safe here
                pubkey: PublicKey::from_slice(node_id.as_slice()).expect("Invalid pubkey"),
                connection_string: metadata.connection_string.clone(),
                alias: metadata.alias.clone(),
                color: metadata.color.clone(),
                label: metadata.label.clone(),
                is_connected: false,
            })
            .collect();

        let nodes = self.nodes.read().await;

        // get peers we are connected to
        let connected_peers: Vec<PublicKey> = nodes
            .iter()
            .flat_map(|(_, n)| n.peer_manager.get_peer_node_ids().into_iter())
            .collect();

        // correctly set is_connected
        for peer in &mut storage_peers {
            if connected_peers.contains(&peer.pubkey) {
                peer.is_connected = true;
            }
        }

        // add any connected peers that weren't in our storage,
        // likely new or inbound connections
        let mut missing: Vec<MutinyPeer> = Vec::new();
        for peer in connected_peers {
            if !storage_peers.iter().any(|p| p.pubkey == peer) {
                let new = MutinyPeer {
                    pubkey: peer,
                    connection_string: None,
                    alias: None,
                    color: None,
                    label: None,
                    is_connected: true,
                };
                missing.push(new);
            }
        }

        storage_peers.append(&mut missing);
        storage_peers.sort();

        log_trace!(self.logger, "finished calling list_peers");
        Ok(storage_peers)
    }

    /// Retrieves the logs from storage.
    pub fn get_logs(
        storage: S,
        logger: Arc<MutinyLogger>,
    ) -> Result<Option<Vec<String>>, MutinyError> {
        logger.get_logs(&storage)
    }

    /// Resets the scorer and network graph. This can be useful if you get stuck in a bad state.
    pub async fn reset_router(&self) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling reset_router");

        // if we're not connected to the db, start it up
        let needs_db_connection = !self.storage.clone().connected().unwrap_or(true);
        if needs_db_connection {
            self.storage.clone().start().await?;
        }

        // delete all the keys we use to store routing data
        self.storage
            .delete(&[GOSSIP_SYNC_TIME_KEY, NETWORK_GRAPH_KEY, PROB_SCORER_KEY])?;

        // shut back down after reading if it was already closed
        if needs_db_connection {
            self.storage.clone().stop().await;
        }

        log_trace!(self.logger, "finished calling reset_router");
        Ok(())
    }

    /// Resets BDK's keychain tracker. This will require a re-sync of the blockchain.
    ///
    /// This can be useful if you get stuck in a bad state.
    pub async fn reset_onchain_tracker(&self) -> Result<(), MutinyError> {
        log_trace!(self.logger, "calling reset_onchain_tracker");

        // if we're not connected to the db, start it up
        let needs_db_connection = !self.storage.clone().connected().unwrap_or(true);
        if needs_db_connection {
            self.storage.clone().start().await?;
        }

        // delete the bdk keychain store
        self.storage.delete(&[KEYCHAIN_STORE_KEY])?;
        self.storage
            .write_data(NEED_FULL_SYNC_KEY.to_string(), true, None)?;

        // shut back down after reading if it was already closed
        if needs_db_connection {
            self.storage.clone().stop().await;
        }

        log_trace!(self.logger, "finished calling reset_onchain_tracker");
        Ok(())
    }

    /// Exports the current state of the node manager to a json object.
    pub async fn export_json(storage: S) -> Result<Value, MutinyError> {
        let needs_db_connection = !storage.clone().connected().unwrap_or(true);
        if needs_db_connection {
            storage.clone().start().await?;
        }

        // get all the data from storage, scanning with prefix "" will get all keys
        let map = storage.scan("", None)?;
        let serde_map = serde_json::map::Map::from_iter(map.into_iter().filter(|(k, _)| {
            // filter out logs and network graph
            // these are really big and not needed for export
            // filter out device id so a new one is generated
            !matches!(
                k.as_str(),
                LOGGING_KEY | NETWORK_GRAPH_KEY | PROB_SCORER_KEY | DEVICE_ID_KEY
            )
        }));

        // shut back down after reading if it was already closed
        if needs_db_connection {
            storage.clone().stop().await;
        }

        Ok(Value::Object(serde_map))
    }
}

// This will create a new node with a node manager and return the PublicKey of the node created.
pub(crate) async fn create_new_node_from_node_manager<S: MutinyStorage>(
    node_manager: &NodeManager<S>,
) -> Result<NodeIdentity, MutinyError> {
    // Begin with a mutex lock so that nothing else can
    // save or alter the node list while it is about to
    // be saved.
    let mut node_mutex = node_manager.node_storage.write().await;

    // Get the current nodes and their bip32 indices
    // so that we can create another node with the next.
    // Always get it from our storage, the node_mutex is
    // mostly for read only and locking.
    let mut existing_nodes = node_manager.storage.get_nodes()?;
    let next_node_index = match existing_nodes
        .nodes
        .iter()
        .max_by_key(|(_, v)| v.child_index)
    {
        None => 0,
        Some((_, v)) => v.child_index + 1,
    };

    let lsp = node_manager.lsp_config.clone();

    let next_node = NodeIndex {
        child_index: next_node_index,
        lsp,
        archived: Some(false),
    };

    let mut node_builder = NodeBuilder::new(node_manager.xprivkey, node_manager.storage.clone())
        .with_node_index(next_node.clone())
        .with_gossip_sync(node_manager.gossip_sync.clone())
        .with_scorer(node_manager.scorer.clone())
        .with_chain(node_manager.chain.clone())
        .with_fee_estimator(node_manager.fee_estimator.clone())
        .with_wallet(node_manager.wallet.clone())
        .with_esplora(node_manager.esplora.clone())
        .with_network(node_manager.network)
        .with_initial_sync(node_manager.has_done_initial_ldk_sync.clone());
    node_builder.with_logger(node_manager.logger.clone());

    #[cfg(target_arch = "wasm32")]
    node_builder.with_websocket_proxy_addr(node_manager.websocket_proxy_addr.clone());

    if let Some(l) = node_manager.lsp_config.clone() {
        node_builder.with_lsp_config(l);
    }
    if let Some(cb) = node_manager.ln_event_callback.clone() {
        node_builder.with_ln_event_callback(cb);
    }
    if node_manager.do_not_connect_peers {
        node_builder.do_not_connect_peers();
    }

    if node_manager.do_not_bump_channel_close_tx {
        node_builder.do_not_bump_channel_close_tx();
    }

    if let Some(ref address) = node_manager.sweep_target_address {
        node_builder.with_sweep_target_address(address.clone());
    }

    let new_node = node_builder.build().await?;
    let node_pubkey = new_node.pubkey;
    let next_node_uuid = new_node.uuid.clone();

    existing_nodes.version += 1;
    existing_nodes
        .nodes
        .insert(next_node_uuid.clone(), next_node);
    node_manager.storage.insert_nodes(&existing_nodes)?;
    node_mutex.nodes = existing_nodes.nodes.clone();

    let mut nodes = node_manager.nodes.write().await;
    nodes.insert(node_pubkey, Arc::new(new_node));

    Ok(NodeIdentity {
        uuid: next_node_uuid,
        pubkey: node_pubkey,
    })
}

/// Turn parameterized LSP options into a [`LspConfig`].
pub fn create_lsp_config(
    lsp_url: Option<String>,
    lsp_connection_string: Option<String>,
    lsp_token: Option<String>,
) -> Result<Option<LspConfig>, MutinyError> {
    match (lsp_url.clone(), lsp_connection_string.clone()) {
        (Some(lsp_url), None) => {
            let trimmed = lsp_url.trim().to_string();
            if !trimmed.is_empty() {
                // make sure url is valid
                if Url::parse(&trimmed).is_err() {
                    return Err(MutinyError::InvalidArgumentsError);
                }

                Ok(Some(LspConfig::new_voltage_flow(trimmed)))
            } else {
                Ok(None)
            }
        }
        (None, Some(lsp_connection_string)) => {
            if !lsp_connection_string.is_empty() {
                Ok(Some(LspConfig::new_lsps(lsp_connection_string, lsp_token)))
            } else {
                Ok(None)
            }
        }
        (Some(_), Some(_)) => Err(MutinyError::InvalidArgumentsError),
        (None, None) => Ok(None),
    }
}

#[cfg(test)]
mod tests {
    use crate::{
        encrypt::encryption_key_from_pass,
        nodemanager::{ChannelClosure, MutinyInvoice, NodeManager, TransactionDetails},
        ActivityItem, MutinyWalletConfigBuilder, PrivacyLevel,
    };
    use crate::{keymanager::generate_seed, nodemanager::NodeManagerBuilder};
    use bdk_chain::ConfirmationTime;
    use bitcoin::hashes::hex::FromHex;
    use bitcoin::hashes::{sha256, Hash};
    use bitcoin::secp256k1::PublicKey;
    use bitcoin::{absolute, Network, Transaction, TxOut, Txid};
    use bitcoin::{bip32::Xpriv, transaction::Version, Amount};
    use hex_conservative::DisplayHex;
    use lightning::ln::PaymentHash;
    use lightning_invoice::Bolt11Invoice;
    use std::collections::HashMap;
    use std::str::FromStr;

    use crate::test_utils::*;

    use crate::event::{HTLCStatus, MillisatAmount, PaymentInfo};
    use crate::lsp::voltage::VoltageConfig;
    use crate::nodemanager::{LspConfig, NodeIndex, NodeStorage};
    use crate::storage::{MemoryStorage, MutinyStorage};
    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};

    wasm_bindgen_test_configure!(run_in_browser);

    const BOLT_11: &str = "lntbs1m1pjrmuu3pp52hk0j956d7s8azaps87amadshnrcvqtkvk06y2nue2w69g6e5vasdqqcqzpgxqyz5vqsp5wu3py6257pa3yzarw0et2200c08r5fu6k3u94yfwmlnc8skdkc9s9qyyssqc783940p82c64qq9pu3xczt4tdxzex9wpjn54486y866aayft2cxxusl9eags4cs3kcmuqdrvhvs0gudpj5r2a6awu4wcq29crpesjcqhdju55";

    #[test]
    async fn create_node_manager() {
        let test_name = "create_node_manager";
        log!("{}", test_name);
        let seed = generate_seed(12).unwrap();
        let network = Network::Regtest;
        let xpriv = Xpriv::new_master(network, &seed.to_seed("")).unwrap();

        let pass = uuid::Uuid::new_v4().to_string();
        let cipher = encryption_key_from_pass(&pass).unwrap();
        let storage = MemoryStorage::new(Some(pass), Some(cipher), None);

        assert!(!NodeManager::has_node_manager(storage.clone()));
        let c = MutinyWalletConfigBuilder::new(xpriv)
            .with_network(network)
            .build();
        NodeManagerBuilder::new(xpriv, storage.clone())
            .with_config(c)
            .build()
            .await
            .expect("node manager should initialize");
        storage.insert_mnemonic(seed).unwrap();
        assert!(NodeManager::has_node_manager(storage));
    }

    #[test]
    async fn created_new_nodes() {
        let test_name = "created_new_nodes";
        log!("{}", test_name);

        let pass = uuid::Uuid::new_v4().to_string();
        let cipher = encryption_key_from_pass(&pass).unwrap();
        let storage = MemoryStorage::new(Some(pass), Some(cipher), None);
        let seed = generate_seed(12).expect("Failed to gen seed");
        let network = Network::Regtest;
        let xpriv = Xpriv::new_master(network, &seed.to_seed("")).unwrap();
        let c = MutinyWalletConfigBuilder::new(xpriv)
            .with_network(network)
            .build();
        let nm = NodeManagerBuilder::new(xpriv, storage.clone())
            .with_config(c)
            .build()
            .await
            .expect("node manager should initialize");

        {
            let node_identity = nm.new_node().await.expect("should create new node");
            let node_storage = nm.node_storage.read().await;
            assert_ne!("", node_identity.uuid);
            assert_ne!("", node_identity.pubkey.to_string());
            assert_eq!(1, node_storage.nodes.len());

            let retrieved_node = node_storage.nodes.get(&node_identity.uuid).unwrap();
            assert_eq!(0, retrieved_node.child_index);
        }

        {
            let node_identity = nm.new_node().await.expect("node manager should initialize");
            let node_storage = nm.node_storage.read().await;

            assert_ne!("", node_identity.uuid);
            assert_ne!("", node_identity.pubkey.to_string());
            assert_eq!(2, node_storage.nodes.len());

            let retrieved_node = node_storage.nodes.get(&node_identity.uuid).unwrap();
            assert_eq!(1, retrieved_node.child_index);
        }
    }

    #[test]
    async fn created_label_transaction() {
        let test_name = "created_new_nodes";
        log!("{}", test_name);

        let pass = uuid::Uuid::new_v4().to_string();
        let cipher = encryption_key_from_pass(&pass).unwrap();
        let storage = MemoryStorage::new(Some(pass), Some(cipher), None);
        let seed = generate_seed(12).expect("Failed to gen seed");
        let network = Network::Regtest;
        let xpriv = Xpriv::new_master(network, &seed.to_seed("")).unwrap();
        let c = MutinyWalletConfigBuilder::new(xpriv)
            .with_network(network)
            .build();
        let nm = NodeManagerBuilder::new(xpriv, storage.clone())
            .with_config(c)
            .build()
            .await
            .expect("node manager should initialize");

        let labels = vec![String::from("label1"), String::from("label2")];

        let address = nm
            .get_new_address(labels.clone())
            .expect("should create new address");

        let fake_tx = Transaction {
            version: Version(2),
            lock_time: absolute::LockTime::ZERO,
            input: vec![],
            output: vec![TxOut {
                value: Amount::from_sat(1_000_000),
                script_pubkey: address.script_pubkey(),
            }],
        };

        // insert fake tx into wallet
        {
            let mut wallet = nm.wallet.wallet.try_write().unwrap();
            wallet.apply_unconfirmed_txs(vec![(fake_tx.clone(), 0)]);
            storage
                .write_changes(&wallet.take_staged().unwrap())
                .unwrap();
        }

        let txs = nm.list_onchain().expect("should list onchain txs");
        let tx_opt = nm
            .get_transaction(fake_tx.compute_txid())
            .expect("should get transaction");

        assert_eq!(txs.len(), 1);
        let tx = &txs[0];
        assert_eq!(tx.txid, Some(fake_tx.compute_txid()));
        assert_eq!(tx.labels, labels);

        assert!(tx_opt.is_some());
        let tx = tx_opt.unwrap();
        assert_eq!(tx.txid, Some(fake_tx.compute_txid()));
        assert_eq!(tx.labels, labels);
    }

    #[test]
    fn test_bolt11_payment_info_into_mutiny_invoice() {
        let preimage: [u8; 32] =
            FromHex::from_hex("7600f5a9ad72452dea7ad86dabbc9cb46be96a1a2fcd961e041d066b38d93008")
                .unwrap();
        let secret: [u8; 32] =
            FromHex::from_hex("7722126954f07b120ba373f2b529efc3ce3a279ab4785a912edfe783c2cdb60b")
                .unwrap();

        let payment_hash = sha256::Hash::from_str(
            "55ecf9169a6fa07e8ba181fdddf5b0bcc7860176659fa22a7cca9da2a359a33b",
        )
        .unwrap();

        let invoice = Bolt11Invoice::from_str(BOLT_11).unwrap();

        let labels = vec!["label1".to_string(), "label2".to_string()];

        let payment_info = PaymentInfo {
            preimage: Some(preimage),
            secret: Some(secret),
            status: HTLCStatus::Succeeded,
            privacy_level: PrivacyLevel::Anonymous,
            amt_msat: MillisatAmount(Some(100_000_000)),
            fee_paid_msat: None,
            bolt11: Some(invoice.clone()),
            payee_pubkey: None,
            last_update: 1681781585,
        };

        let expected: MutinyInvoice = MutinyInvoice {
            bolt11: Some(invoice),
            description: None,
            payment_hash,
            preimage: Some(preimage.to_lower_hex_string()),
            payee_pubkey: None,
            amount_sats: Some(100_000),
            expire: 1681781649 + 86400,
            status: HTLCStatus::Succeeded,
            privacy_level: PrivacyLevel::Anonymous,
            fees_paid: None,
            fee_paid_msat: None,
            inbound: true,
            labels: labels.clone(),
            last_updated: 1681781585,
        };

        let actual = MutinyInvoice::from(
            payment_info,
            PaymentHash(payment_hash.to_byte_array()),
            true,
            labels,
        )
        .unwrap();

        assert_eq!(actual, expected);
    }

    #[test]
    fn test_keysend_payment_info_into_mutiny_invoice() {
        let preimage: [u8; 32] =
            FromHex::from_hex("7600f5a9ad72452dea7ad86dabbc9cb46be96a1a2fcd961e041d066b38d93008")
                .unwrap();

        let payment_hash = sha256::Hash::from_str(
            "55ecf9169a6fa07e8ba181fdddf5b0bcc7860176659fa22a7cca9da2a359a33b",
        )
        .unwrap();

        let pubkey = PublicKey::from_str(
            "02465ed5be53d04fde66c9418ff14a5f2267723810176c9212b722e542dc1afb1b",
        )
        .unwrap();

        let payment_info = PaymentInfo {
            preimage: Some(preimage),
            secret: None,
            status: HTLCStatus::Succeeded,
            privacy_level: PrivacyLevel::Anonymous,
            amt_msat: MillisatAmount(Some(100_000)),
            fee_paid_msat: Some(1_020),
            bolt11: None,
            payee_pubkey: Some(pubkey),
            last_update: 1681781585,
        };

        let expected: MutinyInvoice = MutinyInvoice {
            bolt11: None,
            description: None,
            payment_hash,
            preimage: Some(preimage.to_lower_hex_string()),
            payee_pubkey: Some(pubkey),
            amount_sats: Some(100),
            expire: 1681781585,
            status: HTLCStatus::Succeeded,
            privacy_level: PrivacyLevel::Anonymous,
            fees_paid: Some(1),
            fee_paid_msat: Some(1020),
            inbound: false,
            labels: vec![],
            last_updated: 1681781585,
        };

        let actual = MutinyInvoice::from(
            payment_info,
            PaymentHash(payment_hash.to_byte_array()),
            false,
            vec![],
        )
        .unwrap();

        assert_eq!(actual, expected);
    }

    #[test]
    fn test_serialize_node_storage() {
        let old1: NodeStorage = serde_json::from_str("{\"nodes\":{\"93ca1ee3-d5f1-42ed-8bd9-042b298c70dc\":{\"archived\":false,\"child_index\":0,\"lsp\":\"https://signet-lsp.mutinywallet.com\"}},\"version\":11}").unwrap();
        let old2: NodeStorage = serde_json::from_str("{\"nodes\":{\"93ca1ee3-d5f1-42ed-8bd9-042b298c70dc\":{\"archived\":false,\"child_index\":0,\"lsp\":{\"VoltageFlow\":\"https://signet-lsp.mutinywallet.com\"}}},\"version\":11}").unwrap();
        let node = NodeIndex {
            child_index: 0,
            lsp: Some(LspConfig::VoltageFlow(VoltageConfig {
                url: "https://signet-lsp.mutinywallet.com".to_string(),
                pubkey: None,
                connection_string: None,
            })),
            archived: Some(false),
        };
        let mut nodes = HashMap::new();
        nodes.insert("93ca1ee3-d5f1-42ed-8bd9-042b298c70dc".to_string(), node);
        let expected = NodeStorage { nodes, version: 11 };

        assert_eq!(old1, expected);
        assert_eq!(old2, expected);

        let serialized = serde_json::to_string(&expected).unwrap();
        let deserialized: NodeStorage = serde_json::from_str(&serialized).unwrap();
        assert_eq!(deserialized, expected);
    }

    #[test]
    fn test_sort_activity_item() {
        let preimage: [u8; 32] =
            FromHex::from_hex("7600f5a9ad72452dea7ad86dabbc9cb46be96a1a2fcd961e041d066b38d93008")
                .unwrap();

        let payment_hash = sha256::Hash::from_str(
            "55ecf9169a6fa07e8ba181fdddf5b0bcc7860176659fa22a7cca9da2a359a33b",
        )
        .unwrap();

        let pubkey = PublicKey::from_str(
            "02465ed5be53d04fde66c9418ff14a5f2267723810176c9212b722e542dc1afb1b",
        )
        .unwrap();

        let closure: ChannelClosure = ChannelClosure {
            user_channel_id: None,
            channel_id: None,
            node_id: None,
            reason: "".to_string(),
            timestamp: 1686258926,
            channel_funding_txo: None,
            force_close_spend_delay: None,
        };

        let tx1: TransactionDetails = TransactionDetails {
            transaction: None,
            txid: Some(Txid::all_zeros()),
            internal_id: Txid::all_zeros(),
            received: 0,
            sent: 0,
            fee: None,
            confirmation_time: ConfirmationTime::Unconfirmed { last_seen: 0_u64 },
            labels: vec![],
        };

        let tx2: TransactionDetails = TransactionDetails {
            transaction: None,
            txid: Some(Txid::all_zeros()),
            internal_id: Txid::all_zeros(),
            received: 0,
            sent: 0,
            fee: None,
            confirmation_time: ConfirmationTime::Confirmed {
                height: 1,
                time: 1234,
            },
            labels: vec![],
        };

        let invoice1: MutinyInvoice = MutinyInvoice {
            bolt11: None,
            description: None,
            payment_hash,
            preimage: Some(preimage.to_lower_hex_string()),
            payee_pubkey: Some(pubkey),
            amount_sats: Some(100),
            expire: 1681781585,
            status: HTLCStatus::Succeeded,
            privacy_level: PrivacyLevel::NotAvailable,
            fees_paid: Some(1),
            fee_paid_msat: Some(1024),
            inbound: false,
            labels: vec![],
            last_updated: 1681781585,
        };

        let invoice2: MutinyInvoice = MutinyInvoice {
            bolt11: None,
            description: None,
            payment_hash,
            preimage: Some(preimage.to_lower_hex_string()),
            payee_pubkey: Some(pubkey),
            amount_sats: Some(100),
            expire: 1681781585,
            status: HTLCStatus::Succeeded,
            privacy_level: PrivacyLevel::NotAvailable,
            fees_paid: Some(1),
            fee_paid_msat: Some(1024),
            inbound: false,
            labels: vec![],
            last_updated: 1781781585,
        };

        let invoice3: MutinyInvoice = MutinyInvoice {
            bolt11: None,
            description: None,
            payment_hash,
            preimage: None,
            payee_pubkey: Some(pubkey),
            amount_sats: Some(101),
            expire: 1581781585,
            status: HTLCStatus::InFlight,
            privacy_level: PrivacyLevel::NotAvailable,
            fees_paid: None,
            fee_paid_msat: None,
            inbound: false,
            labels: vec![],
            last_updated: 1581781585,
        };

        let invoice4: MutinyInvoice = MutinyInvoice {
            bolt11: None,
            description: None,
            payment_hash,
            preimage: None,
            payee_pubkey: Some(pubkey),
            amount_sats: Some(102),
            expire: 1581781585,
            status: HTLCStatus::InFlight,
            privacy_level: PrivacyLevel::NotAvailable,
            fees_paid: None,
            fee_paid_msat: None,
            inbound: false,
            labels: vec![],
            last_updated: 1581781585,
        };

        let invoice5: MutinyInvoice = MutinyInvoice {
            bolt11: None,
            description: Some("difference".to_string()),
            payment_hash,
            preimage: Some(preimage.to_lower_hex_string()),
            payee_pubkey: Some(pubkey),
            amount_sats: Some(100),
            expire: 1681781585,
            status: HTLCStatus::Succeeded,
            privacy_level: PrivacyLevel::NotAvailable,
            fees_paid: Some(1),
            fee_paid_msat: Some(1024),
            inbound: false,
            labels: vec![],
            last_updated: 1781781585,
        };

        let mut vec = vec![
            ActivityItem::OnChain(tx1.clone()),
            ActivityItem::OnChain(tx2.clone()),
            ActivityItem::Lightning(Box::new(invoice1.clone())),
            ActivityItem::Lightning(Box::new(invoice2.clone())),
            ActivityItem::Lightning(Box::new(invoice3.clone())),
            ActivityItem::Lightning(Box::new(invoice4.clone())),
            ActivityItem::Lightning(Box::new(invoice5.clone())),
            ActivityItem::ChannelClosed(closure.clone()),
        ];
        vec.sort();

        assert_eq!(
            vec,
            vec![
                ActivityItem::OnChain(tx2),
                ActivityItem::Lightning(Box::new(invoice1)),
                ActivityItem::ChannelClosed(closure),
                ActivityItem::Lightning(Box::new(invoice5)),
                ActivityItem::Lightning(Box::new(invoice2)),
                ActivityItem::OnChain(tx1),
                ActivityItem::Lightning(Box::new(invoice3)),
                ActivityItem::Lightning(Box::new(invoice4)),
            ]
        );
    }
}


================================================
File: mutiny-core/src/onchain.rs
================================================
use anyhow::anyhow;
use bdk_chain::spk_client::{
    FullScanRequestBuilder, FullScanResult, SyncRequestBuilder, SyncResult,
};
use std::collections::HashSet;
use std::str::FromStr;
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::{Arc, RwLock};

use bdk_chain::{BlockId, ConfirmationBlockTime, ConfirmationTime, Indexer, TxUpdate};
use bdk_esplora::EsploraAsyncExt;
use bdk_wallet::bitcoin::FeeRate;
use bdk_wallet::psbt::PsbtUtils;
use bdk_wallet::template::DescriptorTemplateOut;
use bdk_wallet::{
    CreateParams, KeychainKind, LoadParams, LocalOutput, SignOptions, Update, Wallet,
};
use bitcoin::bip32::{ChildNumber, DerivationPath, Xpriv};
use bitcoin::consensus::serialize;
use bitcoin::psbt::{Input, Psbt};
use bitcoin::{Address, Amount, Network, OutPoint, ScriptBuf, Transaction, Txid};
use esplora_client::AsyncClient;
use hex_conservative::DisplayHex;
use lightning::events::bump_transaction::{Utxo, WalletSource};
use lightning::util::logger::Logger;
use lightning::{log_debug, log_error, log_info, log_trace, log_warn};

use crate::error::MutinyError;
use crate::fees::MutinyFeeEstimator;
use crate::labels::*;
use crate::logging::MutinyLogger;
use crate::messagehandler::{CommonLnEvent, CommonLnEventCallback};
use crate::storage::{
    IndexItem, MutinyStorage, KEYCHAIN_STORE_KEY, NEED_FULL_SYNC_KEY, ONCHAIN_PREFIX,
};
use crate::utils::{now, sleep};
use crate::TransactionDetails;

pub(crate) const FULL_SYNC_STOP_GAP: usize = 150;
pub(crate) const RESTORE_SYNC_STOP_GAP: usize = 50;
const PARALLEL_REQUESTS: usize = 10;

#[derive(Clone)]
pub struct OnChainWallet<S: MutinyStorage> {
    pub wallet: Arc<RwLock<Wallet>>,
    pub(crate) storage: S,
    pub network: Network,
    pub blockchain: Arc<AsyncClient>,
    pub fees: Arc<MutinyFeeEstimator<S>>,
    pub(crate) stop: Arc<AtomicBool>,
    logger: Arc<MutinyLogger>,
    ln_event_callback: Option<CommonLnEventCallback>,
}

impl<S: MutinyStorage> OnChainWallet<S> {
    #[allow(clippy::too_many_arguments)]
    pub fn new(
        xprivkey: Xpriv,
        db: S,
        network: Network,
        esplora: Arc<AsyncClient>,
        fees: Arc<MutinyFeeEstimator<S>>,
        stop: Arc<AtomicBool>,
        logger: Arc<MutinyLogger>,
        ln_event_callback: Option<CommonLnEventCallback>,
    ) -> Result<OnChainWallet<S>, MutinyError> {
        let account_number = 0;
        let (receive_descriptor_template, change_descriptor_template) =
            get_tr_descriptors_for_extended_key(xprivkey, network, account_number)?;

        // if we have a keychain set, load the wallet, otherwise create one
        // receive_descriptor_template.clone(),
        // Some(change_descriptor_template.clone()),
        // OnChainStorage(db.clone()),
        let load_wallet_res = db.read_changes()?.map(|changeset| {
            Wallet::load_with_params(
                changeset,
                LoadParams::new()
                    .descriptor(
                        KeychainKind::External,
                        Some(receive_descriptor_template.clone()),
                    )
                    .descriptor(
                        KeychainKind::Internal,
                        Some(change_descriptor_template.clone()),
                    )
                    .extract_keys(),
            )
        });
        let wallet = match load_wallet_res {
            Some(Ok(Some(wallet))) => wallet,
            None | Some(Ok(None)) => {
                // we don't have a bdk wallet, create one
                Wallet::create_with_params(
                    CreateParams::new(receive_descriptor_template, change_descriptor_template)
                        .network(network),
                )?
            }
            Some(Err(bdk_wallet::LoadError::Mismatch(_))) => {
                // failed to read storage, means we have old encoding and need to delete and re-init wallet
                db.delete(&[KEYCHAIN_STORE_KEY])?;
                db.write_data(NEED_FULL_SYNC_KEY.to_string(), true, None)?;
                Wallet::create_with_params(
                    CreateParams::new(receive_descriptor_template, change_descriptor_template)
                        .network(network),
                )?
            }
            Some(Err(e)) => {
                log_error!(logger, "Failed to load wallet: {e}");
                return Err(MutinyError::WalletOperationFailed);
            }
        };

        Ok(OnChainWallet {
            wallet: Arc::new(RwLock::new(wallet)),
            storage: db,
            network,
            blockchain: esplora,
            fees,
            stop,
            logger,
            ln_event_callback,
        })
    }

    pub async fn broadcast_transaction(&self, tx: Transaction) -> Result<(), MutinyError> {
        let txid = tx.compute_txid();
        log_info!(self.logger, "Broadcasting transaction: {txid}");
        log_debug!(self.logger, "Transaction: {}", serialize(&tx).as_hex());

        if let Err(e) = self.blockchain.broadcast(&tx).await {
            log_error!(self.logger, "Failed to broadcast transaction ({txid}): {e}");
            return Err(MutinyError::Other(anyhow!(
                "Failed to broadcast transaction ({txid}): {e}"
            )));
        } else if let Err(e) = self
            .insert_tx(
                tx.clone(),
                ConfirmationTime::Unconfirmed {
                    last_seen: now().as_secs(),
                },
                None,
            )
            .await
        {
            log_warn!(self.logger, "ERROR: Could not sync broadcasted tx ({txid}), will be synced in next iteration: {e:?}");
        }

        if let Some(cb) = self.ln_event_callback.as_ref() {
            let event = CommonLnEvent::TxBroadcasted {
                txid: format!("{:x}", txid),
                hex_tx: bitcoin::consensus::encode::serialize_hex(&tx),
            };
            cb.trigger(event);
            log_debug!(self.logger, "Triggered TxBroadcasted event");
        }

        Ok(())
    }

    /// Tries to commit a wallet update, returns true if successful.
    fn try_commit_update(&self, update: Update) -> Result<bool, MutinyError> {
        // get wallet lock for writing and apply the update
        match self.wallet.try_write() {
            Ok(mut wallet) => match wallet.apply_update_at(update, Some(now().as_secs())) {
                Ok(_) => {
                    // commit the changes
                    if let Some(changeset) = wallet.take_staged() {
                        self.storage.write_changes(&changeset)?;
                    }
                    drop(wallet); // drop so we can read from wallet

                    // update the activity index, just get the list of transactions
                    // and insert them into the index, this is done in background so shouldn't
                    // block the wallet update
                    let index_items = self
                        .list_transactions(false)?
                        .into_iter()
                        .map(|t| IndexItem {
                            timestamp: match t.confirmation_time {
                                ConfirmationTime::Confirmed { time, .. } => Some(time),
                                ConfirmationTime::Unconfirmed { .. } => None,
                            },
                            key: format!("{ONCHAIN_PREFIX}{}", t.internal_id),
                        })
                        .collect::<Vec<_>>();

                    let index = self.storage.activity_index();
                    let mut index = index.try_write()?;
                    // remove old-onchain txs
                    index.retain(|i| !i.key.starts_with(ONCHAIN_PREFIX));
                    index.extend(index_items);

                    Ok(true)
                }
                Err(e) => {
                    // failed to apply wallet update
                    log_error!(self.logger, "Could not apply wallet update: {e}");
                    Err(MutinyError::Other(anyhow!("Could not apply update: {e}")))
                }
            },
            Err(e) => {
                // if we can't get the lock, we just return and try again later
                log_error!(
                    self.logger,
                    "Could not get wallet lock: {e}, retrying in 250ms"
                );

                if self.stop.load(Ordering::Relaxed) {
                    return Err(MutinyError::NotRunning);
                };

                Ok(false)
            }
        }
    }

    pub async fn sync(&self) -> Result<(), MutinyError> {
        // if we need a full sync from a restore
        if self.storage.get(NEED_FULL_SYNC_KEY)?.unwrap_or_default() {
            self.full_sync(RESTORE_SYNC_STOP_GAP).await?;
            self.storage.delete(&[NEED_FULL_SYNC_KEY])?;
        }
        // get first wallet lock that only needs to read
        let (spks, txids, chain_tip) = {
            if let Ok(wallet) = self.wallet.try_read() {
                let spk_vec = wallet
                    .spk_index()
                    .unused_spks()
                    .map(|(_, v)| v)
                    .collect::<Vec<_>>();

                let chain = wallet.local_chain();
                let chain_tip = chain.tip();

                let unconfirmed_txids = wallet
                    .tx_graph()
                    .list_canonical_txs(chain, chain_tip.block_id())
                    .filter(|canonical_tx| !canonical_tx.chain_position.is_confirmed())
                    .map(|canonical_tx| canonical_tx.tx_node.txid)
                    .collect::<Vec<Txid>>();

                (spk_vec, unconfirmed_txids, chain_tip)
            } else {
                log_error!(self.logger, "Could not get wallet lock to sync");
                return Err(MutinyError::WalletOperationFailed);
            }
        };

        let SyncResult {
            tx_update,
            chain_update,
        } = self
            .blockchain
            .sync(
                SyncRequestBuilder::default()
                    .spks(spks)
                    .txids(txids)
                    .chain_tip(chain_tip),
                PARALLEL_REQUESTS,
            )
            .await?;
        let update = Update {
            tx_update,
            chain: chain_update,
            ..Default::default()
        };

        for _ in 0..10 {
            let successful = self.try_commit_update(update.clone())?;

            if successful {
                return Ok(());
            } else {
                // if we can't get the lock, sleep for 250ms and try again
                sleep(250).await;
            }
        }

        log_error!(self.logger, "Could not get wallet lock after 10 retries");
        Err(MutinyError::WalletOperationFailed)
    }

    pub async fn full_sync(&self, gap: usize) -> Result<(), MutinyError> {
        // get first wallet lock that only needs to read
        let spks = {
            if let Ok(wallet) = self.wallet.try_read() {
                wallet.all_unbounded_spk_iters()
            } else {
                log_error!(self.logger, "Could not get wallet lock to sync");
                return Err(MutinyError::WalletOperationFailed);
            }
        };

        let mut request_builder = FullScanRequestBuilder::default();
        for (kind, pks) in spks.into_iter() {
            request_builder = request_builder.spks_for_keychain(kind, pks)
        }

        let FullScanResult {
            tx_update,
            last_active_indices,
            chain_update,
        } = self
            .blockchain
            .full_scan(request_builder, gap, PARALLEL_REQUESTS)
            .await?;
        let update = Update {
            last_active_indices,
            tx_update,
            chain: chain_update,
        };

        // get new wallet lock for writing and apply the update
        for _ in 0..10 {
            let successful = self.try_commit_update(update.clone())?;

            if successful {
                return Ok(());
            } else {
                sleep(250).await;
            }
        }

        log_error!(self.logger, "Could not get wallet lock after 10 retries");
        Err(MutinyError::WalletOperationFailed)
    }

    pub(crate) async fn insert_tx(
        &self,
        tx: Transaction,
        position: ConfirmationTime,
        block_id: Option<BlockId>,
    ) -> Result<(), MutinyError> {
        let txid = tx.compute_txid();
        match position {
            ConfirmationTime::Confirmed { time, .. } => {
                // if the transaction is confirmed and we have the block id,
                // we can insert it directly
                if let Some(block_id) = block_id {
                    let mut wallet = self.wallet.try_write()?;
                    wallet.insert_checkpoint(block_id)?;
                    let txid = tx.compute_txid();
                    let update = Update {
                        tx_update: TxUpdate {
                            txs: vec![Arc::new(tx)],
                            anchors: [(
                                ConfirmationBlockTime {
                                    block_id,
                                    confirmation_time: time,
                                },
                                txid,
                            )]
                            .into_iter()
                            .collect(),
                            ..Default::default()
                        },
                        ..Default::default()
                    };
                    wallet
                        .apply_update_at(update, Some(time))
                        .map_err(|_err| MutinyError::WalletOperationFailed)?;
                } else {
                    // if the transaction is confirmed and we don't have the block id,
                    // we should just sync the wallet otherwise we can get an error
                    // with the wallet being behind the blockchain
                    self.sync().await?;

                    return Ok(());
                }
            }
            ConfirmationTime::Unconfirmed { last_seen } => {
                // if the transaction is unconfirmed, we can just insert it
                let mut wallet = self.wallet.try_write()?;

                // if we already have the transaction, we don't need to insert it
                if wallet.get_tx(txid).is_none() {
                    // insert tx and commit changes
                    wallet.apply_unconfirmed_txs(vec![(tx, last_seen)]);
                    log_debug!(
                        self.logger,
                        "After inserting tx, the tx_graph: ({:?})",
                        wallet.tx_graph()
                    )
                } else {
                    log_debug!(
                        self.logger,
                        "Tried to insert already existing transaction ({txid})",
                    )
                }
            }
        }

        // commit wallet
        let mut wallet = self.wallet.try_write()?;
        if let Some(changeset) = wallet.take_staged() {
            self.storage.write_changes(&changeset)?;
        }

        // update activity index
        let index = self.storage.activity_index();
        let mut index = index.try_write()?;
        let key = format!("{ONCHAIN_PREFIX}{txid}");
        index.retain(|i| i.key != key); // remove old version

        // then insert the new version
        index.insert(IndexItem {
            timestamp: match position {
                ConfirmationTime::Confirmed { time, .. } => Some(time),
                ConfirmationTime::Unconfirmed { .. } => None,
            },
            key,
        });

        Ok(())
    }

    pub fn list_utxos(&self) -> Result<Vec<LocalOutput>, MutinyError> {
        Ok(self.wallet.try_read()?.list_unspent().collect())
    }

    pub fn list_transactions(
        &self,
        include_raw: bool,
    ) -> Result<Vec<TransactionDetails>, MutinyError> {
        if let Ok(wallet) = self.wallet.try_read() {
            let txs = wallet
                .transactions()
                .filter_map(|tx| {
                    // skip txs that were not relevant to our bdk wallet
                    if wallet.spk_index().is_tx_relevant(&tx.tx_node.tx) {
                        let (sent, received) = wallet.sent_and_received(&tx.tx_node.tx);

                        let transaction = if include_raw {
                            Some(tx.tx_node.tx.clone())
                        } else {
                            None
                        };

                        let fee = wallet.calculate_fee(&tx.tx_node.tx).ok();

                        Some(TransactionDetails {
                            transaction: transaction.map(|t| Transaction::clone(&t)),
                            txid: Some(tx.tx_node.txid),
                            internal_id: tx.tx_node.txid,
                            received: received.to_sat(),
                            sent: sent.to_sat(),
                            fee: fee.map(|f| f.to_sat()),
                            confirmation_time: tx.chain_position.cloned().into(),
                            labels: vec![],
                        })
                    } else {
                        None
                    }
                })
                .collect();
            return Ok(txs);
        }
        log_error!(
            self.logger,
            "Could not get wallet lock to list transactions"
        );
        Err(MutinyError::WalletOperationFailed)
    }

    pub fn get_transaction(&self, txid: Txid) -> Result<Option<TransactionDetails>, MutinyError> {
        let wallet = self.wallet.try_read()?;
        let bdk_tx = wallet.get_tx(txid);

        match bdk_tx {
            None => Ok(None),
            Some(tx) => {
                let (sent, received) = wallet.sent_and_received(&tx.tx_node.tx);
                let fee = wallet.calculate_fee(&tx.tx_node.tx).ok();
                let details = TransactionDetails {
                    transaction: Some(Transaction::clone(&tx.tx_node.tx)),
                    txid: Some(txid),
                    internal_id: txid,
                    received: received.to_sat(),
                    sent: sent.to_sat(),
                    fee: fee.map(|fee| fee.to_sat()),
                    confirmation_time: tx.chain_position.cloned().into(),
                    labels: vec![],
                };

                Ok(Some(details))
            }
        }
    }

    #[allow(dead_code)]
    fn get_psbt_previous_labels(&self, psbt: &Psbt) -> Result<Vec<String>, MutinyError> {
        // first get previous labels
        let address_labels = self.storage.get_address_labels()?;

        // get previous addresses
        let prev_addresses = psbt
            .inputs
            .iter()
            .filter_map(|i| {
                let address = if let Some(out) = i.witness_utxo.as_ref() {
                    Address::from_script(&out.script_pubkey, self.network).ok()
                } else {
                    None
                };

                address
            })
            .collect::<Vec<_>>();

        // get addresses from previous labels
        let prev_labels = prev_addresses
            .iter()
            .filter_map(|addr| address_labels.get(&addr.to_string()))
            .flatten()
            .cloned()
            .collect::<Vec<_>>();

        Ok(prev_labels)
    }

    #[allow(dead_code)]
    pub(crate) fn label_psbt(&self, psbt: &Psbt, labels: Vec<String>) -> Result<(), MutinyError> {
        let mut prev_labels = vec![];

        // add on new labels
        prev_labels.extend(labels);

        // deduplicate labels and create aggregate label
        // we use a HashSet to deduplicate so we can retain the order of the labels
        let mut seen = HashSet::new();
        let agg_labels = prev_labels
            .into_iter()
            .filter(|s| seen.insert(s.clone()))
            .collect::<Vec<_>>();

        // add output addresses to previous addresses
        let addresses = psbt
            .unsigned_tx
            .output
            .iter()
            .filter_map(|o| Address::from_script(&o.script_pubkey, self.network).ok())
            .collect::<Vec<_>>();

        // set label for send to address
        for addr in addresses {
            self.storage.set_address_labels(addr, agg_labels.clone())?;
        }

        Ok(())
    }

    pub fn create_signed_psbt(
        &self,
        send_to: Address,
        amount: u64,
        fee_rate: Option<u64>,
    ) -> Result<Psbt, MutinyError> {
        self.create_signed_psbt_to_spk(send_to.script_pubkey(), amount, fee_rate)
    }

    pub fn create_signed_psbt_to_spk(
        &self,
        spk: ScriptBuf,
        amount: u64,
        fee_rate: Option<u64>,
    ) -> Result<Psbt, MutinyError> {
        let mut wallet = self.wallet.try_write()?;

        let fee_rate = if let Some(rate) = fee_rate {
            FeeRate::from_sat_per_vb(rate).ok_or(MutinyError::InvalidFeerate)?
        } else {
            let sat_per_kwu = self.fees.get_normal_fee_rate();
            FeeRate::from_sat_per_kwu(sat_per_kwu.into())
        };
        let mut psbt = {
            let mut builder = wallet.build_tx();
            builder
                .add_recipient(spk, Amount::from_sat(amount))
                .enable_rbf()
                .fee_rate(fee_rate);
            builder.finish()?
        };
        log_debug!(self.logger, "Unsigned PSBT: {psbt}");
        let finalized = wallet.sign(&mut psbt, SignOptions::default())?;
        log_debug!(self.logger, "finalized: {finalized}");
        Ok(psbt)
    }

    pub async fn send(
        &self,
        destination_address: Address,
        amount: u64,
        labels: Vec<String>,
        fee_rate: Option<u64>,
    ) -> Result<Txid, MutinyError> {
        let psbt = self.create_signed_psbt(destination_address, amount, fee_rate)?;
        self.label_psbt(&psbt, labels)?;

        let raw_transaction = psbt.extract_tx()?;
        let txid = raw_transaction.compute_txid();

        self.broadcast_transaction(raw_transaction).await?;
        log_debug!(self.logger, "Transaction broadcast! TXID: {txid}");
        Ok(txid)
    }

    pub async fn send_payjoin(
        &self,
        mut original_psbt: Psbt,
        mut proposal_psbt: Psbt,
        labels: Vec<String>,
    ) -> Result<Transaction, MutinyError> {
        let wallet = self.wallet.try_read()?;

        // add original psbt input map data in place so BDK knows which scripts to sign,
        // proposal_psbt only contains the sender input outpoints, not scripts, which BDK
        // does not look up
        fn input_pairs(
            psbt: &mut Psbt,
        ) -> Box<dyn Iterator<Item = (&bitcoin::TxIn, &mut Input)> + '_> {
            Box::new(psbt.unsigned_tx.input.iter().zip(&mut psbt.inputs))
        }

        let mut original_inputs = input_pairs(&mut original_psbt).peekable();

        for (proposed_txin, proposed_psbtin) in input_pairs(&mut proposal_psbt) {
            log_trace!(
                self.logger,
                "Proposed txin: {:?}",
                proposed_txin.previous_output
            );
            if let Some((original_txin, original_psbtin)) = original_inputs.peek() {
                log_trace!(
                    self.logger,
                    "Original txin: {:?}",
                    original_txin.previous_output
                );
                log_trace!(self.logger, "Original psbtin: {original_psbtin:?}");
                if proposed_txin.previous_output == original_txin.previous_output {
                    proposed_psbtin.witness_utxo = original_psbtin.witness_utxo.clone();
                    proposed_psbtin.non_witness_utxo = original_psbtin.non_witness_utxo.clone();
                    original_inputs.next();
                }
            }
        }

        log_trace!(self.logger, "Augmented PSBT: {proposal_psbt:?}");
        // sign and finalize payjoin
        let result = wallet.sign(&mut proposal_psbt, SignOptions::default());
        log_trace!(self.logger, "Sign result: {result:?}");
        result?;
        drop(wallet);

        self.label_psbt(&proposal_psbt, labels)?;
        let payjoin = proposal_psbt.extract_tx()?;

        Ok(payjoin)
    }

    pub fn create_sweep_psbt(
        &self,
        spk: ScriptBuf,
        fee_rate: Option<u64>,
        allow_dust: Option<bool>,
    ) -> Result<Psbt, MutinyError> {
        let mut wallet = self.wallet.try_write()?;

        let fee_rate = if let Some(rate) = fee_rate {
            FeeRate::from_sat_per_vb(rate).ok_or_else(|| MutinyError::InvalidFeerate)?
        } else {
            let sat_per_kwu = self.fees.get_normal_fee_rate();
            FeeRate::from_sat_per_kwu(sat_per_kwu.into())
        };
        let mut psbt = {
            let mut builder = wallet.build_tx();
            builder
                .drain_wallet() // Spend all outputs in this wallet.
                .drain_to(spk)
                .enable_rbf()
                .allow_dust(allow_dust.unwrap_or_default())
                .fee_rate(fee_rate);
            builder.finish()?
        };
        log_debug!(self.logger, "Unsigned PSBT: {psbt}");
        let finalized = wallet.sign(
            &mut psbt,
            SignOptions {
                trust_witness_utxo: true,
                try_finalize: true,
                allow_all_sighashes: true,
                ..Default::default()
            },
        )?;
        log_debug!(self.logger, "finalized: {finalized}");
        Ok(psbt)
    }

    pub async fn sweep(
        &self,
        destination_address: Address,
        labels: Vec<String>,
        fee_rate: Option<u64>,
        allow_dust: Option<bool>,
    ) -> Result<Txid, MutinyError> {
        let psbt =
            self.create_sweep_psbt(destination_address.script_pubkey(), fee_rate, allow_dust)?;
        self.label_psbt(&psbt, labels)?;

        let raw_transaction = psbt.extract_tx()?;
        let txid = raw_transaction.compute_txid();

        self.broadcast_transaction(raw_transaction).await?;
        log_debug!(self.logger, "Transaction broadcast! TXID: {txid}");
        Ok(txid)
    }

    /// Creates a PSBT that spends all the selected utxos a given output.
    /// A fee rate is not specified because it should be precalculated
    /// in the output's amount.
    pub(crate) fn create_sweep_psbt_to_output(
        &self,
        utxos: &[OutPoint],
        spk: ScriptBuf,
        amount_sats: u64,
        absolute_fee: u64,
    ) -> Result<Psbt, MutinyError> {
        let mut wallet = self.wallet.try_write()?;
        let mut psbt = {
            let mut builder = wallet.build_tx();
            builder
                .manually_selected_only()
                .add_utxos(utxos)?
                .add_recipient(spk, Amount::from_sat(amount_sats))
                .fee_absolute(Amount::from_sat(absolute_fee))
                .enable_rbf();
            builder.finish()?
        };
        log_debug!(self.logger, "Unsigned PSBT: {psbt}");
        let finalized = wallet.sign(&mut psbt, SignOptions::default())?;
        log_debug!(self.logger, "finalized: {finalized}");
        Ok(psbt)
    }

    pub fn estimate_tx_fee(
        &self,
        spk: ScriptBuf,
        amount: u64,
        fee_rate: Option<u64>,
    ) -> Result<u64, MutinyError> {
        let psbt = self.create_signed_psbt_to_spk(spk, amount, fee_rate)?;

        psbt.fee_amount()
            .map(|amount| amount.to_sat())
            .ok_or(MutinyError::WalletOperationFailed)
    }

    pub fn estimate_sweep_tx_fee(
        &self,
        spk: ScriptBuf,
        fee_rate: Option<u64>,
        allow_dust: Option<bool>,
    ) -> Result<u64, MutinyError> {
        let psbt = self.create_sweep_psbt(spk, fee_rate, allow_dust)?;

        psbt.fee_amount()
            .map(|amount| amount.to_sat())
            .ok_or(MutinyError::WalletOperationFailed)
    }

    pub fn construct_sweep_tx(
        &self,
        spk: ScriptBuf,
        fee_rate: Option<u64>,
        allow_dust: Option<bool>,
    ) -> Result<Transaction, MutinyError> {
        let psbt = self.create_sweep_psbt(spk, fee_rate, allow_dust)?;
        Ok(psbt.extract_tx()?)
    }

    /// Bumps the given transaction by replacing the given tx with a transaction at
    /// the new given fee rate in sats/vbyte
    pub async fn bump_fee(&self, txid: Txid, new_fee_rate: u64) -> Result<Txid, MutinyError> {
        let tx = {
            let mut wallet = self.wallet.try_write()?;
            // build RBF fee bump tx
            let mut builder = wallet.build_fee_bump(txid)?;
            builder.fee_rate(
                FeeRate::from_sat_per_vb(new_fee_rate).ok_or(MutinyError::InvalidFeerate)?,
            );
            let mut psbt = builder.finish()?;
            wallet.sign(&mut psbt, SignOptions::default())?;

            psbt.extract_tx()?
        };

        let txid = tx.compute_txid();

        self.broadcast_transaction(tx).await?;
        log_debug!(self.logger, "Fee bump Transaction broadcast! TXID: {txid}");
        Ok(txid)
    }
}

fn get_tr_descriptors_for_extended_key(
    master_xprv: Xpriv,
    network: Network,
    account_number: u32,
) -> Result<(DescriptorTemplateOut, DescriptorTemplateOut), MutinyError> {
    let coin_type = coin_type_from_network(network);

    let base_path = DerivationPath::from_str("m/86'")?;
    let derivation_path = base_path.extend([
        ChildNumber::from_hardened_idx(coin_type)?,
        ChildNumber::from_hardened_idx(account_number)?,
    ]);

    let receive_descriptor_template = bdk_wallet::descriptor!(tr((
        master_xprv,
        derivation_path.extend([ChildNumber::Normal { index: 0 }])
    )))?;
    let change_descriptor_template = bdk_wallet::descriptor!(tr((
        master_xprv,
        derivation_path.extend([ChildNumber::Normal { index: 1 }])
    )))?;

    Ok((receive_descriptor_template, change_descriptor_template))
}

pub(crate) fn coin_type_from_network(network: Network) -> u32 {
    match network {
        Network::Bitcoin => 0,
        Network::Testnet => 1,
        Network::Signet => 1,
        Network::Regtest => 1,
        net => panic!("Got unknown network: {net}!"),
    }
}

pub(crate) fn get_esplora_url(network: Network, user_provided_url: Option<String>) -> String {
    if let Some(url) = user_provided_url {
        url
    } else {
        match network {
            Network::Bitcoin => "https://mutiny.mempool.space/api",
            Network::Testnet => "https://mempool.space/testnet/api",
            Network::Signet => "https://mutinynet.com/api",
            Network::Regtest => "http://localhost:3003",
            net => panic!("Got unknown network: {net}!"),
        }
        .to_string()
    }
}

impl<S: MutinyStorage> WalletSource for OnChainWallet<S> {
    fn list_confirmed_utxos(&self) -> Result<Vec<Utxo>, ()> {
        let wallet = self.wallet.try_read().map_err(|_| ())?;
        let utxos = wallet
            .list_unspent()
            .map(|u| Utxo {
                outpoint: u.outpoint,
                output: u.txout,
                satisfaction_weight: 4 + 2 + 64,
            })
            .collect();

        Ok(utxos)
    }

    fn get_change_script(&self) -> Result<ScriptBuf, ()> {
        let mut wallet = self.wallet.try_write().map_err(|_| ())?;
        let addr = wallet.next_unused_address(KeychainKind::Internal).address;
        Ok(addr.script_pubkey())
    }

    fn sign_psbt(&self, mut psbt: Psbt) -> Result<Transaction, ()> {
        let wallet = self.wallet.try_read().map_err(|e| {
            log_error!(
                self.logger,
                "Could not get wallet lock to sign transaction: {e:?}"
            )
        })?;

        // need to trust witness_utxo for signing since that's LDK sets in the psbt
        let sign_options = SignOptions {
            trust_witness_utxo: true,
            ..Default::default()
        };
        wallet
            .sign(&mut psbt, sign_options)
            .map_err(|e| log_error!(self.logger, "Could not sign transaction: {e:?}"))?;

        psbt.extract_tx()
            .map_err(|e| log_error!(self.logger, "Extract signed transaction: {e:?}"))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::test_utils::*;
    use crate::{encrypt::encryption_key_from_pass, storage::MemoryStorage};
    use bip39::Mnemonic;
    use bitcoin::Address;
    use esplora_client::Builder;
    use std::str::FromStr;
    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};
    wasm_bindgen_test_configure!(run_in_browser);

    async fn create_wallet() -> OnChainWallet<MemoryStorage> {
        let mnemonic = Mnemonic::from_str("abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon about").expect("could not generate");
        let esplora = Arc::new(
            Builder::new("https://blockstream.info/testnet/api/")
                .build_async()
                .unwrap(),
        );
        let pass = uuid::Uuid::new_v4().to_string();
        let cipher = encryption_key_from_pass(&pass).unwrap();
        let db = MemoryStorage::new(Some(pass), Some(cipher), None);
        let logger = Arc::new(MutinyLogger::default());
        let fees = Arc::new(MutinyFeeEstimator::new(
            db.clone(),
            esplora.clone(),
            logger.clone(),
        ));
        let stop = Arc::new(AtomicBool::new(false));
        let xpriv = Xpriv::new_master(Network::Testnet, &mnemonic.to_seed("")).unwrap();

        OnChainWallet::new(
            xpriv,
            db,
            Network::Testnet,
            esplora,
            fees,
            stop,
            logger,
            None,
        )
        .unwrap()
    }

    #[test]
    async fn test_create_wallet() {
        let test_name = "create_wallet";
        log!("{}", test_name);
        let _wallet = create_wallet().await;
    }

    #[test]
    async fn test_label_psbt() {
        let test_name = "label_psbt";
        log!("{}", test_name);
        let wallet = create_wallet().await;

        let psbt = Psbt::from_str("cHNidP8BAKACAAAAAqsJSaCMWvfEm4IS9Bfi8Vqz9cM9zxU4IagTn4d6W3vkAAAAAAD+////qwlJoIxa98SbghL0F+LxWrP1wz3PFTghqBOfh3pbe+QBAAAAAP7///8CYDvqCwAAAAAZdqkUdopAu9dAy+gdmI5x3ipNXHE5ax2IrI4kAAAAAAAAGXapFG9GILVT+glechue4O/p+gOcykWXiKwAAAAAAAEHakcwRAIgR1lmF5fAGwNrJZKJSGhiGDR9iYZLcZ4ff89X0eURZYcCIFMJ6r9Wqk2Ikf/REf3xM286KdqGbX+EhtdVRs7tr5MZASEDXNxh/HupccC1AaZGoqg7ECy0OIEhfKaC3Ibi1z+ogpIAAQEgAOH1BQAAAAAXqRQ1RebjO4MsRwUPJNPuuTycA5SLx4cBBBYAFIXRNTfy4mVAWjTbr6nj3aAfuCMIAAAA").unwrap();

        // set label for input
        let input_addr = Address::from_str("2Mx6uYKYGW5J6sV59e5NsdtCTsJYRxednbx")
            .unwrap()
            .assume_checked();
        let prev_label = "previous".to_string();
        wallet
            .storage
            .set_address_labels(input_addr, vec![prev_label])
            .unwrap();

        let send_to_addr = Address::from_str("mrKjeffvbnmKJURrLNdqLkfrptLrFtnkFx")
            .unwrap()
            .assume_checked();
        let change_addr = Address::from_str("mqfKJuj2Ea4RtXsKawQWrqosGeHFTrp6iZ")
            .unwrap()
            .assume_checked();
        let label = "test".to_string();

        let result = wallet.label_psbt(&psbt, vec![label.clone()]);
        assert!(result.is_ok());

        let expected_labels = vec![label.clone()];

        let addr_labels = wallet.storage.get_address_labels().unwrap();
        assert_eq!(addr_labels.len(), 3);
        assert_eq!(
            addr_labels.get(&send_to_addr.to_string()),
            Some(&expected_labels)
        );
        assert_eq!(
            addr_labels.get(&change_addr.to_string()),
            Some(&expected_labels)
        );

        let label = wallet.storage.get_label(&label).unwrap();
        assert!(label.is_some());
        assert_eq!(label.clone().unwrap().addresses.len(), 2);
        assert!(label
            .clone()
            .unwrap()
            .addresses
            .contains(&send_to_addr.to_string()));
        assert!(label.unwrap().addresses.contains(&change_addr.to_string()));
    }
}


================================================
File: mutiny-core/src/peermanager.rs
================================================
use crate::keymanager::PhantomKeysManager;
use crate::messagehandler::MutinyMessageHandler;
#[cfg(target_arch = "wasm32")]
use crate::networking::socket::{schedule_descriptor_read, MutinySocketDescriptor};
use crate::node::{NetworkGraph, OnionMessenger, PendingConnections};
use crate::storage::MutinyStorage;
use crate::utils::{self, sleep};
use crate::{error::MutinyError, fees::MutinyFeeEstimator};
use crate::{gossip, ldkstorage::PhantomChannelManager, logging::MutinyLogger};
use crate::{gossip::read_peer_info, node::PubkeyConnectionInfo};
use bitcoin::key::{Secp256k1, Verification};
use bitcoin::secp256k1::{PublicKey, Signing};
use lightning::blinded_path::message::{BlindedMessagePath, MessageContext};
use lightning::blinded_path::IntroductionNode;
use lightning::events::{MessageSendEvent, MessageSendEventsProvider};
use lightning::ln::features::{InitFeatures, NodeFeatures};
use lightning::ln::msgs;
use lightning::ln::msgs::{LightningError, RoutingMessageHandler};
use lightning::ln::peer_handler::PeerManager as LdkPeerManager;
use lightning::ln::peer_handler::{APeerManager, PeerHandleError};
use lightning::onion_message::messenger::{Destination, MessageRouter, OnionMessagePath};
use lightning::routing::gossip::NodeId;
use lightning::util::logger::Logger;
use lightning::{ln::msgs::SocketAddress, log_warn};
use lightning::{log_debug, log_error};
use std::sync::atomic::AtomicBool;
use std::sync::Arc;

#[cfg(target_arch = "wasm32")]
use crate::networking::ws_socket::WsTcpSocketDescriptor;

#[cfg(target_arch = "wasm32")]
use lightning::ln::peer_handler::SocketDescriptor as LdkSocketDescriptor;

#[cfg(target_arch = "wasm32")]
use crate::networking::proxy::WsProxy;

#[allow(dead_code)]
pub trait PeerManager: Send + Sync + 'static {
    fn get_peer_node_ids(&self) -> Vec<PublicKey>;

    fn new_outbound_connection(
        &self,
        their_node_id: PublicKey,
        descriptor: AnySocketDescriptor,
        remote_network_address: Option<SocketAddress>,
    ) -> Result<Vec<u8>, PeerHandleError>;

    fn new_inbound_connection(
        &self,
        descriptor: AnySocketDescriptor,
        remote_network_address: Option<SocketAddress>,
    ) -> Result<(), PeerHandleError>;

    fn write_buffer_space_avail(
        &self,
        descriptor: &mut AnySocketDescriptor,
    ) -> Result<(), PeerHandleError>;

    fn read_event(
        &self,
        descriptor: &mut AnySocketDescriptor,
        data: &[u8],
    ) -> Result<bool, PeerHandleError>;

    fn process_events(&self);

    fn socket_disconnected(&self, descriptor: &mut AnySocketDescriptor);

    fn disconnect_by_node_id(&self, node_id: PublicKey);

    fn disconnect_all_peers(&self);

    fn timer_tick_occurred(&self);

    fn broadcast_node_announcement(
        &self,
        rgb: [u8; 3],
        alias: [u8; 32],
        addresses: Vec<SocketAddress>,
    );
}

#[cfg(target_arch = "wasm32")]
type AnySocketDescriptor = MutinySocketDescriptor;

#[cfg(not(target_arch = "wasm32"))]
type AnySocketDescriptor = lightning_net_tokio::SocketDescriptor;

pub(crate) type PeerManagerImpl<S: MutinyStorage> = LdkPeerManager<
    AnySocketDescriptor,
    Arc<PhantomChannelManager<S>>,
    Arc<GossipMessageHandler<S>>,
    Arc<OnionMessenger<S>>,
    Arc<MutinyLogger>,
    Arc<MutinyMessageHandler<S>>,
    Arc<PhantomKeysManager<S>>,
>;

impl<S: MutinyStorage> PeerManager for PeerManagerImpl<S> {
    fn get_peer_node_ids(&self) -> Vec<PublicKey> {
        self.list_peers()
            .into_iter()
            .map(|x| x.counterparty_node_id)
            .collect()
    }

    fn new_outbound_connection(
        &self,
        their_node_id: PublicKey,
        descriptor: AnySocketDescriptor,
        remote_network_address: Option<SocketAddress>,
    ) -> Result<Vec<u8>, PeerHandleError> {
        self.new_outbound_connection(their_node_id, descriptor, remote_network_address)
    }

    fn new_inbound_connection(
        &self,
        descriptor: AnySocketDescriptor,
        remote_network_address: Option<SocketAddress>,
    ) -> Result<(), PeerHandleError> {
        self.new_inbound_connection(descriptor, remote_network_address)
    }

    fn write_buffer_space_avail(
        &self,
        descriptor: &mut AnySocketDescriptor,
    ) -> Result<(), PeerHandleError> {
        self.write_buffer_space_avail(descriptor)
    }

    fn read_event(
        &self,
        peer_descriptor: &mut AnySocketDescriptor,
        data: &[u8],
    ) -> Result<bool, PeerHandleError> {
        self.read_event(peer_descriptor, data)
    }

    fn process_events(&self) {
        self.process_events()
    }

    fn socket_disconnected(&self, descriptor: &mut AnySocketDescriptor) {
        self.socket_disconnected(descriptor)
    }

    fn disconnect_by_node_id(&self, node_id: PublicKey) {
        self.disconnect_by_node_id(node_id)
    }

    fn disconnect_all_peers(&self) {
        self.disconnect_all_peers()
    }

    fn timer_tick_occurred(&self) {
        self.timer_tick_occurred()
    }

    fn broadcast_node_announcement(
        &self,
        rgb: [u8; 3],
        alias: [u8; 32],
        addresses: Vec<SocketAddress>,
    ) {
        self.broadcast_node_announcement(rgb, alias, addresses)
    }
}

#[derive(Clone)]
pub struct GossipMessageHandler<S: MutinyStorage> {
    pub(crate) storage: S,
    pub(crate) network_graph: Arc<NetworkGraph>,
    pub(crate) logger: Arc<MutinyLogger>,
}

impl<S: MutinyStorage> MessageSendEventsProvider for GossipMessageHandler<S> {
    fn get_and_clear_pending_msg_events(&self) -> Vec<MessageSendEvent> {
        Vec::new()
    }
}

impl<S: MutinyStorage> RoutingMessageHandler for GossipMessageHandler<S> {
    fn handle_node_announcement(
        &self,
        msg: &msgs::NodeAnnouncement,
    ) -> Result<bool, LightningError> {
        // We use RGS to sync gossip, but we can save the node's metadata (alias and color)
        // we should only save it for relevant peers however (i.e. peers we have a channel with)
        let node_id = msg.contents.node_id;
        if read_peer_info(&self.storage, &node_id)
            .ok()
            .flatten()
            .is_some()
        {
            if let Err(e) = gossip::save_ln_peer_info(&self.storage, &node_id, &msg.clone().into())
            {
                log_warn!(
                    self.logger,
                    "Failed to save node announcement for {node_id}: {e}"
                );
            }
        }

        // because we got the announcement, may as well update our network graph
        self.network_graph
            .update_node_from_unsigned_announcement(&msg.contents)?;

        Ok(false)
    }

    fn handle_channel_announcement(
        &self,
        msg: &msgs::ChannelAnnouncement,
    ) -> Result<bool, LightningError> {
        // because we got the channel, may as well update our network graph
        self.network_graph
            .update_channel_from_announcement_no_lookup(msg)?;
        Ok(false)
    }

    fn handle_channel_update(&self, msg: &msgs::ChannelUpdate) -> Result<bool, LightningError> {
        // because we got the update, may as well update our network graph
        self.network_graph.update_channel_unsigned(&msg.contents)?;
        Ok(false)
    }

    fn get_next_channel_announcement(
        &self,
        _starting_point: u64,
    ) -> Option<(
        msgs::ChannelAnnouncement,
        Option<msgs::ChannelUpdate>,
        Option<msgs::ChannelUpdate>,
    )> {
        None
    }

    fn get_next_node_announcement(
        &self,
        _starting_point: Option<&NodeId>,
    ) -> Option<msgs::NodeAnnouncement> {
        None
    }

    fn peer_connected(
        &self,
        _their_node_id: &PublicKey,
        _init: &msgs::Init,
        _inbound: bool,
    ) -> Result<(), ()> {
        Ok(())
    }

    fn handle_reply_channel_range(
        &self,
        _their_node_id: &PublicKey,
        _msg: msgs::ReplyChannelRange,
    ) -> Result<(), LightningError> {
        Ok(())
    }

    fn handle_reply_short_channel_ids_end(
        &self,
        _their_node_id: &PublicKey,
        _msg: msgs::ReplyShortChannelIdsEnd,
    ) -> Result<(), LightningError> {
        Ok(())
    }

    fn handle_query_channel_range(
        &self,
        _their_node_id: &PublicKey,
        _msg: msgs::QueryChannelRange,
    ) -> Result<(), LightningError> {
        Ok(())
    }

    fn handle_query_short_channel_ids(
        &self,
        _their_node_id: &PublicKey,
        _msg: msgs::QueryShortChannelIds,
    ) -> Result<(), LightningError> {
        Ok(())
    }

    fn processing_queue_high(&self) -> bool {
        false
    }

    fn provided_node_features(&self) -> NodeFeatures {
        NodeFeatures::empty()
    }

    fn provided_init_features(&self, _their_node_id: &PublicKey) -> InitFeatures {
        let mut features = InitFeatures::empty();
        features.set_gossip_queries_optional();
        features
    }
}

/// LDK currently can't route onion messages, so we need to do it ourselves
/// We just assume they are connected to us or the LSP.
pub struct LspMessageRouter {
    intermediate_nodes: Vec<PublicKey>,
}

impl LspMessageRouter {
    pub fn new(lsp_pubkey: Option<PublicKey>) -> Self {
        let intermediate_nodes = match lsp_pubkey {
            Some(pubkey) => vec![pubkey],
            None => vec![],
        };

        Self { intermediate_nodes }
    }
}

impl MessageRouter for LspMessageRouter {
    fn find_path(
        &self,
        _sender: PublicKey,
        peers: Vec<PublicKey>,
        destination: Destination,
    ) -> Result<OnionMessagePath, ()> {
        let first_node = match &destination {
            Destination::Node(node_id) => Some(*node_id),
            Destination::BlindedPath(path) => match path.introduction_node() {
                IntroductionNode::DirectedShortChannelId(..) => None,
                IntroductionNode::NodeId(node_id) => Some(*node_id),
            },
        };

        if first_node.is_none() || first_node.is_some_and(|node| peers.contains(&node)) {
            Ok(OnionMessagePath {
                intermediate_nodes: vec![],
                destination,
                first_node_addresses: None,
            })
        } else {
            Ok(OnionMessagePath {
                intermediate_nodes: self.intermediate_nodes.clone(),
                destination,
                first_node_addresses: None,
            })
        }
    }

    fn create_blinded_paths<T: Signing + Verification>(
        &self,
        _recipient: PublicKey,
        _context: MessageContext,
        _peers: Vec<PublicKey>,
        _secp_ctx: &Secp256k1<T>,
    ) -> Result<Vec<BlindedMessagePath>, ()> {
        // Bolt12 not yet supported
        Err(())
    }
}

#[allow(clippy::too_many_arguments)]
pub(crate) async fn connect_peer_if_necessary<
    S: MutinyStorage,
    P: PeerManager + APeerManager<Descriptor = AnySocketDescriptor>,
>(
    #[cfg(target_arch = "wasm32")] websocket_proxy_addr: &str,
    peer_connection_info: &PubkeyConnectionInfo,
    storage: &S,
    logger: Arc<MutinyLogger>,
    peer_manager: Arc<P>,
    pending_connections: PendingConnections,
    fee_estimator: Arc<MutinyFeeEstimator<S>>,
    stop: Arc<AtomicBool>,
) -> Result<(), MutinyError> {
    // do not connect to same peer within 5 secs
    const IGNORE_CONN_SECS: u32 = 5;

    if peer_manager
        .get_peer_node_ids()
        .contains(&peer_connection_info.pubkey)
    {
        return Ok(());
    }

    let node_id = NodeId::from_pubkey(&peer_connection_info.pubkey);

    let mut retries = 0;
    let max_retries = 10;
    while retries < max_retries {
        match pending_connections.try_lock() {
            Some(mut pending) => {
                log_debug!(logger, "get pending connections");
                let now_secs = utils::now().as_secs() as u32;
                let pending_expire_secs = now_secs - IGNORE_CONN_SECS;
                if pending
                    .get(&node_id)
                    .is_some_and(|&last| pending_expire_secs < last)
                {
                    log_debug!(logger, "Ignoring connection request to {node_id}");
                    return Ok(());
                }

                // save pending connections
                pending.insert(node_id, now_secs);

                // clear expired pending connections
                if pending.len() > 20 {
                    pending.retain(|_, last| pending_expire_secs < *last);
                }
                break;
            }
            None if retries > max_retries => {
                log_error!(logger, "Can't get pending connections lock");
                return Err(MutinyError::ConnectionFailed);
            }
            None => {
                retries += 1;
                log_debug!(logger, "Can't get pending connections lock {retries}");
                sleep(200).await;
                continue;
            }
        };
    }

    // make sure we have the device lock before connecting
    // otherwise we could cause force closes.
    // If we didn't have the lock last, we need to panic because
    // the state could have changed.
    if let Some(lock) = storage.fetch_device_lock().await? {
        let id = storage.get_device_id()?;
        if !lock.is_last_locker(&id) {
            log_warn!(
                logger,
                "Lock has changed (remote: {}, local: {})! Aborting since state could be outdated",
                lock.device,
                id
            );
            panic!("Lock has changed! Aborting since state could be outdated")
        }
    }

    // first check to see if the fee rate is mostly up to date
    // if not, we need to have updated fees or force closures
    // could occur due to UpdateFee message conflicts.
    fee_estimator.update_fee_estimates_if_necessary().await?;

    #[cfg(target_arch = "wasm32")]
    let ret = connect_peer(
        #[cfg(target_arch = "wasm32")]
        websocket_proxy_addr,
        peer_connection_info,
        logger,
        peer_manager,
        stop,
    )
    .await;

    #[cfg(not(target_arch = "wasm32"))]
    let ret = match lightning_net_tokio::connect_outbound(
        peer_manager.clone(),
        peer_connection_info.pubkey,
        peer_connection_info.socket_address()?,
    )
    .await
    {
        None => {
            lightning::log_error!(
                logger,
                "Connection to peer timed out: {:?}",
                peer_connection_info
            );
            Err(MutinyError::ConnectionFailed)
        }
        Some(connection_closed_future) => {
            // spawn a task to wait for the connection to close
            let mut connection_closed_future = Box::pin(connection_closed_future);
            let pubkey = peer_connection_info.pubkey;
            crate::utils::spawn(async move {
                loop {
                    // If we are stopped, exit the loop
                    if stop.load(std::sync::atomic::Ordering::Relaxed) {
                        break;
                    }

                    tokio::select! {
                        _ = &mut connection_closed_future => break,
                        _ = tokio::time::sleep(std::time::Duration::from_secs(1)) => {},
                    }

                    // make sure they are still a peer
                    if peer_manager
                        .get_peer_node_ids()
                        .iter()
                        .any(|id| *id == pubkey)
                    {
                        break;
                    }
                }
            });

            Ok(())
        }
    };

    ret
}

#[cfg(target_arch = "wasm32")]
async fn connect_peer<P: PeerManager>(
    #[cfg(target_arch = "wasm32")] websocket_proxy_addr: &str,
    peer_connection_info: &PubkeyConnectionInfo,
    logger: Arc<MutinyLogger>,
    peer_manager: Arc<P>,
    stop: Arc<AtomicBool>,
) -> Result<(), MutinyError> {
    let (mut descriptor, socket_addr_opt) = match peer_connection_info.connection_type {
        crate::node::ConnectionType::Tcp(ref t) => {
            let proxy = WsProxy::new(
                websocket_proxy_addr,
                peer_connection_info.clone(),
                logger.clone(),
            )
            .await?;
            let (_, net_addr) = try_parse_addr_string(t);
            (
                AnySocketDescriptor::Tcp(WsTcpSocketDescriptor::new(proxy)),
                net_addr,
            )
        }
    };

    // then give that connection to the peer manager
    let initial_bytes = peer_manager.new_outbound_connection(
        peer_connection_info.pubkey,
        descriptor.clone(),
        socket_addr_opt,
    )?;

    lightning::log_debug!(logger, "connected to peer: {:?}", peer_connection_info);

    let sent_bytes = descriptor.send_data(&initial_bytes, true);
    lightning::log_trace!(
        logger,
        "sent {sent_bytes} to node: {}",
        peer_connection_info.pubkey
    );

    // schedule a reader on the connection
    schedule_descriptor_read(
        descriptor,
        peer_manager.clone(),
        logger.clone(),
        stop.clone(),
    );

    Ok(())
}

#[cfg(target_arch = "wasm32")]
fn try_parse_addr_string(addr: &str) -> (Option<std::net::SocketAddr>, Option<SocketAddress>) {
    use std::net::SocketAddr;
    let socket_addr = addr.parse::<SocketAddr>().ok();
    let net_addr = socket_addr.map(|socket_addr| match socket_addr {
        SocketAddr::V4(sockaddr) => SocketAddress::TcpIpV4 {
            addr: sockaddr.ip().octets(),
            port: sockaddr.port(),
        },
        SocketAddr::V6(sockaddr) => SocketAddress::TcpIpV6 {
            addr: sockaddr.ip().octets(),
            port: sockaddr.port(),
        },
    });
    (socket_addr, net_addr)
}


================================================
File: mutiny-core/src/scorer.rs
================================================
use crate::{logging::MutinyLogger, node::NetworkGraph};
use lightning::blinded_path::IntroductionNode;
use lightning::routing::router::CandidateRouteHop;
use lightning::{
    routing::{
        gossip::NodeId,
        router::Path,
        scoring::{
            ChannelUsage, ProbabilisticScorer, ProbabilisticScoringFeeParameters, ScoreLookUp,
            ScoreUpdate,
        },
    },
    util::ser::{Writeable, Writer},
};
use std::time::Duration;
use std::{collections::HashSet, str::FromStr, sync::Arc};

const HUB_BASE_DISCOUNT_PENALTY_MSAT: u64 = 100_000;

const PUBKEYS: [&str; 251] = [
    "03aefa43fbb4009b21a4129d05953974b7dbabbbfb511921410080860fca8ee1f0", // Voltage Flow 2.0
    "035e4ff418fc8b5554c5d9eea66396c227bd429a3251c8cbc711002ba215bfc226",
    "02f1a8c87607f415c8f22c00593002775941dea48869ce23096af27b0cfdcc0b69",
    "024bfaf0cabe7f874fd33ebf7c6f4e5385971fc504ef3f492432e9e3ec77e1b5cf",
    "033878501f9a4ce97dba9a6bba4e540eca46cb129a322eb98ea1749ed18ab67735",
    "03423790614f023e3c0cdaa654a3578e919947e4c3a14bf5044e7c787ebd11af1a",
    "02e4971e61a3f55718ae31e2eed19aaf2e32caf3eb5ef5ff03e01aa3ada8907e78",
    "0326e692c455dd554c709bbb470b0ca7e0bb04152f777d1445fd0bf3709a2833a3",
    "03a93b87bf9f052b8e862d51ebbac4ce5e97b5f4137563cd5128548d7f5978dda9",
    "033b63e4a9931dc151037acbce12f4f8968c86f5655cf102bbfa85a26bd4adc6d9",
    "0203e5b16ebe87b089f22e18752f1f7a66a1bdf77879df8d1c9e8d912dbfb9beb4",
    "02f460ae6d3d3e104f8afe520ae0cff3d94c35c2ba8df66da89f3c8006a265b90a",
    "033d9e73a183c9714545f292875fb90c4372bddc9c2cc302b265d15e7969a5ed60",
    "03ec512342aeee370b53d9fd12dbd5283dcd670d248018b3a1cf537313e76e6a2d",
    "037f990e61acee8a7697966afd29dd88f3b1f8a7b14d625c4f8742bd952003a590",
    "039cdd937f8d83fb2f78c8d7ddc92ae28c9dbb5c4827181cfc80df60dee1b7bf19",
    "02dfe525d9c5b4bb52a55aa3d67115fa4a6326599c686dbd1083cffe0f45c114f8",
    "027ce055380348d7812d2ae7745701c9f93e70c1adeb2657f053f91df4f2843c71",
    "02bce4f7ae5b2d51c18575b3f277e296d9df800a54d749d7a3145c9e40237e4011",
    "02a0f17d3ddb81b3b0c048956baebdf68468c9d7c8b851e5d26354a64a54cff562",
    "03dc686001f9b1ff700dfb8917df70268e1919433a535e1fb0767c19223509ab57",
    "03f5dcf253ca5ab4a8a0ad27bc5d8787ca920610902425b060311530cb511e9545",
    "037f66e84e38fc2787d578599dfe1fcb7b71f9de4fb1e453c5ab85c05f5ce8c2e3",
    "0261239197442bda65c9933359bbcba72e89f3e77ca87edd7be2e4bf7ba9218117",
    "03f94b8e82c3c9be8f8d1e3bcb595e2855b72f23b92967c26f7d65be9a75184c12",
    "029efe15ef5f0fcc2fdd6b910405e78056b28c9b64e1feff5f13b8dce307e67cad",
    "034a879c36f418cb5b44b6903b3c6c1cfb5f4beb1e79b9b479c040b7df9cbc56be",
    "03011e480a671ac71dbc3fc3e8fe0db32bb9a10cc4d824663e09557d446ef80679",
    "037e27d212432eaf499e4fb648d996944f3454c094dab36336bac573f82211a335",
    "0298f6074a454a1f5345cb2a7c6f9fce206cd0bf675d177cdbf0ca7508dd28852f",
    "0294ac3e099def03c12a37e30fe5364b1223fd60069869142ef96580c8439c2e0a",
    "034ea80f8b148c750463546bd999bf7321a0e6dfc60aaf84bd0400a2e8d376c0d5",
    "03e81689bfd18d0accb28d720ed222209b1a5f2c6825308772beac75b1fe35d491",
    "03b006c37dfb8681e5db9f513386d06c9d18bd514fae5d79a7ed2d5991c7d57330",
    "025e9497188d33af48bb15cfc3cd6d7c549eed05b5f54d45615d3cb7ec3b562588",
    "033dee9c6a0afc40ffd8f27d68ef260f3e5e1c19e59c6f9bb607fb04c1d497a809",
    "0288be11d147e1525f7f234f304b094d6627d2c70f3313d7ba3696887b261c4447",
    "0334bbf89f5fc82c8aebbddc9f2b78f9528cd2fd916fbc091a8ce35aed57c1110d",
    "033d8656219478701227199cbd6f670335c8d408a92ae88b962c49d4dc0e83e025",
    "03e9c99fddf5aaa60e22c166622206947b1fb14ae2926f550f837af6aa83556bb8",
    "03afa7a8196dbca763ee6f9a34b634a7adc03f154e5d6979fe654db5606b5fb2b1",
    "0250baf7a558091eb9c93f43d595b795db61bd2b55ca016d8682fd310cb1b81e6c",
    "031633471d005f37252ede8114c6f4203e0a668270532f0f11a1e4072eb2eef272",
    "03037dc08e9ac63b82581f79b662a4d0ceca8a8ca162b1af3551595b8f2d97b70a",
    "03d06758583bb5154774a6eb221b1276c9e82d65bbaceca806d90e20c108f4b1c7",
    "03641a88d80a2a85bbecd770577aca9b5495616e9fef63d66ef2631b7cca1d395d",
    "037659a0ac8eb3b8d0a720114efc861d3a940382dcfa1403746b4f8f6b2e8810ba",
    "03abf6f44c355dec0d5aa155bdbdd6e0c8fefe318eff402de65c6eb2e1be55dc3e",
    "02e9046555a9665145b0dbd7f135744598418df7d61d3660659641886ef1274844",
    "035542f0f213a5b6e985dff0e0fd973da01bd77325d44242fc325d0ea8eea3d312",
    "0299797daa21faa6e4151517b286c41d4c7a8cb21fbfba59ca3bcd21a9f8392bd4",
    "026e44acf41fcfa19d092a297a7e8452f6ac5eee677ed0f7f2e5d4c7c632467224",
    "02f4c77dcf12255ccf705c18b8d6b95e4f884910bf61e8aa21242607193a79da1b",
    "021fa607f2b6ceebe5742aaa7650cf817351e7d70cf47595a48ffd2e5741076b06",
    "03362ab599d1e8d5e8e02ce38e836a3cf1a6e59f047d7f02d12484f160a6bc76f6",
    "037c65e34444c37deaccde1f61f03b93e22b3d7451894d836f60132ee5a6f486ed",
    "0289753f4559770003baec773453f8d1b2dfae3256546891e4cfef3a0bdbaa4f30",
    "03bd6d28432d67effa2b2b89dd5fd68697940e8a8f2fbb84aaae90d584295b03bf",
    "0335bd24a733d623205f30452c485de9c39ac3135f57679574a49a3add6bb1a050",
    "03b4b86f2301fe2b9ca478ee5980d812de2071a21a9f8f5bb49b88e29a034e1a9b",
    "031c7ecff228dfe6054307ee49c8616998af5f8d4436f13c07d211aeb6c0ec87f7",
    "0293a4a5933422fa7cae2c8ff4c44490f26cf3dd7ac02b826ee20d4cba7dac944d",
    "0242c1650f320c43f3600ebf3b5fcaf566760fcd421f35b68fd1e39a31b29ef540",
    "023d49fd88692d4d1f366ee8ffa9dfe979c2266b036b440928e86cf3abe28d1894",
    "0391e2edea5191627a25ecbd327c0dc2a95c880a5b0e73af38dc4a5a8964263b3f",
    "02ac10d3b0a3da8434898323f75b97281e157fd858c2fb761d1994941aac515d1c",
    "033d38e07e2541628214c8184cf6c562311059872363e9f538b2f45434418b5bc5",
    "03d35779ff612c574b92494d74300ce467e0eb510181a6ae3eb74d8ada891d82aa",
    "03c72f89b660de43fc5c77ef879cbf7846601af88befb80e436242909b14fd0495",
    "023cd6704ce78644a568fbd993f65dc76fb1bf8bcce4c912930447c71d0c2698ad",
    "0380030304baea090616a296674b6ae337a138593b5390266a45a17eef7a62a2b0",
    "03d6f80df785288de2fe5de19f24ba8a1db3d20647a88d0a903be9de3e7bb8fce1",
    "021f98b9898720f8633c93faf0aa54ab399d277464e502d1111b233c2cf4064828",
    "022618bb95c7cd788a4f2d54e638d73212ffce867e1714734b2b65bac5274635ad",
    "0208dfa005c47a8ae85363d12c54007a38550ca0d6f1c559ee11caaac8221eccd6",
    "0317983322379d859c0d43a90c8dcd3e7239b8e0671b00a657ce3924d4498f3754",
    "02439112f98b6f4828e1a7426bfbece166bd36837d7dea4225a75ebd1d96864a07",
    "0379221a4051d4171490e43e4a09e218a02941f06996b71cd814b290da08ad5f7e",
    "02b21ca992bf95e3f324302265ad86cec24f36166fd7afca44efa0809aaa8b25c5",
    "0380ef0209ff1b46c38a37cd40f613d1dae3eba481a909459d6c1434a0e56e5d8c",
    "0385b81d9661adf36c086be5217a03c29a4276c0b5c9e607c745a239bba430d63f",
    "0260fab633066ed7b1d9b9b8a0fac87e1579d1709e874d28a0d171a1f5c43bb877",
    "0340cfadaa3324e0dd176a9969be050114278f93260e1b6333bd2a2a2ea03c64a3",
    "02bb10aaa77a95a358cebb2d112c4de00e47c08f56e89b1acb4487ddd44cc98d6d",
    "03d2e20bc19d995098ba357157a9cfbfbfdff4b78fce5ec713128e988e0115d776",
    "030a58b8653d32b99200a2334cfe913e51dc7d155aa0116c176657a4f1722677a3",
    "02ec20f34bb94460f3d63780dfc24a4d4a1ddabc3bd86c09e1830c5b5db08953e5",
    "02ff30e83896d453cfc89ff4dd06d23d793b7246f154c210324adc1d42c849ce74",
    "02d695b01c7a6909e716c863fb39bc5fb7bbdc3824b7fdce53adc593e5be080e73",
    "0340f8fa6bc058df204691bc1c965de041e550d8ef0512d22007d4cab7ebd7a536",
    "03ef1f35c48695828f614ac685fd5eead1005641cac453ed31052b0ef6cb959a60",
    "03c792f6a89fefd3f1b49b3d2ce23143b6f18d36b2ccb039fdb7dbfeb29159bb70",
    "0229ec1dfd9ae232fcd75e49a4f1112a59f688705e25ecbcc0d56e15a3994c9dfe",
    "03aab7e9327716ee946b8fbfae039b0db85356549e72c5cca113ea67893d0821e5",
    "026af41af0e3861ba170cc0eef8f45a1015125dac57c28df53752dcaeea793b28f",
    "03f3643570433b67f22ef1c2e7660e33c9b9d53f786cb1779544983aa5c8f286e3",
    "0337694505123a12a8fadd95523dcc235898ad3b80a06e4a63ca26fed68dd0d17c",
    "036eb65676a65660e4c1ffd728d88b3d82d027d416fad59867471fe2123de0ab27",
    "023e09c43b215bd3dbf483bcb409da3322ea5ea3b046f74698b89ee9ea785dd30a",
    "03e9cbcd46bd7de2a1559777e7f0c6681522a9b1821b994923da748e06b796cab0",
    "02916bb52b33836e28a3649baea2e4a29c16fd8ad97901b2c97d408f428edef108",
    "02826f50035eca93c7ebfbad4f9621a8eb201f4e28f994db5b6b5af32a65efb6b9",
    "039311d5a11e1df479bfc695b09127f7920e66dacfb19f0ef20a28a2a7959f0080",
    "026165850492521f4ac8abd9bd8088123446d126f648ca35e60f88177dc149ceb2",
    "03a465772d45616bf6c8450a69191db8f3cf8cca19ff92138735fd5f1d436fe4dc",
    "03bcf1f73199ed4445a8d6c033dd8cb550bb5205a16982ad2e13359e3318498c02",
    "0204a91bb5802ad0a799acfd86ef566da03d80cc9e13acb01e680634bf64188a0d",
    "02fcc5bfc48e83f06c04483a2985e1c390cb0f35058baa875ad2053858b8e80dbd",
    "02ad4afb6e50ae4635ec5ddf5a57c44d4cc4b376ac6580f78cda0454a86e5fa6c2",
    "02bc400b9df471549c1a2071a61be27460e9726d3399370671514dd8356606bd81",
    "02fb79c3a9121d85b126687bd111eaebf21aaaaa5cbf232e2b6c3bdf8803f40182",
    "02fe6a27ddcb2dd9fa8479fe1d52549b5932079a493b51f1409fa2c5878f1bc07c",
    "0351fabd839e93962826ab8eff7f86795b66b7295a2330773938d409a725aa8176",
    "02c91d6aa51aa940608b497b6beebcb1aec05be3c47704b682b3889424679ca490",
    "03df3f0a2fd6bea5429a596461ce784c922b2981ada1af89cfefcd9ccfb16c16a7",
    "033533e2db6311c1d417d41279c067d8713ad8a7d577a0d91e65df2f6a82c5b862",
    "035360b3bf6a997ed1bb943ccca2b7ef969b1e25a1ee1322d3c8acca7e34468edd",
    "0254bb156ecd0eac318844415a91a377bc6947ea4c9fbe5d248e563c29a1662835",
    "0333175e2ddb8ae3fab14125c312cf62b9da6dc54fc922edd1aa11e4e059496594",
    "0288f320d25b20df0578af737ea951c1c3adcc4e8cd908d5a291bddc49981a1cdf",
    "03bc77779d860e8b231d307c109bee12fa8f7949ca01273f296548fbe50c063dad",
    "033b277b17cf7c70fd4de5cbe8dcaeda0cd63d44fcd680f82f76dcac2ebad10c2f",
    "021f1beed0a32fb740e9c8ea12702dd4371b444a6464368d93a2957b95f8cd2db1",
    "02f63f49339c8b438c3291ab21e35d1b5642ac2360240068b5ecd3fd5183f2c042",
    "021a7a31f03a9b49807eb18ef03046e264871a1d03cd4cb80d37265499d1b726b9",
    "036b53093df5a932deac828cca6d663472dbc88322b05eec1d42b26ab9b16caa1c",
    "036508f7e82bb78bad307cfacf4edf850fc3f20ca071eaa8074d9d5424a9092c0b",
    "023662f1db3d0527dab0869e30f183021db7dc44f6f2e32ece42dd124846c89ca1",
    "02aace31b8120e29cfc29d991b63fe8614cddd3fbf6148431cc3a68932c363ed29",
    "03e86afe389d298f8f53a2f09fcc4d50cdd34e2fbd8f32cbd55583c596413705c2",
    "03cde60a6323f7122d5178255766e38114b4722ede08f7c9e0c5df9b912cc201d6",
    "030995c0c0217d763c2274aa6ed69a0bb85fa2f7d118f93631550f3b6219a577f5",
    "035fed4182fbd0725264f8a0018cabb6b25514dd231291162ac8dd63afb278e9e8",
    "03501a74753e0f6ae270a1e4e2ffbbc37f7a796360e650c1121c18e116b22ac106",
    "02343c19a39dd11cfc6f7571f36213dd52fb70ee45ee4074913d43891fb59579b5",
    "028ed7bd6ba6763cf040869681890bf5bf95d623108a60e75d76a57f5d637be3ef",
    "0285d50bc04a6a7eaeb37c4964d5f1322b1136c8cea2f242d3c52302226043cbe4",
    "03f80288f858251aed6f70142fab79dede5427a0ff4b618707bd0a616527a8cec7",
    "03f632d57f9c1ad729695f2c8c958b8d1d0b765fc99ea6f3fbe41b039397c49938",
    "029b81d1aaf177fa00c1c5796360163bfa98ee4d5d0daa54c6f510d9e237f376e9",
    "03127747aa9fb9b4813b7ebdd6ac47eb047954513ab06fe909689c2c42eaa49a33",
    "03864ef025fde8fb587d989186ce6a4a186895ee44a926bfc370e2c366597a3f8f",
    "020c92d71dfe47d49d322eed910064787973dff96c05a39d75a75d7e8f33aead4c",
    "02abfbe63425b1ba4f245af72a0a85ba16cd13365704655b2abfc13e53ad338e02",
    "03c157946cc1cd376b929e36006e645fae490b1b1d4156b40db804e01b4bda48cd",
    "026209a739dbf4ab8c73db56773a61247e92fecc53ec5c8f7ae41f6d11fec64a04",
    "03d4e028a0d4a90868ec202ab684fb0085779defea9ca7553e06146557631eec20",
    "021c3ec6432d2b9b5abcb01dd64b3a8f2afe3ba7d8c021f63ffd0a994cd3bc9b88",
    "027ecdd3c509f7db2d8ade67381bb2e8ed88ccbfab8805d24076c4a0fd131f71ff",
    "03f6ceaa67db2cc169fb8f74b762211e3ce20459bac52ac7f8c85f351670a6b678",
    "02df5ffe895c778e10f7742a6c5b8a0cefbe9465df58b92fadeb883752c8107c8f",
    "03cb68051b6faeda941420819446a9429053223a465d370642b2a88336c43b02dd",
    "03d83d26813669d8665d6a5017ecd18d176db0893f00f39e0a38493a1b6e3bbcd7",
    "0387d57be12709c8745bc35ac3dfc22611a944a12bcc1fe49a55d7c9bafea335f9",
    "025022f660d278b8d90415bdde1b385841b6caf179dc69569e4b55fd5aec70555f",
    "03f10c03894188447dbf0a88691387972d93416cc6f2f6e0c0d3505b38f6db8eb5",
    "02b515c74f334dee09821bee299fcbd9668182730c5719b25a8f262b28893198b0",
    "0305f5f4013f6c6eeb097bd8607204ec1f31577a05fae35f0d857c54d3b52e4e45",
    "02a2106a4681d68080cf3d8a3b706d6925142aee0caf99302e481dbb08feabfa1a",
    "031015a7839468a3c266d662d5bb21ea4cea24226936e2864a7ca4f2c3939836e0",
    "03676f530adb4df9f7f4981a8fb216571f2ce36c34cbefe77815c33d5aec4f2638",
    "036d89937841b3d34b70bc1e515dedd1082db048459733e3d3c62d7bca97fbf33e",
    "0355b39fb472045743c767e1f8de60128b9a68deeb5a834f343ed4968cf0193fc7",
    "02e2d1b40f08d2ca704c7f62397eec42245cb394d4a07db695ac5348dd24a527bd",
    "03dd09855c3634daa5c7de0146f4d54eb395b51ae422bc86ee1132a0d7ed50e720",
    "03698a61657d54ef3d43aff229da7037bdbea27654ed7fc043b439265132c52354",
    "02478e2fc963f74d0557a4bd821a743b18d51bbb589bfa124edf39aec95a65fc35",
    "024509d6321a579b3f72117509e243d6cdd86874cb0731ff39be6c92f3e64b53a1",
    "030ed412981860150762a3ec93d9e571442cbc0f2f7d3be1b3d047d7695e94c0c4",
    "035b1ff29e8db1ba8f2a4f4f95db239b54069cb949b8cde329418e2a83da4f1b30",
    "0296b2db342fcf87ea94d981757fdf4d3e545bd5cef4919f58b5d38dfdd73bf5c9",
    "03bb88ccc444534da7b5b64b4f7b15e1eccb18e102db0e400d4b9cfe93763aa26d",
    "02c73c8ac3f37bb28d9fc3819dc17baecdf24b137d476a2a9e22395d490d842bec",
    "03627ebe50fc6eb80b0caab0c3714958c701eda735e3c29588e83150d6d4a93976",
    "032434517e28f7b51665a525d5e11fa493bd4e30a59883b8156c2be4085f4aaf70",
    "0324ba2392e25bff76abd0b1f7e4b53b5f82aa53fddc3419b051b6c801db9e2247",
    "02758d961750972030292701d85c90e332bc1b7d8db0e705df3f087d285f9caf06",
    "03797da684da0b6de8a813f9d7ebb0412c5d7504619b3fa5255861b991a7f86960",
    "032a54b1e9cd2ff8ec5f58915a749cf074e957006e8b4da9c8497fed4b6c6f88dc",
    "021c97a90a411ff2b10dc2a8e32de2f29d2fa49d41bfbb52bd416e460db0747d0d",
    "0293e0945e225ebb21daaa846ccfc8f3f2c5e97421bed2b7f9d1fb11d96b8a3bf3",
    "02d3f41e090bd5b52eed0a9288705b248eb27afe995f02840cb8e7a2abc72580e2",
    "02c29b89b2121b2c1fa2e5422bc70e0bb7ae7326c7a9d2b796ed6b89cdc5a2871b",
    "0381499873090f47c7f857b90a91a5de4708054b5966904e0623023c9a5ad0e8a1",
    "0369a6185476b5d0372f526bc99d7614ff83fc0bfb11821b6e3c978ee64bcc865c",
    "0236333aacf54604abf218af6ab116d4fe6f16e527502e0019123d0cc3c7a8a194",
    "03f2005837649dd49811bbb7e78993581da41c09d3bdcbc6933492276acccd8b6d",
    "02e5544cda426d1dac8e5237e32eec59cbf93b88b76ef94ee7ecf8f76a5358fbbf",
    "0356c1091bb139ad3520eb370f1512ac2f4ed67b87d2687638252152fbf2b4575f",
    "021e9cd0d5417970eb15bfcda0b7628c8f49ef710603577776fa45c5b8ecbca35e",
    "03ef684e8c2ec25ea1a95fa46729e3355dd90210e0c57bad502d60676098ec83b3",
    "02a7792c657562b66bc87e5a2b98d32e8cd9fc16fab40cb67124472bf6b470beb8",
    "02fe3bf758f87d9b0cee6bdafa52d04650daea8c48f7178358b130b62e132c6f5f",
    "026d665c34210fd99f9d4be36bcfbd7d637ae890631274d1f82cbf45af8cd8b2c6",
    "03d6b14390cd178d670aa2d57c93d9519feaae7d1e34264d8bbb7932d47b75a50d",
    "021f0f2a5b46871b23f690a5be893f5b3ec37cf5a0fd8b89872234e984df35ea32",
    "03e472ddc37b014ce7d5f942b00b28fb1db53d461c4a89173962abd4b331a85179",
    "03e046abe9c7e7f963adf989c128fe187e59890314d0a30653a4498b13d197911c",
    "038ec8cd65fb69e147c2bd6de83f2ba57e312764cbeac2f594ae68d6b9c174f019",
    "03019e830b31e86befd057246e078933520a77bb93d2bb7923d4aca7682a845c45",
    "03a32622b5350eea6c5bb16a73ddfa07af452b17b47f0d2ec7d33db884fe074d83",
    "022eb09a7993a0edde69537b420f4119c0de833e0ee47651753b46bf884db75235",
    "02d0e03736cbfc73f3c005bc3770327df0e84bd69bc8e557c279887344deb8bce2",
    "029267159e8ed64dc44f1deda34c918f45c7ba2d6b2533a2c1083a2d15f5f4330a",
    "031f2669adab71548fad4432277a0d90233e3bc07ac29cfb0b3e01bd3fb26cb9fa",
    "028d98b9969fbed53784a36617eb489a59ab6dc9b9d77fcdca9ff55307cd98e3c4",
    "026ec3e3438308519a75ca4496822a6c1e229174fbcaadeeb174704c377112c331",
    "03a01da97af71f7859cd1b2b6a70f221ecd49f6eabf0bf1e267bae9570b47232a6",
    "028f4a60dd133875e8776d5ac36e87097cf59e6e3a1d74fcd14c900270dda57c06",
    "0289b70b52a04e951446674bedb571336295a2890ca0079639ebc067076277d571",
    "03fbe1c1baedbc99b2642ae524d9c2a6f12b771a3ab91e0f56ca6efc6f7f7d53b6",
    "036cb1a035eb1c7f125c004ed046d329285bd57e4100f18b577af721659becd832",
    "03820714a3f891c7c3ae5e00dbdd77f06ceccc24ddd8c99fadef13ec2eec462cce",
    "03808b1a698906bbf0457922aec66168a8edbfe98b1379249ace270b41ae0dde48",
    "0385218f0e307b6a0e989d2a717d346942d96b4fd550e937de5f8ffe1568510a18",
    "029a0f8111f0bcb94003413838451dfc1d0faed030ef46ff84d96c0dc5be3d1415",
    "020f7c502e19ccb375d4abc689f2c1feb6816961d4a1e2dcfa8813f11c3bc9a5e1",
    "024271a1be2d7a3e2a276b241257be734d843885d252f50575e4c7db2691aedd3a",
    "0201bfc5d9c14d50ebaf4dfd83d70df314ed2a9f0119f28619f3f000a1079ef580",
    "021ecaf18c177e308009b9bdbf0d6784536e027759f797d64300787a24e6528a7c",
    "03271338633d2d37b285dae4df40b413d8c6c791fbee7797bc5dc70812196d7d5c",
    "035eb7d2253d934b51dd1cc145b6f36a9c2d953c4379f5fff9c39bb437ece525ae",
    "03ac61c971d146787a036f75e80a9fbede238a75d0c396f1fe996def00f0ac5dbe",
    "0282888287c371a97b5e735ae21f85c80351c492741d57c96e43806e3654904262",
    "03284f74651198c2c35952a8e0204e68a824455f329f799c1368feb850572036e9",
    "02bc320249b608a53a76cf3cbd448fdd3ab8f3766f96e8649c2edc26cf03bf8277",
    "02918715f4981723ec82c3d7f50f6bf927a9145e592e9997cd7a97c87ef6bc7602",
    "03c65f59676fcb31951fe4c610f3a17612dc5a5c35d1f03733468e19277aad6f6b",
    "02c4ae20674d7627021639986d75988b5f17c8693ed43b794beeef2384d04e5bf1",
    "023369b071005d376bfa94b76d2ec52d01d6709f57d6b67bf26250f2ef57a66aea",
    "03193aa3b4db3ecb2025395e704e8e808f412914beb629270f7b902b9460539400",
    "03606d67d00ce06ad053de1f755e6f6c8185ae66a1b1e06ec7b72e2ef702690d5f",
    "0349cb2f33d5542432b016405a22dfda18617d87abe4718e61c45909b8a5449329",
    "021c4c58a15fa847720cbc02775df975c1dd6994be443f6eb1392275559c05db7f",
    "03d607f3e69fd032524a867b288216bfab263b6eaee4e07783799a6fe69bb84fac",
    "0231eccc6510eb2e1c97c8a190d6ea096784aa7c358355442055aac8b20654f932",
    "02db3bce6ad28505ec56254e3c27b912f3d3723d7573e3b4174368b80ebf8f2ba8",
    "026a0ae3ca9ff56a7d38e861022e3805c43f9285720d0990c9fe91eb494287f052",
    "027100442c3b79f606f80f322d98d499eefcb060599efc5d4ecb00209c2cb54190",
    "03391210b7fd47678df727ed7c39ea2f3c8dd43d6fb747582b1c13d4c1376f4714",
    "02c717cf27420cb5efc492921851c6c5b328502c37a9fd282d5d2f04364e466768",
    "030c6ace90f74ea293519469084a077ea49692e147b4d9c881b62c85f676d79eb4",
    "03f171125a76de0c957341488156993e3e6a603366021da31ef5811812b4881c81",
    "03a8b61013b27176c441cb7b6875b159d9dc1c270651e603447e93d5bbc78ffaa6",
    "038c5b2d6a0fe180d1be557d49f7f982190957edf20a4c05a305d7aed17c156ef0",
    "027e9c96bf2a2d9b5f9002bc4d4e4765ab525e4e1fb1ada702a4a64a1b40ccdb9d",
    "0325de5af4666d0ceee17c805817d02159fb2bc67f84c333372183b037294ffb2c",
    "020af8a7428f99ce4510e523031e2078c065c1097a48c860ae2cdd3511c8b7627d",
    "03b211f8a4a9cd40c9a1b5626bb8b0f1ca66b36e6b4fddd2723c67683d6f8d1ec7",
    "02ee60fef298e59b2ae4ff09642a62a1317c7baac97d51b1fc7e5581d1c6fef695",
    "0246ee8e4c965296799eebd29a0948b9a4641843298b0f2a8e42256c4b594e4b8f",
];

fn build_preferred_hubs_set() -> HashSet<NodeId> {
    PUBKEYS
        .iter()
        .map(|pubkey_str| NodeId::from_str(pubkey_str).expect("only pubkeys involved"))
        .collect()
}

pub type ProbScorer = ProbabilisticScorer<Arc<NetworkGraph>, Arc<MutinyLogger>>;

pub struct HubPreferentialScorer {
    inner: ProbScorer,
    preferred_hubs_set: HashSet<NodeId>,
}

impl HubPreferentialScorer {
    pub(crate) fn new(inner: ProbScorer) -> Self {
        Self {
            inner,
            preferred_hubs_set: build_preferred_hubs_set(),
        }
    }

    fn is_source_preferred_hub(&self, candidate: &CandidateRouteHop) -> bool {
        match candidate {
            CandidateRouteHop::FirstHop(_) => false, // source of first hop is us
            CandidateRouteHop::PublicHop(hop) => {
                self.preferred_hubs_set.contains(hop.info.source())
            }
            CandidateRouteHop::PrivateHop(hop) => {
                let source = hop.hint.src_node_id;
                let node_id = NodeId::from_pubkey(&source);
                self.preferred_hubs_set.contains(&node_id)
            }
            CandidateRouteHop::Blinded(hop) => {
                // we can prefer blinded paths with hub introduction points
                let path = hop.hint;
                if let IntroductionNode::NodeId(node_id) = path.introduction_node() {
                    self.preferred_hubs_set
                        .contains(&NodeId::from_pubkey(node_id))
                } else {
                    false
                }
            }
            CandidateRouteHop::OneHopBlinded(hop) => {
                // one hop is just the introduction node which is a known node id
                let path = hop.hint;
                if let IntroductionNode::NodeId(node_id) = path.introduction_node() {
                    self.preferred_hubs_set
                        .contains(&NodeId::from_pubkey(node_id))
                } else {
                    false
                }
            }
        }
    }

    fn is_target_preferred_hub(&self, candidate: &CandidateRouteHop) -> bool {
        match candidate {
            CandidateRouteHop::FirstHop(hop) => self.preferred_hubs_set.contains(hop.payer_node_id),
            CandidateRouteHop::PublicHop(hop) => {
                self.preferred_hubs_set.contains(hop.info.target())
            }
            CandidateRouteHop::PrivateHop(hop) => {
                self.preferred_hubs_set.contains(hop.target_node_id)
            }
            CandidateRouteHop::Blinded(_) => false, // the target of a blinded path is unknown
            CandidateRouteHop::OneHopBlinded(_) => false, // the target of a blinded path is unknown
        }
    }
}

impl ScoreLookUp for HubPreferentialScorer {
    type ScoreParams = ProbabilisticScoringFeeParameters;

    fn channel_penalty_msat(
        &self,
        candidate: &CandidateRouteHop,
        usage: ChannelUsage,
        score_params: &Self::ScoreParams,
    ) -> u64 {
        // normal penalty from the inner scorer
        let mut penalty = self
            .inner
            .channel_penalty_msat(candidate, usage, score_params);

        let hub_to_hub_min_penalty = (score_params.base_penalty_msat as f64 * 0.5) as u64;
        let entering_highway_min_penalty = (score_params.base_penalty_msat as f64 * 0.7) as u64;

        let is_source_preferred_hub = self.is_source_preferred_hub(candidate);
        let is_target_preferred_hub = self.is_target_preferred_hub(candidate);
        if is_source_preferred_hub && is_target_preferred_hub {
            // Both the source and target are on the "hub highway"
            penalty = penalty.saturating_mul(5).saturating_div(10); // 50% discount
            penalty = penalty
                .saturating_sub(HUB_BASE_DISCOUNT_PENALTY_MSAT)
                .max(hub_to_hub_min_penalty); // Base fee discount
        } else if is_target_preferred_hub {
            // Only the target is a preferred hub (entering the "hub highway")
            penalty = penalty.saturating_mul(7).saturating_div(10); // 30% discount
            penalty = penalty.max(entering_highway_min_penalty);
        } else if is_source_preferred_hub {
            // Only the source is a preferred hub (leaving the "hub highway")
            // No discount here
            penalty = penalty.max(score_params.base_penalty_msat);
        } else {
            // Neither the source nor target is a preferred hub (staying "off the highway")
            penalty = penalty.saturating_mul(15).saturating_div(10); // 50% extra penalty
            penalty = penalty
                .saturating_add(HUB_BASE_DISCOUNT_PENALTY_MSAT)
                .max(score_params.base_penalty_msat); // Base fee penalty
        }

        penalty
    }
}

impl ScoreUpdate for HubPreferentialScorer {
    fn payment_path_failed(
        &mut self,
        path: &Path,
        short_channel_id: u64,
        duration_since_epoch: Duration,
    ) {
        self.inner
            .payment_path_failed(path, short_channel_id, duration_since_epoch)
    }

    fn payment_path_successful(&mut self, path: &Path, duration_since_epoch: Duration) {
        self.inner
            .payment_path_successful(path, duration_since_epoch)
    }

    fn probe_failed(&mut self, path: &Path, short_channel_id: u64, duration_since_epoch: Duration) {
        self.inner
            .probe_failed(path, short_channel_id, duration_since_epoch)
    }

    fn probe_successful(&mut self, path: &Path, duration_since_epoch: Duration) {
        self.inner.probe_successful(path, duration_since_epoch)
    }

    fn time_passed(&mut self, duration_since_epoch: Duration) {
        self.inner.time_passed(duration_since_epoch)
    }
}

impl Writeable for HubPreferentialScorer {
    fn write<W: Writer>(&self, writer: &mut W) -> Result<(), lightning::io::Error> {
        self.inner.write(writer)
    }
}


================================================
File: mutiny-core/src/storage.rs
================================================
use crate::ldkstorage::CHANNEL_MANAGER_KEY;
use crate::logging::MutinyLogger;
use crate::nodemanager::{ChannelClosure, NodeStorage};
use crate::utils::{now, spawn, DBTasks, Task};
use crate::vss::{MutinyVssClient, VssKeyValueItem};
use crate::{
    encrypt::{decrypt_with_password, encrypt, encryption_key_from_pass, Cipher},
    DEVICE_LOCK_INTERVAL_SECS,
};
use crate::{
    error::{MutinyError, MutinyStorageError},
    event::PaymentInfo,
};
use crate::{event::HTLCStatus, MutinyInvoice};
use crate::{labels::LabelStorage, TransactionDetails};
use async_trait::async_trait;
use bdk_chain::Merge;
pub use bdk_wallet::ChangeSet;
use bip39::Mnemonic;
use bitcoin::hashes::Hash;
use bitcoin::Txid;
use futures_util::lock::Mutex;
use hex_conservative::*;
use lightning::{ln::PaymentHash, util::logger::Logger};
use lightning::{log_debug, log_trace};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use std::collections::{BTreeSet, HashMap};
use std::sync::{Arc, RwLock};
use uuid::Uuid;

pub const SUBSCRIPTION_TIMESTAMP: &str = "subscription_timestamp";
pub const KEYCHAIN_STORE_KEY: &str = "bdk_keychain";
pub const MNEMONIC_KEY: &str = "mnemonic";
pub(crate) const NEED_FULL_SYNC_KEY: &str = "needs_full_sync";
pub const NODES_KEY: &str = "nodes";
pub const SERVICE_TOKENS: &str = "service_tokens";
const FEE_ESTIMATES_KEY: &str = "fee_estimates";
pub const BITCOIN_PRICE_CACHE_KEY: &str = "bitcoin_price_cache";
const FIRST_SYNC_KEY: &str = "first_sync";
pub const LAST_NWC_SYNC_TIME_KEY: &str = "last_nwc_sync_time";
pub(crate) const DEVICE_ID_KEY: &str = "device_id";
pub const DEVICE_LOCK_KEY: &str = "device_lock";
pub(crate) const EXPECTED_NETWORK_KEY: &str = "network";
pub const PAYMENT_INBOUND_PREFIX_KEY: &str = "payment_inbound/";
pub const PAYMENT_OUTBOUND_PREFIX_KEY: &str = "payment_outbound/";
pub const TRANSACTION_DETAILS_PREFIX_KEY: &str = "transaction_details/";
pub(crate) const ONCHAIN_PREFIX: &str = "onchain_tx/";
pub const LAST_DM_SYNC_TIME_KEY: &str = "last_dm_sync_time";
pub const LAST_HERMES_SYNC_TIME_KEY: &str = "last_hermes_sync_time";
pub const NOSTR_PROFILE_METADATA: &str = "nostr_profile_metadata";
pub const NOSTR_CONTACT_LIST: &str = "nostr_contact_list";

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct DelayedKeyValueItem {
    pub key: String,
    pub value: Value,
    pub version: u32,
    pub write_time: u128,
}

impl From<DelayedKeyValueItem> for VssKeyValueItem {
    fn from(item: DelayedKeyValueItem) -> Self {
        VssKeyValueItem {
            key: item.key,
            value: item.value,
            version: item.version,
        }
    }
}

fn needs_encryption(key: &str) -> bool {
    match key {
        MNEMONIC_KEY => true,
        KEYCHAIN_STORE_KEY => true,
        str if str.starts_with(CHANNEL_MANAGER_KEY) => true,
        _ => false,
    }
}

pub fn encrypt_value(
    key: impl AsRef<str>,
    value: Value,
    cipher: Option<Cipher>,
) -> Result<Value, MutinyError> {
    // Only bother encrypting if a password is set
    let res = match cipher {
        Some(c) if needs_encryption(key.as_ref()) => {
            let str = serde_json::to_string(&value)?;
            let ciphertext = encrypt(&str, c)?;
            Value::String(ciphertext)
        }
        _ => value,
    };

    Ok(res)
}

pub fn decrypt_value(
    key: impl AsRef<str>,
    value: Value,
    password: Option<&str>,
) -> Result<Value, MutinyError> {
    // Only bother encrypting if a password is set
    let json: Value = match password {
        Some(pw) if needs_encryption(key.as_ref()) => {
            let str: String = serde_json::from_value(value)?;
            let ciphertext = decrypt_with_password(&str, pw)?;
            serde_json::from_str(&ciphertext)?
        }
        _ => value,
    };

    Ok(json)
}

#[derive(Debug, Clone, Eq, PartialEq, Serialize, Deserialize)]
pub struct IndexItem {
    pub timestamp: Option<u64>,
    pub key: String,
}

impl PartialOrd for IndexItem {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for IndexItem {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        match (self.timestamp, other.timestamp) {
            (Some(a), Some(b)) => b.cmp(&a).then_with(|| self.key.cmp(&other.key)),
            (Some(_), None) => std::cmp::Ordering::Greater,
            (None, Some(_)) => std::cmp::Ordering::Less,
            (None, None) => self.key.cmp(&other.key),
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VersionedValue {
    pub version: u32,
    pub value: Value,
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct DeviceLock {
    pub time: u32,
    pub device: String,
}

impl DeviceLock {
    pub fn remaining_secs(&self) -> u64 {
        let now = now().as_secs();
        let diff = now.saturating_sub(self.time as u64);
        (DEVICE_LOCK_INTERVAL_SECS * 2).saturating_sub(diff)
    }

    /// Check if the device is locked
    /// This is determined if the time is less than 2 minutes ago
    pub fn is_locked(&self, id: &str) -> bool {
        let now = now().as_secs();
        let diff = now.saturating_sub(self.time as u64);
        diff < DEVICE_LOCK_INTERVAL_SECS * 2 && self.device != id
    }

    // Check if the device is the last one to have the lock
    pub fn is_last_locker(&self, id: &str) -> bool {
        self.device == id
    }
}

#[cfg_attr(target_arch = "wasm32", async_trait(?Send))]
#[cfg_attr(not(target_arch = "wasm32"), async_trait)]
pub trait MutinyStorage: Clone + Sized + Send + Sync + 'static {
    /// Database
    fn database(&self) -> Result<String, MutinyError>;
    /// Get the password used to encrypt the storage
    fn password(&self) -> Option<&str>;

    /// Get the encryption key used for storage
    fn cipher(&self) -> Option<Cipher>;

    /// Get the VSS client used for storage
    fn vss_client(&self) -> Option<Arc<MutinyVssClient>>;

    /// An index of the activity in the storage, this should be a list of (timestamp, key) tuples
    /// This is used to for getting a sorted list of keys quickly
    fn activity_index(&self) -> Arc<RwLock<BTreeSet<IndexItem>>>;

    /// Write a raw data without encript into storage
    fn write_raw<T>(&self, items: Vec<(String, T)>) -> Result<(), MutinyError>
    where
        T: Serialize + Send;

    async fn write_vss(
        &self,
        key: String,
        value: Value,
        version: Option<u32>,
    ) -> Result<(), MutinyError> {
        // save to VSS if it is enabled
        if let (Some(vss), Some(version)) = (self.vss_client(), version) {
            let item = VssKeyValueItem {
                key,
                value,
                version,
            };

            vss.put_objects(vec![item]).await
        } else {
            Ok(())
        }
    }

    /// Set a value in the storage, the function will encrypt the value if needed
    fn write_data<T>(&self, key: String, value: T, version: Option<u32>) -> Result<(), MutinyError>
    where
        T: Serialize + Send,
    {
        let data = serde_json::to_value(value).map_err(|e| MutinyError::PersistenceFailed {
            source: MutinyStorageError::SerdeError { source: e },
        })?;

        // encrypt value in async block so it can be done in parallel
        // with the VSS call
        let local_data = data.clone();
        let key_clone = key.clone();
        let json: Value = encrypt_value(key_clone.clone(), local_data, self.cipher())?;
        self.write_raw(vec![(key_clone, json)])?;

        // save to VSS by spawn an async task
        self.spawn({
            let db = self.clone();
            async move { db.write_vss(key, data, version).await }
        });

        Ok(())
    }

    fn get_delayed_objects(&self) -> Arc<Mutex<HashMap<String, DelayedKeyValueItem>>>;

    /// Get a value from the storage, use get_data if you want the value to be decrypted
    fn get<T>(&self, key: impl AsRef<str>) -> Result<Option<T>, MutinyError>
    where
        T: for<'de> Deserialize<'de>;

    /// Get a value from the storage, the function will decrypt the value if needed
    fn get_data<T>(&self, key: impl AsRef<str>) -> Result<Option<T>, MutinyError>
    where
        T: for<'de> Deserialize<'de>,
    {
        match self.get(&key)? {
            None => Ok(None),
            Some(value) => {
                let json: Value = decrypt_value(key, value, self.password())?;
                let data: T = serde_json::from_value(json)?;
                Ok(Some(data))
            }
        }
    }

    /// Delete a set of values from the storage
    fn delete(&self, keys: &[impl AsRef<str>]) -> Result<(), MutinyError>;

    /// Start the storage, this will be called before any other methods
    async fn start(&mut self) -> Result<(), MutinyError>;

    /// Stop the storage, this will be called when the application is shutting down
    async fn stop(&self);

    /// Check if the storage is connected
    fn connected(&self) -> Result<bool, MutinyError>;

    /// Scan the storage for keys with a given prefix and suffix, this will return a list of keys
    /// If this function does not properly filter the keys, it can cause major problems.
    fn scan_keys(&self, prefix: &str, suffix: Option<&str>) -> Result<Vec<String>, MutinyError>;

    /// Scan the storage for keys with a given prefix and suffix, and then gets their values
    fn scan<T>(&self, prefix: &str, suffix: Option<&str>) -> Result<HashMap<String, T>, MutinyError>
    where
        T: for<'de> Deserialize<'de>,
    {
        let keys = self.scan_keys(prefix, suffix)?;

        let mut map = HashMap::with_capacity(keys.len());

        for key in keys {
            let kv = self.get_data::<T>(key.clone())?;
            if let Some(v) = kv {
                map.insert(key, v);
            }
        }

        Ok(map)
    }

    /// Insert a mnemonic into the storage
    fn insert_mnemonic(&self, mnemonic: Mnemonic) -> Result<Mnemonic, MutinyError> {
        self.write_data(MNEMONIC_KEY.to_string(), &mnemonic, None)?;
        Ok(mnemonic)
    }

    /// Get the mnemonic from the storage
    fn get_mnemonic(&self) -> Result<Option<Mnemonic>, MutinyError> {
        self.get_data(MNEMONIC_KEY)
    }

    fn change_password(
        &mut self,
        new: Option<String>,
        new_cipher: Option<Cipher>,
    ) -> Result<(), MutinyError>;

    fn change_password_and_rewrite_storage(
        &mut self,
        old: Option<String>,
        new: Option<String>,
    ) -> Result<(), MutinyError> {
        // check if old password is correct
        if old != self.password().map(|s| s.to_owned()) {
            return Err(MutinyError::IncorrectPassword);
        }

        // get all of our keys
        let mut keys: Vec<String> = self.scan_keys("", None)?;
        // get the ones that need encryption
        keys.retain(|k| needs_encryption(k));

        // decrypt all of the values
        let mut values: HashMap<String, Value> = HashMap::new();
        for key in keys {
            let value = self.get_data(&key)?;
            if let Some(v) = value {
                values.insert(key.to_owned(), v);
            }
        }

        // change the password
        let new_cipher = new
            .as_ref()
            .filter(|p| !p.is_empty())
            .map(|p| encryption_key_from_pass(p))
            .transpose()?;
        self.change_password(new, new_cipher)?;

        // encrypt all of the values
        for (key, value) in values {
            self.write_data(key, value, None)?;
        }

        Ok(())
    }

    /// Override the storage with the new JSON object
    async fn import(database: String, json: Value) -> Result<(), MutinyError>;

    /// Deletes all data from the storage
    async fn clear(database: String) -> Result<(), MutinyError>;

    /// Deletes all data from the storage and removes lock from VSS
    async fn delete_all(&self) -> Result<(), MutinyError> {
        Self::clear(self.database()?).await?;
        // remove lock from VSS if is is enabled
        if self.vss_client().is_some() {
            let device = self.get_device_id()?;
            // set time to 0 to unlock
            let lock = DeviceLock { time: 0, device };
            // still update the version so it is written to VSS
            let time = now().as_secs() as u32;
            self.write_data(DEVICE_LOCK_KEY.to_string(), lock, Some(time))?;
        }

        Ok(())
    }

    /// Gets the node indexes from storage
    fn get_nodes(&self) -> Result<NodeStorage, MutinyError> {
        let res: Option<NodeStorage> = self.get_data(NODES_KEY)?;
        match res {
            Some(nodes) => Ok(nodes),
            None => Ok(NodeStorage::default()),
        }
    }

    /// Inserts the node indexes into storage
    fn insert_nodes(&self, nodes: &NodeStorage) -> Result<(), MutinyError> {
        let version = Some(nodes.version);
        self.write_data(NODES_KEY.to_string(), nodes, version)
    }

    /// Get the current fee estimates from storage
    /// The key is block target, the value is the fee in satoshis per byte
    fn get_fee_estimates(&self) -> Result<Option<HashMap<String, f64>>, MutinyError> {
        self.get_data(FEE_ESTIMATES_KEY)
    }

    /// Inserts the fee estimates into storage
    /// The key is block target, the value is the fee in satoshis per byte
    fn insert_fee_estimates(&self, fees: HashMap<String, f64>) -> Result<(), MutinyError> {
        self.write_data(FEE_ESTIMATES_KEY.to_string(), fees, None)
    }

    /// Gets a channel closure and handles setting the user_channel_id if needed
    fn get_channel_closure(&self, key: &str) -> Result<Option<ChannelClosure>, MutinyError> {
        if let Some(mut closure) = self.get_data::<ChannelClosure>(key)? {
            closure.set_user_channel_id_from_key(key)?;
            Ok(Some(closure))
        } else {
            Ok(None)
        }
    }

    /// Get the current bitcoin price cache from storage
    fn get_bitcoin_price_cache(&self) -> Result<HashMap<String, f32>, MutinyError> {
        Ok(self.get_data(BITCOIN_PRICE_CACHE_KEY)?.unwrap_or_default())
    }

    /// Inserts the bitcoin price cache into storage
    fn insert_bitcoin_price_cache(&self, prices: HashMap<String, f32>) -> Result<(), MutinyError> {
        self.write_data(BITCOIN_PRICE_CACHE_KEY.to_string(), prices, None)
    }

    fn has_done_first_sync(&self) -> Result<bool, MutinyError> {
        self.get_data::<bool>(FIRST_SYNC_KEY)
            .map(|v| v == Some(true))
    }

    fn set_done_first_sync(&self) -> Result<(), MutinyError> {
        self.write_data(FIRST_SYNC_KEY.to_string(), true, None)
    }

    fn get_dm_sync_time(&self, is_hermes: bool) -> Result<Option<u64>, MutinyError> {
        let key = if is_hermes {
            LAST_HERMES_SYNC_TIME_KEY
        } else {
            LAST_DM_SYNC_TIME_KEY
        };
        self.get_data(key)
    }

    fn set_dm_sync_time(&self, time: u64, is_hermes: bool) -> Result<(), MutinyError> {
        let key = if is_hermes {
            LAST_HERMES_SYNC_TIME_KEY
        } else {
            LAST_DM_SYNC_TIME_KEY
        };

        // only update if the time is newer
        let current = self.get_dm_sync_time(is_hermes)?.unwrap_or_default();
        if current < time {
            self.write_data(key.to_string(), time, None)
        } else {
            Ok(())
        }
    }

    fn get_nwc_sync_time(&self) -> Result<Option<u64>, MutinyError> {
        self.get_data(LAST_NWC_SYNC_TIME_KEY)
    }

    fn set_nwc_sync_time(&self, time: u64) -> Result<(), MutinyError> {
        // only update if the time is newer
        let current = self.get_nwc_sync_time()?.unwrap_or_default();
        if current < time {
            self.write_data(LAST_NWC_SYNC_TIME_KEY.to_string(), time, None)
        } else {
            Ok(())
        }
    }

    fn get_device_id(&self) -> Result<String, MutinyError> {
        match self.get_data(DEVICE_ID_KEY)? {
            Some(id) => Ok(id),
            None => {
                let new_id = Uuid::new_v4().to_string();
                self.write_data(DEVICE_ID_KEY.to_string(), &new_id, None)?;
                Ok(new_id)
            }
        }
    }

    fn get_device_lock(&self) -> Result<Option<DeviceLock>, MutinyError> {
        self.get_data(DEVICE_LOCK_KEY)
    }

    fn set_device_lock(&self, logger: &MutinyLogger) -> Result<(), MutinyError> {
        let device = self.get_device_id()?;
        if let Some(lock) = self.get_device_lock()? {
            if lock.is_locked(&device) {
                log_debug!(logger, "current device is {}", device);
                log_debug!(logger, "locked device is {}", lock.device);
                return Err(MutinyError::AlreadyRunning);
            }
        }

        let time = now().as_secs() as u32;
        let lock = DeviceLock { time, device };
        self.write_data(DEVICE_LOCK_KEY.to_string(), lock, Some(time))
    }

    fn release_device_lock(&self, logger: &MutinyLogger) -> Result<(), MutinyError> {
        let device = self.get_device_id()?;
        if let Some(lock) = self.get_device_lock()? {
            if lock.is_locked(&device) {
                log_debug!(logger, "current device is {}", device);
                log_debug!(logger, "locked device is {}", lock.device);
                return Err(MutinyError::AlreadyRunning);
            }
        }

        let time = 0;
        let lock = DeviceLock { time, device };
        let version = now().as_secs() as u32;
        self.write_data(DEVICE_LOCK_KEY.to_string(), lock, Some(version))
    }

    async fn fetch_device_lock(&self) -> Result<Option<DeviceLock>, MutinyError>;

    /// Write Wallet changeset
    fn write_changes(&self, changeset: &ChangeSet) -> Result<(), MutinyError> {
        if changeset.is_empty() {
            return Ok(());
        }

        let version = now().as_secs() as u32;
        let value = match self.read_changes()? {
            Some(mut keychain_store) => {
                keychain_store.merge(changeset.clone());
                let value = serde_json::to_value(keychain_store)?;
                VersionedValue { value, version }
            }
            None => {
                let value = serde_json::to_value(changeset)?;
                VersionedValue { value, version }
            }
        };
        self.write_data(KEYCHAIN_STORE_KEY.to_string(), value, Some(version))
    }

    /// Read Wallet changeset
    fn read_changes(&self) -> Result<Option<ChangeSet>, MutinyError> {
        match self.get_data::<VersionedValue>(KEYCHAIN_STORE_KEY)? {
            Some(versioned) => {
                let changeset = serde_json::from_value(versioned.value)?;
                Ok(Some(changeset))
            }
            None => Ok(None),
        }
    }

    /// Spawn background task to run db tasks
    fn spawn<Fut: Task>(&self, _fut: Fut);
}

#[derive(Clone)]
pub struct MemoryStorage {
    pub database: String,
    pub password: Option<String>,
    pub cipher: Option<Cipher>,
    pub memory: Arc<RwLock<HashMap<String, Value>>>,
    pub vss_client: Option<Arc<MutinyVssClient>>,
    delayed_keys: Arc<Mutex<HashMap<String, DelayedKeyValueItem>>>,
    pub activity_index: Arc<RwLock<BTreeSet<IndexItem>>>,
    tasks: Arc<DBTasks>,
}

impl MemoryStorage {
    pub fn new(
        password: Option<String>,
        cipher: Option<Cipher>,
        vss_client: Option<Arc<MutinyVssClient>>,
    ) -> Self {
        Self {
            database: "memdb".to_string(),
            cipher,
            password,
            memory: Arc::new(RwLock::new(HashMap::new())),
            vss_client,
            delayed_keys: Arc::new(Mutex::new(HashMap::new())),
            activity_index: Arc::new(RwLock::new(BTreeSet::new())),
            tasks: Arc::new(DBTasks::default()),
        }
    }

    pub async fn load_from_vss(&self) -> Result<(), MutinyError> {
        if let Some(vss) = self.vss_client() {
            let keys = vss.list_key_versions(None).await?;
            let mut items = HashMap::new();
            for key in keys {
                let obj = vss.get_object(&key.key).await?;
                items.insert(key.key, obj.value);
            }
            let mut map = self
                .memory
                .try_write()
                .map_err(|e| MutinyError::write_err(e.into()))?;
            map.extend(items);
        }

        Ok(())
    }
}

impl Default for MemoryStorage {
    fn default() -> Self {
        Self::new(None, None, None)
    }
}

#[cfg_attr(target_arch = "wasm32", async_trait(?Send))]
#[cfg_attr(not(target_arch = "wasm32"), async_trait)]
impl MutinyStorage for MemoryStorage {
    fn database(&self) -> Result<String, MutinyError> {
        Ok(self.database.clone())
    }
    fn password(&self) -> Option<&str> {
        self.password.as_deref()
    }

    fn cipher(&self) -> Option<Cipher> {
        self.cipher.to_owned()
    }

    fn vss_client(&self) -> Option<Arc<MutinyVssClient>> {
        self.vss_client.clone()
    }

    fn activity_index(&self) -> Arc<RwLock<BTreeSet<IndexItem>>> {
        self.activity_index.clone()
    }

    fn write_raw<T>(&self, items: Vec<(String, T)>) -> Result<(), MutinyError>
    where
        T: Serialize + Send,
    {
        let mut map = self
            .memory
            .try_write()
            .map_err(|e| MutinyError::write_err(e.into()))?;
        for (key, value) in items {
            let data = serde_json::to_value(value).map_err(|e| MutinyError::PersistenceFailed {
                source: MutinyStorageError::SerdeError { source: e },
            })?;
            map.insert(key, data);
        }

        Ok(())
    }

    fn get<T>(&self, key: impl AsRef<str>) -> Result<Option<T>, MutinyError>
    where
        T: for<'de> Deserialize<'de>,
    {
        let map = self
            .memory
            .try_read()
            .map_err(|e| MutinyError::read_err(e.into()))?;

        match map.get(key.as_ref()) {
            None => Ok(None),
            Some(value) => {
                let data: T = serde_json::from_value(value.to_owned())?;
                Ok(Some(data))
            }
        }
    }

    fn delete(&self, keys: &[impl AsRef<str>]) -> Result<(), MutinyError> {
        let mut map = self
            .memory
            .try_write()
            .map_err(|e| MutinyError::write_err(e.into()))?;

        for key in keys {
            map.remove(key.as_ref());
        }

        Ok(())
    }

    async fn start(&mut self) -> Result<(), MutinyError> {
        Ok(())
    }

    async fn stop(&self) {
        self.tasks.wait().await
    }

    fn connected(&self) -> Result<bool, MutinyError> {
        Ok(false)
    }

    fn scan_keys(&self, prefix: &str, suffix: Option<&str>) -> Result<Vec<String>, MutinyError> {
        let map = self
            .memory
            .try_read()
            .map_err(|e| MutinyError::read_err(e.into()))?;

        Ok(map
            .keys()
            .filter(|key| {
                key.starts_with(prefix) && (suffix.is_none() || key.ends_with(suffix.unwrap()))
            })
            .cloned()
            .collect())
    }

    fn change_password(
        &mut self,
        new: Option<String>,
        new_cipher: Option<Cipher>,
    ) -> Result<(), MutinyError> {
        self.password = new;
        self.cipher = new_cipher;
        Ok(())
    }

    async fn import(_database: String, _json: Value) -> Result<(), MutinyError> {
        Ok(())
    }

    async fn clear(_database: String) -> Result<(), MutinyError> {
        Ok(())
    }

    async fn fetch_device_lock(&self) -> Result<Option<DeviceLock>, MutinyError> {
        self.get_device_lock()
    }

    fn get_delayed_objects(&self) -> Arc<Mutex<HashMap<String, DelayedKeyValueItem>>> {
        self.delayed_keys.clone()
    }

    fn spawn<Fut: Task>(&self, fut: Fut) {
        let db_tasks = self.tasks.clone();
        db_tasks.inc_started();
        spawn(async move {
            let res = fut.await;
            db_tasks.inc_done();
            res.expect("DB task error")
        });
    }
}

// Dummy implementation for testing or if people want to ignore persistence
#[cfg_attr(target_arch = "wasm32", async_trait(?Send))]
#[cfg_attr(not(target_arch = "wasm32"), async_trait)]
impl MutinyStorage for () {
    fn database(&self) -> Result<String, MutinyError> {
        Ok(String::new())
    }

    fn password(&self) -> Option<&str> {
        None
    }

    fn cipher(&self) -> Option<Cipher> {
        None
    }

    fn vss_client(&self) -> Option<Arc<MutinyVssClient>> {
        None
    }

    fn activity_index(&self) -> Arc<RwLock<BTreeSet<IndexItem>>> {
        Arc::new(RwLock::new(BTreeSet::new()))
    }

    fn write_raw<T: Serialize + Send>(&self, _: Vec<(String, T)>) -> Result<(), MutinyError> {
        Ok(())
    }

    fn get<T>(&self, _key: impl AsRef<str>) -> Result<Option<T>, MutinyError>
    where
        T: for<'de> Deserialize<'de>,
    {
        Ok(None)
    }

    fn delete(&self, _: &[impl AsRef<str>]) -> Result<(), MutinyError> {
        Ok(())
    }

    async fn start(&mut self) -> Result<(), MutinyError> {
        Ok(())
    }

    async fn stop(&self) {}

    fn connected(&self) -> Result<bool, MutinyError> {
        Ok(false)
    }

    fn scan_keys(&self, _prefix: &str, _suffix: Option<&str>) -> Result<Vec<String>, MutinyError> {
        Ok(Vec::new())
    }

    fn change_password(
        &mut self,
        _new: Option<String>,
        _new_cipher: Option<Cipher>,
    ) -> Result<(), MutinyError> {
        Ok(())
    }

    async fn import(_database: String, _json: Value) -> Result<(), MutinyError> {
        Ok(())
    }

    async fn clear(_database: String) -> Result<(), MutinyError> {
        Ok(())
    }

    async fn fetch_device_lock(&self) -> Result<Option<DeviceLock>, MutinyError> {
        self.get_device_lock()
    }

    fn get_delayed_objects(&self) -> Arc<Mutex<HashMap<String, DelayedKeyValueItem>>> {
        Arc::new(Mutex::new(HashMap::new()))
    }

    fn spawn<Fut: futures::future::Future<Output = Result<(), MutinyError>> + 'static>(
        &self,
        _fut: Fut,
    ) {
    }
}

pub(crate) fn transaction_details_key(internal_id: Txid) -> String {
    format!(
        "{}{:x}",
        TRANSACTION_DETAILS_PREFIX_KEY,
        internal_id.to_raw_hash(),
    )
}

#[allow(dead_code)]
pub(crate) fn persist_transaction_details<S: MutinyStorage>(
    storage: &S,
    transaction_details: &TransactionDetails,
) -> Result<(), MutinyError> {
    let key = transaction_details_key(transaction_details.internal_id);
    storage.write_data(key.clone(), transaction_details, None)?;

    // insert into activity index
    match transaction_details.confirmation_time {
        bdk_chain::ConfirmationTime::Confirmed { height: _, time } => {
            let index = storage.activity_index();
            let mut index = index.try_write()?;
            // remove old version
            index.remove(&IndexItem {
                timestamp: None, // timestamp would be None for Unconfirmed
                key: key.clone(),
            });
            index.insert(IndexItem {
                timestamp: Some(time),
                key,
            });
        }
        bdk_chain::ConfirmationTime::Unconfirmed { .. } => {
            let index = storage.activity_index();
            let mut index = index.try_write()?;
            index.insert(IndexItem {
                timestamp: None,
                key,
            });
        }
    }

    Ok(())
}

#[allow(dead_code)]
// Deletes the transaction detail and removes the pending index if it exists
pub(crate) fn delete_transaction_details<S: MutinyStorage>(
    storage: &S,
    txid: Txid,
) -> Result<(), MutinyError> {
    let key = transaction_details_key(txid);
    storage.delete(&[key.clone()])?;

    // delete the pending index item, if it exists
    let index = storage.activity_index();
    let mut index = index.try_write()?;
    index.remove(&IndexItem {
        timestamp: None, // timestamp would be None for Unconfirmed
        key: key.clone(),
    });

    Ok(())
}

pub(crate) fn get_transaction_details<S: MutinyStorage>(
    storage: &S,
    internal_id: Txid,
    logger: &MutinyLogger,
) -> Option<TransactionDetails> {
    let key = transaction_details_key(internal_id);
    log_trace!(logger, "Trace: checking payment key: {key}");
    match storage.get_data(&key).transpose() {
        Some(Ok(v)) => Some(v),
        _ => None,
    }
}

pub(crate) fn payment_key(inbound: bool, payment_hash: &[u8; 32]) -> String {
    if inbound {
        format!("{}{}", PAYMENT_INBOUND_PREFIX_KEY, payment_hash.as_hex())
    } else {
        format!("{}{}", PAYMENT_OUTBOUND_PREFIX_KEY, payment_hash.as_hex())
    }
}

pub(crate) fn persist_payment_info<S: MutinyStorage>(
    storage: &S,
    payment_hash: &[u8; 32],
    payment_info: &PaymentInfo,
    inbound: bool,
) -> Result<(), MutinyError> {
    let key = payment_key(inbound, payment_hash);
    storage.write_data(
        key.clone(),
        payment_info.clone(),
        Some(payment_info.last_update as u32),
    )?;

    // insert into activity index
    match payment_info.status {
        HTLCStatus::InFlight => {
            let index = storage.activity_index();
            let mut index = index.try_write()?;
            index.insert(IndexItem {
                timestamp: None,
                key,
            });
        }
        HTLCStatus::Succeeded => {
            let index = storage.activity_index();
            let mut index = index.try_write()?;
            // remove old version
            index.remove(&IndexItem {
                timestamp: None, // timestamp would be None for InFlight / Pending
                key: key.clone(),
            });
            index.insert(IndexItem {
                timestamp: Some(payment_info.last_update),
                key,
            });
        }
        HTLCStatus::Failed => {
            let index = storage.activity_index();
            let mut index = index.try_write()?;
            index.remove(&IndexItem {
                timestamp: None, // timestamp would be None for InFlight / Pending
                key,
            });
        }
        HTLCStatus::Pending => {} // don't add to index until invoice is paid
    }

    Ok(())
}

pub(crate) fn get_invoice_by_hash<S: MutinyStorage>(
    hash: &bitcoin::hashes::sha256::Hash,
    storage: &S,
    logger: &MutinyLogger,
) -> Result<MutinyInvoice, MutinyError> {
    let (payment_info, inbound) = get_payment_info(storage, hash, logger)?;
    let labels_map = storage.get_invoice_labels()?;
    let labels = payment_info
        .bolt11
        .as_ref()
        .and_then(|inv| labels_map.get(inv).cloned())
        .unwrap_or_default();

    MutinyInvoice::from(
        payment_info,
        PaymentHash(*hash.as_byte_array()),
        inbound,
        labels,
    )
}

pub(crate) fn get_payment_info<S: MutinyStorage>(
    storage: &S,
    payment_hash: &bitcoin::hashes::sha256::Hash,
    logger: &MutinyLogger,
) -> Result<(PaymentInfo, bool), MutinyError> {
    // try inbound first
    let payment_hash = payment_hash.as_byte_array();
    if let Some(payment_info) = read_payment_info(storage, payment_hash, true, logger) {
        return Ok((payment_info, true));
    }

    // if no inbound check outbound
    match read_payment_info(storage, payment_hash, false, logger) {
        Some(payment_info) => Ok((payment_info, false)),
        None => Err(MutinyError::NotFound),
    }
}

pub(crate) fn read_payment_info<S: MutinyStorage>(
    storage: &S,
    payment_hash: &[u8; 32],
    inbound: bool,
    logger: &MutinyLogger,
) -> Option<PaymentInfo> {
    let key = payment_key(inbound, payment_hash);
    log_trace!(logger, "Trace: checking payment key: {key}");
    match storage.get_data(&key).transpose() {
        Some(Ok(v)) => Some(v),
        _ => {
            // To scan for the old format that had `_{node_id}` at the end
            if let Ok(map) = storage.scan(&key, None) {
                map.into_values().next()
            } else {
                None
            }
        }
    }
}

pub(crate) fn list_payment_info<S: MutinyStorage>(
    storage: &S,
    inbound: bool,
) -> Result<Vec<(PaymentHash, PaymentInfo)>, MutinyError> {
    let prefix = match inbound {
        true => PAYMENT_INBOUND_PREFIX_KEY,
        false => PAYMENT_OUTBOUND_PREFIX_KEY,
    };
    let map: HashMap<String, PaymentInfo> = storage.scan(prefix, None)?;

    // convert keys to PaymentHash
    Ok(map
        .into_iter()
        .map(|(key, value)| {
            let payment_hash_str = get_payment_hash_from_key(key.as_str(), prefix);
            let hash: [u8; 32] =
                FromHex::from_hex(payment_hash_str).expect("key should be a sha256 hash");
            (PaymentHash(hash), value)
        })
        .collect())
}

#[derive(Clone)]
pub struct OnChainStorage<S: MutinyStorage>(pub(crate) S);

pub(crate) fn get_payment_hash_from_key<'a>(key: &'a str, prefix: &str) -> &'a str {
    key.trim_start_matches(prefix)
        .splitn(2, '_') // To support the old format that had `_{node_id}` at the end
        .collect::<Vec<&str>>()[0]
}

#[cfg(test)]
mod tests {
    use crate::test_utils::*;

    use crate::{encrypt::encryption_key_from_pass, storage::MemoryStorage};
    use crate::{keymanager, storage::MutinyStorage};

    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};

    wasm_bindgen_test_configure!(run_in_browser);

    #[test]
    async fn insert_and_get_mnemonic_no_password() {
        let test_name = "insert_and_get_mnemonic_no_password";
        log!("{}", test_name);

        let seed = keymanager::generate_seed(12).unwrap();

        let storage = MemoryStorage::default();
        let mnemonic = storage.insert_mnemonic(seed).unwrap();

        let stored_mnemonic = storage.get_mnemonic().unwrap();
        assert_eq!(Some(mnemonic), stored_mnemonic);
    }

    #[test]
    async fn insert_and_get_mnemonic_with_password() {
        let test_name = "insert_and_get_mnemonic_with_password";
        log!("{}", test_name);

        let seed = keymanager::generate_seed(12).unwrap();

        let pass = uuid::Uuid::new_v4().to_string();
        let cipher = encryption_key_from_pass(&pass).unwrap();
        let storage = MemoryStorage::new(Some(pass), Some(cipher), None);

        let mnemonic = storage.insert_mnemonic(seed).unwrap();

        let stored_mnemonic = storage.get_mnemonic().unwrap();
        assert_eq!(Some(mnemonic), stored_mnemonic);
    }

    // #[test]
    // async fn test_device_lock() {
    //     let test_name = "test_device_lock";
    //     log!("{}", test_name);

    //     let vss = std::sync::Arc::new(create_vss_client().await);
    //     let storage = MemoryStorage::new(None, None, Some(vss.clone()));
    //     storage.load_from_vss().await.unwrap();

    //     let logger = Arc::new(MutinyLogger::default());

    //     let id = storage.get_device_id().unwrap();
    //     let lock = storage.get_device_lock().unwrap();
    //     assert_eq!(None, lock);

    //     storage.set_device_lock(&logger).await.unwrap();
    //     // sleep 1 second to make sure it writes to VSS
    //     sleep(1_000).await;

    //     let lock = storage.get_device_lock().unwrap();
    //     assert!(lock.is_some());
    //     assert!(!lock.clone().unwrap().is_locked(&id));
    //     assert!(lock.clone().unwrap().is_last_locker(&id));
    //     assert!(lock.clone().unwrap().is_locked("different_id"));
    //     assert!(!lock.clone().unwrap().is_last_locker("different_id"));
    //     assert_eq!(lock.unwrap().device, id);

    //     // make sure we can set lock again, should work because same device id
    //     storage.set_device_lock(&logger).await.unwrap();
    //     // sleep 1 second to make sure it writes to VSS
    //     sleep(1_000).await;

    //     // create new storage with new device id and make sure we can't set lock
    //     let storage = MemoryStorage::new(None, None, Some(vss));
    //     storage.load_from_vss().await.unwrap();

    //     let new_id = storage.get_device_id().unwrap();
    //     assert_ne!(id, new_id);

    //     let lock = storage.get_device_lock().unwrap();
    //     assert!(lock.is_some());
    //     // not locked for active device
    //     assert!(!lock.clone().unwrap().is_locked(&id));
    //     assert!(lock.clone().unwrap().is_last_locker(&id));
    //     // is locked for new device
    //     assert!(lock.clone().unwrap().is_locked(&new_id));
    //     assert!(!lock.clone().unwrap().is_last_locker(&new_id));
    //     assert_eq!(lock.unwrap().device, id);

    //     assert_eq!(
    //         storage.set_device_lock(&logger).await,
    //         Err(crate::MutinyError::AlreadyRunning)
    //     );
    // }
}


================================================
File: mutiny-core/src/subscription.rs
================================================
use serde::{Deserialize, Serialize};

#[derive(Serialize, Deserialize)]
pub struct CheckSubscribedResponse {
    pub expired_date: Option<u64>,
}

#[derive(Serialize, Deserialize)]
pub struct UserInvoiceResponse {
    inv: String,
}

#[derive(Serialize, Deserialize)]
pub struct WalletConnectRequest {
    wallet_connect_string: String,
}


================================================
File: mutiny-core/src/test_utils.rs
================================================
#![allow(dead_code)]

pub fn create_manager() -> AuthManager {
    let mnemonic = generate_seed(12).unwrap();
    let seed = mnemonic.to_seed("");
    let xprivkey = Xpriv::new_master(Network::Regtest, &seed).unwrap();
    AuthManager::new(xprivkey).unwrap()
}

// pub async fn create_vss_client() -> MutinyVssClient {
//     // Set up test auth client
//     let auth_manager = create_manager();
//     let lnurl_client = Arc::new(
//         lnurl::Builder::default()
//             .build_async()
//             .expect("failed to make lnurl client"),
//     );
//     let logger = Arc::new(MutinyLogger::default());
//     let url = "https://auth-staging.mutinywallet.com";

//     let auth_client =
//         MutinyAuthClient::new(auth_manager, lnurl_client, logger.clone(), url.to_string());

//     // Test authenticate method
//     match auth_client.authenticate().await {
//         Ok(_) => assert!(auth_client.is_authenticated().await.is_some()),
//         Err(e) => panic!("Authentication failed with error: {:?}", e),
//     };

//     let encryption_key = SecretKey::from_slice(&[2; 32]).unwrap();

//     MutinyVssClient::new_authenticated(
//         Arc::new(auth_client),
//         "https://vss-staging.fly.dev/v2".to_string(),
//         encryption_key,
//         logger,
//     )
// }

pub(crate) async fn create_mutiny_wallet<S: MutinyStorage>(storage: S) -> MutinyWallet<S> {
    let network = Network::Regtest;
    let xpriv = Xpriv::new_master(network, &[0; 32]).unwrap();
    let config = MutinyWalletConfigBuilder::new(xpriv)
        .with_network(network)
        .build();
    let mw_builder = MutinyWalletBuilder::new(xpriv, storage.clone()).with_config(config);
    mw_builder
        .build()
        .await
        .expect("mutiny wallet should initialize")
}

pub(crate) async fn create_node<S: MutinyStorage>(storage: S) -> Node<S> {
    // mark first sync as done so we can execute node functions
    storage.set_done_first_sync().unwrap();

    let stop = Arc::new(AtomicBool::new(false));
    let logger = Arc::new(MutinyLogger::default());
    let seed = generate_seed(12).unwrap();
    let network = Network::Regtest;
    let xprivkey = Xpriv::new_master(network, &seed.to_seed("")).unwrap();
    let network_graph = Arc::new(NetworkGraph::new(network, logger.clone()));
    let gossip_sync = Arc::new(RapidGossipSync::new(network_graph.clone(), logger.clone()));
    let params = ProbabilisticScoringDecayParameters::default();
    let scorer = Arc::new(Mutex::new(HubPreferentialScorer::new(ProbScorer::new(
        params,
        network_graph.clone(),
        logger.clone(),
    ))));

    let esplora_server_url = get_esplora_url(network, None);
    let esplora = esplora_client::Builder::new(&esplora_server_url)
        .build_async()
        .unwrap();
    let tx_sync = Arc::new(EsploraSyncClient::from_client(
        esplora.clone(),
        logger.clone(),
    ));
    let esplora = Arc::new(esplora);
    let fee_estimator = Arc::new(MutinyFeeEstimator::new(
        storage.clone(),
        esplora.clone(),
        logger.clone(),
    ));

    let wallet = Arc::new(
        OnChainWallet::new(
            xprivkey,
            storage.clone(),
            network,
            esplora.clone(),
            fee_estimator.clone(),
            stop.clone(),
            logger.clone(),
            None,
        )
        .unwrap(),
    );

    let chain = Arc::new(MutinyChain::new(tx_sync, wallet.clone(), logger.clone()));

    let mut node_builder = NodeBuilder::new(xprivkey, storage)
        .with_uuid(Uuid::new_v4().to_string())
        .with_node_index(NodeIndex::default())
        .with_gossip_sync(gossip_sync)
        .with_scorer(scorer)
        .with_chain(chain)
        .with_fee_estimator(fee_estimator)
        .with_wallet(wallet)
        .with_esplora(esplora)
        .with_network(network);
    node_builder.with_logger(logger.clone());

    #[cfg(target_arch = "wasm32")]
    node_builder.with_websocket_proxy_addr(String::from("wss://p.mutinywallet.com"));

    node_builder.build().await.unwrap()
}

pub fn create_dummy_invoice(
    msats: Option<u64>,
    network: Network,
    sk: Option<SecretKey>,
) -> (Bolt11Invoice, [u8; 32]) {
    let mut preimage = [0u8; 32];
    getrandom::getrandom(&mut preimage).unwrap();
    let invoice_hash = sha256::Hash::hash(&preimage);

    let invoice = create_dummy_invoice_with_payment_hash(msats, network, sk, invoice_hash);

    (invoice, preimage)
}

pub fn create_dummy_invoice_with_payment_hash(
    msats: Option<u64>,
    network: Network,
    sk: Option<SecretKey>,
    invoice_hash: sha256::Hash,
) -> Bolt11Invoice {
    let payment_secret = &mut [0u8; 32];
    getrandom::getrandom(payment_secret).unwrap();

    let sk = sk.unwrap_or_else(|| {
        let priv_key_bytes = &mut [0u8; 32];
        getrandom::getrandom(priv_key_bytes).unwrap();
        SecretKey::from_slice(priv_key_bytes).unwrap()
    });

    let secp = Secp256k1::new();
    let builder = InvoiceBuilder::new(network.into())
        .description("Dummy invoice".to_string())
        .duration_since_epoch(now())
        .payment_hash(invoice_hash)
        .payment_secret(PaymentSecret(*payment_secret))
        .min_final_cltv_expiry_delta(144);

    let builder = if let Some(msats) = msats {
        builder.amount_milli_satoshis(msats)
    } else {
        builder
    };

    builder
        .build_signed(|hash| secp.sign_ecdsa_recoverable(hash, &sk))
        .unwrap()
}

#[allow(unused_macros)]
macro_rules! log {
        ( $( $t:tt )* ) => {
            #[cfg(target_arch = "wasm32")]
            web_sys::console::log_1(&format!( $( $t )* ).into());
            #[cfg(not(target_arch = "wasm32"))]
            println!( $( $t )* );
        }
    }
use bitcoin::hashes::{sha256, Hash};
use bitcoin::secp256k1::{Secp256k1, SecretKey};
use bitcoin::{bip32::Xpriv, Network};
use lightning::ln::PaymentSecret;
use lightning::routing::scoring::ProbabilisticScoringDecayParameters;
use lightning_invoice::{Bolt11Invoice, InvoiceBuilder};
use lightning_transaction_sync::EsploraSyncClient;
#[allow(unused_imports)]
pub(crate) use log;
use std::sync::atomic::AtomicBool;
use std::sync::Arc;
use uuid::Uuid;

use crate::node::{NetworkGraph, Node, RapidGossipSync};
use crate::nodemanager::NodeIndex;
use crate::onchain::{get_esplora_url, OnChainWallet};
use crate::scorer::{HubPreferentialScorer, ProbScorer};
use crate::storage::MutinyStorage;
use crate::utils::{now, Mutex};
use crate::MutinyWallet;
use crate::{authmanager::AuthManager, generate_seed};
use crate::{chain::MutinyChain, MutinyWalletBuilder};
use crate::{fees::MutinyFeeEstimator, MutinyWalletConfigBuilder};
use crate::{logging::MutinyLogger, node::NodeBuilder};

pub const MANAGER_BYTES: [u8; 256] = [
    1, 1, 246, 30, 238, 59, 99, 163, 128, 164, 119, 160, 99, 175, 50, 178, 187, 201, 124, 159, 249,
    240, 31, 44, 66, 37, 233, 115, 152, 129, 8, 0, 0, 0, 0, 3, 123, 222, 76, 244, 143, 88, 178,
    115, 155, 195, 17, 83, 168, 252, 26, 45, 231, 72, 39, 21, 96, 23, 203, 8, 101, 10, 238, 136,
    77, 5, 250, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 172, 120, 225, 100,
    172, 120, 225, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 113, 1, 2, 0, 0, 3, 2, 0, 0, 5,
    33, 3, 49, 56, 184, 182, 87, 71, 249, 167, 155, 99, 242, 124, 162, 190, 245, 15, 63, 119, 66,
    102, 88, 52, 223, 137, 219, 56, 27, 137, 175, 103, 200, 26, 7, 32, 23, 65, 121, 234, 117, 201,
    12, 57, 255, 124, 147, 188, 210, 48, 53, 179, 20, 157, 122, 21, 212, 195, 166, 222, 214, 124,
    167, 7, 217, 175, 93, 50, 9, 0, 11, 32, 124, 241, 131, 188, 131, 90, 195, 214, 250, 125, 197,
    126, 163, 168, 131, 111, 78, 41, 166, 218, 20, 49, 233, 172, 19, 243, 93, 239, 33, 64, 36, 240,
];

// 2 channel monitors, one before and one after a payment

pub const MONITOR_VERSION_HIGHER: [u8; 5849] = [
    1, 1, 0, 0, 0, 0, 0, 0, 0, 10, 154, 109, 35, 244, 90, 14, 0, 34, 81, 32, 65, 93, 220, 7, 194,
    50, 109, 153, 149, 239, 116, 229, 216, 194, 52, 104, 10, 212, 3, 72, 161, 38, 119, 196, 117,
    219, 30, 227, 74, 131, 60, 43, 1, 0, 22, 0, 20, 65, 10, 38, 42, 95, 246, 244, 88, 7, 193, 27,
    85, 33, 248, 164, 100, 116, 167, 81, 131, 0, 0, 0, 0, 0, 0, 153, 138, 15, 64, 0, 0, 0, 0, 101,
    9, 69, 166, 8, 100, 42, 4, 222, 170, 7, 115, 149, 79, 64, 161, 84, 83, 192, 134, 3, 210, 234,
    68, 18, 21, 39, 158, 188, 30, 48, 110, 109, 138, 227, 110, 155, 105, 174, 70, 253, 241, 91,
    239, 159, 253, 83, 253, 26, 206, 232, 60, 39, 226, 223, 127, 106, 59, 88, 192, 252, 24, 23,
    239, 254, 29, 27, 49, 165, 198, 37, 11, 20, 13, 186, 166, 171, 167, 86, 123, 223, 254, 110, 48,
    67, 0, 0, 0, 34, 0, 32, 208, 244, 191, 20, 197, 149, 7, 106, 201, 46, 119, 19, 187, 96, 162,
    41, 247, 125, 88, 42, 229, 34, 6, 202, 244, 7, 46, 78, 14, 61, 91, 97, 33, 138, 148, 48, 45,
    203, 227, 187, 163, 153, 119, 212, 255, 252, 48, 0, 40, 0, 24, 146, 167, 36, 197, 51, 122, 210,
    89, 102, 3, 242, 88, 233, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 74, 0, 33, 3, 33, 88, 253, 177, 233,
    158, 226, 126, 248, 230, 147, 151, 18, 250, 180, 242, 239, 106, 199, 121, 76, 165, 236, 84,
    151, 218, 162, 193, 73, 216, 163, 235, 2, 33, 2, 102, 194, 245, 56, 190, 148, 142, 23, 14, 18,
    212, 128, 124, 41, 30, 99, 228, 244, 77, 167, 111, 159, 210, 77, 134, 43, 250, 151, 154, 217,
    163, 226, 4, 2, 0, 144, 0, 71, 82, 33, 2, 187, 2, 3, 79, 186, 192, 60, 67, 252, 172, 82, 26,
    102, 22, 113, 168, 132, 178, 196, 196, 123, 110, 147, 195, 27, 156, 18, 200, 244, 151, 205,
    254, 33, 3, 131, 221, 176, 32, 165, 131, 251, 198, 154, 238, 179, 38, 122, 19, 19, 211, 203,
    12, 0, 199, 161, 186, 226, 233, 31, 45, 196, 174, 114, 119, 95, 177, 82, 174, 0, 0, 0, 0, 0, 1,
    168, 42, 255, 255, 255, 255, 255, 252, 3, 135, 149, 248, 137, 131, 21, 104, 28, 9, 162, 86, 55,
    4, 108, 206, 224, 27, 220, 58, 30, 188, 197, 98, 195, 108, 44, 133, 114, 206, 49, 40, 182, 3,
    221, 239, 96, 0, 35, 99, 247, 127, 194, 170, 32, 50, 6, 130, 242, 232, 73, 142, 164, 249, 68,
    253, 102, 13, 223, 206, 3, 59, 246, 69, 142, 223, 0, 6, 61, 83, 55, 40, 9, 194, 48, 133, 121,
    91, 253, 51, 163, 8, 142, 250, 101, 232, 15, 239, 217, 168, 110, 45, 90, 138, 230, 5, 159, 56,
    125, 34, 0, 0, 255, 255, 255, 255, 255, 253, 48, 252, 253, 73, 72, 56, 121, 88, 202, 181, 51,
    186, 28, 206, 74, 120, 173, 68, 51, 31, 238, 48, 11, 84, 231, 180, 255, 150, 232, 148, 83, 26,
    0, 0, 255, 255, 255, 255, 255, 254, 139, 124, 72, 238, 170, 26, 98, 126, 151, 25, 85, 15, 71,
    147, 79, 45, 42, 151, 184, 210, 112, 39, 107, 62, 58, 97, 198, 210, 239, 164, 202, 50, 0, 0,
    255, 255, 255, 255, 255, 252, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 5, 96, 10, 179, 100, 168, 83, 45, 155, 65, 255, 164, 116, 148, 201, 149, 185, 13, 76,
    254, 163, 131, 243, 222, 206, 17, 175, 172, 185, 120, 76, 110, 174, 0, 0, 0, 0, 0, 0, 0, 0, 49,
    11, 0, 30, 89, 85, 93, 242, 225, 196, 247, 145, 235, 201, 222, 76, 204, 163, 180, 193, 90, 79,
    60, 70, 161, 206, 157, 206, 204, 111, 40, 202, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3,
    233, 0, 6, 120, 31, 232, 188, 222, 158, 69, 94, 212, 160, 13, 108, 187, 217, 29, 36, 140, 143,
    45, 142, 221, 104, 236, 91, 178, 211, 230, 248, 245, 208, 152, 72, 19, 236, 0, 0, 138, 148, 48,
    45, 203, 227, 187, 163, 153, 119, 212, 255, 252, 48, 0, 40, 0, 24, 146, 167, 36, 197, 51, 122,
    210, 89, 102, 3, 242, 88, 233, 191, 0, 0, 0, 0, 0, 0, 0, 0, 93, 30, 191, 211, 132, 13, 223, 28,
    30, 155, 213, 28, 146, 28, 240, 23, 133, 82, 103, 92, 34, 212, 33, 88, 197, 9, 104, 15, 105,
    87, 104, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 25, 99, 36, 213, 104, 22, 164, 98, 20, 155, 99, 230,
    147, 53, 36, 1, 203, 131, 128, 171, 157, 191, 180, 109, 116, 39, 25, 150, 155, 79, 163, 0, 0,
    0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 114, 112, 224, 0, 6, 119, 81, 98, 164, 145, 193, 45, 31,
    120, 243, 144, 168, 100, 49, 84, 4, 224, 73, 72, 92, 90, 213, 166, 100, 246, 66, 103, 26, 243,
    246, 153, 133, 173, 59, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 232,
    188, 222, 158, 69, 94, 212, 160, 13, 108, 187, 217, 29, 36, 140, 143, 45, 142, 221, 104, 236,
    91, 178, 211, 230, 248, 245, 208, 152, 72, 19, 236, 255, 255, 255, 255, 255, 252, 1, 253, 2, 5,
    0, 32, 240, 36, 143, 171, 249, 153, 75, 141, 246, 252, 141, 209, 37, 176, 178, 5, 117, 242,
    143, 140, 232, 13, 166, 18, 6, 216, 227, 16, 114, 252, 62, 192, 1, 8, 0, 0, 0, 0, 0, 0, 29, 74,
    2, 33, 2, 247, 34, 149, 238, 169, 171, 219, 3, 202, 193, 58, 240, 240, 137, 207, 86, 202, 232,
    140, 14, 53, 247, 218, 92, 84, 243, 232, 62, 175, 106, 234, 190, 4, 33, 3, 231, 119, 4, 90,
    125, 246, 84, 13, 54, 22, 216, 252, 145, 174, 245, 72, 143, 6, 214, 142, 169, 46, 90, 172, 133,
    104, 158, 65, 198, 4, 30, 160, 6, 33, 2, 211, 122, 58, 31, 71, 2, 45, 67, 29, 120, 151, 222,
    10, 201, 133, 51, 19, 121, 126, 166, 229, 158, 89, 93, 135, 55, 118, 28, 228, 32, 0, 159, 8,
    33, 2, 113, 136, 197, 1, 1, 148, 130, 150, 88, 246, 16, 246, 173, 185, 162, 156, 2, 114, 139,
    207, 179, 58, 164, 123, 1, 18, 141, 118, 222, 66, 231, 96, 10, 33, 3, 40, 122, 215, 156, 220,
    181, 67, 246, 235, 119, 185, 229, 133, 56, 178, 33, 14, 251, 214, 74, 32, 3, 135, 146, 115,
    139, 130, 127, 75, 209, 164, 99, 12, 4, 0, 0, 1, 12, 14, 253, 1, 32, 53, 0, 1, 1, 2, 8, 0, 0,
    0, 0, 0, 0, 3, 233, 4, 4, 0, 6, 120, 31, 6, 32, 232, 188, 222, 158, 69, 94, 212, 160, 13, 108,
    187, 217, 29, 36, 140, 143, 45, 142, 221, 104, 236, 91, 178, 211, 230, 248, 245, 208, 152, 72,
    19, 236, 0, 233, 0, 230, 0, 32, 105, 253, 117, 112, 209, 74, 81, 80, 27, 29, 166, 200, 135, 23,
    245, 174, 215, 1, 166, 81, 194, 158, 229, 182, 9, 237, 14, 186, 250, 96, 208, 218, 1, 32, 232,
    188, 222, 158, 69, 94, 212, 160, 13, 108, 187, 217, 29, 36, 140, 143, 45, 142, 221, 104, 236,
    91, 178, 211, 230, 248, 245, 208, 152, 72, 19, 236, 2, 8, 0, 0, 0, 0, 0, 0, 3, 233, 4, 150, 76,
    0, 33, 3, 102, 171, 200, 235, 77, 166, 30, 49, 168, 210, 196, 82, 13, 49, 202, 189, 245, 140,
    197, 37, 15, 133, 86, 87, 57, 127, 61, 214, 36, 147, 147, 138, 2, 9, 0, 7, 8, 160, 0, 8, 10,
    97, 162, 4, 8, 6, 119, 38, 0, 0, 1, 0, 0, 6, 2, 0, 0, 8, 8, 0, 0, 0, 0, 0, 0, 0, 1, 10, 4, 0,
    0, 0, 6, 72, 0, 33, 2, 70, 94, 213, 190, 83, 208, 79, 222, 102, 201, 65, 143, 241, 74, 95, 34,
    103, 114, 56, 16, 23, 108, 146, 18, 183, 34, 229, 66, 220, 26, 251, 27, 2, 5, 0, 3, 2, 66, 0,
    4, 8, 0, 163, 91, 0, 0, 1, 0, 1, 6, 2, 0, 0, 8, 8, 0, 0, 0, 0, 0, 0, 3, 232, 10, 4, 0, 0, 0,
    240, 227, 0, 32, 57, 122, 179, 1, 7, 26, 130, 195, 196, 99, 62, 192, 228, 125, 160, 15, 88,
    109, 160, 95, 173, 118, 136, 134, 116, 254, 120, 47, 153, 245, 218, 163, 1, 8, 0, 0, 0, 0, 0,
    0, 29, 74, 2, 33, 3, 185, 187, 202, 237, 76, 100, 33, 67, 198, 106, 20, 53, 255, 236, 90, 244,
    165, 82, 94, 183, 161, 91, 17, 155, 79, 22, 125, 85, 241, 192, 221, 22, 4, 33, 2, 102, 100, 0,
    142, 24, 185, 50, 208, 0, 31, 53, 171, 84, 151, 45, 201, 84, 247, 94, 197, 103, 203, 69, 109,
    61, 31, 28, 105, 121, 32, 139, 49, 6, 33, 2, 177, 97, 28, 79, 202, 157, 135, 59, 69, 84, 121,
    188, 148, 189, 154, 124, 179, 159, 221, 108, 102, 101, 13, 21, 252, 172, 226, 253, 236, 122,
    87, 141, 8, 33, 3, 228, 66, 52, 168, 196, 34, 8, 67, 145, 248, 210, 70, 197, 31, 154, 136, 216,
    242, 131, 18, 20, 102, 217, 167, 229, 9, 70, 170, 244, 138, 147, 105, 10, 33, 2, 100, 202, 68,
    171, 169, 58, 210, 226, 81, 178, 210, 143, 154, 242, 64, 64, 157, 121, 44, 104, 255, 179, 20,
    201, 86, 92, 20, 252, 246, 4, 197, 2, 12, 4, 0, 0, 1, 12, 14, 0, 255, 255, 255, 255, 255, 251,
    255, 255, 255, 255, 255, 251, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 128, 20, 236, 103, 32, 226, 239, 255, 29, 0, 198, 148, 224, 30, 143, 152, 92, 206, 6, 26,
    175, 144, 0, 153, 187, 27, 143, 131, 91, 3, 0, 0, 0, 6, 119, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 1, 226, 223, 127, 106, 59, 88, 192, 252, 24, 23, 239, 254, 29, 27, 49, 165, 198,
    37, 11, 20, 13, 186, 166, 171, 167, 86, 123, 223, 254, 110, 48, 67, 0, 0, 0, 0, 0, 0, 0, 1, 0,
    0, 0, 0, 0, 34, 0, 32, 208, 244, 191, 20, 197, 149, 7, 106, 201, 46, 119, 19, 187, 96, 162, 41,
    247, 125, 88, 42, 229, 34, 6, 202, 244, 7, 46, 78, 14, 61, 91, 97, 1, 1, 0, 34, 81, 32, 65, 93,
    220, 7, 194, 50, 109, 153, 149, 239, 116, 229, 216, 194, 52, 104, 10, 212, 3, 72, 161, 38, 119,
    196, 117, 219, 30, 227, 74, 131, 60, 43, 253, 1, 206, 0, 253, 1, 131, 253, 1, 128, 0, 8, 0, 0,
    255, 255, 255, 255, 255, 251, 2, 8, 0, 0, 0, 0, 0, 0, 29, 74, 4, 8, 0, 0, 0, 0, 0, 1, 138, 29,
    6, 4, 0, 0, 1, 12, 8, 176, 175, 0, 33, 2, 100, 202, 68, 171, 169, 58, 210, 226, 81, 178, 210,
    143, 154, 242, 64, 64, 157, 121, 44, 104, 255, 179, 20, 201, 86, 92, 20, 252, 246, 4, 197, 2,
    2, 33, 3, 185, 187, 202, 237, 76, 100, 33, 67, 198, 106, 20, 53, 255, 236, 90, 244, 165, 82,
    94, 183, 161, 91, 17, 155, 79, 22, 125, 85, 241, 192, 221, 22, 4, 33, 2, 102, 100, 0, 142, 24,
    185, 50, 208, 0, 31, 53, 171, 84, 151, 45, 201, 84, 247, 94, 197, 103, 203, 69, 109, 61, 31,
    28, 105, 121, 32, 139, 49, 6, 33, 2, 177, 97, 28, 79, 202, 157, 135, 59, 69, 84, 121, 188, 148,
    189, 154, 124, 179, 159, 221, 108, 102, 101, 13, 21, 252, 172, 226, 253, 236, 122, 87, 141, 8,
    33, 3, 228, 66, 52, 168, 196, 34, 8, 67, 145, 248, 210, 70, 197, 31, 154, 136, 216, 242, 131,
    18, 20, 102, 217, 167, 229, 9, 70, 170, 244, 138, 147, 105, 10, 162, 161, 0, 125, 2, 0, 0, 0,
    1, 226, 223, 127, 106, 59, 88, 192, 252, 24, 23, 239, 254, 29, 27, 49, 165, 198, 37, 11, 20,
    13, 186, 166, 171, 167, 86, 123, 223, 254, 110, 48, 67, 0, 0, 0, 0, 0, 35, 109, 154, 128, 2,
    74, 29, 0, 0, 0, 0, 0, 0, 34, 0, 32, 51, 4, 230, 6, 41, 209, 178, 200, 117, 186, 85, 189, 102,
    86, 23, 247, 244, 73, 239, 128, 237, 10, 200, 54, 30, 1, 62, 112, 193, 56, 254, 65, 29, 138, 1,
    0, 0, 0, 0, 0, 22, 0, 20, 51, 158, 131, 246, 71, 104, 102, 154, 80, 177, 165, 227, 253, 31,
    103, 124, 143, 230, 217, 25, 10, 90, 244, 32, 2, 32, 57, 122, 179, 1, 7, 26, 130, 195, 196, 99,
    62, 192, 228, 125, 160, 15, 88, 109, 160, 95, 173, 118, 136, 134, 116, 254, 120, 47, 153, 245,
    218, 163, 12, 0, 15, 2, 16, 0, 2, 64, 115, 40, 21, 5, 135, 46, 119, 177, 184, 231, 240, 114,
    236, 75, 182, 243, 27, 95, 82, 250, 32, 205, 70, 195, 27, 15, 218, 161, 38, 100, 141, 74, 49,
    24, 225, 47, 6, 186, 141, 96, 182, 237, 203, 63, 114, 2, 179, 26, 242, 244, 75, 43, 193, 33,
    45, 118, 237, 7, 2, 143, 249, 63, 220, 252, 4, 1, 1, 6, 0, 0, 253, 1, 210, 253, 1, 206, 0, 253,
    1, 131, 253, 1, 128, 0, 8, 0, 0, 255, 255, 255, 255, 255, 252, 2, 8, 0, 0, 0, 0, 0, 0, 29, 74,
    4, 8, 0, 0, 0, 0, 0, 1, 138, 28, 6, 4, 0, 0, 1, 12, 8, 176, 175, 0, 33, 3, 40, 122, 215, 156,
    220, 181, 67, 246, 235, 119, 185, 229, 133, 56, 178, 33, 14, 251, 214, 74, 32, 3, 135, 146,
    115, 139, 130, 127, 75, 209, 164, 99, 2, 33, 2, 247, 34, 149, 238, 169, 171, 219, 3, 202, 193,
    58, 240, 240, 137, 207, 86, 202, 232, 140, 14, 53, 247, 218, 92, 84, 243, 232, 62, 175, 106,
    234, 190, 4, 33, 3, 231, 119, 4, 90, 125, 246, 84, 13, 54, 22, 216, 252, 145, 174, 245, 72,
    143, 6, 214, 142, 169, 46, 90, 172, 133, 104, 158, 65, 198, 4, 30, 160, 6, 33, 2, 211, 122, 58,
    31, 71, 2, 45, 67, 29, 120, 151, 222, 10, 201, 133, 51, 19, 121, 126, 166, 229, 158, 89, 93,
    135, 55, 118, 28, 228, 32, 0, 159, 8, 33, 2, 113, 136, 197, 1, 1, 148, 130, 150, 88, 246, 16,
    246, 173, 185, 162, 156, 2, 114, 139, 207, 179, 58, 164, 123, 1, 18, 141, 118, 222, 66, 231,
    96, 10, 162, 161, 0, 125, 2, 0, 0, 0, 1, 226, 223, 127, 106, 59, 88, 192, 252, 24, 23, 239,
    254, 29, 27, 49, 165, 198, 37, 11, 20, 13, 186, 166, 171, 167, 86, 123, 223, 254, 110, 48, 67,
    0, 0, 0, 0, 0, 35, 109, 154, 128, 2, 74, 29, 0, 0, 0, 0, 0, 0, 34, 0, 32, 131, 194, 90, 26, 85,
    49, 65, 217, 161, 229, 61, 70, 238, 75, 71, 104, 199, 50, 9, 138, 229, 54, 86, 11, 111, 218,
    185, 204, 87, 142, 216, 222, 28, 138, 1, 0, 0, 0, 0, 0, 22, 0, 20, 51, 158, 131, 246, 71, 104,
    102, 154, 80, 177, 165, 227, 253, 31, 103, 124, 143, 230, 217, 25, 13, 90, 244, 32, 2, 32, 240,
    36, 143, 171, 249, 153, 75, 141, 246, 252, 141, 209, 37, 176, 178, 5, 117, 242, 143, 140, 232,
    13, 166, 18, 6, 216, 227, 16, 114, 252, 62, 192, 12, 0, 15, 2, 16, 0, 2, 64, 100, 121, 216,
    130, 76, 139, 132, 137, 143, 51, 254, 166, 124, 124, 92, 99, 76, 194, 115, 254, 105, 139, 126,
    84, 8, 150, 81, 40, 112, 192, 235, 222, 81, 51, 197, 211, 166, 29, 236, 68, 111, 13, 4, 189,
    89, 161, 221, 139, 119, 233, 155, 245, 105, 88, 213, 141, 173, 99, 88, 166, 202, 37, 119, 4, 4,
    1, 1, 6, 0, 0, 253, 1, 154, 0, 176, 175, 0, 33, 2, 187, 2, 3, 79, 186, 192, 60, 67, 252, 172,
    82, 26, 102, 22, 113, 168, 132, 178, 196, 196, 123, 110, 147, 195, 27, 156, 18, 200, 244, 151,
    205, 254, 2, 33, 3, 210, 234, 68, 18, 21, 39, 158, 188, 30, 48, 110, 109, 138, 227, 110, 155,
    105, 174, 70, 253, 241, 91, 239, 159, 253, 83, 253, 26, 206, 232, 60, 39, 4, 33, 2, 244, 19,
    142, 111, 20, 44, 233, 125, 191, 160, 222, 234, 95, 70, 122, 5, 96, 41, 155, 121, 3, 213, 132,
    63, 131, 69, 15, 228, 130, 253, 114, 21, 6, 33, 2, 63, 234, 246, 244, 91, 189, 96, 58, 68, 236,
    168, 170, 63, 146, 247, 33, 150, 16, 148, 180, 104, 75, 188, 198, 143, 249, 6, 27, 73, 164, 78,
    202, 8, 33, 3, 76, 42, 89, 187, 90, 189, 240, 115, 251, 1, 44, 247, 198, 84, 118, 102, 173, 11,
    202, 151, 61, 122, 222, 253, 36, 37, 19, 183, 217, 8, 229, 173, 2, 2, 0, 144, 4, 1, 0, 6, 183,
    182, 0, 176, 175, 0, 33, 3, 131, 221, 176, 32, 165, 131, 251, 198, 154, 238, 179, 38, 122, 19,
    19, 211, 203, 12, 0, 199, 161, 186, 226, 233, 31, 45, 196, 174, 114, 119, 95, 177, 2, 33, 2,
    45, 83, 223, 96, 212, 69, 226, 199, 245, 94, 185, 86, 181, 149, 106, 88, 201, 145, 45, 215,
    114, 176, 188, 203, 21, 191, 3, 104, 100, 163, 204, 122, 4, 33, 3, 183, 46, 17, 0, 22, 89, 15,
    4, 245, 60, 239, 75, 44, 83, 246, 243, 29, 25, 163, 57, 190, 142, 154, 163, 166, 210, 146, 62,
    254, 20, 139, 230, 6, 33, 3, 33, 88, 253, 177, 233, 158, 226, 126, 248, 230, 147, 151, 18, 250,
    180, 242, 239, 106, 199, 121, 76, 165, 236, 84, 151, 218, 162, 193, 73, 216, 163, 235, 8, 33,
    2, 102, 194, 245, 56, 190, 148, 142, 23, 14, 18, 212, 128, 124, 41, 30, 99, 228, 244, 77, 167,
    111, 159, 210, 77, 134, 43, 250, 151, 154, 217, 163, 226, 2, 2, 0, 6, 8, 34, 226, 223, 127,
    106, 59, 88, 192, 252, 24, 23, 239, 254, 29, 27, 49, 165, 198, 37, 11, 20, 13, 186, 166, 171,
    167, 86, 123, 223, 254, 110, 48, 67, 0, 0, 11, 2, 16, 0, 0, 0, 2, 139, 1, 1, 135, 211, 13, 56,
    138, 53, 76, 177, 22, 89, 33, 173, 232, 104, 58, 46, 9, 214, 248, 141, 2, 74, 73, 175, 151,
    192, 64, 152, 26, 208, 88, 28, 68, 148, 225, 145, 60, 246, 85, 136, 233, 107, 89, 21, 33, 187,
    115, 203, 12, 155, 5, 18, 98, 20, 216, 147, 53, 226, 212, 241, 106, 200, 172, 245, 84, 75, 149,
    55, 54, 37, 197, 178, 195, 160, 223, 29, 37, 12, 142, 168, 202, 82, 118, 153, 95, 154, 132, 46,
    239, 233, 98, 178, 156, 104, 110, 178, 4, 73, 61, 133, 51, 69, 166, 249, 177, 47, 251, 109,
    231, 4, 111, 77, 48, 253, 113, 109, 128, 180, 136, 29, 3, 245, 150, 23, 165, 156, 30, 74, 184,
    6, 55, 180, 180, 179, 100, 37, 185, 14, 208, 210, 191, 137, 29, 30, 7, 12, 226, 111, 250, 114,
    70, 237, 180, 55, 24, 175, 130, 153, 26, 57, 69, 59, 171, 225, 158, 186, 169, 209, 50, 235,
    250, 170, 88, 118, 12, 37, 103, 189, 106, 253, 106, 113, 255, 235, 229, 216, 39, 40, 62, 199,
    224, 43, 253, 1, 158, 253, 1, 154, 0, 176, 175, 0, 33, 2, 187, 2, 3, 79, 186, 192, 60, 67, 252,
    172, 82, 26, 102, 22, 113, 168, 132, 178, 196, 196, 123, 110, 147, 195, 27, 156, 18, 200, 244,
    151, 205, 254, 2, 33, 3, 210, 234, 68, 18, 21, 39, 158, 188, 30, 48, 110, 109, 138, 227, 110,
    155, 105, 174, 70, 253, 241, 91, 239, 159, 253, 83, 253, 26, 206, 232, 60, 39, 4, 33, 2, 244,
    19, 142, 111, 20, 44, 233, 125, 191, 160, 222, 234, 95, 70, 122, 5, 96, 41, 155, 121, 3, 213,
    132, 63, 131, 69, 15, 228, 130, 253, 114, 21, 6, 33, 2, 63, 234, 246, 244, 91, 189, 96, 58, 68,
    236, 168, 170, 63, 146, 247, 33, 150, 16, 148, 180, 104, 75, 188, 198, 143, 249, 6, 27, 73,
    164, 78, 202, 8, 33, 3, 76, 42, 89, 187, 90, 189, 240, 115, 251, 1, 44, 247, 198, 84, 118, 102,
    173, 11, 202, 151, 61, 122, 222, 253, 36, 37, 19, 183, 217, 8, 229, 173, 2, 2, 0, 144, 4, 1, 0,
    6, 183, 182, 0, 176, 175, 0, 33, 3, 131, 221, 176, 32, 165, 131, 251, 198, 154, 238, 179, 38,
    122, 19, 19, 211, 203, 12, 0, 199, 161, 186, 226, 233, 31, 45, 196, 174, 114, 119, 95, 177, 2,
    33, 2, 45, 83, 223, 96, 212, 69, 226, 199, 245, 94, 185, 86, 181, 149, 106, 88, 201, 145, 45,
    215, 114, 176, 188, 203, 21, 191, 3, 104, 100, 163, 204, 122, 4, 33, 3, 183, 46, 17, 0, 22, 89,
    15, 4, 245, 60, 239, 75, 44, 83, 246, 243, 29, 25, 163, 57, 190, 142, 154, 163, 166, 210, 146,
    62, 254, 20, 139, 230, 6, 33, 3, 33, 88, 253, 177, 233, 158, 226, 126, 248, 230, 147, 151, 18,
    250, 180, 242, 239, 106, 199, 121, 76, 165, 236, 84, 151, 218, 162, 193, 73, 216, 163, 235, 8,
    33, 2, 102, 194, 245, 56, 190, 148, 142, 23, 14, 18, 212, 128, 124, 41, 30, 99, 228, 244, 77,
    167, 111, 159, 210, 77, 134, 43, 250, 151, 154, 217, 163, 226, 2, 2, 0, 6, 8, 34, 226, 223,
    127, 106, 59, 88, 192, 252, 24, 23, 239, 254, 29, 27, 49, 165, 198, 37, 11, 20, 13, 186, 166,
    171, 167, 86, 123, 223, 254, 110, 48, 67, 0, 0, 11, 2, 16, 0, 0, 0, 0, 0, 0, 1, 168, 42, 0, 0,
    0, 0, 153, 138, 15, 64, 0, 0, 0, 0, 101, 9, 69, 166, 8, 100, 42, 4, 222, 170, 7, 115, 149, 79,
    64, 161, 84, 83, 192, 134, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 48, 3, 0, 5, 0, 7, 1, 0, 9, 33, 3, 102, 171, 200, 235,
    77, 166, 30, 49, 168, 210, 196, 82, 13, 49, 202, 189, 245, 140, 197, 37, 15, 133, 86, 87, 57,
    127, 61, 214, 36, 147, 147, 138, 13, 0, 15, 2, 0, 0,
];
pub const MONITOR_VERSION_LOWER: [u8; 5714] = [
    1, 1, 0, 0, 0, 0, 0, 0, 0, 5, 154, 109, 35, 244, 90, 14, 0, 34, 81, 32, 65, 93, 220, 7, 194,
    50, 109, 153, 149, 239, 116, 229, 216, 194, 52, 104, 10, 212, 3, 72, 161, 38, 119, 196, 117,
    219, 30, 227, 74, 131, 60, 43, 1, 0, 22, 0, 20, 65, 10, 38, 42, 95, 246, 244, 88, 7, 193, 27,
    85, 33, 248, 164, 100, 116, 167, 81, 131, 0, 0, 0, 0, 0, 0, 153, 138, 15, 64, 0, 0, 0, 0, 101,
    9, 69, 166, 8, 100, 42, 4, 222, 170, 7, 115, 149, 79, 64, 161, 84, 83, 192, 134, 3, 210, 234,
    68, 18, 21, 39, 158, 188, 30, 48, 110, 109, 138, 227, 110, 155, 105, 174, 70, 253, 241, 91,
    239, 159, 253, 83, 253, 26, 206, 232, 60, 39, 226, 223, 127, 106, 59, 88, 192, 252, 24, 23,
    239, 254, 29, 27, 49, 165, 198, 37, 11, 20, 13, 186, 166, 171, 167, 86, 123, 223, 254, 110, 48,
    67, 0, 0, 0, 34, 0, 32, 208, 244, 191, 20, 197, 149, 7, 106, 201, 46, 119, 19, 187, 96, 162,
    41, 247, 125, 88, 42, 229, 34, 6, 202, 244, 7, 46, 78, 14, 61, 91, 97, 33, 93, 30, 191, 211,
    132, 13, 223, 28, 30, 155, 213, 28, 146, 28, 240, 23, 133, 82, 103, 92, 34, 212, 33, 88, 197,
    9, 104, 15, 105, 87, 104, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 74, 0, 33, 3, 33, 88, 253, 177, 233,
    158, 226, 126, 248, 230, 147, 151, 18, 250, 180, 242, 239, 106, 199, 121, 76, 165, 236, 84,
    151, 218, 162, 193, 73, 216, 163, 235, 2, 33, 2, 102, 194, 245, 56, 190, 148, 142, 23, 14, 18,
    212, 128, 124, 41, 30, 99, 228, 244, 77, 167, 111, 159, 210, 77, 134, 43, 250, 151, 154, 217,
    163, 226, 4, 2, 0, 144, 0, 71, 82, 33, 2, 187, 2, 3, 79, 186, 192, 60, 67, 252, 172, 82, 26,
    102, 22, 113, 168, 132, 178, 196, 196, 123, 110, 147, 195, 27, 156, 18, 200, 244, 151, 205,
    254, 33, 3, 131, 221, 176, 32, 165, 131, 251, 198, 154, 238, 179, 38, 122, 19, 19, 211, 203,
    12, 0, 199, 161, 186, 226, 233, 31, 45, 196, 174, 114, 119, 95, 177, 82, 174, 0, 0, 0, 0, 0, 1,
    168, 42, 255, 255, 255, 255, 255, 254, 2, 119, 114, 90, 44, 154, 8, 139, 43, 248, 20, 53, 160,
    39, 155, 42, 205, 51, 89, 215, 173, 239, 34, 207, 251, 99, 149, 117, 197, 34, 191, 28, 219, 2,
    247, 74, 82, 189, 189, 227, 98, 56, 93, 114, 253, 246, 1, 34, 4, 87, 75, 195, 80, 35, 197, 243,
    129, 135, 119, 209, 52, 48, 35, 12, 233, 218, 0, 6, 81, 230, 208, 171, 171, 61, 180, 114, 98,
    13, 153, 144, 117, 231, 52, 180, 150, 77, 227, 78, 247, 176, 113, 68, 195, 220, 221, 87, 178,
    84, 146, 24, 0, 0, 255, 255, 255, 255, 255, 255, 48, 252, 253, 73, 72, 56, 121, 88, 202, 181,
    51, 186, 28, 206, 74, 120, 173, 68, 51, 31, 238, 48, 11, 84, 231, 180, 255, 150, 232, 148, 83,
    26, 0, 0, 255, 255, 255, 255, 255, 254, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 96, 10, 179, 100, 168, 83, 45, 155, 65, 255, 164,
    116, 148, 201, 149, 185, 13, 76, 254, 163, 131, 243, 222, 206, 17, 175, 172, 185, 120, 76, 110,
    174, 0, 0, 0, 0, 0, 0, 0, 0, 93, 30, 191, 211, 132, 13, 223, 28, 30, 155, 213, 28, 146, 28,
    240, 23, 133, 82, 103, 92, 34, 212, 33, 88, 197, 9, 104, 15, 105, 87, 104, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 45, 25, 99, 36, 213, 104, 22, 164, 98, 20, 155, 99, 230, 147, 53, 36, 1, 203, 131, 128,
    171, 157, 191, 180, 109, 116, 39, 25, 150, 155, 79, 163, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,
    0, 114, 112, 224, 0, 6, 119, 81, 98, 164, 145, 193, 45, 31, 120, 243, 144, 168, 100, 49, 84, 4,
    224, 73, 72, 92, 90, 213, 166, 100, 246, 66, 103, 26, 243, 246, 153, 133, 173, 59, 5, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 98, 164, 145, 193, 45, 31, 120, 243, 144,
    168, 100, 49, 84, 4, 224, 73, 72, 92, 90, 213, 166, 100, 246, 66, 103, 26, 243, 246, 153, 133,
    173, 59, 255, 255, 255, 255, 255, 254, 1, 253, 1, 97, 0, 32, 89, 217, 56, 33, 63, 107, 197, 44,
    64, 80, 134, 90, 183, 137, 23, 25, 45, 100, 192, 240, 112, 73, 8, 50, 77, 16, 167, 36, 10, 142,
    187, 118, 1, 8, 0, 0, 0, 0, 0, 0, 0, 0, 2, 33, 2, 15, 137, 104, 72, 210, 98, 222, 187, 143,
    161, 238, 208, 85, 191, 192, 166, 99, 127, 139, 155, 243, 39, 242, 172, 117, 196, 153, 176, 86,
    203, 0, 47, 4, 33, 3, 145, 83, 28, 120, 41, 12, 163, 45, 249, 88, 105, 185, 130, 77, 228, 169,
    21, 241, 114, 192, 231, 75, 138, 21, 193, 194, 89, 100, 165, 86, 190, 94, 6, 33, 2, 97, 95, 89,
    103, 186, 249, 85, 156, 250, 70, 98, 33, 19, 131, 201, 65, 216, 117, 134, 107, 249, 69, 65, 20,
    86, 97, 151, 141, 126, 165, 18, 82, 8, 33, 2, 85, 204, 109, 230, 216, 30, 33, 108, 62, 43, 13,
    255, 136, 174, 50, 235, 129, 103, 240, 176, 16, 46, 218, 47, 162, 71, 33, 26, 190, 13, 53, 239,
    10, 33, 3, 158, 20, 175, 174, 221, 138, 182, 249, 11, 94, 240, 251, 232, 201, 73, 25, 247, 123,
    108, 198, 153, 89, 84, 209, 127, 114, 55, 144, 120, 149, 13, 222, 12, 4, 0, 0, 1, 12, 14, 126,
    59, 0, 1, 0, 2, 8, 0, 0, 0, 0, 0, 114, 112, 224, 4, 4, 0, 6, 119, 81, 6, 32, 98, 164, 145, 193,
    45, 31, 120, 243, 144, 168, 100, 49, 84, 4, 224, 73, 72, 92, 90, 213, 166, 100, 246, 66, 103,
    26, 243, 246, 153, 133, 173, 59, 8, 4, 0, 0, 0, 0, 65, 73, 28, 136, 174, 80, 53, 242, 220, 98,
    76, 43, 50, 6, 2, 5, 205, 185, 103, 13, 169, 25, 93, 148, 104, 201, 117, 18, 196, 1, 65, 178,
    246, 38, 196, 230, 182, 133, 110, 195, 98, 252, 95, 151, 252, 54, 201, 159, 219, 167, 215, 133,
    122, 181, 50, 26, 125, 229, 215, 232, 138, 118, 243, 204, 167, 0, 227, 0, 32, 17, 181, 23, 102,
    210, 241, 125, 227, 46, 171, 126, 131, 218, 214, 253, 66, 22, 116, 205, 142, 85, 228, 175, 72,
    131, 154, 83, 153, 47, 184, 157, 94, 1, 8, 0, 0, 0, 0, 0, 0, 29, 76, 2, 33, 2, 175, 165, 163,
    174, 79, 249, 13, 185, 133, 20, 147, 249, 194, 94, 7, 71, 200, 101, 121, 72, 2, 16, 192, 254,
    121, 87, 124, 156, 129, 38, 193, 125, 4, 33, 2, 28, 121, 32, 158, 56, 3, 101, 176, 228, 108,
    52, 175, 90, 109, 116, 106, 158, 4, 106, 84, 11, 85, 175, 203, 177, 244, 74, 236, 242, 188,
    240, 230, 6, 33, 2, 60, 227, 70, 247, 179, 167, 49, 36, 118, 149, 141, 81, 75, 108, 203, 16,
    246, 243, 177, 242, 116, 25, 218, 67, 219, 185, 182, 104, 73, 24, 120, 9, 8, 33, 2, 224, 26,
    168, 176, 116, 253, 116, 195, 181, 240, 156, 83, 203, 56, 217, 21, 4, 252, 206, 47, 228, 126,
    106, 217, 229, 94, 15, 205, 229, 100, 206, 29, 10, 33, 3, 177, 222, 79, 53, 98, 224, 242, 44,
    101, 16, 136, 157, 31, 227, 224, 74, 42, 163, 135, 176, 53, 119, 107, 139, 182, 243, 177, 220,
    154, 15, 135, 249, 12, 4, 0, 0, 1, 12, 14, 0, 255, 255, 255, 255, 255, 253, 255, 255, 255, 255,
    255, 253, 0, 0, 0, 0, 0, 0, 0, 1, 201, 23, 62, 65, 84, 63, 137, 186, 185, 147, 134, 140, 99,
    135, 108, 219, 50, 127, 85, 78, 39, 244, 54, 22, 164, 110, 100, 107, 224, 32, 19, 197, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 225, 179, 23, 201, 41, 253, 56, 169, 186, 130, 87, 217,
    208, 223, 235, 162, 73, 126, 102, 80, 241, 62, 97, 181, 44, 135, 110, 72, 6, 1, 0, 0, 0, 6,
    119, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 226, 223, 127, 106, 59, 88, 192, 252,
    24, 23, 239, 254, 29, 27, 49, 165, 198, 37, 11, 20, 13, 186, 166, 171, 167, 86, 123, 223, 254,
    110, 48, 67, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 34, 0, 32, 208, 244, 191, 20, 197, 149, 7,
    106, 201, 46, 119, 19, 187, 96, 162, 41, 247, 125, 88, 42, 229, 34, 6, 202, 244, 7, 46, 78, 14,
    61, 91, 97, 1, 1, 0, 34, 81, 32, 65, 93, 220, 7, 194, 50, 109, 153, 149, 239, 116, 229, 216,
    194, 52, 104, 10, 212, 3, 72, 161, 38, 119, 196, 117, 219, 30, 227, 74, 131, 60, 43, 253, 1,
    206, 0, 253, 1, 131, 253, 1, 128, 0, 8, 0, 0, 255, 255, 255, 255, 255, 253, 2, 8, 0, 0, 0, 0,
    0, 0, 29, 76, 4, 8, 0, 0, 0, 0, 0, 1, 138, 28, 6, 4, 0, 0, 1, 12, 8, 176, 175, 0, 33, 3, 177,
    222, 79, 53, 98, 224, 242, 44, 101, 16, 136, 157, 31, 227, 224, 74, 42, 163, 135, 176, 53, 119,
    107, 139, 182, 243, 177, 220, 154, 15, 135, 249, 2, 33, 2, 175, 165, 163, 174, 79, 249, 13,
    185, 133, 20, 147, 249, 194, 94, 7, 71, 200, 101, 121, 72, 2, 16, 192, 254, 121, 87, 124, 156,
    129, 38, 193, 125, 4, 33, 2, 28, 121, 32, 158, 56, 3, 101, 176, 228, 108, 52, 175, 90, 109,
    116, 106, 158, 4, 106, 84, 11, 85, 175, 203, 177, 244, 74, 236, 242, 188, 240, 230, 6, 33, 2,
    60, 227, 70, 247, 179, 167, 49, 36, 118, 149, 141, 81, 75, 108, 203, 16, 246, 243, 177, 242,
    116, 25, 218, 67, 219, 185, 182, 104, 73, 24, 120, 9, 8, 33, 2, 224, 26, 168, 176, 116, 253,
    116, 195, 181, 240, 156, 83, 203, 56, 217, 21, 4, 252, 206, 47, 228, 126, 106, 217, 229, 94,
    15, 205, 229, 100, 206, 29, 10, 162, 161, 0, 125, 2, 0, 0, 0, 1, 226, 223, 127, 106, 59, 88,
    192, 252, 24, 23, 239, 254, 29, 27, 49, 165, 198, 37, 11, 20, 13, 186, 166, 171, 167, 86, 123,
    223, 254, 110, 48, 67, 0, 0, 0, 0, 0, 35, 109, 154, 128, 2, 76, 29, 0, 0, 0, 0, 0, 0, 34, 0,
    32, 51, 225, 205, 29, 34, 103, 27, 41, 45, 87, 228, 143, 80, 119, 195, 209, 26, 8, 150, 85, 30,
    243, 164, 98, 185, 70, 152, 237, 233, 132, 251, 74, 28, 138, 1, 0, 0, 0, 0, 0, 22, 0, 20, 51,
    158, 131, 246, 71, 104, 102, 154, 80, 177, 165, 227, 253, 31, 103, 124, 143, 230, 217, 25, 12,
    90, 244, 32, 2, 32, 17, 181, 23, 102, 210, 241, 125, 227, 46, 171, 126, 131, 218, 214, 253, 66,
    22, 116, 205, 142, 85, 228, 175, 72, 131, 154, 83, 153, 47, 184, 157, 94, 12, 0, 15, 2, 16, 0,
    2, 64, 29, 248, 93, 57, 251, 90, 191, 219, 227, 162, 168, 98, 11, 252, 50, 158, 160, 138, 223,
    167, 135, 212, 146, 192, 86, 10, 159, 50, 39, 201, 235, 229, 102, 39, 141, 18, 118, 169, 213,
    154, 39, 245, 23, 239, 34, 54, 227, 103, 112, 56, 5, 195, 3, 4, 205, 24, 119, 220, 201, 156,
    209, 86, 165, 73, 4, 1, 1, 6, 0, 0, 253, 2, 78, 253, 2, 74, 0, 253, 1, 191, 253, 1, 188, 0, 8,
    0, 0, 255, 255, 255, 255, 255, 254, 2, 8, 0, 0, 0, 0, 0, 0, 0, 0, 4, 8, 0, 0, 0, 0, 0, 1, 137,
    238, 6, 4, 0, 0, 1, 12, 8, 176, 175, 0, 33, 3, 158, 20, 175, 174, 221, 138, 182, 249, 11, 94,
    240, 251, 232, 201, 73, 25, 247, 123, 108, 198, 153, 89, 84, 209, 127, 114, 55, 144, 120, 149,
    13, 222, 2, 33, 2, 15, 137, 104, 72, 210, 98, 222, 187, 143, 161, 238, 208, 85, 191, 192, 166,
    99, 127, 139, 155, 243, 39, 242, 172, 117, 196, 153, 176, 86, 203, 0, 47, 4, 33, 3, 145, 83,
    28, 120, 41, 12, 163, 45, 249, 88, 105, 185, 130, 77, 228, 169, 21, 241, 114, 192, 231, 75,
    138, 21, 193, 194, 89, 100, 165, 86, 190, 94, 6, 33, 2, 97, 95, 89, 103, 186, 249, 85, 156,
    250, 70, 98, 33, 19, 131, 201, 65, 216, 117, 134, 107, 249, 69, 65, 20, 86, 97, 151, 141, 126,
    165, 18, 82, 8, 33, 2, 85, 204, 109, 230, 216, 30, 33, 108, 62, 43, 13, 255, 136, 174, 50, 235,
    129, 103, 240, 176, 16, 46, 218, 47, 162, 71, 33, 26, 190, 13, 53, 239, 10, 162, 161, 0, 125,
    2, 0, 0, 0, 1, 226, 223, 127, 106, 59, 88, 192, 252, 24, 23, 239, 254, 29, 27, 49, 165, 198,
    37, 11, 20, 13, 186, 166, 171, 167, 86, 123, 223, 254, 110, 48, 67, 0, 0, 0, 0, 0, 35, 109,
    154, 128, 2, 76, 29, 0, 0, 0, 0, 0, 0, 34, 0, 32, 208, 147, 170, 59, 12, 215, 105, 107, 155,
    107, 67, 8, 167, 131, 245, 95, 195, 242, 190, 170, 75, 42, 164, 200, 33, 212, 126, 24, 240,
    170, 202, 83, 238, 137, 1, 0, 0, 0, 0, 0, 22, 0, 20, 51, 158, 131, 246, 71, 104, 102, 154, 80,
    177, 165, 227, 253, 31, 103, 124, 143, 230, 217, 25, 15, 90, 244, 32, 2, 32, 89, 217, 56, 33,
    63, 107, 197, 44, 64, 80, 134, 90, 183, 137, 23, 25, 45, 100, 192, 240, 112, 73, 8, 50, 77, 16,
    167, 36, 10, 142, 187, 118, 12, 60, 59, 0, 1, 0, 2, 8, 0, 0, 0, 0, 0, 114, 112, 224, 4, 4, 0,
    6, 119, 81, 6, 32, 98, 164, 145, 193, 45, 31, 120, 243, 144, 168, 100, 49, 84, 4, 224, 73, 72,
    92, 90, 213, 166, 100, 246, 66, 103, 26, 243, 246, 153, 133, 173, 59, 8, 4, 0, 0, 0, 0, 15, 2,
    16, 0, 2, 64, 80, 191, 58, 169, 212, 71, 51, 95, 72, 143, 113, 69, 77, 137, 229, 162, 1, 241,
    198, 96, 5, 234, 242, 250, 7, 189, 12, 196, 211, 195, 70, 104, 68, 157, 50, 134, 195, 251, 238,
    202, 143, 151, 190, 174, 193, 235, 242, 188, 118, 254, 233, 206, 113, 37, 31, 51, 245, 228,
    176, 206, 43, 228, 92, 83, 4, 1, 1, 6, 64, 73, 28, 136, 174, 80, 53, 242, 220, 98, 76, 43, 50,
    6, 2, 5, 205, 185, 103, 13, 169, 25, 93, 148, 104, 201, 117, 18, 196, 1, 65, 178, 246, 38, 196,
    230, 182, 133, 110, 195, 98, 252, 95, 151, 252, 54, 201, 159, 219, 167, 215, 133, 122, 181, 50,
    26, 125, 229, 215, 232, 138, 118, 243, 204, 167, 0, 253, 1, 154, 0, 176, 175, 0, 33, 2, 187, 2,
    3, 79, 186, 192, 60, 67, 252, 172, 82, 26, 102, 22, 113, 168, 132, 178, 196, 196, 123, 110,
    147, 195, 27, 156, 18, 200, 244, 151, 205, 254, 2, 33, 3, 210, 234, 68, 18, 21, 39, 158, 188,
    30, 48, 110, 109, 138, 227, 110, 155, 105, 174, 70, 253, 241, 91, 239, 159, 253, 83, 253, 26,
    206, 232, 60, 39, 4, 33, 2, 244, 19, 142, 111, 20, 44, 233, 125, 191, 160, 222, 234, 95, 70,
    122, 5, 96, 41, 155, 121, 3, 213, 132, 63, 131, 69, 15, 228, 130, 253, 114, 21, 6, 33, 2, 63,
    234, 246, 244, 91, 189, 96, 58, 68, 236, 168, 170, 63, 146, 247, 33, 150, 16, 148, 180, 104,
    75, 188, 198, 143, 249, 6, 27, 73, 164, 78, 202, 8, 33, 3, 76, 42, 89, 187, 90, 189, 240, 115,
    251, 1, 44, 247, 198, 84, 118, 102, 173, 11, 202, 151, 61, 122, 222, 253, 36, 37, 19, 183, 217,
    8, 229, 173, 2, 2, 0, 144, 4, 1, 0, 6, 183, 182, 0, 176, 175, 0, 33, 3, 131, 221, 176, 32, 165,
    131, 251, 198, 154, 238, 179, 38, 122, 19, 19, 211, 203, 12, 0, 199, 161, 186, 226, 233, 31,
    45, 196, 174, 114, 119, 95, 177, 2, 33, 2, 45, 83, 223, 96, 212, 69, 226, 199, 245, 94, 185,
    86, 181, 149, 106, 88, 201, 145, 45, 215, 114, 176, 188, 203, 21, 191, 3, 104, 100, 163, 204,
    122, 4, 33, 3, 183, 46, 17, 0, 22, 89, 15, 4, 245, 60, 239, 75, 44, 83, 246, 243, 29, 25, 163,
    57, 190, 142, 154, 163, 166, 210, 146, 62, 254, 20, 139, 230, 6, 33, 3, 33, 88, 253, 177, 233,
    158, 226, 126, 248, 230, 147, 151, 18, 250, 180, 242, 239, 106, 199, 121, 76, 165, 236, 84,
    151, 218, 162, 193, 73, 216, 163, 235, 8, 33, 2, 102, 194, 245, 56, 190, 148, 142, 23, 14, 18,
    212, 128, 124, 41, 30, 99, 228, 244, 77, 167, 111, 159, 210, 77, 134, 43, 250, 151, 154, 217,
    163, 226, 2, 2, 0, 6, 8, 34, 226, 223, 127, 106, 59, 88, 192, 252, 24, 23, 239, 254, 29, 27,
    49, 165, 198, 37, 11, 20, 13, 186, 166, 171, 167, 86, 123, 223, 254, 110, 48, 67, 0, 0, 11, 2,
    16, 0, 0, 0, 2, 139, 1, 1, 135, 211, 13, 56, 138, 53, 76, 177, 22, 89, 33, 173, 232, 104, 58,
    46, 9, 214, 248, 141, 2, 74, 73, 175, 151, 192, 64, 152, 26, 208, 88, 28, 68, 148, 225, 145,
    60, 246, 85, 136, 233, 107, 89, 21, 33, 187, 115, 203, 12, 155, 5, 18, 98, 20, 216, 147, 53,
    226, 212, 241, 106, 200, 172, 245, 84, 75, 149, 55, 54, 37, 197, 178, 195, 160, 223, 29, 37,
    12, 142, 168, 202, 82, 118, 153, 95, 154, 132, 46, 239, 233, 98, 178, 156, 104, 110, 178, 4,
    73, 61, 133, 51, 69, 166, 249, 177, 47, 251, 109, 231, 4, 111, 77, 48, 253, 113, 109, 128, 180,
    136, 29, 3, 245, 150, 23, 165, 156, 30, 74, 184, 6, 55, 180, 180, 179, 100, 37, 185, 14, 208,
    210, 191, 137, 29, 30, 7, 12, 226, 111, 250, 114, 70, 237, 180, 55, 24, 175, 130, 153, 26, 57,
    69, 59, 171, 225, 158, 186, 169, 209, 50, 235, 250, 170, 88, 118, 12, 37, 103, 189, 106, 253,
    106, 113, 255, 235, 229, 216, 39, 40, 62, 199, 224, 43, 253, 1, 158, 253, 1, 154, 0, 176, 175,
    0, 33, 2, 187, 2, 3, 79, 186, 192, 60, 67, 252, 172, 82, 26, 102, 22, 113, 168, 132, 178, 196,
    196, 123, 110, 147, 195, 27, 156, 18, 200, 244, 151, 205, 254, 2, 33, 3, 210, 234, 68, 18, 21,
    39, 158, 188, 30, 48, 110, 109, 138, 227, 110, 155, 105, 174, 70, 253, 241, 91, 239, 159, 253,
    83, 253, 26, 206, 232, 60, 39, 4, 33, 2, 244, 19, 142, 111, 20, 44, 233, 125, 191, 160, 222,
    234, 95, 70, 122, 5, 96, 41, 155, 121, 3, 213, 132, 63, 131, 69, 15, 228, 130, 253, 114, 21, 6,
    33, 2, 63, 234, 246, 244, 91, 189, 96, 58, 68, 236, 168, 170, 63, 146, 247, 33, 150, 16, 148,
    180, 104, 75, 188, 198, 143, 249, 6, 27, 73, 164, 78, 202, 8, 33, 3, 76, 42, 89, 187, 90, 189,
    240, 115, 251, 1, 44, 247, 198, 84, 118, 102, 173, 11, 202, 151, 61, 122, 222, 253, 36, 37, 19,
    183, 217, 8, 229, 173, 2, 2, 0, 144, 4, 1, 0, 6, 183, 182, 0, 176, 175, 0, 33, 3, 131, 221,
    176, 32, 165, 131, 251, 198, 154, 238, 179, 38, 122, 19, 19, 211, 203, 12, 0, 199, 161, 186,
    226, 233, 31, 45, 196, 174, 114, 119, 95, 177, 2, 33, 2, 45, 83, 223, 96, 212, 69, 226, 199,
    245, 94, 185, 86, 181, 149, 106, 88, 201, 145, 45, 215, 114, 176, 188, 203, 21, 191, 3, 104,
    100, 163, 204, 122, 4, 33, 3, 183, 46, 17, 0, 22, 89, 15, 4, 245, 60, 239, 75, 44, 83, 246,
    243, 29, 25, 163, 57, 190, 142, 154, 163, 166, 210, 146, 62, 254, 20, 139, 230, 6, 33, 3, 33,
    88, 253, 177, 233, 158, 226, 126, 248, 230, 147, 151, 18, 250, 180, 242, 239, 106, 199, 121,
    76, 165, 236, 84, 151, 218, 162, 193, 73, 216, 163, 235, 8, 33, 2, 102, 194, 245, 56, 190, 148,
    142, 23, 14, 18, 212, 128, 124, 41, 30, 99, 228, 244, 77, 167, 111, 159, 210, 77, 134, 43, 250,
    151, 154, 217, 163, 226, 2, 2, 0, 6, 8, 34, 226, 223, 127, 106, 59, 88, 192, 252, 24, 23, 239,
    254, 29, 27, 49, 165, 198, 37, 11, 20, 13, 186, 166, 171, 167, 86, 123, 223, 254, 110, 48, 67,
    0, 0, 11, 2, 16, 0, 0, 0, 0, 0, 0, 1, 168, 42, 0, 0, 0, 0, 153, 138, 15, 64, 0, 0, 0, 0, 101,
    9, 69, 166, 8, 100, 42, 4, 222, 170, 7, 115, 149, 79, 64, 161, 84, 83, 192, 134, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    48, 3, 0, 5, 0, 7, 1, 0, 9, 33, 3, 102, 171, 200, 235, 77, 166, 30, 49, 168, 210, 196, 82, 13,
    49, 202, 189, 245, 140, 197, 37, 15, 133, 86, 87, 57, 127, 61, 214, 36, 147, 147, 138, 13, 0,
    15, 2, 0, 0,
];


================================================
File: mutiny-core/src/utils.rs
================================================
use crate::error::MutinyError;

use bitcoin::Network;
use core::cell::{RefCell, RefMut};
use core::ops::{Deref, DerefMut};
use core::time::Duration;
use futures::{
    future::{self, Either},
    pin_mut,
};
use hex_conservative::DisplayHex;
use lightning::routing::scoring::{LockableScore, ScoreLookUp, ScoreUpdate};
use lightning::util::ser::Writeable;
use lightning::util::ser::Writer;
use lightning_invoice::Bolt11Invoice;
use reqwest::Client;
use std::sync::atomic::{AtomicBool, AtomicU64};
use std::sync::Arc;

// Alias Future trait
// See explaination https://www.reddit.com/r/rust/comments/1582jku/comment/jt7yrqc/
cfg_if::cfg_if! {
    if #[cfg(target_arch = "wasm32")] {

        // Define future for wasm32
        pub trait Future: future::Future<Output = ()> + 'static {}
        impl<F: future::Future<Output = ()> + 'static> Future for F {}

        pub trait Task: future::Future<Output = Result<(), MutinyError>> + 'static {}
        impl<F: future::Future<Output = Result<(), MutinyError>> + 'static> Task for F {}

    } else {

        // Define Future for non-wasm32, note the Send trait
        pub trait Future: future::Future<Output = ()> + Send + 'static {}
        impl<F: future::Future<Output = ()> + Send + 'static> Future for F {}

        pub trait Task: future::Future<Output = Result<(), MutinyError>> + Send + 'static {}
        impl<F: future::Future<Output = Result<(), MutinyError>> + Send + 'static> Task for F {}
    }
}

pub const FETCH_TIMEOUT: i32 = 30_000;

pub(crate) fn min_lightning_amount(network: Network, is_lsps: bool) -> u64 {
    if is_lsps {
        return 1;
    }
    match network {
        Network::Bitcoin => 100_000,
        Network::Testnet | Network::Signet | Network::Regtest => 10_000,
        net => unreachable!("Unknown network {net}!"),
    }
}

pub async fn sleep(millis: i32) {
    let duration = Duration::from_millis(millis as u64);
    #[cfg(target_arch = "wasm32")]
    {
        gloo_timers::future::sleep(duration).await
    }
    #[cfg(not(target_arch = "wasm32"))]
    {
        tokio::time::sleep(duration).await;
    }
}
pub fn now() -> Duration {
    #[cfg(target_arch = "wasm32")]
    return web_time::SystemTime::now()
        .duration_since(web_time::SystemTime::UNIX_EPOCH)
        .unwrap();

    #[cfg(not(target_arch = "wasm32"))]
    return std::time::SystemTime::now()
        .duration_since(std::time::SystemTime::UNIX_EPOCH)
        .unwrap();
}

pub async fn fetch_with_timeout(
    client: &Client,
    req: reqwest::Request,
) -> Result<reqwest::Response, MutinyError> {
    let fetch_future = fetch(client, req);
    let timeout_future = async {
        sleep(FETCH_TIMEOUT).await;
        Err(MutinyError::ConnectionFailed)
    };

    pin_mut!(fetch_future);
    pin_mut!(timeout_future);

    match future::select(fetch_future, timeout_future).await {
        Either::Left((ok, _)) => ok,
        Either::Right((err, _)) => err,
    }
}

async fn fetch(client: &Client, req: reqwest::Request) -> Result<reqwest::Response, MutinyError> {
    client
        .execute(req)
        .await
        .map_err(|_| MutinyError::ConnectionFailed)
}

pub fn get_random_bip32_child_index() -> u32 {
    let mut buffer = [0u8; 4];
    getrandom::getrandom(&mut buffer).unwrap();

    // Convert the byte buffer to u32
    let random_value = u32::from_le_bytes(buffer);

    // Restrict to [0, 2^31 - 1]
    let max_value = 2u32.pow(31) - 1;
    random_value % (max_value + 1)
}

pub type LockResult<Guard> = Result<Guard, ()>;

pub struct Mutex<T: ?Sized> {
    inner: RefCell<T>,
}

unsafe impl<T: ?Sized> Send for Mutex<T> {}
unsafe impl<T: ?Sized> Sync for Mutex<T> {}

#[must_use = "if unused the Mutex will immediately unlock"]
pub struct MutexGuard<'a, T: ?Sized + 'a> {
    lock: RefMut<'a, T>,
}

impl<T: ?Sized> Deref for MutexGuard<'_, T> {
    type Target = T;

    fn deref(&self) -> &T {
        self.lock.deref()
    }
}

impl<T: ?Sized> DerefMut for MutexGuard<'_, T> {
    fn deref_mut(&mut self) -> &mut T {
        self.lock.deref_mut()
    }
}

impl<T> Mutex<T> {
    pub fn new(inner: T) -> Mutex<T> {
        Mutex {
            inner: RefCell::new(inner),
        }
    }

    #[allow(clippy::result_unit_err)]
    pub fn lock(&self) -> LockResult<MutexGuard<'_, T>> {
        Ok(MutexGuard {
            lock: self.inner.borrow_mut(),
        })
    }

    #[allow(clippy::result_unit_err)]
    pub fn try_lock(&self) -> LockResult<MutexGuard<'_, T>> {
        Ok(MutexGuard {
            lock: self.inner.try_borrow_mut().map_err(|_| ())?,
        })
    }
}

impl<'a, T: 'a + ScoreLookUp + ScoreUpdate> LockableScore<'a> for Mutex<T> {
    type ScoreUpdate = T;
    type ScoreLookUp = T;

    type WriteLocked = MutexGuard<'a, Self::ScoreUpdate>;
    type ReadLocked = MutexGuard<'a, Self::ScoreLookUp>;

    fn read_lock(&'a self) -> Self::ReadLocked {
        Mutex::lock(self).expect("Failed to lock mutex")
    }

    fn write_lock(&'a self) -> Self::WriteLocked {
        Mutex::lock(self).expect("Failed to lock mutex")
    }
}

impl<S: Writeable> Writeable for Mutex<S> {
    fn write<W: Writer>(&self, writer: &mut W) -> Result<(), lightning::io::Error> {
        self.lock()
            .expect("Failed to lock mutex for write")
            .write(writer)
    }
}

impl<'a, S: Writeable> Writeable for MutexGuard<'a, S> {
    fn write<W: Writer>(&self, writer: &mut W) -> Result<(), lightning::io::Error> {
        S::write(&**self, writer)
    }
}

/// Stop signal
pub struct StopSignal(Arc<AtomicBool>);

impl StopSignal {
    /// check stop signal
    pub fn stopping(&self) -> bool {
        self.0.load(std::sync::atomic::Ordering::Relaxed)
    }
}

/// Stop handle
#[derive(Clone)]
pub struct StopHandle {
    stopping: Arc<AtomicBool>,
    stopped: Arc<AtomicBool>,
}

impl StopHandle {
    pub async fn stop(&self) {
        // signal stop
        self.stopping
            .store(true, std::sync::atomic::Ordering::Relaxed);
        // wait stopped
        while !self.stopped.load(std::sync::atomic::Ordering::Relaxed) {
            sleep(200).await;
        }
    }
}

pub struct DBTasks {
    pub started: AtomicU64,
    pub done: AtomicU64,
}

impl DBTasks {
    pub fn inc_started(&self) {
        use std::sync::atomic::Ordering;
        self.started.fetch_add(1, Ordering::Relaxed);
    }

    pub fn inc_done(&self) {
        use std::sync::atomic::Ordering;
        self.done.fetch_add(1, Ordering::Relaxed);
    }

    pub async fn wait(&self) {
        use std::sync::atomic::Ordering;

        while self.started.load(Ordering::Relaxed) != self.done.load(Ordering::Relaxed) {
            sleep(200).await;
        }
    }
}

impl Default for DBTasks {
    fn default() -> Self {
        Self {
            started: AtomicU64::new(0),
            done: AtomicU64::new(0),
        }
    }
}

pub fn spawn_with_handle<F: FnOnce(StopSignal) -> Fut + 'static, Fut: Future>(f: F) -> StopHandle {
    let stopping = Arc::new(AtomicBool::new(false));
    let stopped = Arc::new(AtomicBool::new(false));

    let fut = f(StopSignal(stopping.clone()));
    spawn({
        let stopped = stopped.clone();
        async move {
            fut.await;
            stopped.store(true, std::sync::atomic::Ordering::Relaxed);
        }
    });

    StopHandle { stopping, stopped }
}

#[cfg(target_arch = "wasm32")]
pub fn spawn<F>(future: F)
where
    F: future::Future<Output = ()> + 'static,
{
    wasm_bindgen_futures::spawn_local(future);
}

#[cfg(not(target_arch = "wasm32"))]
pub fn spawn<F>(future: F)
where
    F: future::Future<Output = ()> + Send + 'static,
{
    tokio::spawn(future);
}

/// Returns the version of a channel monitor from a serialized version
/// of a channel monitor.
pub fn get_monitor_version(bytes: &[u8]) -> u64 {
    // first two bytes are the version
    // next 8 bytes are the version number
    u64::from_be_bytes(bytes[2..10].try_into().unwrap())
}

/// Nodes that give hodl invoices, we want to warn users against this.
pub const HODL_INVOICE_NODES: [&str; 5] = [
    "0279be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798", // pubkey of ONE_KEY
    "031b301307574bbe9b9ac7b79cbe1700e31e544513eae0b5d7497483083f99e581", // ZeusPay
    "02187352cc4b1856b9604e0a79e1bc9b301be7e0c14acbbb8c29f7051d507127d7", // Robosats
    "0282eb467bc073833a039940392592bf10cf338a830ba4e392c1667d7697654c7e", // Robosats
    "037ff12b6a4e4bcb4b944b6d20af08cdff61b3461c1dff0d00a88697414d891bc7", // Robosats
];

pub fn is_hodl_invoice(invoice: &Bolt11Invoice) -> bool {
    let pubkey = invoice
        .recover_payee_pub_key()
        .serialize()
        .to_lower_hex_string();
    HODL_INVOICE_NODES.contains(&pubkey.as_str())
}


================================================
File: mutiny-core/src/vss.rs
================================================
use crate::authclient::MutinyAuthClient;
use crate::encrypt::{decrypt_with_key, encrypt_with_key};
use crate::{error::MutinyError, logging::MutinyLogger};
use anyhow::anyhow;
use bitcoin::secp256k1::{Secp256k1, SecretKey};
use hex_conservative::DisplayHex;
use lightning::util::logger::*;
use lightning::{log_error, log_info};
use reqwest::{Method, Url};
use serde::{Deserialize, Serialize};
use serde_json::{json, Value};
use std::sync::Arc;

pub struct MutinyVssClient {
    auth_client: Option<Arc<MutinyAuthClient>>,
    client: Option<reqwest::Client>,
    url: String,
    store_id: Option<String>,
    encryption_key: SecretKey,
    pub logger: Arc<MutinyLogger>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct KeyVersion {
    pub key: String,
    pub version: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct VssKeyValueItem {
    pub key: String,
    pub value: Value,
    pub version: u32,
}

impl VssKeyValueItem {
    /// Encrypts the value of the item using the encryption key
    /// and returns an encrypted version of the item
    pub(crate) fn encrypt(self, encryption_key: &SecretKey) -> EncryptedVssKeyValueItem {
        // should we handle this unwrap better?
        let bytes = self.value.to_string().into_bytes();

        let value = encrypt_with_key(encryption_key, &bytes);

        EncryptedVssKeyValueItem {
            key: self.key,
            value,
            version: self.version,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct EncryptedVssKeyValueItem {
    pub key: String,
    pub value: Vec<u8>,
    pub version: u32,
}

impl EncryptedVssKeyValueItem {
    pub(crate) fn decrypt(
        self,
        encryption_key: &SecretKey,
    ) -> Result<VssKeyValueItem, MutinyError> {
        let decrypted = decrypt_with_key(encryption_key, self.value)?;
        let decrypted_value = String::from_utf8(decrypted)?;
        let value = serde_json::from_str(&decrypted_value)?;

        Ok(VssKeyValueItem {
            key: self.key,
            value,
            version: self.version,
        })
    }
}

impl MutinyVssClient {
    pub fn new_authenticated(
        auth_client: Arc<MutinyAuthClient>,
        url: String,
        encryption_key: SecretKey,
        logger: Arc<MutinyLogger>,
    ) -> Self {
        log_info!(logger, "Creating authenticated vss client");
        Self {
            auth_client: Some(auth_client),
            client: None,
            url,
            store_id: None, // we get this from the auth client
            encryption_key,
            logger,
        }
    }

    pub fn new_unauthenticated(
        url: String,
        encryption_key: SecretKey,
        logger: Arc<MutinyLogger>,
    ) -> Self {
        log_info!(logger, "Creating unauthenticated vss client");
        let pk = encryption_key
            .public_key(&Secp256k1::new())
            .serialize()
            .to_lower_hex_string();
        Self {
            auth_client: None,
            client: Some(reqwest::Client::new()),
            url,
            store_id: Some(pk),
            encryption_key,
            logger,
        }
    }

    async fn make_request(
        &self,
        method: Method,
        url: Url,
        body: Option<Value>,
    ) -> Result<reqwest::Response, MutinyError> {
        match (self.auth_client.as_ref(), self.client.as_ref()) {
            (Some(auth_client), _) => auth_client.request(method, url, body).await,
            (None, Some(client)) => {
                let mut request = client.request(method, url);
                if let Some(body) = body {
                    request = request.json(&body);
                }
                request.send().await.map_err(|e| {
                    log_error!(self.logger, "Error making request: {e}");
                    MutinyError::Other(anyhow!("Error making request: {e}"))
                })
            }
            (None, None) => unreachable!("No auth client or http client"),
        }
    }

    pub async fn put_objects(&self, items: Vec<VssKeyValueItem>) -> Result<(), MutinyError> {
        let url = Url::parse(&format!("{}/putObjects", self.url)).map_err(|e| {
            log_error!(self.logger, "Error parsing put objects url: {e}");
            MutinyError::InvalidArgumentsError
        })?;

        let items = items
            .into_iter()
            .map(|item| item.encrypt(&self.encryption_key))
            .collect::<Vec<_>>();

        // todo do we need global version here?
        let body = json!({ "store_id": self.store_id, "transaction_items": items });

        self.make_request(Method::PUT, url, Some(body)).await?;

        Ok(())
    }

    pub async fn get_object(&self, key: &str) -> Result<VssKeyValueItem, MutinyError> {
        let url = Url::parse(&format!("{}/getObject", self.url)).map_err(|e| {
            log_error!(self.logger, "Error parsing get objects url: {e}");
            MutinyError::InvalidArgumentsError
        })?;

        let body = json!({ "store_id": self.store_id, "key": key });

        let result: EncryptedVssKeyValueItem = self
            .make_request(Method::POST, url, Some(body))
            .await?
            .json()
            .await
            .map_err(|e| {
                log_error!(self.logger, "Error parsing get objects response: {e}");
                MutinyError::FailedParsingVssValue
            })?;

        result.decrypt(&self.encryption_key)
    }

    pub async fn list_key_versions(
        &self,
        key_prefix: Option<String>,
    ) -> Result<Vec<KeyVersion>, MutinyError> {
        let url = Url::parse(&format!("{}/listKeyVersions", self.url)).map_err(|e| {
            log_error!(self.logger, "Error parsing list key versions url: {e}");
            MutinyError::InvalidArgumentsError
        })?;

        let body = json!({ "store_id": self.store_id, "key_prefix": key_prefix });

        let result = self
            .make_request(Method::POST, url, Some(body))
            .await?
            .json()
            .await
            .map_err(|e| {
                log_error!(self.logger, "Error parsing list key versions response: {e}");
                MutinyError::Other(anyhow!("Error parsing list key versions response: {e}"))
            })?;

        Ok(result)
    }
}


================================================
File: mutiny-core/src/lsp/lsps.rs
================================================
#![allow(dead_code)]

use async_trait::async_trait;
use bitcoin::hashes::{sha256, Hash};
use bitcoin::secp256k1::{PublicKey, Secp256k1};
use bitcoin::Network;
use futures::channel::oneshot;
use lightning::ln::channelmanager::MIN_FINAL_CLTV_EXPIRY_DELTA;
use lightning::ln::PaymentHash;
use lightning::routing::gossip::RoutingFees;
use lightning::routing::router::{RouteHint, RouteHintHop};
use lightning::util::logger::Logger;
use lightning::{log_debug, log_error, log_info};
use lightning_invoice::{Bolt11Invoice, InvoiceBuilder};
use lightning_liquidity::events::Event;
use lightning_liquidity::lsps0::ser::RequestId;
use lightning_liquidity::lsps2::event::LSPS2ClientEvent;
use lightning_liquidity::lsps2::msgs::OpeningFeeParams;
use lightning_liquidity::lsps2::utils::compute_opening_fee;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::{Arc, Mutex};

use crate::{
    error::MutinyError,
    keymanager::PhantomKeysManager,
    ldkstorage::PhantomChannelManager,
    logging::MutinyLogger,
    lsp::{FeeRequest, InvoiceRequest, Lsp, LspConfig},
    node::{parse_peer_info, LiquidityManager},
    storage::MutinyStorage,
    utils,
};

use super::FeeResponse;

#[derive(Debug, Serialize, Deserialize, PartialEq, Eq, Clone)]
pub struct LspsConfig {
    pub connection_string: String,
    pub token: Option<String>,
}

#[derive(Clone, Debug)]
pub(crate) struct JitChannelInfo {
    pub fee_params: OpeningFeeParams,
    pub payment_size_msat: u64,
}

#[derive(Clone, Debug)]
pub(crate) struct GetInfoResponse {
    pub opening_fee_params_menu: Vec<OpeningFeeParams>,
}

pub(crate) struct PendingPaymentInfo {
    pub expected_fee_msat: Option<u64>,
    pub fee_params: OpeningFeeParams,
}

type PendingFeeRequestSender = oneshot::Sender<Result<GetInfoResponse, MutinyError>>;
type PendingBuyRequestSender = oneshot::Sender<Result<Bolt11Invoice, MutinyError>>;

#[derive(Clone)]
pub struct LspsClient<S: MutinyStorage> {
    pub pubkey: PublicKey,
    pub connection_string: String,
    pub token: Option<String>,
    liquidity_manager: Arc<LiquidityManager<S>>,
    channel_manager: Arc<PhantomChannelManager<S>>,
    keys_manager: Arc<PhantomKeysManager<S>>,
    network: Network,
    logger: Arc<MutinyLogger>,
    pending_fee_requests: Arc<Mutex<HashMap<RequestId, PendingFeeRequestSender>>>,
    pending_buy_requests: Arc<Mutex<HashMap<RequestId, PendingBuyRequestSender>>>,
    pending_channel_info: Arc<Mutex<HashMap<RequestId, JitChannelInfo>>>,
    pending_payments: Arc<Mutex<HashMap<PaymentHash, PendingPaymentInfo>>>,
    stop: Arc<AtomicBool>,
}

impl<S: MutinyStorage> LspsClient<S> {
    #[allow(clippy::too_many_arguments)]
    pub(crate) fn new(
        lsp_connection_string: String,
        token: Option<String>,
        liquidity_manager: Arc<LiquidityManager<S>>,
        channel_manager: Arc<PhantomChannelManager<S>>,
        keys_manager: Arc<PhantomKeysManager<S>>,
        network: Network,
        logger: Arc<MutinyLogger>,
        stop: Arc<AtomicBool>,
    ) -> Result<Self, MutinyError> {
        let (lsp_pubkey, _) = parse_peer_info(&lsp_connection_string)?;

        let client = LspsClient {
            pubkey: lsp_pubkey,
            connection_string: lsp_connection_string,
            token,
            liquidity_manager,
            channel_manager,
            keys_manager,
            network,
            logger,
            pending_fee_requests: Arc::new(Mutex::new(HashMap::new())),
            pending_buy_requests: Arc::new(Mutex::new(HashMap::new())),
            pending_channel_info: Arc::new(Mutex::new(HashMap::new())),
            pending_payments: Arc::new(Mutex::new(HashMap::new())),
            stop,
        };

        let events_client = client.clone();
        utils::spawn(async move {
            events_client.handle_events().await;
        });

        Ok(client)
    }

    pub(crate) async fn handle_event(&self, event: Event) {
        match event {
            Event::LSPS2Client(LSPS2ClientEvent::OpeningParametersReady {
                counterparty_node_id,
                opening_fee_params_menu,
                request_id,
            }) => {
                log_debug!(
                    self.logger,
                    "received GetInfoResponse for counterparty_node_id {counterparty_node_id}",
                );

                let mut pending_fee_requests = self.pending_fee_requests.lock().unwrap();

                if let Some(fee_response_sender) = pending_fee_requests.remove(&request_id) {
                    if fee_response_sender
                        .send(Ok(GetInfoResponse {
                            opening_fee_params_menu,
                        }))
                        .is_err()
                    {
                        log_error!(self.logger, "error sending fee response, receiver dropped?");
                    }
                }
            }
            Event::LSPS2Client(LSPS2ClientEvent::InvoiceParametersReady {
                intercept_scid,
                cltv_expiry_delta,
                counterparty_node_id,
                payment_size_msat,
                request_id,
            }) => {
                log_debug!(self.logger, "received InvoiceGenerationReady with intercept_scid {}, cltv_expiry_delta {}, request_id {:?}, counterparty_node_id {}, payment_size_msat {:?}", intercept_scid, cltv_expiry_delta, request_id, counterparty_node_id, payment_size_msat);

                let mut pending_buy_requests = self.pending_buy_requests.lock().unwrap();

                if let Some(buy_response_sender) = pending_buy_requests.remove(&request_id) {
                    let invoice_expiry_delta_secs = 3600;
                    let (payment_hash, payment_secret) = match self
                        .channel_manager
                        .create_inbound_payment(None, invoice_expiry_delta_secs, None)
                    {
                        Ok((payment_hash, payment_secret)) => (payment_hash, payment_secret),
                        Err(_) => {
                            log_error!(self.logger, "error creating inbound payment");
                            if buy_response_sender
                                .send(Err(MutinyError::InvoiceCreationFailed))
                                .is_err()
                            {
                                log_error!(
                                    self.logger,
                                    "error sending buy response, receiver dropped?"
                                );
                            }
                            return;
                        }
                    };

                    let cltv_expiry_delta: u16 = match cltv_expiry_delta.try_into() {
                        Ok(cltv_expiry_delta) => cltv_expiry_delta,
                        Err(e) => {
                            log_error!(
                                self.logger,
                                "error converting cltv_expiry_delta to u16: {:?}",
                                e
                            );
                            if buy_response_sender
                                .send(Err(MutinyError::InvoiceCreationFailed))
                                .is_err()
                            {
                                log_error!(
                                    self.logger,
                                    "error sending buy response, receiver dropped?"
                                );
                            }
                            return;
                        }
                    };

                    let lsp_route_hint = RouteHint(vec![RouteHintHop {
                        src_node_id: counterparty_node_id,
                        short_channel_id: intercept_scid,
                        fees: RoutingFees {
                            base_msat: 0,
                            proportional_millionths: 0,
                        },
                        cltv_expiry_delta,
                        htlc_minimum_msat: None,
                        htlc_maximum_msat: None,
                    }]);

                    let payment_hash = match sha256::Hash::from_slice(&payment_hash.0) {
                        Ok(payment_hash) => payment_hash,
                        Err(e) => {
                            log_error!(
                                self.logger,
                                "error converting payment_hash to sha256::Hash: {:?}",
                                e
                            );
                            if buy_response_sender
                                .send(Err(MutinyError::InvoiceCreationFailed))
                                .is_err()
                            {
                                log_error!(
                                    self.logger,
                                    "error sending buy response, receiver dropped?"
                                );
                            }
                            return;
                        }
                    };

                    let secp = Secp256k1::new();
                    let payee_pub_key = self.keys_manager.get_node_secret_key().public_key(&secp);
                    let mut invoice = InvoiceBuilder::new(self.network.into())
                        .description("".into())
                        .payment_hash(payment_hash)
                        .payment_secret(payment_secret)
                        .duration_since_epoch(utils::now())
                        .payee_pub_key(payee_pub_key)
                        .basic_mpp()
                        .min_final_cltv_expiry_delta(MIN_FINAL_CLTV_EXPIRY_DELTA.into())
                        .private_route(lsp_route_hint);

                    let payment_size_msat = match payment_size_msat {
                        Some(payment_size_msat) => payment_size_msat,
                        None => {
                            log_error!(self.logger, "payment_size_msat was not specified but is required to create an invoice");
                            if buy_response_sender
                                .send(Err(MutinyError::InvoiceCreationFailed))
                                .is_err()
                            {
                                log_error!(
                                    self.logger,
                                    "error sending buy response, receiver dropped?"
                                );
                            }
                            return;
                        }
                    };

                    invoice = invoice.amount_milli_satoshis(payment_size_msat);

                    let invoice = match invoice.try_build_signed(|hash| {
                        let sig = secp
                            .sign_ecdsa_recoverable(hash, &self.keys_manager.get_node_secret_key());

                        // verify that the signature is correct and we produced a valid invoice
                        let pk = secp.recover_ecdsa(hash, &sig)?;
                        if pk != payee_pub_key {
                            return Err(bitcoin::secp256k1::Error::IncorrectSignature);
                        }

                        Ok(sig)
                    }) {
                        Ok(invoice) => invoice,
                        Err(e) => {
                            log_error!(self.logger, "error building signed invoice: {:?}", e);
                            if buy_response_sender
                                .send(Err(MutinyError::InvoiceCreationFailed))
                                .is_err()
                            {
                                log_error!(
                                    self.logger,
                                    "error sending buy response, receiver dropped?"
                                );
                            }
                            return;
                        }
                    };

                    if buy_response_sender.send(Ok(invoice)).is_err() {
                        log_error!(self.logger, "error sending buy response, receiver dropped?");
                    }

                    log_info!(self.logger, "LSPS invoice created successfully");
                }
            }
            _ => {}
        }
    }

    pub(crate) async fn handle_events(&self) {
        loop {
            for event in self.liquidity_manager.get_and_clear_pending_events() {
                self.handle_event(event).await;
            }

            if self.stop.load(Ordering::Relaxed) {
                break;
            }

            utils::sleep(1000).await;
        }
    }
}

#[cfg_attr(target_arch = "wasm32", async_trait(?Send))]
#[cfg_attr(not(target_arch = "wasm32"), async_trait)]
impl<S: MutinyStorage> Lsp for LspsClient<S> {
    async fn get_lsp_fee_msat(&self, fee_request: FeeRequest) -> Result<FeeResponse, MutinyError> {
        let (pending_fee_request_sender, pending_fee_request_receiver) =
            oneshot::channel::<Result<GetInfoResponse, MutinyError>>();

        log_debug!(
            self.logger,
            "initiating inbound flow for {}msats with token {:?}",
            fee_request.amount_msat,
            &self.token
        );

        let lsps2_client_handler = self
            .liquidity_manager
            .lsps2_client_handler()
            .expect("to be configured with lsps2 client config");

        let request_id = {
            let mut pending_fee_requests = self.pending_fee_requests.lock().unwrap();
            let request_id =
                lsps2_client_handler.request_opening_params(self.pubkey, self.token.clone());
            log_debug!(
                self.logger,
                "requested opening params from lsp with request_id {:?}",
                request_id
            );
            pending_fee_requests.insert(request_id.clone(), pending_fee_request_sender);
            request_id
        };

        let get_info_response = pending_fee_request_receiver.await.map_err(|e| {
            log_debug!(self.logger, "error receiving get info response: {:?}", e);
            MutinyError::LspGenericError
        })??;

        let fee_params = get_info_response.opening_fee_params_menu[0].clone();

        let min_fee_msat = fee_params.min_fee_msat;
        let proportional_fee = fee_params.proportional;

        log_debug!(
            self.logger,
            "received fee information. min_fee_msat {}, proportional fee {}, min payment {}msats, max payment {}msats",
            min_fee_msat,
            proportional_fee,
            fee_params.min_payment_size_msat,
            fee_params.max_payment_size_msat,
        );

        {
            let mut pending_channel_info = self.pending_channel_info.lock().unwrap();
            pending_channel_info.insert(
                request_id.clone(),
                JitChannelInfo {
                    fee_params,
                    payment_size_msat: fee_request.amount_msat,
                },
            );
        }

        let fee_amount_msat = compute_opening_fee(
            fee_request.amount_msat,
            min_fee_msat,
            proportional_fee.into(),
        )
        .ok_or(MutinyError::LspGenericError)?;

        Ok(FeeResponse {
            id: request_id.0,
            fee_amount_msat,
        })
    }

    async fn get_lsp_invoice(
        &self,
        invoice_request: InvoiceRequest,
    ) -> Result<Bolt11Invoice, MutinyError> {
        let fee_request_id = RequestId(invoice_request.fee_id);
        let (fee_params, payment_size_msat) = {
            let channel_info = self.pending_channel_info.lock().unwrap();
            let channel_info = channel_info
                .get(&fee_request_id)
                .ok_or(MutinyError::LspGenericError)?;

            (
                channel_info.fee_params.clone(),
                channel_info.payment_size_msat,
            )
        };

        let lsps2_client_handler = self
            .liquidity_manager
            .lsps2_client_handler()
            .expect("to be configured with lsps2 client config");

        let (pending_buy_request_sender, pending_buy_request_receiver) =
            oneshot::channel::<Result<Bolt11Invoice, MutinyError>>();

        {
            let mut pending_buy_requests: std::sync::MutexGuard<
                '_,
                HashMap<RequestId, oneshot::Sender<Result<Bolt11Invoice, MutinyError>>>,
            > = self.pending_buy_requests.lock().unwrap();

            let request_id = lsps2_client_handler
                .select_opening_params(self.pubkey, Some(payment_size_msat), fee_params.clone())
                .map_err(|_| MutinyError::LspGenericError)?;

            pending_buy_requests.insert(request_id.clone(), pending_buy_request_sender);
        }

        let invoice = pending_buy_request_receiver
            .await
            .map_err(|_| MutinyError::LspGenericError)??;

        let payment_hash = PaymentHash(invoice.payment_hash().to_byte_array());
        let payment_amount = invoice.amount_milli_satoshis();

        let expected_fee_msat = payment_amount.and_then(|payment_amount| {
            compute_opening_fee(
                payment_amount,
                fee_params.min_fee_msat,
                fee_params.proportional.into(),
            )
        });
        {
            let mut pending_payments = self.pending_payments.lock().unwrap();
            pending_payments.insert(
                payment_hash,
                PendingPaymentInfo {
                    expected_fee_msat,
                    fee_params,
                },
            );
        }

        Ok(invoice)
    }

    async fn get_lsp_pubkey(&self) -> PublicKey {
        self.pubkey
    }

    async fn get_lsp_connection_string(&self) -> String {
        self.connection_string.clone()
    }

    async fn get_config(&self) -> LspConfig {
        LspConfig::Lsps(LspsConfig {
            connection_string: self.connection_string.clone(),
            token: self.token.clone(),
        })
    }

    fn get_expected_skimmed_fee_msat(&self, payment_hash: PaymentHash, payment_size: u64) -> u64 {
        let mut pending_payments = self.pending_payments.lock().unwrap();

        if let Some(pending_payment) = pending_payments.get_mut(&payment_hash) {
            if let Some(expected_fee_msat) = pending_payment.expected_fee_msat {
                return expected_fee_msat;
            }

            compute_opening_fee(
                payment_size,
                pending_payment.fee_params.min_fee_msat,
                pending_payment.fee_params.proportional.into(),
            )
            .unwrap_or(0)
        } else {
            0
        }
    }
}


================================================
File: mutiny-core/src/lsp/mod.rs
================================================
#![allow(dead_code)]

use crate::error::MutinyError;
use crate::keymanager::PhantomKeysManager;
use crate::ldkstorage::PhantomChannelManager;
use crate::logging::MutinyLogger;
use crate::lsp::voltage::VoltageConfig;
use crate::node::LiquidityManager;
use crate::storage::MutinyStorage;
use async_lock::RwLock;
use async_trait::async_trait;
use bitcoin::secp256k1::PublicKey;
use bitcoin::Network;
use lightning::ln::PaymentHash;
use lightning_invoice::Bolt11Invoice;
use lsps::{LspsClient, LspsConfig};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use std::sync::{atomic::AtomicBool, Arc};
use voltage::LspClient;

pub mod lsps;
pub mod voltage;

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum LspConfig {
    VoltageFlow(VoltageConfig),
    Lsps(LspsConfig),
}

impl LspConfig {
    pub fn new_voltage_flow(url: String) -> Self {
        Self::VoltageFlow(VoltageConfig {
            url,
            pubkey: None,
            connection_string: None,
        })
    }

    pub fn new_lsps(connection_string: String, token: Option<String>) -> Self {
        Self::Lsps(LspsConfig {
            connection_string,
            token,
        })
    }

    pub fn accept_underpaying_htlcs(&self) -> bool {
        match self {
            LspConfig::VoltageFlow(_) => false,
            LspConfig::Lsps(_) => true,
        }
    }

    /// Checks if the two LSP configs are functionally equivalent, even if they do not
    /// contain the same data.
    pub fn matches(&self, other: &Self) -> bool {
        match (self, other) {
            (LspConfig::VoltageFlow(conf), LspConfig::VoltageFlow(other)) => conf.url == other.url,
            (LspConfig::Lsps(conf), LspConfig::Lsps(other)) => conf == other,
            _ => false,
        }
    }
}

pub fn deserialize_lsp_config<'de, D>(deserializer: D) -> Result<Option<LspConfig>, D::Error>
where
    D: serde::Deserializer<'de>,
{
    let v: Option<Value> = Option::deserialize(deserializer)?;
    match v {
        Some(Value::String(s)) => Ok(Some(LspConfig::VoltageFlow(VoltageConfig {
            url: s,
            pubkey: None,
            connection_string: None,
        }))),
        Some(Value::Object(_)) => LspConfig::deserialize(v.unwrap())
            .map(Some)
            .map_err(|e| serde::de::Error::custom(format!("invalid lsp config: {e}"))),
        Some(Value::Null) => Ok(None),
        Some(x) => Err(serde::de::Error::custom(format!(
            "invalid lsp config: {x:?}"
        ))),
        None => Ok(None),
    }
}

#[derive(Serialize, Deserialize)]
pub struct InvoiceRequest {
    // Used only for VoltageFlow
    pub bolt11: Option<String>,
    // Map to previously fetched fee
    pub fee_id: String,
}

#[derive(Serialize, Deserialize)]
pub struct FeeRequest {
    pub pubkey: String,
    pub amount_msat: u64,
}

#[derive(Serialize, Deserialize)]
pub struct FeeResponse {
    // To be used in subsequent InvoiceRequest
    pub id: String,
    pub fee_amount_msat: u64,
}

#[cfg_attr(target_arch = "wasm32", async_trait(?Send))]
#[cfg_attr(not(target_arch = "wasm32"), async_trait)]
pub(crate) trait Lsp {
    async fn get_lsp_fee_msat(&self, fee_request: FeeRequest) -> Result<FeeResponse, MutinyError>;
    async fn get_lsp_invoice(
        &self,
        invoice_request: InvoiceRequest,
    ) -> Result<Bolt11Invoice, MutinyError>;
    async fn get_lsp_pubkey(&self) -> PublicKey;
    async fn get_lsp_connection_string(&self) -> String;
    fn get_expected_skimmed_fee_msat(&self, payment_hash: PaymentHash, payment_size: u64) -> u64;
    async fn get_config(&self) -> LspConfig;
}

#[derive(Clone)]
pub enum AnyLsp<S: MutinyStorage> {
    VoltageFlow(Arc<RwLock<LspClient>>),
    Lsps(LspsClient<S>),
}

impl<S: MutinyStorage> AnyLsp<S> {
    pub async fn new_voltage_flow(
        config: VoltageConfig,
        logger: Arc<MutinyLogger>,
    ) -> Result<Self, MutinyError> {
        Ok(Self::VoltageFlow(Arc::new(RwLock::new(
            LspClient::new(config, logger).await?,
        ))))
    }

    #[allow(clippy::too_many_arguments)]
    pub fn new_lsps(
        connection_string: String,
        token: Option<String>,
        liquidity_manager: Arc<LiquidityManager<S>>,
        channel_manager: Arc<PhantomChannelManager<S>>,
        keys_manager: Arc<PhantomKeysManager<S>>,
        network: Network,
        logger: Arc<MutinyLogger>,
        stop: Arc<AtomicBool>,
    ) -> Result<Self, MutinyError> {
        let lsps_client = LspsClient::new(
            connection_string,
            token,
            liquidity_manager,
            channel_manager,
            keys_manager,
            network,
            logger,
            stop,
        )?;
        Ok(Self::Lsps(lsps_client))
    }

    pub fn accept_underpaying_htlcs(&self) -> bool {
        match self {
            AnyLsp::VoltageFlow(_) => false,
            AnyLsp::Lsps(_) => true,
        }
    }

    pub fn is_lsps(&self) -> bool {
        matches!(self, AnyLsp::Lsps(_))
    }
}

#[cfg_attr(target_arch = "wasm32", async_trait(?Send))]
#[cfg_attr(not(target_arch = "wasm32"), async_trait)]
impl<S: MutinyStorage> Lsp for AnyLsp<S> {
    async fn get_lsp_fee_msat(&self, fee_request: FeeRequest) -> Result<FeeResponse, MutinyError> {
        match self {
            AnyLsp::VoltageFlow(lock) => {
                let client = lock.read().await;
                client.get_lsp_fee_msat(fee_request).await
            }
            AnyLsp::Lsps(client) => client.get_lsp_fee_msat(fee_request).await,
        }
    }

    async fn get_lsp_invoice(
        &self,
        invoice_request: InvoiceRequest,
    ) -> Result<Bolt11Invoice, MutinyError> {
        match self {
            AnyLsp::VoltageFlow(lock) => {
                let client = lock.read().await;
                client.get_lsp_invoice(invoice_request).await
            }
            AnyLsp::Lsps(client) => client.get_lsp_invoice(invoice_request).await,
        }
    }

    async fn get_lsp_pubkey(&self) -> PublicKey {
        match self {
            AnyLsp::VoltageFlow(lock) => {
                let client = lock.read().await;
                client.get_lsp_pubkey().await
            }
            AnyLsp::Lsps(client) => client.get_lsp_pubkey().await,
        }
    }

    async fn get_lsp_connection_string(&self) -> String {
        match self {
            AnyLsp::VoltageFlow(lock) => {
                let client = lock.read().await;
                client.get_lsp_connection_string().await
            }
            AnyLsp::Lsps(client) => client.get_lsp_connection_string().await,
        }
    }

    async fn get_config(&self) -> LspConfig {
        match self {
            AnyLsp::VoltageFlow(lock) => {
                let client = lock.read().await;
                client.get_config().await
            }
            AnyLsp::Lsps(client) => client.get_config().await,
        }
    }

    fn get_expected_skimmed_fee_msat(&self, payment_hash: PaymentHash, payment_size: u64) -> u64 {
        match self {
            AnyLsp::VoltageFlow(_) => 0,
            AnyLsp::Lsps(client) => {
                client.get_expected_skimmed_fee_msat(payment_hash, payment_size)
            }
        }
    }
}


================================================
File: mutiny-core/src/lsp/voltage.rs
================================================
#![allow(dead_code)]

use crate::logging::MutinyLogger;
use crate::lsp::{FeeRequest, InvoiceRequest, Lsp, LspConfig};
use crate::{error::MutinyError, utils};
use async_trait::async_trait;
use bitcoin::secp256k1::PublicKey;
use lightning::ln::PaymentHash;
use lightning::log_error;
use lightning::util::logger::Logger;
use lightning_invoice::Bolt11Invoice;
use reqwest::Client;
use serde::{Deserialize, Deserializer, Serialize};
use serde_json::Value;
use std::str::FromStr;
use std::sync::Arc;

use super::FeeResponse;

#[derive(Debug, Clone, Serialize, PartialEq, Eq)]
pub struct VoltageConfig {
    pub url: String,
    pub pubkey: Option<PublicKey>,
    pub connection_string: Option<String>,
}

// Need custom Deserializer to handle old encoding
impl<'de> Deserialize<'de> for VoltageConfig {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        let value: Value = Value::deserialize(deserializer)?;
        match value {
            // old encoding was a string, parse as the url
            Value::String(url) => Ok(VoltageConfig {
                url,
                pubkey: None,
                connection_string: None,
            }),
            // new encoding is an object, parse as such
            Value::Object(map) => {
                let url = map
                    .get("url")
                    .and_then(Value::as_str)
                    .ok_or_else(|| serde::de::Error::missing_field("url"))?
                    .to_string();
                let pubkey = map
                    .get("pubkey")
                    .and_then(Value::as_str)
                    .map(PublicKey::from_str)
                    .transpose()
                    .map_err(|_| serde::de::Error::custom("invalid pubkey"))?;
                let connection_string = map
                    .get("connection_string")
                    .and_then(Value::as_str)
                    .map(String::from);
                Ok(VoltageConfig {
                    url,
                    pubkey,
                    connection_string,
                })
            }
            _ => Err(serde::de::Error::custom("invalid value for VoltageConfig")),
        }
    }
}

#[derive(Clone)]
pub struct LspClient {
    pub pubkey: PublicKey,
    pub connection_string: String,
    pub url: String,
    pub http_client: Client,
    pub logger: Arc<MutinyLogger>,
}

#[derive(Debug, Serialize, Deserialize)]
pub(crate) struct GetInfoResponse {
    pub pubkey: PublicKey,
    pub connection_methods: Vec<GetInfoAddress>,
}

#[derive(Clone, Debug, Deserialize, Serialize)]
pub(crate) struct GetInfoAddress {
    #[serde(rename = "type")]
    pub item_type: GetInfoAddressType,
    pub port: u16,
    pub address: String,
}

/// Type of connection
#[derive(Copy, Clone, Debug, Deserialize, Serialize)]
#[serde(rename_all = "lowercase")]
pub(crate) enum GetInfoAddressType {
    Dns,
    IPV4,
    IPV6,
    TORV2,
    TORV3,
    Websocket,
}

#[derive(Serialize, Deserialize)]
pub struct ProposalRequest {
    pub bolt11: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub host: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub port: Option<u16>,
    pub fee_id: String,
}

#[derive(Serialize, Deserialize)]
pub struct ProposalResponse {
    pub jit_bolt11: String,
}

#[derive(Deserialize, Debug)]
struct ErrorResponse {
    error: String,
    message: String,
}

const GET_INFO_PATH: &str = "/api/v1/ln/node_info";
const PROPOSAL_PATH: &str = "/api/v1/proposal";
const FEE_PATH: &str = "/api/v1/fee";

impl LspClient {
    pub async fn new(
        config: VoltageConfig,
        logger: Arc<MutinyLogger>,
    ) -> Result<Self, MutinyError> {
        let http_client = Client::new();

        // if we have both pubkey and connection string, use them, otherwise request them from the LSP
        let (pubkey, connection_string) = match (config.pubkey, config.connection_string) {
            (Some(pk), Some(string)) => (pk, string),
            _ => Self::fetch_connection_info(&http_client, &config.url, &logger).await?,
        };

        Ok(LspClient {
            pubkey,
            url: config.url,
            connection_string,
            http_client,
            logger,
        })
    }

    /// Get the pubkey and connection string from the LSP from the /info endpoint
    pub(crate) async fn fetch_connection_info(
        http_client: &Client,
        url: &str,
        logger: &MutinyLogger,
    ) -> Result<(PublicKey, String), MutinyError> {
        let builder = http_client.get(format!("{}{}", url.trim(), GET_INFO_PATH));
        let request = add_x_auth_token_if_needed(url, builder)?;

        let response: reqwest::Response = utils::fetch_with_timeout(http_client, request)
            .await
            .map_err(|e| {
                log_error!(logger, "Error fetching connection info: {e}");
                MutinyError::LspGenericError
            })?;

        let get_info_response: GetInfoResponse = response.json().await.map_err(|e| {
            log_error!(logger, "Error fetching connection info: {e}");
            MutinyError::LspGenericError
        })?;

        let connection_string = get_info_response
            .connection_methods
            .iter()
            .filter(|address| {
                matches!(
                    address.item_type,
                    GetInfoAddressType::IPV4 | GetInfoAddressType::IPV6 | GetInfoAddressType::TORV3
                )
            })
            .min_by_key(|address| match address.item_type {
                // Prioritize IPV4, then 6, then tor
                // TODO support websocket one day
                GetInfoAddressType::IPV4 => 0,
                GetInfoAddressType::IPV6 => 1,
                GetInfoAddressType::TORV3 => 2,
                _ => unreachable!(),
            })
            .map(|address| {
                format!(
                    "{}@{}:{}",
                    get_info_response.pubkey, address.address, address.port
                )
            })
            .ok_or_else(|| anyhow::anyhow!("No suitable connection method found"))?;

        Ok((get_info_response.pubkey, connection_string))
    }

    /// Get the pubkey and connection string from the LSP from the /info endpoint
    /// and set them on the LSP client
    pub(crate) async fn set_connection_info(&mut self) -> Result<(), MutinyError> {
        let (pubkey, connection_string) =
            Self::fetch_connection_info(&self.http_client, &self.url, &self.logger).await?;
        self.pubkey = pubkey;
        self.connection_string = connection_string;
        Ok(())
    }

    // TODO: Skip LSP invoice verifying
    // Verify that the invoice has all the parameters we expect
    // Returns an Option with an error message if the invoice is invalid
    // pub(crate) fn verify_invoice(
    //     &self,
    //     our_invoice: &Bolt11Invoice,
    //     lsp_invoice: &Bolt11Invoice,
    //     lsp_fee_msats: u64,
    // ) -> Option<String> {
    //     if lsp_invoice.network() != our_invoice.network() {
    //         return Some(format!(
    //             "Received invoice on wrong network: {} != {}",
    //             lsp_invoice.network(),
    //             our_invoice.network()
    //         ));
    //     }

    //     if lsp_invoice.payment_hash() != our_invoice.payment_hash() {
    //         return Some(format!(
    //             "Received invoice with wrong payment hash: {} != {}",
    //             lsp_invoice.payment_hash(),
    //             our_invoice.payment_hash()
    //         ));
    //     }

    //     let invoice_pubkey = lsp_invoice.recover_payee_pub_key();
    //     if invoice_pubkey != self.pubkey {
    //         return Some(format!(
    //             "Received invoice from wrong node: {invoice_pubkey} != {}",
    //             self.pubkey
    //         ));
    //     }

    //     if lsp_invoice.amount_milli_satoshis().is_none() {
    //         return Some("Invoice amount is missing".to_string());
    //     }

    //     if our_invoice.amount_milli_satoshis().is_none() {
    //         return Some("Invoice amount is missing".to_string());
    //     }

    //     let lsp_invoice_amt = lsp_invoice.amount_milli_satoshis().expect("just checked");
    //     let our_invoice_amt = our_invoice.amount_milli_satoshis().expect("just checked");

    //     let expected_lsp_invoice_amt = our_invoice_amt + lsp_fee_msats;

    //     // verify invoice within 10 sats of our target
    //     if lsp_invoice_amt.abs_diff(expected_lsp_invoice_amt) > 10_000 {
    //         return Some(format!(
    //             "Received invoice with wrong amount: {lsp_invoice_amt} when amount was {expected_lsp_invoice_amt}",
    //         ));
    //     }

    //     None
    // }
}

/// Adds the x-auth-token header if needed
fn add_x_auth_token_if_needed(
    lsp_url: &str,
    builder: reqwest::RequestBuilder,
) -> Result<reqwest::Request, MutinyError> {
    if lsp_url.contains("lnolymp.us") {
        Ok(builder
            .header("X-Auth-Token", "mutiny")
            .build()
            .map_err(|_| MutinyError::LspGenericError)?)
    } else {
        Ok(builder.build().map_err(|_| MutinyError::LspGenericError)?)
    }
}

#[cfg_attr(target_arch = "wasm32", async_trait(?Send))]
#[cfg_attr(not(target_arch = "wasm32"), async_trait)]
impl Lsp for LspClient {
    async fn get_lsp_invoice(
        &self,
        invoice_request: InvoiceRequest,
    ) -> Result<Bolt11Invoice, MutinyError> {
        let bolt11 = invoice_request
            .bolt11
            .ok_or(MutinyError::LspInvoiceRequired)?;

        let payload = ProposalRequest {
            bolt11,
            host: None,
            port: None,
            fee_id: invoice_request.fee_id,
        };

        let builder = self
            .http_client
            .post(format!("{}{}", &self.url.trim(), PROPOSAL_PATH))
            .json(&payload);

        let request = add_x_auth_token_if_needed(&self.url, builder)?;

        let response: reqwest::Response =
            utils::fetch_with_timeout(&self.http_client, request).await?;
        let status = response.status().as_u16();
        if (200..300).contains(&status) {
            let proposal_response: ProposalResponse = response.json().await.map_err(|e| {
                log_error!(
                    self.logger,
                    "Error fetching invoice, could not parse response: {e}"
                );
                MutinyError::LspGenericError
            })?;

            let inv = Bolt11Invoice::from_str(&proposal_response.jit_bolt11)?;
            return Ok(inv);
        } else if response.status().as_u16() >= 400 {
            // If it's not OK, copy the response body to a string and try to parse as ErrorResponse
            let response_body = response.text().await.map_err(|e| {
                log_error!(
                    self.logger,
                    "Error fetching invoice, could not parse error response: {e}"
                );
                MutinyError::LspGenericError
            })?;
            if let Ok(error_body) = serde_json::from_str::<ErrorResponse>(&response_body) {
                if error_body.error == "Internal Server Error" {
                    if error_body.message == "Cannot fund new channel at this time" {
                        return Err(MutinyError::LspFundingError);
                    } else if error_body.message.starts_with("Failed to connect to peer") {
                        return Err(MutinyError::LspConnectionError);
                    } else if error_body.message == "Invoice amount is too high" {
                        return Err(MutinyError::LspAmountTooHighError);
                    }
                }
            } else {
                log_error!(
                    self.logger,
                    "Error fetching invoice, could not parse error response: {response_body}"
                );
            }
        }

        log_error!(
            self.logger,
            "Error fetching invoice, got unexpected status code from LSP {status}"
        );

        Err(MutinyError::LspGenericError)
    }

    async fn get_lsp_fee_msat(&self, fee_request: FeeRequest) -> Result<FeeResponse, MutinyError> {
        let builder = self
            .http_client
            .post(format!("{}{}", &self.url.trim(), FEE_PATH))
            .json(&fee_request);

        let request = add_x_auth_token_if_needed(&self.url, builder)?;

        let response: reqwest::Response = utils::fetch_with_timeout(&self.http_client, request)
            .await
            .map_err(|e| {
                log_error!(self.logger, "Error fetching fee from LSP: {e}");
                MutinyError::LspGenericError
            })?;

        let fee_response: FeeResponse = response.json().await.map_err(|e| {
            log_error!(
                self.logger,
                "Error fetching fee from LSP, could not parse response: {e}"
            );
            MutinyError::LspGenericError
        })?;

        Ok(fee_response)
    }

    async fn get_lsp_pubkey(&self) -> PublicKey {
        self.pubkey
    }

    async fn get_lsp_connection_string(&self) -> String {
        self.connection_string.clone()
    }

    async fn get_config(&self) -> LspConfig {
        LspConfig::VoltageFlow(VoltageConfig {
            url: self.url.clone(),
            pubkey: Some(self.pubkey),
            connection_string: Some(self.connection_string.clone()),
        })
    }

    fn get_expected_skimmed_fee_msat(&self, _payment_hash: PaymentHash, _payment_size: u64) -> u64 {
        0
    }
}

// #[cfg(test)]
// #[cfg(not(target_arch = "wasm32"))]
// mod test {
//     use crate::logging::MutinyLogger;
//     use crate::lsp::voltage::{LspClient, VoltageConfig};
//     use crate::test_utils::{create_dummy_invoice, create_dummy_invoice_with_payment_hash};
//     use bitcoin::hashes::{sha256, Hash};
//     use bitcoin::secp256k1::{Secp256k1, SecretKey};
//     use bitcoin::Network;
//     use futures::executor::block_on;
//     use std::sync::Arc;

//     #[test]
//     fn test_verify_invoice() {
//         let secret = SecretKey::from_slice(&[0x42; 32]).unwrap();
//         let pk = secret.public_key(&Secp256k1::new());
//         let client = block_on(LspClient::new(
//             VoltageConfig {
//                 url: "http://localhost:8080".to_string(),
//                 pubkey: Some(pk),
//                 connection_string: Some(format!("{pk}@localhost:9735")),
//             },
//             Arc::new(MutinyLogger::default()),
//         ))
//         .unwrap();

//         let invoice_amount_msats = 100_000_000; // 100k sats
//         let lsp_fee_msat = 1_000; // 1 sat fee
//         let amount_minus_fee = invoice_amount_msats - lsp_fee_msat;

//         // we create our invoices with `amount_minus_fee` so we pay the fee, not the sender
//         let (our_invoice, preimage) =
//             create_dummy_invoice(Some(amount_minus_fee), Network::Regtest, None);
//         let payment_hash = sha256::Hash::hash(&preimage);

//         // check good invoice
//         let lsp_invoice = create_dummy_invoice_with_payment_hash(
//             Some(invoice_amount_msats),
//             Network::Regtest,
//             Some(secret),
//             payment_hash,
//         );
//         assert!(client
//             .verify_invoice(&our_invoice, &lsp_invoice, lsp_fee_msat)
//             .is_none());

//         // check invoice wrong network
//         let lsp_invoice = create_dummy_invoice_with_payment_hash(
//             Some(invoice_amount_msats),
//             Network::Bitcoin,
//             Some(secret),
//             payment_hash,
//         );
//         let err = client
//             .verify_invoice(&our_invoice, &lsp_invoice, lsp_fee_msat)
//             .unwrap();
//         assert!(err.contains("Received invoice on wrong network"));

//         // check invoice wrong payment_hash
//         let lsp_invoice = create_dummy_invoice_with_payment_hash(
//             Some(invoice_amount_msats),
//             Network::Regtest,
//             Some(secret),
//             sha256::Hash::all_zeros(),
//         );
//         let err = client
//             .verify_invoice(&our_invoice, &lsp_invoice, lsp_fee_msat)
//             .unwrap();
//         assert!(err.contains("Received invoice with wrong payment hash"));

//         // check invoice wrong key
//         let lsp_invoice = create_dummy_invoice_with_payment_hash(
//             Some(invoice_amount_msats),
//             Network::Regtest,
//             None,
//             payment_hash,
//         );
//         let err = client
//             .verify_invoice(&our_invoice, &lsp_invoice, lsp_fee_msat)
//             .unwrap();
//         assert!(err.contains("Received invoice from wrong node"));

//         // check invoice no amount
//         let lsp_invoice = create_dummy_invoice_with_payment_hash(
//             None,
//             Network::Regtest,
//             Some(secret),
//             payment_hash,
//         );
//         let err = client
//             .verify_invoice(&our_invoice, &lsp_invoice, lsp_fee_msat)
//             .unwrap();
//         assert!(err.contains("Invoice amount is missing"));

//         // check invoice amount way too low
//         let lsp_invoice = create_dummy_invoice_with_payment_hash(
//             Some(1),
//             Network::Regtest,
//             Some(secret),
//             payment_hash,
//         );
//         let err = client
//             .verify_invoice(&our_invoice, &lsp_invoice, lsp_fee_msat)
//             .unwrap();
//         assert!(err.contains("Received invoice with wrong amount"));

//         // check invoice amount way too high
//         let lsp_invoice = create_dummy_invoice_with_payment_hash(
//             Some(invoice_amount_msats * 10),
//             Network::Regtest,
//             Some(secret),
//             payment_hash,
//         );
//         let err = client
//             .verify_invoice(&our_invoice, &lsp_invoice, lsp_fee_msat)
//             .unwrap();
//         assert!(err.contains("Received invoice with wrong amount"));

//         // check invoice amount small difference
//         let lsp_invoice = create_dummy_invoice_with_payment_hash(
//             Some(invoice_amount_msats + 10_001),
//             Network::Regtest,
//             Some(secret),
//             payment_hash,
//         );
//         let err = client
//             .verify_invoice(&our_invoice, &lsp_invoice, lsp_fee_msat)
//             .unwrap();
//         assert!(err.contains("Received invoice with wrong amount"));

//         // check invoice amount small difference
//         let lsp_invoice = create_dummy_invoice_with_payment_hash(
//             Some(invoice_amount_msats - 10_001),
//             Network::Regtest,
//             Some(secret),
//             payment_hash,
//         );
//         let err = client
//             .verify_invoice(&our_invoice, &lsp_invoice, lsp_fee_msat)
//             .unwrap();
//         assert!(err.contains("Received invoice with wrong amount"));

//         // change fee to 10k sats
//         let lsp_fee_msat = 10_000_000; // 10k sats fee
//         let amount_minus_fee = invoice_amount_msats - lsp_fee_msat;

//         // we create our invoices with `amount_minus_fee` so we pay the fee, not the sender
//         let (our_invoice, preimage) =
//             create_dummy_invoice(Some(amount_minus_fee), Network::Regtest, None);
//         let payment_hash = sha256::Hash::hash(&preimage);

//         // check good invoice
//         let lsp_invoice = create_dummy_invoice_with_payment_hash(
//             Some(invoice_amount_msats),
//             Network::Regtest,
//             Some(secret),
//             payment_hash,
//         );
//         assert!(client
//             .verify_invoice(&our_invoice, &lsp_invoice, lsp_fee_msat)
//             .is_none());

//         // check invoice amount small difference
//         let lsp_invoice = create_dummy_invoice_with_payment_hash(
//             Some(amount_minus_fee + 10_001),
//             Network::Regtest,
//             Some(secret),
//             payment_hash,
//         );
//         let err = client
//             .verify_invoice(&our_invoice, &lsp_invoice, lsp_fee_msat)
//             .unwrap();
//         assert!(err.contains("Received invoice with wrong amount"));

//         // check invoice amount small difference
//         let lsp_invoice = create_dummy_invoice_with_payment_hash(
//             Some(amount_minus_fee - 10_001),
//             Network::Regtest,
//             Some(secret),
//             payment_hash,
//         );
//         let err = client
//             .verify_invoice(&our_invoice, &lsp_invoice, lsp_fee_msat)
//             .unwrap();
//         assert!(err.contains("Received invoice with wrong amount"));
//     }
// }

#[cfg(test)]
#[cfg(target_arch = "wasm32")]
mod wasm_test {
    use wasm_bindgen_test::wasm_bindgen_test_configure;

    wasm_bindgen_test_configure!(run_in_browser);
}


================================================
File: mutiny-core/src/networking/mod.rs
================================================
pub mod websocket;

#[cfg(target_arch = "wasm32")]
pub mod proxy;

#[cfg(target_arch = "wasm32")]
pub mod ws_socket;

#[cfg(target_arch = "wasm32")]
pub mod socket;


================================================
File: mutiny-core/src/networking/proxy.rs
================================================
use crate::node::ConnectionType;
use crate::node::PubkeyConnectionInfo;
use crate::{error::MutinyError, utils, utils::sleep};
use async_trait::async_trait;
use futures::stream::SplitStream;
use futures::{lock::Mutex, stream::SplitSink, SinkExt, StreamExt};
use gloo_net::websocket::{futures::WebSocket, Message, State};
use lightning::log_debug;
use lightning::{log_error, util::logger::Logger};
use std::sync::Arc;

use crate::logging::MutinyLogger;
#[cfg(test)]
use mockall::{automock, predicate::*};

#[cfg_attr(test, automock)]
#[async_trait(?Send)]
pub trait Proxy {
    fn send(&self, data: Message);
    async fn read(&self) -> Option<Result<Message, gloo_net::websocket::WebSocketError>>;
    async fn close(&self);
}

pub struct WsProxy {
    write: WsSplit,
    read: ReadSplit,
    logger: Arc<MutinyLogger>,
}

pub type WsSplit = Arc<Mutex<SplitSink<WebSocket, Message>>>;
pub type ReadSplit = Arc<Mutex<SplitStream<WebSocket>>>;

impl WsProxy {
    pub async fn new(
        proxy_url: &str,
        peer_connection_info: PubkeyConnectionInfo,
        logger: Arc<MutinyLogger>,
    ) -> Result<Self, MutinyError> {
        let ws = match peer_connection_info.connection_type {
            ConnectionType::Tcp(s) => WebSocket::open(&tcp_proxy_to_url(proxy_url, &s)?)
                .map_err(|_| MutinyError::ConnectionFailed)?,
        };

        // wait for connected status or time out at 10s
        let mut retries = 10;
        while retries > 0 {
            match ws.state() {
                State::Open => break,
                State::Closed => break,
                _ => {
                    sleep(1_000).await;
                    retries -= 1;
                }
            }
        }

        match ws.state() {
            State::Open => {}
            _ => return Err(MutinyError::ConnectionFailed),
        }

        // TODO wait until we get an OK response from websocket.
        // A connection to the proxy for connections just means that
        // it just connected to the proxy. It does not mean the proxy
        // successfully connected out to the other end. They may be
        // offline and shortly cut off from the WS but that happens
        // outside of the connect flow. This will falsely return success.

        log_debug!(logger, "connected to ws: {proxy_url}");

        let (write, read) = ws.split();
        Ok(Self {
            write: Arc::new(Mutex::new(write)),
            read: Arc::new(Mutex::new(read)),
            logger,
        })
    }
}

#[async_trait(?Send)]
impl Proxy for WsProxy {
    fn send(&self, data: Message) {
        // There can only be one sender at a time
        // Cannot send and write at the same time either
        // TODO check if the connection is closed before trying to send.
        let cloned_conn = self.write.clone();
        let logger = self.logger.clone();
        utils::spawn(async move {
            let mut write = cloned_conn.lock().await;
            match write.send(data).await {
                Ok(_) => (),
                Err(e) => {
                    log_error!(logger, "error sending data down websocket: {e}");
                }
            }
        });
    }

    async fn read(&self) -> Option<Result<Message, gloo_net::websocket::WebSocketError>> {
        self.read.lock().await.next().await
    }

    async fn close(&self) {
        let _ = self.write.lock().await.close().await;
        log_debug!(self.logger, "closed websocket");
    }
}

pub fn tcp_proxy_to_url(proxy_url: &str, peer_addr: &str) -> Result<String, MutinyError> {
    let mut parts = peer_addr.split(':');
    let host = parts.next().ok_or(MutinyError::PeerInfoParseFailed)?;
    let port = parts.next().ok_or(MutinyError::PeerInfoParseFailed)?;
    Ok(format!(
        "{proxy_url}/v1/{}/{}",
        host.replace('.', "_"),
        port
    ))
}

#[cfg(test)]
mod tests {
    #[cfg(feature = "ignored_tests")]
    use crate::networking::proxy::*;

    use crate::test_utils::*;

    use crate::networking::proxy::tcp_proxy_to_url;

    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};

    wasm_bindgen_test_configure!(run_in_browser);

    #[test]
    // test ignored because it connects to a real server
    #[cfg(feature = "ignored_tests")]
    async fn test_websocket_proxy_init() {
        log!("test websocket proxy");
        let logger = Arc::new(MutinyLogger::default());

        // ACINQ's node pubkey
        const PEER_PUBKEY: &str =
            "03864ef025fde8fb587d989186ce6a4a186895ee44a926bfc370e2c366597a3f8f";

        let proxy = WsProxy::new(
            "wss://p.mutinywallet.com",
            PubkeyConnectionInfo::new(&format!("{}@{}", PEER_PUBKEY, "3.33.236.230:9735")).unwrap(),
            logger,
        )
        .await
        .unwrap();

        proxy.close().await;
    }

    #[test]
    fn test_proxy_to_url() {
        log!("test proxy to url");

        assert_eq!(
            "ws://127.0.0.1:3001/v1/127_0_0_1/4000".to_string(),
            tcp_proxy_to_url("ws://127.0.0.1:3001", "127.0.0.1:4000").unwrap()
        );
    }
}


================================================
File: mutiny-core/src/networking/socket.rs
================================================
use crate::logging::MutinyLogger;
use crate::utils;
use crate::{error::MutinyError, peermanager::PeerManager};
use futures::{pin_mut, select, FutureExt};
use lightning::{ln::peer_handler, log_error, util::logger::Logger};
use lightning::{ln::peer_handler::SocketDescriptor, log_trace};
use std::hash::Hash;
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;

use crate::networking::ws_socket::WsTcpSocketDescriptor;

pub trait ReadDescriptor {
    async fn read(&self) -> Option<Result<Vec<u8>, MutinyError>>;
}

#[derive(Clone, Eq, PartialEq, Hash, Debug)]
pub enum MutinySocketDescriptor {
    Tcp(WsTcpSocketDescriptor),
}

impl MutinySocketDescriptor {
    pub fn is_closed(&self) -> bool {
        match self {
            Self::Tcp(d) => d.is_closed(),
        }
    }
}

impl ReadDescriptor for MutinySocketDescriptor {
    async fn read(&self) -> Option<Result<Vec<u8>, MutinyError>> {
        match self {
            MutinySocketDescriptor::Tcp(s) => s.read().await,
        }
    }
}

impl peer_handler::SocketDescriptor for MutinySocketDescriptor {
    fn send_data(&mut self, data: &[u8], resume_read: bool) -> usize {
        match self {
            MutinySocketDescriptor::Tcp(s) => s.send_data(data, resume_read),
        }
    }

    fn disconnect_socket(&mut self) {
        match self {
            MutinySocketDescriptor::Tcp(s) => s.disconnect_socket(),
        }
    }
}

pub fn schedule_descriptor_read<P: PeerManager>(
    mut descriptor: MutinySocketDescriptor,
    peer_manager: Arc<P>,
    logger: Arc<MutinyLogger>,
    stop: Arc<AtomicBool>,
) {
    log_trace!(logger, "scheduling descriptor reader");
    let descriptor_clone = descriptor.clone();
    utils::spawn(async move {
        loop {
            let mut read_fut = Box::pin(descriptor_clone.read()).fuse();
            let delay_fut = Box::pin(utils::sleep(1_000)).fuse();
            pin_mut!(delay_fut);
            select! {
                msg_option = read_fut => {
                    if let Some(msg) = msg_option {
                        match msg {
                            Ok(b) => {
                                let read_res = peer_manager.read_event(&mut descriptor, &b);
                                match read_res {
                                    Ok(_read_bool) => {
                                        peer_manager.process_events();
                                    }
                                    Err(e) => {
                                        log_error!(logger, "got an error reading event: {}", e);
                                    }
                                }
                                if descriptor.is_closed() {
                                    log_error!(logger, "socket descriptor is closed");
                                    break;
                                }
                            }
                            Err(e) => {
                                log_error!(logger, "got an error reading msg: {}", e);
                                descriptor.disconnect_socket();
                                peer_manager.socket_disconnected(&mut descriptor);
                                peer_manager.process_events();
                                break;
                            }
                        }
                    }
                }
                _ = delay_fut => {
                    if stop.load(Ordering::Relaxed) {
                        break;
                    }
                }
            }
        }
        log_trace!(logger, "WebSocket Closed")
    });
}


================================================
File: mutiny-core/src/networking/websocket.rs
================================================
use async_trait::async_trait;
use futures::{SinkExt, StreamExt};

#[cfg(target_arch = "wasm32")]
use std::sync::Arc;

#[cfg(target_arch = "wasm32")]
use futures::lock::Mutex;

#[allow(dead_code)]
#[cfg_attr(target_arch = "wasm32", async_trait(?Send))]
#[cfg_attr(not(target_arch = "wasm32"), async_trait)]
pub trait SimpleWebSocket {
    async fn new(url: String) -> Result<Self, Box<dyn std::error::Error>>
    where
        Self: Sized;
    async fn send(&mut self, msg: String) -> Result<(), Box<dyn std::error::Error>>;
    async fn recv(&mut self) -> Result<String, Box<dyn std::error::Error>>;
}

#[cfg(target_arch = "wasm32")]
pub struct WebSocketImpl {
    write: crate::networking::proxy::WsSplit,
    read: crate::networking::proxy::ReadSplit,
}

#[cfg(target_arch = "wasm32")]
#[async_trait(?Send)]
impl SimpleWebSocket for WebSocketImpl {
    async fn new(url: String) -> Result<Self, Box<dyn std::error::Error>> {
        let ws = gloo_net::websocket::futures::WebSocket::open(&url)?;
        let (write, read) = ws.split();
        Ok(Self {
            write: Arc::new(Mutex::new(write)),
            read: Arc::new(Mutex::new(read)),
        })
    }

    async fn send(&mut self, msg: String) -> Result<(), Box<dyn std::error::Error>> {
        Ok(self
            .write
            .lock()
            .await
            .send(gloo_net::websocket::Message::Text(msg))
            .await?)
    }

    async fn recv(&mut self) -> Result<String, Box<dyn std::error::Error>> {
        Ok(if let Some(msg) = self.read.lock().await.next().await {
            match msg? {
                gloo_net::websocket::Message::Text(text) => text,
                _ => return Err("received non-text message".into()),
            }
        } else {
            return Err("failed to receive message".into());
        })
    }
}

#[cfg(not(target_arch = "wasm32"))]
pub struct WebSocketImpl {
    ws: tokio_tungstenite::WebSocketStream<
        tokio_tungstenite::MaybeTlsStream<tokio::net::TcpStream>,
    >,
}

#[async_trait]
#[cfg(not(target_arch = "wasm32"))]
impl SimpleWebSocket for WebSocketImpl {
    async fn new(url: String) -> Result<Self, Box<dyn std::error::Error>> {
        let (ws_stream, _response) = tokio_tungstenite::connect_async(url)
            .await
            .map_err(Box::new)?;
        Ok(Self { ws: ws_stream })
    }

    async fn send(&mut self, msg: String) -> Result<(), Box<dyn std::error::Error>> {
        Ok(self
            .ws
            .send(tokio_tungstenite::tungstenite::Message::Text(msg))
            .await?)
    }

    async fn recv(&mut self) -> Result<String, Box<dyn std::error::Error>> {
        match self.ws.next().await {
            Some(Ok(tokio_tungstenite::tungstenite::Message::Text(msg))) => Ok(msg),
            Some(Ok(_)) => Err(Box::new(std::io::Error::new(
                std::io::ErrorKind::Other,
                "received non-text message",
            ))),
            Some(Err(e)) => Err(Box::new(e)),
            None => Err(Box::new(std::io::Error::new(
                std::io::ErrorKind::Other,
                "failed to receive message",
            ))),
        }
    }
}


================================================
File: mutiny-core/src/networking/ws_socket.rs
================================================
use crate::networking::socket::ReadDescriptor;
use crate::utils;
use crate::{error::MutinyError, networking::proxy::Proxy};
use gloo_net::websocket::Message;
use lightning::ln::peer_handler;
use std::cell::OnceCell;
use std::hash::Hash;
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Arc;

static ID_COUNTER: AtomicU64 = AtomicU64::new(0);

pub struct WsTcpSocketDescriptor {
    conn: OnceCell<Arc<dyn Proxy>>,
    id: u64,
}

impl WsTcpSocketDescriptor {
    pub fn new(conn: impl Proxy + 'static) -> Self {
        let id = ID_COUNTER.fetch_add(1, Ordering::AcqRel);
        let inner: Arc<dyn Proxy> = Arc::new(conn);
        let cell = OnceCell::new();
        cell.get_or_init(|| inner);
        Self { conn: cell, id }
    }

    pub fn is_closed(&self) -> bool {
        self.conn.get().is_none()
    }
}

impl ReadDescriptor for WsTcpSocketDescriptor {
    async fn read(&self) -> Option<Result<Vec<u8>, MutinyError>> {
        match self.conn.get()?.read().await {
            Some(Ok(Message::Bytes(b))) => Some(Ok(b)),
            Some(Ok(Message::Text(_))) => {
                // Ignoring text messages sent through tcp socket
                None
            }
            Some(Err(_)) => Some(Err(MutinyError::ConnectionFailed)),
            None => None,
        }
    }
}

unsafe impl Send for WsTcpSocketDescriptor {}
unsafe impl Sync for WsTcpSocketDescriptor {}

impl peer_handler::SocketDescriptor for WsTcpSocketDescriptor {
    fn send_data(&mut self, data: &[u8], _resume_read: bool) -> usize {
        let vec = Vec::from(data);
        match self.conn.get() {
            Some(conn) => {
                conn.send(Message::Bytes(vec));
                data.len()
            }
            None => 0,
        }
    }

    fn disconnect_socket(&mut self) {
        if let Some(conn) = self.conn.take() {
            utils::spawn(async move {
                conn.close().await;
            });
        }
    }
}

impl Clone for WsTcpSocketDescriptor {
    fn clone(&self) -> Self {
        Self {
            conn: self.conn.clone(),
            id: self.id,
        }
    }
}

impl Eq for WsTcpSocketDescriptor {}
impl PartialEq for WsTcpSocketDescriptor {
    fn eq(&self, o: &Self) -> bool {
        self.id == o.id
    }
}
impl Hash for WsTcpSocketDescriptor {
    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {
        self.id.hash(state);
    }
}

impl std::fmt::Debug for WsTcpSocketDescriptor {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        write!(f, "({})", self.id)
    }
}

#[cfg(test)]
mod tests {
    use crate::networking::proxy::MockProxy;

    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};

    use crate::networking::socket::MutinySocketDescriptor;
    use crate::networking::ws_socket::WsTcpSocketDescriptor;

    wasm_bindgen_test_configure!(run_in_browser);

    #[test]
    async fn test_eq_for_ws_socket_descriptor() {
        // Test ne and eq for WsTcpSocketDescriptor
        let mock_proxy = MockProxy::new();
        let tcp_ws = MutinySocketDescriptor::Tcp(WsTcpSocketDescriptor::new(mock_proxy));

        let mock_proxy_2 = MockProxy::new();
        let tcp_ws_2 = MutinySocketDescriptor::Tcp(WsTcpSocketDescriptor::new(mock_proxy_2));
        assert_ne!(tcp_ws, tcp_ws_2);

        let mock_proxy_3 = MockProxy::new();
        let tcp_ws_3 = MutinySocketDescriptor::Tcp(WsTcpSocketDescriptor::new(mock_proxy_3));
        assert_eq!(tcp_ws_3.clone(), tcp_ws_3);
    }
}


================================================
File: mutiny-wasm/README.md
================================================
# mutiny-wasm

A wasm-bindgen wrapper around mutiny-core

## Installing

### Package manager

Using npm:

```bash
$ npm install mutiny-wasm
```

Using bower:

```bash
$ bower install mutiny-wasm
```

Using yarn:

```bash
$ yarn add mutiny-wasm
```

Using pnpm:

```bash
$ pnpm add mutiny-wasm
```

================================================
File: mutiny-wasm/Cargo.toml
================================================
cargo-features = ["per-package-target"]

[package]
name = "mutiny-wasm"
version = "1.12.1"
edition = "2021"
authors = ["utxostack"]
forced-target = "wasm32-unknown-unknown"
description = "A wasm-bindgen wrapper around mutiny-core"
license = "MIT"
documentation = "https://docs.rs/mutiny-wasm"
homepage = "https://mutinywallet.com"
repository = "https://github.com/mutinywallet/mutiny-node"

[lib]
crate-type = ["cdylib"]

[dependencies]
mutiny-core = { path = "../mutiny-core" }

anyhow = "1.0"
async-trait = "0.1.68"
wasm-bindgen = "0.2.91"
wasm-bindgen-futures = "0.4.38"
serde-wasm-bindgen = "0.6"
serde = { version = "^1.0", features = ["derive"] }
serde_json = { version = "^1.0" }
base64 = "0.13.1"
bitcoin = { version = "0.32.2", default-features = false, features = [
  "std",
  "serde",
  "secp-recovery",
  "rand",
] }
lightning = { version = "0.0.124", default-features = false, features = [
  "std",
] }
lightning-invoice = { version = "0.32.0" }
thiserror = "1.0"
instant = { version = "0.1", features = ["wasm-bindgen"] }
log = { version = "0.4.17", features = ["std"] }
rexie = "0.5.0"
gloo-utils = { version = "0.2.0", features = ["serde"] }
web-sys = { version = "0.3.60", features = ["console", "BroadcastChannel"] }
bip39 = { version = "2.0.0" }
getrandom = { version = "0.2", features = ["js"] }
futures = "0.3.25"
urlencoding = "2.1.2"
once_cell = "1.18.0"
hex-conservative = "0.1.1"

# The `console_error_panic_hook` crate provides better debugging of panics by
# logging them with `console.error`. This is great for development, but requires
# all the `std::fmt` and `std::panicking` infrastructure, so isn't great for
# code size when deploying. Alas, we do it anyways.
console_error_panic_hook = { version = "0.1.7" }

[dev-dependencies]
wasm-bindgen-test = "0.3.33"
web-sys = { version = "0.3.65", features = ["console"] }
js-sys = "0.3.65"

[features]
default = []

[package.metadata.wasm-pack.profile.release]
wasm-opt = true


================================================
File: mutiny-wasm/LICENSE
================================================
MIT License

Copyright (c) 2022-2023 Mutiny Wallet Inc.

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


================================================
File: mutiny-wasm/webdriver.json
================================================
{
  "goog:chromeOptions": {
    "args": [
      "--use-fake-device-for-media-stream",
      "--use-fake-ui-for-media-stream"
    ]
  }
}


================================================
File: mutiny-wasm/src/error.rs
================================================
use lightning_invoice::ParseOrSemanticError;
use log::error;
use mutiny_core::error::{MutinyError, MutinyStorageError};
use thiserror::Error;
use wasm_bindgen::JsValue;

#[derive(Error, Debug)]
pub enum MutinyJsError {
    /// Returned when trying to start Mutiny while it is already running.
    #[error("Mutiny is already running.")]
    AlreadyRunning,
    /// Returned when trying to stop Mutiny while it is not running.
    #[error("Mutiny is not running.")]
    NotRunning,
    /// Returned when Mutiny tries to startup with a different network than the one it was
    /// previously running on.
    #[error("Incorrect expected network.")]
    NetworkMismatch,
    #[error("Message Packet size exceeded")]
    PacketSizeExceeded,
    /// Returned on any resource that is not found.
    #[error("Resource Not found.")]
    NotFound,
    /// The funding transaction could not be created.
    #[error("Funding transaction could not be created.")]
    FundingTxCreationFailed,
    /// A network connection has been closed.
    #[error("Network connection closed.")]
    ConnectionFailed,
    /// The invoice or address is on a different network
    #[error("The invoice or address is on a different network.")]
    IncorrectNetwork,
    /// Payment of the given invoice has already been initiated.
    #[error("An invoice must not get payed twice.")]
    NonUniquePaymentHash,
    /// Payment Timed out
    #[error("Payment timed out.")]
    PaymentTimeout,
    /// The given invoice is invalid.
    #[error("The given invoice is invalid.")]
    InvoiceInvalid,
    /// The given invoice is expired.
    #[error("The given invoice is expired.")]
    InvoiceExpired,
    /// Invoice creation failed.
    #[error("Failed to create invoice.")]
    InvoiceCreationFailed,
    /// We have enough balance to pay an invoice, but
    /// the this would take from our reserve amount which is not allowed.
    #[error("Channel reserve amount is too high.")]
    ReserveAmountError,
    /// We do not have enough balance to pay the given amount.
    #[error("We do not have enough balance to pay the given amount.")]
    InsufficientBalance,
    /// Could not make a request to the LSP.
    #[error("Failed to make a request to the LSP.")]
    LspGenericError,
    /// LSP indicated it could not fund the channel requested.
    #[error("Failed to request channel from LSP due to funding error.")]
    LspFundingError,
    /// LSP indicated the amount is too high to fund.
    #[error("Failed to request channel from LSP due to amount being too high.")]
    LspAmountTooHighError,
    /// LSP indicated it was not connected to the client node.
    #[error("Failed to have a connection to the LSP node.")]
    LspConnectionError,
    /// LSP required an invoice and none was provided.
    #[error("Failed to provide an invoice to the LSP.")]
    LspInvoiceRequired,
    /// Subscription Client Not Configured
    #[error("Subscription Client Not Configured")]
    SubscriptionClientNotConfigured,
    /// When an invalid parameter has been passed in by the user.
    #[error("Invalid Parameter")]
    InvalidParameter,
    /// Called incorrect lnurl function, eg calling withdraw on a pay lnurl
    #[error("Called incorrect lnurl function.")]
    IncorrectLnUrlFunction,
    /// No route for the given target could be found.
    #[error("Failed to find route.")]
    RoutingFailed,
    /// A given peer info could not be parsed.
    #[error("Failed to parse the given peer information.")]
    PeerInfoParseFailed,
    /// A channel could not be opened.
    #[error("Failed to create channel.")]
    ChannelCreationFailed,
    /// A channel could not be opened.
    #[error("Failed to create channel. {0}")]
    ChannelCreationFailedWithReason(String),
    /// A channel could not be closed.
    #[error("Failed to close channel.")]
    ChannelClosingFailed,
    /// Persistence failed.
    #[error("Failed to persist data.")]
    PersistenceFailed,
    #[error("Failed to read data from storage.")]
    ReadError,
    #[error("Failed to decode lightning data.")]
    LnDecodeError,
    /// A failure to generate a mnemonic seed.
    #[error("Failed to generate seed")]
    SeedGenerationFailed,
    /// User provided invalid mnemonic.
    #[error("Invalid mnemonic")]
    InvalidMnemonic,
    /// Invalid BTC transaction or hex string.
    #[error("Invalid BTC transaction")]
    InvalidTransaction,
    /// A wallet operation failed.
    #[error("Failed to conduct wallet operation.")]
    WalletOperationFailed,
    /// A signing operation failed.
    #[error("Failed to sign given transaction.")]
    WalletSigningFailed,
    /// A chain access operation failed.
    #[error("Failed to conduct chain access operation.")]
    ChainAccessFailed,
    /// A failure to sync the on-chain wallet
    #[error("Failed to to sync on-chain wallet.")]
    WalletSyncError,
    /// An error with rapid gossip sync
    #[error("Failed to execute a rapid gossip sync function")]
    RapidGossipSyncError,
    /// An error when reading/writing json to the front end.
    #[error("Failed to read or write json from the front end")]
    JsonReadWriteError,
    /// Node pubkey given is invalid
    #[error("The given node pubkey is invalid.")]
    PubkeyInvalid,
    /// Error getting nostr data
    #[error("Failed to get nostr data.")]
    NostrError,
    /// Error with Nip07 Extension
    #[error("Error with NIP-07 extension")]
    Nip07Extension,
    /// Error getting the bitcoin price
    #[error("Failed to get the bitcoin price.")]
    BitcoinPriceError,
    /// Error converting JS f64 value to Amount
    #[error("Satoshi amount is invalid")]
    BadAmountError,
    /// A error with DLCs
    #[error("Failed to execute a dlc function")]
    DLCManagerError,
    /// A error with WasmBindgen
    #[error("Failed to execute a wasm_bindgen function")]
    WasmBindgenError,
    /// Invalid Arguments were given
    #[error("Invalid Arguments were given")]
    InvalidArgumentsError,
    /// Invalid BTC Address or Network was given
    #[error("Invalid BTC Address or Network was given")]
    InvalidAddressNetworkError,
    /// Incorrect password entered.
    #[error("Incorrect password entered.")]
    IncorrectPassword,
    /// Cannot change password to the same password
    #[error("Cannot change password to the same password.")]
    SamePassword,
    /// Payjoin request creation failed.
    #[error("Failed to create payjoin request.")]
    PayjoinCreateRequest,
    // Payjoin request failed.
    #[error("Payjoin response error: {0}")]
    PayjoinResponse(String),
    /// Payjoin configuration error
    #[error("Payjoin configuration failed.")]
    PayjoinConfigError,
    /// Error calling Cashu Mint
    #[error("Error calling Cashu Mint")]
    CashuMintError,
    /// Mint URL in token was empty
    #[error("Mint URL in token is empty")]
    EmptyMintURLError,
    #[error("Encrypt or decrypt failed")]
    EncryptOrDecryptError,
    /// Token already spent.
    #[error("Token has been already spent.")]
    TokenAlreadySpent,
    #[error("Invalid fee rate")]
    InvalidFeerate,
    #[error("Invalid psbt")]
    InvalidPsbt,
    #[error("Invalid hex")]
    InvalidHex,
    #[error("JWT Auth Failure")]
    JwtAuthFailure,
    #[error("Failed to parse VSS value from getObject response.")]
    FailedParsingVssValue,
    /// Unknown error.
    #[error("Unknown Error")]
    UnknownError,
}

impl From<MutinyError> for MutinyJsError {
    fn from(e: MutinyError) -> Self {
        match e {
            MutinyError::AlreadyRunning => MutinyJsError::AlreadyRunning,
            MutinyError::NotRunning => MutinyJsError::NotRunning,
            MutinyError::NotFound => MutinyJsError::NotFound,
            MutinyError::FundingTxCreationFailed => MutinyJsError::FundingTxCreationFailed,
            MutinyError::ConnectionFailed => MutinyJsError::ConnectionFailed,
            MutinyError::IncorrectNetwork => MutinyJsError::IncorrectNetwork,
            MutinyError::NonUniquePaymentHash => MutinyJsError::NonUniquePaymentHash,
            MutinyError::PaymentTimeout => MutinyJsError::PaymentTimeout,
            MutinyError::InvoiceInvalid => MutinyJsError::InvoiceInvalid,
            MutinyError::InvoiceExpired => MutinyJsError::InvoiceExpired,
            MutinyError::InvoiceCreationFailed => MutinyJsError::InvoiceCreationFailed,
            MutinyError::ReserveAmountError => MutinyJsError::ReserveAmountError,
            MutinyError::InsufficientBalance => MutinyJsError::InsufficientBalance,
            MutinyError::LspGenericError => MutinyJsError::LspGenericError,
            MutinyError::LspFundingError => MutinyJsError::LspFundingError,
            MutinyError::LspConnectionError => MutinyJsError::LspConnectionError,
            MutinyError::LspInvoiceRequired => MutinyJsError::LspInvoiceRequired,
            MutinyError::RoutingFailed => MutinyJsError::RoutingFailed,
            MutinyError::PeerInfoParseFailed => MutinyJsError::PeerInfoParseFailed,
            MutinyError::ChannelCreationFailed => MutinyJsError::ChannelCreationFailed,
            MutinyError::ChannelCreationFailedWithReason(x) => {
                MutinyJsError::ChannelCreationFailedWithReason(x)
            }
            MutinyError::ChannelClosingFailed => MutinyJsError::ChannelClosingFailed,
            MutinyError::PersistenceFailed { source: _ } => MutinyJsError::PersistenceFailed,
            MutinyError::ReadError { source: _ } => MutinyJsError::ReadError,
            MutinyError::LnDecodeError => MutinyJsError::LnDecodeError,
            MutinyError::SeedGenerationFailed => MutinyJsError::SeedGenerationFailed,
            MutinyError::WalletOperationFailed => MutinyJsError::WalletOperationFailed,
            MutinyError::InvalidMnemonic => MutinyJsError::InvalidMnemonic,
            MutinyError::InvalidTransaction => MutinyJsError::InvalidTransaction,
            MutinyError::WalletSigningFailed => MutinyJsError::WalletSigningFailed,
            MutinyError::ChainAccessFailed => MutinyJsError::ChainAccessFailed,
            MutinyError::WalletSyncError => MutinyJsError::WalletSyncError,
            MutinyError::RapidGossipSyncError => MutinyJsError::RapidGossipSyncError,
            MutinyError::DLCManagerError => MutinyJsError::DLCManagerError,
            MutinyError::PubkeyInvalid => MutinyJsError::PubkeyInvalid,
            MutinyError::BadAmountError => MutinyJsError::BadAmountError,
            MutinyError::NostrError => MutinyJsError::NostrError,
            MutinyError::Nip07Extension => MutinyJsError::Nip07Extension,
            MutinyError::BitcoinPriceError => MutinyJsError::BitcoinPriceError,
            MutinyError::IncorrectPassword => MutinyJsError::IncorrectPassword,
            MutinyError::SamePassword => MutinyJsError::SamePassword,
            MutinyError::CashuMintError => MutinyJsError::CashuMintError,
            MutinyError::EmptyMintURLError => MutinyJsError::EmptyMintURLError,
            MutinyError::TokenAlreadySpent => MutinyJsError::TokenAlreadySpent,
            MutinyError::Other(_) => MutinyJsError::UnknownError,
            MutinyError::SubscriptionClientNotConfigured => {
                MutinyJsError::SubscriptionClientNotConfigured
            }
            MutinyError::InvalidArgumentsError => MutinyJsError::InvalidArgumentsError,
            MutinyError::LspAmountTooHighError => MutinyJsError::LspAmountTooHighError,
            MutinyError::NetworkMismatch => MutinyJsError::NetworkMismatch,
            MutinyError::PacketSizeExceeded => MutinyJsError::PacketSizeExceeded,
            MutinyError::InvalidFeerate => MutinyJsError::InvalidFeerate,
            MutinyError::InvalidPsbt => MutinyJsError::InvalidPsbt,
            MutinyError::InvalidHex => MutinyJsError::InvalidHex,
            MutinyError::JwtAuthFailure => MutinyJsError::JwtAuthFailure,
            MutinyError::FailedParsingVssValue => MutinyJsError::FailedParsingVssValue,
        }
    }
}

impl From<MutinyStorageError> for MutinyJsError {
    fn from(e: MutinyStorageError) -> Self {
        MutinyError::from(e).into()
    }
}

impl From<base64::DecodeError> for MutinyJsError {
    fn from(_e: base64::DecodeError) -> Self {
        Self::InvalidArgumentsError
    }
}

impl From<bip39::Error> for MutinyJsError {
    fn from(_e: bip39::Error) -> Self {
        Self::InvalidMnemonic
    }
}

impl From<bitcoin::address::error::ParseError> for MutinyJsError {
    fn from(_: bitcoin::address::error::ParseError) -> Self {
        Self::JsonReadWriteError
    }
}

impl From<ParseOrSemanticError> for MutinyJsError {
    fn from(_e: ParseOrSemanticError) -> Self {
        Self::InvoiceInvalid
    }
}

impl From<bitcoin::hashes::hex::HexToArrayError> for MutinyJsError {
    fn from(_e: bitcoin::hashes::hex::HexToArrayError) -> Self {
        Self::InvalidHex
    }
}

impl From<bitcoin::hashes::hex::HexToBytesError> for MutinyJsError {
    fn from(_e: bitcoin::hashes::hex::HexToBytesError) -> Self {
        Self::InvalidHex
    }
}

impl From<bitcoin::secp256k1::Error> for MutinyJsError {
    fn from(_e: bitcoin::secp256k1::Error) -> Self {
        Self::PubkeyInvalid
    }
}

impl From<serde_json::error::Error> for MutinyJsError {
    fn from(_e: serde_json::error::Error) -> Self {
        Self::WasmBindgenError
    }
}

impl From<MutinyJsError> for JsValue {
    fn from(e: MutinyJsError) -> Self {
        JsValue::from(e.to_string())
    }
}


================================================
File: mutiny-wasm/src/indexed_db.rs
================================================
use anyhow::{anyhow, Context};
use async_trait::async_trait;
use bip39::Mnemonic;
use futures::lock::Mutex;
use futures::FutureExt;
use gloo_utils::format::JsValueSerdeExt;
use lightning::util::logger::Logger;
use lightning::{log_debug, log_error, log_info};
use log::error;
use messagehandler::BumpChannelClosureTransaction;
use mutiny_core::event::PaymentInfo;
use mutiny_core::logging::MutinyLogger;
use mutiny_core::logging::LOGGING_KEY;
use mutiny_core::nodemanager::NodeStorage;
use mutiny_core::storage::*;
use mutiny_core::vss::*;
use mutiny_core::*;
use mutiny_core::{
    encrypt::Cipher,
    error::{MutinyError, MutinyStorageError},
};
use nodemanager::ChannelClosure;
use rexie::{ObjectStore, Rexie, TransactionMode};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use std::collections::{BTreeSet, HashMap};
use std::sync::{Arc, RwLock};
use utils::DBTasks;
use wasm_bindgen::JsValue;

pub(crate) const WALLET_DATABASE_NAME: &str = "wallet";
pub(crate) const WALLET_OBJECT_STORE_NAME: &str = "wallet_store";

#[derive(Clone, Debug, PartialEq, Eq)]
pub struct RexieContainer(Option<Rexie>);

// These are okay because we never actually send across threads in the browser
unsafe impl Send for RexieContainer {}
unsafe impl Sync for RexieContainer {}

#[derive(Clone)]
pub struct IndexedDbStorage {
    pub(crate) database: String,
    pub(crate) password: Option<String>,
    pub cipher: Option<Cipher>,
    /// In-memory cache of the wallet data
    /// This is used to avoid having to read from IndexedDB on every get.
    /// This is a RwLock because we want to be able to read from it without blocking
    memory: Arc<RwLock<HashMap<String, Value>>>,
    pub(crate) indexed_db: Arc<RwLock<RexieContainer>>,
    vss: Option<Arc<MutinyVssClient>>,
    logger: Arc<MutinyLogger>,
    delayed_keys: Arc<Mutex<HashMap<String, DelayedKeyValueItem>>>,
    activity_index: Arc<RwLock<BTreeSet<IndexItem>>>,
    tasks: Arc<DBTasks>,
}

impl IndexedDbStorage {
    pub async fn new(
        database: String,
        password: Option<String>,
        cipher: Option<Cipher>,
        vss: Option<Arc<MutinyVssClient>>,
        logger: Arc<MutinyLogger>,
    ) -> Result<IndexedDbStorage, MutinyError> {
        if !database.starts_with(WALLET_DATABASE_NAME) {
            log_error!(
                logger,
                "IndexedDB database must prefix with '{WALLET_DATABASE_NAME}', got '{database}'",
            );
            return Err(MutinyError::PersistenceFailed {
                source: MutinyStorageError::IndexedDBError,
            });
        }
        log_debug!(
            logger,
            "Initialize indexed DB storage with password {} cipher {}",
            password.is_some(),
            cipher.is_some()
        );
        let idx = Self::build_indexed_db_database(database.clone()).await?;
        let indexed_db = Arc::new(RwLock::new(RexieContainer(Some(idx))));
        let password = password.filter(|p| !p.is_empty());

        let map = Self::read_all(
            &indexed_db,
            password.clone(),
            cipher.clone(),
            vss.as_deref(),
            &logger,
        )
        .await?;
        let memory = Arc::new(RwLock::new(map));

        log_debug!(logger, "Complete initialize indexed DB storage");

        Ok(IndexedDbStorage {
            database,
            password,
            cipher,
            memory,
            indexed_db,
            vss,
            logger,
            delayed_keys: Arc::new(Mutex::new(HashMap::new())),
            activity_index: Arc::new(RwLock::new(BTreeSet::new())),
            tasks: Arc::new(Default::default()),
        })
    }

    pub(crate) async fn has_mnemonic(database: String) -> Result<bool, MutinyError> {
        let indexed_db = Self::build_indexed_db_database(database).await?;
        let tx = indexed_db
            .transaction(&[WALLET_OBJECT_STORE_NAME], TransactionMode::ReadOnly)
            .map_err(|e| {
                MutinyError::read_err(
                    anyhow!("Failed to create read only indexed db transaction: {e}").into(),
                )
            })?;

        let store = tx.store(WALLET_OBJECT_STORE_NAME).map_err(|e| {
            MutinyError::read_err(
                anyhow!("Failed to create read only indexed db store: {e}").into(),
            )
        })?;

        let key = JsValue::from(MNEMONIC_KEY);
        let read = store
            .get(&key)
            .await
            .map_err(|_| MutinyError::read_err(MutinyStorageError::IndexedDBError))?;

        Ok(!read.is_null() && !read.is_undefined())
    }

    /// Read the mnemonic from indexed db, if one does not exist,
    /// then generate a new one and save it to indexed db.
    pub(crate) async fn get_mnemonic(
        database: String,
        override_mnemonic: Option<Mnemonic>,
        password: Option<&str>,
        cipher: Option<Cipher>,
    ) -> Result<Mnemonic, MutinyError> {
        let indexed_db = Self::build_indexed_db_database(database).await?;
        let tx = indexed_db
            .transaction(&[WALLET_OBJECT_STORE_NAME], TransactionMode::ReadWrite)
            .map_err(|e| {
                MutinyError::read_err(
                    anyhow!("Failed to create indexed db transaction: {e}").into(),
                )
            })?;

        let store = tx.store(WALLET_OBJECT_STORE_NAME).map_err(|e| {
            MutinyError::read_err(anyhow!("Failed to create indexed db store: {e}").into())
        })?;

        let key = JsValue::from(MNEMONIC_KEY);
        let read = store
            .get(&key)
            .await
            .map_err(|_| MutinyError::read_err(MutinyStorageError::IndexedDBError))?;

        // if there is no mnemonic in indexed db generate a new one and insert
        let res = if read.is_null() || read.is_undefined() {
            let seed = override_mnemonic.unwrap_or_else(|| generate_seed(12).unwrap());

            // encrypt and save to indexed db
            let value = encrypt_value(MNEMONIC_KEY, serde_json::to_value(seed.clone())?, cipher)?;
            store
                .put(&JsValue::from_serde(&value)?, Some(&key))
                .await
                .map_err(|_| MutinyError::write_err(MutinyStorageError::IndexedDBError))?;

            seed
        } else {
            // if there is a mnemonic in indexed db, then decrypt it
            let value = decrypt_value(MNEMONIC_KEY, read.into_serde()?, password)?;

            // If we can't deserialize the value, then the password was incorrect when we tried to decrypt
            let seed: Mnemonic =
                serde_json::from_value(value).map_err(|_| MutinyError::IncorrectPassword)?;

            // if we hae an override mnemonic, then we need to check that it matches the one in indexed db
            if override_mnemonic.is_some_and(|m| m != seed) {
                return Err(MutinyError::InvalidMnemonic);
            }

            seed
        };

        tx.done()
            .await
            .map_err(|_| MutinyError::write_err(MutinyStorageError::IndexedDBError))?;

        Ok(res)
    }

    pub(crate) async fn get_logs(database: String) -> Result<Option<Vec<String>>, MutinyError> {
        let indexed_db = Self::build_indexed_db_database(database).await?;
        let tx = indexed_db
            .transaction(&[WALLET_OBJECT_STORE_NAME], TransactionMode::ReadOnly)
            .map_err(|e| {
                MutinyError::read_err(
                    anyhow!("Failed to create indexed db transaction: {e}").into(),
                )
            })?;

        let store = tx.store(WALLET_OBJECT_STORE_NAME).map_err(|e| {
            MutinyError::read_err(anyhow!("Failed to create indexed db store: {e}").into())
        })?;

        let key = JsValue::from(LOGGING_KEY);
        let read = store
            .get(&key)
            .await
            .map_err(|_| MutinyError::read_err(MutinyStorageError::IndexedDBError))?;

        let result: Option<Vec<String>> = read.into_serde()?;

        Ok(result)
    }

    async fn save_to_indexed_db(
        indexed_db: &Arc<RwLock<RexieContainer>>,
        items: &[(String, Value)],
    ) -> Result<(), MutinyError> {
        // Device lock is only saved to VSS
        if items.len() == 1 && items.iter().all(|(k, _)| k == DEVICE_LOCK_KEY) {
            return Ok(());
        }

        let tx = indexed_db
            .try_write()
            .map_err(|e| MutinyError::read_err(e.into()))
            .and_then(|indexed_db_lock| {
                if let Some(indexed_db) = &indexed_db_lock.0 {
                    indexed_db
                        .transaction(&[WALLET_OBJECT_STORE_NAME], TransactionMode::ReadWrite)
                        .map_err(|e| {
                            MutinyError::read_err(
                                anyhow!("Failed to create indexed db transaction: {e}").into(),
                            )
                        })
                } else {
                    Err(MutinyError::read_err(MutinyStorageError::IndexedDBError))
                }
            })?;

        let store = tx.store(WALLET_OBJECT_STORE_NAME).map_err(|e| {
            MutinyError::read_err(anyhow!("Failed to create indexed db store: {e}").into())
        })?;

        // save to indexed db
        for (key, data) in items {
            store
                .put(&JsValue::from_serde(&data)?, Some(&JsValue::from(key)))
                .await
                .map_err(|_| MutinyError::write_err(MutinyStorageError::IndexedDBError))?;
        }

        tx.done()
            .await
            .map_err(|_| MutinyError::write_err(MutinyStorageError::IndexedDBError))?;

        Ok(())
    }

    async fn delete_from_indexed_db(
        indexed_db: &Arc<RwLock<RexieContainer>>,
        keys: &[String],
    ) -> Result<(), MutinyError> {
        let tx = indexed_db
            .try_write()
            .map_err(|e| {
                error!("Failed to acquire indexed db lock: {e}");
                MutinyError::read_err(e.into())
            })
            .and_then(|indexed_db_lock| {
                if let Some(indexed_db) = &indexed_db_lock.0 {
                    indexed_db
                        .transaction(&[WALLET_OBJECT_STORE_NAME], TransactionMode::ReadWrite)
                        .map_err(|e| {
                            error!("Failed to create indexed db transaction: {e}");
                            MutinyError::read_err(
                                anyhow!("Failed to create indexed db transaction: {e}").into(),
                            )
                        })
                } else {
                    error!("No indexed db instance found");
                    Err(MutinyError::read_err(MutinyStorageError::IndexedDBError))
                }
            })?;

        let store = tx.store(WALLET_OBJECT_STORE_NAME).map_err(|e| {
            error!("Failed to create indexed db store: {e}");
            MutinyError::read_err(anyhow!("Failed to create indexed db store {e}").into())
        })?;

        // delete from indexed db
        for key in keys {
            store
                .delete(&JsValue::from(key))
                .await
                .map_err(|_| MutinyError::write_err(MutinyStorageError::IndexedDBError))?;
        }

        tx.done()
            .await
            .map_err(|_| MutinyError::write_err(MutinyStorageError::IndexedDBError))?;

        Ok(())
    }

    pub(crate) async fn read_all(
        indexed_db: &Arc<RwLock<RexieContainer>>,
        password: Option<String>,
        cipher: Option<Cipher>,
        vss: Option<&MutinyVssClient>,
        logger: &MutinyLogger,
    ) -> Result<HashMap<String, Value>, MutinyError> {
        let store = {
            let tx = indexed_db
                .try_read()
                .map_err(|e| MutinyError::read_err(e.into()))
                .and_then(|indexed_db_lock| {
                    if let Some(indexed_db) = &indexed_db_lock.0 {
                        indexed_db
                            .transaction(&[WALLET_OBJECT_STORE_NAME], TransactionMode::ReadOnly)
                            .map_err(|e| {
                                MutinyError::read_err(
                                    anyhow!("Failed to create indexed db transaction: {e}").into(),
                                )
                            })
                    } else {
                        Err(MutinyError::read_err(MutinyStorageError::IndexedDBError))
                    }
                })?;
            tx.store(WALLET_OBJECT_STORE_NAME).map_err(|e| {
                MutinyError::read_err(anyhow!("Failed to create indexed db store {e}").into())
            })?
        };

        let start = instant::Instant::now();
        // use a memory storage to handle encryption and decryption
        let map = MemoryStorage::new(password, cipher, None);

        let all_json = store.get_all(None, None, None, None).await.map_err(|e| {
            MutinyError::read_err(anyhow!("Failed to get all from store: {e}").into())
        })?;

        log_info!(
            logger,
            "Read {} key values from browser storage",
            all_json.len()
        );

        for (key, value) in all_json {
            let key = key
                .as_string()
                .ok_or(MutinyError::read_err(MutinyStorageError::Other(anyhow!(
                    "key from indexedDB is not a string"
                ))))?;

            // we no longer need to read this key,
            // so we can remove it from memory
            if key == NETWORK_GRAPH_KEY {
                continue;
            }

            let json: Value = value.into_serde()?;
            map.write_raw(vec![(key, json)])?;
        }
        log_debug!(
            logger,
            "Reading browser storage took {}ms",
            start.elapsed().as_millis()
        );

        match vss {
            None => {
                log_info!(logger, "No VSS configured");
                let final_map = map.memory.read().unwrap();
                Ok(final_map.clone())
            }
            Some(vss) => {
                log_info!(logger, "Reading from vss");
                let start = instant::Instant::now();
                let keys = vss.list_key_versions(None).await?;
                log_info!(logger, "Read {} keys from vss", keys.len());
                let mut futs = Vec::with_capacity(keys.len());
                for kv in keys {
                    let key = kv.key.clone();
                    futs.push(
                        Self::handle_vss_key(kv, vss, &map, logger).then(|r| async move {
                            r.with_context(|| format!("handle vss key {}", key))
                        }),
                    );
                }
                let results = futures::future::try_join_all(futs).await?;

                for (key, value) in results.into_iter().flatten() {
                    // save to memory and batch the write to local storage
                    map.write_data(key.clone(), value.clone(), None)?;
                }
                let inner_map = map.memory.read().unwrap().clone();

                if !inner_map.is_empty() {
                    let items: Vec<_> = inner_map
                        .iter()
                        .map(|(k, v)| (k.to_owned(), v.to_owned()))
                        .collect();
                    // write them so we don't have to pull them down again
                    Self::save_to_indexed_db(indexed_db, &items).await?;
                }

                log_debug!(logger, "Reading VSS took {}ms", start.elapsed().as_millis());

                Ok(inner_map)
            }
        }
    }

    async fn handle_vss_key(
        kv: KeyVersion,
        vss: &MutinyVssClient,
        current: &MemoryStorage,
        logger: &MutinyLogger,
    ) -> Result<Option<(String, Value)>, MutinyError> {
        log_debug!(
            logger,
            "Found vss key {} with version {}",
            kv.key,
            kv.version
        );

        match kv.key.as_str() {
            NODES_KEY => {
                // we can get version from node storage, so we should compare
                match current.get_data::<NodeStorage>(&kv.key)? {
                    Some(local) => {
                        if local.version < kv.version {
                            let obj = vss.get_object(&kv.key).await?;
                            if serde_json::from_value::<NodeStorage>(obj.value.clone()).is_ok() {
                                return Ok(Some((kv.key, obj.value)));
                            }
                        }
                    }
                    None => {
                        let obj = vss.get_object(&kv.key).await?;
                        return Ok(Some((kv.key, obj.value)));
                    }
                }
            }
            DEVICE_LOCK_KEY => {
                // we can get version from device lock, so we should compare
                match current.get_data::<DeviceLock>(&kv.key)? {
                    Some(lock) => {
                        // we use time as version for device lock
                        if lock.time < kv.version {
                            let obj = vss.get_object(&kv.key).await?;
                            if serde_json::from_value::<DeviceLock>(obj.value.clone()).is_ok() {
                                return Ok(Some((kv.key, obj.value)));
                            }
                        }
                    }
                    None => {
                        let obj = vss.get_object(&kv.key).await?;
                        return Ok(Some((kv.key, obj.value)));
                    }
                }
            }
            SERVICE_TOKENS => {
                let obj = vss.get_object(&kv.key).await?;
                return Ok(Some((kv.key, obj.value)));
            }
            KEYCHAIN_STORE_KEY => match current
                .get_data::<VersionedValue>(&kv.key)
                .with_context(|| "read keychain data from storage")?
            {
                Some(local) => {
                    if local.version < kv.version {
                        let obj = vss.get_object(&kv.key).await?;
                        if serde_json::from_value::<VersionedValue>(obj.value.clone()).is_ok() {
                            return Ok(Some((kv.key, obj.value)));
                        }
                    }
                }
                None => {
                    let obj = vss.get_object(&kv.key).await?;
                    return Ok(Some((kv.key, obj.value)));
                }
            },
            key => {
                if key.starts_with(MONITORS_PREFIX_KEY) {
                    // we can get versions from monitors, so we should compare
                    match current.get::<Vec<u8>>(&kv.key)? {
                        Some(bytes) => {
                            let current_version = utils::get_monitor_version(&bytes);

                            // if the current version is less than the version from vss, then we want to use the vss version
                            if current_version < kv.version as u64 {
                                let obj = vss.get_object(&kv.key).await?;
                                return Ok(Some((kv.key, obj.value)));
                            } else {
                                log_debug!(
                                    logger,
                                    "Skipping vss key {} with version {}, current version is {current_version}",
                                    kv.key,
                                    kv.version
                                );
                                return Ok(None);
                            }
                        }
                        None => {
                            let obj = vss.get_object(&kv.key).await?;
                            return Ok(Some((kv.key, obj.value)));
                        }
                    }
                } else if key.starts_with(CHANNEL_MANAGER_KEY) {
                    // we can get versions from channel manager, so we should compare
                    match current.get_data::<VersionedValue>(&kv.key)? {
                        Some(local) => {
                            if local.version < kv.version {
                                let obj = vss.get_object(&kv.key).await?;
                                if serde_json::from_value::<VersionedValue>(obj.value.clone())
                                    .is_ok()
                                {
                                    return Ok(Some((kv.key, obj.value)));
                                }
                            } else {
                                log_debug!(
                                    logger,
                                    "Skipping vss key {} with version {}, current version is {}",
                                    kv.key,
                                    kv.version,
                                    local.version
                                );
                                return Ok(None);
                            }
                        }
                        None => {
                            let obj = vss.get_object(&kv.key).await?;
                            if serde_json::from_value::<VersionedValue>(obj.value.clone()).is_ok() {
                                return Ok(Some((kv.key, obj.value)));
                            }
                        }
                    }
                } else if key.starts_with(PAYMENT_INBOUND_PREFIX_KEY)
                    || key.starts_with(PAYMENT_OUTBOUND_PREFIX_KEY)
                {
                    // we can get version from payment info, so we should compare
                    match current.get_data::<PaymentInfo>(&kv.key)? {
                        Some(info) => {
                            if (info.last_update as u32) < kv.version {
                                let obj = vss.get_object(&kv.key).await?;
                                if serde_json::from_value::<PaymentInfo>(obj.value.clone()).is_ok()
                                {
                                    return Ok(Some((kv.key, obj.value)));
                                }
                            } else {
                                log_debug!(
                                    logger,
                                    "Skipping vss key {} with version {}, current version is {}",
                                    kv.key,
                                    kv.version,
                                    info.last_update
                                );
                                return Ok(None);
                            }
                        }
                        None => {
                            let obj = vss.get_object(&kv.key).await?;
                            if serde_json::from_value::<PaymentInfo>(obj.value.clone()).is_ok() {
                                return Ok(Some((kv.key, obj.value)));
                            }
                        }
                    }
                } else if key.starts_with(CHANNEL_CLOSURE_PREFIX) {
                    // we can get version from channel closure info, so we should compare
                    match current.get_data::<ChannelClosure>(&kv.key)? {
                        Some(closure) => {
                            if (closure.timestamp as u32) < kv.version {
                                let obj = vss.get_object(&kv.key).await?;
                                if serde_json::from_value::<ChannelClosure>(obj.value.clone())
                                    .is_ok()
                                {
                                    return Ok(Some((kv.key, obj.value)));
                                }
                            } else {
                                log_debug!(
                                    logger,
                                    "Skipping vss key {} with version {}, current version is {}",
                                    kv.key,
                                    kv.version,
                                    closure.timestamp
                                );
                                return Ok(None);
                            }
                        }
                        None => {
                            let obj = vss.get_object(&kv.key).await?;
                            if serde_json::from_value::<ChannelClosure>(obj.value.clone()).is_ok() {
                                return Ok(Some((kv.key, obj.value)));
                            }
                        }
                    }
                } else if key.starts_with(CHANNEL_CLOSURE_BUMP_PREFIX) {
                    // we can get version from channel closure bumping info, so we should compare
                    match current.get_data::<BumpChannelClosureTransaction>(&kv.key)? {
                        Some(closure) => {
                            if (closure.timestamp as u32) < kv.version {
                                let obj = vss.get_object(&kv.key).await?;
                                if serde_json::from_value::<BumpChannelClosureTransaction>(
                                    obj.value.clone(),
                                )
                                .is_ok()
                                {
                                    return Ok(Some((kv.key, obj.value)));
                                }
                            } else {
                                log_debug!(
                                    logger,
                                    "Skipping vss key {} with version {}, current version is {}",
                                    kv.key,
                                    kv.version,
                                    closure.timestamp
                                );
                                return Ok(None);
                            }
                        }
                        None => {
                            let obj = vss.get_object(&kv.key).await?;
                            if serde_json::from_value::<BumpChannelClosureTransaction>(
                                obj.value.clone(),
                            )
                            .is_ok()
                            {
                                return Ok(Some((kv.key, obj.value)));
                            }
                        }
                    }
                }
            }
        }

        log_debug!(
            logger,
            "Skipping vss key {} with version {}",
            kv.key,
            kv.version
        );

        Ok(None)
    }

    async fn build_indexed_db_database(database: String) -> Result<Rexie, MutinyError> {
        if database.is_empty() {
            return Err(MutinyError::PersistenceFailed {
                source: MutinyStorageError::IndexedDBError,
            });
        }
        let rexie = Rexie::builder(&database)
            .version(1)
            .add_object_store(ObjectStore::new(WALLET_OBJECT_STORE_NAME))
            .build()
            .await
            .map_err(|e| {
                MutinyError::read_err(anyhow!("Failed to create indexed db database {e}").into())
            })?;

        Ok(rexie)
    }

    #[cfg(test)]
    pub(crate) async fn reload_from_indexed_db(&self) -> Result<(), MutinyError> {
        let map = Self::read_all(
            &self.indexed_db,
            self.password.clone(),
            self.cipher.clone(),
            self.vss.as_deref(),
            &self.logger,
        )
        .await?;
        let mut memory = self
            .memory
            .try_write()
            .map_err(|e| MutinyError::write_err(e.into()))?;
        *memory = map;
        Ok(())
    }
}

/// Some values only are read once, so we can remove them from memory after reading them
/// to save memory.
///
/// We also need to skip writing them to the in memory storage on updates.
fn used_once(key: &str) -> bool {
    match key {
        NETWORK_GRAPH_KEY | PROB_SCORER_KEY | GOSSIP_SYNC_TIME_KEY | BITCOIN_PRICE_CACHE_KEY => {
            true
        }
        str if str.starts_with(MONITORS_PREFIX_KEY) => true,
        str if str.starts_with(CHANNEL_MANAGER_KEY) => true,
        _ => false,
    }
}

#[async_trait(?Send)]
impl MutinyStorage for IndexedDbStorage {
    fn database(&self) -> Result<String, MutinyError> {
        Ok(self.database.clone())
    }

    fn password(&self) -> Option<&str> {
        self.password.as_deref()
    }

    fn cipher(&self) -> Option<Cipher> {
        self.cipher.to_owned()
    }

    fn vss_client(&self) -> Option<Arc<MutinyVssClient>> {
        self.vss.clone()
    }

    fn activity_index(&self) -> Arc<RwLock<BTreeSet<IndexItem>>> {
        self.activity_index.clone()
    }

    fn write_raw<T>(&self, items: Vec<(String, T)>) -> Result<(), MutinyError>
    where
        T: Serialize + Send,
    {
        let items = items
            .into_iter()
            .map(|(k, v)| {
                serde_json::to_value(v)
                    .map_err(|e| MutinyError::PersistenceFailed {
                        source: MutinyStorageError::SerdeError { source: e },
                    })
                    .map(|d| (k, d))
            })
            .collect::<Result<Vec<(String, Value)>, MutinyError>>()?;

        let indexed_db = self.indexed_db.clone();
        let items_clone = items.clone();

        // write to index DB in background job
        self.spawn(async move {
            Self::save_to_indexed_db(&indexed_db, &items_clone)
                .await
                .map_err(|e| MutinyError::PersistenceFailed {
                    source: MutinyStorageError::Other(anyhow!(
                        "Failed to save ({items_clone:?}) to indexed db: {e}"
                    )),
                })
        });

        // some values only are read once, so we don't need to write them to memory,
        // just need them in indexed db for next time
        let mut map = self
            .memory
            .try_write()
            .map_err(|e| MutinyError::write_err(e.into()))?;
        for (key, data) in items {
            if !used_once(key.as_ref()) {
                map.insert(key, data);
            }
        }

        Ok(())
    }

    fn get<T>(&self, key: impl AsRef<str>) -> Result<Option<T>, MutinyError>
    where
        T: for<'de> Deserialize<'de>,
    {
        let map = self
            .memory
            .try_read()
            .map_err(|e| MutinyError::read_err(e.into()))?;
        match map.get(key.as_ref()).cloned() {
            None => Ok(None),
            Some(value) => {
                // drop the map so we aren't holding the lock while deserializing
                // we also need to drop if we are going to remove the value from memory
                drop(map);

                let data: T = serde_json::from_value(value)?;

                // some values only are read once, so we can remove them from memory
                let mut map = self
                    .memory
                    .try_write()
                    .map_err(|e| MutinyError::write_err(e.into()))?;
                if used_once(key.as_ref()) {
                    map.remove(key.as_ref());
                }

                Ok(Some(data))
            }
        }
    }

    fn delete(&self, keys: &[impl AsRef<str>]) -> Result<(), MutinyError> {
        let keys: Vec<String> = keys.iter().map(|k| k.as_ref().to_string()).collect();

        let indexed_db = self.indexed_db.clone();
        let keys_clone = keys.clone();

        self.spawn(async move {
            Self::delete_from_indexed_db(&indexed_db, &keys_clone)
                .await
                .map_err(|e| MutinyError::PersistenceFailed {
                    source: MutinyStorageError::Other(anyhow!(
                        "Failed to delete ({keys_clone:?}) from indexed db: {e}"
                    )),
                })
        });

        let mut map = self
            .memory
            .try_write()
            .map_err(|e| MutinyError::write_err(e.into()))?;

        for key in keys {
            map.remove(&key);
        }

        Ok(())
    }

    async fn start(&mut self) -> Result<(), MutinyError> {
        log_debug!(self.logger, "starting storage");
        let indexed_db = if self.indexed_db.try_read()?.0.is_none() {
            Arc::new(RwLock::new(RexieContainer(Some(
                Self::build_indexed_db_database(self.database.clone()).await?,
            ))))
        } else {
            self.indexed_db.clone()
        };

        let map = Self::read_all(
            &indexed_db,
            self.password.clone(),
            self.cipher.clone(),
            self.vss.as_deref(),
            &self.logger,
        )
        .await?;
        let memory = Arc::new(RwLock::new(map));
        self.indexed_db = indexed_db;
        self.memory = memory;
        log_debug!(self.logger, "started storage");
        Ok(())
    }

    fn spawn<Fut: futures::future::Future<Output = Result<(), MutinyError>> + 'static>(
        &self,
        fut: Fut,
    ) {
        let logger = self.logger.clone();
        let tasks = self.tasks.clone();
        tasks.inc_started();
        utils::spawn(async move {
            if let Err(err) = fut.await {
                log_error!(logger, "DBTask error {:?}", err);
            }
            tasks.inc_done();
        })
    }

    async fn stop(&self) {
        log_debug!(self.logger, "stopping storage");
        // Wait all back ground tasks
        self.tasks.wait().await;

        // close DB
        if let Ok(mut indexed_db_lock) = self.indexed_db.try_write() {
            if let Some(indexed_db) = indexed_db_lock.0.take() {
                indexed_db.close();
            }
        }
        log_debug!(self.logger, "stopped storage");
    }

    fn connected(&self) -> Result<bool, MutinyError> {
        Ok(self.indexed_db.try_read()?.0.is_some())
    }

    fn scan_keys(&self, prefix: &str, suffix: Option<&str>) -> Result<Vec<String>, MutinyError> {
        let map = self
            .memory
            .try_read()
            .map_err(|e| MutinyError::read_err(e.into()))?;

        Ok(map
            .keys()
            .filter(|key| {
                key.starts_with(prefix) && (suffix.is_none() || key.ends_with(suffix.unwrap()))
            })
            .cloned()
            .collect())
    }

    fn change_password(
        &mut self,
        new: Option<String>,
        new_cipher: Option<Cipher>,
    ) -> Result<(), MutinyError> {
        self.password = new;
        self.cipher = new_cipher;
        Ok(())
    }

    async fn import(database: String, json: Value) -> Result<(), MutinyError> {
        Self::clear(database.clone()).await?;
        let indexed_db = Self::build_indexed_db_database(database).await?;
        let tx = indexed_db
            .transaction(&[WALLET_OBJECT_STORE_NAME], TransactionMode::ReadWrite)
            .map_err(|e| {
                MutinyError::write_err(
                    anyhow!("Failed to create indexed db transaction: {e}").into(),
                )
            })?;
        let store = tx.store(WALLET_OBJECT_STORE_NAME).map_err(|e| {
            MutinyError::write_err(anyhow!("Failed to create indexed db store: {e}").into())
        })?;

        let map = json
            .as_object()
            .ok_or(MutinyError::write_err(MutinyStorageError::Other(anyhow!(
                "json is not an object"
            ))))?;

        for (key, value) in map {
            let key = JsValue::from(key);
            let value = JsValue::from_serde(&value)?;
            store.put(&value, Some(&key)).await.map_err(|e| {
                MutinyError::write_err(anyhow!("Failed to write to indexed db: {e}").into())
            })?;
        }

        tx.done().await.map_err(|e| {
            MutinyError::write_err(anyhow!("Failed to write to indexed db: {e}").into())
        })?;
        indexed_db.close();

        Ok(())
    }

    async fn clear(database: String) -> Result<(), MutinyError> {
        let indexed_db = Self::build_indexed_db_database(database).await?;
        let tx = indexed_db
            .transaction(&[WALLET_OBJECT_STORE_NAME], TransactionMode::ReadWrite)
            .map_err(|e| MutinyError::write_err(anyhow!("Failed clear indexed db: {e}").into()))?;
        let store = tx
            .store(WALLET_OBJECT_STORE_NAME)
            .map_err(|e| MutinyError::write_err(anyhow!("Failed clear indexed db: {e}").into()))?;

        store
            .clear()
            .await
            .map_err(|e| MutinyError::write_err(anyhow!("Failed clear indexed db: {e}").into()))?;

        tx.done()
            .await
            .map_err(|e| MutinyError::write_err(anyhow!("Failed clear indexed db: {e}").into()))?;

        Ok(())
    }

    async fn fetch_device_lock(&self) -> Result<Option<DeviceLock>, MutinyError> {
        match self.vss.as_ref() {
            None => self.get_device_lock(),
            Some(vss) => {
                let json = vss.get_object(DEVICE_LOCK_KEY).await?;
                let device_lock = serde_json::from_value(json.value)?;
                Ok(Some(device_lock))
            }
        }
    }

    fn get_delayed_objects(&self) -> Arc<Mutex<HashMap<String, DelayedKeyValueItem>>> {
        self.delayed_keys.clone()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::indexed_db::IndexedDbStorage;
    use crate::utils::test::log;
    use bip39::Mnemonic;
    use mutiny_core::storage::MutinyStorage;
    use mutiny_core::utils::sleep;
    use mutiny_core::{encrypt::encryption_key_from_pass, logging::MutinyLogger};
    use serde_json::json;
    use std::str::FromStr;
    use std::sync::Arc;
    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};

    wasm_bindgen_test_configure!(run_in_browser);

    #[test]
    async fn test_empty_string_as_none() {
        let test_name = "test_empty_string_as_none";
        log!("{test_name}");

        let logger = Arc::new(MutinyLogger::default());
        let storage = IndexedDbStorage::new(
            WALLET_DATABASE_NAME.to_string(),
            Some("".to_string()),
            None,
            None,
            logger,
        )
        .await
        .unwrap();

        assert_eq!(storage.password, None);
    }

    #[test]
    async fn test_get_set_delete() {
        let test_name = "test_get_set_delete";
        log!("{test_name}");

        let key = "test_key".to_string();
        let value = "test_value";

        let logger = Arc::new(MutinyLogger::default());
        let password = "password".to_string();
        let cipher = encryption_key_from_pass(&password).unwrap();
        let storage = IndexedDbStorage::new(
            WALLET_DATABASE_NAME.to_string(),
            Some(password),
            Some(cipher),
            None,
            logger,
        )
        .await
        .unwrap();

        let result: Option<String> = storage.get(&key).unwrap();
        assert_eq!(result, None);

        storage.write_raw(vec![(key.clone(), value)]).unwrap();

        let result: Option<String> = storage.get(&key).unwrap();
        assert_eq!(result, Some(value.to_string()));

        // wait for the storage to be persisted
        sleep(1_000).await;
        // reload and check again
        storage.reload_from_indexed_db().await.unwrap();
        let result: Option<String> = storage.get(&key).unwrap();
        assert_eq!(result, Some(value.to_string()));

        storage.delete(&[key.clone()]).unwrap();

        let result: Option<String> = storage.get(&key).unwrap();
        assert_eq!(result, None);

        // wait for the storage to be persisted
        sleep(1_000).await;
        // reload and check again
        storage.reload_from_indexed_db().await.unwrap();
        let result: Option<String> = storage.get(&key).unwrap();
        assert_eq!(result, None);

        // clear the storage to clean up
        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .unwrap();
    }

    #[test]
    async fn test_import() {
        let test_name = "test_import";
        log!("{test_name}");

        let json = json!(
            {
                "test_key": "test_value",
                "test_key2": "test_value2"
            }
        );

        IndexedDbStorage::import(WALLET_DATABASE_NAME.to_string(), json)
            .await
            .unwrap();

        let logger = Arc::new(MutinyLogger::default());
        let password = "password".to_string();
        let cipher = encryption_key_from_pass(&password).unwrap();
        let storage = IndexedDbStorage::new(
            WALLET_DATABASE_NAME.to_string(),
            Some(password),
            Some(cipher),
            None,
            logger,
        )
        .await
        .unwrap();

        let result: Option<String> = storage.get("test_key").unwrap();
        assert_eq!(result, Some("test_value".to_string()));

        let result: Option<String> = storage.get("test_key2").unwrap();
        assert_eq!(result, Some("test_value2".to_string()));

        // clear the storage to clean up
        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .unwrap();
    }

    #[test]
    async fn test_clear() {
        let test_name = "test_clear";
        log!("{test_name}");

        let key = "test_key".to_string();
        let value = "test_value";

        let logger = Arc::new(MutinyLogger::default());
        let password = "password".to_string();
        let cipher = encryption_key_from_pass(&password).unwrap();
        let storage = IndexedDbStorage::new(
            WALLET_DATABASE_NAME.to_string(),
            Some(password),
            Some(cipher),
            None,
            logger,
        )
        .await
        .unwrap();

        storage.write_raw(vec![(key.clone(), value)]).unwrap();

        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .unwrap();

        storage.reload_from_indexed_db().await.unwrap();

        let result: Option<String> = storage.get(key).unwrap();
        assert_eq!(result, None);

        // clear the storage to clean up
        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .unwrap();
    }

    #[test]
    async fn insert_and_get_mnemonic_no_password() {
        let test_name = "insert_and_get_mnemonic_no_password";
        log!("{test_name}");

        let seed = Mnemonic::from_str("abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon about").expect("could not generate");

        let logger = Arc::new(MutinyLogger::default());
        let storage =
            IndexedDbStorage::new(WALLET_DATABASE_NAME.to_string(), None, None, None, logger)
                .await
                .unwrap();
        let mnemonic = storage.insert_mnemonic(seed).unwrap();

        let stored_mnemonic = storage.get_mnemonic().unwrap();
        assert_eq!(Some(mnemonic), stored_mnemonic);

        // clear the storage to clean up
        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .unwrap();
    }

    #[test]
    async fn insert_and_get_mnemonic_with_password() {
        let test_name = "insert_and_get_mnemonic_with_password";
        log!("{test_name}");

        let seed = Mnemonic::from_str("abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon about").expect("could not generate");

        let logger = Arc::new(MutinyLogger::default());
        let password = "password".to_string();
        let cipher = encryption_key_from_pass(&password).unwrap();
        let storage = IndexedDbStorage::new(
            WALLET_DATABASE_NAME.to_string(),
            Some(password),
            Some(cipher),
            None,
            logger,
        )
        .await
        .unwrap();

        let mnemonic = storage.insert_mnemonic(seed).unwrap();

        let stored_mnemonic = storage.get_mnemonic().unwrap();
        assert_eq!(Some(mnemonic), stored_mnemonic);

        // clear the storage to clean up
        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .unwrap();
    }

    #[test]
    async fn test_correct_incorrect_password_error() {
        let test_name = "test_correct_incorrect_password_error";
        log!("{test_name}");
        let logger = Arc::new(MutinyLogger::default());

        let storage = IndexedDbStorage::new(
            WALLET_DATABASE_NAME.to_string(),
            None,
            None,
            None,
            logger.clone(),
        )
        .await
        .unwrap();
        let seed = generate_seed(12).unwrap();
        storage
            .write_data(MNEMONIC_KEY.to_string(), seed, None)
            .unwrap();
        // wait for the storage to be persisted
        utils::sleep(1_000).await;

        let password = Some("password".to_string());
        let cipher = password
            .as_ref()
            .filter(|p| !p.is_empty())
            .map(|p| encryption_key_from_pass(p))
            .transpose()
            .unwrap();

        let storage = IndexedDbStorage::new(
            WALLET_DATABASE_NAME.to_string(),
            password,
            cipher,
            None,
            logger,
        )
        .await
        .unwrap();

        match storage.get_mnemonic() {
            Err(MutinyError::IncorrectPassword) => (),
            Ok(_) => panic!("Expected IncorrectPassword error, got Ok"),
            Err(e) => panic!("Expected IncorrectPassword error, got {:?}", e),
        }

        // clear the storage to clean up
        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .unwrap();
    }
}


================================================
File: mutiny-wasm/src/lib.rs
================================================
// wasm is considered "extra_unused_type_parameters"
#![allow(
    incomplete_features,
    clippy::extra_unused_type_parameters,
    clippy::arc_with_non_send_sync
)]

extern crate mutiny_core;

pub mod error;
mod indexed_db;
mod models;
mod utils;

use crate::error::MutinyJsError;
use crate::indexed_db::IndexedDbStorage;
use crate::models::*;
use bip39::Mnemonic;
use bitcoin::bip32::Xpriv;
use bitcoin::hashes::hex::FromHex;
use bitcoin::hashes::sha256;
use bitcoin::secp256k1::{PublicKey, SecretKey};
use bitcoin::{Address, Network, OutPoint, Txid};
use futures::lock::Mutex;
use gloo_utils::format::JsValueSerdeExt;

use lightning::{log_info, log_warn, routing::gossip::NodeId, util::logger::Logger};
use lightning_invoice::Bolt11Invoice;

use mutiny_core::authclient::MutinyAuthClient;
use mutiny_core::authmanager::AuthManager;
use mutiny_core::encrypt::decrypt_with_password;
use mutiny_core::error::MutinyError;
use mutiny_core::messagehandler::CommonLnEventCallback;
use mutiny_core::storage::{DeviceLock, MutinyStorage, DEVICE_LOCK_KEY};
use mutiny_core::utils::sleep;
use mutiny_core::vss::MutinyVssClient;
use mutiny_core::MutinyWalletBuilder;
use mutiny_core::{
    encrypt::{encrypt, encryption_key_from_pass},
    InvoiceHandler, MutinyWalletConfigBuilder,
};
use mutiny_core::{
    labels::LabelStorage,
    nodemanager::{create_lsp_config, NodeManager},
};
use mutiny_core::{logging::MutinyLogger, lsp::LspConfig};
use web_sys::BroadcastChannel;

use std::str::FromStr;
use std::sync::Arc;
use wasm_bindgen::prelude::*;

static INITIALIZED: once_cell::sync::Lazy<Mutex<bool>> =
    once_cell::sync::Lazy::new(|| Mutex::new(false));

#[cfg(test)]
async fn uninit() {
    let mut init = INITIALIZED.lock().await;
    *init = false;
}

#[wasm_bindgen]
pub struct MutinyWallet {
    mnemonic: Mnemonic,
    inner: mutiny_core::MutinyWallet<IndexedDbStorage>,
}

/// The [MutinyWallet] is the main entry point for interacting with the Mutiny Wallet.
/// It is responsible for managing the on-chain wallet and the lightning nodes.
///
/// It can be used to create a new wallet, or to load an existing wallet.
///
/// It can be configured to use all different custom backend services, or to use the default
/// services provided by Mutiny.
#[wasm_bindgen]
impl MutinyWallet {
    /// Creates a new [MutinyWallet] with the given parameters.
    /// The mnemonic seed is read from storage, unless one is provided.
    /// If no mnemonic is provided, a new one is generated and stored.
    #[wasm_bindgen]
    #[allow(clippy::too_many_arguments)]
    pub async fn new(
        database: String,
        password: Option<String>,
        mnemonic_str: Option<String>,
        websocket_proxy_addr: Option<String>,
        network_str: Option<String>,
        user_esplora_url: Option<String>,
        user_rgs_url: Option<String>,
        lsp_url: Option<String>,
        lsp_connection_string: Option<String>,
        lsp_token: Option<String>,
        auth_url: Option<String>,
        subscription_url: Option<String>,
        storage_url: Option<String>,
        auth_storage_url: Option<String>,
        _scorer_url: Option<String>,
        do_not_connect_peers: Option<bool>,
        skip_device_lock: Option<bool>,
        safe_mode: Option<bool>,
        skip_hodl_invoices: Option<bool>,
        do_not_bump_channel_close_tx: Option<bool>,
        sweep_target_address: Option<String>,
        nip_07_key: Option<String>,
        blind_auth_url: Option<String>,
        hermes_url: Option<String>,
        ln_event_topic: Option<String>,
    ) -> Result<MutinyWallet, MutinyJsError> {
        let start = instant::Instant::now();

        utils::set_panic_hook();
        let mut init = INITIALIZED.lock().await;
        if *init {
            return Err(MutinyJsError::AlreadyRunning);
        } else {
            *init = true;
        }

        let ln_event_callback = ln_event_topic.map(|topic| CommonLnEventCallback {
            callback: Arc::new(move |event| {
                const KEY: &str = "common_ln_event_broadcast_channel";
                let global = web_sys::js_sys::global();
                let value = web_sys::js_sys::Reflect::get(&global, &(KEY.into())).unwrap();
                let channel: BroadcastChannel = if value.is_undefined() {
                    let channel = web_sys::BroadcastChannel::new(&topic).unwrap();
                    web_sys::js_sys::Reflect::set(&global, &(KEY.into()), &channel).unwrap();
                    channel
                } else {
                    value.dyn_into().unwrap()
                };
                let event = serde_wasm_bindgen::to_value(&event).expect("convert to js");
                channel.post_message(&event).unwrap();
            }),
        });

        match Self::new_internal(
            database,
            password,
            mnemonic_str,
            websocket_proxy_addr,
            network_str,
            user_esplora_url,
            user_rgs_url,
            lsp_url,
            lsp_connection_string,
            lsp_token,
            auth_url,
            subscription_url,
            storage_url,
            auth_storage_url,
            do_not_connect_peers,
            skip_device_lock,
            safe_mode,
            skip_hodl_invoices,
            do_not_bump_channel_close_tx,
            sweep_target_address,
            nip_07_key,
            blind_auth_url,
            hermes_url,
            ln_event_callback,
        )
        .await
        {
            Ok(m) => {
                log_info!(
                    m.inner.logger,
                    "Wallet startup took {}ms",
                    start.elapsed().as_millis()
                );
                Ok(m)
            }
            Err(e) => {
                // mark uninitialized because we failed to startup
                *init = false;
                Err(e)
            }
        }
    }

    #[allow(clippy::too_many_arguments)]
    async fn new_internal(
        database: String,
        password: Option<String>,
        mnemonic_str: Option<String>,
        websocket_proxy_addr: Option<String>,
        network_str: Option<String>,
        user_esplora_url: Option<String>,
        user_rgs_url: Option<String>,
        lsp_url: Option<String>,
        lsp_connection_string: Option<String>,
        lsp_token: Option<String>,
        auth_url: Option<String>,
        subscription_url: Option<String>,
        storage_url: Option<String>,
        auth_storage_url: Option<String>,
        do_not_connect_peers: Option<bool>,
        skip_device_lock: Option<bool>,
        safe_mode: Option<bool>,
        skip_hodl_invoices: Option<bool>,
        do_not_bump_channel_close_tx: Option<bool>,
        sweep_target_address: Option<String>,
        _nip_07_key: Option<String>,
        blind_auth_url: Option<String>,
        hermes_url: Option<String>,
        ln_event_callback: Option<CommonLnEventCallback>,
    ) -> Result<MutinyWallet, MutinyJsError> {
        let safe_mode = safe_mode.unwrap_or(false);
        let logger = Arc::new(MutinyLogger::memory_only());

        let version = env!("CARGO_PKG_VERSION");
        log_info!(logger, "Node version {version}");

        let cipher = password
            .as_ref()
            .filter(|p| !p.is_empty())
            .map(|p| encryption_key_from_pass(p))
            .transpose()?;

        let network: Network = network_str
            .map(|s| s.parse().expect("Invalid network"))
            .unwrap_or(Network::Bitcoin);

        let override_mnemonic = mnemonic_str.map(|s| Mnemonic::from_str(&s)).transpose()?;

        let mnemonic = IndexedDbStorage::get_mnemonic(
            database.clone(),
            override_mnemonic,
            password.as_deref(),
            cipher.clone(),
        )
        .await?;

        let seed = mnemonic.to_seed("");
        let xprivkey = Xpriv::new_master(network, &seed).unwrap();

        let (auth_client, vss_client) = if safe_mode {
            (None, None)
        } else if auth_storage_url.is_none() || auth_url.is_none() {
            let vss = storage_url.map(|url| {
                Arc::new(MutinyVssClient::new_unauthenticated(
                    url,
                    xprivkey.private_key,
                    logger.clone(),
                ))
            });

            (None, vss)
        } else {
            let auth_manager = AuthManager::new(xprivkey).unwrap();

            let auth_client = Arc::new(MutinyAuthClient::new(
                auth_manager,
                logger.clone(),
                auth_url.unwrap(),
            ));

            // immediately start fetching JWT
            let auth = auth_client.clone();
            let logger_clone = logger.clone();
            // if this errors, it's okay, we'll call it again when we fetch vss
            if let Err(e) = auth.authenticate().await {
                log_warn!(
                    logger_clone,
                    "Failed to authenticate on startup, will retry on next call: {e}"
                );
            }

            if storage_url.is_none() {
                let vss = auth_storage_url.map(|url| {
                    Arc::new(MutinyVssClient::new_authenticated(
                        auth_client.clone(),
                        url,
                        xprivkey.private_key,
                        logger.clone(),
                    ))
                });

                (Some(auth_client), vss)
            } else if has_used_storage_url(
                storage_url.clone().unwrap(),
                &xprivkey.private_key,
                logger.clone(),
            )
            .await?
            {
                let vss = storage_url.map(|url| {
                    Arc::new(MutinyVssClient::new_unauthenticated(
                        url,
                        xprivkey.private_key,
                        logger.clone(),
                    ))
                });

                (None, vss)
            } else {
                let vss = auth_storage_url.map(|url| {
                    Arc::new(MutinyVssClient::new_authenticated(
                        auth_client.clone(),
                        url,
                        xprivkey.private_key,
                        logger.clone(),
                    ))
                });

                (Some(auth_client), vss)
            }
        };

        let storage =
            IndexedDbStorage::new(database, password, cipher, vss_client, logger.clone()).await?;

        let mut config_builder = MutinyWalletConfigBuilder::new(xprivkey).with_network(network);
        if let Some(w) = websocket_proxy_addr {
            config_builder.with_websocket_proxy_addr(w);
        }
        if let Some(url) = user_esplora_url {
            config_builder.with_user_esplora_url(url);
        }
        if let Some(url) = user_rgs_url {
            config_builder.with_user_rgs_url(url);
        }
        if let Some(url) = lsp_url {
            config_builder.with_lsp_url(url);
        }
        if let Some(url) = lsp_connection_string {
            config_builder.with_lsp_connection_string(url);
        }
        if let Some(url) = lsp_token {
            config_builder.with_lsp_token(url);
        }
        if let Some(a) = auth_client {
            config_builder.with_auth_client(a);
        }
        if let Some(url) = subscription_url {
            config_builder.with_subscription_url(url);
        }
        if let Some(url) = blind_auth_url {
            config_builder.with_blind_auth_url(url);
        }
        if let Some(url) = hermes_url {
            config_builder.with_hermes_url(url);
        }
        if let Some(true) = skip_device_lock {
            config_builder.with_skip_device_lock();
        }
        if let Some(false) = skip_hodl_invoices {
            config_builder.do_not_skip_hodl_invoices();
        }
        if let Some(true) = do_not_connect_peers {
            config_builder.do_not_connect_peers();
        }
        if let Some(true) = do_not_bump_channel_close_tx {
            config_builder.do_not_bump_channel_close_tx();
        }
        if let Some(ref address) = sweep_target_address {
            let send_to = Address::from_str(address)?.require_network(network)?;
            config_builder.with_sweep_target_address(send_to);
        }
        if safe_mode {
            config_builder.with_safe_mode();
        }
        let config = config_builder.build();

        let mut mw_builder = MutinyWalletBuilder::new(xprivkey, storage).with_config(config);
        mw_builder.with_session_id(logger.session_id.clone());
        mw_builder.with_logs(logger.get_memory_logs()?);
        if let Some(cb) = ln_event_callback {
            mw_builder.with_ln_event_callback(cb);
        }
        let inner = mw_builder.build().await?;

        Ok(MutinyWallet { mnemonic, inner })
    }

    fn get_node_manager(&self) -> Result<&NodeManager<IndexedDbStorage>, MutinyJsError> {
        let node_manager = self
            .inner
            .node_manager
            .as_ref()
            .ok_or(MutinyError::NotRunning)?;
        Ok(node_manager)
    }

    pub fn is_safe_mode(&self) -> bool {
        self.inner.is_safe_mode()
    }

    #[wasm_bindgen]
    pub async fn get_version() -> String {
        let version = env!("CARGO_PKG_VERSION");
        version.to_string()
    }

    /// Returns if there is a saved wallet in storage.
    /// This is checked by seeing if a mnemonic seed exists in storage.
    #[wasm_bindgen]
    pub async fn has_node_manager(database: String) -> Result<bool, MutinyJsError> {
        Ok(IndexedDbStorage::has_mnemonic(database).await?)
    }

    /// Returns the number of remaining seconds until the device lock expires.
    #[wasm_bindgen]
    pub async fn get_device_lock_remaining_secs(
        database: String,
        password: Option<String>,
        auth_url: Option<String>,
        storage_url: Option<String>,
        auth_storage_url: Option<String>,
    ) -> Result<Option<u64>, MutinyJsError> {
        let logger = Arc::new(MutinyLogger::default());
        let cipher = password
            .as_ref()
            .filter(|p| !p.is_empty())
            .map(|p| encryption_key_from_pass(p))
            .transpose()?;
        let mnemonic =
            IndexedDbStorage::get_mnemonic(database, None, password.as_deref(), cipher.clone())
                .await?;

        let seed = mnemonic.to_seed("");
        // Network doesn't matter here, only for encoding
        let xprivkey = Xpriv::new_master(Network::Bitcoin, &seed).unwrap();

        let vss_client = if auth_storage_url.is_none() || auth_url.is_none() {
            storage_url.map(|url| {
                Arc::new(MutinyVssClient::new_unauthenticated(
                    url,
                    xprivkey.private_key,
                    logger.clone(),
                ))
            })
        } else {
            let auth_manager = AuthManager::new(xprivkey).unwrap();

            let auth_client = Arc::new(MutinyAuthClient::new(
                auth_manager,
                logger.clone(),
                auth_url.unwrap(),
            ));

            // immediately start fetching JWT
            let auth = auth_client.clone();
            let logger_clone = logger.clone();
            // if this errors, it's okay, we'll call it again when we fetch vss
            if let Err(e) = auth.authenticate().await {
                log_warn!(
                    logger_clone,
                    "Failed to authenticate on startup, will retry on next call: {e}"
                );
            }

            if storage_url.is_none() {
                auth_storage_url.map(|url| {
                    Arc::new(MutinyVssClient::new_authenticated(
                        auth_client.clone(),
                        url,
                        xprivkey.private_key,
                        logger.clone(),
                    ))
                })
            } else if has_used_storage_url(
                storage_url.clone().unwrap(),
                &xprivkey.private_key,
                logger.clone(),
            )
            .await?
            {
                storage_url.map(|url| {
                    Arc::new(MutinyVssClient::new_unauthenticated(
                        url,
                        xprivkey.private_key,
                        logger.clone(),
                    ))
                })
            } else {
                auth_storage_url.map(|url| {
                    Arc::new(MutinyVssClient::new_authenticated(
                        auth_client.clone(),
                        url,
                        xprivkey.private_key,
                        logger.clone(),
                    ))
                })
            }
        };

        if let Some(vss) = vss_client {
            let obj = vss.get_object(DEVICE_LOCK_KEY).await?;
            let lock = serde_json::from_value::<DeviceLock>(obj.value)?;

            return Ok(Some(lock.remaining_secs()));
        };

        Ok(None)
    }

    /// Starts up all the nodes again.
    /// Not needed after [NodeManager]'s `new()` function.
    #[wasm_bindgen]
    pub async fn start(&mut self) -> Result<(), MutinyJsError> {
        Ok(self.inner.start().await?)
    }

    /// Stops all of the nodes and background processes.
    /// Returns after node has been stopped.
    #[wasm_bindgen]
    pub async fn stop(&mut self) -> Result<(), MutinyJsError> {
        // Ok(self.inner.node_manager.stop().await?)

        // uninit
        let mut init = INITIALIZED.lock().await;
        *init = false;

        Ok(self.inner.stop().await?)
    }

    /// Returns the mnemonic seed phrase for the wallet.
    #[wasm_bindgen]
    pub fn show_seed(&self) -> String {
        self.mnemonic.to_string()
    }

    /// Returns the network of the wallet.
    #[wasm_bindgen]
    pub fn get_network(&self) -> String {
        self.inner.get_network().to_string()
    }

    /// Gets a new bitcoin address from the wallet.
    /// Will generate a new address on every call.
    ///
    /// It is recommended to create a new address for every transaction.
    #[wasm_bindgen]
    pub async fn get_new_address(
        &self,
        labels: Vec<String>,
    ) -> Result<MutinyBip21RawMaterials, MutinyJsError> {
        let address = self.inner.create_address(labels.clone()).await?;
        Ok(MutinyBip21RawMaterials {
            address: address.to_string(),
            invoice: None,
            btc_amount: None,
            labels,
        })
    }

    /// Creates a BIP 21 invoice. This creates a new address and a lightning invoice.
    /// The lightning invoice may return errors related to the LSP. Check the error and
    /// fallback to `get_new_address` and warn the user that Lightning is not available.
    ///
    ///
    /// Errors that might be returned include:
    ///
    /// - [`MutinyJsError::LspGenericError`]: This is returned for various reasons, including if a
    ///   request to the LSP server fails for any reason, or if the server returns
    ///   a status other than 500 that can't be parsed into a `ProposalResponse`.
    ///
    /// - [`MutinyJsError::LspFundingError`]: Returned if the LSP server returns an error with
    ///   a status of 500, indicating an "Internal Server Error", and a message
    ///   stating "Cannot fund new channel at this time". This means that the LSP cannot support
    ///   a new channel at this time.
    ///
    /// - [`MutinyJsError::LspAmountTooHighError`]: Returned if the LSP server returns an error with
    ///   a status of 500, indicating an "Internal Server Error", and a message stating "Invoice
    ///   amount is too high". This means that the LSP cannot support the amount that the user
    ///   requested. The user should request a smaller amount from the LSP.
    ///
    /// - [`MutinyJsError::LspConnectionError`]: Returned if the LSP server returns an error with
    ///   a status of 500, indicating an "Internal Server Error", and a message that starts with
    ///   "Failed to connect to peer". This means that the LSP is not connected to our node.
    ///
    /// If the server returns a status of 500 with a different error message,
    /// a [`MutinyJsError::LspGenericError`] is returned.
    #[wasm_bindgen]
    pub async fn create_bip21(
        &self,
        amount: Option<u64>,
        labels: Vec<String>,
    ) -> Result<MutinyBip21RawMaterials, MutinyJsError> {
        Ok(self.inner.create_bip21(amount, labels).await?.into())
    }

    /// Sends an on-chain transaction to the given address.
    /// The amount is in satoshis and the fee rate is in sat/vbyte.
    ///
    /// If a fee rate is not provided, one will be used from the fee estimator.
    #[wasm_bindgen]
    pub async fn send_to_address(
        &self,
        destination_address: String,
        amount: u64,
        labels: Vec<String>,
        fee_rate: Option<u64>,
    ) -> Result<String, MutinyJsError> {
        let send_to =
            Address::from_str(&destination_address)?.require_network(self.inner.get_network())?;
        Ok(self
            .inner
            .send_to_address(send_to, amount, labels, fee_rate)
            .await?
            .to_string())
    }

    /// Sweeps all the funds from the wallet to the given address.
    /// The fee rate is in sat/vbyte.
    ///
    /// If a fee rate is not provided, one will be used from the fee estimator.
    #[wasm_bindgen]
    pub async fn sweep_wallet(
        &self,
        destination_address: String,
        labels: Vec<String>,
        fee_rate: Option<u64>,
        allow_dust: Option<bool>,
    ) -> Result<String, MutinyJsError> {
        let send_to =
            Address::from_str(&destination_address)?.require_network(self.inner.get_network())?;
        Ok(self
            .inner
            .sweep_wallet(send_to, labels, fee_rate, allow_dust)
            .await?
            .to_string())
    }

    /// Constructs a sweep transaction to move all funds from the wallet to the given address.
    /// The fee rate is in sat/vbyte.
    ///
    /// If a fee rate is not provided, one will be used from the fee estimator.
    #[wasm_bindgen]
    pub async fn construct_sweep_tx(
        &self,
        destination_address: String,
        fee_rate: Option<u64>,
        allow_dust: Option<bool>,
    ) -> Result<String, MutinyJsError> {
        let send_to =
            Address::from_str(&destination_address)?.require_network(self.inner.get_network())?;
        Ok(self
            .inner
            .construct_sweep_tx(send_to, fee_rate, allow_dust)?)
    }

    /// Inserts an unconfirmed transaction into the wallet.
    /// The transaction is provided as a hexadecimal string and the last seen time is in seconds.
    #[wasm_bindgen]
    pub async fn insert_unconfirmed_tx(
        &self,
        tx_hex: String,
        last_seen: u64,
    ) -> Result<(), MutinyJsError> {
        Ok(self.inner.insert_unconfirmed_tx(tx_hex, last_seen).await?)
    }

    /// Estimates the onchain fee for a transaction sending to the given address.
    /// The amount is in satoshis and the fee rate is in sat/vbyte.
    pub async fn estimate_tx_fee(
        &self,
        destination_address: String,
        amount: u64,
        fee_rate: Option<u64>,
    ) -> Result<u64, MutinyJsError> {
        let addr = Address::from_str(&destination_address)?.assume_checked();
        Ok(self.inner.estimate_tx_fee(addr, amount, fee_rate).await?)
    }

    /// Estimates the onchain fee for a opening a lightning channel.
    /// The amount is in satoshis and the fee rate is in sat/vbyte.
    pub fn estimate_channel_open_fee(
        &self,
        amount: u64,
        fee_rate: Option<u64>,
    ) -> Result<u64, MutinyJsError> {
        Ok(self
            .get_node_manager()?
            .estimate_channel_open_fee(amount, fee_rate)?)
    }

    /// Estimates the onchain fee for sweeping our on-chain balance to open a lightning channel.
    /// The fee rate is in sat/vbyte.
    pub fn estimate_sweep_channel_open_fee(
        &self,
        fee_rate: Option<u64>,
        allow_dust: Option<bool>,
    ) -> Result<u64, MutinyJsError> {
        Ok(self
            .get_node_manager()?
            .estimate_sweep_channel_open_fee(fee_rate, allow_dust)?)
    }

    /// Estimates the lightning fee for a transaction. Amount is either from the invoice
    /// if one is available or a passed in amount (priority). It will try to predict either
    /// sending the payment through a federation or through lightning, depending on balances.
    /// The amount and fee is in satoshis.
    /// Returns None if it has no good way to calculate fee.
    pub async fn estimate_ln_fee(
        &self,
        invoice_str: Option<String>,
        amt_sats: Option<u64>,
    ) -> Result<Option<u64>, MutinyJsError> {
        let invoice = match invoice_str {
            Some(i) => Some(Bolt11Invoice::from_str(&i)?),
            None => None,
        };
        Ok(self
            .inner
            .estimate_ln_fee(invoice.as_ref(), amt_sats)
            .await?)
    }

    /// Bumps the given transaction by replacing the given tx with a transaction at
    /// the new given fee rate in sats/vbyte
    pub async fn bump_fee(&self, txid: String, fee_rate: u64) -> Result<String, MutinyJsError> {
        let txid = Txid::from_str(&txid)?;
        let result = self.get_node_manager()?.bump_fee(txid, fee_rate).await?;

        Ok(result.to_string())
    }

    /// Checks if the given address has any transactions.
    /// If it does, it returns the details of the first transaction.
    ///
    /// This should be used to check if a payment has been made to an address.
    #[wasm_bindgen]
    pub async fn check_address(
        &self,
        address: String,
    ) -> Result<JsValue /* Option<TransactionDetails> */, MutinyJsError> {
        let address = Address::from_str(&address)?;
        Ok(JsValue::from_serde(
            &self.get_node_manager()?.check_address(address).await?,
        )?)
    }

    /// Gets the details of a specific on-chain transaction.
    #[wasm_bindgen]
    pub fn get_transaction(
        &self,
        txid: String,
    ) -> Result<JsValue /* Option<TransactionDetails> */, MutinyJsError> {
        let txid = Txid::from_str(&txid)?;
        Ok(JsValue::from_serde(&self.inner.get_transaction(txid)?)?)
    }

    /// Gets the current balance of the wallet.
    /// This includes both on-chain and lightning funds.
    ///
    /// This will not include any funds in an unconfirmed lightning channel.
    #[wasm_bindgen]
    pub async fn get_balance(&self) -> Result<MutinyBalance, MutinyJsError> {
        Ok(self.inner.get_balance().await?.into())
    }

    /// Lists all the UTXOs in the wallet.
    #[wasm_bindgen]
    pub fn list_utxos(&self) -> Result<JsValue, MutinyJsError> {
        Ok(JsValue::from_serde(
            &self.get_node_manager()?.list_utxos()?,
        )?)
    }

    /// Gets a fee estimate for an low priority transaction.
    /// Value is in sat/vbyte.
    #[wasm_bindgen]
    pub fn estimate_fee_low(&self) -> Result<u32, MutinyJsError> {
        Ok(self.get_node_manager()?.estimate_fee_low())
    }

    /// Gets a fee estimate for an average priority transaction.
    /// Value is in sat/vbyte.
    #[wasm_bindgen]
    pub fn estimate_fee_normal(&self) -> Result<u32, MutinyJsError> {
        Ok(self.get_node_manager()?.estimate_fee_normal())
    }

    /// Gets a fee estimate for an high priority transaction.
    /// Value is in sat/vbyte.
    #[wasm_bindgen]
    pub fn estimate_fee_high(&self) -> Result<u32, MutinyJsError> {
        Ok(self.get_node_manager()?.estimate_fee_high())
    }

    /// Creates a new lightning node and adds it to the manager.
    #[wasm_bindgen]
    pub async fn new_node(&self) -> Result<NodeIdentity, MutinyJsError> {
        Ok(self.get_node_manager()?.new_node().await?.into())
    }

    /// Lists the pubkeys of the lightning node in the manager.
    #[wasm_bindgen]
    pub async fn list_nodes(&self) -> Result<JsValue /* Vec<String> */, MutinyJsError> {
        Ok(JsValue::from_serde(
            &self.get_node_manager()?.list_nodes().await?,
        )?)
    }

    /// Changes all the node's LSPs to the given config. If any of the nodes have an active channel with the
    /// current LSP, it will fail to change the LSP.
    ///
    /// Requires a restart of the node manager to take effect.
    pub async fn change_lsp(
        &self,
        lsp_url: Option<String>,
        lsp_connection_string: Option<String>,
        lsp_token: Option<String>,
    ) -> Result<(), MutinyJsError> {
        let lsp_config = create_lsp_config(lsp_url, lsp_connection_string, lsp_token)?;

        self.get_node_manager()?.change_lsp(lsp_config).await?;
        Ok(())
    }

    /// Returns the current LSP config
    pub async fn get_configured_lsp(&self) -> Result<JsValue, MutinyJsError> {
        match self.get_node_manager()?.get_configured_lsp().await? {
            Some(LspConfig::VoltageFlow(config)) => Ok(JsValue::from_serde(&config)?),
            Some(LspConfig::Lsps(config)) => Ok(JsValue::from_serde(&config)?),
            None => Ok(JsValue::NULL),
        }
    }

    /// Attempts to connect to a peer from the selected node.
    #[wasm_bindgen]
    pub async fn connect_to_peer(
        &self,
        connection_string: String,
        label: Option<String>,
    ) -> Result<(), MutinyJsError> {
        Ok(self
            .get_node_manager()?
            .connect_to_peer(None, &connection_string, label)
            .await?)
    }

    /// Disconnects from a peer from the selected node.
    #[wasm_bindgen]
    pub async fn disconnect_peer(&self, peer: String) -> Result<(), MutinyJsError> {
        let peer = PublicKey::from_str(&peer)?;
        Ok(self.get_node_manager()?.disconnect_peer(None, peer).await?)
    }

    /// Deletes a peer from the selected node.
    /// This will make it so that the node will not attempt to
    /// reconnect to the peer.
    #[wasm_bindgen]
    pub async fn delete_peer(&self, peer: String) -> Result<(), MutinyJsError> {
        let peer = NodeId::from_str(&peer).map_err(|_| MutinyJsError::InvalidArgumentsError)?;
        Ok(self.get_node_manager()?.delete_peer(None, &peer).await?)
    }

    /// Sets the label of a peer from the selected node.
    #[wasm_bindgen]
    pub fn label_peer(&self, node_id: String, label: Option<String>) -> Result<(), MutinyJsError> {
        let node_id =
            NodeId::from_str(&node_id).map_err(|_| MutinyJsError::InvalidArgumentsError)?;
        self.get_node_manager()?.label_peer(&node_id, label)?;
        Ok(())
    }

    /// Creates a lightning invoice. The amount should be in satoshis.
    /// If no amount is provided, the invoice will be created with no amount.
    /// If no description is provided, the invoice will be created with no description.
    ///
    /// If the manager has more than one node it will create a phantom invoice.
    /// If there is only one node it will create an invoice just for that node.
    #[wasm_bindgen]
    pub async fn create_invoice(
        &self,
        amount: Option<u64>,
        label: String,
        expiry_delta_secs: Option<u32>,
    ) -> Result<MutinyInvoice, MutinyJsError> {
        Ok(self
            .inner
            .create_invoice(amount, vec![label], expiry_delta_secs)
            .await?
            .into())
    }

    /// Pays a lightning invoice from the selected node.
    /// An amount should only be provided if the invoice does not have an amount.
    /// The amount should be in satoshis.
    #[wasm_bindgen]
    pub async fn pay_invoice(
        &self,
        invoice_str: String,
        amt_sats: Option<u64>,
        labels: Vec<String>,
    ) -> Result<MutinyInvoice, MutinyJsError> {
        let invoice = Bolt11Invoice::from_str(&invoice_str)?;
        Ok(self
            .inner
            .pay_invoice(&invoice, amt_sats, labels)
            .await?
            .into())
    }

    /// Sends a spontaneous payment to a node from the selected node.
    /// The amount should be in satoshis.
    #[wasm_bindgen]
    pub async fn keysend(
        &self,
        to_node: String,
        amt_sats: u64,
        message: Option<String>,
        labels: Vec<String>,
    ) -> Result<MutinyInvoice, MutinyJsError> {
        let to_node = PublicKey::from_str(&to_node)?;
        Ok(self
            .get_node_manager()?
            .keysend(None, to_node, amt_sats, message, labels)
            .await?
            .into())
    }

    /// Decodes a lightning invoice into useful information.
    /// Will return an error if the invoice is for a different network.
    #[wasm_bindgen]
    pub async fn decode_invoice(
        &self,
        invoice: String,
        network: Option<String>,
    ) -> Result<MutinyInvoice, MutinyJsError> {
        let invoice = Bolt11Invoice::from_str(&invoice)?;
        let network = network
            .map(|n| Network::from_str(&n).map_err(|_| MutinyJsError::InvalidArgumentsError))
            .transpose()?;
        Ok(self.inner.decode_invoice(invoice, network)?.into())
    }

    /// Gets an invoice from the node manager.
    /// This includes sent and received invoices.
    #[wasm_bindgen]
    pub async fn get_invoice(&self, invoice: String) -> Result<MutinyInvoice, MutinyJsError> {
        let invoice = Bolt11Invoice::from_str(&invoice)?;
        Ok(self.inner.get_invoice(&invoice).await?.into())
    }

    /// Gets an invoice from the node manager.
    /// This includes sent and received invoices.
    #[wasm_bindgen]
    pub async fn get_invoice_by_hash(&self, hash: String) -> Result<MutinyInvoice, MutinyJsError> {
        let hash: sha256::Hash = sha256::Hash::from_str(&hash)?;
        Ok(self.inner.get_invoice_by_hash(&hash).await?.into())
    }

    /// Gets an invoice from the node manager.
    /// This includes sent and received invoices.
    #[wasm_bindgen]
    pub async fn list_invoices(&self) -> Result<JsValue /* Vec<MutinyInvoice> */, MutinyJsError> {
        Ok(JsValue::from_serde(&self.inner.list_invoices()?)?)
    }

    /// Gets an channel closure from the node manager.
    #[wasm_bindgen]
    pub async fn get_channel_closure(
        &self,
        user_channel_id: String,
    ) -> Result<ChannelClosure, MutinyJsError> {
        let user_channel_id: [u8; 16] = FromHex::from_hex(&user_channel_id)?;
        Ok(self
            .get_node_manager()?
            .get_channel_closure(u128::from_be_bytes(user_channel_id))
            .await?
            .into())
    }

    /// Gets all channel closures from the node manager.
    ///
    /// The channel closures are sorted by the time they were closed.
    #[wasm_bindgen]
    pub async fn list_channel_closures(
        &self,
    ) -> Result<JsValue /* Vec<ChannelClosure> */, MutinyJsError> {
        let mut channel_closures: Vec<ChannelClosure> = self
            .get_node_manager()?
            .list_channel_closures()
            .await?
            .into_iter()
            .filter(|closure| closure.timestamp != 0) // filter out placeholder closures
            .map(Into::into)
            .collect();
        channel_closures.sort();
        Ok(JsValue::from_serde(&channel_closures)?)
    }

    /// Opens a channel from our selected node to the given pubkey.
    /// The amount is in satoshis.
    ///
    /// The node must be online and have a connection to the peer.
    /// The wallet much have enough funds to open the channel.
    #[wasm_bindgen]
    pub async fn open_channel(
        &self,
        to_pubkey: Option<String>,
        amount: u64,
        fee_rate: Option<u64>,
    ) -> Result<MutinyChannel, MutinyJsError> {
        let to_pubkey = match to_pubkey {
            Some(pubkey_str) if !pubkey_str.trim().is_empty() => {
                Some(PublicKey::from_str(&pubkey_str)?)
            }
            _ => None,
        };

        Ok(self
            .get_node_manager()?
            .open_channel(None, to_pubkey, amount, fee_rate, None)
            .await?
            .into())
    }

    /// Opens a channel from our selected node to the given pubkey.
    /// It will spend the all the on-chain utxo in full to fund the channel.
    ///
    /// The node must be online and have a connection to the peer.
    pub async fn sweep_all_to_channel(
        &self,
        to_pubkey: Option<String>,
    ) -> Result<MutinyChannel, MutinyJsError> {
        let to_pubkey = match to_pubkey {
            Some(pubkey_str) if !pubkey_str.trim().is_empty() => {
                Some(PublicKey::from_str(&pubkey_str)?)
            }
            _ => None,
        };

        Ok(self
            .get_node_manager()?
            .sweep_all_to_channel(to_pubkey)
            .await?
            .into())
    }

    /// Closes a channel with the given outpoint.
    ///
    /// If force is true, the channel will be force closed.
    ///
    /// If abandon is true, the channel will be abandoned.
    /// This will force close without broadcasting the latest transaction.
    /// This should only be used if the channel will never actually be opened.
    ///
    /// If both force and abandon are true, an error will be returned.
    /// The address must match the network and the network: "bitcoin", "testnet", "signet", "regtest"
    ///
    /// if leave target_feerate_sats_per_1000_weight to none, the node will determine a target
    /// feerate base on current network status
    #[wasm_bindgen]
    pub async fn close_channel(
        &self,
        outpoint: String,
        force: bool,
        abandon: bool,
        address: Option<String>,
        network: Option<String>,
        target_feerate_sats_per_1000_weight: Option<u32>,
    ) -> Result<(), MutinyJsError> {
        let outpoint: OutPoint =
            OutPoint::from_str(&outpoint).map_err(|_| MutinyJsError::InvalidArgumentsError)?;

        let network = if let Some(net) = network {
            Network::from_str(&net).map_err(|_| MutinyJsError::InvalidAddressNetworkError)?
        } else {
            Network::Bitcoin
        };
        let address = if let Some(addr) = address {
            let addr_ = Address::from_str(&addr)
                .map_err(|_| MutinyJsError::InvalidAddressNetworkError)?
                .require_network(network)
                .map_err(|_| MutinyJsError::InvalidAddressNetworkError)?;
            Some(addr_)
        } else {
            None
        };

        Ok(self
            .get_node_manager()?
            .close_channel(
                &outpoint,
                address,
                force,
                abandon,
                target_feerate_sats_per_1000_weight,
            )
            .await?)
    }

    /// Lists all the channels for all the nodes in the node manager.
    #[wasm_bindgen]
    pub async fn list_channels(&self) -> Result<JsValue /* Vec<MutinyChannel> */, MutinyJsError> {
        Ok(JsValue::from_serde(
            &self.get_node_manager()?.list_channels().await?,
        )?)
    }

    /// Lists all the peers for all the nodes in the node manager.
    #[wasm_bindgen]
    pub async fn list_peers(&self) -> Result<JsValue /* Vec<MutinyPeer> */, MutinyJsError> {
        Ok(JsValue::from_serde(
            &self.get_node_manager()?.list_peers().await?,
        )?)
    }

    /// Returns all the on-chain and lightning activity from the wallet.
    #[wasm_bindgen]
    pub async fn get_activity(
        &self,
        limit: Option<usize>,
        offset: Option<usize>,
    ) -> Result<JsValue /* Vec<ActivityItem> */, MutinyJsError> {
        // get activity from the node manager
        let activity = self.inner.get_activity(limit, offset)?;
        let activity: Vec<ActivityItem> = activity.into_iter().map(|a| a.into()).collect();
        Ok(JsValue::from_serde(&activity)?)
    }

    pub fn get_address_labels(
        &self,
    ) -> Result<JsValue /* Map<Address, Vec<String>> */, MutinyJsError> {
        Ok(JsValue::from_serde(
            &self.get_node_manager()?.get_address_labels()?,
        )?)
    }

    /// Set the labels for an address, replacing any existing labels
    /// If you want to do not want to replace any existing labels, use `get_address_labels` to get the existing labels,
    /// add the new labels, and then use `set_address_labels` to set the new labels
    pub fn set_address_labels(
        &self,
        address: String,
        labels: Vec<String>,
    ) -> Result<(), MutinyJsError> {
        let address = Address::from_str(&address)?.assume_checked();
        Ok(self
            .get_node_manager()?
            .set_address_labels(address, labels)?)
    }

    pub fn get_invoice_labels(
        &self,
    ) -> Result<JsValue /* Map<Invoice, Vec<String>> */, MutinyJsError> {
        Ok(JsValue::from_serde(
            &self.get_node_manager()?.get_invoice_labels()?,
        )?)
    }

    /// Set the labels for an invoice, replacing any existing labels
    /// If you want to do not want to replace any existing labels, use `get_invoice_labels` to get the existing labels,
    /// add the new labels, and then use `set_invoice_labels` to set the new labels
    pub fn set_invoice_labels(
        &self,
        invoice: String,
        labels: Vec<String>,
    ) -> Result<(), MutinyJsError> {
        let invoice = Bolt11Invoice::from_str(&invoice)?;
        Ok(self
            .get_node_manager()?
            .set_invoice_labels(invoice, labels)?)
    }

    /// Gets the current bitcoin price in chosen Fiat.
    #[wasm_bindgen]
    pub async fn get_bitcoin_price(&self, fiat: Option<String>) -> Result<f32, MutinyJsError> {
        Ok(self.inner.get_bitcoin_price(fiat).await?)
    }

    /// Exports the current state of the node manager to a json object.
    #[wasm_bindgen]
    pub async fn get_logs(
        database: String,
    ) -> Result<JsValue /* Option<Vec<String>> */, MutinyJsError> {
        let logs = IndexedDbStorage::get_logs(database).await?;
        Ok(JsValue::from_serde(&logs)?)
    }

    /// Resets the scorer and network graph. This can be useful if you get stuck in a bad state.
    #[wasm_bindgen]
    pub async fn reset_router(&self) -> Result<(), MutinyJsError> {
        self.get_node_manager()?.reset_router().await?;
        // Sleep to wait for indexed db to finish writing
        sleep(500).await;
        Ok(())
    }

    /// Resets BDK's keychain tracker. This will require a re-sync of the blockchain.
    ///
    /// This can be useful if you get stuck in a bad state.
    #[wasm_bindgen]
    pub async fn reset_onchain_tracker(&mut self) -> Result<(), MutinyJsError> {
        Ok(self.inner.reset_onchain_tracker().await?)
    }

    /// Exports the current state of the node manager to a json object.
    #[wasm_bindgen]
    pub async fn export_json(
        database: String,
        password: Option<String>,
    ) -> Result<String, MutinyJsError> {
        let logger = Arc::new(MutinyLogger::default());
        let cipher = password
            .as_ref()
            .filter(|p| !p.is_empty())
            .map(|p| encryption_key_from_pass(p))
            .transpose()?;
        // todo init vss
        let storage = IndexedDbStorage::new(database, password, cipher, None, logger).await?;
        if storage.get_mnemonic().is_err() {
            // if we get an error, then we have the wrong password
            return Err(MutinyJsError::IncorrectPassword);
        }
        let json = NodeManager::export_json(storage).await?;
        Ok(serde_json::to_string(&json)?)
    }

    /// Restore a node manager from a json object.
    #[wasm_bindgen]
    pub async fn import_json(database: String, json: String) -> Result<(), MutinyJsError> {
        let json: serde_json::Value = serde_json::from_str(&json)?;
        IndexedDbStorage::import(database, json).await?;
        Ok(())
    }

    /// Clears storage and deletes all data.
    ///
    /// All data in VSS persists but the device lock is cleared.
    #[wasm_bindgen]
    pub async fn delete_all(&self) -> Result<(), MutinyJsError> {
        self.inner.delete_all().await?;
        Ok(())
    }

    /// Restore's the mnemonic after deleting the previous state.
    ///
    /// Backup the state beforehand. Does not restore lightning data.
    /// Should refresh or restart afterwards. Wallet should be stopped.
    #[wasm_bindgen]
    pub async fn restore_mnemonic(
        database: String,
        m: String,
        password: Option<String>,
    ) -> Result<(), MutinyJsError> {
        let logger = Arc::new(MutinyLogger::default());
        let cipher = password
            .as_ref()
            .filter(|p| !p.is_empty())
            .map(|p| encryption_key_from_pass(p))
            .transpose()?;
        let storage =
            IndexedDbStorage::new(database, password, cipher, None, logger.clone()).await?;
        mutiny_core::MutinyWallet::<IndexedDbStorage>::restore_mnemonic(
            storage,
            Mnemonic::from_str(&m).map_err(|_| MutinyJsError::InvalidMnemonic)?,
        )
        .await?;
        Ok(())
    }

    #[wasm_bindgen]
    pub async fn change_password(
        &mut self,
        old_password: Option<String>,
        new_password: Option<String>,
    ) -> Result<(), MutinyJsError> {
        let old_p = old_password.filter(|p| !p.is_empty());
        let new_p = new_password.filter(|p| !p.is_empty());
        self.inner.change_password(old_p, new_p).await?;
        Ok(())
    }

    /// Converts a bitcoin amount in BTC to satoshis.
    #[wasm_bindgen]
    pub fn convert_btc_to_sats(btc: f64) -> Result<u64, MutinyJsError> {
        // rust bitcoin doesn't like extra precision in the float
        // so we round to the nearest satoshi
        // explained here: https://stackoverflow.com/questions/28655362/how-does-one-round-a-floating-point-number-to-a-specified-number-of-digits
        let truncated = 10i32.pow(8) as f64;
        let btc = (btc * truncated).round() / truncated;
        if let Ok(amount) = bitcoin::Amount::from_btc(btc) {
            Ok(amount.to_sat())
        } else {
            Err(MutinyJsError::BadAmountError)
        }
    }

    /// Converts a satoshi amount to BTC.
    #[wasm_bindgen]
    pub fn convert_sats_to_btc(sats: u64) -> f64 {
        bitcoin::Amount::from_sat(sats).to_btc()
    }

    /// If the invoice is from a node that gives hodl invoices
    #[wasm_bindgen]
    pub async fn is_potential_hodl_invoice(invoice: String) -> Result<bool, MutinyJsError> {
        let invoice = Bolt11Invoice::from_str(&invoice)?;
        Ok(mutiny_core::utils::is_hodl_invoice(&invoice))
    }

    /// Encrypt mnemonic with password
    #[wasm_bindgen]
    pub fn encrypt_mnemonic(mnemonic: String, password: String) -> Result<String, MutinyJsError> {
        let cipher = encryption_key_from_pass(&password).unwrap();
        encrypt(&mnemonic, cipher).map_err(|_| MutinyJsError::EncryptOrDecryptError)
    }

    /// Decrypt mnemonic with password
    #[wasm_bindgen]
    pub fn decrypt_mnemonic(encrypted: String, password: String) -> Result<String, MutinyJsError> {
        decrypt_with_password(&encrypted, &password)
            .map_err(|_| MutinyJsError::EncryptOrDecryptError)
    }
}

async fn has_used_storage_url(
    url: String,
    encryption_key: &SecretKey,
    logger: Arc<MutinyLogger>,
) -> Result<bool, MutinyJsError> {
    let vss = MutinyVssClient::new_unauthenticated(url.clone(), *encryption_key, logger.clone());
    log_info!(
        logger,
        "Reading from vss to check if it has been used before"
    );
    let keys = vss.list_key_versions(None).await?;
    let has_used: bool = !keys.is_empty();
    log_info!(logger, "Storage URL '{}' has been used: {}", url, has_used);
    Ok(has_used)
}

#[cfg(test)]
mod tests {
    use crate::utils::test::*;
    use crate::{uninit, MutinyWallet};

    use crate::error::MutinyJsError;
    use crate::indexed_db::{IndexedDbStorage, WALLET_DATABASE_NAME};
    use js_sys::Array;
    use mutiny_core::storage::MutinyStorage;
    use mutiny_core::utils::sleep;
    use wasm_bindgen::JsCast;
    use wasm_bindgen::JsValue;
    use wasm_bindgen_test::{wasm_bindgen_test as test, wasm_bindgen_test_configure};

    wasm_bindgen_test_configure!(run_in_browser);

    #[test]
    async fn create_mutiny_wallet() {
        log!("creating mutiny wallet!");
        let password = Some("password".to_string());

        assert!(
            !MutinyWallet::has_node_manager(WALLET_DATABASE_NAME.to_string())
                .await
                .unwrap()
        );
        MutinyWallet::new(
            WALLET_DATABASE_NAME.to_string(),
            password.clone(),
            None,
            None,
            Some("regtest".to_owned()),
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
        )
        .await
        .expect("mutiny wallet should initialize");
        sleep(1_000).await;
        assert!(
            MutinyWallet::has_node_manager(WALLET_DATABASE_NAME.to_string())
                .await
                .unwrap()
        );

        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .expect("failed to clear storage");
        uninit().await;
    }

    #[test]
    async fn fail_to_create_wallet_different_seed() {
        MutinyWallet::new(
            WALLET_DATABASE_NAME.to_string(),
            None,
            None,
            None,
            Some("regtest".to_owned()),
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
        )
        .await
        .expect("mutiny wallet should initialize");
        sleep(1_000).await;
        assert!(
            MutinyWallet::has_node_manager(WALLET_DATABASE_NAME.to_string())
                .await
                .unwrap()
        );
        uninit().await;

        let seed = mutiny_core::generate_seed(12).unwrap();
        let result = MutinyWallet::new(
            WALLET_DATABASE_NAME.to_string(),
            None,
            Some(seed.to_string()),
            None,
            Some("regtest".to_owned()),
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
        )
        .await;

        match result {
            Err(MutinyJsError::InvalidMnemonic) => {}
            Err(e) => panic!("should have failed to create wallet with different seed {e:?}"),
            Ok(_) => panic!("should have failed to create wallet with different seed"),
        }

        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .expect("failed to clear storage");
        uninit().await;
    }

    #[test]
    async fn fail_to_create_2_mutiny_wallets() {
        log!("trying to create 2 mutiny wallets!");
        let password = Some("password".to_string());

        assert!(
            !MutinyWallet::has_node_manager(WALLET_DATABASE_NAME.to_string())
                .await
                .unwrap()
        );
        MutinyWallet::new(
            WALLET_DATABASE_NAME.to_string(),
            password.clone(),
            None,
            None,
            Some("regtest".to_owned()),
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
        )
        .await
        .expect("mutiny wallet should initialize");
        sleep(1_000).await;
        assert!(
            MutinyWallet::has_node_manager(WALLET_DATABASE_NAME.to_string())
                .await
                .unwrap()
        );

        // try to create a second
        let result = MutinyWallet::new(
            WALLET_DATABASE_NAME.to_string(),
            password.clone(),
            None,
            None,
            Some("regtest".to_owned()),
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
        )
        .await;

        if let Err(MutinyJsError::AlreadyRunning) = result {
            // this is the expected error
        } else {
            panic!("should have failed to create a second mutiny wallet");
        };

        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .expect("failed to clear storage");
        uninit().await;
    }

    #[test]
    async fn correctly_show_seed() {
        log!("showing seed");

        let seed = mutiny_core::generate_seed(12).unwrap();

        let password = Some("password".to_string());

        // make sure storage is empty
        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .expect("failed to clear storage");

        let nm = MutinyWallet::new(
            WALLET_DATABASE_NAME.to_string(),
            password.clone(),
            Some(seed.to_string()),
            None,
            Some("regtest".to_owned()),
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
        )
        .await
        .unwrap();

        log!("checking nm");
        assert!(
            MutinyWallet::has_node_manager(WALLET_DATABASE_NAME.to_string())
                .await
                .unwrap()
        );
        log!("checking seed");
        assert_eq!(seed.to_string(), nm.show_seed());

        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .expect("failed to clear storage");
        uninit().await;
    }

    #[test]
    async fn give_correct_err_with_wrong_password() {
        let seed = mutiny_core::generate_seed(12).unwrap();

        let password = Some("password".to_string());

        // make sure storage is empty
        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .expect("failed to clear storage");

        let mut nm = MutinyWallet::new(
            WALLET_DATABASE_NAME.to_string(),
            password.clone(),
            Some(seed.to_string()),
            None,
            Some("regtest".to_owned()),
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
        )
        .await
        .unwrap();

        log!("checking nm");
        assert!(
            MutinyWallet::has_node_manager(WALLET_DATABASE_NAME.to_string())
                .await
                .unwrap()
        );
        log!("checking seed");
        assert_eq!(seed.to_string(), nm.show_seed());
        nm.stop().await.unwrap();
        drop(nm);
        uninit().await;

        // create with incorrect password
        let result = MutinyWallet::new(
            WALLET_DATABASE_NAME.to_string(),
            None,
            Some(seed.to_string()),
            None,
            Some("regtest".to_owned()),
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
        )
        .await;

        if !matches!(result, Err(MutinyJsError::IncorrectPassword)) {
            panic!("should have failed to create wallet with incorrect password");
        }

        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .expect("failed to clear storage");
        uninit().await;
    }

    #[test]
    async fn created_new_nodes() {
        log!("creating new nodes");

        let nm = MutinyWallet::new(
            WALLET_DATABASE_NAME.to_string(),
            Some("password".to_string()),
            None,
            None,
            Some("regtest".to_owned()),
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
        )
        .await
        .expect("mutiny wallet should initialize");

        let node_identity = nm.new_node().await.expect("should create new node");
        assert_ne!("", node_identity.uuid());
        assert_ne!("", node_identity.pubkey());

        let node_identity = nm
            .new_node()
            .await
            .expect("mutiny wallet should initialize");

        assert_ne!("", node_identity.uuid());
        assert_ne!("", node_identity.pubkey());

        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .expect("failed to clear storage");
        uninit().await;
    }

    fn js_to_option_vec_string(js_val: JsValue) -> Result<Option<Vec<String>>, JsValue> {
        if js_val.is_undefined() || js_val.is_null() {
            return Ok(None);
        }

        let js_array: Array = js_val
            .dyn_into()
            .map_err(|_| JsValue::from_str("Expected an array"))?;

        let vec_string: Result<Vec<String>, _> = (0..js_array.length())
            .map(|index| {
                js_array
                    .get(index)
                    .as_string()
                    .ok_or_else(|| JsValue::from_str("Expected an array of strings"))
            })
            .collect();

        vec_string.map(Some)
    }

    #[test]
    async fn test_get_logs_no_password() {
        log!("getting logs with no password");

        let nm = MutinyWallet::new(
            WALLET_DATABASE_NAME.to_string(),
            None,
            None,
            None,
            Some("regtest".to_owned()),
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
        )
        .await
        .expect("mutiny wallet should initialize");

        // create the nodes so we have some extra data
        let node_identity = nm.new_node().await.expect("should create new node");
        assert_ne!("", node_identity.uuid());
        assert_ne!("", node_identity.pubkey());

        let node_identity = nm
            .new_node()
            .await
            .expect("mutiny wallet should initialize");

        assert_ne!("", node_identity.uuid());
        assert_ne!("", node_identity.pubkey());

        // sleep to make sure logs save
        sleep(6_000).await;
        let logs = MutinyWallet::get_logs(WALLET_DATABASE_NAME.to_string())
            .await
            .expect("should get logs");
        let parsed_logs = js_to_option_vec_string(logs).expect("should parse logs");
        assert!(parsed_logs.is_some());
        assert!(!parsed_logs.clone().unwrap().is_empty());
        assert_ne!("", parsed_logs.unwrap()[0]);

        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .expect("failed to clear storage");
        uninit().await;
    }

    #[test]
    async fn test_get_logs_with_password() {
        log!("getting logs with password");

        let password = Some("password".to_string());
        let nm = MutinyWallet::new(
            WALLET_DATABASE_NAME.to_string(),
            password.clone(),
            None,
            None,
            Some("regtest".to_owned()),
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
            None,
        )
        .await
        .expect("mutiny wallet should initialize");

        // create the nodes so we have some extra data
        let node_identity = nm.new_node().await.expect("should create new node");
        assert_ne!("", node_identity.uuid());
        assert_ne!("", node_identity.pubkey());

        let node_identity = nm
            .new_node()
            .await
            .expect("mutiny wallet should initialize");

        assert_ne!("", node_identity.uuid());
        assert_ne!("", node_identity.pubkey());

        // sleep to make sure logs save
        sleep(6_000).await;
        let logs = MutinyWallet::get_logs(WALLET_DATABASE_NAME.to_string())
            .await
            .expect("should get logs");
        let parsed_logs = js_to_option_vec_string(logs).expect("should parse logs");
        assert!(parsed_logs.is_some());
        assert!(!parsed_logs.clone().unwrap().is_empty());
        assert_ne!("", parsed_logs.unwrap()[0]);

        IndexedDbStorage::clear(WALLET_DATABASE_NAME.to_string())
            .await
            .expect("failed to clear storage");
        uninit().await;
    }
}


================================================
File: mutiny-wasm/src/models.rs
================================================
use bitcoin::hashes::Hash;
use bitcoin::secp256k1::PublicKey;
use bitcoin::OutPoint;
use gloo_utils::format::JsValueSerdeExt;
use hex_conservative::DisplayHex;
use lightning_invoice::Bolt11Invoice;

use mutiny_core::event::HTLCStatus;

use mutiny_core::*;
use serde::{Deserialize, Serialize};

use std::str::FromStr;
use wasm_bindgen::prelude::*;

#[derive(Serialize, Deserialize, Debug, Clone, Copy, PartialEq, Eq)]
#[wasm_bindgen]
pub enum ActivityType {
    OnChain,
    Lightning,
    ChannelOpen,
    ChannelClose,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq, Eq)]
#[wasm_bindgen]
pub struct ActivityItem {
    bolt11: Option<Bolt11Invoice>,
    pub kind: ActivityType,
    id: String,
    pub amount_sats: Option<u64>,
    pub inbound: bool,
    pub(crate) labels: Vec<String>,
    pub last_updated: Option<u64>,
    pub fee_paid_msat: Option<u64>,
    privacy_level: String,
}

#[wasm_bindgen]
impl ActivityItem {
    #[wasm_bindgen(getter)]
    pub fn value(&self) -> JsValue {
        JsValue::from_serde(&serde_json::to_value(self).unwrap()).unwrap()
    }

    #[wasm_bindgen(getter)]
    pub fn id(&self) -> String {
        self.id.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn labels(&self) -> Vec<String> {
        self.labels.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn bolt11(&self) -> Option<String> {
        self.bolt11.clone().map(|b| b.to_string())
    }
}

impl From<mutiny_core::ActivityItem> for ActivityItem {
    fn from(a: mutiny_core::ActivityItem) -> Self {
        let kind = match a {
            mutiny_core::ActivityItem::OnChain(_) => {
                if a.is_channel_open() {
                    ActivityType::ChannelOpen
                } else {
                    ActivityType::OnChain
                }
            }
            mutiny_core::ActivityItem::Lightning(_) => ActivityType::Lightning,
            mutiny_core::ActivityItem::ChannelClosed(_) => ActivityType::ChannelClose,
        };

        let id = match a {
            mutiny_core::ActivityItem::OnChain(ref t) => t.internal_id.to_string(),
            mutiny_core::ActivityItem::Lightning(ref ln) => {
                ln.payment_hash.to_byte_array().to_lower_hex_string()
            }
            mutiny_core::ActivityItem::ChannelClosed(ref c) => c
                .user_channel_id
                .map(|c| c.to_lower_hex_string())
                .unwrap_or_default(),
        };

        let (inbound, amount_sats) = match a {
            mutiny_core::ActivityItem::OnChain(ref t) => {
                let inbound = t.received > t.sent;
                let amount_sats = if inbound {
                    Some(t.received - t.sent)
                } else {
                    Some(t.sent - t.received)
                };
                (inbound, amount_sats)
            }
            mutiny_core::ActivityItem::Lightning(ref ln) => (ln.inbound, ln.amount_sats),
            mutiny_core::ActivityItem::ChannelClosed(_) => (false, None),
        };

        let fee_paid_msat = match a {
            mutiny_core::ActivityItem::Lightning(ref ln) => ln.fee_paid_msat,
            _ => None,
        };

        let privacy_level = match kind {
            ActivityType::OnChain => PrivacyLevel::NotAvailable,
            ActivityType::Lightning => {
                if let mutiny_core::ActivityItem::Lightning(ref ln) = a {
                    ln.privacy_level
                } else {
                    PrivacyLevel::NotAvailable
                }
            }
            ActivityType::ChannelOpen => PrivacyLevel::NotAvailable,
            ActivityType::ChannelClose => PrivacyLevel::NotAvailable,
        };

        let bolt11 = match kind {
            ActivityType::Lightning => {
                if let mutiny_core::ActivityItem::Lightning(ref ln) = a {
                    ln.bolt11.clone()
                } else {
                    None
                }
            }
            _ => None,
        };

        ActivityItem {
            kind,
            id,
            amount_sats,
            inbound,
            fee_paid_msat,
            labels: a.labels(),
            bolt11,
            last_updated: a.last_updated(),
            privacy_level: privacy_level.to_string(),
        }
    }
}

#[derive(Serialize, Deserialize, Clone, Eq, PartialEq, Debug)]
#[wasm_bindgen]
pub struct MutinyInvoice {
    bolt11: Option<Bolt11Invoice>,
    description: Option<String>,
    payment_hash: String,
    preimage: Option<String>,
    payee_pubkey: Option<String>,
    pub amount_sats: Option<u64>,
    pub expire: u64,
    pub expired: bool,
    status: String,
    privacy_level: String,
    pub fees_paid: Option<u64>,
    pub inbound: bool,
    pub last_updated: u64,
    pub potential_hodl_invoice: bool,
    labels: Vec<String>,
}

#[wasm_bindgen]
impl MutinyInvoice {
    #[wasm_bindgen(getter)]
    pub fn value(&self) -> JsValue {
        JsValue::from_serde(&serde_json::to_value(self).unwrap()).unwrap()
    }

    #[wasm_bindgen(getter)]
    pub fn bolt11(&self) -> Option<String> {
        self.bolt11.clone().map(|b| b.to_string())
    }

    #[wasm_bindgen(getter)]
    pub fn description(&self) -> Option<String> {
        self.description.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn payment_hash(&self) -> String {
        self.payment_hash.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn preimage(&self) -> Option<String> {
        self.preimage.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn payee_pubkey(&self) -> Option<String> {
        self.payee_pubkey.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn status(&self) -> String {
        self.status.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn privacy_level(&self) -> String {
        self.privacy_level.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn paid(&self) -> bool {
        self.status == HTLCStatus::Succeeded.to_string()
    }

    #[wasm_bindgen(getter)]
    pub fn labels(&self) -> Vec<String> {
        self.labels.clone()
    }
}

impl From<mutiny_core::MutinyInvoice> for MutinyInvoice {
    fn from(m: mutiny_core::MutinyInvoice) -> Self {
        let potential_hodl_invoice = match m.bolt11 {
            Some(ref b) => utils::is_hodl_invoice(b),
            None => false,
        };
        let now = utils::now().as_secs();
        MutinyInvoice {
            bolt11: m.bolt11,
            description: m.description,
            payment_hash: m.payment_hash.to_byte_array().to_lower_hex_string(),
            preimage: m.preimage,
            payee_pubkey: m.payee_pubkey.map(|p| p.serialize().to_lower_hex_string()),
            amount_sats: m.amount_sats,
            expire: m.expire,
            expired: m.expire < now,
            status: m.status.to_string(),
            privacy_level: m.privacy_level.to_string(),
            fees_paid: m.fees_paid,
            inbound: m.inbound,
            last_updated: m.last_updated,
            potential_hodl_invoice,
            labels: m.labels,
        }
    }
}

#[derive(Serialize, Deserialize, Clone, Eq, PartialEq)]
#[wasm_bindgen]
pub struct MutinyPeer {
    pubkey: String,
    connection_string: Option<String>,
    alias: Option<String>,
    color: Option<String>,
    label: Option<String>,
    pub is_connected: bool,
}

#[wasm_bindgen]
impl MutinyPeer {
    #[wasm_bindgen(getter)]
    pub fn value(&self) -> JsValue {
        JsValue::from_serde(&serde_json::to_value(self).unwrap()).unwrap()
    }

    #[wasm_bindgen(getter)]
    pub fn pubkey(&self) -> String {
        self.pubkey.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn connection_string(&self) -> Option<String> {
        self.connection_string.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn alias(&self) -> Option<String> {
        self.alias.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn color(&self) -> Option<String> {
        self.color.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn label(&self) -> Option<String> {
        self.label.clone()
    }
}

impl From<nodemanager::MutinyPeer> for MutinyPeer {
    fn from(m: nodemanager::MutinyPeer) -> Self {
        MutinyPeer {
            pubkey: m.pubkey.serialize().to_lower_hex_string(),
            connection_string: m.connection_string,
            alias: m.alias,
            color: m.color,
            label: m.label,
            is_connected: m.is_connected,
        }
    }
}

#[derive(Serialize, Deserialize, Clone, Eq, PartialEq)]
#[wasm_bindgen]
pub struct MutinyChannel {
    user_chan_id: String,
    pub balance: u64,
    pub size: u64,
    pub reserve: u64,
    pub inbound: u64,
    outpoint: Option<String>,
    peer: String,
    pub confirmations_required: Option<u32>,
    pub confirmations: u32,
    pub is_outbound: bool,
    pub is_usable: bool,
    pub is_anchor: bool,
    pub force_close_spend_delay: Option<u16>,
}

#[wasm_bindgen]
impl MutinyChannel {
    #[wasm_bindgen(getter)]
    pub fn value(&self) -> JsValue {
        JsValue::from_serde(&serde_json::to_value(self).unwrap()).unwrap()
    }

    #[wasm_bindgen(getter)]
    pub fn user_chan_id(&self) -> String {
        self.user_chan_id.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn outpoint(&self) -> Option<String> {
        self.outpoint.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn peer(&self) -> String {
        self.peer.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn confirmed(&self) -> bool {
        match self.confirmations_required {
            Some(c) => self.confirmations >= c,
            None => false,
        }
    }
}

impl From<nodemanager::MutinyChannel> for MutinyChannel {
    fn from(m: nodemanager::MutinyChannel) -> Self {
        MutinyChannel {
            user_chan_id: m.user_chan_id,
            balance: m.balance,
            size: m.size,
            reserve: m.reserve,
            inbound: m.inbound,
            outpoint: m.outpoint.map(|o| o.to_string()),
            peer: m.peer.serialize().to_lower_hex_string(),
            confirmations_required: m.confirmations_required,
            confirmations: m.confirmations,
            is_outbound: m.is_outbound,
            is_usable: m.is_usable,
            is_anchor: m.is_anchor,
            force_close_spend_delay: m.force_close_spend_delay,
        }
    }
}

impl From<MutinyChannel> for nodemanager::MutinyChannel {
    fn from(m: MutinyChannel) -> Self {
        nodemanager::MutinyChannel {
            user_chan_id: m.user_chan_id,
            balance: m.balance,
            size: m.size,
            reserve: m.reserve,
            inbound: m.inbound,
            outpoint: m
                .outpoint
                .map(|o| OutPoint::from_str(&o).expect("Invalid outpoint")),
            peer: PublicKey::from_str(&m.peer).expect("Invalid peer pubkey"),
            confirmations_required: m.confirmations_required,
            confirmations: m.confirmations,
            is_outbound: m.is_outbound,
            is_usable: m.is_usable,
            is_anchor: m.is_anchor,
            force_close_spend_delay: m.force_close_spend_delay,
        }
    }
}

/// Information about a channel that was closed.
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq, Eq, Hash)]
#[wasm_bindgen]
pub struct ChannelClosure {
    channel_id: Option<String>,
    node_id: Option<String>,
    reason: String,
    pub timestamp: u64,
    channel_funding_txo: Option<String>,
    force_close_spend_delay: Option<u16>,
}

#[wasm_bindgen]
impl ChannelClosure {
    #[wasm_bindgen(getter)]
    pub fn value(&self) -> JsValue {
        JsValue::from_serde(&serde_json::to_value(self).unwrap()).unwrap()
    }

    #[wasm_bindgen(getter)]
    pub fn channel_id(&self) -> Option<String> {
        self.channel_id.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn node_id(&self) -> Option<String> {
        self.node_id.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn reason(&self) -> String {
        self.reason.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn channel_funding_txo(&self) -> Option<String> {
        self.channel_funding_txo.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn force_close_spend_delay(&self) -> Option<u16> {
        self.force_close_spend_delay
    }
}

impl PartialOrd for ChannelClosure {
    fn partial_cmp(&self, other: &Self) -> Option<core::cmp::Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for ChannelClosure {
    fn cmp(&self, other: &Self) -> core::cmp::Ordering {
        self.timestamp.cmp(&other.timestamp)
    }
}

struct ByteBuf<'a>(&'a [u8]);

impl<'a> std::fmt::LowerHex for ByteBuf<'a> {
    fn fmt(&self, fmt: &mut std::fmt::Formatter) -> Result<(), std::fmt::Error> {
        for byte in self.0 {
            fmt.write_fmt(format_args!("{:02x}", byte))?;
        }
        Ok(())
    }
}

impl From<nodemanager::ChannelClosure> for ChannelClosure {
    fn from(c: nodemanager::ChannelClosure) -> Self {
        ChannelClosure {
            channel_id: c
                .channel_id
                .map(|channel_id| format!("{:x}", ByteBuf(&channel_id))),
            node_id: c.node_id.map(|c| c.serialize().to_lower_hex_string()),
            reason: c.reason,
            timestamp: c.timestamp,
            channel_funding_txo: c.channel_funding_txo.map(|txo| format!("{}", txo)),
            force_close_spend_delay: c.force_close_spend_delay,
        }
    }
}

#[derive(Serialize, Deserialize, Clone, Eq, PartialEq)]
#[wasm_bindgen]
pub struct MutinyBalance {
    pub confirmed: u64,
    pub unconfirmed: u64,
    pub lightning: u64,
    pub closing: u64,
}

#[wasm_bindgen]
impl MutinyBalance {
    #[wasm_bindgen(getter)]
    pub fn value(&self) -> JsValue {
        JsValue::from_serde(&serde_json::to_value(self).unwrap()).unwrap()
    }
}

impl From<mutiny_core::MutinyBalance> for MutinyBalance {
    fn from(m: mutiny_core::MutinyBalance) -> Self {
        MutinyBalance {
            confirmed: m.confirmed,
            unconfirmed: m.unconfirmed,
            lightning: m.lightning,
            closing: m.closing,
        }
    }
}

#[derive(Serialize, Deserialize, Clone, Eq, PartialEq)]
#[wasm_bindgen]
pub struct LnUrlParams {
    pub max: u64,
    pub min: u64,
    tag: String,
}

#[wasm_bindgen]
impl LnUrlParams {
    #[wasm_bindgen(getter)]
    pub fn value(&self) -> JsValue {
        JsValue::from_serde(&serde_json::to_value(self).unwrap()).unwrap()
    }

    #[wasm_bindgen(getter)]
    pub fn tag(&self) -> String {
        self.tag.clone()
    }
}

impl From<mutiny_core::LnUrlParams> for LnUrlParams {
    fn from(m: mutiny_core::LnUrlParams) -> Self {
        LnUrlParams {
            max: m.max,
            min: m.min,
            tag: m.tag,
        }
    }
}

// This is the NodeIdentity that refer to a specific node
// Used for public facing identification.
#[derive(Serialize, Deserialize, Clone, Eq, PartialEq)]
#[wasm_bindgen]
pub struct NodeIdentity {
    uuid: String,
    pubkey: PublicKey,
}

#[wasm_bindgen]
impl NodeIdentity {
    #[wasm_bindgen(getter)]
    pub fn value(&self) -> JsValue {
        JsValue::from_serde(&serde_json::to_value(self).unwrap()).unwrap()
    }

    #[wasm_bindgen(getter)]
    pub fn uuid(&self) -> String {
        self.uuid.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn pubkey(&self) -> String {
        self.pubkey.to_string()
    }
}

impl From<nodemanager::NodeIdentity> for NodeIdentity {
    fn from(m: nodemanager::NodeIdentity) -> Self {
        NodeIdentity {
            uuid: m.uuid,
            pubkey: m.pubkey,
        }
    }
}

#[derive(Serialize, Deserialize, Clone, Eq, PartialEq)]
#[wasm_bindgen]
pub struct MutinyBip21RawMaterials {
    pub(crate) address: String,
    pub(crate) invoice: Option<String>,
    pub(crate) btc_amount: Option<String>,
    pub(crate) labels: Vec<String>,
}

#[wasm_bindgen]
impl MutinyBip21RawMaterials {
    #[wasm_bindgen(getter)]
    pub fn value(&self) -> JsValue {
        JsValue::from_serde(&serde_json::to_value(self).unwrap()).unwrap()
    }

    #[wasm_bindgen(getter)]
    pub fn address(&self) -> String {
        self.address.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn invoice(&self) -> Option<String> {
        self.invoice.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn btc_amount(&self) -> Option<String> {
        self.btc_amount.clone()
    }

    #[wasm_bindgen(getter)]
    pub fn labels(&self) -> Vec<String> {
        self.labels.clone()
    }
}

impl From<nodemanager::MutinyBip21RawMaterials> for MutinyBip21RawMaterials {
    fn from(m: nodemanager::MutinyBip21RawMaterials) -> Self {
        MutinyBip21RawMaterials {
            address: m.address.to_string(),
            invoice: m.invoice.map(|i| i.to_string()),
            btc_amount: m.btc_amount,
            labels: m.labels,
        }
    }
}

/// FedimintSweepResult is the result of how much was swept and the fees paid.
#[derive(Serialize, Deserialize, Clone, Eq, PartialEq)]
#[wasm_bindgen]
pub struct FedimintSweepResult {
    pub amount: u64,
    pub fees: Option<u64>,
}

#[wasm_bindgen]
impl FedimintSweepResult {
    #[wasm_bindgen(getter)]
    pub fn value(&self) -> JsValue {
        JsValue::from_serde(&serde_json::to_value(self).unwrap()).unwrap()
    }
}

impl From<mutiny_core::FedimintSweepResult> for FedimintSweepResult {
    fn from(m: mutiny_core::FedimintSweepResult) -> Self {
        FedimintSweepResult {
            amount: m.amount,
            fees: m.fees,
        }
    }
}


================================================
File: mutiny-wasm/src/utils.rs
================================================
#![allow(dead_code)]
use log::{debug, Level, Log, Metadata, Record};
use wasm_bindgen::prelude::*;
use web_sys::console;

pub fn set_panic_hook() {
    // When the `console_error_panic_hook` feature is enabled, we can call the
    // `set_panic_hook` function at least once during initialization, and then
    // we will get better error messages if our code ever panics.
    //
    // For more details see
    // https://github.com/rustwasm/console_error_panic_hook#readme
    console_error_panic_hook::set_once();
}

#[wasm_bindgen(start)]
pub async fn main_js() -> Result<(), JsValue> {
    init(Config::new(Level::Trace).message_on_new_line());
    debug!("Main function begins and ends");
    Ok(())
}

/// Specify what to be logged
pub struct Config {
    level: Level,
    module_prefix: Option<String>,
    message_location: MessageLocation,
}

/// Specify where the message will be logged.
pub enum MessageLocation {
    /// The message will be on the same line as other info (level, path...)
    SameLine,
    /// The message will be on its own line, a new after other info.
    NewLine,
}

impl Default for Config {
    fn default() -> Self {
        Self {
            level: Level::Debug,
            module_prefix: None,
            message_location: MessageLocation::SameLine,
        }
    }
}

impl Config {
    /// Specify the maximum level you want to log
    pub fn new(level: Level) -> Self {
        Self {
            level,
            module_prefix: None,
            message_location: MessageLocation::SameLine,
        }
    }

    /// Configure the `target` of the logger. If specified, the logger
    /// only output for `log`s in module that its path starts with
    /// `module_prefix`. wasm-logger only supports single prefix. Only
    /// the last call to `module_prefix` has effect if you call it multiple times.
    pub fn module_prefix(mut self, module_prefix: &str) -> Self {
        self.module_prefix = Some(module_prefix.to_string());
        self
    }

    /// Put the message on a new line, separated from other information
    /// such as level, file path, line number.
    pub fn message_on_new_line(mut self) -> Self {
        self.message_location = MessageLocation::NewLine;
        self
    }
}

/// The logger
pub struct WasmLogger {
    pub config: Config,
}

impl Log for WasmLogger {
    fn enabled(&self, metadata: &Metadata<'_>) -> bool {
        if let Some(ref prefix) = self.config.module_prefix {
            metadata.target().starts_with(prefix)
        } else {
            true
        }
    }

    fn log(&self, record: &Record<'_>) {
        if self.enabled(record.metadata()) {
            let s = JsValue::from_str(&format!("{}", record.args()));

            match record.level() {
                Level::Trace => console::debug_1(&s),
                Level::Debug => console::log_1(&s),
                Level::Info => console::info_1(&s),
                Level::Warn => console::warn_1(&s),
                Level::Error => console::error_1(&s),
            }
        }
    }

    fn flush(&self) {}
}

/// Initialize the logger which the given config. If failed, it will log a message to the the browser console.
///
/// ## Examples
/// ```rust
/// wasm_logger::init(wasm_logger::Config::new(log::Level::Debug));
/// ```
/// or
/// ```rust
/// wasm_logger::init(wasm_logger::Config::with_prefix(log::Level::Debug, "some::module"));
/// ```
pub fn init(config: Config) {
    let max_level = config.level;
    let wl = WasmLogger { config };

    match log::set_boxed_logger(Box::new(wl)) {
        Ok(_) => log::set_max_level(max_level.to_level_filter()),
        Err(e) => console::error_1(&JsValue::from(e.to_string())),
    }
}

#[cfg(test)]
pub(crate) mod test {
    macro_rules! log {
        ( $( $t:tt )* ) => {
            web_sys::console::log_1(&format!( $( $t )* ).into());
        }
    }
    pub(crate) use log;
}


================================================
File: .cargo/config.toml
================================================
[build]
target = "wasm32-unknown-unknown"
# for fedimint to use tokio::task::Builder - https://github.com/fedimint/fedimint/issues/3951
rustflags = ["--cfg", "tokio_unstable"]

[target.wasm32-unknown-unknown]
# Increase the stack size to 3MB, the default is 1MB
# This is to prevent index out of bounds panics in the wasm code while running.
rustflags = [
    "-C", "link-args=-z stack-size=3000000",
]


================================================
File: .github/workflows/release.yml
================================================
name: Publish Package to npmjs
on:
  push:
    tags:
      - '*'
jobs:
  mutiny-wasm:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-node@v3
        with:
          node-version: '16.x'
          registry-url: 'https://registry.npmjs.org'

      - uses: actions-rs/toolchain@v1
        with:
          toolchain: nightly-2024-09-19
          components: clippy
          target: wasm32-unknown-unknown
          override: true
          profile: minimal

      - uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: cargo-${{ runner.os }}-release-${{ hashFiles('**/Cargo.toml') }}
          restore-keys: |
            cargo-${{ runner.os }}-release-
            cargo-${{ runner.os }}-

      - uses: jetli/wasm-pack-action@v0.4.0
        with:
          version: 'v0.13.1'

      - name: Build wasm
        env:
          RUSTUP_TOOLCHAIN: nightly-2024-09-19
        run: wasm-pack build ./mutiny-wasm --release --weak-refs --target web --scope nervina-labs

      - name: Publish wasm
        run: wasm-pack publish --access public -t web
        env:
          RUSTUP_TOOLCHAIN: nightly-2024-09-19
          NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}


================================================
File: .github/workflows/test.yml
================================================
name: Tests

on:
  pull_request:

jobs:
  check_formatting:
    name: Check Formatting
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - uses: actions/checkout@v3

      - uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: cargo-${{ runner.os }}-formatting-v2-${{ hashFiles('**/Cargo.toml', '**/Cargo.lock') }}
          restore-keys: |
            cargo-${{ runner.os }}-formatting-v2-
            cargo-${{ runner.os }}-

      - name: Install nightly toolchain
        uses: actions-rs/toolchain@v1
        with:
          toolchain: nightly-2024-09-19
          components: rustfmt
          profile: minimal

      - name: Check formatting
        run: |
          cargo +nightly-2024-09-19 fmt -- --check

      - name: Check docs
        run: cargo +nightly-2024-09-19 doc

  website:
    name: Build WASM binary
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - uses: actions/checkout@v3
      - uses: actions-rs/toolchain@v1
        with:
          toolchain: nightly-2024-09-19
          target: wasm32-unknown-unknown
          override: true
          profile: minimal

      - uses: jetli/wasm-pack-action@v0.4.0
        with:
          version: 'v0.12.1'

      - uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: cargo-${{ runner.os }}-browser-tests-v2-${{ hashFiles('**/Cargo.toml', '**/Cargo.lock') }}
          restore-keys: |
            cargo-${{ runner.os }}-browser-tests-v2-
            cargo-${{ runner.os }}-

      - name: Build wasm package
        env:
          RUSTUP_TOOLCHAIN: nightly-2024-09-19
        run: wasm-pack build ./mutiny-wasm --release --weak-refs --target web

  browser_tests:
    name: Browser Tests
    runs-on: ubuntu-latest
    timeout-minutes: 60
    env:
      RUSTUP_TOOLCHAIN: nightly-2024-09-19
      WASM_BINDGEN_TEST_TIMEOUT: 240
    steps:
      - uses: actions/checkout@v3
      - uses: actions-rs/toolchain@v1
        with:
          toolchain: nightly-2024-09-19
          target: wasm32-unknown-unknown
          override: true
          profile: minimal

      - uses: jetli/wasm-pack-action@v0.4.0
        with:
          version: 'v0.12.1'

      - name: Setup trunk
        uses: jetli/trunk-action@v0.1.0
        with:
          version: 'latest'

      - uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: cargo-${{ runner.os }}-browser-tests-v2-${{ hashFiles('**/Cargo.toml', '**/Cargo.lock') }}
          restore-keys: |
            cargo-${{ runner.os }}-browser-tests-v2-
            cargo-${{ runner.os }}-

      - run: wasm-pack test --headless --firefox ./mutiny-core
      - run: wasm-pack test --headless --chrome ./mutiny-core

      - run: wasm-pack test --headless --firefox ./mutiny-wasm
      - run: wasm-pack test --headless --chrome ./mutiny-wasm

  wasm_checks:
    name: Rust Wasm Checks
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - uses: actions/checkout@v3
      - uses: actions-rs/toolchain@v1
        with:
          toolchain: nightly-2024-09-19
          components: clippy
          target: wasm32-unknown-unknown
          override: true
          profile: minimal

      - name: Setup trunk
        uses: jetli/trunk-action@v0.1.0
        with:
          version: 'latest'

      - uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: cargo-${{ runner.os }}-rust-wasm-checks-v2-${{ hashFiles('**/Cargo.toml', '**/Cargo.lock') }}
          restore-keys: |
            cargo-${{ runner.os }}-rust-wasm-checks-v2-
            cargo-${{ runner.os }}-

      - name: Check clippy mutiny-wasm
        run: cargo clippy --all-features --tests --package mutiny-wasm -- -D warnings

  core_tests_linux:
    name: Core Tests on Linux
    timeout-minutes: 60
    runs-on: ubuntu-latest

    strategy:
      fail-fast: false
      matrix:
        target: 
          - wasm32-unknown-unknown
          - x86_64-unknown-linux-gnu

    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Install Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: nightly-2024-09-19
          override: true
          profile: minimal
          components: clippy

      - uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: cargo-${{ runner.os }}-core-tests-linux-v2-${{ hashFiles('**/Cargo.toml', '**/Cargo.lock') }}
          restore-keys: |
            cargo-${{ runner.os }}-core-tests-linux-v2-
            cargo-${{ runner.os }}-

      - name: Add targets
        run: rustup target add ${{ matrix.target }}

      - name: Run cargo clippy
        run: cargo clippy --all-features --tests --package mutiny-core --target=${{ matrix.target }} -- -D warnings

      - name: Run cargo test
        if: matrix.target != 'wasm32-unknown-unknown'
        run: cargo test --package mutiny-core --target=${{ matrix.target }}

      - name: Run cargo build
        if: matrix.target != 'wasm32-unknown-unknown'
        run: cargo build --all-features --package mutiny-core --target=${{ matrix.target }}

  core_tests_mac:
    name: Core Tests on macOS
    runs-on: macos-latest
    timeout-minutes: 60

    strategy:
      fail-fast: false
      matrix:
        target: 
          - x86_64-apple-darwin

    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Install Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: nightly-2024-09-19
          override: true
          profile: minimal
          components: clippy

      - uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: cargo-${{ runner.os }}-core-tests-mac-v2-${{ hashFiles('**/Cargo.toml', '**/Cargo.lock') }}
          restore-keys: |
            cargo-${{ runner.os }}-core-tests-mac-v2-
            cargo-${{ runner.os }}-

      - name: Add targets
        run: rustup target add ${{ matrix.target }}

      - name: Run cargo clippy
        run: cargo clippy --all-features --tests --package mutiny-core --target=${{ matrix.target }} -- -D warnings

      - name: Run cargo test
        run: cargo test --package mutiny-core --target=${{ matrix.target }}

      - name: Run cargo build
        run: cargo build --all-features --package mutiny-core --target=${{ matrix.target }}

  core_tests_windows:
    name: Core Tests on Windows
    runs-on: windows-latest
    timeout-minutes: 60

    strategy:
      fail-fast: false
      matrix:
        target: 
          - x86_64-pc-windows-msvc
          - i686-pc-windows-msvc

    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Install Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: nightly-2024-09-19
          override: true
          profile: minimal
          components: clippy

      - uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: cargo-${{ runner.os }}-core-tests-windows-v2-${{ hashFiles('**/Cargo.toml', '**/Cargo.lock') }}
          restore-keys: |
            cargo-${{ runner.os }}-core-tests-windows-v2-
            cargo-${{ runner.os }}-

      - name: Add targets
        run: rustup target add ${{ matrix.target }}

      - name: Run cargo clippy
        run: cargo clippy --all-features --tests --package mutiny-core --target=${{ matrix.target }} -- -D warnings

      - name: Run cargo test
        run: cargo test --package mutiny-core --target=${{ matrix.target }}

      - name: Run cargo build
        run: cargo build --all-features --package mutiny-core --target=${{ matrix.target }}


